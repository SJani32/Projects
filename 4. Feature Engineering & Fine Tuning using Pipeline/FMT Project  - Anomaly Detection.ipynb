{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f665e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor #as vif\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV, LeaveOneOut\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import calendar\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe54192",
   "metadata": {},
   "source": [
    "### 1. Import and understand the data. [5 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187f266",
   "metadata": {},
   "source": [
    "#### 1A. Import ‘signal-data.csv’ as DataFrame. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660877bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "      <th>Pass/Fail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-07-19 11:55:00</td>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-07-19 12:32:00</td>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>...</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>208.2045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-07-19 13:17:00</td>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>...</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>82.8602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-07-19 14:43:00</td>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>100.0</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>...</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-19 15:22:00</td>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>73.8432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time        0        1          2          3       4      5  \\\n",
       "0  2008-07-19 11:55:00  3030.93  2564.00  2187.7333  1411.1265  1.3602  100.0   \n",
       "1  2008-07-19 12:32:00  3095.78  2465.14  2230.4222  1463.6606  0.8294  100.0   \n",
       "2  2008-07-19 13:17:00  2932.61  2559.94  2186.4111  1698.0172  1.5102  100.0   \n",
       "3  2008-07-19 14:43:00  2988.72  2479.90  2199.0333   909.7926  1.3204  100.0   \n",
       "4  2008-07-19 15:22:00  3032.24  2502.87  2233.3667  1326.5200  1.5334  100.0   \n",
       "\n",
       "          6       7       8  ...       581     582     583     584      585  \\\n",
       "0   97.6133  0.1242  1.5005  ...       NaN  0.5005  0.0118  0.0035   2.3630   \n",
       "1  102.3433  0.1247  1.4966  ...  208.2045  0.5019  0.0223  0.0055   4.4447   \n",
       "2   95.4878  0.1241  1.4436  ...   82.8602  0.4958  0.0157  0.0039   3.1745   \n",
       "3  104.2367  0.1217  1.4882  ...   73.8432  0.4990  0.0103  0.0025   2.0544   \n",
       "4  100.3967  0.1235  1.5031  ...       NaN  0.4800  0.4766  0.1045  99.3032   \n",
       "\n",
       "      586     587     588       589  Pass/Fail  \n",
       "0     NaN     NaN     NaN       NaN         -1  \n",
       "1  0.0096  0.0201  0.0060  208.2045         -1  \n",
       "2  0.0584  0.0484  0.0148   82.8602          1  \n",
       "3  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "4  0.0202  0.0149  0.0044   73.8432         -1  \n",
       "\n",
       "[5 rows x 592 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1567 entries, 0 to 1566\n",
      "Columns: 592 entries, Time to Pass/Fail\n",
      "dtypes: float64(590), int64(1), object(1)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Importing the dataframe\n",
    "sd = pd.read_csv('D:/Great Learning/Study Material/7. Module-6_Featurization, Model Selection & Tuning/Featurization, Model Selection & Tuning - Project/signal-data.csv')\n",
    "display(sd.head())\n",
    "sd.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23bda14",
   "metadata": {},
   "source": [
    "- Here we observe that 1 Column is 'int' type, 1 column is 'object' type & rest all columns are 'float'  type.\n",
    "- We need to verify 'Time' column & convert it into datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a26c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd['Time'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878bc16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting 'Time' Feature to datetime format\n",
    "sd['Time'] = pd.to_datetime(sd['Time'])\n",
    "sd['Time'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0ec4a",
   "metadata": {},
   "source": [
    "#### 1B. Print 5 point summary and share at least 2 observations. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc029823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1567</td>\n",
       "      <td>2008-07-30 21:44:12.712188928</td>\n",
       "      <td>2008-01-08 02:02:00</td>\n",
       "      <td>2008-07-09 15:32:00</td>\n",
       "      <td>2008-08-23 13:02:00</td>\n",
       "      <td>2008-09-22 11:16:30</td>\n",
       "      <td>2008-12-10 18:47:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1561.0</td>\n",
       "      <td>3014.452896</td>\n",
       "      <td>2743.24</td>\n",
       "      <td>2966.26</td>\n",
       "      <td>3011.49</td>\n",
       "      <td>3056.65</td>\n",
       "      <td>3356.35</td>\n",
       "      <td>73.621787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1560.0</td>\n",
       "      <td>2495.850231</td>\n",
       "      <td>2158.75</td>\n",
       "      <td>2452.2475</td>\n",
       "      <td>2499.405</td>\n",
       "      <td>2538.8225</td>\n",
       "      <td>2846.44</td>\n",
       "      <td>80.407705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1553.0</td>\n",
       "      <td>2200.547318</td>\n",
       "      <td>2060.66</td>\n",
       "      <td>2181.0444</td>\n",
       "      <td>2201.0667</td>\n",
       "      <td>2218.0555</td>\n",
       "      <td>2315.2667</td>\n",
       "      <td>29.513152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1553.0</td>\n",
       "      <td>1396.376627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1081.8758</td>\n",
       "      <td>1285.2144</td>\n",
       "      <td>1591.2235</td>\n",
       "      <td>3715.0417</td>\n",
       "      <td>441.69164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1553.0</td>\n",
       "      <td>4.197013</td>\n",
       "      <td>0.6815</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>1.3168</td>\n",
       "      <td>1.5257</td>\n",
       "      <td>1114.5366</td>\n",
       "      <td>56.35554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1553.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1553.0</td>\n",
       "      <td>101.112908</td>\n",
       "      <td>82.1311</td>\n",
       "      <td>97.92</td>\n",
       "      <td>101.5122</td>\n",
       "      <td>104.5867</td>\n",
       "      <td>129.2522</td>\n",
       "      <td>6.237214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1558.0</td>\n",
       "      <td>0.121822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>0.008961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>1.462862</td>\n",
       "      <td>1.191</td>\n",
       "      <td>1.4112</td>\n",
       "      <td>1.4616</td>\n",
       "      <td>1.5169</td>\n",
       "      <td>1.6564</td>\n",
       "      <td>0.073897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0108</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.015116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.0349</td>\n",
       "      <td>-0.0056</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.009302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>0.964353</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.012452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>199.956809</td>\n",
       "      <td>182.094</td>\n",
       "      <td>198.1307</td>\n",
       "      <td>199.5356</td>\n",
       "      <td>202.0071</td>\n",
       "      <td>272.0451</td>\n",
       "      <td>3.257276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>9.005371</td>\n",
       "      <td>2.2493</td>\n",
       "      <td>7.094875</td>\n",
       "      <td>8.967</td>\n",
       "      <td>10.861875</td>\n",
       "      <td>19.5465</td>\n",
       "      <td>2.796596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>413.086035</td>\n",
       "      <td>333.4486</td>\n",
       "      <td>406.1274</td>\n",
       "      <td>412.2191</td>\n",
       "      <td>419.089275</td>\n",
       "      <td>824.9271</td>\n",
       "      <td>17.221095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>9.907603</td>\n",
       "      <td>4.4696</td>\n",
       "      <td>9.567625</td>\n",
       "      <td>9.85175</td>\n",
       "      <td>10.128175</td>\n",
       "      <td>102.8677</td>\n",
       "      <td>2.403867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.971444</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.012062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1564.0</td>\n",
       "      <td>190.047354</td>\n",
       "      <td>169.1774</td>\n",
       "      <td>188.299825</td>\n",
       "      <td>189.6642</td>\n",
       "      <td>192.189375</td>\n",
       "      <td>215.5977</td>\n",
       "      <td>2.781041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1557.0</td>\n",
       "      <td>12.481034</td>\n",
       "      <td>9.8773</td>\n",
       "      <td>12.46</td>\n",
       "      <td>12.4996</td>\n",
       "      <td>12.5471</td>\n",
       "      <td>12.9898</td>\n",
       "      <td>0.217965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>1.405054</td>\n",
       "      <td>1.1797</td>\n",
       "      <td>1.3965</td>\n",
       "      <td>1.406</td>\n",
       "      <td>1.415</td>\n",
       "      <td>1.4534</td>\n",
       "      <td>0.016737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>-5618.39361</td>\n",
       "      <td>-7150.25</td>\n",
       "      <td>-5933.25</td>\n",
       "      <td>-5523.25</td>\n",
       "      <td>-5356.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>626.822178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>2699.378435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2578.0</td>\n",
       "      <td>2664.0</td>\n",
       "      <td>2841.75</td>\n",
       "      <td>3656.25</td>\n",
       "      <td>295.498535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>-3806.299734</td>\n",
       "      <td>-9986.75</td>\n",
       "      <td>-4371.75</td>\n",
       "      <td>-3820.75</td>\n",
       "      <td>-3352.75</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>1380.162148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>-298.598136</td>\n",
       "      <td>-14804.5</td>\n",
       "      <td>-1476.0</td>\n",
       "      <td>-78.75</td>\n",
       "      <td>1377.25</td>\n",
       "      <td>14106.0</td>\n",
       "      <td>2902.690117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>1.203845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0948</td>\n",
       "      <td>1.283</td>\n",
       "      <td>1.3043</td>\n",
       "      <td>1.3828</td>\n",
       "      <td>0.1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>1.938477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9065</td>\n",
       "      <td>1.9865</td>\n",
       "      <td>2.0032</td>\n",
       "      <td>2.0528</td>\n",
       "      <td>0.189495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>6.638628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.2637</td>\n",
       "      <td>7.2647</td>\n",
       "      <td>7.3297</td>\n",
       "      <td>7.6588</td>\n",
       "      <td>1.244249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>69.499532</td>\n",
       "      <td>59.4</td>\n",
       "      <td>67.3778</td>\n",
       "      <td>69.1556</td>\n",
       "      <td>72.2667</td>\n",
       "      <td>77.9</td>\n",
       "      <td>3.461181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>2.366197</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>2.0889</td>\n",
       "      <td>2.3778</td>\n",
       "      <td>2.6556</td>\n",
       "      <td>3.5111</td>\n",
       "      <td>0.408694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>0.184159</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.1617</td>\n",
       "      <td>0.1867</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>0.032944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1565.0</td>\n",
       "      <td>3.673189</td>\n",
       "      <td>2.0698</td>\n",
       "      <td>3.3627</td>\n",
       "      <td>3.431</td>\n",
       "      <td>3.5313</td>\n",
       "      <td>4.8044</td>\n",
       "      <td>0.535322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>85.337469</td>\n",
       "      <td>83.1829</td>\n",
       "      <td>84.4905</td>\n",
       "      <td>85.13545</td>\n",
       "      <td>85.7419</td>\n",
       "      <td>105.6038</td>\n",
       "      <td>2.026549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>8.960279</td>\n",
       "      <td>7.6032</td>\n",
       "      <td>8.58</td>\n",
       "      <td>8.7698</td>\n",
       "      <td>9.0606</td>\n",
       "      <td>23.3453</td>\n",
       "      <td>1.344456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>50.582639</td>\n",
       "      <td>49.8348</td>\n",
       "      <td>50.25235</td>\n",
       "      <td>50.3964</td>\n",
       "      <td>50.5788</td>\n",
       "      <td>59.7711</td>\n",
       "      <td>1.182618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>64.555787</td>\n",
       "      <td>63.6774</td>\n",
       "      <td>64.0248</td>\n",
       "      <td>64.1658</td>\n",
       "      <td>64.3447</td>\n",
       "      <td>94.2641</td>\n",
       "      <td>2.574749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>49.41737</td>\n",
       "      <td>40.2289</td>\n",
       "      <td>49.4212</td>\n",
       "      <td>49.6036</td>\n",
       "      <td>49.74765</td>\n",
       "      <td>50.1652</td>\n",
       "      <td>1.182619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>66.221274</td>\n",
       "      <td>64.9193</td>\n",
       "      <td>66.04065</td>\n",
       "      <td>66.2318</td>\n",
       "      <td>66.343275</td>\n",
       "      <td>67.9586</td>\n",
       "      <td>0.304141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>86.836577</td>\n",
       "      <td>84.7327</td>\n",
       "      <td>86.5783</td>\n",
       "      <td>86.8207</td>\n",
       "      <td>87.0024</td>\n",
       "      <td>88.4188</td>\n",
       "      <td>0.446756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>118.679554</td>\n",
       "      <td>111.7128</td>\n",
       "      <td>118.0156</td>\n",
       "      <td>118.3993</td>\n",
       "      <td>118.9396</td>\n",
       "      <td>133.3898</td>\n",
       "      <td>1.807221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1543.0</td>\n",
       "      <td>67.904909</td>\n",
       "      <td>1.434</td>\n",
       "      <td>74.8</td>\n",
       "      <td>78.29</td>\n",
       "      <td>80.2</td>\n",
       "      <td>86.12</td>\n",
       "      <td>24.062943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1543.0</td>\n",
       "      <td>3.353066</td>\n",
       "      <td>-0.0759</td>\n",
       "      <td>2.69</td>\n",
       "      <td>3.074</td>\n",
       "      <td>3.521</td>\n",
       "      <td>37.88</td>\n",
       "      <td>2.360425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>355.538904</td>\n",
       "      <td>342.7545</td>\n",
       "      <td>350.801575</td>\n",
       "      <td>353.7209</td>\n",
       "      <td>360.77225</td>\n",
       "      <td>377.2973</td>\n",
       "      <td>6.234706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>10.031165</td>\n",
       "      <td>9.464</td>\n",
       "      <td>9.925425</td>\n",
       "      <td>10.03485</td>\n",
       "      <td>10.152475</td>\n",
       "      <td>11.053</td>\n",
       "      <td>0.175038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>136.74306</td>\n",
       "      <td>108.8464</td>\n",
       "      <td>130.728875</td>\n",
       "      <td>136.4</td>\n",
       "      <td>142.098225</td>\n",
       "      <td>176.3136</td>\n",
       "      <td>7.849247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>733.672811</td>\n",
       "      <td>699.8139</td>\n",
       "      <td>724.4423</td>\n",
       "      <td>733.45</td>\n",
       "      <td>741.4545</td>\n",
       "      <td>789.7523</td>\n",
       "      <td>12.170315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>1.177958</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1.25105</td>\n",
       "      <td>1.34035</td>\n",
       "      <td>1.5111</td>\n",
       "      <td>0.189637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1566.0</td>\n",
       "      <td>139.972231</td>\n",
       "      <td>125.7982</td>\n",
       "      <td>136.9268</td>\n",
       "      <td>140.00775</td>\n",
       "      <td>143.1957</td>\n",
       "      <td>163.2509</td>\n",
       "      <td>4.524251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count                           mean                  min  \\\n",
       "Time    1567  2008-07-30 21:44:12.712188928  2008-01-08 02:02:00   \n",
       "0     1561.0                    3014.452896              2743.24   \n",
       "1     1560.0                    2495.850231              2158.75   \n",
       "2     1553.0                    2200.547318              2060.66   \n",
       "3     1553.0                    1396.376627                  0.0   \n",
       "4     1553.0                       4.197013               0.6815   \n",
       "5     1553.0                          100.0                100.0   \n",
       "6     1553.0                     101.112908              82.1311   \n",
       "7     1558.0                       0.121822                  0.0   \n",
       "8     1565.0                       1.462862                1.191   \n",
       "9     1565.0                      -0.000841              -0.0534   \n",
       "10    1565.0                       0.000146              -0.0349   \n",
       "11    1565.0                       0.964353               0.6554   \n",
       "12    1565.0                     199.956809              182.094   \n",
       "13    1564.0                            0.0                  0.0   \n",
       "14    1564.0                       9.005371               2.2493   \n",
       "15    1564.0                     413.086035             333.4486   \n",
       "16    1564.0                       9.907603               4.4696   \n",
       "17    1564.0                       0.971444               0.5794   \n",
       "18    1564.0                     190.047354             169.1774   \n",
       "19    1557.0                      12.481034               9.8773   \n",
       "20    1567.0                       1.405054               1.1797   \n",
       "21    1565.0                    -5618.39361             -7150.25   \n",
       "22    1565.0                    2699.378435                  0.0   \n",
       "23    1565.0                   -3806.299734             -9986.75   \n",
       "24    1565.0                    -298.598136             -14804.5   \n",
       "25    1565.0                       1.203845                  0.0   \n",
       "26    1565.0                       1.938477                  0.0   \n",
       "27    1565.0                       6.638628                  0.0   \n",
       "28    1565.0                      69.499532                 59.4   \n",
       "29    1565.0                       2.366197               0.6667   \n",
       "30    1565.0                       0.184159               0.0341   \n",
       "31    1565.0                       3.673189               2.0698   \n",
       "32    1566.0                      85.337469              83.1829   \n",
       "33    1566.0                       8.960279               7.6032   \n",
       "34    1566.0                      50.582639              49.8348   \n",
       "35    1566.0                      64.555787              63.6774   \n",
       "36    1566.0                       49.41737              40.2289   \n",
       "37    1566.0                      66.221274              64.9193   \n",
       "38    1566.0                      86.836577              84.7327   \n",
       "39    1566.0                     118.679554             111.7128   \n",
       "40    1543.0                      67.904909                1.434   \n",
       "41    1543.0                       3.353066              -0.0759   \n",
       "42    1566.0                           70.0                 70.0   \n",
       "43    1566.0                     355.538904             342.7545   \n",
       "44    1566.0                      10.031165                9.464   \n",
       "45    1566.0                      136.74306             108.8464   \n",
       "46    1566.0                     733.672811             699.8139   \n",
       "47    1566.0                       1.177958               0.4967   \n",
       "48    1566.0                     139.972231             125.7982   \n",
       "\n",
       "                      25%                  50%                  75%  \\\n",
       "Time  2008-07-09 15:32:00  2008-08-23 13:02:00  2008-09-22 11:16:30   \n",
       "0                 2966.26              3011.49              3056.65   \n",
       "1               2452.2475             2499.405            2538.8225   \n",
       "2               2181.0444            2201.0667            2218.0555   \n",
       "3               1081.8758            1285.2144            1591.2235   \n",
       "4                  1.0177               1.3168               1.5257   \n",
       "5                   100.0                100.0                100.0   \n",
       "6                   97.92             101.5122             104.5867   \n",
       "7                  0.1211               0.1224               0.1238   \n",
       "8                  1.4112               1.4616               1.5169   \n",
       "9                 -0.0108              -0.0013               0.0084   \n",
       "10                -0.0056               0.0004               0.0059   \n",
       "11                 0.9581               0.9658               0.9713   \n",
       "12               198.1307             199.5356             202.0071   \n",
       "13                    0.0                  0.0                  0.0   \n",
       "14               7.094875                8.967            10.861875   \n",
       "15               406.1274             412.2191           419.089275   \n",
       "16               9.567625              9.85175            10.128175   \n",
       "17                 0.9682               0.9726               0.9768   \n",
       "18             188.299825             189.6642           192.189375   \n",
       "19                  12.46              12.4996              12.5471   \n",
       "20                 1.3965                1.406                1.415   \n",
       "21               -5933.25             -5523.25             -5356.25   \n",
       "22                 2578.0               2664.0              2841.75   \n",
       "23               -4371.75             -3820.75             -3352.75   \n",
       "24                -1476.0               -78.75              1377.25   \n",
       "25                 1.0948                1.283               1.3043   \n",
       "26                 1.9065               1.9865               2.0032   \n",
       "27                 5.2637               7.2647               7.3297   \n",
       "28                67.3778              69.1556              72.2667   \n",
       "29                 2.0889               2.3778               2.6556   \n",
       "30                 0.1617               0.1867               0.2071   \n",
       "31                 3.3627                3.431               3.5313   \n",
       "32                84.4905             85.13545              85.7419   \n",
       "33                   8.58               8.7698               9.0606   \n",
       "34               50.25235              50.3964              50.5788   \n",
       "35                64.0248              64.1658              64.3447   \n",
       "36                49.4212              49.6036             49.74765   \n",
       "37               66.04065              66.2318            66.343275   \n",
       "38                86.5783              86.8207              87.0024   \n",
       "39               118.0156             118.3993             118.9396   \n",
       "40                   74.8                78.29                 80.2   \n",
       "41                   2.69                3.074                3.521   \n",
       "42                   70.0                 70.0                 70.0   \n",
       "43             350.801575             353.7209            360.77225   \n",
       "44               9.925425             10.03485            10.152475   \n",
       "45             130.728875                136.4           142.098225   \n",
       "46               724.4423               733.45             741.4545   \n",
       "47                  0.985              1.25105              1.34035   \n",
       "48               136.9268            140.00775             143.1957   \n",
       "\n",
       "                      max          std  \n",
       "Time  2008-12-10 18:47:00          NaN  \n",
       "0                 3356.35    73.621787  \n",
       "1                 2846.44    80.407705  \n",
       "2               2315.2667    29.513152  \n",
       "3               3715.0417    441.69164  \n",
       "4               1114.5366     56.35554  \n",
       "5                   100.0          0.0  \n",
       "6                129.2522     6.237214  \n",
       "7                  0.1286     0.008961  \n",
       "8                  1.6564     0.073897  \n",
       "9                  0.0749     0.015116  \n",
       "10                  0.053     0.009302  \n",
       "11                 0.9848     0.012452  \n",
       "12               272.0451     3.257276  \n",
       "13                    0.0          0.0  \n",
       "14                19.5465     2.796596  \n",
       "15               824.9271    17.221095  \n",
       "16               102.8677     2.403867  \n",
       "17                 0.9848     0.012062  \n",
       "18               215.5977     2.781041  \n",
       "19                12.9898     0.217965  \n",
       "20                 1.4534     0.016737  \n",
       "21                    0.0   626.822178  \n",
       "22                3656.25   295.498535  \n",
       "23                 2363.0  1380.162148  \n",
       "24                14106.0  2902.690117  \n",
       "25                 1.3828       0.1776  \n",
       "26                 2.0528     0.189495  \n",
       "27                 7.6588     1.244249  \n",
       "28                   77.9     3.461181  \n",
       "29                 3.5111     0.408694  \n",
       "30                 0.2851     0.032944  \n",
       "31                 4.8044     0.535322  \n",
       "32               105.6038     2.026549  \n",
       "33                23.3453     1.344456  \n",
       "34                59.7711     1.182618  \n",
       "35                94.2641     2.574749  \n",
       "36                50.1652     1.182619  \n",
       "37                67.9586     0.304141  \n",
       "38                88.4188     0.446756  \n",
       "39               133.3898     1.807221  \n",
       "40                  86.12    24.062943  \n",
       "41                  37.88     2.360425  \n",
       "42                   70.0          0.0  \n",
       "43               377.2973     6.234706  \n",
       "44                 11.053     0.175038  \n",
       "45               176.3136     7.849247  \n",
       "46               789.7523    12.170315  \n",
       "47                 1.5111     0.189637  \n",
       "48               163.2509     4.524251  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using .describe method to get 5 points summary & other details.\n",
    "sd.describe(include='all', datetime_is_numeric=True).T.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a9be8",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- There seems to be few missing values present the dataset.\n",
    "- Few columns/features like '5', '13', '42' etc. have same value for each entry. These features shall not be useful in predicting 'Pass/Fail' set of any enrty.\n",
    "- The data presented is highly unscaled. Hence it is extremely important to scale the data before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09040904",
   "metadata": {},
   "source": [
    "### 2. Data cleansing: [15 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7efdb3",
   "metadata": {},
   "source": [
    "#### 2A. Write a for loop which will remove all the features with 20%+ Null values and impute rest with mean of the feature. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "175d8878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null_Val</th>\n",
       "      <th>Null_Val(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pass/Fail</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Null_Val  Null_Val(%)\n",
       "Time              0         0.00\n",
       "0                 6         0.38\n",
       "1                 7         0.45\n",
       "2                14         0.89\n",
       "3                14         0.89\n",
       "...             ...          ...\n",
       "586               1         0.06\n",
       "587               1         0.06\n",
       "588               1         0.06\n",
       "589               1         0.06\n",
       "Pass/Fail         0         0.00\n",
       "\n",
       "[592 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Featues with more than 20% Null values are: \n",
      " ['72', '73', '85', '109', '110', '111', '112', '157', '158', '220', '244', '245', '246', '247', '292', '293', '345', '346', '358', '382', '383', '384', '385', '492', '516', '517', '518', '519', '578', '579', '580', '581'] \n",
      "\n",
      "\n",
      "Null values present after dropping & Imputing the dataset: 0\n"
     ]
    }
   ],
   "source": [
    "#Creating the dataframe with 1 column as null value & another column as percentage of null value\n",
    "Null = pd.DataFrame({'Null_Val': sd.isnull().sum(), 'Null_Val(%)': round(sd.isnull().sum()/len(sd)*100, 2)})\n",
    "display(Null)\n",
    "\n",
    "#Creating a list of Features with Null values > 20% & Then dropping the same columns from the dataframe\n",
    "NullFeat_20 = []\n",
    "\n",
    "for col in sd.columns:\n",
    "    if Null.loc[col, 'Null_Val(%)']>20:\n",
    "        NullFeat_20.append(col)\n",
    "print('The Featues with more than 20% Null values are: \\n',NullFeat_20, '\\n\\n')\n",
    "\n",
    "#Dropping the features from dataset\n",
    "sdata = sd.drop(NullFeat_20, axis=1)\n",
    "\n",
    "#Imputing the rest of null values with mean of the feature except 'Time' & 'Pass/Fail' Feature\n",
    "sdata_temp = sdata.drop(['Time', 'Pass/Fail'], axis=1)\n",
    "mean_fil = lambda x: x.fillna(x.mean())\n",
    "sdata_temp = sdata_temp.apply(mean_fil, axis=0)\n",
    "sdata.update(sdata_temp)\n",
    "\n",
    "#After dropping feature with more than 20% null values & Imputing the rest of the features with mean, checking for any null\n",
    "#values\n",
    "print('Null values present after dropping & Imputing the dataset:', sdata.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ca475",
   "metadata": {},
   "source": [
    "#### 2B. Identify and drop the features which are having same value for all the rows. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7caf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Dataset \"before\" dropping Features with same value in all the rows: (1567, 560)\n",
      "Shape of Dataset \"after\" Dropping Featues with same value in all the rows: (1567, 443) \n",
      "\n",
      "The total number of Feature having same value in all rows which have been dropped are 117\n"
     ]
    }
   ],
   "source": [
    "#Identifying all the features with same value in all rows\n",
    "same_val_col = []\n",
    "print('Shape of Dataset \"before\" dropping Features with same value in all the rows:', sdata.shape)\n",
    "for col in sdata.columns:\n",
    "    if (sdata[col].mean()==sdata[col].median()) & (sdata[col].median()==sdata[col].mode()[0]):\n",
    "        same_val_col.append(col)\n",
    "#print('The Features with same values in all rows are: \\n',same_val_col)\n",
    "\n",
    "#Dropping these features from the dataset\n",
    "sdata = sdata.drop(same_val_col, axis=1)\n",
    "print('Shape of Dataset \"after\" Dropping Featues with same value in all the rows:', sdata.shape, '\\n')\n",
    "print('The total number of Feature having same value in all rows which have been dropped are', len(same_val_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3a055d",
   "metadata": {},
   "source": [
    "#### 2C. Drop other features if required using relevant functional knowledge. Clearly justify the same. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f4de34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.121822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>0.008936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>1.462862</td>\n",
       "      <td>1.191</td>\n",
       "      <td>1.41125</td>\n",
       "      <td>1.4616</td>\n",
       "      <td>1.51685</td>\n",
       "      <td>1.6564</td>\n",
       "      <td>0.073849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>-0.0534</td>\n",
       "      <td>-0.0108</td>\n",
       "      <td>-0.0013</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.015107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>-0.0349</td>\n",
       "      <td>-0.0056</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.009296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.964353</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.012444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.003719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>-0.0169</td>\n",
       "      <td>0.01345</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.012354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.002866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pass/Fail</th>\n",
       "      <td>1567.0</td>\n",
       "      <td>-0.867262</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.49801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            count      mean     min      25%     50%      75%     max  \\\n",
       "7          1567.0  0.121822     0.0   0.1211  0.1224   0.1238  0.1286   \n",
       "8          1567.0  1.462862   1.191  1.41125  1.4616  1.51685  1.6564   \n",
       "9          1567.0 -0.000841 -0.0534  -0.0108 -0.0013   0.0084  0.0749   \n",
       "10         1567.0  0.000146 -0.0349  -0.0056  0.0004   0.0059   0.053   \n",
       "11         1567.0  0.964353  0.6554   0.9581  0.9658   0.9713  0.9848   \n",
       "...           ...       ...     ...      ...     ...      ...     ...   \n",
       "584        1567.0  0.003847  0.0017   0.0031  0.0036   0.0041  0.1045   \n",
       "586        1567.0  0.021458 -0.0169  0.01345  0.0205   0.0276  0.1028   \n",
       "587        1567.0  0.016475  0.0032   0.0106  0.0148   0.0203  0.0799   \n",
       "588        1567.0  0.005283   0.001   0.0033  0.0046   0.0064  0.0286   \n",
       "Pass/Fail  1567.0 -0.867262    -1.0     -1.0    -1.0     -1.0     1.0   \n",
       "\n",
       "                std  \n",
       "7          0.008936  \n",
       "8          0.073849  \n",
       "9          0.015107  \n",
       "10         0.009296  \n",
       "11         0.012444  \n",
       "...             ...  \n",
       "584        0.003719  \n",
       "586        0.012354  \n",
       "587        0.008805  \n",
       "588        0.002866  \n",
       "Pass/Fail   0.49801  \n",
       "\n",
       "[217 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the columns/Feature with Standard Deviation less than 1.\n",
    "sdata_des = sdata.describe(include='all', datetime_is_numeric=True).T\n",
    "sdata_des[sdata_des['std']<1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bd2064",
   "metadata": {},
   "source": [
    "- Here we observe that there are 216 rows with standard deviation less than 1 (excluding the target column - 'Pass/Fail').\n",
    "- We can further observe from the above dataframe that there are multiple rows with standard deviation less than 0.09.\n",
    "- Even when we perform Normalization, the standard deviation is set to be around 1.\n",
    "- These rows are practically not much useful in predicting the data set compared to other rows.\n",
    "- Hence it is better to drop these rows rather than just increase the correlation & multi-colinearity in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85b49c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 227)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping the rows with less than 1 standard deviation\n",
    "std_lt1_drop = sdata_des[sdata_des['std']<1].index[:-1]\n",
    "sdata.drop(std_lt1_drop, axis=1, inplace=True)\n",
    "sdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1469b1e8",
   "metadata": {},
   "source": [
    "- Here we see that the number of data has been reduced from 443 to 227 as we have dropped these rows.\n",
    "- Now we need to check the correlation of the dataset for all collumns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461f0af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    }
   ],
   "source": [
    "#Checking the correlation of all the columns\n",
    "sdata_corr = sdata.corr().abs()\n",
    "upper_sdata_corr = sdata_corr.where(np.triu(np.ones(sdata_corr.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper_sdata_corr.columns if any(upper_sdata_corr[column]>.95)]\n",
    "print(len(to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c60bcb",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "- A dataset with no correlation is hardly possible in real indusrtial scenerio.\n",
    "- Here we observe that there are in total 68 features that have more than 95% correlation.\n",
    "- Features having this much high correlation may impact the accuracy of the model.\n",
    "- While it is not possible to remove 100% of correlated Features, we can remove very highly correlated Features.\n",
    "- Hence here we have selected feature with 95% or more correlation only which is extremly high.\n",
    "- Therefore, it is better to drop these features from our dataset to avoid the model to get impacted by them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7828a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 159)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping these 68 features from the dataset\n",
    "sdata.drop(to_drop, axis=1, inplace=True)\n",
    "sdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7786d2",
   "metadata": {},
   "source": [
    "#### 2D. Check for multi-collinearity in the data and take necessary action. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d9d8aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018.640385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1130.064137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7759.539379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>89.179830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14.130933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>570</td>\n",
       "      <td>1088.449533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>572</td>\n",
       "      <td>5.023029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>577</td>\n",
       "      <td>12.659013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>585</td>\n",
       "      <td>1.957034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>589</td>\n",
       "      <td>2.530951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Features    VIF_Score\n",
       "0          0  2018.640385\n",
       "1          1  1130.064137\n",
       "2          2  7759.539379\n",
       "3          3    89.179830\n",
       "4          4    14.130933\n",
       "..       ...          ...\n",
       "152      570  1088.449533\n",
       "153      572     5.023029\n",
       "154      577    12.659013\n",
       "155      585     1.957034\n",
       "156      589     2.530951\n",
       "\n",
       "[157 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for Multi-Collinearity\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = sdata.columns[1:-1]\n",
    "vif['VIF_Score'] = [variance_inflation_factor(sdata.iloc[:, 1:-1].values,i) for i in range(sdata.iloc[:, 1:-1].shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c41b752",
   "metadata": {},
   "source": [
    "- Ideally, a VIF score greater than 10 is considered as a very high multi-collinearity.\n",
    "- Here we need to check if we remove all the features with VIF Score > 10, how many Feature needs to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0b7ad7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with VIF Score less than 10: 47\n",
      "Features with VIF Score more than 10: 110\n"
     ]
    }
   ],
   "source": [
    "print('Features with VIF Score less than 10:', len(vif[vif['VIF_Score']<10]))\n",
    "print('Features with VIF Score more than 10:', len(vif[vif['VIF_Score']>10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40191a",
   "metadata": {},
   "source": [
    "- Here we see that only 47 Features have VIF Score less than 10.\n",
    "- So if we are to remove all the other Features, we shall need to drop 110 Features.\n",
    "- Dropping these many features doesn't seem much feasible at this point, as many valuable information maybe lost.\n",
    "- Further in the given dataset, we don't know what each Feature represents as the names are not available.\n",
    "- So we cannot even proceed to merge some feature to reduce the VIF Score. It can only be reduced by droping them. \n",
    "- Hence it is not advisible to remove these many Features.\n",
    "- We see that the VIF scores for many Features is extremely high.\n",
    "- Hence we may select to remove the Features with VIF Score more than 100 for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0021e11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for all the features with 'VIF_Score' > 100 & Removing them to see the reduction in Mulit-Collinearity\n",
    "Feat = list(vif[vif['VIF_Score']>100]['Features'])\n",
    "len(Feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffc996ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fin_Feature</th>\n",
       "      <th>Fin_VIF_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>51.087876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>11.912967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>9.520879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1.137601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>45.472751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>569</td>\n",
       "      <td>7.286057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>572</td>\n",
       "      <td>4.619860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>577</td>\n",
       "      <td>11.721734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>585</td>\n",
       "      <td>1.801716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>589</td>\n",
       "      <td>2.339091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fin_Feature  Fin_VIF_Score\n",
       "0            3      51.087876\n",
       "1            4      11.912967\n",
       "2           23       9.520879\n",
       "3           24       1.137601\n",
       "4           33      45.472751\n",
       "..         ...            ...\n",
       "85         569       7.286057\n",
       "86         572       4.619860\n",
       "87         577      11.721734\n",
       "88         585       1.801716\n",
       "89         589       2.339091\n",
       "\n",
       "[90 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping all the Features with VIF Score more than 100 (i.e. dropping 123 Features)\n",
    "sdata_final = sdata.drop(Feat, axis=1)\n",
    "\n",
    "#Re-checking Multi-Colinearity after dropping all these columns\n",
    "vif_fin = pd.DataFrame()\n",
    "vif_fin['Fin_Feature'] = sdata_final.columns[1:-1]\n",
    "vif_fin['Fin_VIF_Score'] = [variance_inflation_factor(sdata_final.iloc[:, 1:-1].values, i) for i in range(sdata_final.iloc[:, 1:-1].shape[1])]\n",
    "vif_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "607666b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 92)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdata_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf97c9",
   "metadata": {},
   "source": [
    "After dropping the Features with more than 100 VIF Score, the Dataset has now 92 feature present in it on which we may proceed further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96994b1",
   "metadata": {},
   "source": [
    "#### 2E. Make all relevant modifications on the data using both functional/logical reasoning/assumptions. [2 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678cbc8a",
   "metadata": {},
   "source": [
    "-- Initially, the Time Feature had data type as object. Hence we converted it to date-time data type.\n",
    "\n",
    "##### Modification made in  2A.\n",
    "- Here we dropped Features/Columns with more than 20% null values, rather than inputing this null values.\n",
    "- Instead of changing more than 20% of the Feature values, it is better to drop the values.\n",
    "\n",
    "##### Modification made in 2B.\n",
    "- Here we dropped Features that have same values in each rows.\n",
    "- These type of Features have make no impact on accuracy or prediction of the model & rather have negative impact on models. Hence are useless.\n",
    "- These type of Features may affect correlation and multi-collinearity & thus are not good for the model.\n",
    "\n",
    "##### Modification made in 2C.\n",
    "Standard Deviation:\n",
    "- Initially we checked for the features with standard deviation less than 1.\n",
    "- We than proceed to remove these features as they may have no impact in predection of model.\n",
    "\n",
    "Correlation:\n",
    "- A correlated Feature is not good for model.\n",
    "- However we cannot remove correlation totally.\n",
    "- Here we don't know what the Feture represents exactly as the names are not mentioned.\n",
    "- Therefore we need to be very careful in removing the Features.\n",
    "- Hence we only chose to remove 95% or more correlated Features.\n",
    "\n",
    "##### Modification made in 2D.\n",
    "- Here we checked the multi-collinearity present in the dataset.\n",
    "- We found vary high multi-collinearity for many Features.\n",
    "- Normally the VIF score for Multi-Collinearity shall be less than 10. But here very few Feature have less than 10 IVF Score. So if we proceed to remove all other Features, we may loose much more information.\n",
    "- Hence we choose to remove only features with more than IVF Score more than 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0aa28",
   "metadata": {},
   "source": [
    "### 3. Data analysis & visualisation: [5 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8072bb",
   "metadata": {},
   "source": [
    "#### 3A. Perform a detailed univariate Analysis with appropriate detailed comments after each analysis. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f36bfa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Analysing the distribution of target variable 'Pass/Fail'\n",
    "sns.countplot(data=sdata_final, x='Pass/Fail')\n",
    "for i in range(len(sdata_final['Pass/Fail'].value_counts())):\n",
    "    plt.text(i, sdata_final['Pass/Fail'].value_counts().values[i]+10, sdata_final['Pass/Fail'].value_counts().values[i], ha='center')\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fdb0b1",
   "metadata": {},
   "source": [
    "- Here we see that the targer variable is highly imblanced.\n",
    "- The value '1' which represents Failure is very low compared to that of '-1' which represents pass state.\n",
    "- Hence during model building it is extremly important to sample the target varaible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9076c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Analysing the data month-wise from 'Time' column\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(data=sdata_final, x=sdata_final['Time'].dt.month)\n",
    "plt.xlabel('Month')\n",
    "plt.xticks(range(12), [calendar.month_abbr[i] for i in sdata_final['Time'].dt.month.value_counts().index.sort_values(ascending=True)])\n",
    "for i in range(1, len(sdata_final['Time'].dt.month.value_counts())+1):\n",
    "    plt.text(i-1, sdata_final['Time'].dt.month.value_counts()[i]+5, sdata_final['Time'].dt.month.value_counts()[i], ha='center')\n",
    "plt.title('Month-wise Count-plot for manufacture products')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e044e24",
   "metadata": {},
   "source": [
    "- Here we observe that the maximum manufacturing has been achieved in the month of Aug, follwed by Sep.\n",
    "- The least manufacturing is observed in the month of Dec.\n",
    "- For most of the months the avg. manufacturing number is around 50, for the 3 months period of 'Feb', 'Jul' & 'Oct' this number rises to 111, while it rises extremly to 442 in 'AUg' & 'Sep'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a8bae5",
   "metadata": {},
   "source": [
    "#### 3B. Perform bivariate and multivariate analysis with appropriate detailed comments after each analysis. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64d683f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtkAAAFNCAYAAADVUnNWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAB8SUlEQVR4nO3dd3hcZ5X48e+ZXtQl915iO7YTJ46TkARCgPRG752lbGGpYQk1hQUChN52AywL/Fg6gSSkBxJCCYkT994lWX2k6X3u+/tjRo7suMjWdJ3P8+iRNDO6952iO2fee95zxBiDUkoppZRSqnhslR6AUkoppZRS9UaDbKWUUkoppYpMg2yllFJKKaWKTINspZRSSimlikyDbKWUUkoppYpMg2yllFJKKaWKTINspdSkJSJGRBYXeZtzRSQqIvZibreUSvE4FLZ7n4i8tdjbVUqpWqBBtlKq4kRkv4ikRaTjiMvXFwLA+UXYx6Mi8s6JbudEjDGdxpgGY0yuWNsUkfmFxyFa+NovIjcWa/vFICI3i8j/G3uZMeYqY8yPiryfj4nIn49yeUfhNbRynNt5wZjHM3bE4xsVkbnFHPdxxvGcx00pVR80yFZKVYt9wOtHfxGRMwBv5YZTlVqMMQ3kH6dPi8iVR95ARBzlH1ZZ/QS4UEQWHHH564BNxpjN49mIMebxwoehBmBF4eKW0cuMMZ3j2c4keLyVUqdIg2ylVLX4CfCWMb+/Ffjx2BuISLOI/FhEBkXkgIh8UkRsheveJiJ/EZHbRWRERPaJyFWF6z4LvAD4VmGW8ltjNnupiOwq/M23RUSONjgRuUVEvln42VmY/fxi4XeviCRFpHXMrLNjzLj2ikikMKY3jtnmO0RkW2HfD4jIvPE8UMaYvwNbgJUicomIdIvIR0WkD/ihiLhF5Gsi0lP4+pqIuMfs9yMi0lu47h1H3M/DZvxHH9cxv68QkYdEZFhE+kXk44Vg/+PAawuP74YjtyUitsLzdUBEBgrPY3PhutHH7K0i0ikiQyLyiWPc927gj8Cbj7jqLcCPCttbLCKPiUiosK1fjOdxHXMf3154XiKF5+49Y6472uPtFZEfFZ7HbSLyHyLSPeZvZorIbwqv230i8r7C5Ud93JRS9UGDbKVUtXgCaBKR0yWfz/xa4MjT6N8EmoGFwAvJB1ZvH3P9+cAOoAP4IvADERFjzCeAx4H3FmYp3zvmb64FzgVWAa8BrjjG+B4DLin8fC7QVxgDwAXADmPMyNg/EBE/8A3gKmNMI3AhsL5w3cvIB1ivAKYUxvezY+x77DZFRC4iP/u6rnDxdKANmAe8G/gE8DzgrML9Og/4ZOHvrwRuAC4DTgMuPdE+x+y7EXgYuB+YCSwGHjHG3A98DvhF4fFddZQ/f1vh60Xkn78G4FtH3Ob5wFLgJeRn6k8/xlB+xJggW0SWFu7r6OP3GeBBoBWYTf51czIGyL8umsi/vr4qIqvHXH/k430TML9wvy4D3jRmbDbgbmADMKtw3z4gIleM83FTStUoDbKVUtVkdDb7MmA7cHD0ijGB98eMMRFjzH7gyxw+o3nAGPO9Qj70j4AZwLQT7PM2Y0ywkB7wJ/LB2tH8HThNRNqBi4EfALNEpIF8sP3YMf7OIj/j7DXG9BpjthQufw/weWPMNmNMlnywddYJZrOHgGHg+8CNxphHxuzjJmNMyhiTAN4I3GqMGTDGDAK38Ozj9Brgh8aYzcaYGHDzcfZ3pGuBPmPMl40xycLz8I9x/u0bga8YY/YaY6LAx4DXyeHpFrcYYxLGmA3kg9JjBZ13AtNE5MLC728B7ivcV4AM+QB4ZmGcfznaRo7FGPMHY8wek/cY+YD9BWNucuTj/Rrgc8aYkcJM+zfG3PZcYIox5lZjTNoYsxf4Hvn0FqVUHdMgWylVTX4CvIH8jOePj7iuA3ABB8ZcdoD87OCovtEfjDHxwo8NJ9hn35if46O3F5Et8uwiuBcUgqm15APqi8kH1X8DLuIYQXYhiH0t8M9Ar4j8QUSWFa6eB3xdRIIiEiQfPMsR9+dIHcaYVmPM6caYsYHcoDEmOeb3mTz3cZo55rquI64brznAnpO4/VhHG5ODwz8EHfW5OFLhuf0V8BYREfIB/NgFlv9B/rF8svA8vuMomzkmEblKRJ4opMQEgavJv/5GHe3xHvuYjv15HjBz9HkubO/jnPjDn1KqxmmQrZSqGsaYA+QXQF4N/PaIq4d4doZy1FzGzHafaPMnOZYVYxbBPV64+DHgxcDZwFOF368gn47xnIoXhe08YIy5jPys+nbys5iQD8TeY4xpGfPlNcb87WTGObqbI37v4bmPU0/h517ywfLY68aKAb4xv08f83MXsGicYzjS0caUBfpP8HfH8iPyM8iXAY3APYcGYkyfMeZdxpiZ5M8YfEfGWaKwkLv+G+B2YJoxpgW4l3zQfmgXR/xZL/m0lFFjH98uYN8Rz3OjMebqY2xLKVUnNMhWSlWbfwJeXJgFPqSQAvJL4LMi0lhIq/gQz83bPpZ+8jmzE/EY+dSErcaYNPAo8E7yQdTgkTcWkWkicn0hNzsFRIHR0n7/BXxMRFYUbtssIq+e4PhG/Qz4pIhMkXxZxE/z7OP0S+BtIrJcRHzk84nHWg+8QkR8hcD0n8Zcdw8wXUQ+IPnFlY0icn7hun5gfiEH+Vhj+qCILCik2IzmImdP8T4+DgSBO4CfF54PAETk1SIyGvSOkA9kx1tS0QW4gUEgK/nFs5ef4G9+Sf65bBWRWcDYnP8ngXBhoaRXROwislJEzi1cf6LHTSlVo/SfWilVVQq5sGuPcfW/k59p3Qv8Bfg/4H/GuemvA68qVID4xglvfXR/I19WcHTWeiuQ5Biz2OSPsR8mP4s7TD6t5F8BjDF3Al8Afi4iYWAzcNUpjutI/0k+tWUjsAl4pnAZxpj7gK+Rr9Cxu/B9rK8CafLB34+An45eYYyJkJ85vo58ascu8gsZIZ++ARAQkWeOMqb/IZ8O9GfyZyuS5J/PU2KMMeRTiubx3NSic4F/iEgUuAt4vzFm3zi3GwHeRz5wHiGfvnTXCf7sVqCb/P16GPg1+Q9Vox8OryOf67+P/BmZ75NfwAsnftyUUjVK8scppZRSShWDiPwL8DpjzAtPeGOlVN3SmWyllFJqAkRkhohcJPla4EvJn724s9LjUkpVlnaqUkoppSbGBfw3sIB8nvjPge9UckBKqcrTdBGllFJKKaWKTNNFlFJKKaWUKjINspVSSimllCqyuszJ7ujoMPPnz6/0MJRSSimlVB17+umnh4wxU452XV0G2fPnz2ft2mOV2VVKKaWUUmriROTAsa7TdBGllFJKKaWKTINspZRSSimlikyDbKWUUkoppYpMg2yllFJKKaWKTINspZRSSimlikyDbKWUUkoppYpMg2yllFJKKaWKTINspZRSSimlikyDbKWUUkoppYpMg2yllFJKKaWKTINspZRSVcuyDH2hBJZlKj0UpZQ6KRpkK6WUqkqWZdjRH2FDV5BgIlPp4Sil1EnRIFsppVTVsSzDzoEI/eEkzV4XnYFYpYeklFInRYNspZRSVcWyDLsGIvQGk7T5XPjdDkbiGaKpbKWHppRS46ZBtlJKqaphjGH3YISeUIJ2vwsRAcBpt9ETTFR4dEopNX4aZCullKoKxhj2DETpHknQ7nMfCrABGj0OeoIJUtlcBUeolFLjp0G2UkqpijPGsGcwRudIgg7/4QE2gK3w+0A4VYnhKaXUSdMgWymlVEUZY9g7FKNzOE7HmBSRIzV5nBwIxMlpOT+lVA3QIFsppVTFGGPYNxSjMxA/LAf7aJx2Gxkrx3BMZ7OVUtWvIkG2iLSJyEMisqvwvfUYt2sRkV+LyHYR2SYiF5R7rEoppUrnQCDG/kCMNr/rUErI8fidTg4MxzFGZ7OVUtWtUjPZNwKPGGNOAx4p/H40XwfuN8YsA1YB28o0PqWUUiV2YCjG3sEY7X73uAJsAK/LTiSRJaLl/JRSVa5SQfZLgR8Vfv4R8LIjbyAiTcDFwA8AjDFpY0ywTONTSilVQp2BGHsGo7SdRIA9yu2w0T2s5fyUUtWtUkH2NGNML0Dh+9Sj3GYhMAj8UETWicj3RcRfzkEqpZQqvq7hOLsLAbbddnIBNkCD20F/OEkyo+X8lFLVq2RBtog8LCKbj/L10nFuwgGsBr5rjDkbiHHstBJE5N0islZE1g4ODhbhHiillCq27pE4O/sjtPlOLcAGEBHsNqEvlCzy6JRSqngcpdqwMebSY10nIv0iMsMY0ysiM4CBo9ysG+g2xvyj8PuvOU6QbYy5A7gDYM2aNboiRimlqszBkQQ7+iK0n+IM9lhNHiddI3Fmt3px2LVQllKq+lTqyHQX8NbCz28Ffn/kDYwxfUCXiCwtXPQSYGt5hqeUUqqYeoMJtveHixJgA9htQs4yBKJazk8pVZ0qFWTfBlwmIruAywq/IyIzReTeMbf7d+CnIrIROAv4XLkHqpRSamL6ggm29YVpn0CKyNE0uB3sD2g5P6VUdSpZusjxGGMC5Gemj7y8B7h6zO/rgTXlG5lSSqli6g8l2dIbps3nKmqADeB22AnEkoQSGVp8rqJuWymlJkoT2ZRSSpXEQDjJlp4QbT5XyfKm3Q4HXcPxkmxbKaUmQoNspZRSRTcQTrL5YIiWEgbYAH6XnaFoinham9MopaqLBtlKqUmpL5hgOJau9DDq0mAkyeaefIDtLHHlDxHBabfRE9Ryfkqp6qJBtlJq0ukPJdnSF2Z9V5BtvWFSWW1qUixDkSSbDoZo8ZY+wB7V4HZyMBgnnbXKsj+llBoPDbKVUpPKcDTFlt4QbV4XHX4XQ9EUT+4bZiCc1CoVExSIpth0MFzWABvy5fyMgaGIlvNTSlUPDbKVUpNGOJlhU0+YZk8+T1hEaPG68LscbO4JsbknRCKts9qnYiSWZmN3iCaPs6wB9qgmj5MDwzEsSz8oKaWqgwbZSqlJIZ7OsrEriM9px+U4/NDntNuY0uAhFM/y5L4APSMJDdZOQjCeZn1XkCaP8zmPbbk47TZSWYtgIlOR/Sul1JE0yFZK1b1UNsfG7hAOmw2P037M2zV7nTR5nGzvD7OhO0gspRUrTiQUz7C+K0ijx1GxAHuU12lnfyBW0TEopdQoDbKVUnUtk7PYfDBEzjL43Sfuv+UozGon0xZP7humMxAjp7PaRxVKZFjfHaTB7cDtOPaHl3LxuRyE4hkiSZ3NVkpVngbZSqm6lbMM2/vCxFI5mjzOk/rbBo+DVp+LPYMx1h0YIayB22FCiQzrOkfwOe1VEWCPypfzS1R6GEoppUG2Uqo+GWPYNRAhEE3Teoott+02oaPBTc4Ynt4/zN7BKNmclokLJzOs7xzB73IcN/2mEho9DnpCSZIZXcCqlKosDbKVUnVp31CMnmCCtlMMsMfyuRy0+d10DcdZe2CEYHzyNrGJFAJsXxUG2AA2EWzkO04qpVQlaZCtlKo73SNx9g/FaPe7EZGibNMmQpvfjV2EZzpH2NkfnnTNT6KpLOs7g3gc1Rlgj2ryOOkcjmsuvVKqojTIVkrVlcFIkh19Edr8bmxFCrDH8jjtdPjd9IVSPLk/wFBkcsyYRlNZ1nWO4HbY8bqqN8CG/OLVrGUIRLU5jVKqcjTIVkrVjWA8zeaDYVp9Luy24gfYo0SEVp8Lj8POxoMhtvaE6joHOJbKsr5zBJfdVvUB9ii/y0FnIK5dPJVSFaNBtlKqLkRTWTYU6jWXq+Og25Gf1R6OpXmqTluzx9NZ1nWN4LTb8LlOXAKxWnicdsKpLOGk1jpXSlWGBtlKqZqXSOfY0BXEU4FyciJCs9eF3+1gS0+Yjd3105o9ns6yrjOIQ2orwB7lddjpHolXehhKqUlKg2ylVE1LZy02HQxiQyoaCDrtNjoa3ESTWf6xL0D3SLymW7Mn0jnWdwWxi4yriU818rvtDEZSdfOhRylVWzTIVkrVrGzOYktPiHTWosFTHYFgk9dJs8fJroEI67pGiNZga/ZkJseGrhGE2g2wIX+WwS5CX1ib0yilyk+DbKVUTbIsw46+CKFEhmbvxGthF5PDbqPD7yGdNTy1b5gDQ7XTmj2Zyc9gGyM01HCAParR46R7JEFGmwgppcpMg2ylVM0xxrB7MMJgNEW7313p4RxTgzvfmn3vUIynDwwTSlR3a/b8DHYQyzJVc2Zgouw2IWcZAhEt56eUKi8NspVSNaczEKd7OFmUbo6lNtqa3Rh4ev8wuweiVTmrmszk2NgdJGcZGj3OSg+nqBrdTvYPazk/pVR5aZCtlKopvcEEe4ZitDe4itbNsRx8LgftDW4OBuOs3T/MSKx6WrOnsjk2dQfJ5uovwAZwOWwk0jmC8eo+k6CUqi8aZCulasZQJMm23jBtPldJujmWmk2ENp8bh83GM10jbO+rfGv2VDbHpq4Q6ToNsEd5nXY6tZyfUqqMNMhWStWEUCLDpoNhWkrczbEcPE47U/xuBsP51uyDkco0sUlnLTZ1h0jlLJrqOMAG8LsdDEfTxGqw2otSqjZpkK2UqnqxVJaNXUEa3OXr5lhqIkKLz4XX4WBTd4itPeGytmYfrS+ezOTqPsAe5bTb6AlqOT+lVHnUx7uVUqpuJTM5NnQHcTlseJzl7eZYDi6HjSmNHoKJDE/uC9AXTJR8VjuTs9h8MEg8nau68oel1Ohx0BNMVDxFRyk1OWiQrZSqWumsxebuEBhqsq33yWjyOGlwO9naF2Fjd4h4ujRpDfkAO0QslaNlEgXYwKE8/oFIssIjUUpNBhpkK6WqUs4ybOsNk8jm6npB3lhOu40pDW5iqSxP7hsuemv2fIfMMJFklpYaKH9YCo0eJ53Dtd3yXilVGzTIVkpVnXw3xzDBeHrSzbZCPhBs8brY1R/lma4RIsmJl54bDbBD8TStkzTAhvwHmVTGYiRePSUUlVL1SYNspVRVMcawdzBKfzhFWxV3cyy10SY22axh7f4R9g1FT7k1ezZnsbU3zEg8Pakf01F+l4P9AS3np5QqLQ2ylVJVpWs4TudInHb/5J1tHctfaM1+IJBvYhM6yYYqOcuwrS/MSCxd1S3oy8nrshNOpAkX4QyBUkodiwbZSqmq0R9KsmswSpvPXVPdHEvNbhPa/W4E4enOEXb3R8bVmj1nGbb3hglEdQb7SC67Xcv5KaVKSoNspVRVGI6m2NIbos1b+81mSsXrstPud9EdTPDU/mGGj9OafTTAHogmdQb7KBo9DvpCybLWJldKTS4aZCulKi6czLDxYIhmjwtHnTSbKRWb5Ge1XXYb6zpH2NYbJpU9PFAcXTg6EEnR4fdUaKTVTUSwiTAQ1nJ+SqnS0HczpVRFxdP5bo5+lwOXQw9J4+V22JnS4GYomuKpfcMMhPOt2S3LsKM/Qn84RUeDzmAfT6PbQedwnOw4Um+UUupk1Xd3B6VUVUtmcmzsDuGw1Wc3x1ITEVq8LjI5iy09IaY0urHbbPSHk7pwdBwcdhtZyzAcSzO1SWf8lVLFpdNGSqmKGA0Mc5bB79bP+xPhtNvoaPAQjGcZCCdp87l04eg4+V0ODgRiJW9lr5SafDTIVkqVXc4ybO8LE0vlaJok3RzLodnrpM2vlVlOhsdpJ5rKEU6Upo29Umry0iBbKVVWxhh29kcIRCd350FVPTxOO53DsUoPQylVZzTIVkqV1b6hGL2hBG0aYKsq4XfZGYqmiad1NlspVTwaZCulyqZ7JM7+oVi+sYqmNKgqISI47EJvUMv5KaWKR4NspVRZDIST7OiL0OZ3Y9MAW1WZRreTg8HEuDppKqXUeGiQrZQquWA8zZaeMK0+7eaoqpPdJljGMBRJVXooSqk6oUG2UqqkIskMG7qCNHocOLWbo6pijW4n+wMxLEvL+SmlJk7f8ZRSJZNI59jQHcTrdOB2aLMZVd1cDhvJrEUwkan0UJRSdUCDbKVUSaSyOTZ2B7GLDa9LA2xVG3xOO50BLeenlJo4DbKVUkWXzVlsORgiaxkatJujqiE+l4OReIZoSsv5KaUmRoNspVRRWZZhR1+ESDKr3RxVTXLabfQEE5UehlKqxmmQrZQqGmMMuwcjDERStPndlR6OUqek0eOgJ5gglc1VeihKqRpWkSBbRNpE5CER2VX43nqU2ywVkfVjvsIi8oEKDFcpNU4HAjG6R5K0+7Wbo6pdo3XcB8Jazk8pdeoqNZN9I/CIMeY04JHC74cxxuwwxpxljDkLOAeIA3eWdZRKqXHrDSbYOxSj3e/Sbo6q5jV5nBwIxMlpOT+l1CmqVJD9UuBHhZ9/BLzsBLd/CbDHGHOglINSSp2aoUiSbb1h2nzazVHVB6fdRsbKMRzT2Wyl1KmpVJA9zRjTC1D4PvUEt38d8LPj3UBE3i0ia0Vk7eDgYJGGqZQ6kVA8w6aDYVq0m6OqMw2u/Gy2MTqbrZQ6eSWrrSUiDwPTj3LVJ05yOy7geuBjx7udMeYO4A6ANWvW6BFRqTKIpbJs7A7S4NZujqr+eJx2hqIpwskszV6tlKOUOjklC7KNMZce6zoR6ReRGcaYXhGZAQwcZ1NXAc8YY/qLPkil1ClLZvLdHF0OGx6nNptR9cntsHFwJKFBtlLqpFVq6uku4K2Fn98K/P44t309J0gVUUqVVzprsbk7BCbfvEOpetXgdtAfTpLMaDk/pdTJqVSQfRtwmYjsAi4r/I6IzBSRe0dvJCK+wvW/rcgolVLPkc1ZbO0Nk8jmaNRmM6rOiQh2m9AXSlZ6KEqpGlORKShjTIB8xZAjL+8Brh7zexxoL+PQlFLHYVmGnf0RQvG0NptRk0aTx0nXSJzZrV4cuvZAKTVOerRQSo2LMYa9g1H6w9rNUU0udpuQswyBqJbzU0qNnwbZSqlx6RqO0zWS0G6OalJqcDvYr+X8lFInQYNspdQJ9QUT7BqI0urTbo5qcnI77CQyWUKJTKWHotSE5SyDpd1MS06DbKXUccXTWbb1RWjTZjNqkvM4HHQOxys9DKUmJGcZNh8McTCYqPRQ6p4G2Uqp49o/FMdpt+mCL1Ux1ZKi4Xc7CERTxFLZSg9FqVNijGH3QITBSIpeDbJLTt81lVLHFE5m6A8nafJoLWxVfpmcxWfu2cqNv91EOmtVejgAOGw2erWcn6pR3SMJeoJJpja6iWdyxNP6gbGUNMhWSh2VMYY9A1G8TrvmYauys4zh64/s4sn9w2ztDfO9x/dWekgANHqcHAzGqyboV2q8BiNJdvZHDltbE4zpGoNS0iBbKXVUI/EMwXgav1tnsVX5/fCv+3ls5yBvuWAer1w9m/u39PHojoFKDwu7TTAGhiJazk/VjnAyw5aeMK1j1tb4XQ56w3pWppT03VMp9RyWZdjVH6HBrR0dVfn9bv1Bfrf+INeeMYNXrZ6NZWB7X5hv/Wk3C6c0MLfNV9HxNXmc7B+OMb3Zg00XA6sql8zk2NgdxO9y4ByztsbjtBOIpUhmcnic9gqOsH7pTHYNMMYwEE5quR1VNgPhJAk98KoK+PPOQX7wl31ctKidd75g4aG25v9xxTK8Tju33beNRDpX0TE67TbSWYuReLqi41DqRDI5i83dIezYjnk8D+nruGQ0yK4BOcuwrTfMjv6IBtqq5DI5i91DUZo8OoutymtDd5CvPryTFTOb+NBlSw8rGdnmd3HDFUs5GEzwnUd3V7ziiNdp54CW81NVzLIM2/vCxDM5Go6xeN3rtNOnKSMlo0F2jTBAXyipgbYqud5gglzOHHZaUalS2zcU5bN/2MbMFi+fvHo5LsdzX3+rZrfwhvPm8ujOQe7f0leBUT7L53IQimeIJHXhmKpOewejBKJpWn3H7tLrddoZiWd0IW+J6LtoDWn3uzTQViWVzOTYNxSj2aut01X59IeT3HzXVvxuO7dcv+KYs24Ar14zh9VzW7njz3vZPRAt4yify2m30aO1hlUVOjiSoHM4TttxAmzgUJWRsH5YLAkNsmuIiGigrUqqaziOzSba2VGVTTiR4aa7tpDK5bj5uhV0NLiPe3ubCB+6bAktPie33b+NaAUbwzR6HPSEkiQzlc0RV2qsQDTFjr4wbX73uMqvehx2+rT2e0lokF1jNNBWpRJLZekeSWgutiqbZCbHZ/6wlYFIkk9ds5x57f5x/V2z18lHr1jGUDTN1x/ZWbH8bJsINvILhZWqBtFUls0HQzR7XeOeLPG68lVGsjlNGSk2DbJrkAbaqhT2DUVxO2zYtPGMKoOcZbj9wR3s6Itww+VLWTGz+aT+ftmMJt5+4Xye2DvM79YfLNEoT6zJ46RzOE5Oj8OqwkZL9Xmc9qOuaTgWm+Rrv4eT2v2x2DTIrlEiQkeDWwNtVRSheIaBSIpGncVWZWCM4buP7uYf+4Z5zwsXceGijlPazvWrZnLhonb+92/72dobLvIox8dht5G1DIGoNqdRlZPNWWzpCYHJL8o9WS67jcGInpEpNg2ya5wG2mqijDHsGozgP4UDs1Kn4udPdfHA1n5efc5srjljxilvR0R434tPY1qThy/ev51QojKLt/wuB52BeMXLCqrJyRjDzv4I0VT2lCdKfC4HA5GUnpEpMg2y64AG2moihqIpIsnsKc1+KHWyHtjSx/892clLlk3lzc+bN+Ht+d0ObrxyGeFkhtsf3FGRIMHjtBNJZQkn9HS7Kr99QzH6I0nafMdfNHw8dpuQs4yWpCwyDbLrhAba6lTkLMPugSiNbg2wVek9uS/Adx7dzTnzWnnvixaPq/LBeCyc0sB7Ll7E+q4gv1zbVZRtniyPw053UJvTqPLqCybYH4hPKMAe5bDZGNK0p6LSILuOaKCtTlZ/KEkqa+F2aPt0VVrb+8J84YEdLJzSwEevWIajyM2OLl8+jRcvncrPnuxkXedIUbc9Hn63ncFIquIt39XkEYyn2dYXodXrLMqC9Qa3g75QSuOHItIgu85ooK3GK5212DMUpVkXO6oS6x6Jc+s9W2n3u7jp2uV4XcX/UCci/Msli5jb5uPLD+0s+0JEEcEuQl9Ym9Oo0ouns2zqDtHocRTtA6vdJmQti2ha056KRYPsOjQaaG/vC2ugrY7pYDCOZZmizygqNdZwLM1Nd23BLsIt16+g5QQd6CbC47Rz41XLSGctvvDAjrLX/W30OOkaTpDResOqhFLZHBu7QzjttqKfhbSLaKWcItJ31zrV0eCmP5zSQFsdVSKd40Agru3TVUnF01luvnsL4WSGT1+7nBnN3pLvc3arj39/8WK29Yb58RMHSr6/sew2wTKGoYgGKao0cpZhW2+EbM7CX4K1NH63g75QUivlFIkG2XVMA211LAeGYzjtNm2frkomk7P43L3b6ByO87ErT+e0aY1l2/cLTpvCNWfM4M51B3lib6Bs+wVodDs5MKzl/FTxGWPYNRAhGE+XbILEabeRylrEdG1BUWiQXec00FZHiiQz9IwktKKIKhnLGL728C42dId434sXs3pea9nH8E/PX8BpUxv42sM76QuVr8mGy2Ejkc4RjGspNFVcXcNxeoJJ2kqYcgX5DpAjsXRJ9zFZaJA9CWigrUYZY9g7GMPrchStfJpSR/rhX/fx512DvPWC+bx42bSKjMFpt/HRK5chItx2/zbS2fLlSftcdjpHtJyfKp6BcJJdg1HafK6SH7v9Lge9QV3AWwwaZE8SGmgrgGA8w3AsRYPOYqsS+d26g/xufQ/XnjmDV66eVdGxTGvy8MFLl7BnMMb3/7K3bPv1uRwMR9PEUlqlQU1cKJFhS0+YVq+rLCl+LoeNeCZHXKuMTNhx32lF5BXHu94Y89viDkeV0migDWGWTW/Cpvm4k4plGXYPRPC7tGSfKo3Hdg7yg7/u46JF7bzz+Qur4mzJeQvaeOXq2fzmmW6Wz2jikqVTy7Jfp91GTzBR1lx0VX8S6RybuoM0uB04y1wJKhjLaCfgCTrRo3fdca4zgAbZNUYD7clrKJoimsrR0TDxzmBKHWlDV5CvPbyTlTOb+NBlS6tqUe2bnzeP7X1hvv3obhZOaWBum6/k+2z0OOgJJpjb7tNmT+qUZHIWmw8GsYsNj7O8ryG/y0FvOMnM1tJXBKpnxw2yjTFvL9dAVPlooD35ZHMWuwaiNGnjGVUCewejfPbebcxq8fKJa5bjclRXJqLdJvzHFct4/8/Xcdt92/jyq88qSUOcsUY78A1GUsxuLX1Qr+qLZRm294VJZqyS1pY/Fo/TTiCWIpnJlT3AryfHPRKKyJsK3z90tK/yDFGVguZoTy69oSSZnFV1wY+qff3hJDffvQW/287N16+o2nz/Nr+LG65YysFggu88urssJfYaPU46h+Pk9BirTkJ+gXqUoUi6IgH2WKG4VhmZiBO94/oL3xuP8aVqmAbak0Mqm2PfUJQWbTyjiiycyHDTXVtI5yxuvm5F1acirZrdwhvOm8ujOwe5f0tfyffntNtIZy1GNFBRJ+FgMEHnSJx2f2WP2V6nnb5w+cpf1qMTpYv8d+H7LeUZjio3TR2pf13DCUCqKkdW1b5kJset92xlIJLkMy9dybx2/4n/qAq8es0ctvZGuOPPezltaiOLpzaUdH8+p4P9gVjVfwBR1WEokmRnf5Q2n7viC4e9TjvD8TTprJ4FPVXjetRExCMi/yYi3xGR/xn9KvXgVHnojHb9iqezdA3HafZqLrYqnpxl+NIDO9jZH+GGy5eyYmZzpYc0bjYRPnTZElp8Tm67fxvREpfZ87rsRBIZwkltTqOOL5LMsKU3QovXWRWTIqNBvr52T914P5r8BJgOXAE8BswGIqUalCo/DbTr0/6hfPt0WxWUUlP1wRjDdx/dzZP7h3nPCxdx4aKOSg/ppDV7nXz0imUMRdN8/ZGdJc/Pdtnt9GhzD3UcyUyOjd0hvA572Uv1HY/HYS9rx9R6M95ncrEx5lNAzBjzI+Aa4IzSDUtVggba9SWUyNAXTtLkqc6FaKo2/ezJTh7Y2s+rz5nNNWfMqPRwTtmyGU28/cL5PLF3mN+tP1jSfTV6HPQGkyQzuZLuR9WmbM5ic08IDCWvenOyvK58lZFsrnwdU+vJeIPs0XMFQRFZCTQD80syIlVRGmjXB2MMewaj+JzaPv1onjkwwqd+v5m/7RkqS5WJenH/5j5+9lQXL1k2lTc/b16lhzNh16+ayYWL2vnfv+1na2+4ZPsRya+J6NcZQXUEyzLs6IsQS2ZpqsK0PpsIxkA4qd0fT8V4g+w7RKQV+CRwF7AV+ELJRqUqamygraWnatNwLE0onsZfpeXUKmn3QJTP37+NzQdDfP6+7Xzgl+t5av+wBtsn8I99Ab772G7OmdfKe1+0uC4+vIkI73vxaUxr8vDF+7cTSpQu97TJ46RrJK4zguow+wMxBiIp2vzVuzDWZbcxGNEPiKfiRHWyPwdgjPk+sMYY82djzEJjzNTRyiOqPo0G2js00K45OcuwayBKg7v6ZkUqrS+c5JZ7ttDkcfL9t6zhg5eeRiyV5dZ7tvKRX29kfVdQg+2j2N4b5osP7GDRlAZuvHIZjirKGZ0ov9vBjVcuI5zMcPuDO0p2vLPbhKxlGI5pOT+V1xtMsD8Qo63CpfpOxOdyMBBJaSxwCk50pLxyzM86cz3JaKBdmwbCSRJp7dJ1pHAiw813bSGbM9x8/QraG9y8eNk0/uuN5/DeFy0mEEvxqd9v5mN3bmLzwVClh1s1ukbi3HrPVtr9Lm66bkVdvq4WTmngPRcvYn1XkF+u7SrZfvwuBwcCMf0gpwjG02zrC9PqdVX9wnS7TchZhohWGTlp9TMdoUpCA+3akslZ7BmMasm+I6SzFv957zYGIkk+ec3pzBnT5tpht3HFiun895vW8O4XLKQnmOBjd27iU7/fzI6+yV1EKRBNcfNdW7DbhFuvX1nXr6vLl0/jxUun8rMnO1nXOVKSfXicdmLpLOGE5rdOZrFUlo3dQZo8zpo5K+Sw2RiKpio9jJpzomd3aqGF+ofH/Kxt1ScZDbRrR89IgpxlqqoEVKVZxvCVh3eyrTfMBy9dcsyazi6HjetWzeSON6/hHRfNZ+9glBt+vYFb79nCnsFomUddebFUllvu2UokmeWm61YwvdlT6SGVlIjwL5csYk6bjy8/tJNAiQIKt8NB53CsJNtW1S+VzbGpO4jbYcftqJ2zQg1uB32hlBZEOEkneif+Hvn26Q1jfta26pOQBtrVL5nJsT8Qo1nbpx/mh3/dx193D/GOi+bzgtOmnPD2Hqedl589m++9ZQ1vft48tvaG+cAv1vP5+7ZxIDA5gqNMzuJz922jczjOjVctK3lXxGrhcdq58aplpLMWX3hgR0kWKfpddgLRNPG0zmZPNjnLsLUnTM7k85xrSX5NgUVUX7cn5UTP8k7gQWNMoByDUdVtbAv2pdObqqIjlXpW53AMm03bp49114aD/G59D9edOYOXnTXrpP7W53LwmjVzuPqMGfx+/UF+v76Hv+8JcPGSKbzhvLnMbPGWaNSVZRnD1x7eycbuEB+8dAmr57ZWekhlNafVx3tftJgvPbiDHz9xgHdctKCo2xcR7HahN5hk0ST58KLyZVV39kcIJzJVXUnkeOwiBKIpmjz1mzZWbCeayZ4H/EpEHheRm0XkfKmHuk3qlOmMdnWKprIcHEnSrAe/Q/66e4jvP76PCxa280/PX3jKJeca3A7eeP48vv+WNbxi9Wz+vjfAv/z0ab7+yE76w/VX1uqHf93Hn3cN8dYL5vPiZVMrPZyKuHjJFK4+YwZ3rjvIE3uLP8fU6HZyMJggo+X8Jo3OQJy+UJJWX+2eafS7HfSFkrpw9yQcN8g2xtxmjHkxcDWwAXgH8IyI/J+IvEVEppVjkKq6dDS4GYhooF1N9g1FcTtsdVG7uBi29Yb5ykM7WTq9kQ9fvqQos/tNXidvu3A+33/LGq49cyaP7Rzkn//f03zn0d11syDoznXd/G59D9eeOYNXrj65mf96887nL2Dx1Aa+9vDOoreVttsEg2H3QFSPoZNAfyjJ7sEobX5XTR+jnXYbqaxFLK2dS8drXKujjDERY8ydxpj3GGPOBv4TmAL8uKSjU1Wr3a+BdrUIxtMMRlI06iw2AAdHEnzmD1vpaHDxyWuWF31xUavPxbtesJA73ryGy5ZP46Gt/bz7J2v53uN7GanhGsiP7hjgf/66n4sWd/DOCcz81wun3cZHr1wGArfdv410trizzq1eF32hJNt79Rhaz0KJTL5Un6/6S/WNh02kpo9z5TauIFtELhIRf+HnNwHvBH5tjLmilINT1U0D7cozxrB7MIq/xhbRlEownubmu7dgE+Hm61eUtORcR4Obf71kMd990zm8cMkU7tnYwzt/spb//ds+wiXsHFgKG7qCfP2RXayc2cSHLi3OzH89mN7k4UOXLmHPYIzv/2VvUbctInQ0uBmKpth8MKSdIOtQIp1jY3cQv8tRNxWf/C4HvcFEpYdRM8b7rH8XiIvIKuA/gANMYBZbRNpE5CER2VX4ftSVNSLyQRHZIiKbReRnIlLfNaRqkAbalTUYSRFJZmtupXopJDM5br1nK8PxNJ++djkzmsuzMHF6k4f3v2QJ33nDOVywsJ3fPnOQd/54Lf/vHweIpqp/Jf7ewSifvXcbs1u9fOKa5bgc9REMFMt5C9p55epZ3Le5j0d3DBR9+21+N8F4ms094aLPlqvKSWctNh0M4rDZ6qqBk8thI57JaXWccRrv0TRr8pnuLwW+boz5OhMr4Xcj8Igx5jTgkcLvhxGRWcD7yLdzXwnYgddNYJ+qRDTQroycZdgzGKXRrQF2zjJ88YHt7BmM8tErlrJkWvkrjM5q9XLD5Uv55uvPZvXcFn7xVBfv/PFT/GJtV9W+IfWFk9x89xb8bgc3X7eCBn0tHdWbnzefFTOb+Paju+kajhd9+21+N5Fkho0Hg6Symu9a63KWYVtvmFTWqtv/qWCsts7WVcp4g+yIiHwMeBPwBxGxAxM5D/tS4EeFn38EvOwYt3MAXhFxAD6gZwL7VCWkgXb59YYSJDNWTTU0KAVjDP/95z08tX+E91y8iPMWtFd0PPPa/dx41el87bVnsXxGE//viQO868dr+e0z3SQz1RNAhQpt5jM5wy2FNvPq6Ow24SOXL8XjsPP5+7eX5Hls8bpIZSw2dgWr6nWiTo4xhj2DEYZjaVrqtGeB3+Wgtw4rK5XCeIPs1wIp4J+MMX3ALOBLE9jvNGNML0Dh+3PqRBljDgK3A51ALxAyxjw4gX2qEtNAu3zSWYt9QzFa6rjN9Xj9+plu7tvcxytXz+bqM2ZUejiHLJrSwKevXcHtr1rFwikN/PBv+3n3T9Zy94aeipduS2ZyfOaerQxGUnzymtOZ2+Y78R9Ncu0Nbm64fCndw3G+/ejukpQxa/I4SWcN67uCJLSCQ03qHklwcCRJu78+A2zIN22KJDP6YXAcxj2TTT5N5HERWQKcBfzseH8gIg8XcqmP/HrpeHZYyNN+KbAAmAn4C4suj3X7d4vIWhFZOzg4OM67pYpNA+3yOBiMY1kGR50spjlVj+4Y4Md/P8DFp03hLRfMq/Rwjmrp9EY+89KV3PaKM5jZ4uWOx/fy7p+s5f7NfRVZ7DaaWrNrIMINlx+7zbx6rlVzWnjD+XN5dMcgD2zpL8k+mrxOjIF1XSNVm2akjm4okmRnf4RWX22X6huvUFyrjJzIeN+h/wy4C3nSjwBvB/73eH9gjLnUGLPyKF+/B/pFZAZA4fvRVpNcCuwzxgwaYzLAb4ELj7O/O4wxa4wxa6ZMOXHrZFU6o4G2lqYqjUQ6x4FAfNK3T9/Yna+IccasZj5w6WlVXx5rxcxmPv/yM/jMS1fS7nfz7Ud38y8/fYZHtvWX7f/EGMN3Ht19KLXmgkUdZdlvPXnNmjmsntvCHY/vYfdAtCT7aHA7sIvwzIGRmlg8qyCSzLC5J1+qbzJU5/E67fRpysgJjTfIFmNMHHgF8E1jzMuBFRPY713AWws/vxX4/VFu0wk8T0R8hS6TLwG2TWCfqoza/W4Goxpol8L+QAyn3TYpDuTHciAQ47P3bmNmi5ePX316zZTHEhHOmtPCl151Jp++djk+t52vPbKLf/u/Z/jzzkGsEndS+78nO3lwa/+hdvHq5NlE+NBlS2n2OvnC/dtLFgT7CmXf1h0YIZzURWbVLJnJsaE7iM9ZP6X6TsTrtDMSz2hFnBMYd5AtIhcAbwT+ULhsIqutbgMuE5FdwGWF3xGRmSJyL4Ax5h/Ar4FngE2Fsd4xgX2qMtNAu/giyQx9oeSkrigSiKa4+e4teJx2brpueU2u3hcRzp3fxtdecxYfu2oZdpvwpQd38L6frePve4ZKku973+Zefv5UF5eePpU3nT+36NufTJq9Tj56xTIGoym+/sjOkrWZ9rkceJx2njkwQiiugXY1yuQsNh8MYUPwuibPIvTRdBj9AHh84w2y3w98DLjTGLNFRBYCfzrVnRpjAsaYlxhjTit8Hy5c3mOMuXrM7W4yxiwrpJm82RhTH72LJxENtIvHGMPewRgep31S5PsdTTyd5ea7txBL5bjp2uVMbazt0vkiwoWLOvjG687mhsuXkrUMn7tvOx/85XrW7h8uWvD2xN4A//XYHs6Z18q/XbJ40r5+imnZjCbefuF8ntg7zO/Xl67wlcdpp8Ht4JnOEYaj+hZYTSzLsLMvQjydm5Qddz0OO30hTRk5nnFNARlj/kw+L3v0973ka1grdUKjgTa9YZbNaJrUaQ4TEYxnGI6l6Gio7cDyVGVzFp+/bztdIwk+fe1yFk5pqPSQisZuE164ZArPX9zBn3YM8LMnO7nlnq0sndbIm583jzNnN59yYLytN8yXHtjBoikN3Hjlskm/WLaYrl81k629Yf737/tZOr2R02c0lWQ/bocd8QgbukOsnNXElBr/cFkv9g7FGIik6Jik5S+9LjuBWIpsztLjyjGMt636FBH5kojcKyJ/HP0q9eBU/dAZ7YmxLMOugQgN7sk3WwL5Wfxv/mk367uCvPdFi1k996hNYmue3SZcevo0/utN5/CvlyxiKJrik7/fzCd+t5ktPaGT3l7XSJzP3LOVjgYXN123oq46z1UDEeF9Lz6NqY1uvnD/dkKJ0p06dzlsNHudbOoO0a+zhxV3cCRBZyBW16X6TsQmgjEQTuri3GMZ70ePnwLbyZfTuwXYDzxVojGpOqWB9qkbiqaIpbOTNkj66ZOd/HH7AG84by6Xnj6t0sMpOafdxlUrZ3DHm9fwrhcspGskzo2/3cRNd21mZ39kXNsIRFPcdNcW7HbhlutX0qw11UvC73Zw45XLCCcz3P7gjpIe25x2G60+F5t7QvSMJEq2H3V8w9F8mdo2v3vSp1657DYGI/qh71jGG2S3G2N+AGSMMY8ZY94BPK+E41J1SgPtk5fNWewaiNLsmZwzJg9s6eMXT3Vx2fJpvO7cOZUeTlm5HDauXzWT7715DW+/cD67BqJ8+Fcb+Mw9W9k7eOzycbFUPnc9msxy07UrmN6s6QWltHBKA++5eBHru4L8cm1XSfflsNto97vZ1hcuSYt3dXzRVJZNB0M0eydHqb4T8bkcDERS+n5+DOMNskfPgfWKyDUicjYwu0RjUnVOA+2T0xtKkslZk6Y01FhrDwzznUd3s3puC//6wkWTdtbI47TzitWz+f5b1vCm8+eypSfE+3+xntvu20bnEYFWJmfxuXu30TWS4GNXLWPx1PrJXa9mly+fxouXTuVnT3ayrnOkpPuy24R2v5td/RH2D0VLVt1EHS6ZybG5O4jHacflmHzH46Ox24ScZYholZGjGu+r5D9FpBn4MHAD8H3ggyUblap77X43Q9EU67TZwnGlsjn2DUVpmYSNZ3YPRPnC/duZ3+Hno7pgD8jPGr323Ll8/y3n8to1c3imM8h7/+8ZvvzgDnqCCSxj+OrDO9l4MMT7X3IaZ9dp7no1EhH+5ZJFzGnz8eWHdhIocSUQu01ob3CzdyjG3qGYBtolls1ZbOkJkTP5/0P1LIfNxpBWvjkqOd4/poh4gH8GFpOvVf0DY0zVR0Rr1qwxa9eurfQwiiabs/jL7iHa/fW3gjmezhJP5zhtWgMzm73Y9PTbYXYPROkNJmjxTa4guz+c5CO/3oDDbuP2V62ibRIvLjqeUCLDb5/p5p5NvWRzFounNrCzP8rbLpzPK1frycZK6BqJ8+FfbmB+h5/PvWxlyT8cWsYwHEszq9XD4imNegwtAWMM23rDDEZTtPnq7314onKWIZrKcuGi9kn5+hORp40xa4523Yn++38ErCEfYF8FfLnIY1OTnM/loNXnYtdAhE0HQyQzuUoPqWrE01m6R+I0TbIFa5Fkhpvv3kI6Z3HzdSs0wD6OZq+Tt1+0gO+/eQ3XnDGDvYMxXrpqJq84e1alhzZpzWn18d4XLWZbb5gfP3Gg5PuzidDud3FwJMmO/giWpuAVVc4y7BuK0RdOaoB9DHabkLUsoumqn4MtuxOd81hujDkDQER+ADxZ+iGpycZuEzr8HsKJDE/uC7BsehNTm3Sh1v6hGE6bDdskykNOZy0+e+82+kJJPvPSlcxt81V6SDWh1e/i3Rcv4u0XLZiUufvV5uIlU9jSG+bOdQdZPqOJ5y1sL+n+pBBo94WSWJbRfgRFMhJLs7M/QiKTq8szycVkFyEQTdE0CZvyHM+JjsaHMtlrIU1E1bYmr5MGt5MtPSG29YZJZ61KD6liQokMfeEkjZ7Jk/s3mk+8pSfMBy9dwspZzZUeUs3RALt6vPP5C1g8tYGvPbyzLF3xRISOhvyi8q29IbK5yXv8nKh4Osvmg0HWdQULZwrck2qy41T43Q76QkldG3CEEx2RV4lIuPAVAc4c/VlEwuUYoJpcnIXyVEORFGsPDBOMpys9pLIzxrBnMIrf5ZhU1TT+92/7+cvuId5+4XwuXjKl0sNRakKcdhsfvXIZCNx2/7ayTRq0+90MR9Ns7gmT0UD7pGRyFvuGovxj7zCheJYpDe5J25vgZDntNlJZi1haUz7HOm6QbYyxG2OaCl+NxhjHmJ9L0z9WTXoiQovPhdNm45nOIHsHo5Oq1F8gmiIUz0yqFex3b+jhznUHueaMGbxc84lVnZje5OFDly5hz2CM7/9lb9n22+Z3E0lk2NgdJJXVoOdEjDEMhJM8uW+YzkCcVp9r0q2FKQabCCOxyTcxdjx6blFVLY/TTrvfRedwfNKU+stZht2DMRrckyfA/vueIb73+F7OX9DGu16wcFLN3qv6d96Cdl65ehb3be7j0R0DZdtvi89FMmOxqUsXlB9POJlhXVeQLb1hPA47bX635rOfIr/LQU9QO5GOpUG2qmqj+XA5Y3hq3zDdI/G6zvkaCCdJZnKT5hTl9t4wtz+4kyXTGrnh8qX65qbq0pufN58VM5v49qO7y9qlscnjJJW12NAVJKGn8Q+TyubY0Rfm6f0jpDMWHX63NpiZIJfDRiKTI65VRg7RV5SqCaOl/nb2R9jYXZ8zM5mcxZ7B6KRZnd0TTHDrH7bS3uDiU9cunzQfLNTkY7cJH7l8KR6Hnc/fv72sx68mrxPLgnVdIxr8kD9b2D0S5x97AwxEUrT7Xfgn0ZnDcgjGtPvjKA2yVc2w24QpDR6iySxP7RtmIFz6Ffvl1DOSIGfMpKgQEYynufnuLQhw83UraNb8R1Xn2hvc3HD5UrqH43z70d1lPSPX4HFgQ3imc3Kk3R3LSCzN2v3D7B6I0uh20uJ1aXpakfldDnrr7L15Iur/3VzVnSavE7/bUVel/pKZHPsCMZo99d94JZnJ8Zk/bCUQS/Opa5czs8Vb6SEpVRar5rTwhvPn8uiOQR7Y0l/WffvdDpw2G+sOjBBOTq6ZxqOV5Ct1J87JyuO0E0lm6vJs86nQV5mqSfVW6u9AIIbDJnWfk5yzDLc/uIPdA1E+cvlSlk3XIkVqcnnNmjmsntvCHY/v4Ym9gbLu2+dy4HHaWXdghFC8/gNtLclXOaEaf08uFg2yVc2ql1J/0VSWnmCi7nOxjTHc8fhe/rFvmHe/YGHJu+ApVY1sInz4sqXMb/fzuXu3cfeGnrLu3+O043c7eKZzhOFoqqz7LpfRknz/2BfggJbkKzuv006fpowAGmSrOlDrpf72DkbxOOq/8cxv1x3k3k29vOLsWVxz5sxKD0epimnyOvncy8/gvAVt3PH4Xr7/+N6yThC4HXaaPE42dIcYitRXMBROZnimc4TNPWF8TgftWpKv7LxOOyPxTF2kck6UBtmqLtRqqb9gPM1QNE1DnbdPf2znIP/7t/1cfFoHb71wfqWHo1TFeZx2PnbV6Vx35gx+v6GHL5S56ojLYaPZ62Rjd4j+MrR9L7VkJsf2vjBr94+QzRmmNLgnxSLyajQ6YTTZcv+PRl+Bqq7UUqk/Ywy7+6P4XfWdI7ipO8jXHt7JiplNfODSJdjqfMZeqfGy24R3X7yId71gAU/sDfDJ320u6/oSp91Gq8/F5p4QPSO12URktCTfk/sCDEZSdPhdk6pbbrXyOOz01cGHt4nSIFvVnVop9TcYSRFOZev6DeFAIMZn793GjGYPn7x6uc4sKXUU16+axceuWsa+QIyP/Hoj3SPla1jjKCwi39YXLmujnGIYjqV5av8wu/qjNHlcWpKvinhddgKxFNnc5E4Z0Xc8VbequdRfNmexezBKcx0vdgxEU9x891ZcDhs3X7ei7lNilJqICxZ18LmXnUEik+Mjv97Ilp5Q2fZtt+XT7XYNRDgwFKv6VLtYKsvG7iAbukawi9DRoHnX1cYmgjEQTtbWGqli0yBb1bVqLfXXF06Sylh128Y3ns5y6z1biaWy3HTdCqY2eSo9JKWq3tLpjdz+qlU0e5188neb+fPOwbLtezTQ3jMUZW+VBtqZnMXewShP7hsmmszS0eDRknxVzGW3MVhnC2tPVn2+wys1RrWV+ktnLfYNxmip05JS2ZzFbfdtZ38gxo1XLmPRlIZKD0mpmjG92cOXXnUmS6c38qUHd/Crp7vKFvCOLiA/EIizayCCVSUlUS3r2ZJ8ncNx2vwuGuv4LGC98LkcDERSNVlat1g0yFaTRrWU+useiWMZU5cdx4wxfPvR3azrCvLeFy1m9bzWSg9JqZrT6HHymZeu5OLTpvDjvx/g23/aXbZAxSZCh99F90iCHf2VD7RDiQzPdI2wZUxJPl08XRvsNiFnGSKTuMqIJkmqSWV0piaWyi+KPG1aA7NavGVbLJNI5zgQyM/E1KOfPdnJw9sGeP25c7hs+fRKD0epmuW02/jw5UuY1uTmV093MxhN89Erl5ZlobSI0OF30xdKYoxh6fSmsuc8JzM59gdi9AST+F12OhrcZd2/Kg6HzcZQNEWLrz7f806k/qbSlBoHv7sypf72B2I47ba6nIl5aGsfP3uqi0tPn8rrz5tb6eEoVfNsIrzlgvm890WLWd81wo2/3USgTF0apbCgcCCSYmtvqGxVInKWoWs4zj/2BhjSknw1r8HtoC+UqvgZkUrRIFtNWqOl/iKFUn+lXqARTmboDSVpqsMqG88cGOFbf9rN2XNa+LdLFmsZLaWK6IoV07np2hX0hZJ8+Fcb2DcUK9u+2/1uAtE0m3vCZEoYaBtjDpXk2z0QpdnrollL8tU8u03IWhbR9OSsMqJBtpr0mgul/jYfLF2pP2MMeweieJ32unvT2DMY5bb7tzOv3c+NVy2ry1xzVTnJTI7BaJLhWIpQIlPSQK+arZ7XyhdeeQYAH/3NRp7pHCnbvtv9biKJDBu7gyU5PsZSWTYdDGlJvjplFynbGZhqo++GSvFsqb/BQqm/ULy4CzVG4hlG4mka3PU1iz0QTnLr3Vvxux3cdO1yPa2riiqWypLM5lg9t5UzZ7cwvdlNKpsjEE0RiKWIp7NVWWquVBZ0NHD7q1cxrcnNLXdv4cGtfWXbd4vPRSKdY2NXsGjpdemsxZ6BKE/t15J89czvdhzK759sNMhWqkBEaC2U+nu6c6Ropf4sy7CrP0KDu75KTkWTWW6+ewupbI6br1tOuy5MUkUUTmYAwznzWmnxuWj1u1g8tZHnLWznvIVtnD69Ea/LzkgiTWASzXJ3NLj5wivP5Kw5LXzzj7v5yRMHyha8NHtdpHMWGyYYaFuWoS+Y4Ml9AbpH4rT6tCRfPXPabaSyFrF0edY+VROddlLqCB6nHZfDRudwnOFommUzmyY0Az0YSRLPZOnw109DlkzO4rP3bqU3lOTW61cwr91f6SGpOjIST+Nz21k5s/k5M5sigs/lwOdyMK3ZSzZnEU1lGY6lGYikiCSzGAxepx2P016Xi4x9LgefumY5331sD79c20V/OMn7X3IazjKkajV6nESTWdZ1jrBqTstJn70KJTLs6o8QSWVo9rjKMmZVeXYRRmL1dzb3RCbXvVVqnI4s9bdkWiMzWzwnnU+db58eo9lTP+WLLGP42sM72dwT5obLl3LG7JZKD0nVCWMMgViajkYXy6Y3jSsAc9httPhctPhcLJzSQCKdI5LMMBBJMRxLYxmDvRCY11OHVYfdxntftJjpTR5+/MQBhqIpPnH16WWZEW7wOIilsjzTOcJZc1rHFTglMzn2DcXoDSXwuxx1NemgTsznctATTDCnzVfpoZSVBtlKHYff7cDjtLOjP8xQNMXS6Y0nlTPYE0yQyVk01dGp0B//fT9/3jXEWy+YzwuXTKn0cFSdsAoB9qwWD4unNp7ywjevy47XZWdqk4ecZYgms4zE0/SHk0RjGQzgceRvU+uz3CLCq9fMYUqjm68/sov/+M1GbrpuBdObSh/A+t0O4uks6w6MsGpuyzGPcdmcRW8oyd7BKHZbvv52vS3+VifmctiIxDLE09lJtXanfj7WK1Uip1rqb7SZQou3fmax/7Cxh988c5CrVk7nlatnVXo4qk7kLEMglmJhh48l0049wD6S3SY0+5zM7/Bz/sJ2zl/YzoqZzTR5HYQSGQKxFCPxNKlsbeeKXrJ0Kp956UqC8Qwf+dUGdvZHyrJfnys/CbHuwMhzFosbYxiKJHlq/zB7BrUkn8oLxiZX90cNspUap9FSf5sOhtjed+KasV3DcQSpm1JUT+wNcMfjezlvfhvvuXiRvlmqosjkLIZjKU6f3sT8joaSvq48TjtTGt0sn9nM8xd3cPbcVua3+wppKvmKJdFktmwtzItp5axmvviqM3E7bXzszk38fW+gLPv1OO34XA7WdY0wEksD+aowG7tDbDoYOlS5qV6Og+rU+V0OesOl7UdRbTTIVuokOO02OvxuBsIpntp/7FJ/sVSWg8EETd76SBPZ0RfhSw/uYPHUBj5yxVJ9w1RFkczkCCczrJrTwowWb1n3bbMJzV4nc9v9nLugnectbGflrGZa/E6iqfwsdzCeLls32GKY0+rj9letYn67j8/fu427Nhwsy349TjuNbifru4Js7wvz5L5h4qkcHQ0e3A4tyafyPE47kWSmpv6nJmryJMYoVSSjpf6SmRxPd44wv93HvHb/YYHnvqEoTlt9tE/vCSa49Z4ttPlcfOqa5VrHVhVFLJUlY1msntdaFWsWPIVqJB0NbizLEEtnCcYzDITzM9wALrsNn8tR1R8yW3wuPvuyM/jyQzv43uP76A+neMdFC0o+ZpfDRrPXyWA4RZvfVRfHPlUaoXgaT3N5P1RXigbZSp2iI0v9nT6zCb/bQSier2zQ4a/9utFdI3FuumsLBrjl+hW0+Oonv1xVTjiZwW4TzpnXWpWLoGw2odHjpNHjZE6bj1Q2RzSZZSiaYjCSJpuzsNkEr9OO22GrutQpj9POjVeezv/8dR93behhIJLkw5ctLfkHZGeh0otSx+J12ukLJ5mmQbZS6kTGlvp7slDqry+cL1FVbW+8J2tHX4Rb7tmCXYRbr1/JzDKfzlf1aTiWosHjYOWs5ppJJXA77Lgb7LQ3uFkyzRBL5wjF0/RHUgzH83nITpsNn8uOo0rqPtttwrtesJBpTR6+//hePvG7TXzymuW0ahCsKsjrtDMcT5POWnVVUvNY6v8e1oE/bh9ga0+YYOFgrqqP3+2g1ediR3+YUKL2SxStPTDMJ363Cb/LwRdeeSaLpzZUekiqxhljGIqm6Ghws2p2S80E2EcSERrcDma1+lg9t5ULF3Vw5uwWpjS5iWdyBGIphmMpEulcVbSRvn7VTD5+9ensD8T5yK830DUSr/SQ1CQ2OvmU7+ha/6QaDgLFtmbNGrN27dpKD6NoLvnSn9gfyB8YmzwO5rX7mdfmY24hF3hum2/SdVFSpfPH7QN844+7mNfm4+brVtDq15kvNTGWMQSiaWa3eVg8pRFbFec0T4Qxhng6l08ZiyYJxjMIYC/Mcleyu+HO/gifuWcrWcvwiatPZ+Ws5oqNRU1usVT20NmseiAiTxtj1hz1Og2yq19vMMFv13UzEstwYDhOZyBO53CcxJgVuh0NLua2+ZnX7mNeWz74nt3q1UVq6qTcua6b//nrfs6c3cwnrj695mfkVeVlcxbD8TSLpzQwt91X82lUJyOTs4gmswRiKQYjKVIZCyR/ytzrtJf9segLJ7nl7i30hfJt2C9ZOrWs+1eVl8zk6ByOE0tlOXN2S0UW8VrGEEykuWhRR9WkV03E8YJsfQetAVMa3ayY2Uz7mIV0ljEMRVIcGI5zIBDnwHCMzkCcTQeDZHL5D04CTG/2FALvfAA+t83HzBZvRWdUVPWxjOF//7afO9cd5KJF7Xz48qX6GlETls5ahBJpVsxoYvokzOl32m20+l20+l0smtJAIpMjnMgvjB6JpzEG2nzla9AyvcnDl165is/eu5UvP7STgUiKV58ze1J98JksjDEMx9LsG4rlvwL57z3BBKNl4F+5ejZvu3B+2cdmE8EYCCeztNX5mVINsmuUTYSpTR6mNnk4d37boctzlqE3lOBAYbb7QCDGgeE4T+4bPvSPZbcJs1q8h2a95xbST6Y1eaq6NJUqjWzO4ht/3MWfdgxyzRkzeNcLFurrQE1YMpMjnsmxak4L7Q21X2lnokQEn8uBz+VgerOXTM5i31CU7pEELV5X2T7UNngc3PrSlXzjkV385IkD9IeT/MsLF9XFjOJklclZdI/E2Tt4eEAdSWYP3WZqo5sFHX5esLiDBR1+nto/wm+e6Wbx1Aaev7ij7GN22W0MRpIaZKvaYrcJs1t9zG71cdGYy9NZi4PB+JjgO87O/giP7xo6dBuXw8bc1kKudyHlZF67j3a/tsKtV8lMjtvu387TB0Z40/lzec2aOfpcqwmLprLkLIuz57ZURQ3sauS021gyrYlWn4ttvWGcNjsNnvK8JTvtNj502RKmNXn4xdouBiMpbrxqmaaH1YBQIlOYnY4emqXuHkmQLcyiuew25rX7uGBhOws6/Czo8DO/3Y//iHVba+a30TUS5+uP7GROq5d57f6y3g+fy8FAJMXiqaauJ3U0J7sGZHMWf9k9dFi6SLEk0jm6Rgoz3oH4oZzv4TGVTPwu+6HZ7rGz38110s1wsgonMtx6z1Z2DUT410sWc8WK6ZUekqoD4WQGh004c3YLXpeuCRmPRDrH1t4Q4US27I1cHtzax7f/tJu5bT5uum4FHXrWoSrkLMPBYOLZdI+hGPuHYoe9N7f5XSwsBNILOvzM7/Azs9k77qA1EE3xwV+ux+O085XXnFX2AgqBWIqz5rTUfG11XfhY40oZZB9LOJHJz3gXUk5GZ7+jqWdPP7V4nYfPehcqnuhsSPUbiCS56a4t9IeTfOTypVywqPynC1X9CcRSNHkcrKihGtjVwrIMB4Zj7BuK0+h2lHXR+jOdI9x233a8Ljs3XbuchVO0ZGc5RVNZ9h+RO90ZiJPOWQA4bMKcNh8L2g8PqIsx0bW1N8zH79zE2XNa+NS1y8v6AS+UyDC92c3iqY1l22cpVF2QLSJtwC+A+cB+4DXGmJGj3O79wLvIr+H7njHma+PZvgbZpWGMYSSeOZTn3Tm64HI4TjJjHbrdlEb3oVnv0Yons1u9+qZbJQ4EYtx01xaSmRyfvGZ53ZRRUpVjjCEQSzO10c3S6Y2a3zsBwXiazT0hMNDsLd8M376hGLfes4VYKsdHr1zGOfNay7bvycIyhr5Q8lAwPRpYD0RSh27T5HEUAumGQwH17NbSFiu4d1Mv331sD689dw5vOn9eyfZzpJxliKayXLiovabLelZjkP1FYNgYc5uI3Ai0GmM+esRtVgI/B84D0sD9wL8YY3adaPsaZJeXZQwDkRSdY1NOhuN0DccP5YnZBGY0e5l7KPj2sWRaI9OaPBUe/eSypSfEZ/6wFbfdzs3Xr2BBR3nz8FT9yVmGkXiaOa1eFk5pqOk3y2qRyubY1R9hIJKmzecqW85qIJrilnu2ciAQ0xSyCUpmcuwPHJ7qsT/wbOldm8CsFu+hWekFHX4WtPtpq8AaKGMM3/zjbh7a1s/Hrz6dCxa2l23fgViK1fNaa3rtRjUG2TuAS4wxvSIyA3jUGLP0iNu8GrjCGPPOwu+fAlLGmC+eaPsaZFeHnGXoCSXyM96F2e8DgTi9oXwJIZvAq86Zw+vOnaPl4srgyX0BvnD/DqY0urnl+hX6AUdNWDZnMZxIc9qUBua0Ta4a2KVmTD4nd/dAFK/TXrY0vHg6yxfu38EznSO8+pzZvOl588qaQlBrjDEMRlPPpnsUvnpDSUajK7/L/mwgXQim57b7qursbjprceNvN9I9kuDLr1nFnFZfWfYbjKeZ3eZlQUftpihVY5AdNMa0jPl9xBjTesRtTgd+D1wAJIBHgLXGmH8/0fY1yK5u6axF10icezb28PC2ARZ2+PngpUuYr7OqJfPQ1j6+9afdLJrSwE3XrdBFq2rC0lmLUDLNihnNTGvWD2ylEklm2NoTJpnJ0Vqmmto5y/Ddx/bwwJY+Lj6tgw9cukQnQsi/5juH4/mAesws9di1SjOaPcwfkzu9oMPP1EZ3TXwAHYzkF0I2uB185TWryvLBLpOzSGVzPG9he008RkdTkSBbRB4Gjnau6RPAj04UZBcu/yfg34AosBVIGGM+eIz9vRt4N8DcuXPPOXDgwITvQ7WotyB7rH/sC/CtP+0mmszyhvPn8oqzZ9d1OZ9yM8bw66e7+fETBzh7Tgsfu+p0rfigJiyRzhHPZFk1u4XWOq9zWw0yOYs9g1F6guWrqW2M4TfPHORHf9/PiplNfPyq02maJB/OLWMYCKfoHH72DGy+VF78UL8Jt8P2nGB6Xh0s/N90MMQnf7eJc+e38fGrTy/LWYxALMWa+W1lr25SLNU4k33CdJGj/M3ngG5jzHdOtH2dya4toUSG7z66m7/uCbB0WiMfumwJMydhd7his4zh+4/v5e6NvbxwyRTe/5LTdDZqjExh5b4+JicnmsySw2LV7BYaaziPshYNhJNs6w3jspevpvbjuwb5ykM7mdbk4ebrVjC9js5aPLueKE7XSH4xf+dw/udU9tnF/B0NbhZ0+J5djNjuZ3pz/TZvu2vDQb73+D7edP5cXnvu3JLvLxhPM7/Dz5y28qSoFFs1BtlfAgJjFj62GWP+4yi3m2qMGRCRucCDwAVHq0JyJA2ya48xhj/vGuK/HttDOmfx9gvnc/UZMzQX8BRlchZfe3gnf941xEtXzeQdz1+gj+UYyUyORCaL024jlbVwO+z4XfaaPV1ZLqFEGpfDxhmztAZ2pVSipvaWnhCf/cM2bDbhk9eczrLpTSXfZzEZYxiMpOgsLMofXZzfPXJ4Zaw2v4u5bb5DX/PafMxp8z2nkUu9M8bwlYd38tiOQT517fLDukqXQjprkbUszi/jgstiqsYgux34JTAX6ARebYwZFpGZwPeNMVcXbvc40A5kgA8ZYx4Zz/Y1yK5dgWiKb/5pN08fGGHV7Gbe95LTmNpYPzMn5RBPZ/n8fdtZ3xXkbRfO5xVnz9LgcYxUNkc0lWX1vFYaXA5CiQzdI3ECsTQ2ERrdDi1BdxTDsRRNXicrZjbjcujjU0k5y3CgkBPc7HWWZQFd90icW+7eynAszQ2XL6nK2vqjixA7hw+fle4aThyq6gHQ5nMxt913WEA9p81Xs+kKpZDM5PjobzfSH0ryldecVfKzy4FYivMWtNVkuk3VBdmlpkF2bTPG8ODWfn7wl32IwLtesJCXLJuqgeI4BONpbrl7K3uHovz7i0/j0tOnVXpIVSWTswglMqye20qz7/BUh2Qmx0A4SedwnEzO4HOVr6JDNRutgT2tyc2SaVoDu5qMxNJs6Q0hSFlKoIUSGT5zz1Z29kd4x/MX8NJVMytyXB59TY4G0mO/xgbTLT7nYYH06JemOY1PfzjJB3+5nlafi9tftaqkZ68CsRRLpjYys7X2UkU1yK5xky3IHtUXTvK1h3eypSfM+Qva+LcXLaa1xtuvllJfOMmnf7+ZQCzNjVcuK/kpvlqTyVkEE2lWzW6h/Tito3OWIRhP0zUcZySexmG30eh21m3+5fHkLMNwPMXcVp/WwK5SqWyOnf0RBiMp2nzukr9OU9kcX35wJ3/fG+DaM2fwzucvLNk+jTEMx9KH0jtGZ6i7RuLE02OCae+YYLowQz2n1TdpFmqW0vquIDfdtZkLFrbz0SuXlexDVTKTw2aTmmyCpEF2jZusQTbkF6bctaGHH/99Px6nnX+7ZDEXLa6+05SVtncwys13byGTM9x07XKWzaitnMlSyweLaVbObGLqSdQHj6ez9IeTHBxJkMkZ/C7HpMlFzuQsRhJplkxtZHarV88kVbHRmtq7+qNleY1axvDDv+7jd+t7OH9BGzdcvnRCbeBHuwnnA+nYYTPUsTHBdJPHUQik/YfNTGtJ0tL67TPd/PBv+3nrBfN51TmzS7afQCzF8xa2T+i1VAkaZNe4yRxkj+oajvOVh3eyeyDKC5dM4T0XL9RTfgWbuoP8573b8Lns3HL9SubW6ArtUslZhkAsxfIZTcw4xbzCbM5iOJamcyROJJFfMNngdtTt7HYqmyOSzLLiJD+UqMoKF2pqp8pUU/uejT187/G9LJzSwKevWX7Cco7GGIKFYHrs7HTXcPywWtONo8H0mMWHc9t8tOiZzIowxvClB3fw191D3HTdClbPLc1scyCW4vTpjUxrrq2UEQ2ya5wG2XnZnMWvn+nm50910ex18u8vXsyaeZM7JeKvu4e4/cEdzGjxcst1K5jSOLlfI0eyjCEQTXHatMailYeKprL0hRL0BJPkLEOD21FzMy/HE09nSWZyrJrTokFNDTpUU3skQYuv9DW1n9wX4IsP7KDZ6+Tm61Ywp82XD6YTmUMB9NhUj8iYYLrB7Tg8X7qQ6tHideqZkyqTzOT4yK83MBRN89XXnsX0Enz4jqezeJw2Vs2prZQRDbJrnAbZh9s9EOWrD++kczjOFSum846L5k/KBWr3be7lu4/uYdn0Rj517XKd2T+CMYahaJoFU3wladmbyVkMFyoZRFM5XHYbDR5HTZdKjCQzGGDVnBattFDjDtXUdthL/lzu6o9w6x+2kslZzG/30zkcJ5J8Npj2u+3MbfM/ZwFiq0+D6VrSG0rwwV+uZ2qjhy++8syiTy4Yk0/ru3BRR01VMNIgu8ZpkP1cmZzFT/9xgN8+c5CpTW4+8JIlrJzVXOlhlYUxhp8/1cX/PdnJmnmtfPTKZXU1k1oMxhgC8RRzWnwsmtpQ0jdyYwyRVJbeYIK+UBIDNLqdNfUmARBMpPE4bJwxu0VfT3Uins6ytTdMNJml1Vfamtr94STfeGQX6Zz1nGC6zV+edvCq9J4+MMItd2/h4iVT+PBlS4r+vAZiKVbOaqbjOIvTq40G2TVOg+xj29ob5msP76QvlOSlZ83kzc+bX3PBzcnIWYb//vMe7tvcx0uWTeW9L1qsJdWOYiiaYkaLh6XTGsv65p7OWgxFUnSOxElmsrjtDvzu6m9yE4ilaPG5WD6jqa7/fyaj0Zra+wMxmjzlqamt6tsv13bxkycO8E/PX8DLzppV1G3HUlkaPI6amjQ7XpCt5wNVTVs+o4mvv/Zs/vfv+/nd+h6ePjDCBy9dwmnTGis9tKJLZy1uf3AHf98b4FWrZ/OWC+ZVffBWCYFYKl/TeWp5A2wAl8PGzFYvM1o8hBNZDgbjDERSADR5nFXXwt0y+RJ90xo9LJ3eVLcLOSczu01YOKWBVp+LLT0hUlmrLDW1Vf169Tmz2T0Q5Yd/3cfCDj9nzm4p2ra9LjuBWIpszqqLCaTavwdq0vO67PzLCxdxy/UriKdz3PDrDfz0HwfI5qwT/3GNiKWy3HTXZv6+N8A7n7+At144XwPsoxiOpWj1uVg6vamiNZ1FhGafk+Uzm3newnYWTWkgmc0xFEsRS2WphjOIOSu/KHROq59lGmDXvVa/izXz22j0OBiK5RftKnUqRIQPXHoas1q8fOH+7QxEkkXbtk0EYyA8Jqe/lmmQrerG6rmtfOsNq3nhkin8/KkuPvzrDRwIxCo9rAkbjqX52J2b2NYX4cOXLeGlRT49Vy+CiXSh7Xd1BYwep505bT6et6Cds2a34HPbGY6nGYmnK/ZBMJOzCMTyVVcWT9UmM5OFx2nnjFnNLJ7SyEg8TWJMDWqlTobP5eDjV59O1jJ8/t7tpLLFey257XYGixi4V5IG2aquNLgdfOiypXz8qmUEomk+8Iv1/PaZ7pqdtekJJviP32ygN5Tg09cu55KlUys9pKoUTmbwOu2smNlctacYbTah1e/izNktnL+gnXltPmLpLIFYini6fLM2qWyOcDLDGbOai1bWUNUOEWFOm49z5rdiGYuReLoqzqyo2jO71ceHLlvC7sEo33l0T9FeR16XnYFIqmbft8eqzncjpSbogkUdfOv1Z3Pu/DZ++Lf9fPzOTfSGEpUe1knZPRDlP36zkUQ6x2dfdkbJGgDUumgyi8MmrJzVXDOL9rwuO/M6/FywqIMzZjXjdtgIxFIEE+mSvrHE01ni6Sxnz2nVJjOTXJPHyTnz25jS6CYQS5Gpo/Q6VT7nL2jn9efO4Y/bB7h3U29Rtmm3CTnLEElmirK9SqqNdySlTkGLz8XHrlrGhy5bwoFAjH//2Tru3dRbE7M26zpH+Pidm3A7bHzxlatYUocLOYshns5ixLBqTm2WnbPbhPYGN2fNbeXc+W3MbPYSSWUIxFIkM8U9lR9JZsgZw+p5bTT7dOGbAqfdxrLpjSyf0UwklT2s66JS4/W68+Zy7vxWvveXfWzpCRVlmw6bjaFoqijbqiQNslVdExFetHQq33rDapbPaOK7j+3hpru2VPU/7593DnLrPVuZ1uTmi688k1mttdVitlwS6RyZnMVZNRpgH8nvdrBoagMXLGxn+YwmxJYvRRhKZCY8ux2Mp3HZbaye26pNZtRhRIRpzR7Ond+K0y4EYimsGpiIUNXDJsKHL1vKtEY3t92/nUAR3l8b3A76QimsGk8Z0SBbTQodDW5uuX4F/3rJIrb2hnnv/z3DH7cPVN2s9l0bevjSgztYOr2Rz7/iTNprqCB/OSUzOZLZLKvmtNRdt0+H3cbUJg9r5rWxZn4r05rchJJpArHUSS8uMsYwFEvS5HVyZp18GFGl4XM5OHtuK7NbfQzFUqSzmj6ixs/vdvCJa5aTylh8/r7tE04/stuErGURLeN6lVLQIFtNGiLCVStn8M3Xn83cdj9ffXgnn79vO8F4utJDwxjDj/++n+89vpcLFrZz6/UrdcbxGNJZi1g6y6o5rXXfSr7R4+S0aY1cuKiD06c3YhnDUDRFOJE54WyjZQxDsRTTm7w1la+uKsduExZPbeCs2S3EM1nCdZATq8pnbpuPD1x6Gjv6I/z3Y3smvD27SFFmxStJj7pq0pnR7OXzLz+Dt184n6f2D/Pen63j73uGKjaenGX45h9386unu7lixXQ+euUyDYiOIZOzCCczrJrdQrO3vgPssZx2G9OavZw7v43V81ppb3QxEk8zfIwZx9Ea2PPb/Syb3lhVJQ1V9WtvcHPu/DYa3FpTW52cCxd18OpzZvPA1n7u39w3oW353Q76QsmqO+N8MvSdXE1KdpvwitWz+dprz6KjwcXn7tvOVx7aUfaFP8lMjs/du42HtvXzunPn8G+XLNKA6BiyOYtgPM3KWU20+l2VHk5FiAjNXifLpjdxwaJ2TpvaWKh5nSSazDe5yeQshuNplkxvZOGUBm1apE7JaE3tRR0NDMeLvxBX1a83nj+P1XNb+O8/72F7b/iUt+O020hlLWI1XM9dg2w1qc1r93P7q1bx+nPn8NjOQf79Z8+wrnOkLPuOJrN8+q4tPLV/mH9+4SLeeL62ST+WnGUYTqRZPqOJKY1aeg7A7bAzs9XL+QvbOGtOK00+B4FYmlAiwxmzmpjdqjWw1cTYbMLcdj/nzGsjZ+U/5NbyrKIqD7tNuOHypXQ0uPn8/dsZiZ16SqZdZEJ/X2kaZKtJz2G38Ybz53H7q1bhddr59F1b+M6ju0vaDW0omuKjv93Irv4IH71yGdecMaNk+6p1OcswHE+xdFoj01u00sqRRIQWn4sVM5u5YFE75y1o0w8iqqiavU5Wz2ujo9HNUCxVsU6lqnY0epx8/OrTiaWy3Hb/qS+E9Lkc9ARrq8fFWBpkK1Vw2rRGvvras3jZWTO5f3Mf7//FuqLV/ByrazjOR369kcFIiluuX8FFizuKvo96YZl8gL2oo0FnZsfB47Tj1wWzqgRcjkJN7elNhJIZYlpTW53Agg4/73vxaWztDfODv+w7pW24HDYSmVxZu+IWkwbZSo3hdtj5p+cv5HMvPwPLGD7220388K/7ilbOakdfhI/+ZiNZy+LzrziDM2e3FGW79cgYQyCWZn67n7ntGmArVWkiwvSW/AJchy1fU1vTR9TxXLxkCi8/exZ/2NTLw9v6T3k7wVhtVrrRIFupo1g5q5lvvO5sLl8xnd+uO8gHf7me3QPRCW1z7YFhPvG7TTR4HHzxlWeyaEpDkUZbnwKxNLNbPSzo8GuuulJVxO92cPY8ramtxuetF8xn1exmvvPobnb1R0767/0uB73hZAlGVnoaZCt1DD6Xg/e+aDE3XbecaDLLDb/ewM+e7DylfMQ/bu/nP/+wjdmtXr7wyjOZ0ay5xccTiKWY3uxh8ZRGDbCVqkKjNbXPnNWcr6mdqM2ZRlV6dpvwkSuW0erLV/I62d4UHqedSDJTkxVuNMhW6gTWzGvjW284m+cv7uD/nuzkI7/ZSNdwfNx//9tnuvnqw7tYObOJz738DFp9k7P83HgNx1NMaXCzZFojNi1nqFRV62j05GtqexwMRVNaU1sdVbPXyceuOp1wIsMXH9hxSq+TUBU0jjtZGmQrNQ6NHic3XL6UG69cRn84yft/sY7frTt43K57ljH84C/7+OHf9vP8xR3cdN2KumsBXmzBeJpmr4ul2kBFqZpxqKb2FD+hZJpALEUgliKUyJBI5zTwVgAsntrAv71oMZsOhvjhX09uIaTXaaevBlNG9B1fqZNw0eIOls9s4tt/2s0P/rqPJ/YF+MBLljC9+fCSadmcxTf+uIs/7Rjk2jNm8K6LF2LTtIfjCicz+Nx2VsxswmHXz/9K1ZLRmtozW7wksxbJTI5oMksokSGSzJK1nk2zc9psuBz5Lz0uTi4vXjaV3QMRfr+hh8VTG7hk6dRx/Z3XaWc4niadtWqqI7IG2UqdpFafi09cfTp/3D7AHY/v5d9//gz/dNFCrlgxDREhmclx2/3befrACG9+3jxefc5szSs+gUgyg8surJzVjFMDbKVqlsNuo8Fuo8HtoKPBfejydNYimc2RzOQIJzKEk/k87vwkt0FEcNptuB02HDbRY2Yde8dFC9g7FOObf9rN3DYfC8dRBGD09RBOZg57XVU7qcfyO2vWrDFr166t9DCKJpuz+MvuIdr9tfPCmiwGIkm+8cguNnSHOGdeK2+9YD7f+tMudg9E+ddLFnPFiumVHmLVi6ayiMBZc1rwOO2VHo5SqkyMMaQKs96JdI5QIkM4kSE+ZoGbTQS3w4bLbtMzXHVkJJ7mg79Yj90mfPU1Z9HkdZ7wb2KpLA0eBytnNZdhhOMnIk8bY9Yc9ToNsqufBtnVzTKGezf18sO/7c+fyrLb+MgVS3newvZKD63qxdNZspZh9dxWvC4NsJVS+S6vyUyOVNYilsoWZr4zpMaUCnTY8rPeTrtN12/UqJ39+b4RK2c1c/N1K074PFrGEEykuWhRR1V94DpekK3pIkpNkE2Ea8+cyeq5rfxibReXL5/GipnV9Um7GiUzOdI5SwNspdRh7DbB73bgd0Ob/9lqTJlcftY7mbGIJPOBdySZOWxhpcteyPe22zTlpMotmdbIv16yiG/8cTc/eeIAb7tw/nFvbxPBGAgns4e9LqqZBtlKFcnMFi8fvHRJpYdRE1LZfJvcs+e1ahtwpdS4OO35metGD0xpzJ/ZHU05SWUsEpks4WSWSCJLMJE51I1SkEMLLXXNR3W5bPl0dg1E+c0z3Sya4ucFp0057u3ddjuDkaQG2UopdTSZnEUkmWX13FaaPCfOw1NKqWMRETxOOx6nnWacTC+cRLSsZ/O94+ksoWSGcCJLOJlvmmMMOGz54NvtsGvKSQW96wUL2T8U4xt/3MXcNh/z2v3HvK3XZWcgkmLxVFMTz5kG2UqpssnkLIKJNKtmt9Ds0wBbKVUaNpvgddnxuuy0+l3MKlyezVmHSgzGkvngO5LMkslpicFKcdpt3HjV6XzwF+v57L3b+Mqrz6LBc/Tw1G4TcpYhkszQUgON3TTIVkqVRc4yBBMZVs5spr2GSjApperHqZYYdNpt+N0ODbpLpM3v4sarlvHxOzdx+0M7+NQ1y485U+2w2RiKpjTIVkopyAfYgViK5TOamNrkOfEfKKVUGY3OXDd5nExtzB+jRvO9E+kcA5Ek/eEUljF4HHZ8LrsurCyy02c08e6LF/KdR/fwsyc7edPz5h31dg1uB32hFAs7GrBVecqIBtlKqZKyjGE4lmLJtEZmtHgrPRyllBqXsfnerX4Xi6ZYBBMZeoIJArE0AvhdDq3vX0RXrsgvhPzF2i4WTW3ggqOUwrXbhKxlEU1nq35djy6zVUqVjDGGQDTNwil+5rT5Kj0cpZQ6ZQ67jY4GN2fObuHCRe2cPr0RscFQNMlIPH1YXrc6NSLCP1+8iNOmNvDVh3bSNRI/6u3sIgSiqTKP7uRpkK2UKgljDIF4irlt3uOuFldKqVrjdtiZ1uxlzbw2zl/YzoIOP+msRSCaIhhPH1a7W50cl8PGx646HbfDxmf/sI14Ovuc2/jdDvpCSaq9oaIG2UqpkgjE0sxo9rJoaoPmLiql6pbP5WBOm4/zF7axen4rM1u8RFMZArEUkWQGq8oDwWo0pdHNf1y5jN5Qgq88tPM5j6HTbst3BE3nKjTC8dEgWylVdIFYimlNbpZMbdQAWyk1KYgITR4ni6Y2cOGiDs6a00Jbg4tgIk0gliKezlb9zGs1OWNWM//0/IX8Y98wv1zb9Zzr7SKMxNIVGNn46cJHVXaWMSQzOVIZK1/L1GnH5dDPe/ViOJaize9i6fSmql/5rZRSpWCzCS0+Fy0+F4umNBAqLJgcLgSFumByfK47cwa7ByL83z86WTSlgXPntx26zudy0BNMVPV6Hw2yVcllcvnC/+mchfDswWd2q5NkxmIknv+UL+RnAtzagatmBRNpmrxOls9o0udPKaXIpzZ0NLjpaHCTzOQIxtN0jyQIxFLYRGhwO7Td+zGICP/2osUcGI7z5Qd38JXXnMXMQpUql8NGJJYhns7ic1VnOFudo1I1yzKGVCYfVBsMFuBz2pnS6KbF58LvtuN1Pre+aCZnEU/niCYzDMcz+YUjOQOS777lddn1IFTlwskMXqedFTObcehzpZRSz+Fx2pne7GV6s5d4OksgmubgSIJQIoOz0CRHJygO53bY+fhVp/PBX67nP+/dxpdftQqv69mzAMFYRoNsVZ8yOYtUxiKVyx2aiW72OpnR4qHJ48TrGl8qiNNuo9lro9nrZFZrvjJFIpMjns4xEkszEksTTmby+yBfu9Tt1Ja31SKazOKwCStnNWvqj1JKjYPP5cDX5mB2q5dIKstgOEVvKEHWMri0w+RhpjV5+OgVy/j0XZv5+iM7+eiVyxAR/C4HveEkM1ursweDBtlq3A51v8rkMMZgGfA67bQ3umjxOfG7HHid9qLk4YpI/gDkerb1bbrQeSuczDAcSxNOZMgVFpG47DY8Tp3troRYKosRw6o5rZpjqJRSJ2l0wWSTx8n8Dj/hRIa+cJKBSBJTeJ892hngyWbVnBbeesF8fvi3/fzmmYO86pzZeJx2ArEUyUyuKt9/NMhWx5TNWSSzFqlsvkSOIDT7HExr8tHkzc9Sux3le1GPtr1t9jmZ0+bDssbMdsfTDMfShBIZbJI/aHmddtwO26Q/MJVSIp0ja1msnqcBtlJKTZTdJrT6XbT6XSyeml8weTCYIBBNY5P87PdkPta+/OxZ7B6M8pMn9rNwip/Vc1sBCMXTeJqrbzZbg2wFPDtLnczksIzBAG6HjVafi1afD7/HiddZXYsRbTbB73bgdzuY0pif7U5lc/nZ7kSG4XiaYCKDZeVzu912Ox6nTfOFiySZyZHMZjl7bmvV5sMppVStOnLB5EgsnQ+4J/GCSRHhfS8+ja7hOF96YAdffc1ZNHkd9IWTTNMgW1WLnGUKQdKzhdybvE7mNPpoLsxS1+KnZbcjP7ve4nMxt92PZRnimRzxVJbhWJqReJpUIbfbJoXcbp3tPmnprEUsnQ+wGz3OSg9HKaXqmsdpZ0aLlxktXmKpLIFoioPBBOFkBodtci2Y9DjtfPzq/ELIz967lS++8kxG4hnSWavq1gRpkD0JGGNI5yySGYusZYEBp8NGq9/JfJ8Pvzuf+1yP/6A2W/7TfoPbwdQmD5CfgR2d7Q7E04zEM+Tn7vNBerXN2FebTM4iksqwanYLzV4NsJVSqpxGz+DOafMRSWUZCKfoKyyYdNvt+Nz2ul8wOaPZy0cuX8Ytd2/hW3/aw9svmkc4mTm0hqtaVCTIFpFXAzcDpwPnGWPWHuN2VwJfB+zA940xt5VtkDUsZxlS2VyhjF5eo9vJzBYPLT4XPtfknr31OPOz9K1+F/Pwk7MM8XSWWCrLcDzNSCxDJmuBgMNmw+O04bJP3sdrrGzOIhhPc+bsZlr9rkoPRymlJq2xCyYXTMIFk+fMa+XNz5vHj584wLx2H1MaPRpkF2wGXgH897FuICJ24NvAZUA38JSI3GWM2VqeIdaOdKHiR9ayAHDYhFafizmtPhq8DnxOu+YhH4fdJjR6nDR6nExv9h7KT4+nc4QSaYajGUYSaUw+tRu3Ix+kT7bZ7pxlGEmkWTGzmY5GT6WHo5RSquDIBZPBeIaeYJxArL4XTL7qnNnsGojy038cYGaLh2XTG6sq3qlIkG2M2Qac6NPVecBuY8zewm1/DrwUmNRB9ugsdSpr5cvoAQ0uO9ObC81eXA48Tp11nQgp5Gp7nHba/C4WdORncOOZHLHks7ndWSt/nsBhs9V9a/icZRiOp1gyrZFpzRpgK6VUtXLabUxpdDOlMb9gcjia5mAwzlA0haNQMKBeFkyKCB+49DRu+FWc7/xpDxcvmcKKmc2VHtYh1ZyTPQvoGvN7N3D+sW4sIu8G3g0wd+7c0o6sAkQgEE1htz/bkrzB48SnnRDLwmG30WS30eRxMqMlP9udzFjE01mC8cyh1vCj6u0jTs4YFnU0MLvVV+mhKKWUGieP087MVi8zWw9fMBlKZBCpn/eq975oMTfdvYWvPLiTH7zt3EoP55CSBdki8jAw/ShXfcIY8/vxbOIol5mjXJa/wpg7gDsA1qxZc8zb1SKH3caZs1pwO211nV9VS0QEr8uO12WnvZADNtoaPp21Kjy64rPbhFafLnJUSqlaNXbBZDiZrav3quUzm5nW5GHZjMZKD+UwJQuyjTGXTnAT3cCcMb/PBnomuM2apYvMqt9oa3illFKqWolIXVaGumTZ1EoP4TmqOSJ4CjhNRBaIiAt4HXBXhceklFJKKaXUCVUkyBaRl4tIN3AB8AcReaBw+UwRuRfAGJMF3gs8AGwDfmmM2VKJ8SqllFJKKXUyKlVd5E7gzqNc3gNcPeb3e4F7yzg0pZRSSimlJqya00WUUkoppZSqSRpkK6WUUkopVWQaZCullFJKKVVkGmQrpZRSSilVZBpkK6WUUkopVWQaZCullFJKKVVkGmQrpZRSSilVZGKMqfQYik5EIsCOSo+jyDqAoUoPosjq8T5Bfd4vvU+1ox7vl96n2lGP90vvkzqeecaYKUe7oiLNaMpghzFmTaUHUUwislbvU22ox/ul96l21OP90vtUO+rxful9UqdK00WUUkoppZQqMg2ylVJKKaWUKrJ6DbLvqPQASkDvU+2ox/ul96l21OP90vtUO+rxful9UqekLhc+KqWUUkopVUn1OpOtlFJKKaVUxWiQXWVEJFrpMRSLiOREZP2Yr/nHue2jIlL1K51FxIjIT8b87hCRQRG5p5LjKgYReXnh/i2r9Fgmqp6fJ6iv48SRTnTfauVYAfX1PzVKRD4hIltEZGPhuH5+pcdUDCIyW0R+LyK7RGSPiHxdRFzHuf0HRMRXzjGejMLr7stjfr9BRG6u4JAmJQ2yVSkljDFnjfnaX+kBFUEMWCki3sLvlwEHT2YDIlKtpTNfD/wFeN3J/JGI2EsznAmZ8POkVBGc0v9UtRKRC4BrgdXGmDOBS4Guyo5q4kREgN8CvzPGnAYsARqAzx7nzz4AVG2QDaSAV4hIR6UHMplpkF2FRKRBRB4RkWdEZJOIvLRw+XwR2SYi3yvMJDw4JoioCSJyjog8JiJPi8gDIjJjzNVvEpG/ichmETmvYoM8sfuAawo/vx742egVInJe4T6sK3xfWrj8bSLyKxG5G3iw/EM+PhFpAC4C/olCQCAil4jIn0XkThHZKiL/JSK2wnVREblVRP4BXFC5kR/XqTxPj4vIWWNu91cRObOcgx6vwvNzz5jfvyUibyv8vF9EbhlzDKmpmdTj3bdacZz/qWM9Z1eLyHYR+YuIfKNKz7rMAIaMMSkAY8yQMabnWMf1wlmHr9XAcf3FQNIY80MAY0wO+CDwDhHxi8jthf+jjSLy7yLyPmAm8CcR+VMFx308WfKLGz945BUiMq8QY2wsfJ8rIs2F48boMd4nIl0i4iz3wOuJBtnVKQm83BizGngR8OXCJ22A04BvG2NWAEHglZUZ4rh45dlUkTsL/6zfBF5ljDkH+B8OnynwG2MuBP61cF21+jnwOhHxAGcC/xhz3XbgYmPM2cCngc+Nue4C4K3GmBeXbaTj9zLgfmPMTmBYRFYXLj8P+DBwBrAIeEXhcj+w2RhzvjHmL+Ue7DidyvP0feBtACKyBHAbYzaWbcTFNVQ4hnwXuKHSg5mEXsbR/6eeo/Aa/W/gKmPM84Gjdo+rAg8Cc0Rkp4h8R0ReWCfH9RXA02MvMMaEgU7gncAC4OzC7P1PjTHfAHqAFxljXlTuwZ6EbwNvFJHmIy7/FvDj0fsDfMMYEwI2AC8s3OY64AFjTKZso61DGmRXJwE+JyIbgYeBWcC0wnX7jDHrCz8/Dcwv++jGb2y6yMuBpcBK4CERWQ98Epg95vY/AzDG/BloEpGWMo93XApB13zys6P3HnF1M/ArEdkMfJX8wXvUQ8aY4bIM8uS9nnxQSuH76ws/P2mM2VuY2fkZ8PzC5TngN+Ud4sk5xefpV8C1hcDhHcD/lmWwpfHbwvdqP07Uq2P9Tx3NMmCvMWZf4fefHee2FWOMiQLnAO8GBoFfAO+h9o/rAhyt1JoAFwP/ZYzJAlTxMfw5Ch8Ufgy874irLgD+r/DzT3j2uP4L4LWFn19X+F1NQLXmhk52byQ/k3GOMSYjIvsBT+G61Jjb5YBaShcRYIsx5ljpBUce5Kq5vuRdwO3AJUD7mMs/A/zJGPNyyS/0fHTMdbFyDe5kiEg7+dOlK0XEAHbyj/29HPs5SRYC72p3Us+TMSYuIg8BLwVeA1TzArssh0+UeI64fvRYkaP2jvUnum9V7Tj/U3dx9Psl1IjC//2jwKMisgn4N2r/uL6FI84Ki0gTMAfYS3WOeby+BjwD/PA4txm9f3cBnxeRNvIfpv5Y2qHVP53Jrk7NwEAhwH4RMK/SAyqSHcAUyS+eQUScIjJ2pve1hcufD4QKp6+q1f8AtxpjNh1xeTPPLrB7W1lHdOpeRf7U4TxjzHxjzBxgH/nZjfNEZEEhT++15Bdx1ZJTeZ6+D3wDeKrKZ60OAMtFxF04HfySSg+oiGr9vh3rfwqOfr+2Awvl2QpMr6UKichSETltzEVnAduo/eP6I4BPRN4ChxZzf5n8mawHgX+WwoL1QgAKEAEayz/Uk1M4hv2S/NqAUX/j2cW4b6RwXC+cqXgS+DpwT41MpFQ1DbKrSOGfOEU+R2qNiKwl/w+wvaIDKxJjTJr8m88XRGQDsB64cMxNRkTkb8B/cfgBoeoYY7qNMV8/ylVfJD8T8Ffys1e14PXAnUdc9hvgDcDfgduAzeSDhCNvV9VO5XkyxjwNhDn+zE/FjB4njDFd5N88N5I/Zqyr6MCKoI7u2/H+p55zv4wxCfI5y/eLyF+AfqAag9EG4EeSXwi9EVhOfk1DTR/XTb4r38uBV4vILmAn+bVRHyf/obsT2Fi4f28o/NkdwH1VvPBxrC8DY6uMvA94e+E5fDPw/jHX/QJ4E5oqUhTa8bGKiMgq4HvGmGpdga0mERG5BLjBGHNthYdSViIyk/zp8GXGGKvCw3mOej5O1PN9OxERaTDGRAuL3L8N7DLGfLXS45oIEXmU/DFkbaXHolQl6Ex2lRCRfya/QOSTlR6LUpNV4XTxP4BPVGmAXbfHiXq+b+P0rsLCwS3k05n+u7LDUUpNlM5kK6WUUkopVWQ6k62UUkoppVSRaZCtlFJKKaVUkWmQrZRSSimlVJFpkK2UUnVERIyI/GTM7w4RGRSRe05xey0i8q9jfr/kVLellFKTiQbZSilVX2LkOw2OdoO9jGcb75yKFvI1nJVSSp0EDbKVUqr+3AdcU/j59eRL4wH5jnUi8jsR2SgiT4jImYXLbxaR/xGRR0Vkr4i8r/AntwGLRGS9iHypcFmDiPxaRLaLyE8LtZ2VUkqNoUG2UkrVn58DrxMRD3Am+drfo24B1hljziTf0e7HY65bBlwBnAfcJCJO4EZgjzHmLGPMRwq3Oxv4APmOfwuBi0p4X5RSqiZpkK2UUnXGGLMRmE9+FvveI65+PvCTwu3+CLSLSHPhuj8YY1LGmCFgAJh2jF08WWhZb5Fvoz2/qHdAKaXqgKPSA1BKKVUSdwG3A5cA7WMuP1pqx2hXstSYy3Ic+z1ivLdTSqlJS2eylVKqPv0PcKsxZtMRl/8ZeCPkK4UAQ8aY8HG2EwEaSzFApZSqZzr7oJRSdcgY0w18/ShX3Qz8UEQ2AnHgrSfYTkBE/ioim8kvqPxDsceqlFL1SIwxJ76VUkoppZRSatw0XUQppZRSSqki0yBbKaWUUkqpItMgWymllFJKqSLTIFsppZRSSqki0yBbKaWUUkqpItMgWymllFJKqSLTIFsppZRSSqki0yBbKaWUUkqpIvv/uWenyntG1kEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Bivariate Analysis of 'Time' vs 'Pass/fail'\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.lineplot(data=sdata_final, x=sdata_final['Time'].dt.month, y='Pass/Fail')#, marker='o')\n",
    "plt.xlabel('Month')\n",
    "plt.xticks(range(12), [calendar.month_abbr[i] for i in range(12)])\n",
    "plt.title('Month-wise Production Vs Target')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dfa7e3",
   "metadata": {},
   "source": [
    "- Here we observe that as most of the target feature is represented by '-1' compared to '1', the mean skewed towards -1.\n",
    "- This has been observed previously as well because the manufacturing products passed '-1' are very much higher than the products failed '1'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c754a",
   "metadata": {},
   "source": [
    "Performing Multi-Variate Analysis is not possibe here as we are not sure of what each feature represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddd4fa1",
   "metadata": {},
   "source": [
    "### 4. Data pre-processing: [10 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c8a78",
   "metadata": {},
   "source": [
    "#### 4A. Segregate predictors vs target attributes. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98c6da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating Predictors/Independent Feature\n",
    "x = sdata_final.drop('Pass/Fail', axis=1)\n",
    "x['Time'] = pd.to_numeric(pd.to_datetime(x['Time']))\n",
    "#Seperating Target Feature\n",
    "y = sdata_final['Pass/Fail']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a786ff76",
   "metadata": {},
   "source": [
    "#### 4B. Check for target balancing and fix it if found imbalanced. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96696398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have already established that the target variable is highly imbalanced\n",
    "# Hence we need to balance the target variable\n",
    "# To balance the Target variable we oversample the minority class\n",
    "\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "xros, yros = ros.fit_resample(x, y.ravel())\n",
    "\n",
    "xros = pd.DataFrame(xros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "112da05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2926, 91)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35343400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2926,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yros.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a655e02",
   "metadata": {},
   "source": [
    "#### 4C. Perform train-test split and standardise the data or vice versa if required. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a882aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into train-test data\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(xros, yros, test_size=0.20, random_state=1, stratify=yros)\n",
    "\n",
    "#Standardizing the independnet Feature - x_tr & x_te\n",
    "ss = StandardScaler()\n",
    "x_tr_ss = ss.fit_transform(x_tr)\n",
    "x_te_ss = ss.fit_transform(x_te)\n",
    "\n",
    "x_tr_ss = pd.DataFrame(x_tr_ss, columns = x.columns)\n",
    "x_te_ss = pd.DataFrame(x_te_ss, columns = x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b3ab205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -1 1170]\n",
      " [   1 1170]]\n"
     ]
    }
   ],
   "source": [
    "#Checking the distribution of target classes in training set\n",
    "utr, ctr = np.unique(y_tr, return_counts=True)\n",
    "print(np.asarray((utr, ctr)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a9f78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1 293]\n",
      " [  1 293]]\n"
     ]
    }
   ],
   "source": [
    "#Checking the distribution of target classes in testing set\n",
    "ute, cte = np.unique(y_te, return_counts=True)\n",
    "print(np.asarray((ute, cte)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e45e2",
   "metadata": {},
   "source": [
    "#### 4D. Check if the train and test data have similar statistical characteristics when compared with original data. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ed4a9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of Target Feature class in Original Dataset: \n",
      " -1    0.933631\n",
      " 1    0.066369\n",
      "Name: Pass/Fail, dtype: float64 \n",
      "\n",
      "Ratio of Target Feature class in Training  Dataset after Oversampling:\n",
      "[[-1.   0.5]\n",
      " [ 1.   0.5]] \n",
      "\n",
      "Ratio of Target Feature class in Testing Dataset after Oversampling:\n",
      "[[-1.   0.5]\n",
      " [ 1.   0.5]]\n"
     ]
    }
   ],
   "source": [
    "#Checking the ratio of Target Feature class\n",
    "#Checking the ratio of Target Feature class in original dataset\n",
    "print('Ratio of Target Feature class in Original Dataset: \\n', sdata_final['Pass/Fail'].value_counts(normalize=True), '\\n')\n",
    "\n",
    "#Checking the ratio of Target Feature class in train dataset after oversampling\n",
    "print('Ratio of Target Feature class in Training  Dataset after Oversampling:')\n",
    "utr, ctr = np.unique(y_tr, return_counts=True)\n",
    "print(np.asarray((utr, ctr/len(y_tr))).T, '\\n')\n",
    "\n",
    "#checking the ratio of Target Feature class in test dataset after oversampling\n",
    "print('Ratio of Target Feature class in Testing Dataset after Oversampling:')\n",
    "ute, cte = np.unique(y_te, return_counts=True)\n",
    "print(np.asarray((ute, cte/len(y_te))).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ee7a251",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Characteristic of Original Dataset (excluding the Target Feature):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>33</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>59</th>\n",
       "      <th>...</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>555</th>\n",
       "      <th>561</th>\n",
       "      <th>564</th>\n",
       "      <th>569</th>\n",
       "      <th>572</th>\n",
       "      <th>577</th>\n",
       "      <th>585</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.567000e+03</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.217454e+18</td>\n",
       "      <td>1396.376627</td>\n",
       "      <td>4.197013</td>\n",
       "      <td>-3806.299734</td>\n",
       "      <td>-298.598136</td>\n",
       "      <td>8.960279</td>\n",
       "      <td>67.904909</td>\n",
       "      <td>3.353066</td>\n",
       "      <td>157.420991</td>\n",
       "      <td>2.960241</td>\n",
       "      <td>...</td>\n",
       "      <td>17.013313</td>\n",
       "      <td>1.230712</td>\n",
       "      <td>57.746537</td>\n",
       "      <td>32.284956</td>\n",
       "      <td>6.444985</td>\n",
       "      <td>21.117674</td>\n",
       "      <td>28.450165</td>\n",
       "      <td>16.642363</td>\n",
       "      <td>3.067826</td>\n",
       "      <td>99.670066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.023985e+15</td>\n",
       "      <td>439.712852</td>\n",
       "      <td>56.103066</td>\n",
       "      <td>1379.280537</td>\n",
       "      <td>2900.835956</td>\n",
       "      <td>1.344027</td>\n",
       "      <td>23.877841</td>\n",
       "      <td>2.342268</td>\n",
       "      <td>60.905653</td>\n",
       "      <td>9.510891</td>\n",
       "      <td>...</td>\n",
       "      <td>4.535925</td>\n",
       "      <td>1.243000</td>\n",
       "      <td>32.152263</td>\n",
       "      <td>19.020006</td>\n",
       "      <td>2.393043</td>\n",
       "      <td>9.280454</td>\n",
       "      <td>86.304681</td>\n",
       "      <td>12.485267</td>\n",
       "      <td>3.576891</td>\n",
       "      <td>93.861936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.199758e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>-9986.750000</td>\n",
       "      <td>-14804.500000</td>\n",
       "      <td>7.603200</td>\n",
       "      <td>1.434000</td>\n",
       "      <td>-0.075900</td>\n",
       "      <td>40.261400</td>\n",
       "      <td>-28.988200</td>\n",
       "      <td>...</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>4.826900</td>\n",
       "      <td>7.236900</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>3.250400</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>4.582000</td>\n",
       "      <td>1.197500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.215618e+18</td>\n",
       "      <td>1083.885800</td>\n",
       "      <td>1.017700</td>\n",
       "      <td>-4370.625000</td>\n",
       "      <td>-1474.375000</td>\n",
       "      <td>8.580000</td>\n",
       "      <td>74.240000</td>\n",
       "      <td>2.699000</td>\n",
       "      <td>115.537450</td>\n",
       "      <td>-1.855450</td>\n",
       "      <td>...</td>\n",
       "      <td>14.820000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>34.147100</td>\n",
       "      <td>15.766900</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>15.466200</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>11.501550</td>\n",
       "      <td>2.306500</td>\n",
       "      <td>44.368600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.219497e+18</td>\n",
       "      <td>1287.353800</td>\n",
       "      <td>1.317100</td>\n",
       "      <td>-3819.750000</td>\n",
       "      <td>-80.500000</td>\n",
       "      <td>8.770000</td>\n",
       "      <td>78.270000</td>\n",
       "      <td>3.080000</td>\n",
       "      <td>183.284200</td>\n",
       "      <td>0.973600</td>\n",
       "      <td>...</td>\n",
       "      <td>17.013313</td>\n",
       "      <td>1.230712</td>\n",
       "      <td>57.746537</td>\n",
       "      <td>29.780100</td>\n",
       "      <td>6.290000</td>\n",
       "      <td>20.182400</td>\n",
       "      <td>8.650000</td>\n",
       "      <td>13.817900</td>\n",
       "      <td>2.757700</td>\n",
       "      <td>72.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.222082e+18</td>\n",
       "      <td>1590.169900</td>\n",
       "      <td>1.529600</td>\n",
       "      <td>-3356.375000</td>\n",
       "      <td>1376.250000</td>\n",
       "      <td>9.060600</td>\n",
       "      <td>80.180000</td>\n",
       "      <td>3.515000</td>\n",
       "      <td>206.976700</td>\n",
       "      <td>4.337700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.405000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>69.630650</td>\n",
       "      <td>44.113400</td>\n",
       "      <td>7.310000</td>\n",
       "      <td>23.035200</td>\n",
       "      <td>10.130000</td>\n",
       "      <td>17.080900</td>\n",
       "      <td>3.294950</td>\n",
       "      <td>114.749700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.228935e+18</td>\n",
       "      <td>3715.041700</td>\n",
       "      <td>1114.536600</td>\n",
       "      <td>2363.000000</td>\n",
       "      <td>14106.000000</td>\n",
       "      <td>23.345300</td>\n",
       "      <td>86.120000</td>\n",
       "      <td>37.880000</td>\n",
       "      <td>258.543200</td>\n",
       "      <td>168.145500</td>\n",
       "      <td>...</td>\n",
       "      <td>131.680000</td>\n",
       "      <td>39.330000</td>\n",
       "      <td>303.550000</td>\n",
       "      <td>101.114600</td>\n",
       "      <td>32.580000</td>\n",
       "      <td>84.802400</td>\n",
       "      <td>454.560000</td>\n",
       "      <td>96.960100</td>\n",
       "      <td>99.303200</td>\n",
       "      <td>737.304800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            3            4           23            24  \\\n",
       "count  1.567000e+03  1567.000000  1567.000000  1567.000000   1567.000000   \n",
       "mean   1.217454e+18  1396.376627     4.197013 -3806.299734   -298.598136   \n",
       "std    7.023985e+15   439.712852    56.103066  1379.280537   2900.835956   \n",
       "min    1.199758e+18     0.000000     0.681500 -9986.750000 -14804.500000   \n",
       "25%    1.215618e+18  1083.885800     1.017700 -4370.625000  -1474.375000   \n",
       "50%    1.219497e+18  1287.353800     1.317100 -3819.750000    -80.500000   \n",
       "75%    1.222082e+18  1590.169900     1.529600 -3356.375000   1376.250000   \n",
       "max    1.228935e+18  3715.041700  1114.536600  2363.000000  14106.000000   \n",
       "\n",
       "                33           40           41           51           59  ...  \\\n",
       "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000  ...   \n",
       "mean      8.960279    67.904909     3.353066   157.420991     2.960241  ...   \n",
       "std       1.344027    23.877841     2.342268    60.905653     9.510891  ...   \n",
       "min       7.603200     1.434000    -0.075900    40.261400   -28.988200  ...   \n",
       "25%       8.580000    74.240000     2.699000   115.537450    -1.855450  ...   \n",
       "50%       8.770000    78.270000     3.080000   183.284200     0.973600  ...   \n",
       "75%       9.060600    80.180000     3.515000   206.976700     4.337700  ...   \n",
       "max      23.345300    86.120000    37.880000   258.543200   168.145500  ...   \n",
       "\n",
       "               550          551          555          561          564  \\\n",
       "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000   \n",
       "mean     17.013313     1.230712    57.746537    32.284956     6.444985   \n",
       "std       4.535925     1.243000    32.152263    19.020006     2.393043   \n",
       "min       6.110000     0.120000     4.826900     7.236900     0.970000   \n",
       "25%      14.820000     0.910000    34.147100    15.766900     4.980000   \n",
       "50%      17.013313     1.230712    57.746537    29.780100     6.290000   \n",
       "75%      18.405000     1.330000    69.630650    44.113400     7.310000   \n",
       "max     131.680000    39.330000   303.550000   101.114600    32.580000   \n",
       "\n",
       "               569          572          577          585          589  \n",
       "count  1567.000000  1567.000000  1567.000000  1567.000000  1567.000000  \n",
       "mean     21.117674    28.450165    16.642363     3.067826    99.670066  \n",
       "std       9.280454    86.304681    12.485267     3.576891    93.861936  \n",
       "min       3.250400     3.540000     4.582000     1.197500     0.000000  \n",
       "25%      15.466200     7.500000    11.501550     2.306500    44.368600  \n",
       "50%      20.182400     8.650000    13.817900     2.757700    72.023000  \n",
       "75%      23.035200    10.130000    17.080900     3.294950   114.749700  \n",
       "max      84.802400   454.560000    96.960100    99.303200   737.304800  \n",
       "\n",
       "[8 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Statisctical Characteristic of Training Dataset before Standardizing (excluding the Target Feature):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>33</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>59</th>\n",
       "      <th>...</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>555</th>\n",
       "      <th>561</th>\n",
       "      <th>564</th>\n",
       "      <th>569</th>\n",
       "      <th>572</th>\n",
       "      <th>577</th>\n",
       "      <th>585</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.217150e+18</td>\n",
       "      <td>1368.745619</td>\n",
       "      <td>2.748669</td>\n",
       "      <td>-3777.045981</td>\n",
       "      <td>-394.212752</td>\n",
       "      <td>9.146789</td>\n",
       "      <td>65.178010</td>\n",
       "      <td>3.375547</td>\n",
       "      <td>158.138166</td>\n",
       "      <td>5.607628</td>\n",
       "      <td>...</td>\n",
       "      <td>17.551326</td>\n",
       "      <td>1.393261</td>\n",
       "      <td>58.814662</td>\n",
       "      <td>33.785253</td>\n",
       "      <td>6.519140</td>\n",
       "      <td>21.890089</td>\n",
       "      <td>22.882417</td>\n",
       "      <td>15.532050</td>\n",
       "      <td>3.097789</td>\n",
       "      <td>100.111055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.623119e+15</td>\n",
       "      <td>392.778225</td>\n",
       "      <td>39.790691</td>\n",
       "      <td>1407.803492</td>\n",
       "      <td>2668.587481</td>\n",
       "      <td>1.936190</td>\n",
       "      <td>25.650102</td>\n",
       "      <td>1.765434</td>\n",
       "      <td>62.106974</td>\n",
       "      <td>10.551114</td>\n",
       "      <td>...</td>\n",
       "      <td>6.889095</td>\n",
       "      <td>2.186651</td>\n",
       "      <td>33.779878</td>\n",
       "      <td>20.273109</td>\n",
       "      <td>2.457886</td>\n",
       "      <td>10.215790</td>\n",
       "      <td>72.235866</td>\n",
       "      <td>10.254021</td>\n",
       "      <td>3.041876</td>\n",
       "      <td>86.489219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.199758e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>-9986.750000</td>\n",
       "      <td>-14804.500000</td>\n",
       "      <td>7.603200</td>\n",
       "      <td>1.434000</td>\n",
       "      <td>-0.075900</td>\n",
       "      <td>40.261400</td>\n",
       "      <td>-28.988200</td>\n",
       "      <td>...</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>4.826900</td>\n",
       "      <td>7.236900</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>3.250400</td>\n",
       "      <td>3.540000</td>\n",
       "      <td>4.582000</td>\n",
       "      <td>1.197500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.215517e+18</td>\n",
       "      <td>1070.043900</td>\n",
       "      <td>1.030400</td>\n",
       "      <td>-4373.750000</td>\n",
       "      <td>-1490.812500</td>\n",
       "      <td>8.621100</td>\n",
       "      <td>65.550000</td>\n",
       "      <td>2.666000</td>\n",
       "      <td>113.452300</td>\n",
       "      <td>-0.821800</td>\n",
       "      <td>...</td>\n",
       "      <td>14.612500</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>36.587275</td>\n",
       "      <td>16.721100</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>15.466200</td>\n",
       "      <td>7.470000</td>\n",
       "      <td>11.089225</td>\n",
       "      <td>2.302000</td>\n",
       "      <td>45.426400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.219202e+18</td>\n",
       "      <td>1269.607800</td>\n",
       "      <td>1.309250</td>\n",
       "      <td>-3806.299734</td>\n",
       "      <td>-50.625000</td>\n",
       "      <td>8.804300</td>\n",
       "      <td>77.830000</td>\n",
       "      <td>3.093000</td>\n",
       "      <td>185.757400</td>\n",
       "      <td>2.520900</td>\n",
       "      <td>...</td>\n",
       "      <td>17.013313</td>\n",
       "      <td>1.230712</td>\n",
       "      <td>57.746537</td>\n",
       "      <td>30.148700</td>\n",
       "      <td>6.444985</td>\n",
       "      <td>21.117674</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>13.705000</td>\n",
       "      <td>2.751150</td>\n",
       "      <td>74.058900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.221790e+18</td>\n",
       "      <td>1572.469800</td>\n",
       "      <td>1.510200</td>\n",
       "      <td>-3273.750000</td>\n",
       "      <td>1334.750000</td>\n",
       "      <td>9.163800</td>\n",
       "      <td>79.800000</td>\n",
       "      <td>3.773000</td>\n",
       "      <td>207.369600</td>\n",
       "      <td>10.112725</td>\n",
       "      <td>...</td>\n",
       "      <td>18.862500</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>69.964750</td>\n",
       "      <td>47.296400</td>\n",
       "      <td>7.492500</td>\n",
       "      <td>23.930800</td>\n",
       "      <td>10.195000</td>\n",
       "      <td>16.411100</td>\n",
       "      <td>3.325800</td>\n",
       "      <td>118.771050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.228935e+18</td>\n",
       "      <td>3715.041700</td>\n",
       "      <td>1114.536600</td>\n",
       "      <td>2363.000000</td>\n",
       "      <td>14106.000000</td>\n",
       "      <td>23.345300</td>\n",
       "      <td>85.400000</td>\n",
       "      <td>37.880000</td>\n",
       "      <td>258.543200</td>\n",
       "      <td>168.145500</td>\n",
       "      <td>...</td>\n",
       "      <td>131.680000</td>\n",
       "      <td>39.330000</td>\n",
       "      <td>303.550000</td>\n",
       "      <td>99.037500</td>\n",
       "      <td>32.580000</td>\n",
       "      <td>83.409300</td>\n",
       "      <td>452.540000</td>\n",
       "      <td>96.960100</td>\n",
       "      <td>99.303200</td>\n",
       "      <td>737.304800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            3            4           23            24  \\\n",
       "count  2.340000e+03  2340.000000  2340.000000  2340.000000   2340.000000   \n",
       "mean   1.217150e+18  1368.745619     2.748669 -3777.045981   -394.212752   \n",
       "std    6.623119e+15   392.778225    39.790691  1407.803492   2668.587481   \n",
       "min    1.199758e+18     0.000000     0.681500 -9986.750000 -14804.500000   \n",
       "25%    1.215517e+18  1070.043900     1.030400 -4373.750000  -1490.812500   \n",
       "50%    1.219202e+18  1269.607800     1.309250 -3806.299734    -50.625000   \n",
       "75%    1.221790e+18  1572.469800     1.510200 -3273.750000   1334.750000   \n",
       "max    1.228935e+18  3715.041700  1114.536600  2363.000000  14106.000000   \n",
       "\n",
       "                33           40           41           51           59  ...  \\\n",
       "count  2340.000000  2340.000000  2340.000000  2340.000000  2340.000000  ...   \n",
       "mean      9.146789    65.178010     3.375547   158.138166     5.607628  ...   \n",
       "std       1.936190    25.650102     1.765434    62.106974    10.551114  ...   \n",
       "min       7.603200     1.434000    -0.075900    40.261400   -28.988200  ...   \n",
       "25%       8.621100    65.550000     2.666000   113.452300    -0.821800  ...   \n",
       "50%       8.804300    77.830000     3.093000   185.757400     2.520900  ...   \n",
       "75%       9.163800    79.800000     3.773000   207.369600    10.112725  ...   \n",
       "max      23.345300    85.400000    37.880000   258.543200   168.145500  ...   \n",
       "\n",
       "               550          551          555          561          564  \\\n",
       "count  2340.000000  2340.000000  2340.000000  2340.000000  2340.000000   \n",
       "mean     17.551326     1.393261    58.814662    33.785253     6.519140   \n",
       "std       6.889095     2.186651    33.779878    20.273109     2.457886   \n",
       "min       6.210000     0.160000     4.826900     7.236900     0.970000   \n",
       "25%      14.612500     0.917500    36.587275    16.721100     4.980000   \n",
       "50%      17.013313     1.230712    57.746537    30.148700     6.444985   \n",
       "75%      18.862500     1.340000    69.964750    47.296400     7.492500   \n",
       "max     131.680000    39.330000   303.550000    99.037500    32.580000   \n",
       "\n",
       "               569          572          577          585          589  \n",
       "count  2340.000000  2340.000000  2340.000000  2340.000000  2340.000000  \n",
       "mean     21.890089    22.882417    15.532050     3.097789   100.111055  \n",
       "std      10.215790    72.235866    10.254021     3.041876    86.489219  \n",
       "min       3.250400     3.540000     4.582000     1.197500     0.000000  \n",
       "25%      15.466200     7.470000    11.089225     2.302000    45.426400  \n",
       "50%      21.117674     8.700000    13.705000     2.751150    74.058900  \n",
       "75%      23.930800    10.195000    16.411100     3.325800   118.771050  \n",
       "max      83.409300   452.540000    96.960100    99.303200   737.304800  \n",
       "\n",
       "[8 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Statisctical Characteristic of Testing Dataset before Standardizing (excluding the Target Feature):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>33</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>59</th>\n",
       "      <th>...</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>555</th>\n",
       "      <th>561</th>\n",
       "      <th>564</th>\n",
       "      <th>569</th>\n",
       "      <th>572</th>\n",
       "      <th>577</th>\n",
       "      <th>585</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "      <td>586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.217551e+18</td>\n",
       "      <td>1371.501863</td>\n",
       "      <td>3.228486</td>\n",
       "      <td>-3787.091694</td>\n",
       "      <td>-480.600614</td>\n",
       "      <td>9.059733</td>\n",
       "      <td>67.220639</td>\n",
       "      <td>3.389252</td>\n",
       "      <td>156.764781</td>\n",
       "      <td>4.446864</td>\n",
       "      <td>...</td>\n",
       "      <td>17.358284</td>\n",
       "      <td>1.280792</td>\n",
       "      <td>59.073515</td>\n",
       "      <td>32.370003</td>\n",
       "      <td>6.581379</td>\n",
       "      <td>21.498751</td>\n",
       "      <td>25.037456</td>\n",
       "      <td>15.589691</td>\n",
       "      <td>3.058816</td>\n",
       "      <td>105.475923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.593450e+15</td>\n",
       "      <td>401.041461</td>\n",
       "      <td>45.889861</td>\n",
       "      <td>1421.155295</td>\n",
       "      <td>2580.221558</td>\n",
       "      <td>1.526890</td>\n",
       "      <td>24.106251</td>\n",
       "      <td>2.270125</td>\n",
       "      <td>61.885003</td>\n",
       "      <td>9.571787</td>\n",
       "      <td>...</td>\n",
       "      <td>6.057670</td>\n",
       "      <td>1.781291</td>\n",
       "      <td>28.137236</td>\n",
       "      <td>18.993536</td>\n",
       "      <td>2.268129</td>\n",
       "      <td>9.205903</td>\n",
       "      <td>76.338125</td>\n",
       "      <td>9.812999</td>\n",
       "      <td>1.202196</td>\n",
       "      <td>93.657141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.199772e+18</td>\n",
       "      <td>847.797600</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>-8812.250000</td>\n",
       "      <td>-10366.333000</td>\n",
       "      <td>8.116100</td>\n",
       "      <td>2.126000</td>\n",
       "      <td>0.544100</td>\n",
       "      <td>40.261400</td>\n",
       "      <td>-21.205500</td>\n",
       "      <td>...</td>\n",
       "      <td>6.110000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.385900</td>\n",
       "      <td>7.236900</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>3.290800</td>\n",
       "      <td>4.940000</td>\n",
       "      <td>5.728100</td>\n",
       "      <td>1.471600</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.216508e+18</td>\n",
       "      <td>1084.722100</td>\n",
       "      <td>1.020400</td>\n",
       "      <td>-4438.250000</td>\n",
       "      <td>-1468.312500</td>\n",
       "      <td>8.607400</td>\n",
       "      <td>67.904909</td>\n",
       "      <td>2.634250</td>\n",
       "      <td>113.056500</td>\n",
       "      <td>-1.047750</td>\n",
       "      <td>...</td>\n",
       "      <td>14.530000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>37.714300</td>\n",
       "      <td>16.089100</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>15.466200</td>\n",
       "      <td>7.280000</td>\n",
       "      <td>11.256275</td>\n",
       "      <td>2.303200</td>\n",
       "      <td>45.426400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.219336e+18</td>\n",
       "      <td>1281.786200</td>\n",
       "      <td>1.304800</td>\n",
       "      <td>-3826.125000</td>\n",
       "      <td>-189.375000</td>\n",
       "      <td>8.810500</td>\n",
       "      <td>78.150000</td>\n",
       "      <td>3.093000</td>\n",
       "      <td>180.166350</td>\n",
       "      <td>1.967750</td>\n",
       "      <td>...</td>\n",
       "      <td>17.013313</td>\n",
       "      <td>1.230712</td>\n",
       "      <td>57.746537</td>\n",
       "      <td>29.917350</td>\n",
       "      <td>6.444985</td>\n",
       "      <td>21.117674</td>\n",
       "      <td>8.675000</td>\n",
       "      <td>13.586000</td>\n",
       "      <td>2.798250</td>\n",
       "      <td>78.119900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.221887e+18</td>\n",
       "      <td>1562.549975</td>\n",
       "      <td>1.529600</td>\n",
       "      <td>-3309.333300</td>\n",
       "      <td>759.000000</td>\n",
       "      <td>9.158500</td>\n",
       "      <td>79.860000</td>\n",
       "      <td>3.673000</td>\n",
       "      <td>206.719525</td>\n",
       "      <td>8.415650</td>\n",
       "      <td>...</td>\n",
       "      <td>18.557500</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>74.591200</td>\n",
       "      <td>44.874500</td>\n",
       "      <td>7.485000</td>\n",
       "      <td>24.055350</td>\n",
       "      <td>10.165000</td>\n",
       "      <td>16.679450</td>\n",
       "      <td>3.436750</td>\n",
       "      <td>128.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.228879e+18</td>\n",
       "      <td>3619.739700</td>\n",
       "      <td>1112.160000</td>\n",
       "      <td>1614.750000</td>\n",
       "      <td>10126.666700</td>\n",
       "      <td>23.345300</td>\n",
       "      <td>86.120000</td>\n",
       "      <td>37.880000</td>\n",
       "      <td>248.948600</td>\n",
       "      <td>87.039100</td>\n",
       "      <td>...</td>\n",
       "      <td>90.700000</td>\n",
       "      <td>25.470000</td>\n",
       "      <td>213.696600</td>\n",
       "      <td>101.114600</td>\n",
       "      <td>15.040000</td>\n",
       "      <td>84.802400</td>\n",
       "      <td>454.560000</td>\n",
       "      <td>96.960100</td>\n",
       "      <td>9.167700</td>\n",
       "      <td>579.181700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            3            4           23            24  \\\n",
       "count  5.860000e+02   586.000000   586.000000   586.000000    586.000000   \n",
       "mean   1.217551e+18  1371.501863     3.228486 -3787.091694   -480.600614   \n",
       "std    6.593450e+15   401.041461    45.889861  1421.155295   2580.221558   \n",
       "min    1.199772e+18   847.797600     0.681500 -8812.250000 -10366.333000   \n",
       "25%    1.216508e+18  1084.722100     1.020400 -4438.250000  -1468.312500   \n",
       "50%    1.219336e+18  1281.786200     1.304800 -3826.125000   -189.375000   \n",
       "75%    1.221887e+18  1562.549975     1.529600 -3309.333300    759.000000   \n",
       "max    1.228879e+18  3619.739700  1112.160000  1614.750000  10126.666700   \n",
       "\n",
       "               33          40          41          51          59  ...  \\\n",
       "count  586.000000  586.000000  586.000000  586.000000  586.000000  ...   \n",
       "mean     9.059733   67.220639    3.389252  156.764781    4.446864  ...   \n",
       "std      1.526890   24.106251    2.270125   61.885003    9.571787  ...   \n",
       "min      8.116100    2.126000    0.544100   40.261400  -21.205500  ...   \n",
       "25%      8.607400   67.904909    2.634250  113.056500   -1.047750  ...   \n",
       "50%      8.810500   78.150000    3.093000  180.166350    1.967750  ...   \n",
       "75%      9.158500   79.860000    3.673000  206.719525    8.415650  ...   \n",
       "max     23.345300   86.120000   37.880000  248.948600   87.039100  ...   \n",
       "\n",
       "              550         551         555         561         564         569  \\\n",
       "count  586.000000  586.000000  586.000000  586.000000  586.000000  586.000000   \n",
       "mean    17.358284    1.280792   59.073515   32.370003    6.581379   21.498751   \n",
       "std      6.057670    1.781291   28.137236   18.993536    2.268129    9.205903   \n",
       "min      6.110000    0.120000    5.385900    7.236900    1.100000    3.290800   \n",
       "25%     14.530000    0.890000   37.714300   16.089100    4.980000   15.466200   \n",
       "50%     17.013313    1.230712   57.746537   29.917350    6.444985   21.117674   \n",
       "75%     18.557500    1.330000   74.591200   44.874500    7.485000   24.055350   \n",
       "max     90.700000   25.470000  213.696600  101.114600   15.040000   84.802400   \n",
       "\n",
       "              572         577         585         589  \n",
       "count  586.000000  586.000000  586.000000  586.000000  \n",
       "mean    25.037456   15.589691    3.058816  105.475923  \n",
       "std     76.338125    9.812999    1.202196   93.657141  \n",
       "min      4.940000    5.728100    1.471600    0.000000  \n",
       "25%      7.280000   11.256275    2.303200   45.426400  \n",
       "50%      8.675000   13.586000    2.798250   78.119900  \n",
       "75%     10.165000   16.679450    3.436750  128.281900  \n",
       "max    454.560000   96.960100    9.167700  579.181700  \n",
       "\n",
       "[8 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Statisctical Characteristic of Training Dataset after Standardizing (excluding the Target Feature):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>33</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>59</th>\n",
       "      <th>...</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>555</th>\n",
       "      <th>561</th>\n",
       "      <th>564</th>\n",
       "      <th>569</th>\n",
       "      <th>572</th>\n",
       "      <th>577</th>\n",
       "      <th>585</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "      <td>2.340000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.090796e-14</td>\n",
       "      <td>1.800554e-16</td>\n",
       "      <td>-6.345530e-17</td>\n",
       "      <td>-6.725389e-17</td>\n",
       "      <td>-3.373370e-17</td>\n",
       "      <td>-5.069070e-16</td>\n",
       "      <td>-3.263534e-16</td>\n",
       "      <td>3.053113e-17</td>\n",
       "      <td>-2.149278e-16</td>\n",
       "      <td>-1.247815e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.920122e-16</td>\n",
       "      <td>5.423012e-17</td>\n",
       "      <td>-3.534803e-16</td>\n",
       "      <td>1.626904e-16</td>\n",
       "      <td>1.466538e-16</td>\n",
       "      <td>-4.451123e-17</td>\n",
       "      <td>-8.421564e-18</td>\n",
       "      <td>1.143909e-16</td>\n",
       "      <td>4.939069e-17</td>\n",
       "      <td>-6.500024e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "      <td>1.000214e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.626517e+00</td>\n",
       "      <td>-3.485525e+00</td>\n",
       "      <td>-5.196216e-02</td>\n",
       "      <td>-4.411860e+00</td>\n",
       "      <td>-5.401122e+00</td>\n",
       "      <td>-7.974005e-01</td>\n",
       "      <td>-2.485668e+00</td>\n",
       "      <td>-1.955431e+00</td>\n",
       "      <td>-1.898369e+00</td>\n",
       "      <td>-3.279580e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.646624e+00</td>\n",
       "      <td>-5.641160e-01</td>\n",
       "      <td>-1.598564e+00</td>\n",
       "      <td>-1.309815e+00</td>\n",
       "      <td>-2.258170e+00</td>\n",
       "      <td>-1.824986e+00</td>\n",
       "      <td>-2.678247e-01</td>\n",
       "      <td>-1.068107e+00</td>\n",
       "      <td>-6.248431e-01</td>\n",
       "      <td>-1.157745e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.465438e-01</td>\n",
       "      <td>-7.606470e-01</td>\n",
       "      <td>-4.319191e-02</td>\n",
       "      <td>-4.239452e-01</td>\n",
       "      <td>-4.110167e-01</td>\n",
       "      <td>-2.715649e-01</td>\n",
       "      <td>1.450556e-02</td>\n",
       "      <td>-4.019969e-01</td>\n",
       "      <td>-7.196522e-01</td>\n",
       "      <td>-6.094904e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.266821e-01</td>\n",
       "      <td>-2.176218e-01</td>\n",
       "      <td>-6.581474e-01</td>\n",
       "      <td>-8.418936e-01</td>\n",
       "      <td>-6.263386e-01</td>\n",
       "      <td>-6.289541e-01</td>\n",
       "      <td>-2.134080e-01</td>\n",
       "      <td>-4.333690e-01</td>\n",
       "      <td>-2.616672e-01</td>\n",
       "      <td>-6.324065e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.099172e-01</td>\n",
       "      <td>-2.524555e-01</td>\n",
       "      <td>-3.618249e-02</td>\n",
       "      <td>-2.078415e-02</td>\n",
       "      <td>1.287802e-01</td>\n",
       "      <td>-1.769259e-01</td>\n",
       "      <td>4.933584e-01</td>\n",
       "      <td>-1.600784e-01</td>\n",
       "      <td>4.447993e-01</td>\n",
       "      <td>-2.926125e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.811299e-02</td>\n",
       "      <td>-7.435314e-02</td>\n",
       "      <td>-3.162692e-02</td>\n",
       "      <td>-1.794165e-01</td>\n",
       "      <td>-3.017689e-02</td>\n",
       "      <td>-7.562611e-02</td>\n",
       "      <td>-1.963768e-01</td>\n",
       "      <td>-1.782170e-01</td>\n",
       "      <td>-1.139800e-01</td>\n",
       "      <td>-3.012829e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.007841e-01</td>\n",
       "      <td>5.187857e-01</td>\n",
       "      <td>-3.113123e-02</td>\n",
       "      <td>3.575808e-01</td>\n",
       "      <td>6.480328e-01</td>\n",
       "      <td>8.787707e-03</td>\n",
       "      <td>5.701777e-01</td>\n",
       "      <td>2.251783e-01</td>\n",
       "      <td>7.928571e-01</td>\n",
       "      <td>4.270696e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.903667e-01</td>\n",
       "      <td>-2.436262e-02</td>\n",
       "      <td>3.301513e-01</td>\n",
       "      <td>6.665990e-01</td>\n",
       "      <td>3.960997e-01</td>\n",
       "      <td>1.998031e-01</td>\n",
       "      <td>-1.756763e-01</td>\n",
       "      <td>8.574562e-02</td>\n",
       "      <td>7.497338e-02</td>\n",
       "      <td>2.157955e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.779765e+00</td>\n",
       "      <td>5.974867e+00</td>\n",
       "      <td>2.794688e+01</td>\n",
       "      <td>4.362369e+00</td>\n",
       "      <td>5.434827e+00</td>\n",
       "      <td>7.334789e+00</td>\n",
       "      <td>7.885470e-01</td>\n",
       "      <td>1.954863e+01</td>\n",
       "      <td>1.616992e+00</td>\n",
       "      <td>1.540810e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.657011e+01</td>\n",
       "      <td>1.735295e+01</td>\n",
       "      <td>7.246552e+00</td>\n",
       "      <td>3.219348e+00</td>\n",
       "      <td>1.060522e+01</td>\n",
       "      <td>6.023260e+00</td>\n",
       "      <td>5.949253e+00</td>\n",
       "      <td>7.942782e+00</td>\n",
       "      <td>3.163376e+01</td>\n",
       "      <td>7.368895e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time             3             4            23            24  \\\n",
       "count  2.340000e+03  2.340000e+03  2.340000e+03  2.340000e+03  2.340000e+03   \n",
       "mean  -1.090796e-14  1.800554e-16 -6.345530e-17 -6.725389e-17 -3.373370e-17   \n",
       "std    1.000214e+00  1.000214e+00  1.000214e+00  1.000214e+00  1.000214e+00   \n",
       "min   -2.626517e+00 -3.485525e+00 -5.196216e-02 -4.411860e+00 -5.401122e+00   \n",
       "25%   -2.465438e-01 -7.606470e-01 -4.319191e-02 -4.239452e-01 -4.110167e-01   \n",
       "50%    3.099172e-01 -2.524555e-01 -3.618249e-02 -2.078415e-02  1.287802e-01   \n",
       "75%    7.007841e-01  5.187857e-01 -3.113123e-02  3.575808e-01  6.480328e-01   \n",
       "max    1.779765e+00  5.974867e+00  2.794688e+01  4.362369e+00  5.434827e+00   \n",
       "\n",
       "                 33            40            41            51            59  \\\n",
       "count  2.340000e+03  2.340000e+03  2.340000e+03  2.340000e+03  2.340000e+03   \n",
       "mean  -5.069070e-16 -3.263534e-16  3.053113e-17 -2.149278e-16 -1.247815e-17   \n",
       "std    1.000214e+00  1.000214e+00  1.000214e+00  1.000214e+00  1.000214e+00   \n",
       "min   -7.974005e-01 -2.485668e+00 -1.955431e+00 -1.898369e+00 -3.279580e+00   \n",
       "25%   -2.715649e-01  1.450556e-02 -4.019969e-01 -7.196522e-01 -6.094904e-01   \n",
       "50%   -1.769259e-01  4.933584e-01 -1.600784e-01  4.447993e-01 -2.926125e-01   \n",
       "75%    8.787707e-03  5.701777e-01  2.251783e-01  7.928571e-01  4.270696e-01   \n",
       "max    7.334789e+00  7.885470e-01  1.954863e+01  1.616992e+00  1.540810e+01   \n",
       "\n",
       "       ...           550           551           555           561  \\\n",
       "count  ...  2.340000e+03  2.340000e+03  2.340000e+03  2.340000e+03   \n",
       "mean   ... -5.920122e-16  5.423012e-17 -3.534803e-16  1.626904e-16   \n",
       "std    ...  1.000214e+00  1.000214e+00  1.000214e+00  1.000214e+00   \n",
       "min    ... -1.646624e+00 -5.641160e-01 -1.598564e+00 -1.309815e+00   \n",
       "25%    ... -4.266821e-01 -2.176218e-01 -6.581474e-01 -8.418936e-01   \n",
       "50%    ... -7.811299e-02 -7.435314e-02 -3.162692e-02 -1.794165e-01   \n",
       "75%    ...  1.903667e-01 -2.436262e-02  3.301513e-01  6.665990e-01   \n",
       "max    ...  1.657011e+01  1.735295e+01  7.246552e+00  3.219348e+00   \n",
       "\n",
       "                564           569           572           577           585  \\\n",
       "count  2.340000e+03  2.340000e+03  2.340000e+03  2.340000e+03  2.340000e+03   \n",
       "mean   1.466538e-16 -4.451123e-17 -8.421564e-18  1.143909e-16  4.939069e-17   \n",
       "std    1.000214e+00  1.000214e+00  1.000214e+00  1.000214e+00  1.000214e+00   \n",
       "min   -2.258170e+00 -1.824986e+00 -2.678247e-01 -1.068107e+00 -6.248431e-01   \n",
       "25%   -6.263386e-01 -6.289541e-01 -2.134080e-01 -4.333690e-01 -2.616672e-01   \n",
       "50%   -3.017689e-02 -7.562611e-02 -1.963768e-01 -1.782170e-01 -1.139800e-01   \n",
       "75%    3.960997e-01  1.998031e-01 -1.756763e-01  8.574562e-02  7.497338e-02   \n",
       "max    1.060522e+01  6.023260e+00  5.949253e+00  7.942782e+00  3.163376e+01   \n",
       "\n",
       "                589  \n",
       "count  2.340000e+03  \n",
       "mean  -6.500024e-18  \n",
       "std    1.000214e+00  \n",
       "min   -1.157745e+00  \n",
       "25%   -6.324065e-01  \n",
       "50%   -3.012829e-01  \n",
       "75%    2.157955e-01  \n",
       "max    7.368895e+00  \n",
       "\n",
       "[8 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Statisctical Characteristic of Testing Dataset after Standardizing (excluding the Target Feature):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>33</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>59</th>\n",
       "      <th>...</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>555</th>\n",
       "      <th>561</th>\n",
       "      <th>564</th>\n",
       "      <th>569</th>\n",
       "      <th>572</th>\n",
       "      <th>577</th>\n",
       "      <th>585</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "      <td>5.860000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.683655e-14</td>\n",
       "      <td>1.500506e-16</td>\n",
       "      <td>-1.353440e-17</td>\n",
       "      <td>6.152644e-17</td>\n",
       "      <td>-2.245076e-17</td>\n",
       "      <td>-3.751266e-17</td>\n",
       "      <td>3.376139e-16</td>\n",
       "      <td>5.162727e-17</td>\n",
       "      <td>1.060964e-17</td>\n",
       "      <td>-3.613909e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.601387e-17</td>\n",
       "      <td>-1.202465e-16</td>\n",
       "      <td>-2.978277e-16</td>\n",
       "      <td>5.418495e-17</td>\n",
       "      <td>-3.997561e-17</td>\n",
       "      <td>-1.940048e-16</td>\n",
       "      <td>3.130791e-17</td>\n",
       "      <td>-1.278841e-17</td>\n",
       "      <td>3.992824e-17</td>\n",
       "      <td>6.081597e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "      <td>1.000854e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.698870e+00</td>\n",
       "      <td>-1.306976e+00</td>\n",
       "      <td>-5.554956e-02</td>\n",
       "      <td>-3.538988e+00</td>\n",
       "      <td>-3.834623e+00</td>\n",
       "      <td>-6.185382e-01</td>\n",
       "      <td>-2.702629e+00</td>\n",
       "      <td>-1.254373e+00</td>\n",
       "      <td>-1.884187e+00</td>\n",
       "      <td>-2.682287e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.858453e+00</td>\n",
       "      <td>-6.522143e-01</td>\n",
       "      <td>-1.909693e+00</td>\n",
       "      <td>-1.324376e+00</td>\n",
       "      <td>-2.418761e+00</td>\n",
       "      <td>-1.979546e+00</td>\n",
       "      <td>-2.634939e-01</td>\n",
       "      <td>-1.005810e+00</td>\n",
       "      <td>-1.321392e+00</td>\n",
       "      <td>-1.127154e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.583646e-01</td>\n",
       "      <td>-7.156985e-01</td>\n",
       "      <td>-4.815818e-02</td>\n",
       "      <td>-4.585809e-01</td>\n",
       "      <td>-3.831282e-01</td>\n",
       "      <td>-2.964981e-01</td>\n",
       "      <td>2.840984e-02</td>\n",
       "      <td>-3.328658e-01</td>\n",
       "      <td>-7.068857e-01</td>\n",
       "      <td>-5.745331e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.672920e-01</td>\n",
       "      <td>-2.195743e-01</td>\n",
       "      <td>-7.597570e-01</td>\n",
       "      <td>-8.579136e-01</td>\n",
       "      <td>-7.066384e-01</td>\n",
       "      <td>-6.558514e-01</td>\n",
       "      <td>-2.328146e-01</td>\n",
       "      <td>-4.419769e-01</td>\n",
       "      <td>-6.290666e-01</td>\n",
       "      <td>-6.417111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.709321e-01</td>\n",
       "      <td>-2.238978e-01</td>\n",
       "      <td>-4.195544e-02</td>\n",
       "      <td>-2.748936e-02</td>\n",
       "      <td>1.129649e-01</td>\n",
       "      <td>-1.633690e-01</td>\n",
       "      <td>4.537702e-01</td>\n",
       "      <td>-1.306118e-01</td>\n",
       "      <td>3.784691e-01</td>\n",
       "      <td>-2.592235e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.699650e-02</td>\n",
       "      <td>-2.813861e-02</td>\n",
       "      <td>-4.720119e-02</td>\n",
       "      <td>-1.292413e-01</td>\n",
       "      <td>-6.018659e-02</td>\n",
       "      <td>-4.143017e-02</td>\n",
       "      <td>-2.145250e-01</td>\n",
       "      <td>-2.043619e-01</td>\n",
       "      <td>-2.169266e-01</td>\n",
       "      <td>-2.923364e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.581283e-01</td>\n",
       "      <td>4.767869e-01</td>\n",
       "      <td>-3.705257e-02</td>\n",
       "      <td>3.364633e-01</td>\n",
       "      <td>4.808345e-01</td>\n",
       "      <td>6.474006e-02</td>\n",
       "      <td>5.247668e-01</td>\n",
       "      <td>1.250991e-01</td>\n",
       "      <td>8.079085e-01</td>\n",
       "      <td>4.149880e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.981356e-01</td>\n",
       "      <td>2.764862e-02</td>\n",
       "      <td>5.519712e-01</td>\n",
       "      <td>6.589178e-01</td>\n",
       "      <td>3.987396e-01</td>\n",
       "      <td>2.779503e-01</td>\n",
       "      <td>-1.949899e-01</td>\n",
       "      <td>1.111474e-01</td>\n",
       "      <td>3.146385e-01</td>\n",
       "      <td>2.437130e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.719546e+00</td>\n",
       "      <td>5.610788e+00</td>\n",
       "      <td>2.418571e+01</td>\n",
       "      <td>3.804269e+00</td>\n",
       "      <td>4.114503e+00</td>\n",
       "      <td>9.363984e+00</td>\n",
       "      <td>7.846723e-01</td>\n",
       "      <td>1.520631e+01</td>\n",
       "      <td>1.490871e+00</td>\n",
       "      <td>8.636088e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211759e+01</td>\n",
       "      <td>1.359120e+01</td>\n",
       "      <td>5.500014e+00</td>\n",
       "      <td>3.622460e+00</td>\n",
       "      <td>3.732524e+00</td>\n",
       "      <td>6.882294e+00</td>\n",
       "      <td>5.631387e+00</td>\n",
       "      <td>8.299188e+00</td>\n",
       "      <td>5.085779e+00</td>\n",
       "      <td>5.062193e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time             3             4            23            24  \\\n",
       "count  5.860000e+02  5.860000e+02  5.860000e+02  5.860000e+02  5.860000e+02   \n",
       "mean  -1.683655e-14  1.500506e-16 -1.353440e-17  6.152644e-17 -2.245076e-17   \n",
       "std    1.000854e+00  1.000854e+00  1.000854e+00  1.000854e+00  1.000854e+00   \n",
       "min   -2.698870e+00 -1.306976e+00 -5.554956e-02 -3.538988e+00 -3.834623e+00   \n",
       "25%   -1.583646e-01 -7.156985e-01 -4.815818e-02 -4.585809e-01 -3.831282e-01   \n",
       "50%    2.709321e-01 -2.238978e-01 -4.195544e-02 -2.748936e-02  1.129649e-01   \n",
       "75%    6.581283e-01  4.767869e-01 -3.705257e-02  3.364633e-01  4.808345e-01   \n",
       "max    1.719546e+00  5.610788e+00  2.418571e+01  3.804269e+00  4.114503e+00   \n",
       "\n",
       "                 33            40            41            51            59  \\\n",
       "count  5.860000e+02  5.860000e+02  5.860000e+02  5.860000e+02  5.860000e+02   \n",
       "mean  -3.751266e-17  3.376139e-16  5.162727e-17  1.060964e-17 -3.613909e-17   \n",
       "std    1.000854e+00  1.000854e+00  1.000854e+00  1.000854e+00  1.000854e+00   \n",
       "min   -6.185382e-01 -2.702629e+00 -1.254373e+00 -1.884187e+00 -2.682287e+00   \n",
       "25%   -2.964981e-01  2.840984e-02 -3.328658e-01 -7.068857e-01 -5.745331e-01   \n",
       "50%   -1.633690e-01  4.537702e-01 -1.306118e-01  3.784691e-01 -2.592235e-01   \n",
       "75%    6.474006e-02  5.247668e-01  1.250991e-01  8.079085e-01  4.149880e-01   \n",
       "max    9.363984e+00  7.846723e-01  1.520631e+01  1.490871e+00  8.636088e+00   \n",
       "\n",
       "       ...           550           551           555           561  \\\n",
       "count  ...  5.860000e+02  5.860000e+02  5.860000e+02  5.860000e+02   \n",
       "mean   ... -8.601387e-17 -1.202465e-16 -2.978277e-16  5.418495e-17   \n",
       "std    ...  1.000854e+00  1.000854e+00  1.000854e+00  1.000854e+00   \n",
       "min    ... -1.858453e+00 -6.522143e-01 -1.909693e+00 -1.324376e+00   \n",
       "25%    ... -4.672920e-01 -2.195743e-01 -7.597570e-01 -8.579136e-01   \n",
       "50%    ... -5.699650e-02 -2.813861e-02 -4.720119e-02 -1.292413e-01   \n",
       "75%    ...  1.981356e-01  2.764862e-02  5.519712e-01  6.589178e-01   \n",
       "max    ...  1.211759e+01  1.359120e+01  5.500014e+00  3.622460e+00   \n",
       "\n",
       "                564           569           572           577           585  \\\n",
       "count  5.860000e+02  5.860000e+02  5.860000e+02  5.860000e+02  5.860000e+02   \n",
       "mean  -3.997561e-17 -1.940048e-16  3.130791e-17 -1.278841e-17  3.992824e-17   \n",
       "std    1.000854e+00  1.000854e+00  1.000854e+00  1.000854e+00  1.000854e+00   \n",
       "min   -2.418761e+00 -1.979546e+00 -2.634939e-01 -1.005810e+00 -1.321392e+00   \n",
       "25%   -7.066384e-01 -6.558514e-01 -2.328146e-01 -4.419769e-01 -6.290666e-01   \n",
       "50%   -6.018659e-02 -4.143017e-02 -2.145250e-01 -2.043619e-01 -2.169266e-01   \n",
       "75%    3.987396e-01  2.779503e-01 -1.949899e-01  1.111474e-01  3.146385e-01   \n",
       "max    3.732524e+00  6.882294e+00  5.631387e+00  8.299188e+00  5.085779e+00   \n",
       "\n",
       "                589  \n",
       "count  5.860000e+02  \n",
       "mean   6.081597e-17  \n",
       "std    1.000854e+00  \n",
       "min   -1.127154e+00  \n",
       "25%   -6.417111e-01  \n",
       "50%   -2.923364e-01  \n",
       "75%    2.437130e-01  \n",
       "max    5.062193e+00  \n",
       "\n",
       "[8 rows x 91 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Checking the statistical characteristic of DataSet\n",
    "#Original Dataset\n",
    "print('Statistical Characteristic of Original Dataset (excluding the Target Feature):')\n",
    "display(x.describe())\n",
    "print('\\n')\n",
    "\n",
    "#Training Dataset Before Standardizing\n",
    "print('Statisctical Characteristic of Training Dataset before Standardizing (excluding the Target Feature):')\n",
    "display(x_tr.describe())\n",
    "print('\\n')\n",
    "\n",
    "#Testing Dataset Before Standardizing\n",
    "print('Statisctical Characteristic of Testing Dataset before Standardizing (excluding the Target Feature):')\n",
    "display(x_te.describe())\n",
    "print('\\n')\n",
    "\n",
    "#Training Dataset After Standardizing\n",
    "print('Statisctical Characteristic of Training Dataset after Standardizing (excluding the Target Feature):')\n",
    "display(x_tr_ss.describe())\n",
    "print('\\n')\n",
    "\n",
    "#Testing Dataset After Standardizing\n",
    "print('Statisctical Characteristic of Testing Dataset after Standardizing (excluding the Target Feature):')\n",
    "display(x_te_ss.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70e7121",
   "metadata": {},
   "source": [
    "- Here we observe that initially in the original dataset (after cleaning), the ratio of Target Class Pass was 93.36% while that of Fail Class was 6.64%.\n",
    "- Then after Oversampling of the dataset & then splitting it into train and test set with stratification of y, we have the ratio of Pass class & Fail class as 50% each in train & test data set.\n",
    "- Moreover the Original Dataset contained a total of 1567 of data point which were bifurcated as 1463 as '-1 - Pass' and 104 as '1 - Fail'.\n",
    "- After Oversampling the total Data point have been increased to 2926 which are then bifurcated to 1463 as '-1 - Pass' as well as '1 - Fail' i.e. the points are distributed 50-50 for both the class.\n",
    "- Further when we splitted the dataset into training & test data, we strartified y, hence the distribution of each class is maintained same in training & test set.\n",
    "- We here initially split the dataset into train & test set & then we performed Standardization on both the sets. By doing this we have not let the train data get affected from test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569666a8",
   "metadata": {},
   "source": [
    "### 5. Model training, testing and tuning: [20 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9309b22b",
   "metadata": {},
   "source": [
    "#### 5A. Use any Supervised Learning technique to train a model. [2 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c58fc7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As the Target is Classification Feature, We proceed to train a Logistic Regression Model.\n",
    "#Training the Logistic Regression Model with Training Dataset\n",
    "logi = LogisticRegression()\n",
    "logi_fit = logi.fit(x_tr_ss, y_tr)\n",
    "logi_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d3b6e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score/Accuracy of the Logistic Regression Model on Test Data is: 0.7218430034129693 \n",
      "\n",
      "The Confusion Matrix of the Logistic Regression Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEXCAYAAACNj66GAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqM0lEQVR4nO3debxd4/3+/9eVQRKJIQhNJEhIEGpozVOT0ppC9FM0qMbUUH7UVPNQJa2Wn9IqGsTQajSteagpRWgRpDQSVAgRQkJEIkhyznl//1jryHbsvc86yR7OPrmeeaxH9r7XWvd9r5Od97n3ve77XooIzMysdrSrdgXMzKxlHLjNzGqMA7eZWY1x4DYzqzEO3GZmNcaB28ysxjhwt0GSrpF07lKct46kTyS1L0e9WitJ/5A0vNr1yErSm5J2y3DcepJCUodK1Msqx4G7yrL+J2yJiDgmIi5sadkRMT0iukVEfUvKk3SYpPo06M+T9KKkIUtT92qIiD0j4qZS5yvpxjRw7tsk/fI0/bBSl2nLBwduK5WnIqIbsCpwFXCrpFVLXUgNfhv4H/BFaz5t/R4AvF61GlnNc+BupSR1Sltm76bb5ZI65ew/TdLMdN9RaQtug3TfjZIuSl+vIeleSXMlzZH0hKR2kv4ErAPck7aUT2v61VrSapJuSMv4SNKdzdU7IhqAPwFdgf4513KppOmS3k+7crq04FqulnS/pAXAYEm9JN0mabakaZJOyMlrG0nPpS3/9yVdlqZ3lvRnSR+mP4tnJa2V7ntM0lHp63aSzpH0lqRZkm6WtEq6r/HnMzy9lg8knd3Mj+QeYEdJ3dP3ewD/Bd7LqXPBMtP9h6b7PmxaXnruGZJeT/ePlbRac/9OVtscuFuvs4HtgC2AzYFtgHMAJO0BnAzsBmwAfKtIPqcAM4AewFrAWUBExKHAdGCftHvkN3nO/ROwIrAJsCbw2+YqnbaIDwcWA2+lyb8GBqTXsgGwNnBeC67lYGAksBLwb5Jg+GKaz67AiZJ2T4+9ArgiIlYG1gfGpunDgVWAPsDqwDHAZ3nKOizdBgP9gG7AlU2O2QnYMC37PEkbF/mRfA7cDQxL3/8IuDlrmZIGAlcDhwK90rr3zjn3BGA/kp9bL+Aj4A9F6mNtQUR4q+IGvAnslif9dWCvnPe7A2+mr0cDv8rZtwEQwAbp+xuBi9LXvwDuatxXrGxgvTSfDkBPoAHonuEaDgPqgLkkAfsz4MB0n4AFwPo5x28PTGvBtdycs39bYHqT8s8EbkhfjwcuANZocswRJEF/szz1fww4Kn09Djg2Z9+G6TV1yPn59M7ZPwEYVuDnciNwEUmgf4rkF8f7QBfgSeCwDGWeB9yas68rsKjx3w14Gdg1Z3/PPPXtUO3PubfSbm5xt169WNJiJX3dK2ff2zn7cl83dQkwFXhI0huSzshYfh9gTkR8lPH4pyNiVaA7SQtz5zS9B0mr/fm0i2Iu8ECaDtmuJTdtXaBXY15pfmeRfJsAOJKkdf9K2h3SeJP0T8CDJH3v70r6jaSOecrK93PvkJM/5HRzAJ+StJALiognSa73HODeiGja0i9W5pd+PhGxAPgw59h1gTtyfhYvA/VN6mttjAN36/UuyX/KRuukaQAz+fLX5T6FMomI+RFxSkT0A/YBTpa0a+PuIuW/DazW0huMEfEJcCxwqKQtgQ9IWuCbRMSq6bZKJDcys15Lbj3fJmmtr5qzrRQRe6XlvxYRB5F07fwa+LukrhGxOCIuiIiBwA7AEJJui6by/dzrSFrKy+LPJN1WTbtJmitzJjk/E0krknSXNHob2LPJz6NzRLyzjPW1VsyBu3XomN48a9w6AGOAcyT1kLQGyVfmP6fHjwUOl7Rx+h/5vEIZSxoiaQNJAuaRtMYah/u9T9Kn+hURMRP4B3CVpO6SOkraJcvFRMSHwHXAeZHcrLwW+K2kNdM6rZ3TJ535WlITgHmSTpfURVJ7SZtK2jrN+4eSeqTlzk3PqZc0WNLX0z74eSTdCfmGPY4BTpLUV1I34JfAXyOiLsu1F/E74DskXTktKfPvwBBJO0lagaTrK/f/7TXASEnrAqSfl6HLWFdr5Ry4W4f7SVqljdvPSfpGnyMZgTAJmJimERH/IAkEj5J0gzyV5rMwT979gUeAT9LjroqIx9J9vyL55TBX0ql5zj2UJMC9AswCTmzBNV0O7CVpM+D0tJ5PS5qX1mfDpbgWIhljvg/Jjc5pJC3660j6jyEZtTFZ0ickNyqHRcTnwNdIguA8ku6Ex1nyizDXaJJulfFp/p8Dx7fguvOKiDkRMS4i8n3LKVhmREwGjgP+QtL6/ojkZnOjK0i6ph6SNB94muQ+gLVhyv85slqSjmp4CehUgpZhVbWlazErF7e4a5Sk70laIR0f/GvgnloNdG3pWswqwYG7dh0NzCYZNlgP/KS61VkmbelazMrOXSVmZjXGLW4zsxrTapd7XPzBG/4qYF/RpdfOzR9ky526Re9oWfNoSczpuEa/guVJ6kMyXv9rJLOPR0XEFZIuIRkRtYikW/DwiJibnnMmyeSxeuCEiHiwWPlucZuZATTUZ9+KqwNOiYiNSdYbOi5dc+ZhYNOI2Ixk1cgz4Yv1aIaRrAm0B8nciaKrYDpwm5kBREP2rVg2ETMjYmL6ej7JvIG1I+KhnNFST7NkxvBQkvVoFkbENJL5DNsUK8OB28wMoKEh8yZphJLlgxu3EfmylLQesCXwTJNdR5DMTIZklcvc9XhmpGkFtdo+bjOzSopmWtJfPjZGAaOKHZMuX3AbcGJEzMtJP5ukO+WWxqR8RRTL24HbzAyS1nSJpCtP3gbcEhG356QPJ1ngbNec5Q9m8OXF1XqzZEG5vNxVYmYGUL84+1ZEuqDb9cDLEXFZTvoeJOv27BsRn+accjcwTMmTovqSrC80oVgZbnGbmUGzNx1bYEeSBdomSXohTTuLZDG1TsDDSWzn6Uge7D1Z0lhgCkkXynHRzAO7W+3MSY/jtnw8jtvyKcU47kVvTMgcc1bot80yl7cs3OI2M6NlNyerzYHbzAxKenOy3By4zcyg2ZuOrYkDt5kZlPLmZNk5cJuZgbtKzMxqjlvcZmY1xi1uM7Pa0sycl1bFgdvMDKC+dp5P7cBtZgbu4zYzqznNP9mm1XDgNjMDt7jNzGqOR5WYmdUYt7jNzGpMnUeVmJnVFI/jNjOrNe7jNjOrMe7jNjOrMW5xm5nVmBqa8t6u2hUwM2sVoiH7VoSkPpIelfSypMmSfpqmrybpYUmvpX93zznnTElTJb0qaffmqurAbWYGSVdJ1q24OuCUiNgY2A44TtJA4AxgXET0B8al70n3DQM2AfYArpLUvlgBDtxmZlCywB0RMyNiYvp6PvAysDYwFLgpPewmYL/09VDg1ohYGBHTgKnANsXKcOA2M4MWdZVIGiHpuZxtRL4sJa0HbAk8A6wVETMhCe7AmulhawNv55w2I00ryDcnzcygRaNKImIUMKrYMZK6AbcBJ0bEPEkFD81XRLG8HbjNzKCko0okdSQJ2rdExO1p8vuSekbETEk9gVlp+gygT87pvYF3i+XvrhIzMyjlqBIB1wMvR8RlObvuBoanr4cDd+WkD5PUSVJfoD8woVgZbnGbmUEpJ+DsCBwKTJL0Qpp2FnAxMFbSkcB04ACAiJgsaSwwhWREynHRzMIpFQvckroCnzdXITOzqihR4I6IJ8nfbw2wa4FzRgIjs5ZRtsAtqR3J2MRDgK2BhUAnSbOB+4FREfFauco3M2uRKHo/sFUpZx/3o8D6wJnA1yKiT0SsCewMPA1cLOmHZSzfzCy70k3AKbtydpXsFhGLmyZGxBySu623pXdezcyqr4bWKilb4M4XtBtJ6hYRnxQ7xsysolpBSzqrag0HnFKlcs3M8ovIvlVZOW9OnlxoF9CtXOWamS0Vt7gB+CXQHVipydatzOWambWcb04CMBG4MyKeb7pD0lFlLNfMrMWivnammJQzcB8OfFhg31ZlLNfMrOVaQUs6q3KOKnm1aZqkr0XEexHxfrnKNTNbKjX0sOBK9zXfX+HyzMyyaYjsW5VVepGpggvSmplVlbtKCrq2wuWZmWXjwL1kdmRuWkRc1dwxy5uZ78/mrAsv5YM5H9FOYv+he3Logftx6ZXX8fi/nqFDxw70WbsnF511Miuv1I1/T5jI5dfcwOLFdXTs2IFTjjuSbb+5RbUvw8pswID1+cstV3/xvl/fdfj5BZfyzrvvcd65J7PxRv3Zfoe9eX7if6tYyxpXQ6NKFGWaBSRpHPACyWLhz0fEgjS9HzAYOBC4NiL+nu/8xR+8Uf2OpAqY/cEcZn84h4EbbsCCBZ9y4JEn8Ltfnct7sz5g229uQYcO7bnsqusBOPnYI3n5f1NZvXt31uyxOq+98SZHn3QO/7zrz1W+isrp0mvnaleh6tq1a8f0N59nh52GsOKKXWhoCK7+w8WcdvqFy23grlv0zjJ3w3566VGZY86Kp15X1W7fco4q2VXSXsDRwI6SupMsEv4qcB8wPCLeK1f5taLHGqvRY43VAOjadUX6rduH92d/yI7bfvOLYzbbZCMefvRJADYesMEX6Rv0XZeFixaxaNEiVlhhhcpW3Kpm12/vxBtvvMX06e9UuyptSw2NKilrH3dE3I9HkmT2zsz3efm119lskw2/lH7HfQ+xx67f+srxDz/2JBsPWN9Bezlz4IFDufWvd1a7Gm1PKxgtklXZhwNK2jF9+g2SfijpMknrFjj2i0feX3fzmHJXrVX59NPPOOnsizj9hKPp1rXrF+l/vGkM7du3Z8h3B3/p+KlvvMVlV43mvJ8dX+mqWhV17NiRfYZ8l7/fdm+1q9LmREND5q3aKjGq5Gpgc0mbA6eRPETzZuArTcjcR94vL33cAIvr6jjx7IvY+7uD+c6gHb9Iv+v+hxn/rwlc97tfkTx/NPHerNn89KwL+eW5p7JO717VqLJVyR57DOY//5nErFkfVLsqbU8NtbgrEbjrIiIkDQWuiIjrJQ1v9qzlRERw3q8up9+6fRg+7P++SH/y6ee4/pa/ceOVv6FL585fpM+b/wnH/ux8Tjz6ML6x2SbVqLJV0bAf7OduknLxqJKcAqTHgQdI1i7ZBZgNvBARXy923vLS4p744kv86Nif0X/99WinpOfqp0cP51eXX8OixYtZdeWVgeQG5fmnHc8fbxzDdX/6K+v0XvuLPEZdPpLVu69ajepX3PI8qqRLl868+cZz9N9we+bNmw/A0KF7cMVvL6JHj9WYO3ceL744mb2GHFLlmlZeKUaVLPj5QZljTtefjylanqTRwBBgVkRsmqZtAVwDdCYZqHFsRExI950JHAnUAydExINF869A4P4acDDwbEQ8IWkdYFBE3FzsvOUlcFvLLM+B2worSeA+b1j2wP2LW5sL3LsAnwA35wTuh4DfRsQ/0hF3p0XEIEkDgTHANkAv4BFgQEQU/ApQia6S+SRdJPWSBgAbpZU0M2s9SjgcMCLGS1qvaTKwcvp6FeDd9PVQ4NaIWAhMkzSVJIg/VSj/SgTu8cDO6TjuccBzwA+A5e/7nJm1Xi24OSlpBDAiJ2lUOriimBOBByVdSjKib4c0fW3g6ZzjZqRpBVUicCsiPpV0JPD7iPiNpBcqUK6ZWWZRl/3mZO4IuBb4CXBSRNwm6UCSEXa7kX/xvaK/RSqxrKskbU/Swr4vTWtfgXLNzLIr/7Kuw4Hb09d/I+kOgaSF3SfnuN4s6UbJqxKB+6fAmcAdETE5Xavk0QqUa2aWXTRk35bOuyyZv/Jt4LX09d3AMEmdJPUF+gMTimVU9q6SiBhP0s/d+P4N4IRyl2tm1iIlnIAjaQwwCFhD0gzgfODHwBWSOgCfk/aRpw3ascAUkmGCxxUbUQIVCNySepDMmNyEZPwiABHx7XKXbWaWVZQwcEfEQQV2fTNfYkSMBEZmzb8SXSW3AK8AfYELgDeBZytQrplZdjX06LJKBO7VI+J6YHFEPB4RRwDbVaBcM7Ps6uqzb1VWieGAi9O/Z0ram6SDvncFyjUzy64VtKSzqkTgvkjSKsApwO9JZg6dVIFyzcwyK/fyH6VUzmdOdgaOATYgmQV0fUQMLn6WmVmVuMUNwE0k3SRPAHsCA0nGdJuZtT4O3AAMbFy6VdL1NDOg3Mysmko5HLDcyhm4G29KEhF1uU9wMTNrdeocuCF5XNm89LWALul7ARERKxc+1cysstziBiLCC0mZWe1w4DYzqzHVf3h7Zs3OnJR0gKSV0tfnSLpd0jfKXzUzs8qJhsi8VVuWKe/nRsR8STsBu5MM87u6vNUyM6usqIvMW7VlCdyNE/P3Bq6OiLuAFcpXJTOzKmhowVZlWfq435H0R5JH7PxaUicqsziVmVnFlPBZwWWXJQAfCDwI7BERc4HVgJ+Vs1JmZhVXQy3uZgN3RHwKzAJ2SpPqWPLIHTOzNqH8Ty4rnWa7SiSdD2wFbAjcAHQE/gzsWN6qmZlVUCsIyFll6eP+HrAlMBEgIt5tHB5oZtZWNNRVuwbZZenjXhTJQrUBIKlreatkZlZ5pewqkTRa0ixJLzVJP17Sq5ImS/pNTvqZkqam+3ZvLv8sLe6x6aiSVSX9GDgCuDbDeWZmtSNKuhDejcCVwM2NCZIGA0OBzSJioaQ10/SBwDCSB6r3Ah6RNKDYk96bDdwRcamk7wDzSPq5z4uIh5f+eszMWp9S3nSMiPGS1muS/BPg4ohYmB4zK00fCtyapk+TNBXYBniqUP6Z1ipJA7WDtZm1WdFQ9qWnBwA7SxoJfA6cGhHPkjwh7Omc42akaQVlGVUyn7R/m2TGZEdggZdlNbO2pKE+e+CWNAIYkZM0KiJGNXNaB6A7sB2wNUk3dD+Spa6bKjqvPktXyZdGkEjaj6QZb2bWZrSkqyQN0s0F6qZmALengz0mSGoA1kjT++Qc1xt4t1hGLZ66HhF3At9u6XlmZq1ZNCjztpTuJI2dkgaQ9GB8ANwNDJPUSVJfoD/NPOoxS1fJ/+W8bUcyGaf6y2OZmZVQlDCqSRoDDALWkDQDOB8YDYxOhwguAoanre/JksYCU0hmph9XbEQJZLs5uU/O6zrgTZK7oGZmbUYpb05GxEEFdv2wwPEjgZFZ88/Sx3141szMzGpVBUaVlEzBwC3p9xTpEomIE8pSIzOzKmjJqJJqK9bifq5itTAzq7Io7czJsioYuCPipkpWxMysmlrDcq1ZZRlV0gM4HRgIdG5MjwgPCTSzNqOhhlrcWcZx3wK8DPQFLiAZVfJsGetkZlZxEcq8VVuWwL16RFwPLI6IxyPiCJIpm2ZmbUYFJuCUTJZx3IvTv2dK2ptkKmbv8lXJzKzy2sqokkYXSVoFOAX4PbAycFJZa2VmVmG11MedJXA/ExEfAx8Dg8tcHzOzqmgNfddZZenj/rekhyQdKal72WtkZlYFEdm3ams2cEdEf+AcksfqPC/pXkl559ubmdWqhlDmrdoyLesaERMi4mSSdbjnAJ6cY2ZtSkODMm/VlmUCzsrA90geZrk+cAd+kIKZtTGtoSWdVZabky+SLAD+i4go+PDKUtths8MqVZTVkPl3nV7tKlgbVUs3J7ME7n7pYt9mZm1Wm2pxO2ib2fKglgJdlha3mVmb16Za3GZmy4P6thC4/QQcM1ueBG0gcOMn4JjZcqShtE95Hw0MAWZFxKZN9p0KXAL0iIgP0rQzgSOBeuCEiHiwWP5+Ao6ZGdBQ2hb3jcCVwM25iZL6AN8BpuekDSSZJ7MJ0At4RNKAiKgvlLmfgGNmRmm7SiJivKT18uz6LXAacFdO2lDg1ohYCEyTNJVkkmPBeTN+Ao6ZGdDQgm1pSNoXeCciXmyya23g7Zz3M9K0gvwEHDMzoB5l3iSNkPRczjaiWN6SVgTOBs7LtztPWtEedz8Bx8yMlrWkI2IUMKoFp6xP0mvxoiRIYuhESduQtLD75BzbmyTOFuQn4JiZUd7hgBExCViz8b2kN4GtIuIDSXcDf5F0GcnNyf7AhGL5ZZnyfm/60k/AMbM2q5SrtUoaAwwC1pA0Azg/7XL+ioiYLGksMAWoA44rNqIEso0quYE8/S1pX7eZWZtQyuGAEXFQM/vXa/J+JDAya/5ZukruzXndmWRt7qL9L2ZmtaZoE7eVydJVclvu+/QrwCNlq5GZWRU0qG1MeS+kP7BOqStiZlZNbWpZV0nz+fI1vUcyk9LMrM1Y2ok11ZClq2SlSlTEzKyaWsEzgDNrduakpHFZ0szMalkDyrxVW7H1uDsDK5KMQ+zOkmmZK5MMEjczazPqqx+PMyvWVXI0cCJJkH6eJYF7HvCH8lbLzKyy2kQfd0RcAVwh6fiI+H0F62RmVnG1NKoky+qADZJWbXwjqbukY8tXJTOzymtQ9q3asgTuH0fE3MY3EfER8OOy1cjMrArKvR53KWWZgNNOkiIiACS1B1Yob7XMzCqrNQTkrLIE7geBsZKuIekGOgZ4oKy1MjOrsLYyqqTR6cAI4CckI0seAq4tZ6XMzCqtllrczfZxR0RDRFwTEftHxPeBySQPVDAzazOiBVu1ZVpkStIWwEHAD4BpwO1lrJOZWcW1htEiWRWbOTkAGEYSsD8E/gooIvwUHDNrc2qpq6RYi/sV4Algn4iYCiDJz5o0szaplh6kUKyP+/skS7g+KulaSbuS/zHyZmY1r01MwImIOyLiB8BGwGMkT3ZfS9LVkr5bofqZmVVELU3AyTKqZEFE3BIRQ4DewAvAGeWumJlZJZVyVImk0ZJmSXopJ+0SSa9I+q+kO5osJXKmpKmSXpW0e3P5Z5nyvuTCIuZExB8j4tstOc/MrLVrIDJvGdwI7NEk7WFg04jYDPgfcCaApIEkA0E2Sc+5Kp2hXlCLAreZWVtVyq6SiBgPzGmS9lBE1KVvnybpwQAYCtwaEQsjYhowFdimWP4O3GZmJKNKsm6SRkh6Lmcb0cLijgD+kb5eG3g7Z9+MNK2gpXnKu5lZm9OS0SIRMQoYtTTlSDobqANuaUzKV0SxPBy4zcwga9/1MpE0HBgC7Nq44ipJC7tPzmG9gXeL5eOuEjMzyr9WiaQ9SBbt2zciPs3ZdTcwTFInSX2B/sCEYnlVrMUtqSvweUTU0gQlM1tOlHJ8tqQxwCCSh63PAM4nGUXSCXhYEsDTEXFMREyWNBaYQtKFclxzcbJsgVtSO5IhLocAWwMLgU6SZgP3A6Mi4rVylW9m1hL1JewqiYiD8iRfX+T4kcDIrPmXs6vkUWB9kt8yX4uIPhGxJrAzyVCYiyX9sIzlm5llVkszJ8vZVbJbRCxumhgRc4DbgNskdSxj+WZmmVXi5mSplK3FnS9oN5LUrbljzMwqqZYepFCtUSVTqlSumVle7ioBJJ1caBfQrVzlmpktjWgVbelsytnH/UvgEpLhLU15/LiZtSp1DtwATATujIjnm+6QdFQZy61pw47cn/0OGYIk7rzlXsZc9zdOOPcn7PydHVi8qI4Zb73DL066mE/mfVLtqloZvffRfM65ZRwfzvsUtYPvb78Jh3xrcz5e8Dmn3fQg786ZT6/VVuKSw3Zn5RU7M3fB55x6wwNMnv4++26zMWfuv0u1L6Hm1E7YLm/L93DgrQL7tipjuTVr/Q37st8hQxi+99EcvNsR7PSd7enTtzfPjH+OYYMP4+DdDmf6GzM47HiPomzr2rdrxylDd+SOsw7mTyfuz1+fnMTr781h9LiJbDugN/ec80O2HdCb0Y9MBKBTh/Yct9c2nDx0xyrXvHaVeFnXsirnqJJXI+KDAvveL1e5tWy9/usyaeIUFn62kPr6eiY+9QKD9tyZZx5/lvr6ZCLVS89PZq2ePapcUyu3Hqt0ZeM+yb9z184r0G+t7sz6eAGPTZrGPltvBMA+W2/Eo5OmAdClU0e27NeLFToUXcbZiqilm5NlC9ySRkn6eoF9XSUdIemQcpVfi15/ZRpbbrs5q3RfmU5dOrHDt7djrV5rfumYfQ/ai3//8+kq1dCq4Z0P5/HKjA/4+rpr8eH8T+mxSlcgCe5zPvmsyrVrO6IFf6qtnH3cVwHnpsH7JWA20JlkAZWVgdEsWdbQgDenvsXNV/2FK2+9jE8XfMZrU16nvm7JkgWHn3AodXX1/OP2h6tYS6ukTxcu4tQbHuBn39uJbp1XqHZ12rTW0JLOqmyBOyJeAA5MJ9tsBfQEPgNejohX852TLkY+AmDdVTagx4o9y1W9VuvuMfdx95j7ADj2jB8za+ZsAPY+YA922m17jv3BSdWsnlXQ4vp6Thn9AHt9cwC7br4+AKuvtCKzP15Aj1W6MvvjBazWrUuVa9l2lHKtknIr+7C8iPgkIh6LiDERcWehoJ0eOyoitoqIrZbHoA3QffVVAVhr7TUZvNcuPHjnI2w/aBt+dNzBnHLYmSz8bGF1K2gVERFcMOZR+q7VnUMHb/FF+rc2XY97nn0FgHuefYVBX+9bpRq2PQ0RmbdqK+cEnEnkH2EjINIHZloTv77uQlbpvgp1i+v4zVm/Zf7Hn/CzkSeyQqcV+MNfLwNg0vNTuPiM/7/KNbVyemHaTO597lX691ydA39zKwDHD9mOI3b7Jqfd+AB3PP0yPbt345LDljyPds8LbmbBwkUsrqvn0UlvcPVP9mX9r61WrUuoOdUPx9kpyvTbQ9K6xfZHRKGhggBs3WuXWvo5WoWMv37/alfBWqEue57QggeP5Xfwut/LHHP+8tYdy1zesihnH3fRwGxm1pq0htEiWZWzq+TJiNhJ0ny+/C2ksatk5XKVbWbWUp7yDkTETunfK5WrDDOzUnGLOw9Ja5KM4wYgIqZXqmwzs+bU0jjusg8HlLSvpNeAacDjwJvAP8pdrplZS0RE5q3aKrG86oXAdsD/IqIvsCvwrwqUa2aWWSkXmZI0WtIsSS/lpK0m6WFJr6V/d8/Zd6akqZJelbR7c/lXInAvjogPgXaS2kXEo8AWFSjXzCyzEi8ydSOwR5O0M4BxEdEfGJe+R9JAYBiwSXrOVZKKrhZWicA9N532Ph64RdIV5H+4gplZ1dTTkHlrTkSMB+Y0SR4K3JS+vgnYLyf91ohYGBHTgKnANsXyL+fqgOvkVOpT4CTgAeB1YJ9ylWtmtjRa0sctaYSk53K2ERmKWCsiZqZlzQQal/5cG3g757gZaVpB5RxVcifwjYhYIOm2iPg+S37bmJm1Ki0ZVRIRo4BRJSo63yzMoh3p5ewqya1MvzKWY2a2zCqwHvf7knoCpH/PStNnAH1yjusNvFsso3IG7ijw2sys1anAo8vuBoanr4cDd+WkD5PUSVJfkmcWTCiWUTm7SjaXNI+k5d0lfQ2e8m5mrVApx2dLGgMMAtaQNAM4H7gYGCvpSGA6cEBa7mRJY4EpJAM3jouI+rwZp8o55d0PvzOzmpFltEhWEXFQgV27Fjh+JDAya/4Vm/JuZtaatYYHJGTlwG1mRm3diHPgNjODZbnpWHEO3GZmOHCbmdWc+qidhV0duM3M8IMUzMxqTmtYZzsrB24zM9zHbWZWc9ziNjOrMW5xm5nVGI8qMTOrMR5VYmZWY7xWiZlZjXGL28ysxrjFbWZWY9ziNjOrMR5VYmZWY8KB28ystngCjplZjamlKe/tql0BM7PWoIHIvDVH0kmSJkt6SdIYSZ0lrSbpYUmvpX93X9q6OnCbmQH1DQ2Zt2IkrQ2cAGwVEZsC7YFhwBnAuIjoD4xL3y8VB24zM5LhgFn/ZNAB6CKpA7Ai8C4wFLgp3X8TsN/S1tWB28yMpI876yZphKTncrYROfm8A1wKTAdmAh9HxEPAWhExMz1mJrDm0tbVNyfNzGjZqJKIGAWMyrcv7bseCvQF5gJ/k/TDElTxCw7cZmaUdFTJbsC0iJgNIOl2YAfgfUk9I2KmpJ7ArKUtwF0lZmYka5Vk3ZoxHdhO0oqSBOwKvAzcDQxPjxkO3LW0dXWL28yM0k15j4hnJP0dmAjUAf8h6VbpBoyVdCRJcD9gactw4DYzo7QTcCLifOD8JskLSVrfy8yB28wML+tqZlZzvKyrmVmNcYvbzKzGNHhZVzOz2lJLqwM6cJuZ4cBtZlZzaidsg2rpt8zyStKIdG0Esy/4c7H88pT32jCi+UNsOeTPxXLKgdvMrMY4cJuZ1RgH7trgfkzLx5+L5ZRvTpqZ1Ri3uM3MaowDt5lZjXHgNjOrMQ7cGUiql/SCpJck/U3SisuQ142S9i+y/zFJr0p6UdK/JG24tGXlyftySbsU2PeApLmS7m2Sfquk/qWqQ1tWpc/JC+lW7NjrJA1MX78paY30dRdJj0tqn773Z6BGOHBn81lEbBERmwKLgGNydzZ+8EvokIjYHLgJuKQUGUpaDdguIsYXOOQS4NA86VcDp5WiDsuBanxOtki3vxc6KCKOiogpeXYdAdweEfXpe38GaoQDd8s9AWwgaZCkRyX9BZgkqb2kSyQ9K+m/ko4GUOJKSVMk3Qes2YKyxqdlrSfpCUkT022HNO+eksbntPJ2TutxY/p+kqST0rz2Bx4oVFBEjAPmF7je3SR5XZuWqeTnhDSPqyU9J2mypAty0h+TtFWeUw4h54G1/gzUDv9DtED6wd2TJQFwG2DTiJgmaQTwcURsLakT8C9JDwFbAhsCXwfWAqYAozMWuQ8wCZgFfCciPk+/so4BtgIOBh6MiJFpa25FYAtg7bTVh6RV07x2BAq2ygqJiAZJU4HNgedbev7yqIKfk1skfZa+3hU4OyLmpJ+FcZI2i4j/FqjjCkC/iHizuevxZ6D1ceDOpoukF9LXTwDXAzsAEyJiWpr+XWCznL7GVYD+wC7AmPTr6LuS/pmhvMb/kG8CxwMdgSslbQHUAwPS454FRkvqCNwZES9IegPoJ+n3wH3AQ+mxPYHZLb7yxCygF/5P25xKf04OiYjnGt9IOib9xdCB5N97IJA3cANrAHOzXhj+DLQqDtzZfBYRW+QmSAJYkJsEHB8RDzY5bi9avmJk0/+QPwfeJ2nxtAM+B4iI8enNxr2BP0m6JCJulrQ5sDtwHHAgSV/mZ0DnNL9tgT+m2Z8XEXc3U5/O6flWXKU/J7nn9wVOBbaOiI8k3Uj6712ors3sb8qfgVbEfdyl8yDwk7T1i6QBkrqS9FMPS/s2ewKDlyLvVYCZEdFAcvOocRTAusCsiLiWpHX3jXTEQLuIuA04F/hGmsfLwAYAEfFMzk2t5oI2JC38yUtRb/uqcn1OVib5BfGxpLVIumoKioiPgPaSsgZvfwZaEbe4S+c6YD1gopJm1mxgP+AO4NskfdX/Ax5firyvAm6TdADwKEtacIOAn0laDHwC/AhYG7hBUuMv5TPTv+8Djk7r+RWSngA2ArpJmgEcGREPpkHgs4iYuRT1tq8qy+ckIl6U9B+S4PoG8K8Mpz0E7AQ8Av4M1BKvVbIckfQkMCQi5rbgnJOAeRFxfdkqZlUhaUvg5IjINwQw9zh/BloZd5UsX04B1mnhOXNJxpNbGxMR/wEeVfPjy+fiz0Cr4hZ3lUi6A+jbJPn0pjetbPnmz4nl48BtZlZj3FViZlZjHLjNzGqMA7d9icq0wp1yVqgrcOygxjVYWljGF6vdNSn36CZp+0m6P0tdzVo7B25rqiwr3BVZoa7RIJLp4aUwBhjWJG1Ymm5W8xy4rZiSrXCXu0KdpD2UrHL4oqRxktYj+QVxUtra31lSD0m3pWU8K2nH9NzVJT0k6T+S/kgyhbypR4CN0hmIpN8adgPulHRemt9Lkkalk2C+RF9es3orSY+lr7tKGp2e/x9JQ9P0TSRNSOv+X3ntaiszB27LS0tWuJuUJm1DsvrcQOBI0hXugK2BH6drZXyPJSvc/Zg8LWhJPYBrge+na44fkK5Qdw3w27S1/wRwRfp+a+D7LJnxeT7wZERsCdxNnnHp6UJNt5Os0wKwL/BoRMwHroyIrdNvFF2AIS34sZwN/DOt02DgknS6+jHAFek6JVsBM1qQp1mLecq7NVXuFe62A8Y35hURcwrUYzdgYE6DeGVJK6Vl/F967n2SPipw/hiSBwNcQdJNcnOaPljSaSRL4K5GMkX8ngJ5NPVdYF9Jp6bvO5P84ngKOFtSb5IHE7yWMT+zpeLAbU2Ve4U7ZTgGkm+D20fEl1akS+uS5fx/AT2VrJS4A8kCTp1J1n3ZKiLeVrLqYr5FlupY8m00d79Ivim82uT4lyU9Q7JK44OSjoqILMuymi0Vd5XY0liWFe6eAr6Vdq00PlINkievrJRz3EPA/9f4Rsla5KRlHJKm7Ql0z1fBSGaWjSWZqn1/RHzOkiD8gaRuJE8FyudN4Jvp6+83ue7jG/vF07U+kNQPeCMifkfSfbNZgXzNSsKB25bGdSRPaJko6SWStb07kKxw9xpJv/jV5FnhLiJmAyOA2yW9CPw13XUP8L3Gm5PACcBW6c2+KSwZ3XIBsIukiSRdF9OL1HMMyRrmt6ZlzyXpX58E3EnyIIp8LgCuULJaXn1O+oUkD7X4b3rdF6bpPwBeSruYNmJJt4xZWXjKu5lZjXGL28ysxjhwm5nVGAduM7Ma48BtZlZjHLjNzGqMA7eZWY1x4DYzqzH/Dy5FP9USJH3UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report for Logistic Regression Model \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.76      0.73       293\n",
      "           1       0.74      0.69      0.71       293\n",
      "\n",
      "    accuracy                           0.72       586\n",
      "   macro avg       0.72      0.72      0.72       586\n",
      "weighted avg       0.72      0.72      0.72       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicting the values for test Set on the trained Model\n",
    "logi_pred = logi.predict(x_te_ss)\n",
    "\n",
    "#Scoring the Model on Test Set\n",
    "logi_score = logi.score(x_te_ss, y_te)\n",
    "print('The Score/Accuracy of the Logistic Regression Model on Test Data is:', logi_score, '\\n')\n",
    "\n",
    "#Generating the Confuision Matrix\n",
    "print('The Confusion Matrix of the Logistic Regression Model')\n",
    "logi_conmat = metrics.confusion_matrix(y_te, logi_pred, labels=[-1,1])\n",
    "sns.heatmap(logi_conmat, fmt='g', annot=True, yticklabels=['Pass(-1)', 'Fail(1)'], xticklabels=['Pred_Pass(-1)', 'Pred_Fail(1)'])\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Logistic Regression Model')\n",
    "plt.show();\n",
    "\n",
    "#Generating the Classification Report\n",
    "logi_cr = metrics.classification_report(y_te, logi_pred)\n",
    "print('The Classification Report for Logistic Regression Model \\n', logi_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b1536",
   "metadata": {},
   "source": [
    "#### 5B. Use cross validation techniques. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6773bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the upsampled data before using CV\n",
    "xros_ss = ss.fit_transform(xros)\n",
    "xros_ss = pd.DataFrame(xros_ss, columns=x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0545d20d",
   "metadata": {},
   "source": [
    "###### Using different Cross-Validation Techniques on Logistic Regression Model with Up-Sampled Dataset & checking the accuracy of the each Cross-Validation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ba5872d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model on Up-Sampled dataset using KFoldCV: 0.6272757024638833\n"
     ]
    }
   ],
   "source": [
    "#Using KFold Cross Validation on upsampled dataset & Logistic Regression Model\n",
    "kfold = KFold(n_splits=10)\n",
    "kf_result = cross_val_score(logi, xros_ss, yros, cv=kfold)\n",
    "print('Accuracy of Logistic Regression Model on Up-Sampled dataset using KFoldCV:', kf_result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ffed171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model on Up-Sampled dataset using LeaveOneOut CV: 0.7566643882433356\n"
     ]
    }
   ],
   "source": [
    "#Using LeaveOneOUt Cross Validation on upsampled dataset & Logistic Regression Model\n",
    "loo = LeaveOneOut()\n",
    "loo_result = cross_val_score(logi, xros_ss, yros, cv=loo)\n",
    "print('Accuracy of Logistic Regression Model on Up-Sampled dataset using LeaveOneOut CV:', loo_result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae235702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression Model on Up-Sampled dataset using StratifiedKFold CV: 0.7106000748048062\n"
     ]
    }
   ],
   "source": [
    "#Using StratifiedKFold\n",
    "skfold = StratifiedKFold(n_splits=10)\n",
    "skf_results = cross_val_score(logi, xros_ss, yros, cv=skfold)\n",
    "print('Accuracy of Logistic Regression Model on Up-Sampled dataset using StratifiedKFold CV:', skf_results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b6b141",
   "metadata": {},
   "source": [
    "#### 5C. Apply hyper-parameter tuning techniques to get the best accuracy. [3 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dfb91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using GridSearchCV to tune the Hyper-Parameter of Logistic Regression Model\n",
    "logi_para = {'solver': ['liblinear', 'lfbgs', 'sag', 'saga'], 'penalty':['elasticnet', 'l1', 'l2', 'none'],\n",
    "             'multi_class': ['auto', 'ovr', 'multinomial'], 'C':[0.1, 1, 10],\n",
    "             'tol': [0.00001, 0.0001, 0.001], 'class_weight': ['balanced', None]}\n",
    "logi_grid = GridSearchCV(logi, param_grid=logi_para, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e02054e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5220 fits failed out of a total of 8640.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 48, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got lfbgs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1149, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 97, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.74871795 0.74786325        nan        nan        nan\n",
      "        nan        nan        nan 0.73974359 0.73974359 0.73974359\n",
      " 0.74316239 0.74316239 0.74316239        nan        nan        nan\n",
      " 0.74230769 0.74230769 0.74230769 0.74017094 0.74017094 0.74017094\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.74615385 0.74273504 0.74273504 0.74230769\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.74871795 0.74871795        nan        nan        nan\n",
      "        nan        nan        nan 0.73974359 0.73974359 0.73974359\n",
      " 0.74316239 0.74316239 0.74316239        nan        nan        nan\n",
      " 0.74230769 0.74230769 0.74230769 0.74017094 0.74017094 0.74017094\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.7465812  0.74230769 0.74273504 0.74188034\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74401709 0.74401709 0.74444444\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74444444 0.74401709 0.74401709 0.74401709 0.74401709 0.74401709\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.7491453  0.74871795 0.7465812  0.7465812  0.7465812\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.74871795 0.74786325        nan        nan        nan\n",
      "        nan        nan        nan 0.73974359 0.73974359 0.73974359\n",
      " 0.74316239 0.74316239 0.74316239        nan        nan        nan\n",
      " 0.74230769 0.74230769 0.74230769 0.74017094 0.74017094 0.74017094\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7457265  0.74615385 0.7474359  0.74273504 0.74273504 0.74188034\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.74871795 0.74871795        nan        nan        nan\n",
      "        nan        nan        nan 0.73974359 0.73974359 0.73974359\n",
      " 0.74316239 0.74316239 0.74316239        nan        nan        nan\n",
      " 0.74230769 0.74230769 0.74230769 0.74017094 0.74017094 0.74017094\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.7465812  0.74230769 0.74230769 0.74273504\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74401709 0.74401709 0.74401709\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74444444 0.74444444 0.74401709 0.74358974 0.74316239 0.74444444\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.74871795 0.7491453  0.7465812  0.74615385 0.7465812\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7517094  0.7517094  0.7517094         nan        nan        nan\n",
      "        nan        nan        nan 0.74273504 0.74273504 0.74273504\n",
      " 0.7508547  0.7508547  0.7508547         nan        nan        nan\n",
      " 0.74700855 0.74700855 0.74700855 0.74145299 0.74102564 0.74102564\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.74615385 0.74230769 0.74145299 0.74230769\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7517094  0.7517094  0.75213675        nan        nan        nan\n",
      "        nan        nan        nan 0.74273504 0.74102564 0.74273504\n",
      " 0.7508547  0.7508547  0.7508547         nan        nan        nan\n",
      " 0.74700855 0.74700855 0.74700855 0.74102564 0.74188034 0.74145299\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.7465812  0.74230769 0.74230769 0.74102564\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74358974 0.74401709 0.74401709\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.75042735 0.75042735 0.75042735 0.74700855 0.7465812  0.74700855\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.7491453  0.74871795 0.7465812  0.74615385 0.7465812\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7517094  0.7517094  0.7517094         nan        nan        nan\n",
      "        nan        nan        nan 0.74273504 0.74273504 0.74273504\n",
      " 0.7508547  0.7508547  0.7508547         nan        nan        nan\n",
      " 0.74700855 0.74700855 0.74700855 0.74102564 0.74102564 0.74145299\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.7465812  0.74145299 0.74145299 0.74230769\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7517094  0.7517094  0.7517094         nan        nan        nan\n",
      "        nan        nan        nan 0.74273504 0.74273504 0.74273504\n",
      " 0.7508547  0.7508547  0.7508547         nan        nan        nan\n",
      " 0.7465812  0.74700855 0.74700855 0.74188034 0.74145299 0.74102564\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.7465812  0.74230769 0.74273504 0.74273504\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.74401709 0.74401709 0.74401709\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.75042735 0.75042735 0.75042735 0.74615385 0.7465812  0.7465812\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.74871795 0.74871795 0.7465812  0.74615385 0.74615385\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7534188  0.7534188  0.7534188         nan        nan        nan\n",
      "        nan        nan        nan 0.74230769 0.74145299 0.74188034\n",
      " 0.75       0.75       0.74871795        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.74615385 0.74273504 0.74273504 0.74145299\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7457265  0.74700855 0.74188034 0.74230769 0.74230769\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7534188  0.7534188  0.7534188         nan        nan        nan\n",
      "        nan        nan        nan 0.74188034 0.74145299 0.74230769\n",
      " 0.75       0.75       0.74871795        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.7465812  0.74188034 0.74145299 0.74230769\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74615385 0.7465812  0.7465812  0.74145299 0.74102564 0.74145299\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.7465812  0.74615385 0.7457265\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.7491453  0.7491453  0.7465812  0.74615385 0.7465812\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.7491453  0.7491453  0.74615385 0.7465812  0.7465812\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7534188  0.7534188  0.7542735         nan        nan        nan\n",
      "        nan        nan        nan 0.74188034 0.74230769 0.74230769\n",
      " 0.75       0.75       0.74871795        nan        nan        nan\n",
      " 0.74615385 0.74615385 0.7465812  0.74230769 0.74188034 0.74188034\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.7465812  0.74615385 0.74273504 0.74230769 0.74230769\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7534188  0.7534188  0.7542735         nan        nan        nan\n",
      "        nan        nan        nan 0.74188034 0.74145299 0.74145299\n",
      " 0.75       0.75       0.74871795        nan        nan        nan\n",
      " 0.74615385 0.7465812  0.7465812  0.74230769 0.74316239 0.74188034\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7465812  0.74615385 0.7465812  0.74230769 0.74188034 0.74145299\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.7457265  0.7457265  0.7457265\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.74871795 0.74871795 0.7465812  0.7465812  0.74615385\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.74871795 0.74871795 0.74871795 0.7465812  0.7465812  0.7465812 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;, &#x27;multinomial&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lfbgs&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;],\n",
       "                         &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;, &#x27;multinomial&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lfbgs&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;],\n",
       "                         &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'class_weight': ['balanced', None],\n",
       "                         'multi_class': ['auto', 'ovr', 'multinomial'],\n",
       "                         'penalty': ['elasticnet', 'l1', 'l2', 'none'],\n",
       "                         'solver': ['liblinear', 'lfbgs', 'sag', 'saga'],\n",
       "                         'tol': [1e-05, 0.0001, 0.001]})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the Model with Training Dataset\n",
    "logi_grid.fit(x_tr_ss, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94981f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10,\n",
       " 'class_weight': None,\n",
       " 'multi_class': 'auto',\n",
       " 'penalty': 'l1',\n",
       " 'solver': 'liblinear',\n",
       " 'tol': 0.001}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the Best Parameters of the Model\n",
    "logi_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b362d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7542735042735043"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the Best Score of the Model\n",
    "logi_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c03d6e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score/Accuracy of the Logistic Regression Model on Test Data is with Hyper-Parameter Tuning (GSCV) is: 0.7252559726962458 \n",
      "\n",
      "The Confusion Matrix of the Logistic Regression Model with tune Hyper-Parameters (GSCV)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEXCAYAAAC6baP3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAw20lEQVR4nO3deZwcVdn28d+VBEhI2PclLCEJGBBRCfIA0SAoO8EFBAGDAgHkBUUERVREQVF8BBRBwiIgCCI7iIBE9kdk3wIiOwkJCSRA2Mlk7vePc4ZUmlm6k57pms71nU99pruquuru7uq665xTdUoRgZmZWbX6NDoAMzPrXZw4zMysJk4cZmZWEycOMzOriROHmZnVxInDzMxq0pDEIekPkn40H69bQ9Kbkvp2R1xlJenvksY2Oo5qSXpO0tZVzLeWpJDUbwHX96akIQsaT1nkz2Roo+Ow7iPpF5K+3eg4iiTdLWn9aubtMnF0x48uIg6MiJ/Vuu6IeCEiBkXEnFrWJ2kfSXPyDmaWpIck7Tg/sTdCRGwXEefVe7mSzs07qZ0rxp+cx+9T73V2h7xNPAMfvKfj5mc5kn6Qt5E3Jb1b2GbelDSxvlHPH0m3SNqvYtxoSZMbFVNR3m7eyp/Zi5J+U/YDvZ7+/CStAHwNOKMwbon8WT2XP78XJF0qaZPCPGMkPZj3Ya9ImiBprcL04ZL+mqe9LulhSd+RNFDSa5I+204sJ0m6ND/9NfDTat7DwlRV9a+IGAQsDZwGXCxp6XqvpOw/knb8F/igNJOP/ncFnm5YRA0SET/PSWgQcCB5m8lDVUdiC5NOtvWP5c9wK+CrwP41LneBSqA9bT7i3Qe4LiLeya9fDPgn8FFgR2BJ4CPAxcD2eZ6hwPnA4cBSwNqk/Vhrnr4O8G9gEvDRiFiK9DveGFgE+AspWRXj7gvsAbQdlF4NbClplS7fQUR0OgDPAVu3M34x4GRgSh5OBhYrTD8SmJqn7QcEMDRPOxc4Lj9eHrgWeA2YCdxOSmh/yh/KO8CbeXlr5eX0y69dFvhjXserwJUdvId9gDsKzxfPyxlZeC+/Bl4ApgF/AAbU8F5OB64D3gK2BlYFLgNeBp4FDi0saxPgXmBWXtdv8vj+wAXAjPxZ3AOslKfdAuyXH/cBfgg8D0wnbUxL5Wltn8/Y/F5eAY7u5Ls9N7/vl4Bl8rgdgb8DdwD7dLXOPH3vPG0GcDSFbSa/9vukRDQDuARYtiLefu3E9nXgmsLzp4BLCs8nARvlxwEMBcYBs4H3SdvMNYVt+LvAw8DrpB9R/y62+32Yd5v54DtvZxseDUwm/aink7aVr1f8Vjrbvo5g7vb1jcp1VcT1wbZQGDcamJwf7wrcVzH9cPJvI8f9B+AfwBvArcCahXnXy9NmAk8Au1W853m29Xbiq/yc/gqcCqxD2jnOIG2XFwJLV+xnvpe/o/eAfoXt5g3gMeALFd/PncBJpN/LM8Bmefyk/D2M7eo7AAaS9jGteZt5k/T7rWa73Tcv7zY6+f228xn9E9ir8Hy//P0P7GR7/DLwYCfTLwD+1sn0zfLnuHhh3Pb5c+pXGPeP4ufW0bAgJY6jgU2BjYCPkXaIPwSQtC3wHdJOdCjwmU6WczjpR7cCsBLwAyAiYm/Sl7JTpCO+X7Xz2j+RksD6wIqkjahTOct+nbSDeT6P/iUwPL+XocBqwI9reC9fBY4HlgD+D7gGeCgvZyvg25K2yfOeApwSEUuSfkyX5PFjSUcSg4HlSEe877Szrn3ysCUwBBhE+mEWbQGsm9f9Y0kf6eQjeZd0pLF7fv41UmKoap2SRpB2JnuTfnDLAasXXnsosAvpc1uVlOB/30k8bW4FRknqk4+AFgE2z+tsi+Hh4gsiYjxph/SrvM3sVJi8G7At6Uhtw/x+6mll0ve3GmmH8ntJy+RpXW1f3wU+BwwjbWcL4mpg7YrvfC/Sb6XNnsDPSAdtD5I+MyQNJO04/kz6Pe0BnFZR713c1u/oLJC8bYwCHgAE/IK0DXyEtJ3/pOIlewA7kBJKC2mnPYr0uR4LXFBxNPwp0jawXI75YmAk6TPeCzhV0qA8b7vfQUS8BWwHTIm5pcspVLfdfia/l22o/vcLqWTxROH51sANOZaO3A+sl6uWtiy8r+IyLm3ndQBExP+RktMXC6P3Bv6cP+s2j5P2553rKrPQcYnjaWD7wvNtgOfy43OAXxSmDaXjEsdPgato5wirct0UjlCBVUhHCctU8R72AVpIRwKzSV/obnmaSEdP6xTm/x/g2Rrey/mF6Z8CXqhY/1HAH/Pj20g/guUr5vkGKels2E78tzC3xDEB+GZh2rr5PfUrfD6rF6bfDezewedyLnAcKdH8i7ThTyMdiRVLHJ2t88fAxYVpA0lH/G0ljseBrQrTV2kn3g+VOPK8k4BPkJLa+Pxe1iMl/qsL87W7bVVsR8UjvF8Bf6him6mlxPEO8x65TScdWFWzfZ1QmDa8cl3tbAtvk7bltuFNcokjz3M6cHx+vD5pp7dYIe7i9zUImEPa4X0FuL1ifWcAx7S3rXcQX5BK06+S9hHHAX3amW8X4IGK7+gbXSz7QWBM4ft5sjDto3ndKxXGzSAliq6+g9HFz6+G7XZINb/fdt7HbGC9wvObKraBjfL3Ogt4ojB+U9KB5sukA75zgUGFZW7bxXp/CNyYHy+Zt6OPV8xzPHBOV+9hQUocqzL3iJ38eNXCtEmFacXHlU4kVUPcKOkZSd+vcv2DgZkR8WqV898VEUsDy5COykbl8SuQSi335Qak14Dr83io7r0Ux60JrNq2rLy8H5BKU5CORocD/5F0T6GR/k/ADaS2lymSfiVpkXbW1d7n3q+wfEhVT23eJu0cOhQRd5De7w+BayPXvVa5znk+n0hHTTMK864JXFH4LB4n7aiK8XbkVtKP+tP58S2ko7zP5Oe1qOkzmQ8zYt4jt7Z11Lp9FT/njhwaEUu3DaTqxaLzgK9KEumo8pKIeK8wvfh9vUmqllqV9F19qmLb3ZNUmvrQayVNLJw8MKowzyciYpmIWCcifhgRrZJWlHRxbjCfRapaWb4i7nl+W5K+lhuD22LZoOI10wqP38nvp3JcNd9Be6rZbovxVvv7hZRUlyg8n0FKTOT38GD+Xr9IqmJrG39XROwWESuQ9l+fJtX8fGgZHTif1IaxGqnq66mIeKBiniVISatTC5I4ppA+3DZr5HGQikTF6orBHS0kIt6IiMMjYgiwE/AdSVu1Te5k/ZOAZWtt4M4/lG8Ce0v6OKm+9R1g/cKPcalIjXvVvpdinJNIRzJLF4YlImL7vP4nI2IPUlXAL4FLJQ2MiNkRcWxEjCDVR+5IRWNW1t7n3sK8P6L5cQGp2rCymqqrdU6l8JlIWpxUVG8zCdiu4vPoHxEvVhFTW+IYlR/fSteJo7NtZkG8Tdr5tFm5oxkrVLN9FbepNRY00Ii4i1TqG0WqWvpTxSzF72sQqa1wCum7urXiuxoUEQcVF19Yz/oxt3rn9i7C+kV+7YaRqmn3IpUE5gm9ENeawJnA/wOWyzvSR9t5TTW6+g7a22aq2W6Ln0W1v19I1WvDC88nAJ/PVYVViYh7gMtJyRRSqeVLXbzmBVIb8p6kA4r2fusfIVWzd6raxLGIpP6FoR9wEfBDSStIWp5UZXFBnv8S4OuSPpJ3JD/uaMGSdpQ0NB8dzSJl9bbTbaeR6tQ/JCKmkhpxT5O0jKRFJH26mjcTETOAs0h1nK2kDfQkSSvmmFYrtElU/V6yu4FZkr4naYCkvpI2kDQyL3svSSvk9b6WXzMn11t+NLfBzCIVPds77fgi4DBJa+cf/c+Bv1Qc7c6P35Lq2W+rcZ2XAjtK2kLSoqSqx+J29Qfg+LwjIG8vY6qM6VZSu8qAiJhM2ui3JSWmyiOlNh1uMwvoQdJRfN/cLtFZu90Hqty+9pE0Im9fx9Qp3vNJ7VAtuURZtH3h+/oZ8O+ImEQ6SWW4pL3z72kRSSPVeRtZtZYgVam9lo94j+hi/oGkHfPLAJK+ztydZE2q+A6mActJWqrwspq22xp+v5BOLihuP+eTDiCuyPuKvpL6k86Ialv+FpL2L8S/HrAzcFee5RhgM0knSlo5zzNU0gUVB9fnkZLx5uS2rcI6FgM+SWrn6lS1ieM6UsZuG35Cqru8l5Q9HyE13hwHEBF/J+2IbiZVQ/0rL6dYXG4zjJQt38zznRYRt+RpvyAlp9ckfbed1+5N+oL+Q6pT/naV7wfSWWDbS9qQdDbHU8BduRh9E6kev9b3QqRrTHYi1VM+SzraOYvUfgBpxzdR0pukhvLdI+Jd0hHspaSN7nHSTvMCPuwc0hHkbXn57wKH1PC+2xURMyNiQuSKzmrXGRETgYNJjZNTScXw4jnxp5CqBm+U9AZpQ/9UlTH9l7Rd3J6fzyKdPXNndHwtz9nAiLzNXFnNeqr0LdL3+hrpiK2WZXe1fZ1MOtPmqfy/Hv5E2tFWljYgfVfHkKqoPkl6P0TEG8DnSW1KU0jVe7+kUF2yAI4ltVe9DvyNdLTcoYh4DPhf0u9tGqkN484FWH9n38F/SAdHz+TtZlVq326r/f1CShTbSxqQ1/8u6QDpMdJnM4vUeD6SdFIHpO1uZ+CRvO+4HriC1F5HRDxNardZi7R/eZ10Zue9pLOp2lxKqq6fkA++i3YGbol0ckCn1P5+or7yEcujpAa6BT0ybqhmei/WvPJOaTqpveHJwvhzSQ3BP2xUbAaSfg5Mj4iTGx1LG0n/BvaNiEe7mrfbLrSR9AVS9hxIOmq5prfuaJvpvdhC4yDgnmLSsPKIiB80OoZKEVFVTQB075XjB5DqJ58m1fUd1PnspdZM78WanKTnSFVrhzc4FGtSPVJVZWZmzWNh6qvKzMzqoFd1JtZdZr/yjItd9iEDVh3V9Uy20Gl5/8X5uZZkHrXscxZZfsgCr6/enDjMzHpaa013higdJw4zs54WrY2OYIE4cZiZ9bRWJw4zM6tBuMRhZmY1cYnDzMxqMmd2oyNYIE4cZmY9zVVVZmZWE1dVmZlZLdw4bmZmtXGJw8zMauLGcTMzq4mrqszMrCauqjIzs5q4xGFmZjVxicPMzGoR4W7VzcysFnNaGh3BAnHiMDPraW7jMDOzmvgOgGZmVpNeXuLo0+gAzMwWOq2t1Q+dkDRY0s2SHpc0UdK38vhlJf1D0pP5/zKF1xwl6SlJT0jaZn7Cd+IwM+tp0Vr90LkW4PCI+AiwKXCwpBHA94EJETEMmJCfk6ftDqwPbAucJqlvreE7cZiZ9bSWluqHTkTE1Ii4Pz9+A3gcWA0YA5yXZzsP2CU/HgNcHBHvRcSzwFPAJrWG78RhZtbDIuZUPUgaJ+newjCuvWVKWgv4OPBvYKWImJrWFVOBFfNsqwGTCi+bnMfVxI3jZmY9rYYrxyNiPDC+s3kkDQIuA74dEbMkdThre6uoOpjMicPMrKfV8awqSYuQksaFEXF5Hj1N0ioRMVXSKsD0PH4yMLjw8tWBKbWu01VVZmY9rX5nVQk4G3g8In5TmHQ1MDY/HgtcVRi/u6TFJK0NDAPurjV8lzjMzHpa/boc2RzYG3hE0oN53A+AE4BLJO0LvADsChAREyVdAjxGOiPr4JiPjrOcOMzMelqdqqoi4g7ab7cA2KqD1xwPHL8g63XiMDPrae5W3czMauLEYWZmNenlfVU5cZiZ9TSXOMzMrCa+kZOZmdXEVVVmZlYTV1WVj6SBwLvzc2GLmVm3c+JoPEl9SH3M7wmMBN4DFpP0MnAdMD4inmxgiGZmc0XN/QqWSrP0VXUzsA5wFLByRAyOiBWBUcBdwAmS9mpkgGZmH6hTX1WN0hQlDmDriJhdOTIiZpJ6jbws9yBpZtZ4Pquq8dpLGm0kDYqINzubx8ysR5W0JFGtZqmq6sxjjQ7AzGweEdUPJdQUJQ5J3+loEjCoJ2MxM+uSSxyl8HNgGWCJimEQzfMezaxZuHG8FO4HroyI+yonSNqvAfGYmXUo5vTuS8yaJXF8HZjRwbSNezIQM7MulbQkUa2mSBwR8UTlOEkrR8RLETGtETGZmXWol/dV1cz1/9c1OgAzs3a1RvVDCTVFiaMDHd2H18yssVxVVVpnNjoAM7N2OXE0XtvV4cVxEXFaV/MsbKZOe5kf/OzXvDLzVfpIfHnMduy92y7c8M/bOe3sC3jm+UlcdObJbPCR4QC8OHUaO391HGutsToAG66/HscceUgj34J1s+HD1+HPF57+wfMha6/BT479Nbfe9i9OO/UEFuu/GC0tLRxyyA+4594HGxdob+ezqkrhKkkPAlcB90XEWwCShgBbAruRSiCXNizCEujXty9HHLI/I9Ydyltvvc1u+x7KZiM/ztAha3Lyz3/EsSf+9kOvGbzaKlx23u8bEK01wn//+zQbj/w8AH369OGF5+7jyqv+zhmnn8jPjvsN199wM9tt+1lO+MXRbPW5XRscbS9W0raLajVF43hEbAVMAA4AJkp6XdIM4AJgZWBsRCzUSQNgheWXZcS6QwEYOHBxhqw5mGkvz2CdtdZg7TVXb3B0VjZbfXYLnnnmeV544UUigiWWXAKAJZdagilTfbLiAonW6ocuSDpH0nRJjxbGbSTpLkkPSrpX0iaFaUdJekrSE5K2mZ/wm6XEQURch8+kqtqLU6fx+JNPs+H663Yx30t8eZ+DGTRwcQ7Zfyyf3GiDHorQGm233cZw8V+uBOA73z2G6679M7864Uf06SNGfWZMY4Pr7epb4jgXOBU4vzDuV8CxEfF3Sdvn56MljSDdu2h9YFXgJknDa73pXVOUONpI2jzf/Q9Je0n6jaQ1O5h3XM7E9551/kU9G2iDvf32Oxx29HF879ADGDRwYIfzrbDcMvzj8vO59Nzfc8Qh4zjy2F/y5ltv9WCk1iiLLLIIO+34eS697FoADhj3NQ4/4iesvc5IDj/iWM48438bHGHvFq2tVQ9dLiviNmBm5Whgyfx4KWBKfjwGuDgi3ouIZ4GngE2oUVMlDuB04G1JHwOOBJ5n3iz8gYgYHxEbR8TG+31tj56MsaFmt7Tw7aOPY4fPb8nnRm/e6byLLrooSy+Vtr311xvG4NVW4bkXXuyJMK3Btt12Sx544BGmT38FgK/tvStXXJEK9Jdeeg0jR27UwOiaQA3XcRQPcvMwroo1fBs4UdIk4Nekm9wBrAZMKsw3OY+rSbMljpaICFJWPSUiTiF1dmhARPDjX5zMkDUHM3b3L3Y5/8xXX2NOPvtj0otTeWHSFAavtkp3h2klsPtXdvmgmgpgytRpfObT/wPAZ7fcgieferZBkTWJOXOqHooHuXkYX8UaDgIOi4jBwGHA2Xl8e9e31Vxv1jRtHNkbko4C9gI+Lakv4Dv/ZQ88PJFrrp/AsHXW4ktjDwbgWweM5f3Zs/nFSacz87XX+eYRx7DesCGMP+l47nvwUU4960/07deXvn368OMj/h9LLek83OwGDOjP1lt9moO++b0Pxh144BH85jc/pV+/frz37rscdNCRDYywCXT/dRxjgW/lx38FzsqPJwODC/OtztxqrKopSnqjkPkhaWXgq8A9EXG7pDWA0RHRbnVVm9mvPNM8H4LVzYBVRzU6BCuhlvdfXOBeKd768e5V73MG/vTiLtcnaS3g2ojYID9/HDgoIm6RtBXwq4j4pKT1gT+T2jVWJZ2NOqzWxvGmK3GQqqjmSBoOrAcsXC3fZlZ+dezkUNJFwGhgeUmTgWOA/YFTJPUD3gXGAUTEREmXkO6M2gIcXGvSgOZLHLcBoyQtQ8qk9wJfAfZsaFRmZkV1PB03Ijo6u+eTHcx/PHD8gqyz2RKHIuJtSfsCv4uIX+Urys3MSiNa3OVImUjS/5BKGPvmcX0bGI+Z2Yf18i5Hmi1xfIt0vvIVuS5vCHBzg2MyM5tXL7+RU1MljnwF5W2F588AhzYuIjOzdrjEUR6SViBdMb4+0L9tfER8tmFBmZlViF6eOJrtyvELgf8AawPHAs8B9zQyIDOzD+nlt45ttsSxXEScDcyOiFsj4hvApo0OysxsHi1zqh9KqKmqqoDZ+f9USTuQLqX3jSbMrFxKWpKoVrMljuMkLQUcDvyO1K3wYY0NycxsXr29q6emSByS+gMHAkNJXQSfHRFbNjYqM7MOuMRRCueRqqluB7YDRjC3Z0gzs3Jx4iiFERHxUQBJZwN3NzgeM7MO9fbTcZslcbQ1ihMRLdIC93psZtZ9Wpw4yuBjkmblxwIG5OcCIiKW7PilZmY9yyWOEogId2RoZr2HE4eZmdWkd/dxWK4rxyXtKmmJ/PiHki6X9IlGx2VmVk/RGlUPZVSqxAH8KCLekLQFsA3pNNvTGxyTmVldRUtUPZRR2RJHW8csOwCnR8RVwKINjMfMrP5aaxhKqGxtHC9KOgPYGvilpMUoX3IzM1sgvfw+TqXbKe8G3ABsGxGvAcsCRzQ0IjOzeuvlJY5SJY6IeBuYDmyRR7UATzYuIjOz+ovW6ocyKlXikHQM8D3SfcMBFgEuaFxEZmbdoI4lDknnSJou6dGK8YdIekLSREm/Kow/StJTedo28xN+2do4vgB8HLgfICKmtJ2ea2bWLFpb6rq4c4FTgfPbRkjaEhgDbBgR70laMY8fAexOur32qsBNkoZHRE13jCpViQN4P1JH9QEgaWCD4zEzq7t6VlVFxG3AzIrRBwEnRMR7eZ7pefwY4OKIeC8ingWeAjapNf6yJY5L8llVS0vaH7gJOLPBMZmZ1Veo+mH+DAdGSfq3pFsljczjVwMmFeabnMfVpFRVVRHxa0mfA2YB6wI/joh/NDgsM7O6qqXRW9I4YFxh1PiIGN/Fy/oBywCbAiNJB+VDSB2/fiic6qOZu/BSyYnCycLMmla0Vl+SyEmiq0RRaTJwea76v1tSK7B8Hj+4MN/qwJQal12uqipJb0ialYd3Jc0pdJduZtYUWueo6mE+XQl8FkDScFIPHK8AVwO7S1pM0trAMObjxnelKnFExDxnUEnahflouDEzK7N6Xp8h6SJgNLC8pMnAMcA5wDn5FN33gbG59DFR0iXAY6Tr5A6u9YwqAKVllZekuyJi0+5cx+xXnin3h2ANMWDVUY0OwUqo5f0XF/gWo5NGblX1PmfwPRNKd0vTUpU4JH2x8LQPsDHz0XBjZlZmJT9e71KpEgewU+FxC/Ac6bxjM7OmUUvjeBmVKnFExNcbHYOZWXdz4qgDSb+jkyqpiDi0B8MxM+tWC3C2VCmUInEA9zY6ADOznhLzf0V4KZQicUTEeY2Owcysp5S1u/RqlSJxtJG0Aqlb9RFA/7bxEfHZhgVlZlZnrb28xFGqK8eBC4HHgbWBY0lnVd3TyIDMzOotQlUPZVS2xLFcRJwNzI6IWyPiG6ROuszMmka0quqhjEpVVQXMzv+nStqB1PnW6g2Mx8ys7nxWVX0dJ2kp4HDgd8CSwGGNDcnMrL56extH2RLHvyPideB1YMtGB2Nm1h3K2nZRrbK1cfyfpBsl7StpmUYHY2bWHSKqH8qoVIkjIoYBPyTdSP0+SddK2qvBYZmZ1VVrqOqhjEqVOAAi4u6I+A7pPhwzAV8caGZNpbVVVQ9lVKo2DklLAl8AdgfWAa7AN3IysyZT1pJEtUqVOICHSLc8/GlE/KunVrr8Wp/rqVVZL/L2f65odAjWpHp743jZEseQKPstCc3MFpBLHHXkpGFmC4PevqMrVeIwM1sYuMRhZmY1mePEseB8B0AzW5gEThz14DsAmtlCo7WXN3KUInH4DoBmtjBprWOJQ9I5wI7A9IjYoGLad4ETgRUi4pU87ihgX2AOcGhE3FDrOkuRONr4DoBmtjCoc1XVucCpwPnFkZIGA58DXiiMG0G6wHp9YFXgJknDI2JOLSssW5cjvgOgmTW91hqGrkTEbaTumSqdBBzJvO3HY4CLI+K9iHgWeIr56J2jbInDdwA0s6Y3B1U9SBon6d7CMK6r5UvaGXgxIh6qmLQaMKnwfHIeV5NSVVXhOwCa2UKgmpJEm4gYD4yvdn5JiwNHA59vb3J7q6ghHKB8icN3ADSzptfNp+OuQ6ruf0gSpIPv+yVtQiphDC7MuzrpAL0mpUocEXFtfug7AJpZ0+rO3tIj4hFgxbbnkp4DNo6IVyRdDfxZ0m9IjePDgLtrXUepEoekP9JOsSm3dZiZNYU6n457ETAaWF7SZOCY3Fb8IRExUdIlwGNAC3BwrWdUQckSB3Bt4XF/0r05ai5GmZmVWc176k5ExB5dTF+r4vnxwPELss5SJY6IuKz4PGfSmxoUjplZt2iVuxzpTsOANRodhJlZPfXyHkfKlTgkvcG8n+lLpCvJzcyaRi2n45ZRqRJHRCzR6BjMzLpbd55V1RNKdeW4pAnVjDMz681aUdVDGZWixCGpP7A46XSyZZh7deOSpHONzcyaxpxy5oOqlSJxAAcA3yYlifuYmzhmAb9vUExmZt3CbRx1EBGnAKdIOiQiftfoeMzMulNvP6uqVG0cQKukpdueSFpG0jcbGI+ZWd21qvqhjMqWOPaPiNfankTEq8D+jQvHzKz+6nk/jkYoRVVVQR9JiogAkNQXWLTBMZmZ1VVZE0K1ypY4bgAukfQHUjXggcD1jQ3JzKy+fFZVfX0PGAccRDqz6kbgzIZGZGZWZ729xFGqNo6IaI2IP0TElyPiS8BE0g2dzMyaRtQwlFHZShxI2gjYA/gK8CxweUMDMjOrs7KeLVWtUiQOScOB3UkJYwbwF0AR4bsAmlnT6e1VVaVIHMB/gNuBnSLiKQBJvte4mTWlet7IqRHK0sbxJVIX6jdLOlPSVlDS3r3MzBaQLwCsg4i4IiK+AqwH3AIcBqwk6XRJn29ocGZmddbbLwAsReJoExFvRcSFEbEjsDrwIPD9xkZlZlZfvf2sqlIljqKImBkRZ0TEZxsdi5lZPbUSVQ9lVJbGcTOzhUZZq6Cq5cRhZtbDfFaVmZnVpJ5nVUk6R9J0SY8Wxp0o6T+SHpZ0RcXtKo6S9JSkJyRtMz/xO3GYmfWwOrdxnAtsWzHuH8AGEbEh8F/gKABJI0gXW6+fX3Na7oW8Jk4cZmY9rJ5nVUXEbcDMinE3RkRLfnoX6SxVgDHAxRHxXkQ8CzwFbFJr/E2ZOCQNnJ8sambWE2q5jkPSOEn3FoZxNa7uG8Df8+PVgEmFaZPzuJo0ReO4pD6k4teewEjgPWAxSS8D1wHjI+LJBoZoZvaBOTWcZhsR44Hx87MeSUcDLcCFbaPaW0Wty22WEsfNwDqkeryVI2JwRKwIjCIV006QtFcjAzQza9MTV45LGgvsCOzZdldVUgljcGG21YEptS67KUocwNYRMbtyZETMBC4DLpO0SM+HZWb2Yd19YZ+kbUk3xvtMRLxdmHQ18GdJvwFWBYYBd9e6/KZIHO0ljTaSBkXEm53NY2bWk+qZNiRdBIwGlpc0GTiGVPuyGPAPSQB3RcSBETFR0iXAY6QqrIMjoubLSpoicXThMWCNRgdhZtamnleOR8Qe7Yw+u5P5jweOX5B1NkXikPSdjiYBg3oyFjOzrkRJ+6CqVlMkDuDnwImkolelZjkBwMyaRIsTRyncD1wZEfdVTpC0XwPi6RW+efDX+do+uxEBj018gm8eeCTfPfJgtt9ha1pbW3nl5RkcdMCRvPTS9EaHat3opZdn8INfn8Err75OH4kvb7cle+2yDTfc/m9Ov+AKnpk0hYtO/gnrDx/ywWvO+svVXH7DrfTt04fvH7Q3m39ywwa+g96nd6eN5jka/zrwfAfTNu7JQHqLVVZZiQMPGsvoUbvwP5tsR9++ffjSl3fityefyeab7sCozXbi+utv5ntHHdLoUK2b9e3bl+/u/1WuHv9LLjzpGC6+9iaefv5Fhq25Oif96Ft8coN155n/6edf5O+33sWVfziB0487guNOPY85c3p7f689q7d3q94UiSMinoiIVzqYNq2n4+kt+vbrx4AB/enbty8DBgzgpanTeOONNz+YPnDxAcw9/dua1QrLLs2IoWsB6Ttfe/CqTJsxkyFrrMbaq6/yoflvvus+tvvMpiy66CKsvvKKrLHqSjzy36d7OOrerbffAbApqqokjQd+FxGPtDNtIPAV4L2IuPBDL15ITZ06jd/99iweffx23n33Xf454Q7++c87APjRMYez+x5fYNasN9hx+z0bHKn1pBenvcx/nn6eDdcd2uE802a8yobrzZ2+0vLLMP2VV3sivKbR2xvHm6LEAZwG/EjS45L+Kum03NXw7cD/AUsAlzY2xHJZeukl2WGHrdlwg9GsO3QzFl98cXb7yhgAfnbs/7L+elvw179cxbgD9m5wpNZT3n7nXQ477rd874A9GTRwQIfztVcKzdcKWJV6e4mjKRJHRDwYEbuR+qn6PXA76QrJ/SLiYxFxSkS8V3xNseOw92fPakDUjTV6y815/rlJzHhlJi0tLVxz9Q18atNPzDPPXy+5mp3HVPbWbM1odksLhx33W3bYcjO23nxkp/OuvPyyTHt5xgfPp73yKisst3Q3R9hc5hBVD2XUFImjTb5C/JaIuCgiroyIJzqZd3xEbBwRGy+6yJI9GWYpTJo0hY032YgBA/oD8JnRm/HEE08zZJ21Pphnux225knXXTe9iOCYk89iyOBVGfvF7bqcf/Smn+Dvt97F++/PZvJL03l+ykt8dPg6PRBp82iNqHooo2Zp43iE9s9wExD5ZiZWcN+9D3HVlddz251X09Iyh4cfmsi551zM2X88iaHDhtDa2sqkF17ksG/9qNGhWjd7YOJ/uWbCnQxbazBfPvhoAA4duyuzZ7fw89PP59XX3+Cbx/wv6w1ZkzOOP5Kha67ONqM+xZgDvk+/vn04+ptj6du3qY5Bu10500H11AxnzUhas7PpEdHRqboALDVond7/IVjdvfzwRY0OwUpo0SGbLHCDzlfX/ELV+5w/P39F6RqQmqLE0VViMDMrk95+VlVTJA5Jd0TEFpLeYN5SYFtV1cLXiGFmpeUuR0ogIrbI/5dodCxmZl1xiaOEJK0I9G97HhEvNDAcM7N5lPX6jGo11akQknaW9CTwLHAr8Bxzb9JuZlYKEVH1UEZNlTiAnwGbAv+NiLWBrYA7GxuSmdm83MlhucyOiBlAH0l9IuJmYKMGx2RmNo/e3uVIs7VxvCZpEHAbcKGk6bR/cyczs4aZU9qUUJ2mKHFIarun+BjgbeAw4HrgaWCnRsVlZtae3t7G0SwljiuBT0TEW5Iui4gvAec1OCYzs3b17vJG8ySO4iX5Qzqcy8ysBHwdRzlEB4/NzEqnrGdLVasp2jiAj0malbsc2TA/niXpDUkL3802zKzU6tnGkW9aN13So4Vxy0r6h6Qn8/9lCtOOkvSUpCckbTM/8TdF4oiIvhGxZEQsERH98uO25+6nysxKZQ6tVQ9VOBeovOPa94EJETEMmJCfI2kEsDuwfn7NaZL61hp/UyQOM7PepJ43coqI24CZFaPHMPcEofOAXQrjL46I9yLiWeApYJNa43fiMDPrYVHDULzNdR7GVbGKlSJiKkD+v2IevxowqTDf5DyuJs3SOG5m1mvU0jgeEeOB8XVadXs3haq5pd6Jw8ysh/XAWVXTJK0SEVMlrQJMz+MnA4ML860OTKl14a6qMjPrYXOitephPl0NjM2PxwJXFcbvLmkxSWsDw4C7a124SxxmZj2snhcASroIGA0sL2kycAxwAnCJpH2BF4BdASJioqRLgMdI/fgdHBFzal2nE4eZWQ+rZx9UEbFHB5O26mD+44HjF2SdThxmZj2st1857sRhZtbDytrrbbWcOMzMephLHGZmVpMFOFuqFJw4zMx6mLtVNzOzmlTTB1WZOXGYmfUwlzjMzKwmLnGYmVlNXOIwM7Oa+KwqMzOrSThxmJlZLXwBoJmZ1cRdjpiZWU1c4jAzs5rMaXUbh5mZ1cCn45qZWU3cxmFmZjVxG4eZmdXEJQ4zM6uJ+6oyM7OauMsRMzOrSW+vqurT6ADMzBY2rRFVD12RdJikiZIelXSRpP6SlpX0D0lP5v/L1DN+Jw4zsx4WNfx1RtJqwKHAxhGxAdAX2B34PjAhIoYBE/LzunHiMDPrYfUscZCaHAZI6gcsDkwBxgDn5ennAbvUM363cZiZ9bDWOjWOR8SLkn4NvAC8A9wYETdKWikipuZ5pkpasS4rzFziMDPrYRFR9SBpnKR7C8O4tuXktosxwNrAqsBASXt1d/wucZiZ9bBazqqKiPHA+A4mbw08GxEvA0i6HNgMmCZplVzaWAWYvoAhz8MlDjOzHhY1DF14AdhU0uKSBGwFPA5cDYzN84wFrqpn/Ort5xNbfUkal49wzD7g7aK8JB0LfAVoAR4A9gMGAZcAa5CSy64RMbNu63TisCJJ90bExo2Ow8rF24UVuarKzMxq4sRhZmY1ceKwSq7HtvZ4u7APuI3DzMxq4hKHmZnVxInDzMxq4sRhZmY1ceIoEUlzJD2Y+9X/q6TFF2BZ50r6cifTb5H0hKSHJN0pad35XVc7yz5Z0qc7mHa9pNckXVsx/mJJw+oVQ7Nr0LbyYB46m/csSSPy4+ckLZ8fD5B0q6S++bm3g17MiaNc3omIjXK/+u8DBxYntv3o6mjPiPgYqdvlE+uxQEnLAptGxG0dzHIisHc7408HjqxHDAuJRmwrG+Xh0o5mioj9IuKxdiZ9A7g8Iubk594OejEnjvK6HRgqabSkmyX9GXhEUl9JJ0q6R9LDkg4AUHKqpMck/Q2opRvl2/K61pJ0u6T787BZXvYqkm4rHOGOynGcm58/IumwvKwvA9d3tKKImAC80cH73TrfU8Bq05PbCnkZp+eeWifmLi/axt8iqb0rzPek0F+St4PezV9OCeUfzXbM3QFvAmwQEc/mLpVfj4iRkhYD7pR0I/BxYF3go8BKwGPAOVWucifgEVIPmp+LiHdzdcFFwMbAV4EbIuL4fCS7OLARsFo+4kXS0nlZmwMdHpF2JCJaJT0FfAy4r9bXL6x6cFu5UNI7+fFWwNERMTNvDxMkbRgRD3cQ46LAkIh4rqv34+2gd3DiKJcBkh7Mj28HziZ1kXx3RDybx38e2LBQz7wUMAz4NHBRrgqYIumfVayvbWfwHHAIsAhwqqSNgDnA8DzfPcA5khYBroyIByU9AwyR9Dvgb8CNed5VgJdrfufJdNI9BbzD6FpPbyt7RsS9bU8kHZgTUz/Sdz4CaDdxAMsDr1X7xvB2UHpOHOXyTkRsVBwhCeCt4ijgkIi4oWK+7amqF+Z5VO4MfgJMIx3t9QHeBYiI23Jj9w7AnySdGBHnS/oYsA1wMLAbqR77HaB/Xt6ngDPy4n8cEVd3EU///HrrWk9vK8XXrw18FxgZEa9KOpf8nXcUaxfTK3k7KDm3cfQ+NwAH5aN/JA2XNJDUTrF7rtdeBdhyPpa9FDA1IlpJDZdtZ8CsCUyPiDNJR7afyGfL9ImIy4AfAZ/Iy3gcGAoQEf8uNKh2lTQglXAmzkfc1r7u2laWJCWo1yWtRKoq61BEvAr0lVRt8vB2UHIucfQ+ZwFrAfcrHWK+TLoR/RXAZ0ltFf8Fbp2PZZ8GXCZpV+Bm5h69jgaOkDQbeBP4GrAa8EdJbQcfR+X/fwMOyHF+iKTbgfWAQZImA/tGxA15B/RO232SrS66ZVuJiIckPUDauT8D3FnFy24EtgBuAm8HvZ37qrK6k3QHsGNEvFbDaw4DZkXE2d0WmDWMpI8D34mI9k7BLc7n7aAXcFWVdYfDSXceq8VrpOtJrAlFxAPAzer6+pLX8HZQei5xNDlJVwBrV4z+XmWDqZm3FauWE4eZmdXEVVVmZlYTJw4zM6uJE4c1jLqph1cVemjtYN7Rbf1w1biOD3p7rVjvARXjdpF0XTWxmvVGThzWSN3Sw2snPbS2GU3qnqMeLgJ2rxi3ex5v1pScOKws6tbDa7GHVknbKvX0+5CkCZLWIiWow3JpZ5SkFSRdltdxj6TN82uXk3SjpAcknUHqwqPSTcB6+Qpscqlpa+BKST/Oy3tU0vh8Ed48NO89KzaWdEt+PFDSOfn1D0gak8evL+nuHPvD8r0rrAGcOKzhNLeH10fyqE1Iva+OAPYl9/AKjAT2z30lfYG5PbzuTzslCEkrAGcCX8r3Hdk199D6B+CkXNq5HTglPx8JfIm5V70fA9wRER8Hrqada1NyR4GXk/rqAtgZuDki3gBOjYiRuUQ1ANixho/laOCfOaYtgRNzdyEHAqfkfqo2BibXsEyzunCXI9ZI3d3D66bAbW3LioiZHcSxNTCiUCBYUtISeR1fzK/9m6RXO3j9RaQbE51CqqY6P4/fUtKRpG7olyV10XFNB8uo9HlgZ0nfzc/7kxLXv4CjJa1OujHSk1Uuz6xunDiskbq7h1dVMQ+kkvf/RMQ8PbLmWKp5/Z3AKkq9BW9G6kCwP6nvr40jYpJSz8PtdfLXwtySf3G6SCWlJyrmf1zSv0k9Fd8gab+IqKZbdLO6cVWVld2C9PD6L+AzuWqr7ba2kO48t0RhvhuB/9f2ROl+JOR17JnHbQcs016Aka6ivYTUVcZ1EfEuc5PAK5IGke6M2J7ngE/mx1+qeN+HtLWL5L6ekDQEeCYifkuqPtuwg+WadRsnDiu7s0h3qLtf0qOk+3v0I/Xw+iSpXeR02unhNSJeBsYBl0t6CPhLnnQN8IW2xnHgUGDj3Nj8GHPP7joW+LSk+0lVRy90EudFpPuYXJzX/RqpfeUR4ErSzbDacyxwilJvsXMK439GurHWw/l9/yyP/wrwaK7iW4+51WJmPcZdjpiZWU1c4jAzs5o4cZiZWU2cOMzMrCZOHGZmVhMnDjMzq4kTh5mZ1cSJw8zMavL/ATMXqe1HYqFJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report for Logistic Regression Model with tuned Hyper-Parameter (GSCV) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.72      0.73      0.73       293\n",
      "           1       0.73      0.72      0.72       293\n",
      "\n",
      "    accuracy                           0.73       586\n",
      "   macro avg       0.73      0.73      0.73       586\n",
      "weighted avg       0.73      0.73      0.73       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running the model of Test Dataset\n",
    "#Predicting the values for Test Set on the trained Model\n",
    "logi_grid_pred = logi_grid.predict(x_te_ss)\n",
    "\n",
    "#Scoring the Model on Test Set\n",
    "logi_grid_score = logi_grid.score(x_te_ss, y_te)\n",
    "print('The Score/Accuracy of the Logistic Regression Model on Test Data is with Hyper-Parameter Tuning (GSCV) is:', logi_grid_score, '\\n')\n",
    "\n",
    "#Generating the Confuision Matrix\n",
    "print('The Confusion Matrix of the Logistic Regression Model with tune Hyper-Parameters (GSCV)')\n",
    "logi_grid_conmat = metrics.confusion_matrix(y_te, logi_grid_pred, labels=[-1,1])\n",
    "sns.heatmap(logi_grid_conmat, fmt='g', annot=True, yticklabels=['Pass(-1)', 'Fail(1)'], xticklabels=['Pred_Pass(-1)', 'Pred_Fail(1)'])\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Logistic Regression Model with Tuned Hyper-Parameters (GSCV)')\n",
    "plt.show();\n",
    "\n",
    "#Generating the Classification Report\n",
    "logi_grid_cr = metrics.classification_report(y_te, logi_grid_pred)\n",
    "print('The Classification Report for Logistic Regression Model with tuned Hyper-Parameter (GSCV) \\n', logi_grid_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d144c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using RandomizedSearchCV to tune the Hper-Parameters of Logistic Regression Model\n",
    "logi_random = RandomizedSearchCV(logi, param_distributions=logi_para, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ff8d7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "40 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 48, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got lfbgs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.7508547  0.74700855 0.74316239        nan 0.74871795 0.74615385\n",
      "        nan        nan 0.74273504        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "                   param_distributions={&#x27;C&#x27;: [0.1, 1, 10],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;,\n",
       "                                                        &#x27;multinomial&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;,\n",
       "                                                    &#x27;none&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lfbgs&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;],\n",
       "                                        &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "                   param_distributions={&#x27;C&#x27;: [0.1, 1, 10],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;,\n",
       "                                                        &#x27;multinomial&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;,\n",
       "                                                    &#x27;none&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lfbgs&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;],\n",
       "                                        &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': [0.1, 1, 10],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'multi_class': ['auto', 'ovr',\n",
       "                                                        'multinomial'],\n",
       "                                        'penalty': ['elasticnet', 'l1', 'l2',\n",
       "                                                    'none'],\n",
       "                                        'solver': ['liblinear', 'lfbgs', 'sag',\n",
       "                                                   'saga'],\n",
       "                                        'tol': [1e-05, 0.0001, 0.001]})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the Model with Trainig Dataset\n",
    "logi_random.fit(x_tr_ss, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e63bc544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 1e-05,\n",
       " 'solver': 'liblinear',\n",
       " 'penalty': 'l2',\n",
       " 'multi_class': 'ovr',\n",
       " 'class_weight': None,\n",
       " 'C': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters\n",
    "logi_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8f26c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7508547008547009"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best Score\n",
    "logi_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7dd27f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score/Accuracy of the Logistic Regression Model on Test Data is with Hyper-Parameter Tuning (RSCV) is: 0.7218430034129693 \n",
      "\n",
      "The Confusion Matrix of the Logistic Regression Model with tune Hyper-Parameters (RSCV)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report for Logistic Regression Model with Hyper-Parameter Tuning (RSCV) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.76      0.73       293\n",
      "           1       0.74      0.69      0.71       293\n",
      "\n",
      "    accuracy                           0.72       586\n",
      "   macro avg       0.72      0.72      0.72       586\n",
      "weighted avg       0.72      0.72      0.72       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running the model of Test Dataset\n",
    "#Predicting the values for Test Set on the trained Model\n",
    "logi_random_pred = logi_random.predict(x_te_ss)\n",
    "\n",
    "#Scoring the Model on Test Set\n",
    "logi_random_score = logi_random.score(x_te_ss, y_te)\n",
    "print('The Score/Accuracy of the Logistic Regression Model on Test Data is with Hyper-Parameter Tuning (RSCV) is:', logi_random_score, '\\n')\n",
    "\n",
    "#Generating the Confuision Matrix\n",
    "print('The Confusion Matrix of the Logistic Regression Model with tune Hyper-Parameters (RSCV)')\n",
    "logi_random_conmat = metrics.confusion_matrix(y_te, logi_random_pred, labels=[-1,1])\n",
    "sns.heatmap(logi_random_conmat, fmt='g', annot=True, yticklabels=['Pass(-1)', 'Fail(1)'], xticklabels=['Pred_Pass(-1)', 'Pred_Fail(1)'])\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Logistic Regression Model with Tuned Hyper-Parameters (RSCV)')\n",
    "plt.show();\n",
    "\n",
    "#Generating the Classification Report\n",
    "logi_random_cr = metrics.classification_report(y_te, logi_random_pred)\n",
    "print('The Classification Report for Logistic Regression Model with Hyper-Parameter Tuning (RSCV) \\n', logi_random_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd2e45f",
   "metadata": {},
   "source": [
    "- Here we observed the accuracies as follows:\n",
    "    - Basic Logistic Regression Model (Logi): 72.18%\n",
    "    - Hyper-Parameter Tune with GridSearchCV (GSCV): 72.52%\n",
    "    - Hyper-Parameter Tune with RandomizedSearchCV (RSCV): 72.18%\n",
    "- We can see that the basic model & RandomizedSearchCV has hit the same result.\n",
    "- But a very slight improvement can be seen in GSCV model.\n",
    "- The Recall for 1-Fail has also increased in the GSCV model which better predicts the failed products which is much useful to us rather than just imporving the accuracy of model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c21f808",
   "metadata": {},
   "source": [
    "#### 5D. Use any other technique/method which can enhance the model performance. [4 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5fd7b699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=91)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=91)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=91)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have already Removed various attribute, Standardization/Normalisation, target balancing previously.\n",
    "\n",
    "#We have not done Dimensionality Reduction, hence we try the model with Dimensionality Reduction\n",
    "xros_pca = PCA(n_components=len(xros_ss.columns))\n",
    "xros_pca.fit(xros_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d778bda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precise Variance Covered by Minimum Required Components (i.e. 62) for 90% or above: 0.9025870298352955 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking number of components required for minimum 90% of explianed variance\n",
    "for var in range(1, len(xros_pca.explained_variance_ratio_)):\n",
    "    if np.cumsum(xros_pca.explained_variance_ratio_)[var]<0.90:\n",
    "        var+=1\n",
    "    else:\n",
    "        thresh = var+1\n",
    "        break;\n",
    "print('Precise Variance Covered by Minimum Required Components (i.e. {}) for 90% or above: {}'.format(thresh, np.cumsum(xros_pca.explained_variance_ratio_)[thresh-1]), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b742f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying PCA with 62 components\n",
    "xros_pca_r = PCA(n_components=62)\n",
    "xros_pca62 = pd.DataFrame(xros_pca_r.fit_transform(xros_ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "912f0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataframe into train & test set after performing PCA\n",
    "xpca_tr, xpca_te, ypca_tr, ypca_te = train_test_split(xros_pca62, yros, test_size=0.2, stratify=yros, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab0c2d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score/Accuracy of the Logistic Regression Model on Test Data after performing PCA is: 0.7610921501706485 \n",
      "\n",
      "The Confusion Matrix of the Logistic Regression Model after performing PCA\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report for Logistic Regression Model after performing PCA\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.78      0.77       293\n",
      "           1       0.77      0.74      0.76       293\n",
      "\n",
      "    accuracy                           0.76       586\n",
      "   macro avg       0.76      0.76      0.76       586\n",
      "weighted avg       0.76      0.76      0.76       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting this dataframe on Logistic Regression \n",
    "pca_logi = LogisticRegression()\n",
    "pca_logi.fit(xpca_tr, ypca_tr)\n",
    "\n",
    "#Predicting the values for test Set on the trained Model\n",
    "pca_logi_pred = pca_logi.predict(xpca_te)\n",
    "\n",
    "#Scoring the Model on Test Set\n",
    "pca_logi_score = pca_logi.score(xpca_te, ypca_te)\n",
    "print('The Score/Accuracy of the Logistic Regression Model on Test Data after performing PCA is:', pca_logi_score, '\\n')\n",
    "\n",
    "#Generating the Confuision Matrix\n",
    "print('The Confusion Matrix of the Logistic Regression Model after performing PCA')\n",
    "pca_logi_conmat = metrics.confusion_matrix(ypca_te, pca_logi_pred, labels=[-1,1])\n",
    "sns.heatmap(pca_logi_conmat, fmt='g', annot=True, yticklabels=['Pass(-1)', 'Fail(1)'], xticklabels=['Pred_Pass(-1)', 'Pred_Fail(1)'])\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Logistic Regression Model after performing PCA')\n",
    "plt.show();\n",
    "\n",
    "#Generating the Classification Report\n",
    "pca_logi_cr = metrics.classification_report(ypca_te, pca_logi_pred)\n",
    "print('The Classification Report for Logistic Regression Model after performing PCA\\n', pca_logi_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "471e70db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1113: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5220 fits failed out of a total of 8640.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 48, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got lfbgs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "360 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1149, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 97, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72136752 0.72136752 0.72136752        nan        nan        nan\n",
      "        nan        nan        nan 0.72179487 0.72136752 0.72136752\n",
      " 0.73504274 0.73504274 0.73504274        nan        nan        nan\n",
      " 0.73333333 0.73333333 0.73333333 0.73162393 0.73162393 0.73162393\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73675214 0.73632479 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72136752 0.72136752 0.72179487        nan        nan        nan\n",
      "        nan        nan        nan 0.72179487 0.72136752 0.72136752\n",
      " 0.73504274 0.73504274 0.73504274        nan        nan        nan\n",
      " 0.73333333 0.73333333 0.73333333 0.73162393 0.73162393 0.73162393\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73675214 0.73717949 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.72435897 0.72393162 0.72350427\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73760684 0.73760684 0.73803419 0.73675214 0.73717949 0.73717949\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73803419 0.73760684 0.73888889 0.73931624 0.73888889\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72136752 0.72136752 0.72136752        nan        nan        nan\n",
      "        nan        nan        nan 0.72136752 0.72136752 0.72136752\n",
      " 0.73504274 0.73504274 0.73504274        nan        nan        nan\n",
      " 0.73333333 0.73333333 0.73333333 0.73162393 0.73162393 0.73162393\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73632479 0.73675214 0.73632479\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.72136752 0.72136752 0.72136752        nan        nan        nan\n",
      "        nan        nan        nan 0.72179487 0.72136752 0.72136752\n",
      " 0.73504274 0.73504274 0.73504274        nan        nan        nan\n",
      " 0.73333333 0.73333333 0.73333333 0.73162393 0.73162393 0.73162393\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73632479 0.73632479 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.72307692 0.72393162 0.72350427\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73760684 0.73760684 0.73760684 0.73717949 0.73717949 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73803419 0.73760684 0.73888889 0.73931624 0.73888889\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      "        nan        nan        nan 0.73418803 0.73418803 0.73461538\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      " 0.73888889 0.73931624 0.73888889 0.73589744 0.73589744 0.73589744\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73632479 0.73675214 0.73632479\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      "        nan        nan        nan 0.73418803 0.73418803 0.73418803\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      " 0.73846154 0.73888889 0.73846154 0.73589744 0.73589744 0.73589744\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73632479 0.73675214 0.73632479\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73846154 0.73846154 0.73846154\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73803419 0.73888889 0.73846154 0.73846154 0.73803419\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73803419 0.73760684 0.73931624 0.73888889 0.73888889\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      "        nan        nan        nan 0.73418803 0.73418803 0.73418803\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      " 0.73888889 0.73803419 0.73803419 0.73675214 0.73589744 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73974359 0.73931624 0.73931624 0.73632479 0.73632479 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      "        nan        nan        nan 0.73418803 0.73418803 0.73418803\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      " 0.73888889 0.73888889 0.73888889 0.73589744 0.73589744 0.73589744\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73675214 0.73632479 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73846154 0.73846154 0.73846154\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73803419 0.73888889 0.73803419 0.73846154 0.73846154\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73803419 0.73760684 0.73931624 0.73931624 0.73931624\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73846154 0.73846154 0.73846154        nan        nan        nan\n",
      "        nan        nan        nan 0.73589744 0.73589744 0.73589744\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73675214 0.73675214 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73675214 0.73632479 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73846154 0.73846154 0.73803419        nan        nan        nan\n",
      "        nan        nan        nan 0.73632479 0.73589744 0.73589744\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73888889 0.73632479 0.73675214 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73675214 0.73675214 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73846154 0.73888889 0.73846154\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73760684 0.73803419 0.73760684 0.73888889 0.73888889 0.73888889\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73803419 0.73760684 0.73931624 0.73931624 0.73888889\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73846154 0.73846154 0.73846154        nan        nan        nan\n",
      "        nan        nan        nan 0.73589744 0.73589744 0.73589744\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73675214 0.73675214 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73717949 0.73632479 0.73632479\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73846154 0.73846154 0.73803419        nan        nan        nan\n",
      "        nan        nan        nan 0.73589744 0.73589744 0.73632479\n",
      " 0.73888889 0.73888889 0.73888889        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73675214 0.73675214 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73931624 0.73931624 0.73931624 0.73632479 0.73632479 0.73675214\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.73846154 0.73888889 0.73888889\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73760684 0.73760684 0.73846154 0.73888889 0.73888889\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.73803419 0.73803419 0.73760684 0.73888889 0.73931624 0.73888889]\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;, &#x27;multinomial&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lfbgs&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;],\n",
       "                         &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;, &#x27;multinomial&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lfbgs&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;],\n",
       "                         &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'class_weight': ['balanced', None],\n",
       "                         'multi_class': ['auto', 'ovr', 'multinomial'],\n",
       "                         'penalty': ['elasticnet', 'l1', 'l2', 'none'],\n",
       "                         'solver': ['liblinear', 'lfbgs', 'sag', 'saga'],\n",
       "                         'tol': [1e-05, 0.0001, 0.001]})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the same above paramenter of Logistic Regression used in GSCV, we perform GSCV after PCA\n",
    "pca_logi_grid = GridSearchCV(pca_logi, param_grid=logi_para, cv=10)\n",
    "\n",
    "#Fitting the Model\n",
    "pca_logi_grid.fit(xpca_tr, ypca_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c23b5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1,\n",
       " 'class_weight': None,\n",
       " 'multi_class': 'auto',\n",
       " 'penalty': 'none',\n",
       " 'solver': 'sag',\n",
       " 'tol': 1e-05}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best Parameters\n",
    "pca_logi_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d571556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7397435897435898"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best score\n",
    "pca_logi_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1fa7dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score/Accuracy of the Logistic Regression Model on Test Data is after performing PCA with Hyper-Parameter Tuning (GSCV) is: 0.7559726962457338 \n",
      "\n",
      "The Confusion Matrix of the Logistic Regression Model after performing PCA with tune Hyper-Parameters (GSCV)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report for Logistic Regression Model after performing PCA with tuned Hyper-Parameter (GSCV) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.77      0.76       293\n",
      "           1       0.77      0.74      0.75       293\n",
      "\n",
      "    accuracy                           0.76       586\n",
      "   macro avg       0.76      0.76      0.76       586\n",
      "weighted avg       0.76      0.76      0.76       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running the model of Test Dataset\n",
    "#Predicting the values for Test Set on the trained Model\n",
    "pca_logi_grid_pred = pca_logi_grid.predict(xpca_te)\n",
    "\n",
    "#Scoring the Model on Test Set\n",
    "pca_logi_grid_score = pca_logi_grid.score(xpca_te, ypca_te)\n",
    "print('The Score/Accuracy of the Logistic Regression Model on Test Data is after performing PCA with Hyper-Parameter Tuning (GSCV) is:', pca_logi_grid_score, '\\n')\n",
    "\n",
    "#Generating the Confuision Matrix\n",
    "print('The Confusion Matrix of the Logistic Regression Model after performing PCA with tune Hyper-Parameters (GSCV)')\n",
    "pca_logi_grid_conmat = metrics.confusion_matrix(ypca_te, pca_logi_grid_pred, labels=[-1,1])\n",
    "sns.heatmap(pca_logi_grid_conmat, fmt='g', annot=True, yticklabels=['Pass(-1)', 'Fail(1)'], xticklabels=['Pred_Pass(-1)', 'Pred_Fail(1)'])\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Logistic Regression Model after performing PCA with Tuned Hyper-Parameters (GSCV)')\n",
    "plt.show();\n",
    "\n",
    "#Generating the Classification Report\n",
    "pca_logi_grid_cr = metrics.classification_report(ypca_te, pca_logi_grid_pred)\n",
    "print('The Classification Report for Logistic Regression Model after performing PCA with tuned Hyper-Parameter (GSCV) \\n', pca_logi_grid_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c378c00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 48, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got lfbgs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.73931624        nan        nan        nan        nan\n",
      " 0.73931624 0.73846154        nan 0.73846154]\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "                   param_distributions={&#x27;C&#x27;: [0.1, 1, 10],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;,\n",
       "                                                        &#x27;multinomial&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;,\n",
       "                                                    &#x27;none&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lfbgs&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;],\n",
       "                                        &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "                   param_distributions={&#x27;C&#x27;: [0.1, 1, 10],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;,\n",
       "                                                        &#x27;multinomial&#x27;],\n",
       "                                        &#x27;penalty&#x27;: [&#x27;elasticnet&#x27;, &#x27;l1&#x27;, &#x27;l2&#x27;,\n",
       "                                                    &#x27;none&#x27;],\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lfbgs&#x27;, &#x27;sag&#x27;,\n",
       "                                                   &#x27;saga&#x27;],\n",
       "                                        &#x27;tol&#x27;: [1e-05, 0.0001, 0.001]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "                   param_distributions={'C': [0.1, 1, 10],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'multi_class': ['auto', 'ovr',\n",
       "                                                        'multinomial'],\n",
       "                                        'penalty': ['elasticnet', 'l1', 'l2',\n",
       "                                                    'none'],\n",
       "                                        'solver': ['liblinear', 'lfbgs', 'sag',\n",
       "                                                   'saga'],\n",
       "                                        'tol': [1e-05, 0.0001, 0.001]})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using the same above paramenter of Logistic Regression used in RSCV, we perform RSCV after PCA\n",
    "pca_logi_random = RandomizedSearchCV(pca_logi, param_distributions=logi_para, cv=10)\n",
    "\n",
    "#Fitting the Model\n",
    "pca_logi_random_fit = pca_logi_random.fit(xpca_tr, ypca_tr)\n",
    "pca_logi_random_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d9bbf96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tol': 0.001,\n",
       " 'solver': 'sag',\n",
       " 'penalty': 'l2',\n",
       " 'multi_class': 'ovr',\n",
       " 'class_weight': None,\n",
       " 'C': 10}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best parameters =\n",
    "pca_logi_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76f4bb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7393162393162394"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best Score\n",
    "pca_logi_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "202c0a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Score/Accuracy of the Logistic Regression Model on Test Data after performing PCA is with Hyper-Parameter Tuning (RSCV) is: 0.7559726962457338 \n",
      "\n",
      "The Confusion Matrix of the Logistic Regression Model after performing PCA with tune Hyper-Parameters (RSCV)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classification Report for Logistic Regression Model after performing PCA with Hyper-Parameter Tuning (RSCV) \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.77      0.76       293\n",
      "           1       0.77      0.74      0.75       293\n",
      "\n",
      "    accuracy                           0.76       586\n",
      "   macro avg       0.76      0.76      0.76       586\n",
      "weighted avg       0.76      0.76      0.76       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Running the model of Test Dataset\n",
    "#Predicting the values for Test Set on the trained Model\n",
    "pca_logi_random_pred = pca_logi_random.predict(xpca_te)\n",
    "\n",
    "#Scoring the Model on Test Set\n",
    "pca_logi_random_score = pca_logi_random.score(xpca_te, ypca_te)\n",
    "print('The Score/Accuracy of the Logistic Regression Model on Test Data after performing PCA is with Hyper-Parameter Tuning (RSCV) is:', pca_logi_random_score, '\\n')\n",
    "\n",
    "#Generating the Confuision Matrix\n",
    "print('The Confusion Matrix of the Logistic Regression Model after performing PCA with tune Hyper-Parameters (RSCV)')\n",
    "pca_logi_random_conmat = metrics.confusion_matrix(ypca_te, pca_logi_random_pred, labels=[-1,1])\n",
    "sns.heatmap(pca_logi_random_conmat, fmt='g', annot=True, yticklabels=['Pass(-1)', 'Fail(1)'], xticklabels=['Pred_Pass(-1)', 'Pred_Fail(1)'])\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual values')\n",
    "plt.title('Logistic Regression Model after performing PCA with Tuned Hyper-Parameters (RSCV)')\n",
    "plt.show();\n",
    "\n",
    "#Generating the Classification Report\n",
    "pca_logi_random_cr = metrics.classification_report(ypca_te, pca_logi_random_pred)\n",
    "print('The Classification Report for Logistic Regression Model after performing PCA with Hyper-Parameter Tuning (RSCV) \\n', pca_logi_random_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfede4a9",
   "metadata": {},
   "source": [
    "- Here we observed the accuracies as follows:\n",
    "    - Basic Logistic Regression Model after performing PCA (Logi): 76.11%\n",
    "    - Hyper-Parameter Tune with GridSearchCV (GSCV) after performing PCA: 75.59%\n",
    "    - Hyper-Parameter Tune with RandomizedSearchCV (RSCV) after performing PCA: 75.59%\n",
    "- We can see that the GSCV & RSCV has hit the same result.\n",
    "- A very slight improvement can be seen in GSCV & RSCV model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c97fb",
   "metadata": {},
   "source": [
    "#### 5E. Display and explain the classification report in detail. [3 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02163ef6",
   "metadata": {},
   "source": [
    "The Classification Report of all the model of Logistic Regression (Base, GSCV & RSCV) and model after performing PCA are displayed along-with all the model itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad61bc",
   "metadata": {},
   "source": [
    "##### Observations:\n",
    "*Before performing PCA:\n",
    "- The base model & RSCV has same result. While a very slight improvement is seen in GSCV model.\n",
    "- In GSCV model, recall for '1' has increased which is an important factor in predicting the failure of products which means that predicting Failed products has improved, while on the contrary the recall for '-1' has comparatively decreased.\n",
    "- For Precision, in GSCV model, for '-1' has increased, while that of '1' has decreased, compared to that of base & RSCV model. Although, the true predictions of '1' has increased, contrary to recall, precision has decreased as it has wrongly predicted '-1' as 1.\n",
    "- Due to increase in recall, although precision has decreased, the f1-score of '-1' has increased in GSCV model.\n",
    "\n",
    "*After performing PCA:\n",
    "- The main noticeable difference is that with decrease in dimensions/Features, the overall accuracy of model has increased for base, GSCV & RSCV model.\n",
    "- Here the GSCV & RSCV model has hit the same result. This is what is mentioned & proved by Brgstra in his paper that RSCV has probably equal or more chance of hitting the right parameter combination rather than GSCV.\n",
    "- It is observed that recall, precision & f1-score for both the classes '-1' & '1' has been almost same.\n",
    "\n",
    "\n",
    "Here it should be noted that after performing PCA the accuracy of models have increased.\n",
    "\n",
    "Further there seems not much of a difference in accuracy of model even after tuining of Hyper-Parameter because Logistic Regression model bydefault tries to fit the model with best parameters & also there are not many parameter unlike other model in which Hyper-Parameters can be played with to notch up the accuracy of model by tuining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f9022",
   "metadata": {},
   "source": [
    "#### 5F. Apply the above steps for all possible models that you have learnt so far. [5 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da0fd9",
   "metadata": {},
   "source": [
    "Initially we build simple model for each supervised learning techniques with PCA & no hypertuining of parameters and later on we run the same model with hypertuning parameters & performing PCA to compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67975077",
   "metadata": {},
   "source": [
    "##### Building all the models without PCA & without Hypertuning of Parameters\n",
    "\n",
    "We have already Upsampled the dataset in 4B and then Standardized & split it into train & test sets in 4C. Hence we use same models:\n",
    "\n",
    "x_tr_ss, x_te_ss, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bac072aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to run all the models\n",
    "def fun(model, x_tr_ss, x_te_ss, y_tr, y_te):\n",
    "    t_start = time.time()\n",
    "    model.fit(x_tr_ss, y_tr)\n",
    "    score_train = model.score(x_tr_ss, y_tr)\n",
    "    score_test = model.score(x_te_ss, y_te)\n",
    "    pred = model.predict(x_te_ss)\n",
    "    t_end = time.time()\n",
    "    duration = t_end-t_start\n",
    "    return score_train, score_test, duration, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d39f8222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building all models\n",
    "lr = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svm = SVC()\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "bag = BaggingClassifier(random_state=1)\n",
    "adb = AdaBoostClassifier(random_state=1)\n",
    "gb = GradientBoostingClassifier(random_state=1)\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "xgb = XGBClassifier()\n",
    "cgb = CatBoostClassifier()\n",
    "lgb = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2408f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.014811\n",
      "0:\tlearn: 0.6864383\ttotal: 249ms\tremaining: 4m 9s\n",
      "1:\tlearn: 0.6782605\ttotal: 288ms\tremaining: 2m 23s\n",
      "2:\tlearn: 0.6701129\ttotal: 320ms\tremaining: 1m 46s\n",
      "3:\tlearn: 0.6629333\ttotal: 438ms\tremaining: 1m 49s\n",
      "4:\tlearn: 0.6543224\ttotal: 477ms\tremaining: 1m 34s\n",
      "5:\tlearn: 0.6471920\ttotal: 513ms\tremaining: 1m 25s\n",
      "6:\tlearn: 0.6407273\ttotal: 603ms\tremaining: 1m 25s\n",
      "7:\tlearn: 0.6347969\ttotal: 645ms\tremaining: 1m 20s\n",
      "8:\tlearn: 0.6274130\ttotal: 685ms\tremaining: 1m 15s\n",
      "9:\tlearn: 0.6198474\ttotal: 779ms\tremaining: 1m 17s\n",
      "10:\tlearn: 0.6135204\ttotal: 822ms\tremaining: 1m 13s\n",
      "11:\tlearn: 0.6071078\ttotal: 856ms\tremaining: 1m 10s\n",
      "12:\tlearn: 0.6006766\ttotal: 963ms\tremaining: 1m 13s\n",
      "13:\tlearn: 0.5958822\ttotal: 999ms\tremaining: 1m 10s\n",
      "14:\tlearn: 0.5902191\ttotal: 1.03s\tremaining: 1m 7s\n",
      "15:\tlearn: 0.5843400\ttotal: 1.13s\tremaining: 1m 9s\n",
      "16:\tlearn: 0.5788989\ttotal: 1.17s\tremaining: 1m 7s\n",
      "17:\tlearn: 0.5737943\ttotal: 1.21s\tremaining: 1m 5s\n",
      "18:\tlearn: 0.5670215\ttotal: 1.27s\tremaining: 1m 5s\n",
      "19:\tlearn: 0.5626246\ttotal: 1.35s\tremaining: 1m 6s\n",
      "20:\tlearn: 0.5578869\ttotal: 1.39s\tremaining: 1m 4s\n",
      "21:\tlearn: 0.5539016\ttotal: 1.42s\tremaining: 1m 3s\n",
      "22:\tlearn: 0.5497755\ttotal: 1.52s\tremaining: 1m 4s\n",
      "23:\tlearn: 0.5449310\ttotal: 1.56s\tremaining: 1m 3s\n",
      "24:\tlearn: 0.5404515\ttotal: 1.59s\tremaining: 1m 2s\n",
      "25:\tlearn: 0.5365077\ttotal: 1.69s\tremaining: 1m 3s\n",
      "26:\tlearn: 0.5298408\ttotal: 1.73s\tremaining: 1m 2s\n",
      "27:\tlearn: 0.5252762\ttotal: 1.76s\tremaining: 1m 1s\n",
      "28:\tlearn: 0.5216417\ttotal: 1.87s\tremaining: 1m 2s\n",
      "29:\tlearn: 0.5173526\ttotal: 1.91s\tremaining: 1m 1s\n",
      "30:\tlearn: 0.5127684\ttotal: 1.95s\tremaining: 1m\n",
      "31:\tlearn: 0.5086423\ttotal: 2.03s\tremaining: 1m 1s\n",
      "32:\tlearn: 0.5044430\ttotal: 2.08s\tremaining: 1m\n",
      "33:\tlearn: 0.4996474\ttotal: 2.11s\tremaining: 60s\n",
      "34:\tlearn: 0.4957121\ttotal: 2.2s\tremaining: 1m\n",
      "35:\tlearn: 0.4915733\ttotal: 2.25s\tremaining: 1m\n",
      "36:\tlearn: 0.4886780\ttotal: 2.29s\tremaining: 59.5s\n",
      "37:\tlearn: 0.4846325\ttotal: 2.36s\tremaining: 59.7s\n",
      "38:\tlearn: 0.4805779\ttotal: 2.43s\tremaining: 59.8s\n",
      "39:\tlearn: 0.4766350\ttotal: 2.46s\tremaining: 59s\n",
      "40:\tlearn: 0.4713221\ttotal: 2.53s\tremaining: 59.2s\n",
      "41:\tlearn: 0.4656337\ttotal: 2.6s\tremaining: 59.4s\n",
      "42:\tlearn: 0.4613311\ttotal: 2.64s\tremaining: 58.8s\n",
      "43:\tlearn: 0.4568670\ttotal: 2.67s\tremaining: 58.1s\n",
      "44:\tlearn: 0.4537733\ttotal: 2.76s\tremaining: 58.7s\n",
      "45:\tlearn: 0.4493254\ttotal: 2.8s\tremaining: 58.1s\n",
      "46:\tlearn: 0.4461688\ttotal: 2.83s\tremaining: 57.4s\n",
      "47:\tlearn: 0.4423721\ttotal: 2.94s\tremaining: 58.3s\n",
      "48:\tlearn: 0.4394139\ttotal: 2.98s\tremaining: 57.9s\n",
      "49:\tlearn: 0.4355643\ttotal: 3.02s\tremaining: 57.4s\n",
      "50:\tlearn: 0.4322619\ttotal: 3.13s\tremaining: 58.2s\n",
      "51:\tlearn: 0.4276027\ttotal: 3.17s\tremaining: 57.8s\n",
      "52:\tlearn: 0.4243383\ttotal: 3.2s\tremaining: 57.2s\n",
      "53:\tlearn: 0.4198032\ttotal: 3.29s\tremaining: 57.7s\n",
      "54:\tlearn: 0.4168675\ttotal: 3.33s\tremaining: 57.3s\n",
      "55:\tlearn: 0.4139273\ttotal: 3.37s\tremaining: 56.8s\n",
      "56:\tlearn: 0.4116886\ttotal: 3.46s\tremaining: 57.2s\n",
      "57:\tlearn: 0.4090051\ttotal: 3.51s\tremaining: 57s\n",
      "58:\tlearn: 0.4069345\ttotal: 3.54s\tremaining: 56.4s\n",
      "59:\tlearn: 0.4046426\ttotal: 3.63s\tremaining: 56.8s\n",
      "60:\tlearn: 0.4012710\ttotal: 3.69s\tremaining: 56.7s\n",
      "61:\tlearn: 0.3989682\ttotal: 3.72s\tremaining: 56.2s\n",
      "62:\tlearn: 0.3968274\ttotal: 3.81s\tremaining: 56.7s\n",
      "63:\tlearn: 0.3937704\ttotal: 3.86s\tremaining: 56.5s\n",
      "64:\tlearn: 0.3909804\ttotal: 3.9s\tremaining: 56.1s\n",
      "65:\tlearn: 0.3882225\ttotal: 3.93s\tremaining: 55.7s\n",
      "66:\tlearn: 0.3859311\ttotal: 4.04s\tremaining: 56.3s\n",
      "67:\tlearn: 0.3832543\ttotal: 4.08s\tremaining: 55.9s\n",
      "68:\tlearn: 0.3802846\ttotal: 4.11s\tremaining: 55.5s\n",
      "69:\tlearn: 0.3772463\ttotal: 4.21s\tremaining: 55.9s\n",
      "70:\tlearn: 0.3750486\ttotal: 4.25s\tremaining: 55.6s\n",
      "71:\tlearn: 0.3720558\ttotal: 4.28s\tremaining: 55.2s\n",
      "72:\tlearn: 0.3682149\ttotal: 4.38s\tremaining: 55.6s\n",
      "73:\tlearn: 0.3664106\ttotal: 4.41s\tremaining: 55.2s\n",
      "74:\tlearn: 0.3631037\ttotal: 4.44s\tremaining: 54.8s\n",
      "75:\tlearn: 0.3613421\ttotal: 4.54s\tremaining: 55.2s\n",
      "76:\tlearn: 0.3591414\ttotal: 4.58s\tremaining: 54.8s\n",
      "77:\tlearn: 0.3571188\ttotal: 4.67s\tremaining: 55.3s\n",
      "78:\tlearn: 0.3549885\ttotal: 4.71s\tremaining: 54.9s\n",
      "79:\tlearn: 0.3527891\ttotal: 4.74s\tremaining: 54.5s\n",
      "80:\tlearn: 0.3500560\ttotal: 4.83s\tremaining: 54.8s\n",
      "81:\tlearn: 0.3486239\ttotal: 4.87s\tremaining: 54.5s\n",
      "82:\tlearn: 0.3459677\ttotal: 4.9s\tremaining: 54.1s\n",
      "83:\tlearn: 0.3444170\ttotal: 4.99s\tremaining: 54.4s\n",
      "84:\tlearn: 0.3412592\ttotal: 5.03s\tremaining: 54.1s\n",
      "85:\tlearn: 0.3399301\ttotal: 5.06s\tremaining: 53.8s\n",
      "86:\tlearn: 0.3374373\ttotal: 5.15s\tremaining: 54.1s\n",
      "87:\tlearn: 0.3357786\ttotal: 5.2s\tremaining: 53.9s\n",
      "88:\tlearn: 0.3332871\ttotal: 5.25s\tremaining: 53.7s\n",
      "89:\tlearn: 0.3309469\ttotal: 5.34s\tremaining: 54s\n",
      "90:\tlearn: 0.3288896\ttotal: 5.38s\tremaining: 53.8s\n",
      "91:\tlearn: 0.3265502\ttotal: 5.42s\tremaining: 53.4s\n",
      "92:\tlearn: 0.3244892\ttotal: 5.52s\tremaining: 53.8s\n",
      "93:\tlearn: 0.3215755\ttotal: 5.56s\tremaining: 53.6s\n",
      "94:\tlearn: 0.3188317\ttotal: 5.59s\tremaining: 53.3s\n",
      "95:\tlearn: 0.3171938\ttotal: 5.62s\tremaining: 52.9s\n",
      "96:\tlearn: 0.3145264\ttotal: 5.71s\tremaining: 53.2s\n",
      "97:\tlearn: 0.3124639\ttotal: 5.75s\tremaining: 53s\n",
      "98:\tlearn: 0.3106854\ttotal: 5.8s\tremaining: 52.8s\n",
      "99:\tlearn: 0.3088892\ttotal: 5.88s\tremaining: 52.9s\n",
      "100:\tlearn: 0.3076110\ttotal: 5.92s\tremaining: 52.7s\n",
      "101:\tlearn: 0.3059302\ttotal: 5.95s\tremaining: 52.4s\n",
      "102:\tlearn: 0.3045392\ttotal: 6.06s\tremaining: 52.7s\n",
      "103:\tlearn: 0.3030343\ttotal: 6.1s\tremaining: 52.5s\n",
      "104:\tlearn: 0.3011380\ttotal: 6.13s\tremaining: 52.3s\n",
      "105:\tlearn: 0.2996705\ttotal: 6.23s\tremaining: 52.6s\n",
      "106:\tlearn: 0.2975195\ttotal: 6.28s\tremaining: 52.4s\n",
      "107:\tlearn: 0.2954577\ttotal: 6.31s\tremaining: 52.1s\n",
      "108:\tlearn: 0.2929524\ttotal: 6.41s\tremaining: 52.4s\n",
      "109:\tlearn: 0.2915302\ttotal: 6.46s\tremaining: 52.2s\n",
      "110:\tlearn: 0.2893053\ttotal: 6.51s\tremaining: 52.1s\n",
      "111:\tlearn: 0.2873241\ttotal: 6.59s\tremaining: 52.3s\n",
      "112:\tlearn: 0.2854083\ttotal: 6.63s\tremaining: 52.1s\n",
      "113:\tlearn: 0.2833990\ttotal: 6.66s\tremaining: 51.8s\n",
      "114:\tlearn: 0.2816080\ttotal: 6.76s\tremaining: 52s\n",
      "115:\tlearn: 0.2794776\ttotal: 6.8s\tremaining: 51.8s\n",
      "116:\tlearn: 0.2777579\ttotal: 6.85s\tremaining: 51.7s\n",
      "117:\tlearn: 0.2759088\ttotal: 6.93s\tremaining: 51.8s\n",
      "118:\tlearn: 0.2744586\ttotal: 6.96s\tremaining: 51.6s\n",
      "119:\tlearn: 0.2730784\ttotal: 6.99s\tremaining: 51.3s\n",
      "120:\tlearn: 0.2710306\ttotal: 7.09s\tremaining: 51.5s\n",
      "121:\tlearn: 0.2690615\ttotal: 7.14s\tremaining: 51.4s\n",
      "122:\tlearn: 0.2680753\ttotal: 7.17s\tremaining: 51.1s\n",
      "123:\tlearn: 0.2660133\ttotal: 7.27s\tremaining: 51.3s\n",
      "124:\tlearn: 0.2640279\ttotal: 7.31s\tremaining: 51.2s\n",
      "125:\tlearn: 0.2625113\ttotal: 7.34s\tremaining: 50.9s\n",
      "126:\tlearn: 0.2608607\ttotal: 7.42s\tremaining: 51s\n",
      "127:\tlearn: 0.2591489\ttotal: 7.49s\tremaining: 51s\n",
      "128:\tlearn: 0.2577963\ttotal: 7.52s\tremaining: 50.8s\n",
      "129:\tlearn: 0.2564375\ttotal: 7.59s\tremaining: 50.8s\n",
      "130:\tlearn: 0.2548559\ttotal: 7.65s\tremaining: 50.8s\n",
      "131:\tlearn: 0.2530377\ttotal: 7.69s\tremaining: 50.6s\n",
      "132:\tlearn: 0.2518418\ttotal: 7.75s\tremaining: 50.6s\n",
      "133:\tlearn: 0.2508896\ttotal: 7.83s\tremaining: 50.6s\n",
      "134:\tlearn: 0.2501399\ttotal: 7.86s\tremaining: 50.4s\n",
      "135:\tlearn: 0.2489821\ttotal: 7.93s\tremaining: 50.4s\n",
      "136:\tlearn: 0.2478517\ttotal: 8s\tremaining: 50.4s\n",
      "137:\tlearn: 0.2465303\ttotal: 8.03s\tremaining: 50.1s\n",
      "138:\tlearn: 0.2449138\ttotal: 8.13s\tremaining: 50.4s\n",
      "139:\tlearn: 0.2434237\ttotal: 8.18s\tremaining: 50.3s\n",
      "140:\tlearn: 0.2416580\ttotal: 8.23s\tremaining: 50.2s\n",
      "141:\tlearn: 0.2400079\ttotal: 8.32s\tremaining: 50.3s\n",
      "142:\tlearn: 0.2386925\ttotal: 8.36s\tremaining: 50.1s\n",
      "143:\tlearn: 0.2372277\ttotal: 8.43s\tremaining: 50.1s\n",
      "144:\tlearn: 0.2356452\ttotal: 8.51s\tremaining: 50.2s\n",
      "145:\tlearn: 0.2346656\ttotal: 8.55s\tremaining: 50s\n",
      "146:\tlearn: 0.2334395\ttotal: 8.57s\tremaining: 49.8s\n",
      "147:\tlearn: 0.2327946\ttotal: 8.66s\tremaining: 49.9s\n",
      "148:\tlearn: 0.2317242\ttotal: 8.7s\tremaining: 49.7s\n",
      "149:\tlearn: 0.2301921\ttotal: 8.73s\tremaining: 49.5s\n",
      "150:\tlearn: 0.2284629\ttotal: 8.82s\tremaining: 49.6s\n",
      "151:\tlearn: 0.2276794\ttotal: 8.86s\tremaining: 49.4s\n",
      "152:\tlearn: 0.2269347\ttotal: 8.89s\tremaining: 49.2s\n",
      "153:\tlearn: 0.2261032\ttotal: 8.99s\tremaining: 49.4s\n",
      "154:\tlearn: 0.2246010\ttotal: 9.04s\tremaining: 49.3s\n",
      "155:\tlearn: 0.2233607\ttotal: 9.07s\tremaining: 49.1s\n",
      "156:\tlearn: 0.2222013\ttotal: 9.17s\tremaining: 49.2s\n",
      "157:\tlearn: 0.2213762\ttotal: 9.22s\tremaining: 49.1s\n",
      "158:\tlearn: 0.2197497\ttotal: 9.28s\tremaining: 49.1s\n",
      "159:\tlearn: 0.2178915\ttotal: 9.36s\tremaining: 49.1s\n",
      "160:\tlearn: 0.2166680\ttotal: 9.4s\tremaining: 49s\n",
      "161:\tlearn: 0.2153468\ttotal: 9.43s\tremaining: 48.8s\n",
      "162:\tlearn: 0.2145042\ttotal: 9.52s\tremaining: 48.9s\n",
      "163:\tlearn: 0.2136961\ttotal: 9.56s\tremaining: 48.7s\n",
      "164:\tlearn: 0.2120999\ttotal: 9.59s\tremaining: 48.5s\n",
      "165:\tlearn: 0.2107649\ttotal: 9.71s\tremaining: 48.8s\n",
      "166:\tlearn: 0.2097616\ttotal: 9.77s\tremaining: 48.7s\n",
      "167:\tlearn: 0.2083894\ttotal: 9.8s\tremaining: 48.5s\n",
      "168:\tlearn: 0.2073355\ttotal: 9.89s\tremaining: 48.6s\n",
      "169:\tlearn: 0.2061881\ttotal: 9.93s\tremaining: 48.5s\n",
      "170:\tlearn: 0.2052988\ttotal: 10s\tremaining: 48.6s\n",
      "171:\tlearn: 0.2042308\ttotal: 10.1s\tremaining: 48.4s\n",
      "172:\tlearn: 0.2034463\ttotal: 10.1s\tremaining: 48.5s\n",
      "173:\tlearn: 0.2025459\ttotal: 10.2s\tremaining: 48.3s\n",
      "174:\tlearn: 0.2016052\ttotal: 10.2s\tremaining: 48.3s\n",
      "175:\tlearn: 0.2006213\ttotal: 10.3s\tremaining: 48.3s\n",
      "176:\tlearn: 0.1998697\ttotal: 10.4s\tremaining: 48.1s\n",
      "177:\tlearn: 0.1986609\ttotal: 10.4s\tremaining: 48.1s\n",
      "178:\tlearn: 0.1975327\ttotal: 10.5s\tremaining: 48.1s\n",
      "179:\tlearn: 0.1969570\ttotal: 10.5s\tremaining: 48s\n",
      "180:\tlearn: 0.1962706\ttotal: 10.6s\tremaining: 47.9s\n",
      "181:\tlearn: 0.1949697\ttotal: 10.7s\tremaining: 47.9s\n",
      "182:\tlearn: 0.1934890\ttotal: 10.7s\tremaining: 47.7s\n",
      "183:\tlearn: 0.1919366\ttotal: 10.7s\tremaining: 47.6s\n",
      "184:\tlearn: 0.1910442\ttotal: 10.8s\tremaining: 47.7s\n",
      "185:\tlearn: 0.1894944\ttotal: 10.8s\tremaining: 47.5s\n",
      "186:\tlearn: 0.1886537\ttotal: 10.9s\tremaining: 47.3s\n",
      "187:\tlearn: 0.1876990\ttotal: 11s\tremaining: 47.4s\n",
      "188:\tlearn: 0.1868805\ttotal: 11s\tremaining: 47.3s\n",
      "189:\tlearn: 0.1861012\ttotal: 11.1s\tremaining: 47.1s\n",
      "190:\tlearn: 0.1854065\ttotal: 11.2s\tremaining: 47.2s\n",
      "191:\tlearn: 0.1843496\ttotal: 11.2s\tremaining: 47.1s\n",
      "192:\tlearn: 0.1837122\ttotal: 11.2s\tremaining: 46.9s\n",
      "193:\tlearn: 0.1825445\ttotal: 11.3s\tremaining: 47s\n",
      "194:\tlearn: 0.1815142\ttotal: 11.4s\tremaining: 46.9s\n",
      "195:\tlearn: 0.1809824\ttotal: 11.4s\tremaining: 46.8s\n",
      "196:\tlearn: 0.1804286\ttotal: 11.4s\tremaining: 46.6s\n",
      "197:\tlearn: 0.1796729\ttotal: 11.5s\tremaining: 46.7s\n",
      "198:\tlearn: 0.1785422\ttotal: 11.6s\tremaining: 46.6s\n",
      "199:\tlearn: 0.1776256\ttotal: 11.6s\tremaining: 46.4s\n",
      "200:\tlearn: 0.1769258\ttotal: 11.7s\tremaining: 46.5s\n",
      "201:\tlearn: 0.1760745\ttotal: 11.7s\tremaining: 46.4s\n",
      "202:\tlearn: 0.1752371\ttotal: 11.8s\tremaining: 46.2s\n",
      "203:\tlearn: 0.1740888\ttotal: 11.9s\tremaining: 46.3s\n",
      "204:\tlearn: 0.1731516\ttotal: 11.9s\tremaining: 46.2s\n",
      "205:\tlearn: 0.1723667\ttotal: 12s\tremaining: 46.1s\n",
      "206:\tlearn: 0.1717126\ttotal: 12.1s\tremaining: 46.2s\n",
      "207:\tlearn: 0.1707904\ttotal: 12.1s\tremaining: 46.1s\n",
      "208:\tlearn: 0.1699787\ttotal: 12.1s\tremaining: 45.9s\n",
      "209:\tlearn: 0.1693786\ttotal: 12.2s\tremaining: 46s\n",
      "210:\tlearn: 0.1683468\ttotal: 12.3s\tremaining: 45.9s\n",
      "211:\tlearn: 0.1678333\ttotal: 12.3s\tremaining: 45.7s\n",
      "212:\tlearn: 0.1664430\ttotal: 12.4s\tremaining: 45.8s\n",
      "213:\tlearn: 0.1658015\ttotal: 12.5s\tremaining: 45.7s\n",
      "214:\tlearn: 0.1646853\ttotal: 12.5s\tremaining: 45.6s\n",
      "215:\tlearn: 0.1642831\ttotal: 12.6s\tremaining: 45.7s\n",
      "216:\tlearn: 0.1629964\ttotal: 12.6s\tremaining: 45.6s\n",
      "217:\tlearn: 0.1620896\ttotal: 12.7s\tremaining: 45.4s\n",
      "218:\tlearn: 0.1609560\ttotal: 12.8s\tremaining: 45.5s\n",
      "219:\tlearn: 0.1602924\ttotal: 12.8s\tremaining: 45.4s\n",
      "220:\tlearn: 0.1594983\ttotal: 12.8s\tremaining: 45.3s\n",
      "221:\tlearn: 0.1587486\ttotal: 12.9s\tremaining: 45.3s\n",
      "222:\tlearn: 0.1581150\ttotal: 13s\tremaining: 45.2s\n",
      "223:\tlearn: 0.1572930\ttotal: 13s\tremaining: 45.1s\n",
      "224:\tlearn: 0.1568158\ttotal: 13.1s\tremaining: 45.1s\n",
      "225:\tlearn: 0.1556733\ttotal: 13.2s\tremaining: 45.1s\n",
      "226:\tlearn: 0.1551439\ttotal: 13.2s\tremaining: 44.9s\n",
      "227:\tlearn: 0.1543136\ttotal: 13.2s\tremaining: 44.8s\n",
      "228:\tlearn: 0.1536213\ttotal: 13.3s\tremaining: 44.8s\n",
      "229:\tlearn: 0.1528220\ttotal: 13.4s\tremaining: 44.7s\n",
      "230:\tlearn: 0.1519625\ttotal: 13.4s\tremaining: 44.6s\n",
      "231:\tlearn: 0.1512369\ttotal: 13.5s\tremaining: 44.7s\n",
      "232:\tlearn: 0.1502654\ttotal: 13.5s\tremaining: 44.6s\n",
      "233:\tlearn: 0.1495062\ttotal: 13.6s\tremaining: 44.4s\n",
      "234:\tlearn: 0.1487227\ttotal: 13.7s\tremaining: 44.5s\n",
      "235:\tlearn: 0.1477821\ttotal: 13.7s\tremaining: 44.4s\n",
      "236:\tlearn: 0.1471912\ttotal: 13.7s\tremaining: 44.2s\n",
      "237:\tlearn: 0.1463328\ttotal: 13.8s\tremaining: 44.3s\n",
      "238:\tlearn: 0.1458544\ttotal: 13.9s\tremaining: 44.2s\n",
      "239:\tlearn: 0.1451005\ttotal: 13.9s\tremaining: 44.1s\n",
      "240:\tlearn: 0.1445220\ttotal: 14s\tremaining: 44.1s\n",
      "241:\tlearn: 0.1440329\ttotal: 14.1s\tremaining: 44s\n",
      "242:\tlearn: 0.1434041\ttotal: 14.1s\tremaining: 43.9s\n",
      "243:\tlearn: 0.1427993\ttotal: 14.2s\tremaining: 44s\n",
      "244:\tlearn: 0.1420891\ttotal: 14.2s\tremaining: 43.9s\n",
      "245:\tlearn: 0.1414411\ttotal: 14.3s\tremaining: 43.7s\n",
      "246:\tlearn: 0.1408369\ttotal: 14.4s\tremaining: 43.8s\n",
      "247:\tlearn: 0.1400272\ttotal: 14.4s\tremaining: 43.7s\n",
      "248:\tlearn: 0.1391391\ttotal: 14.4s\tremaining: 43.6s\n",
      "249:\tlearn: 0.1382534\ttotal: 14.5s\tremaining: 43.6s\n",
      "250:\tlearn: 0.1375001\ttotal: 14.6s\tremaining: 43.5s\n",
      "251:\tlearn: 0.1367035\ttotal: 14.6s\tremaining: 43.4s\n",
      "252:\tlearn: 0.1362365\ttotal: 14.7s\tremaining: 43.3s\n",
      "253:\tlearn: 0.1355703\ttotal: 14.7s\tremaining: 43.3s\n",
      "254:\tlearn: 0.1346215\ttotal: 14.8s\tremaining: 43.2s\n",
      "255:\tlearn: 0.1340153\ttotal: 14.8s\tremaining: 43.1s\n",
      "256:\tlearn: 0.1334173\ttotal: 14.9s\tremaining: 43.1s\n",
      "257:\tlearn: 0.1325320\ttotal: 15s\tremaining: 43.1s\n",
      "258:\tlearn: 0.1319880\ttotal: 15s\tremaining: 43s\n",
      "259:\tlearn: 0.1315790\ttotal: 15.1s\tremaining: 43s\n",
      "260:\tlearn: 0.1309201\ttotal: 15.2s\tremaining: 42.9s\n",
      "261:\tlearn: 0.1304819\ttotal: 15.2s\tremaining: 42.8s\n",
      "262:\tlearn: 0.1299369\ttotal: 15.3s\tremaining: 42.9s\n",
      "263:\tlearn: 0.1291877\ttotal: 15.3s\tremaining: 42.8s\n",
      "264:\tlearn: 0.1284509\ttotal: 15.4s\tremaining: 42.7s\n",
      "265:\tlearn: 0.1277411\ttotal: 15.5s\tremaining: 42.7s\n",
      "266:\tlearn: 0.1272444\ttotal: 15.5s\tremaining: 42.6s\n",
      "267:\tlearn: 0.1267043\ttotal: 15.5s\tremaining: 42.5s\n",
      "268:\tlearn: 0.1262991\ttotal: 15.6s\tremaining: 42.4s\n",
      "269:\tlearn: 0.1257958\ttotal: 15.7s\tremaining: 42.4s\n",
      "270:\tlearn: 0.1252945\ttotal: 15.7s\tremaining: 42.3s\n",
      "271:\tlearn: 0.1248169\ttotal: 15.8s\tremaining: 42.3s\n",
      "272:\tlearn: 0.1241357\ttotal: 15.9s\tremaining: 42.3s\n",
      "273:\tlearn: 0.1231941\ttotal: 15.9s\tremaining: 42.1s\n",
      "274:\tlearn: 0.1224916\ttotal: 16s\tremaining: 42.1s\n",
      "275:\tlearn: 0.1218154\ttotal: 16s\tremaining: 42.1s\n",
      "276:\tlearn: 0.1210770\ttotal: 16.1s\tremaining: 42s\n",
      "277:\tlearn: 0.1203091\ttotal: 16.1s\tremaining: 41.8s\n",
      "278:\tlearn: 0.1195579\ttotal: 16.2s\tremaining: 41.9s\n",
      "279:\tlearn: 0.1191835\ttotal: 16.3s\tremaining: 41.8s\n",
      "280:\tlearn: 0.1187490\ttotal: 16.3s\tremaining: 41.7s\n",
      "281:\tlearn: 0.1181983\ttotal: 16.4s\tremaining: 41.7s\n",
      "282:\tlearn: 0.1174959\ttotal: 16.4s\tremaining: 41.6s\n",
      "283:\tlearn: 0.1166638\ttotal: 16.5s\tremaining: 41.5s\n",
      "284:\tlearn: 0.1159260\ttotal: 16.5s\tremaining: 41.5s\n",
      "285:\tlearn: 0.1155250\ttotal: 16.6s\tremaining: 41.4s\n",
      "286:\tlearn: 0.1151963\ttotal: 16.6s\tremaining: 41.3s\n",
      "287:\tlearn: 0.1144546\ttotal: 16.7s\tremaining: 41.4s\n",
      "288:\tlearn: 0.1140016\ttotal: 16.8s\tremaining: 41.3s\n",
      "289:\tlearn: 0.1132876\ttotal: 16.8s\tremaining: 41.2s\n",
      "290:\tlearn: 0.1127365\ttotal: 16.9s\tremaining: 41.2s\n",
      "291:\tlearn: 0.1119739\ttotal: 17s\tremaining: 41.1s\n",
      "292:\tlearn: 0.1115021\ttotal: 17s\tremaining: 41s\n",
      "293:\tlearn: 0.1110377\ttotal: 17.1s\tremaining: 41s\n",
      "294:\tlearn: 0.1105869\ttotal: 17.1s\tremaining: 41s\n",
      "295:\tlearn: 0.1099803\ttotal: 17.2s\tremaining: 40.8s\n",
      "296:\tlearn: 0.1094582\ttotal: 17.2s\tremaining: 40.8s\n",
      "297:\tlearn: 0.1091084\ttotal: 17.3s\tremaining: 40.7s\n",
      "298:\tlearn: 0.1085792\ttotal: 17.4s\tremaining: 40.7s\n",
      "299:\tlearn: 0.1079409\ttotal: 17.4s\tremaining: 40.7s\n",
      "300:\tlearn: 0.1075878\ttotal: 17.5s\tremaining: 40.7s\n",
      "301:\tlearn: 0.1072366\ttotal: 17.6s\tremaining: 40.6s\n",
      "302:\tlearn: 0.1067569\ttotal: 17.6s\tremaining: 40.6s\n",
      "303:\tlearn: 0.1061794\ttotal: 17.7s\tremaining: 40.5s\n",
      "304:\tlearn: 0.1055781\ttotal: 17.7s\tremaining: 40.4s\n",
      "305:\tlearn: 0.1051783\ttotal: 17.8s\tremaining: 40.4s\n",
      "306:\tlearn: 0.1049174\ttotal: 17.9s\tremaining: 40.3s\n",
      "307:\tlearn: 0.1044725\ttotal: 18s\tremaining: 40.4s\n",
      "308:\tlearn: 0.1039841\ttotal: 18s\tremaining: 40.3s\n",
      "309:\tlearn: 0.1036365\ttotal: 18.1s\tremaining: 40.3s\n",
      "310:\tlearn: 0.1032680\ttotal: 18.2s\tremaining: 40.2s\n",
      "311:\tlearn: 0.1030036\ttotal: 18.2s\tremaining: 40.2s\n",
      "312:\tlearn: 0.1025994\ttotal: 18.3s\tremaining: 40.2s\n",
      "313:\tlearn: 0.1019249\ttotal: 18.4s\tremaining: 40.1s\n",
      "314:\tlearn: 0.1015071\ttotal: 18.5s\tremaining: 40.1s\n",
      "315:\tlearn: 0.1010683\ttotal: 18.5s\tremaining: 40s\n",
      "316:\tlearn: 0.1005608\ttotal: 18.6s\tremaining: 40.1s\n",
      "317:\tlearn: 0.1001606\ttotal: 18.7s\tremaining: 40s\n",
      "318:\tlearn: 0.0995939\ttotal: 18.7s\tremaining: 39.9s\n",
      "319:\tlearn: 0.0992223\ttotal: 18.8s\tremaining: 39.8s\n",
      "320:\tlearn: 0.0986278\ttotal: 18.8s\tremaining: 39.8s\n",
      "321:\tlearn: 0.0980167\ttotal: 18.9s\tremaining: 39.7s\n",
      "322:\tlearn: 0.0976902\ttotal: 19s\tremaining: 39.7s\n",
      "323:\tlearn: 0.0972447\ttotal: 19s\tremaining: 39.7s\n",
      "324:\tlearn: 0.0969836\ttotal: 19s\tremaining: 39.6s\n",
      "325:\tlearn: 0.0966083\ttotal: 19.1s\tremaining: 39.6s\n",
      "326:\tlearn: 0.0962620\ttotal: 19.2s\tremaining: 39.5s\n",
      "327:\tlearn: 0.0957745\ttotal: 19.2s\tremaining: 39.4s\n",
      "328:\tlearn: 0.0952639\ttotal: 19.3s\tremaining: 39.3s\n",
      "329:\tlearn: 0.0948636\ttotal: 19.4s\tremaining: 39.3s\n",
      "330:\tlearn: 0.0944785\ttotal: 19.4s\tremaining: 39.2s\n",
      "331:\tlearn: 0.0940818\ttotal: 19.4s\tremaining: 39.1s\n",
      "332:\tlearn: 0.0935610\ttotal: 19.5s\tremaining: 39.1s\n",
      "333:\tlearn: 0.0932492\ttotal: 19.6s\tremaining: 39s\n",
      "334:\tlearn: 0.0926804\ttotal: 19.6s\tremaining: 38.9s\n",
      "335:\tlearn: 0.0922439\ttotal: 19.7s\tremaining: 38.9s\n",
      "336:\tlearn: 0.0918868\ttotal: 19.7s\tremaining: 38.8s\n",
      "337:\tlearn: 0.0914984\ttotal: 19.8s\tremaining: 38.7s\n",
      "338:\tlearn: 0.0913248\ttotal: 19.9s\tremaining: 38.8s\n",
      "339:\tlearn: 0.0907462\ttotal: 20s\tremaining: 38.8s\n",
      "340:\tlearn: 0.0904493\ttotal: 20.1s\tremaining: 38.8s\n",
      "341:\tlearn: 0.0900821\ttotal: 20.1s\tremaining: 38.7s\n",
      "342:\tlearn: 0.0894804\ttotal: 20.1s\tremaining: 38.6s\n",
      "343:\tlearn: 0.0889881\ttotal: 20.2s\tremaining: 38.6s\n",
      "344:\tlearn: 0.0887098\ttotal: 20.3s\tremaining: 38.6s\n",
      "345:\tlearn: 0.0883773\ttotal: 20.3s\tremaining: 38.5s\n",
      "346:\tlearn: 0.0880065\ttotal: 20.4s\tremaining: 38.4s\n",
      "347:\tlearn: 0.0876810\ttotal: 20.5s\tremaining: 38.3s\n",
      "348:\tlearn: 0.0874262\ttotal: 20.5s\tremaining: 38.3s\n",
      "349:\tlearn: 0.0867905\ttotal: 20.5s\tremaining: 38.2s\n",
      "350:\tlearn: 0.0866665\ttotal: 20.6s\tremaining: 38.2s\n",
      "351:\tlearn: 0.0861810\ttotal: 20.7s\tremaining: 38.1s\n",
      "352:\tlearn: 0.0858459\ttotal: 20.7s\tremaining: 38s\n",
      "353:\tlearn: 0.0855737\ttotal: 20.8s\tremaining: 38s\n",
      "354:\tlearn: 0.0852597\ttotal: 20.9s\tremaining: 37.9s\n",
      "355:\tlearn: 0.0848966\ttotal: 21s\tremaining: 37.9s\n",
      "356:\tlearn: 0.0844944\ttotal: 21s\tremaining: 37.8s\n",
      "357:\tlearn: 0.0843192\ttotal: 21s\tremaining: 37.7s\n",
      "358:\tlearn: 0.0840356\ttotal: 21.1s\tremaining: 37.7s\n",
      "359:\tlearn: 0.0836810\ttotal: 21.2s\tremaining: 37.6s\n",
      "360:\tlearn: 0.0833385\ttotal: 21.2s\tremaining: 37.5s\n",
      "361:\tlearn: 0.0829804\ttotal: 21.3s\tremaining: 37.5s\n",
      "362:\tlearn: 0.0825324\ttotal: 21.3s\tremaining: 37.5s\n",
      "363:\tlearn: 0.0821365\ttotal: 21.4s\tremaining: 37.4s\n",
      "364:\tlearn: 0.0817947\ttotal: 21.5s\tremaining: 37.4s\n",
      "365:\tlearn: 0.0814417\ttotal: 21.5s\tremaining: 37.3s\n",
      "366:\tlearn: 0.0810181\ttotal: 21.6s\tremaining: 37.2s\n",
      "367:\tlearn: 0.0806385\ttotal: 21.7s\tremaining: 37.2s\n",
      "368:\tlearn: 0.0804738\ttotal: 21.7s\tremaining: 37.1s\n",
      "369:\tlearn: 0.0800626\ttotal: 21.7s\tremaining: 37s\n",
      "370:\tlearn: 0.0796078\ttotal: 21.8s\tremaining: 37s\n",
      "371:\tlearn: 0.0792345\ttotal: 21.9s\tremaining: 36.9s\n",
      "372:\tlearn: 0.0788928\ttotal: 21.9s\tremaining: 36.8s\n",
      "373:\tlearn: 0.0787128\ttotal: 22s\tremaining: 36.8s\n",
      "374:\tlearn: 0.0784613\ttotal: 22s\tremaining: 36.7s\n",
      "375:\tlearn: 0.0781873\ttotal: 22.1s\tremaining: 36.6s\n",
      "376:\tlearn: 0.0778334\ttotal: 22.2s\tremaining: 36.6s\n",
      "377:\tlearn: 0.0774684\ttotal: 22.2s\tremaining: 36.6s\n",
      "378:\tlearn: 0.0771664\ttotal: 22.3s\tremaining: 36.5s\n",
      "379:\tlearn: 0.0768510\ttotal: 22.4s\tremaining: 36.5s\n",
      "380:\tlearn: 0.0766254\ttotal: 22.4s\tremaining: 36.4s\n",
      "381:\tlearn: 0.0762267\ttotal: 22.4s\tremaining: 36.3s\n",
      "382:\tlearn: 0.0760119\ttotal: 22.5s\tremaining: 36.3s\n",
      "383:\tlearn: 0.0756442\ttotal: 22.6s\tremaining: 36.2s\n",
      "384:\tlearn: 0.0753091\ttotal: 22.6s\tremaining: 36.1s\n",
      "385:\tlearn: 0.0749305\ttotal: 22.7s\tremaining: 36.1s\n",
      "386:\tlearn: 0.0746266\ttotal: 22.7s\tremaining: 36s\n",
      "387:\tlearn: 0.0742746\ttotal: 22.8s\tremaining: 36s\n",
      "388:\tlearn: 0.0740136\ttotal: 22.9s\tremaining: 35.9s\n",
      "389:\tlearn: 0.0738367\ttotal: 22.9s\tremaining: 35.8s\n",
      "390:\tlearn: 0.0734700\ttotal: 23s\tremaining: 35.8s\n",
      "391:\tlearn: 0.0729777\ttotal: 23s\tremaining: 35.7s\n",
      "392:\tlearn: 0.0727733\ttotal: 23.1s\tremaining: 35.6s\n",
      "393:\tlearn: 0.0724511\ttotal: 23.2s\tremaining: 35.7s\n",
      "394:\tlearn: 0.0722679\ttotal: 23.2s\tremaining: 35.6s\n",
      "395:\tlearn: 0.0719412\ttotal: 23.3s\tremaining: 35.5s\n",
      "396:\tlearn: 0.0716560\ttotal: 23.3s\tremaining: 35.5s\n",
      "397:\tlearn: 0.0714601\ttotal: 23.4s\tremaining: 35.4s\n",
      "398:\tlearn: 0.0712918\ttotal: 23.4s\tremaining: 35.3s\n",
      "399:\tlearn: 0.0709587\ttotal: 23.5s\tremaining: 35.3s\n",
      "400:\tlearn: 0.0707208\ttotal: 23.6s\tremaining: 35.2s\n",
      "401:\tlearn: 0.0704005\ttotal: 23.6s\tremaining: 35.1s\n",
      "402:\tlearn: 0.0701676\ttotal: 23.7s\tremaining: 35.1s\n",
      "403:\tlearn: 0.0698243\ttotal: 23.8s\tremaining: 35.1s\n",
      "404:\tlearn: 0.0694368\ttotal: 23.8s\tremaining: 35s\n",
      "405:\tlearn: 0.0690670\ttotal: 23.9s\tremaining: 35s\n",
      "406:\tlearn: 0.0687437\ttotal: 23.9s\tremaining: 34.9s\n",
      "407:\tlearn: 0.0683804\ttotal: 24s\tremaining: 34.8s\n",
      "408:\tlearn: 0.0681718\ttotal: 24.1s\tremaining: 34.8s\n",
      "409:\tlearn: 0.0678151\ttotal: 24.1s\tremaining: 34.7s\n",
      "410:\tlearn: 0.0675617\ttotal: 24.2s\tremaining: 34.6s\n",
      "411:\tlearn: 0.0671511\ttotal: 24.3s\tremaining: 34.6s\n",
      "412:\tlearn: 0.0669310\ttotal: 24.3s\tremaining: 34.5s\n",
      "413:\tlearn: 0.0666061\ttotal: 24.3s\tremaining: 34.4s\n",
      "414:\tlearn: 0.0663409\ttotal: 24.4s\tremaining: 34.4s\n",
      "415:\tlearn: 0.0660666\ttotal: 24.5s\tremaining: 34.4s\n",
      "416:\tlearn: 0.0658157\ttotal: 24.5s\tremaining: 34.3s\n",
      "417:\tlearn: 0.0655952\ttotal: 24.5s\tremaining: 34.2s\n",
      "418:\tlearn: 0.0653707\ttotal: 24.6s\tremaining: 34.2s\n",
      "419:\tlearn: 0.0650539\ttotal: 24.7s\tremaining: 34.1s\n",
      "420:\tlearn: 0.0647654\ttotal: 24.7s\tremaining: 34s\n",
      "421:\tlearn: 0.0644673\ttotal: 24.8s\tremaining: 34s\n",
      "422:\tlearn: 0.0642441\ttotal: 24.8s\tremaining: 33.9s\n",
      "423:\tlearn: 0.0639278\ttotal: 24.9s\tremaining: 33.8s\n",
      "424:\tlearn: 0.0637439\ttotal: 25s\tremaining: 33.8s\n",
      "425:\tlearn: 0.0635001\ttotal: 25s\tremaining: 33.7s\n",
      "426:\tlearn: 0.0632716\ttotal: 25s\tremaining: 33.6s\n",
      "427:\tlearn: 0.0630209\ttotal: 25.1s\tremaining: 33.6s\n",
      "428:\tlearn: 0.0628034\ttotal: 25.2s\tremaining: 33.5s\n",
      "429:\tlearn: 0.0625479\ttotal: 25.2s\tremaining: 33.4s\n",
      "430:\tlearn: 0.0622988\ttotal: 25.3s\tremaining: 33.4s\n",
      "431:\tlearn: 0.0621285\ttotal: 25.4s\tremaining: 33.3s\n",
      "432:\tlearn: 0.0619364\ttotal: 25.4s\tremaining: 33.3s\n",
      "433:\tlearn: 0.0616092\ttotal: 25.5s\tremaining: 33.2s\n",
      "434:\tlearn: 0.0612343\ttotal: 25.5s\tremaining: 33.2s\n",
      "435:\tlearn: 0.0609190\ttotal: 25.6s\tremaining: 33.1s\n",
      "436:\tlearn: 0.0606716\ttotal: 25.6s\tremaining: 33s\n",
      "437:\tlearn: 0.0605278\ttotal: 25.7s\tremaining: 33s\n",
      "438:\tlearn: 0.0603435\ttotal: 25.7s\tremaining: 32.9s\n",
      "439:\tlearn: 0.0600523\ttotal: 25.8s\tremaining: 32.8s\n",
      "440:\tlearn: 0.0598536\ttotal: 25.9s\tremaining: 32.8s\n",
      "441:\tlearn: 0.0594352\ttotal: 25.9s\tremaining: 32.7s\n",
      "442:\tlearn: 0.0592931\ttotal: 25.9s\tremaining: 32.6s\n",
      "443:\tlearn: 0.0589226\ttotal: 26s\tremaining: 32.6s\n",
      "444:\tlearn: 0.0586703\ttotal: 26.1s\tremaining: 32.5s\n",
      "445:\tlearn: 0.0584809\ttotal: 26.1s\tremaining: 32.4s\n",
      "446:\tlearn: 0.0582301\ttotal: 26.2s\tremaining: 32.4s\n",
      "447:\tlearn: 0.0579752\ttotal: 26.3s\tremaining: 32.4s\n",
      "448:\tlearn: 0.0576689\ttotal: 26.3s\tremaining: 32.3s\n",
      "449:\tlearn: 0.0575184\ttotal: 26.4s\tremaining: 32.3s\n",
      "450:\tlearn: 0.0573192\ttotal: 26.4s\tremaining: 32.2s\n",
      "451:\tlearn: 0.0572185\ttotal: 26.5s\tremaining: 32.1s\n",
      "452:\tlearn: 0.0569522\ttotal: 26.6s\tremaining: 32.1s\n",
      "453:\tlearn: 0.0566862\ttotal: 26.6s\tremaining: 32s\n",
      "454:\tlearn: 0.0564764\ttotal: 26.7s\tremaining: 31.9s\n",
      "455:\tlearn: 0.0562128\ttotal: 26.7s\tremaining: 31.8s\n",
      "456:\tlearn: 0.0559243\ttotal: 26.8s\tremaining: 31.8s\n",
      "457:\tlearn: 0.0556989\ttotal: 26.8s\tremaining: 31.8s\n",
      "458:\tlearn: 0.0554549\ttotal: 26.9s\tremaining: 31.7s\n",
      "459:\tlearn: 0.0552506\ttotal: 27s\tremaining: 31.6s\n",
      "460:\tlearn: 0.0549694\ttotal: 27s\tremaining: 31.6s\n",
      "461:\tlearn: 0.0548050\ttotal: 27s\tremaining: 31.5s\n",
      "462:\tlearn: 0.0546232\ttotal: 27.1s\tremaining: 31.5s\n",
      "463:\tlearn: 0.0543381\ttotal: 27.2s\tremaining: 31.4s\n",
      "464:\tlearn: 0.0540731\ttotal: 27.2s\tremaining: 31.3s\n",
      "465:\tlearn: 0.0539344\ttotal: 27.3s\tremaining: 31.3s\n",
      "466:\tlearn: 0.0537234\ttotal: 27.4s\tremaining: 31.2s\n",
      "467:\tlearn: 0.0535161\ttotal: 27.4s\tremaining: 31.1s\n",
      "468:\tlearn: 0.0531302\ttotal: 27.5s\tremaining: 31.1s\n",
      "469:\tlearn: 0.0528849\ttotal: 27.5s\tremaining: 31.1s\n",
      "470:\tlearn: 0.0526625\ttotal: 27.6s\tremaining: 31s\n",
      "471:\tlearn: 0.0523415\ttotal: 27.7s\tremaining: 31s\n",
      "472:\tlearn: 0.0520468\ttotal: 27.7s\tremaining: 30.9s\n",
      "473:\tlearn: 0.0519159\ttotal: 27.7s\tremaining: 30.8s\n",
      "474:\tlearn: 0.0517042\ttotal: 27.8s\tremaining: 30.7s\n",
      "475:\tlearn: 0.0515101\ttotal: 27.9s\tremaining: 30.7s\n",
      "476:\tlearn: 0.0513911\ttotal: 27.9s\tremaining: 30.6s\n",
      "477:\tlearn: 0.0512956\ttotal: 28s\tremaining: 30.6s\n",
      "478:\tlearn: 0.0510538\ttotal: 28.1s\tremaining: 30.5s\n",
      "479:\tlearn: 0.0508361\ttotal: 28.1s\tremaining: 30.4s\n",
      "480:\tlearn: 0.0506710\ttotal: 28.1s\tremaining: 30.3s\n",
      "481:\tlearn: 0.0504525\ttotal: 28.2s\tremaining: 30.3s\n",
      "482:\tlearn: 0.0502130\ttotal: 28.3s\tremaining: 30.3s\n",
      "483:\tlearn: 0.0500234\ttotal: 28.3s\tremaining: 30.2s\n",
      "484:\tlearn: 0.0498284\ttotal: 28.4s\tremaining: 30.1s\n",
      "485:\tlearn: 0.0496000\ttotal: 28.4s\tremaining: 30.1s\n",
      "486:\tlearn: 0.0494634\ttotal: 28.5s\tremaining: 30s\n",
      "487:\tlearn: 0.0492384\ttotal: 28.5s\tremaining: 29.9s\n",
      "488:\tlearn: 0.0491072\ttotal: 28.6s\tremaining: 29.9s\n",
      "489:\tlearn: 0.0489352\ttotal: 28.6s\tremaining: 29.8s\n",
      "490:\tlearn: 0.0487274\ttotal: 28.7s\tremaining: 29.7s\n",
      "491:\tlearn: 0.0485248\ttotal: 28.8s\tremaining: 29.7s\n",
      "492:\tlearn: 0.0483533\ttotal: 28.8s\tremaining: 29.6s\n",
      "493:\tlearn: 0.0481086\ttotal: 28.8s\tremaining: 29.5s\n",
      "494:\tlearn: 0.0479223\ttotal: 28.9s\tremaining: 29.5s\n",
      "495:\tlearn: 0.0476231\ttotal: 29s\tremaining: 29.5s\n",
      "496:\tlearn: 0.0474365\ttotal: 29s\tremaining: 29.4s\n",
      "497:\tlearn: 0.0471876\ttotal: 29.1s\tremaining: 29.4s\n",
      "498:\tlearn: 0.0469880\ttotal: 29.2s\tremaining: 29.3s\n",
      "499:\tlearn: 0.0467666\ttotal: 29.2s\tremaining: 29.2s\n",
      "500:\tlearn: 0.0465379\ttotal: 29.3s\tremaining: 29.2s\n",
      "501:\tlearn: 0.0464358\ttotal: 29.3s\tremaining: 29.1s\n",
      "502:\tlearn: 0.0462469\ttotal: 29.4s\tremaining: 29s\n",
      "503:\tlearn: 0.0461232\ttotal: 29.4s\tremaining: 29s\n",
      "504:\tlearn: 0.0459087\ttotal: 29.5s\tremaining: 28.9s\n",
      "505:\tlearn: 0.0457244\ttotal: 29.5s\tremaining: 28.8s\n",
      "506:\tlearn: 0.0455437\ttotal: 29.6s\tremaining: 28.8s\n",
      "507:\tlearn: 0.0453917\ttotal: 29.7s\tremaining: 28.7s\n",
      "508:\tlearn: 0.0452310\ttotal: 29.7s\tremaining: 28.7s\n",
      "509:\tlearn: 0.0450521\ttotal: 29.7s\tremaining: 28.6s\n",
      "510:\tlearn: 0.0448942\ttotal: 29.8s\tremaining: 28.6s\n",
      "511:\tlearn: 0.0447325\ttotal: 29.9s\tremaining: 28.5s\n",
      "512:\tlearn: 0.0446279\ttotal: 29.9s\tremaining: 28.4s\n",
      "513:\tlearn: 0.0444513\ttotal: 30s\tremaining: 28.4s\n",
      "514:\tlearn: 0.0443073\ttotal: 30.1s\tremaining: 28.3s\n",
      "515:\tlearn: 0.0441488\ttotal: 30.1s\tremaining: 28.2s\n",
      "516:\tlearn: 0.0439314\ttotal: 30.2s\tremaining: 28.2s\n",
      "517:\tlearn: 0.0438144\ttotal: 30.3s\tremaining: 28.2s\n",
      "518:\tlearn: 0.0436685\ttotal: 30.3s\tremaining: 28.1s\n",
      "519:\tlearn: 0.0435028\ttotal: 30.4s\tremaining: 28.1s\n",
      "520:\tlearn: 0.0433360\ttotal: 30.4s\tremaining: 28s\n",
      "521:\tlearn: 0.0431582\ttotal: 30.5s\tremaining: 28s\n",
      "522:\tlearn: 0.0428973\ttotal: 30.6s\tremaining: 27.9s\n",
      "523:\tlearn: 0.0426952\ttotal: 30.6s\tremaining: 27.8s\n",
      "524:\tlearn: 0.0425405\ttotal: 30.7s\tremaining: 27.7s\n",
      "525:\tlearn: 0.0423209\ttotal: 30.7s\tremaining: 27.6s\n",
      "526:\tlearn: 0.0421333\ttotal: 30.8s\tremaining: 27.6s\n",
      "527:\tlearn: 0.0420141\ttotal: 30.8s\tremaining: 27.6s\n",
      "528:\tlearn: 0.0418894\ttotal: 30.9s\tremaining: 27.5s\n",
      "529:\tlearn: 0.0417242\ttotal: 31s\tremaining: 27.4s\n",
      "530:\tlearn: 0.0416414\ttotal: 31s\tremaining: 27.4s\n",
      "531:\tlearn: 0.0414869\ttotal: 31s\tremaining: 27.3s\n",
      "532:\tlearn: 0.0413582\ttotal: 31.1s\tremaining: 27.2s\n",
      "533:\tlearn: 0.0411691\ttotal: 31.2s\tremaining: 27.2s\n",
      "534:\tlearn: 0.0410005\ttotal: 31.2s\tremaining: 27.1s\n",
      "535:\tlearn: 0.0408005\ttotal: 31.3s\tremaining: 27.1s\n",
      "536:\tlearn: 0.0406800\ttotal: 31.4s\tremaining: 27s\n",
      "537:\tlearn: 0.0405385\ttotal: 31.4s\tremaining: 27s\n",
      "538:\tlearn: 0.0403957\ttotal: 31.5s\tremaining: 26.9s\n",
      "539:\tlearn: 0.0402850\ttotal: 31.5s\tremaining: 26.9s\n",
      "540:\tlearn: 0.0401226\ttotal: 31.6s\tremaining: 26.8s\n",
      "541:\tlearn: 0.0399228\ttotal: 31.7s\tremaining: 26.8s\n",
      "542:\tlearn: 0.0397785\ttotal: 31.7s\tremaining: 26.7s\n",
      "543:\tlearn: 0.0396871\ttotal: 31.7s\tremaining: 26.6s\n",
      "544:\tlearn: 0.0395544\ttotal: 31.8s\tremaining: 26.6s\n",
      "545:\tlearn: 0.0393468\ttotal: 31.9s\tremaining: 26.5s\n",
      "546:\tlearn: 0.0391706\ttotal: 31.9s\tremaining: 26.4s\n",
      "547:\tlearn: 0.0390140\ttotal: 32s\tremaining: 26.4s\n",
      "548:\tlearn: 0.0388607\ttotal: 32.1s\tremaining: 26.3s\n",
      "549:\tlearn: 0.0387272\ttotal: 32.1s\tremaining: 26.3s\n",
      "550:\tlearn: 0.0385110\ttotal: 32.2s\tremaining: 26.2s\n",
      "551:\tlearn: 0.0383223\ttotal: 32.2s\tremaining: 26.2s\n",
      "552:\tlearn: 0.0381345\ttotal: 32.3s\tremaining: 26.1s\n",
      "553:\tlearn: 0.0379863\ttotal: 32.4s\tremaining: 26.1s\n",
      "554:\tlearn: 0.0379027\ttotal: 32.4s\tremaining: 26s\n",
      "555:\tlearn: 0.0377491\ttotal: 32.5s\tremaining: 25.9s\n",
      "556:\tlearn: 0.0376406\ttotal: 32.6s\tremaining: 25.9s\n",
      "557:\tlearn: 0.0374285\ttotal: 32.6s\tremaining: 25.8s\n",
      "558:\tlearn: 0.0373199\ttotal: 32.6s\tremaining: 25.7s\n",
      "559:\tlearn: 0.0372007\ttotal: 32.7s\tremaining: 25.7s\n",
      "560:\tlearn: 0.0370999\ttotal: 32.7s\tremaining: 25.6s\n",
      "561:\tlearn: 0.0369930\ttotal: 32.8s\tremaining: 25.6s\n",
      "562:\tlearn: 0.0368978\ttotal: 32.9s\tremaining: 25.5s\n",
      "563:\tlearn: 0.0367944\ttotal: 32.9s\tremaining: 25.5s\n",
      "564:\tlearn: 0.0365807\ttotal: 33s\tremaining: 25.4s\n",
      "565:\tlearn: 0.0364359\ttotal: 33.1s\tremaining: 25.4s\n",
      "566:\tlearn: 0.0362806\ttotal: 33.1s\tremaining: 25.3s\n",
      "567:\tlearn: 0.0361170\ttotal: 33.2s\tremaining: 25.2s\n",
      "568:\tlearn: 0.0359344\ttotal: 33.2s\tremaining: 25.2s\n",
      "569:\tlearn: 0.0357999\ttotal: 33.3s\tremaining: 25.1s\n",
      "570:\tlearn: 0.0356773\ttotal: 33.3s\tremaining: 25s\n",
      "571:\tlearn: 0.0355651\ttotal: 33.4s\tremaining: 25s\n",
      "572:\tlearn: 0.0354038\ttotal: 33.5s\tremaining: 24.9s\n",
      "573:\tlearn: 0.0353246\ttotal: 33.5s\tremaining: 24.9s\n",
      "574:\tlearn: 0.0351387\ttotal: 33.5s\tremaining: 24.8s\n",
      "575:\tlearn: 0.0350022\ttotal: 33.6s\tremaining: 24.8s\n",
      "576:\tlearn: 0.0348746\ttotal: 33.7s\tremaining: 24.7s\n",
      "577:\tlearn: 0.0347655\ttotal: 33.7s\tremaining: 24.6s\n",
      "578:\tlearn: 0.0346425\ttotal: 33.8s\tremaining: 24.6s\n",
      "579:\tlearn: 0.0345123\ttotal: 33.9s\tremaining: 24.5s\n",
      "580:\tlearn: 0.0344420\ttotal: 33.9s\tremaining: 24.4s\n",
      "581:\tlearn: 0.0343509\ttotal: 34s\tremaining: 24.4s\n",
      "582:\tlearn: 0.0342065\ttotal: 34s\tremaining: 24.4s\n",
      "583:\tlearn: 0.0340784\ttotal: 34.1s\tremaining: 24.3s\n",
      "584:\tlearn: 0.0339976\ttotal: 34.2s\tremaining: 24.2s\n",
      "585:\tlearn: 0.0338547\ttotal: 34.2s\tremaining: 24.2s\n",
      "586:\tlearn: 0.0337466\ttotal: 34.2s\tremaining: 24.1s\n",
      "587:\tlearn: 0.0336317\ttotal: 34.3s\tremaining: 24.1s\n",
      "588:\tlearn: 0.0335052\ttotal: 34.4s\tremaining: 24s\n",
      "589:\tlearn: 0.0334079\ttotal: 34.4s\tremaining: 23.9s\n",
      "590:\tlearn: 0.0332988\ttotal: 34.5s\tremaining: 23.9s\n",
      "591:\tlearn: 0.0331975\ttotal: 34.6s\tremaining: 23.8s\n",
      "592:\tlearn: 0.0330351\ttotal: 34.6s\tremaining: 23.7s\n",
      "593:\tlearn: 0.0329019\ttotal: 34.6s\tremaining: 23.7s\n",
      "594:\tlearn: 0.0327949\ttotal: 34.7s\tremaining: 23.6s\n",
      "595:\tlearn: 0.0326906\ttotal: 34.8s\tremaining: 23.6s\n",
      "596:\tlearn: 0.0325843\ttotal: 34.8s\tremaining: 23.5s\n",
      "597:\tlearn: 0.0324316\ttotal: 34.8s\tremaining: 23.4s\n",
      "598:\tlearn: 0.0322788\ttotal: 34.9s\tremaining: 23.4s\n",
      "599:\tlearn: 0.0321481\ttotal: 35s\tremaining: 23.3s\n",
      "600:\tlearn: 0.0319608\ttotal: 35s\tremaining: 23.2s\n",
      "601:\tlearn: 0.0318459\ttotal: 35.1s\tremaining: 23.2s\n",
      "602:\tlearn: 0.0316937\ttotal: 35.2s\tremaining: 23.1s\n",
      "603:\tlearn: 0.0315922\ttotal: 35.2s\tremaining: 23.1s\n",
      "604:\tlearn: 0.0314908\ttotal: 35.3s\tremaining: 23s\n",
      "605:\tlearn: 0.0314062\ttotal: 35.3s\tremaining: 23s\n",
      "606:\tlearn: 0.0312607\ttotal: 35.4s\tremaining: 22.9s\n",
      "607:\tlearn: 0.0310819\ttotal: 35.5s\tremaining: 22.9s\n",
      "608:\tlearn: 0.0309806\ttotal: 35.5s\tremaining: 22.8s\n",
      "609:\tlearn: 0.0308386\ttotal: 35.5s\tremaining: 22.7s\n",
      "610:\tlearn: 0.0307314\ttotal: 35.6s\tremaining: 22.7s\n",
      "611:\tlearn: 0.0305903\ttotal: 35.7s\tremaining: 22.6s\n",
      "612:\tlearn: 0.0304924\ttotal: 35.7s\tremaining: 22.5s\n",
      "613:\tlearn: 0.0304034\ttotal: 35.8s\tremaining: 22.5s\n",
      "614:\tlearn: 0.0302900\ttotal: 35.9s\tremaining: 22.5s\n",
      "615:\tlearn: 0.0302345\ttotal: 36s\tremaining: 22.4s\n",
      "616:\tlearn: 0.0301292\ttotal: 36s\tremaining: 22.4s\n",
      "617:\tlearn: 0.0300079\ttotal: 36.1s\tremaining: 22.3s\n",
      "618:\tlearn: 0.0299329\ttotal: 36.1s\tremaining: 22.2s\n",
      "619:\tlearn: 0.0298307\ttotal: 36.2s\tremaining: 22.2s\n",
      "620:\tlearn: 0.0297242\ttotal: 36.2s\tremaining: 22.1s\n",
      "621:\tlearn: 0.0296043\ttotal: 36.3s\tremaining: 22s\n",
      "622:\tlearn: 0.0295123\ttotal: 36.3s\tremaining: 22s\n",
      "623:\tlearn: 0.0294053\ttotal: 36.3s\tremaining: 21.9s\n",
      "624:\tlearn: 0.0293030\ttotal: 36.3s\tremaining: 21.8s\n",
      "625:\tlearn: 0.0291681\ttotal: 36.4s\tremaining: 21.7s\n",
      "626:\tlearn: 0.0290623\ttotal: 36.4s\tremaining: 21.7s\n",
      "627:\tlearn: 0.0289602\ttotal: 36.5s\tremaining: 21.6s\n",
      "628:\tlearn: 0.0288396\ttotal: 36.6s\tremaining: 21.6s\n",
      "629:\tlearn: 0.0287467\ttotal: 36.6s\tremaining: 21.5s\n",
      "630:\tlearn: 0.0286346\ttotal: 36.6s\tremaining: 21.4s\n",
      "631:\tlearn: 0.0285346\ttotal: 36.7s\tremaining: 21.4s\n",
      "632:\tlearn: 0.0284079\ttotal: 36.8s\tremaining: 21.3s\n",
      "633:\tlearn: 0.0282913\ttotal: 36.8s\tremaining: 21.3s\n",
      "634:\tlearn: 0.0281505\ttotal: 36.9s\tremaining: 21.2s\n",
      "635:\tlearn: 0.0280713\ttotal: 36.9s\tremaining: 21.1s\n",
      "636:\tlearn: 0.0279182\ttotal: 37s\tremaining: 21.1s\n",
      "637:\tlearn: 0.0278088\ttotal: 37.1s\tremaining: 21s\n",
      "638:\tlearn: 0.0276877\ttotal: 37.1s\tremaining: 21s\n",
      "639:\tlearn: 0.0275550\ttotal: 37.2s\tremaining: 20.9s\n",
      "640:\tlearn: 0.0274092\ttotal: 37.3s\tremaining: 20.9s\n",
      "641:\tlearn: 0.0272605\ttotal: 37.3s\tremaining: 20.8s\n",
      "642:\tlearn: 0.0271547\ttotal: 37.3s\tremaining: 20.7s\n",
      "643:\tlearn: 0.0270107\ttotal: 37.4s\tremaining: 20.7s\n",
      "644:\tlearn: 0.0268504\ttotal: 37.4s\tremaining: 20.6s\n",
      "645:\tlearn: 0.0267947\ttotal: 37.5s\tremaining: 20.5s\n",
      "646:\tlearn: 0.0266936\ttotal: 37.6s\tremaining: 20.5s\n",
      "647:\tlearn: 0.0265782\ttotal: 37.6s\tremaining: 20.4s\n",
      "648:\tlearn: 0.0264729\ttotal: 37.7s\tremaining: 20.4s\n",
      "649:\tlearn: 0.0264056\ttotal: 37.8s\tremaining: 20.3s\n",
      "650:\tlearn: 0.0262814\ttotal: 37.8s\tremaining: 20.3s\n",
      "651:\tlearn: 0.0261920\ttotal: 37.8s\tremaining: 20.2s\n",
      "652:\tlearn: 0.0260803\ttotal: 37.9s\tremaining: 20.2s\n",
      "653:\tlearn: 0.0260208\ttotal: 38s\tremaining: 20.1s\n",
      "654:\tlearn: 0.0259522\ttotal: 38s\tremaining: 20s\n",
      "655:\tlearn: 0.0258969\ttotal: 38.1s\tremaining: 20s\n",
      "656:\tlearn: 0.0257995\ttotal: 38.2s\tremaining: 19.9s\n",
      "657:\tlearn: 0.0257172\ttotal: 38.2s\tremaining: 19.9s\n",
      "658:\tlearn: 0.0256058\ttotal: 38.3s\tremaining: 19.8s\n",
      "659:\tlearn: 0.0255376\ttotal: 38.3s\tremaining: 19.8s\n",
      "660:\tlearn: 0.0254778\ttotal: 38.4s\tremaining: 19.7s\n",
      "661:\tlearn: 0.0254199\ttotal: 38.5s\tremaining: 19.6s\n",
      "662:\tlearn: 0.0253333\ttotal: 38.5s\tremaining: 19.6s\n",
      "663:\tlearn: 0.0252526\ttotal: 38.6s\tremaining: 19.5s\n",
      "664:\tlearn: 0.0251248\ttotal: 38.6s\tremaining: 19.5s\n",
      "665:\tlearn: 0.0250180\ttotal: 38.7s\tremaining: 19.4s\n",
      "666:\tlearn: 0.0249237\ttotal: 38.7s\tremaining: 19.3s\n",
      "667:\tlearn: 0.0248147\ttotal: 38.8s\tremaining: 19.3s\n",
      "668:\tlearn: 0.0247182\ttotal: 38.9s\tremaining: 19.2s\n",
      "669:\tlearn: 0.0246526\ttotal: 38.9s\tremaining: 19.2s\n",
      "670:\tlearn: 0.0245651\ttotal: 39s\tremaining: 19.1s\n",
      "671:\tlearn: 0.0244760\ttotal: 39s\tremaining: 19.1s\n",
      "672:\tlearn: 0.0244008\ttotal: 39.1s\tremaining: 19s\n",
      "673:\tlearn: 0.0243246\ttotal: 39.2s\tremaining: 18.9s\n",
      "674:\tlearn: 0.0242577\ttotal: 39.2s\tremaining: 18.9s\n",
      "675:\tlearn: 0.0241961\ttotal: 39.3s\tremaining: 18.8s\n",
      "676:\tlearn: 0.0241310\ttotal: 39.4s\tremaining: 18.8s\n",
      "677:\tlearn: 0.0240612\ttotal: 39.4s\tremaining: 18.7s\n",
      "678:\tlearn: 0.0239506\ttotal: 39.4s\tremaining: 18.6s\n",
      "679:\tlearn: 0.0238446\ttotal: 39.5s\tremaining: 18.6s\n",
      "680:\tlearn: 0.0237552\ttotal: 39.6s\tremaining: 18.5s\n",
      "681:\tlearn: 0.0236561\ttotal: 39.6s\tremaining: 18.5s\n",
      "682:\tlearn: 0.0235815\ttotal: 39.7s\tremaining: 18.4s\n",
      "683:\tlearn: 0.0234989\ttotal: 39.8s\tremaining: 18.4s\n",
      "684:\tlearn: 0.0234571\ttotal: 39.8s\tremaining: 18.3s\n",
      "685:\tlearn: 0.0233626\ttotal: 39.9s\tremaining: 18.3s\n",
      "686:\tlearn: 0.0232702\ttotal: 39.9s\tremaining: 18.2s\n",
      "687:\tlearn: 0.0231688\ttotal: 40s\tremaining: 18.1s\n",
      "688:\tlearn: 0.0231191\ttotal: 40s\tremaining: 18.1s\n",
      "689:\tlearn: 0.0230336\ttotal: 40.1s\tremaining: 18s\n",
      "690:\tlearn: 0.0229635\ttotal: 40.1s\tremaining: 18s\n",
      "691:\tlearn: 0.0229096\ttotal: 40.2s\tremaining: 17.9s\n",
      "692:\tlearn: 0.0228338\ttotal: 40.3s\tremaining: 17.8s\n",
      "693:\tlearn: 0.0227429\ttotal: 40.3s\tremaining: 17.8s\n",
      "694:\tlearn: 0.0226839\ttotal: 40.4s\tremaining: 17.7s\n",
      "695:\tlearn: 0.0226095\ttotal: 40.5s\tremaining: 17.7s\n",
      "696:\tlearn: 0.0225133\ttotal: 40.5s\tremaining: 17.6s\n",
      "697:\tlearn: 0.0224002\ttotal: 40.6s\tremaining: 17.6s\n",
      "698:\tlearn: 0.0223042\ttotal: 40.6s\tremaining: 17.5s\n",
      "699:\tlearn: 0.0222345\ttotal: 40.7s\tremaining: 17.4s\n",
      "700:\tlearn: 0.0221597\ttotal: 40.8s\tremaining: 17.4s\n",
      "701:\tlearn: 0.0220755\ttotal: 40.8s\tremaining: 17.3s\n",
      "702:\tlearn: 0.0219760\ttotal: 40.8s\tremaining: 17.3s\n",
      "703:\tlearn: 0.0218956\ttotal: 40.9s\tremaining: 17.2s\n",
      "704:\tlearn: 0.0218416\ttotal: 41s\tremaining: 17.1s\n",
      "705:\tlearn: 0.0217547\ttotal: 41s\tremaining: 17.1s\n",
      "706:\tlearn: 0.0216822\ttotal: 41s\tremaining: 17s\n",
      "707:\tlearn: 0.0216093\ttotal: 41.1s\tremaining: 17s\n",
      "708:\tlearn: 0.0215255\ttotal: 41.2s\tremaining: 16.9s\n",
      "709:\tlearn: 0.0214725\ttotal: 41.2s\tremaining: 16.8s\n",
      "710:\tlearn: 0.0214030\ttotal: 41.3s\tremaining: 16.8s\n",
      "711:\tlearn: 0.0213169\ttotal: 41.4s\tremaining: 16.7s\n",
      "712:\tlearn: 0.0212090\ttotal: 41.5s\tremaining: 16.7s\n",
      "713:\tlearn: 0.0211457\ttotal: 41.5s\tremaining: 16.6s\n",
      "714:\tlearn: 0.0210791\ttotal: 41.5s\tremaining: 16.6s\n",
      "715:\tlearn: 0.0210030\ttotal: 41.6s\tremaining: 16.5s\n",
      "716:\tlearn: 0.0209188\ttotal: 41.7s\tremaining: 16.4s\n",
      "717:\tlearn: 0.0208618\ttotal: 41.7s\tremaining: 16.4s\n",
      "718:\tlearn: 0.0208115\ttotal: 41.8s\tremaining: 16.3s\n",
      "719:\tlearn: 0.0207514\ttotal: 41.8s\tremaining: 16.3s\n",
      "720:\tlearn: 0.0206929\ttotal: 41.9s\tremaining: 16.2s\n",
      "721:\tlearn: 0.0206310\ttotal: 42s\tremaining: 16.2s\n",
      "722:\tlearn: 0.0205827\ttotal: 42s\tremaining: 16.1s\n",
      "723:\tlearn: 0.0205308\ttotal: 42s\tremaining: 16s\n",
      "724:\tlearn: 0.0204730\ttotal: 42.1s\tremaining: 16s\n",
      "725:\tlearn: 0.0204096\ttotal: 42.2s\tremaining: 15.9s\n",
      "726:\tlearn: 0.0203402\ttotal: 42.2s\tremaining: 15.9s\n",
      "727:\tlearn: 0.0202914\ttotal: 42.3s\tremaining: 15.8s\n",
      "728:\tlearn: 0.0202182\ttotal: 42.4s\tremaining: 15.7s\n",
      "729:\tlearn: 0.0201706\ttotal: 42.4s\tremaining: 15.7s\n",
      "730:\tlearn: 0.0201371\ttotal: 42.5s\tremaining: 15.6s\n",
      "731:\tlearn: 0.0200921\ttotal: 42.6s\tremaining: 15.6s\n",
      "732:\tlearn: 0.0200340\ttotal: 42.7s\tremaining: 15.5s\n",
      "733:\tlearn: 0.0199618\ttotal: 42.7s\tremaining: 15.5s\n",
      "734:\tlearn: 0.0198810\ttotal: 42.8s\tremaining: 15.4s\n",
      "735:\tlearn: 0.0197953\ttotal: 42.9s\tremaining: 15.4s\n",
      "736:\tlearn: 0.0197420\ttotal: 42.9s\tremaining: 15.3s\n",
      "737:\tlearn: 0.0196778\ttotal: 43s\tremaining: 15.3s\n",
      "738:\tlearn: 0.0196391\ttotal: 43s\tremaining: 15.2s\n",
      "739:\tlearn: 0.0195683\ttotal: 43.1s\tremaining: 15.1s\n",
      "740:\tlearn: 0.0195306\ttotal: 43.2s\tremaining: 15.1s\n",
      "741:\tlearn: 0.0194533\ttotal: 43.2s\tremaining: 15s\n",
      "742:\tlearn: 0.0193812\ttotal: 43.2s\tremaining: 15s\n",
      "743:\tlearn: 0.0193158\ttotal: 43.3s\tremaining: 14.9s\n",
      "744:\tlearn: 0.0192527\ttotal: 43.4s\tremaining: 14.8s\n",
      "745:\tlearn: 0.0191871\ttotal: 43.4s\tremaining: 14.8s\n",
      "746:\tlearn: 0.0191289\ttotal: 43.5s\tremaining: 14.7s\n",
      "747:\tlearn: 0.0190728\ttotal: 43.6s\tremaining: 14.7s\n",
      "748:\tlearn: 0.0189873\ttotal: 43.6s\tremaining: 14.6s\n",
      "749:\tlearn: 0.0188972\ttotal: 43.7s\tremaining: 14.6s\n",
      "750:\tlearn: 0.0188475\ttotal: 43.7s\tremaining: 14.5s\n",
      "751:\tlearn: 0.0187806\ttotal: 43.8s\tremaining: 14.4s\n",
      "752:\tlearn: 0.0187443\ttotal: 43.8s\tremaining: 14.4s\n",
      "753:\tlearn: 0.0186767\ttotal: 43.9s\tremaining: 14.3s\n",
      "754:\tlearn: 0.0186123\ttotal: 43.9s\tremaining: 14.3s\n",
      "755:\tlearn: 0.0185597\ttotal: 44s\tremaining: 14.2s\n",
      "756:\tlearn: 0.0185225\ttotal: 44.1s\tremaining: 14.2s\n",
      "757:\tlearn: 0.0184667\ttotal: 44.1s\tremaining: 14.1s\n",
      "758:\tlearn: 0.0183996\ttotal: 44.2s\tremaining: 14s\n",
      "759:\tlearn: 0.0183650\ttotal: 44.3s\tremaining: 14s\n",
      "760:\tlearn: 0.0183000\ttotal: 44.3s\tremaining: 13.9s\n",
      "761:\tlearn: 0.0182640\ttotal: 44.4s\tremaining: 13.9s\n",
      "762:\tlearn: 0.0181870\ttotal: 44.5s\tremaining: 13.8s\n",
      "763:\tlearn: 0.0181436\ttotal: 44.5s\tremaining: 13.7s\n",
      "764:\tlearn: 0.0180917\ttotal: 44.6s\tremaining: 13.7s\n",
      "765:\tlearn: 0.0180477\ttotal: 44.6s\tremaining: 13.6s\n",
      "766:\tlearn: 0.0179626\ttotal: 44.7s\tremaining: 13.6s\n",
      "767:\tlearn: 0.0179006\ttotal: 44.8s\tremaining: 13.5s\n",
      "768:\tlearn: 0.0178389\ttotal: 44.8s\tremaining: 13.5s\n",
      "769:\tlearn: 0.0177638\ttotal: 44.8s\tremaining: 13.4s\n",
      "770:\tlearn: 0.0177021\ttotal: 44.9s\tremaining: 13.3s\n",
      "771:\tlearn: 0.0176574\ttotal: 45s\tremaining: 13.3s\n",
      "772:\tlearn: 0.0176139\ttotal: 45s\tremaining: 13.2s\n",
      "773:\tlearn: 0.0175668\ttotal: 45.1s\tremaining: 13.2s\n",
      "774:\tlearn: 0.0174968\ttotal: 45.1s\tremaining: 13.1s\n",
      "775:\tlearn: 0.0174272\ttotal: 45.2s\tremaining: 13s\n",
      "776:\tlearn: 0.0173772\ttotal: 45.2s\tremaining: 13s\n",
      "777:\tlearn: 0.0173061\ttotal: 45.3s\tremaining: 12.9s\n",
      "778:\tlearn: 0.0172441\ttotal: 45.3s\tremaining: 12.9s\n",
      "779:\tlearn: 0.0171979\ttotal: 45.4s\tremaining: 12.8s\n",
      "780:\tlearn: 0.0171341\ttotal: 45.5s\tremaining: 12.8s\n",
      "781:\tlearn: 0.0170733\ttotal: 45.5s\tremaining: 12.7s\n",
      "782:\tlearn: 0.0170466\ttotal: 45.6s\tremaining: 12.6s\n",
      "783:\tlearn: 0.0169831\ttotal: 45.7s\tremaining: 12.6s\n",
      "784:\tlearn: 0.0169328\ttotal: 45.7s\tremaining: 12.5s\n",
      "785:\tlearn: 0.0168805\ttotal: 45.7s\tremaining: 12.5s\n",
      "786:\tlearn: 0.0168489\ttotal: 45.8s\tremaining: 12.4s\n",
      "787:\tlearn: 0.0167745\ttotal: 45.9s\tremaining: 12.3s\n",
      "788:\tlearn: 0.0167203\ttotal: 45.9s\tremaining: 12.3s\n",
      "789:\tlearn: 0.0166732\ttotal: 46s\tremaining: 12.2s\n",
      "790:\tlearn: 0.0166292\ttotal: 46.1s\tremaining: 12.2s\n",
      "791:\tlearn: 0.0165861\ttotal: 46.1s\tremaining: 12.1s\n",
      "792:\tlearn: 0.0165185\ttotal: 46.2s\tremaining: 12.1s\n",
      "793:\tlearn: 0.0164740\ttotal: 46.2s\tremaining: 12s\n",
      "794:\tlearn: 0.0164168\ttotal: 46.3s\tremaining: 11.9s\n",
      "795:\tlearn: 0.0163747\ttotal: 46.4s\tremaining: 11.9s\n",
      "796:\tlearn: 0.0163035\ttotal: 46.4s\tremaining: 11.8s\n",
      "797:\tlearn: 0.0162586\ttotal: 46.4s\tremaining: 11.8s\n",
      "798:\tlearn: 0.0161857\ttotal: 46.6s\tremaining: 11.7s\n",
      "799:\tlearn: 0.0161499\ttotal: 46.6s\tremaining: 11.6s\n",
      "800:\tlearn: 0.0161264\ttotal: 46.6s\tremaining: 11.6s\n",
      "801:\tlearn: 0.0160559\ttotal: 46.7s\tremaining: 11.5s\n",
      "802:\tlearn: 0.0160086\ttotal: 46.8s\tremaining: 11.5s\n",
      "803:\tlearn: 0.0159540\ttotal: 46.8s\tremaining: 11.4s\n",
      "804:\tlearn: 0.0159028\ttotal: 46.9s\tremaining: 11.4s\n",
      "805:\tlearn: 0.0158699\ttotal: 46.9s\tremaining: 11.3s\n",
      "806:\tlearn: 0.0158253\ttotal: 47s\tremaining: 11.2s\n",
      "807:\tlearn: 0.0157748\ttotal: 47.1s\tremaining: 11.2s\n",
      "808:\tlearn: 0.0157206\ttotal: 47.1s\tremaining: 11.1s\n",
      "809:\tlearn: 0.0156450\ttotal: 47.2s\tremaining: 11.1s\n",
      "810:\tlearn: 0.0155852\ttotal: 47.3s\tremaining: 11s\n",
      "811:\tlearn: 0.0155331\ttotal: 47.3s\tremaining: 10.9s\n",
      "812:\tlearn: 0.0155078\ttotal: 47.3s\tremaining: 10.9s\n",
      "813:\tlearn: 0.0154857\ttotal: 47.4s\tremaining: 10.8s\n",
      "814:\tlearn: 0.0154298\ttotal: 47.5s\tremaining: 10.8s\n",
      "815:\tlearn: 0.0153869\ttotal: 47.5s\tremaining: 10.7s\n",
      "816:\tlearn: 0.0153352\ttotal: 47.6s\tremaining: 10.7s\n",
      "817:\tlearn: 0.0152882\ttotal: 47.6s\tremaining: 10.6s\n",
      "818:\tlearn: 0.0152369\ttotal: 47.7s\tremaining: 10.5s\n",
      "819:\tlearn: 0.0151979\ttotal: 47.7s\tremaining: 10.5s\n",
      "820:\tlearn: 0.0151604\ttotal: 47.8s\tremaining: 10.4s\n",
      "821:\tlearn: 0.0151191\ttotal: 47.9s\tremaining: 10.4s\n",
      "822:\tlearn: 0.0150596\ttotal: 47.9s\tremaining: 10.3s\n",
      "823:\tlearn: 0.0150093\ttotal: 48s\tremaining: 10.3s\n",
      "824:\tlearn: 0.0149667\ttotal: 48s\tremaining: 10.2s\n",
      "825:\tlearn: 0.0149251\ttotal: 48.1s\tremaining: 10.1s\n",
      "826:\tlearn: 0.0148676\ttotal: 48.1s\tremaining: 10.1s\n",
      "827:\tlearn: 0.0148131\ttotal: 48.2s\tremaining: 10s\n",
      "828:\tlearn: 0.0147819\ttotal: 48.2s\tremaining: 9.95s\n",
      "829:\tlearn: 0.0147337\ttotal: 48.4s\tremaining: 9.9s\n",
      "830:\tlearn: 0.0146701\ttotal: 48.4s\tremaining: 9.84s\n",
      "831:\tlearn: 0.0146200\ttotal: 48.4s\tremaining: 9.78s\n",
      "832:\tlearn: 0.0145836\ttotal: 48.5s\tremaining: 9.73s\n",
      "833:\tlearn: 0.0145454\ttotal: 48.6s\tremaining: 9.67s\n",
      "834:\tlearn: 0.0145148\ttotal: 48.6s\tremaining: 9.6s\n",
      "835:\tlearn: 0.0144637\ttotal: 48.7s\tremaining: 9.55s\n",
      "836:\tlearn: 0.0144398\ttotal: 48.7s\tremaining: 9.49s\n",
      "837:\tlearn: 0.0144059\ttotal: 48.8s\tremaining: 9.43s\n",
      "838:\tlearn: 0.0143529\ttotal: 48.9s\tremaining: 9.38s\n",
      "839:\tlearn: 0.0143111\ttotal: 48.9s\tremaining: 9.32s\n",
      "840:\tlearn: 0.0142635\ttotal: 49s\tremaining: 9.26s\n",
      "841:\tlearn: 0.0142284\ttotal: 49.1s\tremaining: 9.21s\n",
      "842:\tlearn: 0.0141845\ttotal: 49.1s\tremaining: 9.15s\n",
      "843:\tlearn: 0.0141380\ttotal: 49.1s\tremaining: 9.08s\n",
      "844:\tlearn: 0.0140923\ttotal: 49.2s\tremaining: 9.03s\n",
      "845:\tlearn: 0.0140612\ttotal: 49.3s\tremaining: 8.97s\n",
      "846:\tlearn: 0.0140234\ttotal: 49.3s\tremaining: 8.91s\n",
      "847:\tlearn: 0.0139796\ttotal: 49.4s\tremaining: 8.85s\n",
      "848:\tlearn: 0.0139474\ttotal: 49.5s\tremaining: 8.79s\n",
      "849:\tlearn: 0.0138987\ttotal: 49.5s\tremaining: 8.73s\n",
      "850:\tlearn: 0.0138474\ttotal: 49.5s\tremaining: 8.68s\n",
      "851:\tlearn: 0.0138306\ttotal: 49.6s\tremaining: 8.62s\n",
      "852:\tlearn: 0.0137888\ttotal: 49.7s\tremaining: 8.56s\n",
      "853:\tlearn: 0.0137571\ttotal: 49.7s\tremaining: 8.5s\n",
      "854:\tlearn: 0.0137030\ttotal: 49.8s\tremaining: 8.45s\n",
      "855:\tlearn: 0.0136691\ttotal: 49.8s\tremaining: 8.38s\n",
      "856:\tlearn: 0.0136295\ttotal: 49.9s\tremaining: 8.32s\n",
      "857:\tlearn: 0.0135843\ttotal: 50s\tremaining: 8.27s\n",
      "858:\tlearn: 0.0135579\ttotal: 50s\tremaining: 8.21s\n",
      "859:\tlearn: 0.0135222\ttotal: 50s\tremaining: 8.14s\n",
      "860:\tlearn: 0.0134870\ttotal: 50.1s\tremaining: 8.09s\n",
      "861:\tlearn: 0.0134436\ttotal: 50.2s\tremaining: 8.03s\n",
      "862:\tlearn: 0.0133988\ttotal: 50.2s\tremaining: 7.97s\n",
      "863:\tlearn: 0.0133763\ttotal: 50.3s\tremaining: 7.92s\n",
      "864:\tlearn: 0.0133317\ttotal: 50.4s\tremaining: 7.86s\n",
      "865:\tlearn: 0.0132897\ttotal: 50.4s\tremaining: 7.8s\n",
      "866:\tlearn: 0.0132554\ttotal: 50.4s\tremaining: 7.74s\n",
      "867:\tlearn: 0.0132203\ttotal: 50.5s\tremaining: 7.68s\n",
      "868:\tlearn: 0.0131842\ttotal: 50.6s\tremaining: 7.62s\n",
      "869:\tlearn: 0.0131550\ttotal: 50.6s\tremaining: 7.57s\n",
      "870:\tlearn: 0.0131086\ttotal: 50.8s\tremaining: 7.52s\n",
      "871:\tlearn: 0.0130592\ttotal: 50.8s\tremaining: 7.46s\n",
      "872:\tlearn: 0.0130227\ttotal: 50.9s\tremaining: 7.4s\n",
      "873:\tlearn: 0.0129804\ttotal: 50.9s\tremaining: 7.34s\n",
      "874:\tlearn: 0.0129483\ttotal: 51s\tremaining: 7.28s\n",
      "875:\tlearn: 0.0129085\ttotal: 51s\tremaining: 7.22s\n",
      "876:\tlearn: 0.0128740\ttotal: 51.1s\tremaining: 7.16s\n",
      "877:\tlearn: 0.0128515\ttotal: 51.2s\tremaining: 7.11s\n",
      "878:\tlearn: 0.0128246\ttotal: 51.2s\tremaining: 7.05s\n",
      "879:\tlearn: 0.0127968\ttotal: 51.3s\tremaining: 6.99s\n",
      "880:\tlearn: 0.0127668\ttotal: 51.4s\tremaining: 6.94s\n",
      "881:\tlearn: 0.0127119\ttotal: 51.4s\tremaining: 6.88s\n",
      "882:\tlearn: 0.0126822\ttotal: 51.4s\tremaining: 6.81s\n",
      "883:\tlearn: 0.0126287\ttotal: 51.5s\tremaining: 6.76s\n",
      "884:\tlearn: 0.0125959\ttotal: 51.6s\tremaining: 6.7s\n",
      "885:\tlearn: 0.0125621\ttotal: 51.6s\tremaining: 6.64s\n",
      "886:\tlearn: 0.0125203\ttotal: 51.7s\tremaining: 6.58s\n",
      "887:\tlearn: 0.0124826\ttotal: 51.7s\tremaining: 6.53s\n",
      "888:\tlearn: 0.0124587\ttotal: 51.8s\tremaining: 6.46s\n",
      "889:\tlearn: 0.0124230\ttotal: 51.8s\tremaining: 6.41s\n",
      "890:\tlearn: 0.0124036\ttotal: 51.9s\tremaining: 6.35s\n",
      "891:\tlearn: 0.0123781\ttotal: 51.9s\tremaining: 6.29s\n",
      "892:\tlearn: 0.0123331\ttotal: 52s\tremaining: 6.23s\n",
      "893:\tlearn: 0.0122999\ttotal: 52.1s\tremaining: 6.17s\n",
      "894:\tlearn: 0.0122729\ttotal: 52.1s\tremaining: 6.11s\n",
      "895:\tlearn: 0.0122509\ttotal: 52.2s\tremaining: 6.05s\n",
      "896:\tlearn: 0.0122197\ttotal: 52.2s\tremaining: 5.99s\n",
      "897:\tlearn: 0.0121856\ttotal: 52.3s\tremaining: 5.94s\n",
      "898:\tlearn: 0.0121599\ttotal: 52.3s\tremaining: 5.88s\n",
      "899:\tlearn: 0.0121078\ttotal: 52.4s\tremaining: 5.82s\n",
      "900:\tlearn: 0.0120721\ttotal: 52.5s\tremaining: 5.76s\n",
      "901:\tlearn: 0.0120481\ttotal: 52.5s\tremaining: 5.71s\n",
      "902:\tlearn: 0.0120263\ttotal: 52.5s\tremaining: 5.64s\n",
      "903:\tlearn: 0.0119868\ttotal: 52.6s\tremaining: 5.59s\n",
      "904:\tlearn: 0.0119695\ttotal: 52.7s\tremaining: 5.53s\n",
      "905:\tlearn: 0.0119432\ttotal: 52.7s\tremaining: 5.47s\n",
      "906:\tlearn: 0.0119064\ttotal: 52.8s\tremaining: 5.42s\n",
      "907:\tlearn: 0.0118852\ttotal: 52.9s\tremaining: 5.36s\n",
      "908:\tlearn: 0.0118431\ttotal: 52.9s\tremaining: 5.3s\n",
      "909:\tlearn: 0.0118073\ttotal: 53s\tremaining: 5.24s\n",
      "910:\tlearn: 0.0117781\ttotal: 53s\tremaining: 5.18s\n",
      "911:\tlearn: 0.0117544\ttotal: 53.1s\tremaining: 5.12s\n",
      "912:\tlearn: 0.0117260\ttotal: 53.2s\tremaining: 5.07s\n",
      "913:\tlearn: 0.0116970\ttotal: 53.2s\tremaining: 5.01s\n",
      "914:\tlearn: 0.0116615\ttotal: 53.3s\tremaining: 4.95s\n",
      "915:\tlearn: 0.0116387\ttotal: 53.3s\tremaining: 4.89s\n",
      "916:\tlearn: 0.0115964\ttotal: 53.4s\tremaining: 4.83s\n",
      "917:\tlearn: 0.0115656\ttotal: 53.4s\tremaining: 4.77s\n",
      "918:\tlearn: 0.0115325\ttotal: 53.4s\tremaining: 4.71s\n",
      "919:\tlearn: 0.0114995\ttotal: 53.5s\tremaining: 4.65s\n",
      "920:\tlearn: 0.0114667\ttotal: 53.6s\tremaining: 4.59s\n",
      "921:\tlearn: 0.0114480\ttotal: 53.6s\tremaining: 4.54s\n",
      "922:\tlearn: 0.0114117\ttotal: 53.6s\tremaining: 4.47s\n",
      "923:\tlearn: 0.0113885\ttotal: 53.7s\tremaining: 4.42s\n",
      "924:\tlearn: 0.0113713\ttotal: 53.8s\tremaining: 4.36s\n",
      "925:\tlearn: 0.0113358\ttotal: 53.8s\tremaining: 4.3s\n",
      "926:\tlearn: 0.0112991\ttotal: 53.9s\tremaining: 4.25s\n",
      "927:\tlearn: 0.0112852\ttotal: 54s\tremaining: 4.19s\n",
      "928:\tlearn: 0.0112628\ttotal: 54s\tremaining: 4.13s\n",
      "929:\tlearn: 0.0112294\ttotal: 54.1s\tremaining: 4.07s\n",
      "930:\tlearn: 0.0111972\ttotal: 54.1s\tremaining: 4.01s\n",
      "931:\tlearn: 0.0111592\ttotal: 54.2s\tremaining: 3.95s\n",
      "932:\tlearn: 0.0111389\ttotal: 54.3s\tremaining: 3.9s\n",
      "933:\tlearn: 0.0111135\ttotal: 54.3s\tremaining: 3.84s\n",
      "934:\tlearn: 0.0110798\ttotal: 54.3s\tremaining: 3.78s\n",
      "935:\tlearn: 0.0110583\ttotal: 54.4s\tremaining: 3.72s\n",
      "936:\tlearn: 0.0110294\ttotal: 54.5s\tremaining: 3.66s\n",
      "937:\tlearn: 0.0110153\ttotal: 54.5s\tremaining: 3.6s\n",
      "938:\tlearn: 0.0109811\ttotal: 54.6s\tremaining: 3.54s\n",
      "939:\tlearn: 0.0109593\ttotal: 54.7s\tremaining: 3.49s\n",
      "940:\tlearn: 0.0109286\ttotal: 54.7s\tremaining: 3.43s\n",
      "941:\tlearn: 0.0109028\ttotal: 54.7s\tremaining: 3.37s\n",
      "942:\tlearn: 0.0108852\ttotal: 54.8s\tremaining: 3.31s\n",
      "943:\tlearn: 0.0108487\ttotal: 54.9s\tremaining: 3.25s\n",
      "944:\tlearn: 0.0108252\ttotal: 54.9s\tremaining: 3.19s\n",
      "945:\tlearn: 0.0108061\ttotal: 55s\tremaining: 3.14s\n",
      "946:\tlearn: 0.0107743\ttotal: 55s\tremaining: 3.08s\n",
      "947:\tlearn: 0.0107418\ttotal: 55.1s\tremaining: 3.02s\n",
      "948:\tlearn: 0.0107206\ttotal: 55.1s\tremaining: 2.96s\n",
      "949:\tlearn: 0.0106960\ttotal: 55.2s\tremaining: 2.91s\n",
      "950:\tlearn: 0.0106717\ttotal: 55.3s\tremaining: 2.85s\n",
      "951:\tlearn: 0.0106345\ttotal: 55.3s\tremaining: 2.79s\n",
      "952:\tlearn: 0.0106153\ttotal: 55.4s\tremaining: 2.73s\n",
      "953:\tlearn: 0.0105873\ttotal: 55.4s\tremaining: 2.67s\n",
      "954:\tlearn: 0.0105519\ttotal: 55.5s\tremaining: 2.61s\n",
      "955:\tlearn: 0.0105334\ttotal: 55.5s\tremaining: 2.56s\n",
      "956:\tlearn: 0.0105106\ttotal: 55.6s\tremaining: 2.5s\n",
      "957:\tlearn: 0.0104950\ttotal: 55.6s\tremaining: 2.44s\n",
      "958:\tlearn: 0.0104688\ttotal: 55.7s\tremaining: 2.38s\n",
      "959:\tlearn: 0.0104528\ttotal: 55.8s\tremaining: 2.32s\n",
      "960:\tlearn: 0.0104229\ttotal: 55.8s\tremaining: 2.26s\n",
      "961:\tlearn: 0.0103841\ttotal: 55.9s\tremaining: 2.21s\n",
      "962:\tlearn: 0.0103522\ttotal: 55.9s\tremaining: 2.15s\n",
      "963:\tlearn: 0.0103257\ttotal: 56s\tremaining: 2.09s\n",
      "964:\tlearn: 0.0102917\ttotal: 56.1s\tremaining: 2.03s\n",
      "965:\tlearn: 0.0102625\ttotal: 56.1s\tremaining: 1.98s\n",
      "966:\tlearn: 0.0102341\ttotal: 56.1s\tremaining: 1.92s\n",
      "967:\tlearn: 0.0102037\ttotal: 56.2s\tremaining: 1.86s\n",
      "968:\tlearn: 0.0101837\ttotal: 56.3s\tremaining: 1.8s\n",
      "969:\tlearn: 0.0101488\ttotal: 56.4s\tremaining: 1.74s\n",
      "970:\tlearn: 0.0101200\ttotal: 56.4s\tremaining: 1.69s\n",
      "971:\tlearn: 0.0100874\ttotal: 56.5s\tremaining: 1.63s\n",
      "972:\tlearn: 0.0100584\ttotal: 56.6s\tremaining: 1.57s\n",
      "973:\tlearn: 0.0100327\ttotal: 56.6s\tremaining: 1.51s\n",
      "974:\tlearn: 0.0100137\ttotal: 56.6s\tremaining: 1.45s\n",
      "975:\tlearn: 0.0099887\ttotal: 56.7s\tremaining: 1.4s\n",
      "976:\tlearn: 0.0099710\ttotal: 56.8s\tremaining: 1.34s\n",
      "977:\tlearn: 0.0099402\ttotal: 56.8s\tremaining: 1.28s\n",
      "978:\tlearn: 0.0099207\ttotal: 56.9s\tremaining: 1.22s\n",
      "979:\tlearn: 0.0098946\ttotal: 57s\tremaining: 1.16s\n",
      "980:\tlearn: 0.0098709\ttotal: 57s\tremaining: 1.1s\n",
      "981:\tlearn: 0.0098368\ttotal: 57.1s\tremaining: 1.05s\n",
      "982:\tlearn: 0.0098099\ttotal: 57.2s\tremaining: 988ms\n",
      "983:\tlearn: 0.0097905\ttotal: 57.2s\tremaining: 930ms\n",
      "984:\tlearn: 0.0097705\ttotal: 57.3s\tremaining: 872ms\n",
      "985:\tlearn: 0.0097398\ttotal: 57.3s\tremaining: 814ms\n",
      "986:\tlearn: 0.0097189\ttotal: 57.4s\tremaining: 756ms\n",
      "987:\tlearn: 0.0096949\ttotal: 57.4s\tremaining: 698ms\n",
      "988:\tlearn: 0.0096696\ttotal: 57.5s\tremaining: 639ms\n",
      "989:\tlearn: 0.0096526\ttotal: 57.5s\tremaining: 581ms\n",
      "990:\tlearn: 0.0096361\ttotal: 57.6s\tremaining: 523ms\n",
      "991:\tlearn: 0.0096129\ttotal: 57.7s\tremaining: 465ms\n",
      "992:\tlearn: 0.0095911\ttotal: 57.7s\tremaining: 407ms\n",
      "993:\tlearn: 0.0095632\ttotal: 57.8s\tremaining: 349ms\n",
      "994:\tlearn: 0.0095411\ttotal: 57.8s\tremaining: 291ms\n",
      "995:\tlearn: 0.0095184\ttotal: 57.9s\tremaining: 232ms\n",
      "996:\tlearn: 0.0094940\ttotal: 58s\tremaining: 174ms\n",
      "997:\tlearn: 0.0094735\ttotal: 58s\tremaining: 116ms\n",
      "998:\tlearn: 0.0094506\ttotal: 58s\tremaining: 58.1ms\n",
      "999:\tlearn: 0.0094308\ttotal: 58.1s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "\n",
    "for model, name in zip([lr, knn, svm, dt, bag, adb, gb, rf, cgb, lgb,  xgb], ['Logistic Regression', 'KNeighbors', 'SVM',\n",
    "                                                                             'DecisionTree', 'Bagging', 'AdaBoost', 'GradientBoost',\n",
    "                                                                             'Random Forest', 'CatBoost', 'LightGBM', 'XGBoost']):\n",
    "    if model==xgb:\n",
    "        le = LabelEncoder()\n",
    "        y_tr = le.fit_transform(y_tr)\n",
    "        y_te = le.fit_transform(y_te)\n",
    "        \n",
    "    result[name] = fun(model, x_tr_ss, x_te_ss, y_tr, y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "caba6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smit1\\AppData\\Local\\Temp\\ipykernel_10072\\1669963339.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mod_perform = pd.DataFrame(np.array(list(result.values()))[:, :-1], columns=['Training Score', 'Test Score', 'Duration'],\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.77094</td>\n",
       "      <td>0.721843</td>\n",
       "      <td>0.113728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.90273</td>\n",
       "      <td>0.773142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.996581</td>\n",
       "      <td>0.986348</td>\n",
       "      <td>1.214389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.361856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.757679</td>\n",
       "      <td>1.688601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.937179</td>\n",
       "      <td>0.754266</td>\n",
       "      <td>1.668377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost</th>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>7.709227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.858362</td>\n",
       "      <td>1.682107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988055</td>\n",
       "      <td>59.595356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911263</td>\n",
       "      <td>1.818029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964164</td>\n",
       "      <td>2.189227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Training Score Test Score   Duration\n",
       "Model                                                   \n",
       "Logistic Regression        0.77094   0.721843   0.113728\n",
       "KNeighbors                0.931624    0.90273   0.773142\n",
       "SVM                       0.996581   0.986348   1.214389\n",
       "DecisionTree                   1.0   0.675768   0.361856\n",
       "Bagging                   0.999573   0.757679   1.688601\n",
       "AdaBoost                  0.937179   0.754266   1.668377\n",
       "GradientBoost             0.998291   0.849829   7.709227\n",
       "Random Forest                  1.0   0.858362   1.682107\n",
       "CatBoost                       1.0   0.988055  59.595356\n",
       "LightGBM                       1.0   0.911263   1.818029\n",
       "XGBoost                        1.0   0.964164   2.189227"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the result as a dataframe\n",
    "mod_perform = pd.DataFrame(np.array(list(result.values()))[:, :-1], columns=['Training Score', 'Test Score', 'Duration'],\n",
    "                         index = result.keys())\n",
    "mod_perform.index.name = 'Model'\n",
    "mod_perform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8376252",
   "metadata": {},
   "source": [
    "##### Building all the models with PCA & with Hypertuning of Parameters\n",
    "\n",
    "We have already upsampled the data in 4B, then we scaled the data in 5B & performed PCA in 5D. Hence we use the same model here to tune the HyperParameters:\n",
    "\n",
    "xpca_tr, xpca_te, ypca_tr, ypca_te\n",
    "\n",
    "Hence we just tune the parmeters here Using RandomizedSearchCV\n",
    "\n",
    "Also we have tuned Logistic Regression Model in 5D.\n",
    "\n",
    "We have already build the all model previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2fb0152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tun_fun(model, name, xpca_tr, xpca_te, ypca_tr, ypca_te):\n",
    "    global filename\n",
    "    start = time.time()\n",
    "    rscv = RandomizedSearchCV(model, params, cv=10, random_state=1)\n",
    "    rscv.fit(xpca_tr, ypca_tr)\n",
    "    rscv_best_params = rscv.best_params_\n",
    "    rscv_best_score = rscv.best_score_\n",
    "    rscv_score_train = rscv.score(xpca_tr, ypca_tr)\n",
    "    rscv_score_test = rscv.score(xpca_te, ypca_te)\n",
    "    rscv_pred = rscv.predict(xpca_te)\n",
    "    end = time.time()\n",
    "    pickle.dump(rscv, open(name, 'wb'))\n",
    "    \n",
    "    rscv_duration = end-start\n",
    "    return rscv_best_params, rscv_best_score, rscv_score_train, rscv_score_test, rscv_duration, rscv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb414a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "70 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 48, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got lfbgs.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.73589744        nan        nan        nan        nan 0.73888889\n",
      " 0.73162393        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "40 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 238, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1452, in check_scalar\n",
      "    raise TypeError(\n",
      "TypeError: max_depth must be an instance of int, not ndarray.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.95811966        nan 0.96068376 0.95726496 0.96666667 0.95726496\n",
      "        nan        nan 0.96111111        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:675: RuntimeWarning: overflow encountered in exp\n",
      "  sample_weight = np.exp(\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:506: UserWarning: Sample weights have reached infinite values, at iteration 3, causing overflow. Iterations stopped. Try lowering the learning rate.\n",
      "  return super().fit(X, y, sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6515705\ttotal: 65.6ms\tremaining: 32.7s\n",
      "1:\tlearn: 0.6115368\ttotal: 110ms\tremaining: 27.3s\n",
      "2:\tlearn: 0.5795733\ttotal: 213ms\tremaining: 35.2s\n",
      "3:\tlearn: 0.5475655\ttotal: 258ms\tremaining: 31.9s\n",
      "4:\tlearn: 0.5119059\ttotal: 371ms\tremaining: 36.8s\n",
      "5:\tlearn: 0.4839112\ttotal: 441ms\tremaining: 36.3s\n",
      "6:\tlearn: 0.4542017\ttotal: 489ms\tremaining: 34.4s\n",
      "7:\tlearn: 0.4336639\ttotal: 599ms\tremaining: 36.9s\n",
      "8:\tlearn: 0.4143273\ttotal: 647ms\tremaining: 35.3s\n",
      "9:\tlearn: 0.3962852\ttotal: 759ms\tremaining: 37.2s\n",
      "10:\tlearn: 0.3775537\ttotal: 807ms\tremaining: 35.9s\n",
      "11:\tlearn: 0.3604455\ttotal: 927ms\tremaining: 37.7s\n",
      "12:\tlearn: 0.3470574\ttotal: 972ms\tremaining: 36.4s\n",
      "13:\tlearn: 0.3304154\ttotal: 1.07s\tremaining: 37.1s\n",
      "14:\tlearn: 0.3128439\ttotal: 1.13s\tremaining: 36.6s\n",
      "15:\tlearn: 0.2947317\ttotal: 1.17s\tremaining: 35.4s\n",
      "16:\tlearn: 0.2803876\ttotal: 1.28s\tremaining: 36.5s\n",
      "17:\tlearn: 0.2640558\ttotal: 1.33s\tremaining: 35.6s\n",
      "18:\tlearn: 0.2515794\ttotal: 1.42s\tremaining: 36.1s\n",
      "19:\tlearn: 0.2410020\ttotal: 1.48s\tremaining: 35.6s\n",
      "20:\tlearn: 0.2329470\ttotal: 1.52s\tremaining: 34.8s\n",
      "21:\tlearn: 0.2231575\ttotal: 1.64s\tremaining: 35.7s\n",
      "22:\tlearn: 0.2148892\ttotal: 1.69s\tremaining: 35s\n",
      "23:\tlearn: 0.2078207\ttotal: 1.79s\tremaining: 35.4s\n",
      "24:\tlearn: 0.2011868\ttotal: 1.83s\tremaining: 34.8s\n",
      "25:\tlearn: 0.1931026\ttotal: 1.95s\tremaining: 35.5s\n",
      "26:\tlearn: 0.1865690\ttotal: 2s\tremaining: 35s\n",
      "27:\tlearn: 0.1773292\ttotal: 2.11s\tremaining: 35.6s\n",
      "28:\tlearn: 0.1714904\ttotal: 2.17s\tremaining: 35.2s\n",
      "29:\tlearn: 0.1661467\ttotal: 2.21s\tremaining: 34.6s\n",
      "30:\tlearn: 0.1585843\ttotal: 2.32s\tremaining: 35.1s\n",
      "31:\tlearn: 0.1547582\ttotal: 2.37s\tremaining: 34.6s\n",
      "32:\tlearn: 0.1486169\ttotal: 2.48s\tremaining: 35.1s\n",
      "33:\tlearn: 0.1435898\ttotal: 2.53s\tremaining: 34.7s\n",
      "34:\tlearn: 0.1372878\ttotal: 2.63s\tremaining: 34.9s\n",
      "35:\tlearn: 0.1304945\ttotal: 2.69s\tremaining: 34.7s\n",
      "36:\tlearn: 0.1267004\ttotal: 2.75s\tremaining: 34.4s\n",
      "37:\tlearn: 0.1228203\ttotal: 2.89s\tremaining: 35.2s\n",
      "38:\tlearn: 0.1192779\ttotal: 2.94s\tremaining: 34.7s\n",
      "39:\tlearn: 0.1141729\ttotal: 3.04s\tremaining: 35s\n",
      "40:\tlearn: 0.1104448\ttotal: 3.08s\tremaining: 34.5s\n",
      "41:\tlearn: 0.1073762\ttotal: 3.17s\tremaining: 34.6s\n",
      "42:\tlearn: 0.1039327\ttotal: 3.25s\tremaining: 34.6s\n",
      "43:\tlearn: 0.1002113\ttotal: 3.36s\tremaining: 34.8s\n",
      "44:\tlearn: 0.0974477\ttotal: 3.41s\tremaining: 34.5s\n",
      "45:\tlearn: 0.0947172\ttotal: 3.52s\tremaining: 34.7s\n",
      "46:\tlearn: 0.0904958\ttotal: 3.57s\tremaining: 34.5s\n",
      "47:\tlearn: 0.0875273\ttotal: 3.66s\tremaining: 34.5s\n",
      "48:\tlearn: 0.0842406\ttotal: 3.71s\tremaining: 34.2s\n",
      "49:\tlearn: 0.0815631\ttotal: 3.81s\tremaining: 34.3s\n",
      "50:\tlearn: 0.0789674\ttotal: 3.89s\tremaining: 34.2s\n",
      "51:\tlearn: 0.0756255\ttotal: 3.93s\tremaining: 33.9s\n",
      "52:\tlearn: 0.0735094\ttotal: 4.04s\tremaining: 34.1s\n",
      "53:\tlearn: 0.0714528\ttotal: 4.09s\tremaining: 33.8s\n",
      "54:\tlearn: 0.0689018\ttotal: 4.18s\tremaining: 33.8s\n",
      "55:\tlearn: 0.0667032\ttotal: 4.25s\tremaining: 33.7s\n",
      "56:\tlearn: 0.0651313\ttotal: 4.29s\tremaining: 33.3s\n",
      "57:\tlearn: 0.0624412\ttotal: 4.39s\tremaining: 33.5s\n",
      "58:\tlearn: 0.0602996\ttotal: 4.44s\tremaining: 33.2s\n",
      "59:\tlearn: 0.0584856\ttotal: 4.54s\tremaining: 33.3s\n",
      "60:\tlearn: 0.0571890\ttotal: 4.6s\tremaining: 33.1s\n",
      "61:\tlearn: 0.0549959\ttotal: 4.66s\tremaining: 32.9s\n",
      "62:\tlearn: 0.0528935\ttotal: 4.76s\tremaining: 33s\n",
      "63:\tlearn: 0.0506648\ttotal: 4.81s\tremaining: 32.8s\n",
      "64:\tlearn: 0.0492264\ttotal: 4.92s\tremaining: 32.9s\n",
      "65:\tlearn: 0.0480701\ttotal: 4.97s\tremaining: 32.7s\n",
      "66:\tlearn: 0.0457482\ttotal: 5.06s\tremaining: 32.7s\n",
      "67:\tlearn: 0.0437045\ttotal: 5.13s\tremaining: 32.6s\n",
      "68:\tlearn: 0.0423886\ttotal: 5.18s\tremaining: 32.3s\n",
      "69:\tlearn: 0.0413318\ttotal: 5.3s\tremaining: 32.5s\n",
      "70:\tlearn: 0.0401233\ttotal: 5.35s\tremaining: 32.3s\n",
      "71:\tlearn: 0.0389856\ttotal: 5.44s\tremaining: 32.3s\n",
      "72:\tlearn: 0.0379507\ttotal: 5.52s\tremaining: 32.3s\n",
      "73:\tlearn: 0.0371785\ttotal: 5.56s\tremaining: 32s\n",
      "74:\tlearn: 0.0360221\ttotal: 5.67s\tremaining: 32.1s\n",
      "75:\tlearn: 0.0350793\ttotal: 5.71s\tremaining: 31.9s\n",
      "76:\tlearn: 0.0339021\ttotal: 5.82s\tremaining: 32s\n",
      "77:\tlearn: 0.0329992\ttotal: 5.86s\tremaining: 31.7s\n",
      "78:\tlearn: 0.0322222\ttotal: 5.98s\tremaining: 31.9s\n",
      "79:\tlearn: 0.0316287\ttotal: 6.03s\tremaining: 31.7s\n",
      "80:\tlearn: 0.0307606\ttotal: 6.12s\tremaining: 31.7s\n",
      "81:\tlearn: 0.0296974\ttotal: 6.19s\tremaining: 31.6s\n",
      "82:\tlearn: 0.0287964\ttotal: 6.25s\tremaining: 31.4s\n",
      "83:\tlearn: 0.0283227\ttotal: 6.35s\tremaining: 31.4s\n",
      "84:\tlearn: 0.0278261\ttotal: 6.4s\tremaining: 31.2s\n",
      "85:\tlearn: 0.0272351\ttotal: 6.51s\tremaining: 31.3s\n",
      "86:\tlearn: 0.0264404\ttotal: 6.56s\tremaining: 31.1s\n",
      "87:\tlearn: 0.0257147\ttotal: 6.66s\tremaining: 31.2s\n",
      "88:\tlearn: 0.0252311\ttotal: 6.72s\tremaining: 31.1s\n",
      "89:\tlearn: 0.0242551\ttotal: 6.77s\tremaining: 30.8s\n",
      "90:\tlearn: 0.0236087\ttotal: 6.88s\tremaining: 30.9s\n",
      "91:\tlearn: 0.0231807\ttotal: 6.92s\tremaining: 30.7s\n",
      "92:\tlearn: 0.0226417\ttotal: 7.01s\tremaining: 30.7s\n",
      "93:\tlearn: 0.0220997\ttotal: 7.08s\tremaining: 30.6s\n",
      "94:\tlearn: 0.0213492\ttotal: 7.13s\tremaining: 30.4s\n",
      "95:\tlearn: 0.0208927\ttotal: 7.24s\tremaining: 30.5s\n",
      "96:\tlearn: 0.0203635\ttotal: 7.28s\tremaining: 30.3s\n",
      "97:\tlearn: 0.0198911\ttotal: 7.39s\tremaining: 30.3s\n",
      "98:\tlearn: 0.0194159\ttotal: 7.45s\tremaining: 30.2s\n",
      "99:\tlearn: 0.0189093\ttotal: 7.53s\tremaining: 30.1s\n",
      "100:\tlearn: 0.0184041\ttotal: 7.61s\tremaining: 30.1s\n",
      "101:\tlearn: 0.0179825\ttotal: 7.66s\tremaining: 29.9s\n",
      "102:\tlearn: 0.0176266\ttotal: 7.78s\tremaining: 30s\n",
      "103:\tlearn: 0.0171088\ttotal: 7.82s\tremaining: 29.8s\n",
      "104:\tlearn: 0.0165670\ttotal: 7.97s\tremaining: 30s\n",
      "105:\tlearn: 0.0161635\ttotal: 8.1s\tremaining: 30.1s\n",
      "106:\tlearn: 0.0158532\ttotal: 8.18s\tremaining: 30.1s\n",
      "107:\tlearn: 0.0154440\ttotal: 8.24s\tremaining: 29.9s\n",
      "108:\tlearn: 0.0150615\ttotal: 8.34s\tremaining: 29.9s\n",
      "109:\tlearn: 0.0147025\ttotal: 8.38s\tremaining: 29.7s\n",
      "110:\tlearn: 0.0143864\ttotal: 8.49s\tremaining: 29.7s\n",
      "111:\tlearn: 0.0140858\ttotal: 8.55s\tremaining: 29.6s\n",
      "112:\tlearn: 0.0138020\ttotal: 8.59s\tremaining: 29.4s\n",
      "113:\tlearn: 0.0135205\ttotal: 8.67s\tremaining: 29.3s\n",
      "114:\tlearn: 0.0132158\ttotal: 8.71s\tremaining: 29.2s\n",
      "115:\tlearn: 0.0130257\ttotal: 8.83s\tremaining: 29.2s\n",
      "116:\tlearn: 0.0126938\ttotal: 8.89s\tremaining: 29.1s\n",
      "117:\tlearn: 0.0123761\ttotal: 9s\tremaining: 29.1s\n",
      "118:\tlearn: 0.0121388\ttotal: 9.06s\tremaining: 29s\n",
      "119:\tlearn: 0.0118581\ttotal: 9.1s\tremaining: 28.8s\n",
      "120:\tlearn: 0.0116218\ttotal: 9.2s\tremaining: 28.8s\n",
      "121:\tlearn: 0.0113654\ttotal: 9.25s\tremaining: 28.7s\n",
      "122:\tlearn: 0.0111326\ttotal: 9.36s\tremaining: 28.7s\n",
      "123:\tlearn: 0.0108826\ttotal: 9.42s\tremaining: 28.6s\n",
      "124:\tlearn: 0.0107403\ttotal: 9.46s\tremaining: 28.4s\n",
      "125:\tlearn: 0.0105441\ttotal: 9.56s\tremaining: 28.4s\n",
      "126:\tlearn: 0.0103231\ttotal: 9.61s\tremaining: 28.2s\n",
      "127:\tlearn: 0.0101495\ttotal: 9.72s\tremaining: 28.2s\n",
      "128:\tlearn: 0.0099057\ttotal: 9.77s\tremaining: 28.1s\n",
      "129:\tlearn: 0.0097035\ttotal: 9.81s\tremaining: 27.9s\n",
      "130:\tlearn: 0.0095458\ttotal: 9.9s\tremaining: 27.9s\n",
      "131:\tlearn: 0.0093830\ttotal: 9.96s\tremaining: 27.8s\n",
      "132:\tlearn: 0.0092478\ttotal: 10s\tremaining: 27.6s\n",
      "133:\tlearn: 0.0091054\ttotal: 10.1s\tremaining: 27.6s\n",
      "134:\tlearn: 0.0089710\ttotal: 10.2s\tremaining: 27.5s\n",
      "135:\tlearn: 0.0088642\ttotal: 10.3s\tremaining: 27.5s\n",
      "136:\tlearn: 0.0087134\ttotal: 10.3s\tremaining: 27.4s\n",
      "137:\tlearn: 0.0085759\ttotal: 10.4s\tremaining: 27.3s\n",
      "138:\tlearn: 0.0084579\ttotal: 10.5s\tremaining: 27.3s\n",
      "139:\tlearn: 0.0083209\ttotal: 10.6s\tremaining: 27.3s\n",
      "140:\tlearn: 0.0081984\ttotal: 10.6s\tremaining: 27.1s\n",
      "141:\tlearn: 0.0080911\ttotal: 10.8s\tremaining: 27.2s\n",
      "142:\tlearn: 0.0079581\ttotal: 10.8s\tremaining: 27s\n",
      "143:\tlearn: 0.0077677\ttotal: 10.9s\tremaining: 27s\n",
      "144:\tlearn: 0.0076219\ttotal: 11s\tremaining: 26.9s\n",
      "145:\tlearn: 0.0074976\ttotal: 11s\tremaining: 26.7s\n",
      "146:\tlearn: 0.0073308\ttotal: 11.1s\tremaining: 26.7s\n",
      "147:\tlearn: 0.0071715\ttotal: 11.2s\tremaining: 26.6s\n",
      "148:\tlearn: 0.0070439\ttotal: 11.3s\tremaining: 26.6s\n",
      "149:\tlearn: 0.0069480\ttotal: 11.3s\tremaining: 26.5s\n",
      "150:\tlearn: 0.0067867\ttotal: 11.4s\tremaining: 26.3s\n",
      "151:\tlearn: 0.0067162\ttotal: 11.5s\tremaining: 26.3s\n",
      "152:\tlearn: 0.0066067\ttotal: 11.5s\tremaining: 26.2s\n",
      "153:\tlearn: 0.0065239\ttotal: 11.6s\tremaining: 26.2s\n",
      "154:\tlearn: 0.0064468\ttotal: 11.7s\tremaining: 26s\n",
      "155:\tlearn: 0.0063606\ttotal: 11.7s\tremaining: 25.9s\n",
      "156:\tlearn: 0.0062745\ttotal: 11.8s\tremaining: 25.9s\n",
      "157:\tlearn: 0.0061701\ttotal: 11.9s\tremaining: 25.7s\n",
      "158:\tlearn: 0.0060813\ttotal: 12s\tremaining: 25.8s\n",
      "159:\tlearn: 0.0060123\ttotal: 12.1s\tremaining: 25.6s\n",
      "160:\tlearn: 0.0059505\ttotal: 12.2s\tremaining: 25.6s\n",
      "161:\tlearn: 0.0058787\ttotal: 12.2s\tremaining: 25.5s\n",
      "162:\tlearn: 0.0057983\ttotal: 12.3s\tremaining: 25.4s\n",
      "163:\tlearn: 0.0057225\ttotal: 12.4s\tremaining: 25.4s\n",
      "164:\tlearn: 0.0056469\ttotal: 12.4s\tremaining: 25.2s\n",
      "165:\tlearn: 0.0055534\ttotal: 12.5s\tremaining: 25.2s\n",
      "166:\tlearn: 0.0054988\ttotal: 12.6s\tremaining: 25.1s\n",
      "167:\tlearn: 0.0054451\ttotal: 12.7s\tremaining: 25.1s\n",
      "168:\tlearn: 0.0053884\ttotal: 12.7s\tremaining: 24.9s\n",
      "169:\tlearn: 0.0053212\ttotal: 12.8s\tremaining: 24.8s\n",
      "170:\tlearn: 0.0052488\ttotal: 12.9s\tremaining: 24.8s\n",
      "171:\tlearn: 0.0051885\ttotal: 12.9s\tremaining: 24.7s\n",
      "172:\tlearn: 0.0051026\ttotal: 13s\tremaining: 24.7s\n",
      "173:\tlearn: 0.0050310\ttotal: 13.1s\tremaining: 24.5s\n",
      "174:\tlearn: 0.0049661\ttotal: 13.1s\tremaining: 24.4s\n",
      "175:\tlearn: 0.0048965\ttotal: 13.3s\tremaining: 24.4s\n",
      "176:\tlearn: 0.0048294\ttotal: 13.3s\tremaining: 24.4s\n",
      "177:\tlearn: 0.0047675\ttotal: 13.4s\tremaining: 24.3s\n",
      "178:\tlearn: 0.0047274\ttotal: 13.5s\tremaining: 24.1s\n",
      "179:\tlearn: 0.0046754\ttotal: 13.5s\tremaining: 24.1s\n",
      "180:\tlearn: 0.0046099\ttotal: 13.7s\tremaining: 24.1s\n",
      "181:\tlearn: 0.0045631\ttotal: 13.7s\tremaining: 23.9s\n",
      "182:\tlearn: 0.0045173\ttotal: 13.8s\tremaining: 23.9s\n",
      "183:\tlearn: 0.0044802\ttotal: 13.9s\tremaining: 23.8s\n",
      "184:\tlearn: 0.0044437\ttotal: 13.9s\tremaining: 23.7s\n",
      "185:\tlearn: 0.0044049\ttotal: 14s\tremaining: 23.7s\n",
      "186:\tlearn: 0.0043658\ttotal: 14.1s\tremaining: 23.5s\n",
      "187:\tlearn: 0.0043186\ttotal: 14.1s\tremaining: 23.5s\n",
      "188:\tlearn: 0.0042743\ttotal: 14.2s\tremaining: 23.4s\n",
      "189:\tlearn: 0.0042373\ttotal: 14.3s\tremaining: 23.3s\n",
      "190:\tlearn: 0.0041851\ttotal: 14.4s\tremaining: 23.2s\n",
      "191:\tlearn: 0.0041498\ttotal: 14.4s\tremaining: 23.1s\n",
      "192:\tlearn: 0.0040979\ttotal: 14.5s\tremaining: 23.1s\n",
      "193:\tlearn: 0.0040309\ttotal: 14.6s\tremaining: 23s\n",
      "194:\tlearn: 0.0039822\ttotal: 14.7s\tremaining: 22.9s\n",
      "195:\tlearn: 0.0039345\ttotal: 14.7s\tremaining: 22.8s\n",
      "196:\tlearn: 0.0039020\ttotal: 14.8s\tremaining: 22.8s\n",
      "197:\tlearn: 0.0038606\ttotal: 14.9s\tremaining: 22.7s\n",
      "198:\tlearn: 0.0038268\ttotal: 14.9s\tremaining: 22.6s\n",
      "199:\tlearn: 0.0037810\ttotal: 15.1s\tremaining: 22.6s\n",
      "200:\tlearn: 0.0037557\ttotal: 15.1s\tremaining: 22.5s\n",
      "201:\tlearn: 0.0037171\ttotal: 15.2s\tremaining: 22.4s\n",
      "202:\tlearn: 0.0036807\ttotal: 15.2s\tremaining: 22.3s\n",
      "203:\tlearn: 0.0036423\ttotal: 15.4s\tremaining: 22.3s\n",
      "204:\tlearn: 0.0036423\ttotal: 15.4s\tremaining: 22.2s\n",
      "205:\tlearn: 0.0036067\ttotal: 15.5s\tremaining: 22.2s\n",
      "206:\tlearn: 0.0035679\ttotal: 15.6s\tremaining: 22.1s\n",
      "207:\tlearn: 0.0035368\ttotal: 15.6s\tremaining: 21.9s\n",
      "208:\tlearn: 0.0034896\ttotal: 15.7s\tremaining: 21.9s\n",
      "209:\tlearn: 0.0034397\ttotal: 15.8s\tremaining: 21.8s\n",
      "210:\tlearn: 0.0034127\ttotal: 15.9s\tremaining: 21.7s\n",
      "211:\tlearn: 0.0033766\ttotal: 15.9s\tremaining: 21.7s\n",
      "212:\tlearn: 0.0033503\ttotal: 16s\tremaining: 21.5s\n",
      "213:\tlearn: 0.0033275\ttotal: 16.1s\tremaining: 21.5s\n",
      "214:\tlearn: 0.0032968\ttotal: 16.1s\tremaining: 21.4s\n",
      "215:\tlearn: 0.0032698\ttotal: 16.3s\tremaining: 21.4s\n",
      "216:\tlearn: 0.0032380\ttotal: 16.3s\tremaining: 21.3s\n",
      "217:\tlearn: 0.0032097\ttotal: 16.4s\tremaining: 21.2s\n",
      "218:\tlearn: 0.0031805\ttotal: 16.5s\tremaining: 21.2s\n",
      "219:\tlearn: 0.0031573\ttotal: 16.5s\tremaining: 21.1s\n",
      "220:\tlearn: 0.0031354\ttotal: 16.6s\tremaining: 21s\n",
      "221:\tlearn: 0.0031110\ttotal: 16.7s\tremaining: 20.9s\n",
      "222:\tlearn: 0.0030912\ttotal: 16.8s\tremaining: 20.9s\n",
      "223:\tlearn: 0.0030691\ttotal: 16.9s\tremaining: 20.8s\n",
      "224:\tlearn: 0.0030430\ttotal: 16.9s\tremaining: 20.7s\n",
      "225:\tlearn: 0.0030177\ttotal: 17s\tremaining: 20.6s\n",
      "226:\tlearn: 0.0029851\ttotal: 17.1s\tremaining: 20.5s\n",
      "227:\tlearn: 0.0029615\ttotal: 17.2s\tremaining: 20.5s\n",
      "228:\tlearn: 0.0029516\ttotal: 17.2s\tremaining: 20.4s\n",
      "229:\tlearn: 0.0029516\ttotal: 17.3s\tremaining: 20.3s\n",
      "230:\tlearn: 0.0029311\ttotal: 17.4s\tremaining: 20.3s\n",
      "231:\tlearn: 0.0028998\ttotal: 17.4s\tremaining: 20.1s\n",
      "232:\tlearn: 0.0028758\ttotal: 17.5s\tremaining: 20.1s\n",
      "233:\tlearn: 0.0028757\ttotal: 17.6s\tremaining: 20s\n",
      "234:\tlearn: 0.0028757\ttotal: 17.6s\tremaining: 19.9s\n",
      "235:\tlearn: 0.0028757\ttotal: 17.8s\tremaining: 19.9s\n",
      "236:\tlearn: 0.0028586\ttotal: 17.8s\tremaining: 19.8s\n",
      "237:\tlearn: 0.0028585\ttotal: 17.8s\tremaining: 19.6s\n",
      "238:\tlearn: 0.0028344\ttotal: 17.9s\tremaining: 19.6s\n",
      "239:\tlearn: 0.0028131\ttotal: 18s\tremaining: 19.5s\n",
      "240:\tlearn: 0.0028130\ttotal: 18.1s\tremaining: 19.4s\n",
      "241:\tlearn: 0.0027875\ttotal: 18.2s\tremaining: 19.4s\n",
      "242:\tlearn: 0.0027607\ttotal: 18.2s\tremaining: 19.3s\n",
      "243:\tlearn: 0.0027607\ttotal: 18.3s\tremaining: 19.2s\n",
      "244:\tlearn: 0.0027607\ttotal: 18.4s\tremaining: 19.1s\n",
      "245:\tlearn: 0.0027394\ttotal: 18.5s\tremaining: 19.1s\n",
      "246:\tlearn: 0.0027394\ttotal: 18.5s\tremaining: 19s\n",
      "247:\tlearn: 0.0027393\ttotal: 18.6s\tremaining: 18.9s\n",
      "248:\tlearn: 0.0027393\ttotal: 18.7s\tremaining: 18.8s\n",
      "249:\tlearn: 0.0027393\ttotal: 18.7s\tremaining: 18.7s\n",
      "250:\tlearn: 0.0027143\ttotal: 18.9s\tremaining: 18.7s\n",
      "251:\tlearn: 0.0026932\ttotal: 18.9s\tremaining: 18.6s\n",
      "252:\tlearn: 0.0026738\ttotal: 19s\tremaining: 18.6s\n",
      "253:\tlearn: 0.0026738\ttotal: 19.1s\tremaining: 18.5s\n",
      "254:\tlearn: 0.0026447\ttotal: 19.2s\tremaining: 18.4s\n",
      "255:\tlearn: 0.0026246\ttotal: 19.2s\tremaining: 18.3s\n",
      "256:\tlearn: 0.0026246\ttotal: 19.3s\tremaining: 18.3s\n",
      "257:\tlearn: 0.0026246\ttotal: 19.4s\tremaining: 18.2s\n",
      "258:\tlearn: 0.0026246\ttotal: 19.4s\tremaining: 18.1s\n",
      "259:\tlearn: 0.0026077\ttotal: 19.6s\tremaining: 18.1s\n",
      "260:\tlearn: 0.0025843\ttotal: 19.6s\tremaining: 18s\n",
      "261:\tlearn: 0.0025843\ttotal: 19.7s\tremaining: 17.9s\n",
      "262:\tlearn: 0.0025842\ttotal: 19.8s\tremaining: 17.8s\n",
      "263:\tlearn: 0.0025842\ttotal: 19.8s\tremaining: 17.7s\n",
      "264:\tlearn: 0.0025841\ttotal: 19.9s\tremaining: 17.7s\n",
      "265:\tlearn: 0.0025841\ttotal: 20s\tremaining: 17.6s\n",
      "266:\tlearn: 0.0025699\ttotal: 20.1s\tremaining: 17.5s\n",
      "267:\tlearn: 0.0025544\ttotal: 20.1s\tremaining: 17.4s\n",
      "268:\tlearn: 0.0025543\ttotal: 20.2s\tremaining: 17.4s\n",
      "269:\tlearn: 0.0025542\ttotal: 20.3s\tremaining: 17.3s\n",
      "270:\tlearn: 0.0025542\ttotal: 20.4s\tremaining: 17.2s\n",
      "271:\tlearn: 0.0025542\ttotal: 20.4s\tremaining: 17.1s\n",
      "272:\tlearn: 0.0025541\ttotal: 20.5s\tremaining: 17s\n",
      "273:\tlearn: 0.0025541\ttotal: 20.6s\tremaining: 17s\n",
      "274:\tlearn: 0.0025431\ttotal: 20.7s\tremaining: 16.9s\n",
      "275:\tlearn: 0.0025205\ttotal: 20.7s\tremaining: 16.8s\n",
      "276:\tlearn: 0.0025037\ttotal: 20.8s\tremaining: 16.8s\n",
      "277:\tlearn: 0.0025036\ttotal: 20.9s\tremaining: 16.7s\n",
      "278:\tlearn: 0.0025035\ttotal: 21s\tremaining: 16.6s\n",
      "279:\tlearn: 0.0024816\ttotal: 21s\tremaining: 16.5s\n",
      "280:\tlearn: 0.0024629\ttotal: 21.1s\tremaining: 16.5s\n",
      "281:\tlearn: 0.0024427\ttotal: 21.2s\tremaining: 16.4s\n",
      "282:\tlearn: 0.0024245\ttotal: 21.3s\tremaining: 16.3s\n",
      "283:\tlearn: 0.0024244\ttotal: 21.4s\tremaining: 16.2s\n",
      "284:\tlearn: 0.0024243\ttotal: 21.4s\tremaining: 16.1s\n",
      "285:\tlearn: 0.0024091\ttotal: 21.5s\tremaining: 16.1s\n",
      "286:\tlearn: 0.0023868\ttotal: 21.6s\tremaining: 16s\n",
      "287:\tlearn: 0.0023665\ttotal: 21.7s\tremaining: 15.9s\n",
      "288:\tlearn: 0.0023344\ttotal: 21.7s\tremaining: 15.9s\n",
      "289:\tlearn: 0.0023173\ttotal: 21.8s\tremaining: 15.8s\n",
      "290:\tlearn: 0.0022947\ttotal: 21.9s\tremaining: 15.7s\n",
      "291:\tlearn: 0.0022946\ttotal: 21.9s\tremaining: 15.6s\n",
      "292:\tlearn: 0.0022767\ttotal: 22s\tremaining: 15.6s\n",
      "293:\tlearn: 0.0022767\ttotal: 22.1s\tremaining: 15.5s\n",
      "294:\tlearn: 0.0022767\ttotal: 22.1s\tremaining: 15.4s\n",
      "295:\tlearn: 0.0022767\ttotal: 22.2s\tremaining: 15.3s\n",
      "296:\tlearn: 0.0022766\ttotal: 22.3s\tremaining: 15.2s\n",
      "297:\tlearn: 0.0022766\ttotal: 22.4s\tremaining: 15.2s\n",
      "298:\tlearn: 0.0022766\ttotal: 22.4s\tremaining: 15.1s\n",
      "299:\tlearn: 0.0022766\ttotal: 22.5s\tremaining: 15s\n",
      "300:\tlearn: 0.0022765\ttotal: 22.6s\tremaining: 14.9s\n",
      "301:\tlearn: 0.0022765\ttotal: 22.7s\tremaining: 14.8s\n",
      "302:\tlearn: 0.0022765\ttotal: 22.8s\tremaining: 14.8s\n",
      "303:\tlearn: 0.0022765\ttotal: 22.8s\tremaining: 14.7s\n",
      "304:\tlearn: 0.0022765\ttotal: 22.9s\tremaining: 14.7s\n",
      "305:\tlearn: 0.0022765\ttotal: 23s\tremaining: 14.6s\n",
      "306:\tlearn: 0.0022614\ttotal: 23.1s\tremaining: 14.5s\n",
      "307:\tlearn: 0.0022436\ttotal: 23.2s\tremaining: 14.4s\n",
      "308:\tlearn: 0.0022437\ttotal: 23.2s\tremaining: 14.3s\n",
      "309:\tlearn: 0.0022436\ttotal: 23.3s\tremaining: 14.3s\n",
      "310:\tlearn: 0.0022436\ttotal: 23.4s\tremaining: 14.2s\n",
      "311:\tlearn: 0.0022436\ttotal: 23.5s\tremaining: 14.1s\n",
      "312:\tlearn: 0.0022436\ttotal: 23.6s\tremaining: 14.1s\n",
      "313:\tlearn: 0.0022436\ttotal: 23.7s\tremaining: 14s\n",
      "314:\tlearn: 0.0022435\ttotal: 23.7s\tremaining: 13.9s\n",
      "315:\tlearn: 0.0022435\ttotal: 23.8s\tremaining: 13.9s\n",
      "316:\tlearn: 0.0022435\ttotal: 23.9s\tremaining: 13.8s\n",
      "317:\tlearn: 0.0022435\ttotal: 23.9s\tremaining: 13.7s\n",
      "318:\tlearn: 0.0022434\ttotal: 24s\tremaining: 13.6s\n",
      "319:\tlearn: 0.0022434\ttotal: 24s\tremaining: 13.5s\n",
      "320:\tlearn: 0.0022434\ttotal: 24.1s\tremaining: 13.4s\n",
      "321:\tlearn: 0.0022434\ttotal: 24.1s\tremaining: 13.3s\n",
      "322:\tlearn: 0.0022432\ttotal: 24.3s\tremaining: 13.3s\n",
      "323:\tlearn: 0.0022331\ttotal: 24.3s\tremaining: 13.2s\n",
      "324:\tlearn: 0.0022331\ttotal: 24.4s\tremaining: 13.1s\n",
      "325:\tlearn: 0.0022331\ttotal: 24.5s\tremaining: 13.1s\n",
      "326:\tlearn: 0.0022331\ttotal: 24.5s\tremaining: 13s\n",
      "327:\tlearn: 0.0022183\ttotal: 24.6s\tremaining: 12.9s\n",
      "328:\tlearn: 0.0022183\ttotal: 24.7s\tremaining: 12.8s\n",
      "329:\tlearn: 0.0022183\ttotal: 24.8s\tremaining: 12.8s\n",
      "330:\tlearn: 0.0022083\ttotal: 24.8s\tremaining: 12.7s\n",
      "331:\tlearn: 0.0022082\ttotal: 24.9s\tremaining: 12.6s\n",
      "332:\tlearn: 0.0022082\ttotal: 25s\tremaining: 12.5s\n",
      "333:\tlearn: 0.0022081\ttotal: 25s\tremaining: 12.4s\n",
      "334:\tlearn: 0.0022081\ttotal: 25.2s\tremaining: 12.4s\n",
      "335:\tlearn: 0.0022081\ttotal: 25.2s\tremaining: 12.3s\n",
      "336:\tlearn: 0.0022081\ttotal: 25.3s\tremaining: 12.2s\n",
      "337:\tlearn: 0.0022081\ttotal: 25.4s\tremaining: 12.2s\n",
      "338:\tlearn: 0.0022080\ttotal: 25.4s\tremaining: 12.1s\n",
      "339:\tlearn: 0.0022080\ttotal: 25.5s\tremaining: 12s\n",
      "340:\tlearn: 0.0021986\ttotal: 25.6s\tremaining: 11.9s\n",
      "341:\tlearn: 0.0021986\ttotal: 25.7s\tremaining: 11.9s\n",
      "342:\tlearn: 0.0021985\ttotal: 25.7s\tremaining: 11.8s\n",
      "343:\tlearn: 0.0021985\ttotal: 25.8s\tremaining: 11.7s\n",
      "344:\tlearn: 0.0021985\ttotal: 25.9s\tremaining: 11.6s\n",
      "345:\tlearn: 0.0021924\ttotal: 25.9s\tremaining: 11.5s\n",
      "346:\tlearn: 0.0021924\ttotal: 26s\tremaining: 11.5s\n",
      "347:\tlearn: 0.0021924\ttotal: 26.1s\tremaining: 11.4s\n",
      "348:\tlearn: 0.0021737\ttotal: 26.1s\tremaining: 11.3s\n",
      "349:\tlearn: 0.0021737\ttotal: 26.3s\tremaining: 11.3s\n",
      "350:\tlearn: 0.0021737\ttotal: 26.3s\tremaining: 11.2s\n",
      "351:\tlearn: 0.0021737\ttotal: 26.4s\tremaining: 11.1s\n",
      "352:\tlearn: 0.0021651\ttotal: 26.5s\tremaining: 11s\n",
      "353:\tlearn: 0.0021650\ttotal: 26.5s\tremaining: 10.9s\n",
      "354:\tlearn: 0.0021650\ttotal: 26.6s\tremaining: 10.9s\n",
      "355:\tlearn: 0.0021612\ttotal: 26.7s\tremaining: 10.8s\n",
      "356:\tlearn: 0.0021612\ttotal: 26.8s\tremaining: 10.7s\n",
      "357:\tlearn: 0.0021612\ttotal: 26.8s\tremaining: 10.6s\n",
      "358:\tlearn: 0.0021611\ttotal: 26.9s\tremaining: 10.5s\n",
      "359:\tlearn: 0.0021488\ttotal: 27s\tremaining: 10.5s\n",
      "360:\tlearn: 0.0021297\ttotal: 27s\tremaining: 10.4s\n",
      "361:\tlearn: 0.0021297\ttotal: 27.1s\tremaining: 10.3s\n",
      "362:\tlearn: 0.0021296\ttotal: 27.2s\tremaining: 10.3s\n",
      "363:\tlearn: 0.0021296\ttotal: 27.3s\tremaining: 10.2s\n",
      "364:\tlearn: 0.0021296\ttotal: 27.4s\tremaining: 10.1s\n",
      "365:\tlearn: 0.0021138\ttotal: 27.4s\tremaining: 10s\n",
      "366:\tlearn: 0.0020967\ttotal: 27.5s\tremaining: 9.97s\n",
      "367:\tlearn: 0.0020967\ttotal: 27.6s\tremaining: 9.88s\n",
      "368:\tlearn: 0.0020967\ttotal: 27.6s\tremaining: 9.81s\n",
      "369:\tlearn: 0.0020967\ttotal: 27.7s\tremaining: 9.73s\n",
      "370:\tlearn: 0.0020807\ttotal: 27.8s\tremaining: 9.65s\n",
      "371:\tlearn: 0.0020807\ttotal: 27.9s\tremaining: 9.59s\n",
      "372:\tlearn: 0.0020807\ttotal: 27.9s\tremaining: 9.5s\n",
      "373:\tlearn: 0.0020590\ttotal: 28s\tremaining: 9.43s\n",
      "374:\tlearn: 0.0020433\ttotal: 28.1s\tremaining: 9.35s\n",
      "375:\tlearn: 0.0020433\ttotal: 28.1s\tremaining: 9.27s\n",
      "376:\tlearn: 0.0020433\ttotal: 28.2s\tremaining: 9.21s\n",
      "377:\tlearn: 0.0020432\ttotal: 28.3s\tremaining: 9.12s\n",
      "378:\tlearn: 0.0020432\ttotal: 28.3s\tremaining: 9.05s\n",
      "379:\tlearn: 0.0020432\ttotal: 28.4s\tremaining: 8.97s\n",
      "380:\tlearn: 0.0020432\ttotal: 28.5s\tremaining: 8.89s\n",
      "381:\tlearn: 0.0020431\ttotal: 28.6s\tremaining: 8.83s\n",
      "382:\tlearn: 0.0020430\ttotal: 28.6s\tremaining: 8.74s\n",
      "383:\tlearn: 0.0020429\ttotal: 28.7s\tremaining: 8.68s\n",
      "384:\tlearn: 0.0020323\ttotal: 28.8s\tremaining: 8.6s\n",
      "385:\tlearn: 0.0020323\ttotal: 28.9s\tremaining: 8.53s\n",
      "386:\tlearn: 0.0020323\ttotal: 29s\tremaining: 8.46s\n",
      "387:\tlearn: 0.0020323\ttotal: 29s\tremaining: 8.38s\n",
      "388:\tlearn: 0.0020323\ttotal: 29.1s\tremaining: 8.31s\n",
      "389:\tlearn: 0.0020322\ttotal: 29.2s\tremaining: 8.23s\n",
      "390:\tlearn: 0.0020322\ttotal: 29.3s\tremaining: 8.16s\n",
      "391:\tlearn: 0.0020322\ttotal: 29.3s\tremaining: 8.08s\n",
      "392:\tlearn: 0.0020322\ttotal: 29.4s\tremaining: 8.02s\n",
      "393:\tlearn: 0.0020322\ttotal: 29.5s\tremaining: 7.94s\n",
      "394:\tlearn: 0.0020321\ttotal: 29.5s\tremaining: 7.85s\n",
      "395:\tlearn: 0.0020321\ttotal: 29.6s\tremaining: 7.79s\n",
      "396:\tlearn: 0.0020321\ttotal: 29.7s\tremaining: 7.7s\n",
      "397:\tlearn: 0.0020322\ttotal: 29.8s\tremaining: 7.63s\n",
      "398:\tlearn: 0.0020321\ttotal: 29.9s\tremaining: 7.56s\n",
      "399:\tlearn: 0.0020321\ttotal: 29.9s\tremaining: 7.47s\n",
      "400:\tlearn: 0.0020320\ttotal: 30s\tremaining: 7.4s\n",
      "401:\tlearn: 0.0020320\ttotal: 30s\tremaining: 7.33s\n",
      "402:\tlearn: 0.0020320\ttotal: 30.1s\tremaining: 7.24s\n",
      "403:\tlearn: 0.0020193\ttotal: 30.2s\tremaining: 7.18s\n",
      "404:\tlearn: 0.0020193\ttotal: 30.3s\tremaining: 7.1s\n",
      "405:\tlearn: 0.0020193\ttotal: 30.4s\tremaining: 7.03s\n",
      "406:\tlearn: 0.0020193\ttotal: 30.4s\tremaining: 6.95s\n",
      "407:\tlearn: 0.0020193\ttotal: 30.5s\tremaining: 6.87s\n",
      "408:\tlearn: 0.0020193\ttotal: 30.6s\tremaining: 6.8s\n",
      "409:\tlearn: 0.0020193\ttotal: 30.6s\tremaining: 6.72s\n",
      "410:\tlearn: 0.0020193\ttotal: 30.7s\tremaining: 6.66s\n",
      "411:\tlearn: 0.0020193\ttotal: 30.8s\tremaining: 6.58s\n",
      "412:\tlearn: 0.0020192\ttotal: 30.9s\tremaining: 6.51s\n",
      "413:\tlearn: 0.0020192\ttotal: 31s\tremaining: 6.43s\n",
      "414:\tlearn: 0.0020192\ttotal: 31s\tremaining: 6.35s\n",
      "415:\tlearn: 0.0020192\ttotal: 31.1s\tremaining: 6.28s\n",
      "416:\tlearn: 0.0020113\ttotal: 31.1s\tremaining: 6.2s\n",
      "417:\tlearn: 0.0019936\ttotal: 31.2s\tremaining: 6.13s\n",
      "418:\tlearn: 0.0019936\ttotal: 31.3s\tremaining: 6.05s\n",
      "419:\tlearn: 0.0019936\ttotal: 31.4s\tremaining: 5.98s\n",
      "420:\tlearn: 0.0019936\ttotal: 31.5s\tremaining: 5.9s\n",
      "421:\tlearn: 0.0019936\ttotal: 31.6s\tremaining: 5.83s\n",
      "422:\tlearn: 0.0019936\ttotal: 31.6s\tremaining: 5.75s\n",
      "423:\tlearn: 0.0019936\ttotal: 31.7s\tremaining: 5.67s\n",
      "424:\tlearn: 0.0019936\ttotal: 31.8s\tremaining: 5.61s\n",
      "425:\tlearn: 0.0019936\ttotal: 31.8s\tremaining: 5.53s\n",
      "426:\tlearn: 0.0019935\ttotal: 31.9s\tremaining: 5.46s\n",
      "427:\tlearn: 0.0019935\ttotal: 32s\tremaining: 5.38s\n",
      "428:\tlearn: 0.0019935\ttotal: 32s\tremaining: 5.3s\n",
      "429:\tlearn: 0.0019935\ttotal: 32.1s\tremaining: 5.23s\n",
      "430:\tlearn: 0.0019935\ttotal: 32.3s\tremaining: 5.16s\n",
      "431:\tlearn: 0.0019935\ttotal: 32.3s\tremaining: 5.08s\n",
      "432:\tlearn: 0.0019934\ttotal: 32.4s\tremaining: 5.02s\n",
      "433:\tlearn: 0.0019839\ttotal: 32.5s\tremaining: 4.94s\n",
      "434:\tlearn: 0.0019838\ttotal: 32.5s\tremaining: 4.86s\n",
      "435:\tlearn: 0.0019838\ttotal: 32.6s\tremaining: 4.79s\n",
      "436:\tlearn: 0.0019838\ttotal: 32.7s\tremaining: 4.71s\n",
      "437:\tlearn: 0.0019838\ttotal: 32.8s\tremaining: 4.64s\n",
      "438:\tlearn: 0.0019838\ttotal: 32.8s\tremaining: 4.56s\n",
      "439:\tlearn: 0.0019837\ttotal: 32.9s\tremaining: 4.48s\n",
      "440:\tlearn: 0.0019785\ttotal: 33s\tremaining: 4.41s\n",
      "441:\tlearn: 0.0019785\ttotal: 33s\tremaining: 4.33s\n",
      "442:\tlearn: 0.0019641\ttotal: 33.1s\tremaining: 4.26s\n",
      "443:\tlearn: 0.0019641\ttotal: 33.2s\tremaining: 4.19s\n",
      "444:\tlearn: 0.0019641\ttotal: 33.2s\tremaining: 4.11s\n",
      "445:\tlearn: 0.0019494\ttotal: 33.3s\tremaining: 4.04s\n",
      "446:\tlearn: 0.0019494\ttotal: 33.4s\tremaining: 3.96s\n",
      "447:\tlearn: 0.0019494\ttotal: 33.5s\tremaining: 3.89s\n",
      "448:\tlearn: 0.0019494\ttotal: 33.6s\tremaining: 3.81s\n",
      "449:\tlearn: 0.0019494\ttotal: 33.6s\tremaining: 3.73s\n",
      "450:\tlearn: 0.0019348\ttotal: 33.8s\tremaining: 3.67s\n",
      "451:\tlearn: 0.0019159\ttotal: 33.9s\tremaining: 3.59s\n",
      "452:\tlearn: 0.0019159\ttotal: 33.9s\tremaining: 3.52s\n",
      "453:\tlearn: 0.0019159\ttotal: 34s\tremaining: 3.44s\n",
      "454:\tlearn: 0.0019158\ttotal: 34s\tremaining: 3.37s\n",
      "455:\tlearn: 0.0019158\ttotal: 34.1s\tremaining: 3.29s\n",
      "456:\tlearn: 0.0019158\ttotal: 34.2s\tremaining: 3.22s\n",
      "457:\tlearn: 0.0019158\ttotal: 34.3s\tremaining: 3.14s\n",
      "458:\tlearn: 0.0019158\ttotal: 34.3s\tremaining: 3.07s\n",
      "459:\tlearn: 0.0019158\ttotal: 34.5s\tremaining: 3s\n",
      "460:\tlearn: 0.0019158\ttotal: 34.5s\tremaining: 2.92s\n",
      "461:\tlearn: 0.0019158\ttotal: 34.6s\tremaining: 2.85s\n",
      "462:\tlearn: 0.0019157\ttotal: 34.7s\tremaining: 2.77s\n",
      "463:\tlearn: 0.0019157\ttotal: 34.8s\tremaining: 2.7s\n",
      "464:\tlearn: 0.0019157\ttotal: 34.8s\tremaining: 2.62s\n",
      "465:\tlearn: 0.0019157\ttotal: 34.9s\tremaining: 2.54s\n",
      "466:\tlearn: 0.0019157\ttotal: 35s\tremaining: 2.47s\n",
      "467:\tlearn: 0.0019157\ttotal: 35s\tremaining: 2.4s\n",
      "468:\tlearn: 0.0019157\ttotal: 35.2s\tremaining: 2.32s\n",
      "469:\tlearn: 0.0019157\ttotal: 35.2s\tremaining: 2.25s\n",
      "470:\tlearn: 0.0019157\ttotal: 35.2s\tremaining: 2.17s\n",
      "471:\tlearn: 0.0019157\ttotal: 35.4s\tremaining: 2.1s\n",
      "472:\tlearn: 0.0019157\ttotal: 35.4s\tremaining: 2.02s\n",
      "473:\tlearn: 0.0019157\ttotal: 35.5s\tremaining: 1.95s\n",
      "474:\tlearn: 0.0019009\ttotal: 35.6s\tremaining: 1.87s\n",
      "475:\tlearn: 0.0019009\ttotal: 35.6s\tremaining: 1.79s\n",
      "476:\tlearn: 0.0019008\ttotal: 35.7s\tremaining: 1.72s\n",
      "477:\tlearn: 0.0019009\ttotal: 35.7s\tremaining: 1.65s\n",
      "478:\tlearn: 0.0019009\ttotal: 35.9s\tremaining: 1.57s\n",
      "479:\tlearn: 0.0019009\ttotal: 35.9s\tremaining: 1.5s\n",
      "480:\tlearn: 0.0019009\ttotal: 36s\tremaining: 1.42s\n",
      "481:\tlearn: 0.0019008\ttotal: 36.1s\tremaining: 1.35s\n",
      "482:\tlearn: 0.0019008\ttotal: 36.1s\tremaining: 1.27s\n",
      "483:\tlearn: 0.0019008\ttotal: 36.2s\tremaining: 1.2s\n",
      "484:\tlearn: 0.0019008\ttotal: 36.3s\tremaining: 1.12s\n",
      "485:\tlearn: 0.0019008\ttotal: 36.4s\tremaining: 1.05s\n",
      "486:\tlearn: 0.0019008\ttotal: 36.4s\tremaining: 973ms\n",
      "487:\tlearn: 0.0019008\ttotal: 36.5s\tremaining: 899ms\n",
      "488:\tlearn: 0.0019007\ttotal: 36.6s\tremaining: 824ms\n",
      "489:\tlearn: 0.0019008\ttotal: 36.7s\tremaining: 749ms\n",
      "490:\tlearn: 0.0019008\ttotal: 36.8s\tremaining: 674ms\n",
      "491:\tlearn: 0.0019008\ttotal: 36.8s\tremaining: 599ms\n",
      "492:\tlearn: 0.0019008\ttotal: 36.9s\tremaining: 525ms\n",
      "493:\tlearn: 0.0019008\ttotal: 37s\tremaining: 449ms\n",
      "494:\tlearn: 0.0019008\ttotal: 37.1s\tremaining: 375ms\n",
      "495:\tlearn: 0.0019007\ttotal: 37.1s\tremaining: 300ms\n",
      "496:\tlearn: 0.0019007\ttotal: 37.2s\tremaining: 225ms\n",
      "497:\tlearn: 0.0019007\ttotal: 37.3s\tremaining: 150ms\n",
      "498:\tlearn: 0.0019007\ttotal: 37.3s\tremaining: 74.8ms\n",
      "499:\tlearn: 0.0019006\ttotal: 37.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6482877\ttotal: 51.2ms\tremaining: 25.5s\n",
      "1:\tlearn: 0.6087338\ttotal: 164ms\tremaining: 40.9s\n",
      "2:\tlearn: 0.5662072\ttotal: 222ms\tremaining: 36.7s\n",
      "3:\tlearn: 0.5325874\ttotal: 267ms\tremaining: 33.1s\n",
      "4:\tlearn: 0.5094853\ttotal: 356ms\tremaining: 35.3s\n",
      "5:\tlearn: 0.4841596\ttotal: 396ms\tremaining: 32.6s\n",
      "6:\tlearn: 0.4636492\ttotal: 519ms\tremaining: 36.6s\n",
      "7:\tlearn: 0.4425003\ttotal: 566ms\tremaining: 34.8s\n",
      "8:\tlearn: 0.4221044\ttotal: 663ms\tremaining: 36.2s\n",
      "9:\tlearn: 0.4003658\ttotal: 744ms\tremaining: 36.5s\n",
      "10:\tlearn: 0.3788846\ttotal: 866ms\tremaining: 38.5s\n",
      "11:\tlearn: 0.3617399\ttotal: 916ms\tremaining: 37.2s\n",
      "12:\tlearn: 0.3462328\ttotal: 1.01s\tremaining: 37.8s\n",
      "13:\tlearn: 0.3289688\ttotal: 1.09s\tremaining: 37.9s\n",
      "14:\tlearn: 0.3143693\ttotal: 1.13s\tremaining: 36.7s\n",
      "15:\tlearn: 0.2993646\ttotal: 1.25s\tremaining: 37.8s\n",
      "16:\tlearn: 0.2852610\ttotal: 1.29s\tremaining: 36.8s\n",
      "17:\tlearn: 0.2755904\ttotal: 1.38s\tremaining: 37s\n",
      "18:\tlearn: 0.2619893\ttotal: 1.46s\tremaining: 36.8s\n",
      "19:\tlearn: 0.2511380\ttotal: 1.55s\tremaining: 37.2s\n",
      "20:\tlearn: 0.2390674\ttotal: 1.62s\tremaining: 37s\n",
      "21:\tlearn: 0.2305111\ttotal: 1.67s\tremaining: 36.2s\n",
      "22:\tlearn: 0.2231070\ttotal: 1.79s\tremaining: 37.1s\n",
      "23:\tlearn: 0.2107929\ttotal: 1.83s\tremaining: 36.4s\n",
      "24:\tlearn: 0.1998662\ttotal: 1.95s\tremaining: 37.1s\n",
      "25:\tlearn: 0.1917845\ttotal: 2s\tremaining: 36.6s\n",
      "26:\tlearn: 0.1863291\ttotal: 2.1s\tremaining: 36.8s\n",
      "27:\tlearn: 0.1809360\ttotal: 2.17s\tremaining: 36.6s\n",
      "28:\tlearn: 0.1719281\ttotal: 2.21s\tremaining: 36s\n",
      "29:\tlearn: 0.1635182\ttotal: 2.33s\tremaining: 36.5s\n",
      "30:\tlearn: 0.1564143\ttotal: 2.37s\tremaining: 35.9s\n",
      "31:\tlearn: 0.1493398\ttotal: 2.48s\tremaining: 36.2s\n",
      "32:\tlearn: 0.1435017\ttotal: 2.52s\tremaining: 35.7s\n",
      "33:\tlearn: 0.1372314\ttotal: 2.64s\tremaining: 36.2s\n",
      "34:\tlearn: 0.1297261\ttotal: 2.69s\tremaining: 35.8s\n",
      "35:\tlearn: 0.1261925\ttotal: 2.78s\tremaining: 35.9s\n",
      "36:\tlearn: 0.1191726\ttotal: 2.85s\tremaining: 35.7s\n",
      "37:\tlearn: 0.1151679\ttotal: 2.91s\tremaining: 35.4s\n",
      "38:\tlearn: 0.1128732\ttotal: 3.01s\tremaining: 35.6s\n",
      "39:\tlearn: 0.1085108\ttotal: 3.06s\tremaining: 35.2s\n",
      "40:\tlearn: 0.1027542\ttotal: 3.16s\tremaining: 35.4s\n",
      "41:\tlearn: 0.0999822\ttotal: 3.22s\tremaining: 35.1s\n",
      "42:\tlearn: 0.0964392\ttotal: 3.27s\tremaining: 34.8s\n",
      "43:\tlearn: 0.0934873\ttotal: 3.37s\tremaining: 35s\n",
      "44:\tlearn: 0.0893522\ttotal: 3.42s\tremaining: 34.6s\n",
      "45:\tlearn: 0.0869892\ttotal: 3.52s\tremaining: 34.8s\n",
      "46:\tlearn: 0.0847938\ttotal: 3.58s\tremaining: 34.5s\n",
      "47:\tlearn: 0.0805067\ttotal: 3.62s\tremaining: 34s\n",
      "48:\tlearn: 0.0783839\ttotal: 3.73s\tremaining: 34.3s\n",
      "49:\tlearn: 0.0762077\ttotal: 3.78s\tremaining: 34s\n",
      "50:\tlearn: 0.0737612\ttotal: 3.9s\tremaining: 34.3s\n",
      "51:\tlearn: 0.0708489\ttotal: 3.94s\tremaining: 34s\n",
      "52:\tlearn: 0.0690085\ttotal: 4.04s\tremaining: 34.1s\n",
      "53:\tlearn: 0.0666631\ttotal: 4.11s\tremaining: 34s\n",
      "54:\tlearn: 0.0648416\ttotal: 4.15s\tremaining: 33.6s\n",
      "55:\tlearn: 0.0627237\ttotal: 4.26s\tremaining: 33.8s\n",
      "56:\tlearn: 0.0609307\ttotal: 4.31s\tremaining: 33.5s\n",
      "57:\tlearn: 0.0591821\ttotal: 4.42s\tremaining: 33.7s\n",
      "58:\tlearn: 0.0567707\ttotal: 4.47s\tremaining: 33.4s\n",
      "59:\tlearn: 0.0551787\ttotal: 4.59s\tremaining: 33.6s\n",
      "60:\tlearn: 0.0540559\ttotal: 4.64s\tremaining: 33.4s\n",
      "61:\tlearn: 0.0525102\ttotal: 4.75s\tremaining: 33.6s\n",
      "62:\tlearn: 0.0508797\ttotal: 4.81s\tremaining: 33.3s\n",
      "63:\tlearn: 0.0492362\ttotal: 4.85s\tremaining: 33s\n",
      "64:\tlearn: 0.0472853\ttotal: 4.96s\tremaining: 33.2s\n",
      "65:\tlearn: 0.0460011\ttotal: 5s\tremaining: 32.9s\n",
      "66:\tlearn: 0.0448467\ttotal: 5.11s\tremaining: 33s\n",
      "67:\tlearn: 0.0431864\ttotal: 5.16s\tremaining: 32.8s\n",
      "68:\tlearn: 0.0418621\ttotal: 5.2s\tremaining: 32.5s\n",
      "69:\tlearn: 0.0406074\ttotal: 5.3s\tremaining: 32.6s\n",
      "70:\tlearn: 0.0391615\ttotal: 5.37s\tremaining: 32.5s\n",
      "71:\tlearn: 0.0380639\ttotal: 5.46s\tremaining: 32.5s\n",
      "72:\tlearn: 0.0371153\ttotal: 5.51s\tremaining: 32.2s\n",
      "73:\tlearn: 0.0356579\ttotal: 5.63s\tremaining: 32.4s\n",
      "74:\tlearn: 0.0347034\ttotal: 5.68s\tremaining: 32.2s\n",
      "75:\tlearn: 0.0339162\ttotal: 5.8s\tremaining: 32.4s\n",
      "76:\tlearn: 0.0325016\ttotal: 5.85s\tremaining: 32.2s\n",
      "77:\tlearn: 0.0318592\ttotal: 5.94s\tremaining: 32.2s\n",
      "78:\tlearn: 0.0309585\ttotal: 6.02s\tremaining: 32.1s\n",
      "79:\tlearn: 0.0302598\ttotal: 6.07s\tremaining: 31.9s\n",
      "80:\tlearn: 0.0295747\ttotal: 6.18s\tremaining: 31.9s\n",
      "81:\tlearn: 0.0288357\ttotal: 6.22s\tremaining: 31.7s\n",
      "82:\tlearn: 0.0281103\ttotal: 6.34s\tremaining: 31.8s\n",
      "83:\tlearn: 0.0275244\ttotal: 6.39s\tremaining: 31.7s\n",
      "84:\tlearn: 0.0268351\ttotal: 6.52s\tremaining: 31.8s\n",
      "85:\tlearn: 0.0261066\ttotal: 6.63s\tremaining: 31.9s\n",
      "86:\tlearn: 0.0253093\ttotal: 6.73s\tremaining: 31.9s\n",
      "87:\tlearn: 0.0249064\ttotal: 6.78s\tremaining: 31.7s\n",
      "88:\tlearn: 0.0242612\ttotal: 6.86s\tremaining: 31.7s\n",
      "89:\tlearn: 0.0236048\ttotal: 6.94s\tremaining: 31.6s\n",
      "90:\tlearn: 0.0228795\ttotal: 6.97s\tremaining: 31.3s\n",
      "91:\tlearn: 0.0222662\ttotal: 7.01s\tremaining: 31.1s\n",
      "92:\tlearn: 0.0217109\ttotal: 7.06s\tremaining: 30.9s\n",
      "93:\tlearn: 0.0212019\ttotal: 7.11s\tremaining: 30.7s\n",
      "94:\tlearn: 0.0205485\ttotal: 7.22s\tremaining: 30.8s\n",
      "95:\tlearn: 0.0201224\ttotal: 7.28s\tremaining: 30.6s\n",
      "96:\tlearn: 0.0198051\ttotal: 7.39s\tremaining: 30.7s\n",
      "97:\tlearn: 0.0192376\ttotal: 7.46s\tremaining: 30.6s\n",
      "98:\tlearn: 0.0186140\ttotal: 7.59s\tremaining: 30.7s\n",
      "99:\tlearn: 0.0182165\ttotal: 7.63s\tremaining: 30.5s\n",
      "100:\tlearn: 0.0178646\ttotal: 7.72s\tremaining: 30.5s\n",
      "101:\tlearn: 0.0173983\ttotal: 7.79s\tremaining: 30.4s\n",
      "102:\tlearn: 0.0169277\ttotal: 7.84s\tremaining: 30.2s\n",
      "103:\tlearn: 0.0164237\ttotal: 7.95s\tremaining: 30.3s\n",
      "104:\tlearn: 0.0160616\ttotal: 8s\tremaining: 30.1s\n",
      "105:\tlearn: 0.0157312\ttotal: 8.11s\tremaining: 30.1s\n",
      "106:\tlearn: 0.0152967\ttotal: 8.16s\tremaining: 30s\n",
      "107:\tlearn: 0.0149624\ttotal: 8.2s\tremaining: 29.8s\n",
      "108:\tlearn: 0.0146994\ttotal: 8.31s\tremaining: 29.8s\n",
      "109:\tlearn: 0.0144474\ttotal: 8.36s\tremaining: 29.6s\n",
      "110:\tlearn: 0.0139867\ttotal: 8.4s\tremaining: 29.4s\n",
      "111:\tlearn: 0.0137187\ttotal: 8.52s\tremaining: 29.5s\n",
      "112:\tlearn: 0.0133116\ttotal: 8.56s\tremaining: 29.3s\n",
      "113:\tlearn: 0.0129958\ttotal: 8.68s\tremaining: 29.4s\n",
      "114:\tlearn: 0.0127211\ttotal: 8.73s\tremaining: 29.2s\n",
      "115:\tlearn: 0.0124855\ttotal: 8.77s\tremaining: 29s\n",
      "116:\tlearn: 0.0122278\ttotal: 8.88s\tremaining: 29.1s\n",
      "117:\tlearn: 0.0119608\ttotal: 8.92s\tremaining: 28.9s\n",
      "118:\tlearn: 0.0117109\ttotal: 9.04s\tremaining: 28.9s\n",
      "119:\tlearn: 0.0113856\ttotal: 9.09s\tremaining: 28.8s\n",
      "120:\tlearn: 0.0111224\ttotal: 9.19s\tremaining: 28.8s\n",
      "121:\tlearn: 0.0109036\ttotal: 9.25s\tremaining: 28.7s\n",
      "122:\tlearn: 0.0107134\ttotal: 9.29s\tremaining: 28.5s\n",
      "123:\tlearn: 0.0105237\ttotal: 9.41s\tremaining: 28.5s\n",
      "124:\tlearn: 0.0102697\ttotal: 9.46s\tremaining: 28.4s\n",
      "125:\tlearn: 0.0101159\ttotal: 9.55s\tremaining: 28.4s\n",
      "126:\tlearn: 0.0099219\ttotal: 9.61s\tremaining: 28.2s\n",
      "127:\tlearn: 0.0097152\ttotal: 9.65s\tremaining: 28.1s\n",
      "128:\tlearn: 0.0095614\ttotal: 9.77s\tremaining: 28.1s\n",
      "129:\tlearn: 0.0093621\ttotal: 9.81s\tremaining: 27.9s\n",
      "130:\tlearn: 0.0091948\ttotal: 9.91s\tremaining: 27.9s\n",
      "131:\tlearn: 0.0090682\ttotal: 9.97s\tremaining: 27.8s\n",
      "132:\tlearn: 0.0089438\ttotal: 10s\tremaining: 27.6s\n",
      "133:\tlearn: 0.0087807\ttotal: 10.1s\tremaining: 27.7s\n",
      "134:\tlearn: 0.0086212\ttotal: 10.2s\tremaining: 27.5s\n",
      "135:\tlearn: 0.0084608\ttotal: 10.3s\tremaining: 27.5s\n",
      "136:\tlearn: 0.0082753\ttotal: 10.3s\tremaining: 27.4s\n",
      "137:\tlearn: 0.0081051\ttotal: 10.4s\tremaining: 27.4s\n",
      "138:\tlearn: 0.0079783\ttotal: 10.5s\tremaining: 27.3s\n",
      "139:\tlearn: 0.0078329\ttotal: 10.6s\tremaining: 27.3s\n",
      "140:\tlearn: 0.0077206\ttotal: 10.7s\tremaining: 27.2s\n",
      "141:\tlearn: 0.0075451\ttotal: 10.7s\tremaining: 27s\n",
      "142:\tlearn: 0.0074407\ttotal: 10.8s\tremaining: 27s\n",
      "143:\tlearn: 0.0073125\ttotal: 10.9s\tremaining: 26.9s\n",
      "144:\tlearn: 0.0071630\ttotal: 11s\tremaining: 26.9s\n",
      "145:\tlearn: 0.0070500\ttotal: 11.1s\tremaining: 26.8s\n",
      "146:\tlearn: 0.0069522\ttotal: 11.1s\tremaining: 26.7s\n",
      "147:\tlearn: 0.0068461\ttotal: 11.2s\tremaining: 26.7s\n",
      "148:\tlearn: 0.0067058\ttotal: 11.3s\tremaining: 26.5s\n",
      "149:\tlearn: 0.0066312\ttotal: 11.4s\tremaining: 26.5s\n",
      "150:\tlearn: 0.0065222\ttotal: 11.4s\tremaining: 26.4s\n",
      "151:\tlearn: 0.0064304\ttotal: 11.5s\tremaining: 26.2s\n",
      "152:\tlearn: 0.0063342\ttotal: 11.6s\tremaining: 26.2s\n",
      "153:\tlearn: 0.0062602\ttotal: 11.6s\tremaining: 26.1s\n",
      "154:\tlearn: 0.0061577\ttotal: 11.7s\tremaining: 26.1s\n",
      "155:\tlearn: 0.0060804\ttotal: 11.8s\tremaining: 26s\n",
      "156:\tlearn: 0.0059761\ttotal: 11.8s\tremaining: 25.8s\n",
      "157:\tlearn: 0.0059081\ttotal: 11.9s\tremaining: 25.8s\n",
      "158:\tlearn: 0.0058075\ttotal: 12s\tremaining: 25.7s\n",
      "159:\tlearn: 0.0057239\ttotal: 12.1s\tremaining: 25.7s\n",
      "160:\tlearn: 0.0056699\ttotal: 12.1s\tremaining: 25.6s\n",
      "161:\tlearn: 0.0055461\ttotal: 12.3s\tremaining: 25.6s\n",
      "162:\tlearn: 0.0054706\ttotal: 12.3s\tremaining: 25.5s\n",
      "163:\tlearn: 0.0054195\ttotal: 12.4s\tremaining: 25.3s\n",
      "164:\tlearn: 0.0053610\ttotal: 12.5s\tremaining: 25.3s\n",
      "165:\tlearn: 0.0052983\ttotal: 12.5s\tremaining: 25.2s\n",
      "166:\tlearn: 0.0052419\ttotal: 12.6s\tremaining: 25.2s\n",
      "167:\tlearn: 0.0051660\ttotal: 12.7s\tremaining: 25.1s\n",
      "168:\tlearn: 0.0050917\ttotal: 12.8s\tremaining: 25.1s\n",
      "169:\tlearn: 0.0050331\ttotal: 12.9s\tremaining: 25s\n",
      "170:\tlearn: 0.0049561\ttotal: 12.9s\tremaining: 24.8s\n",
      "171:\tlearn: 0.0048875\ttotal: 13s\tremaining: 24.9s\n",
      "172:\tlearn: 0.0048154\ttotal: 13.1s\tremaining: 24.7s\n",
      "173:\tlearn: 0.0047642\ttotal: 13.2s\tremaining: 24.7s\n",
      "174:\tlearn: 0.0047123\ttotal: 13.2s\tremaining: 24.6s\n",
      "175:\tlearn: 0.0046424\ttotal: 13.3s\tremaining: 24.6s\n",
      "176:\tlearn: 0.0045930\ttotal: 13.4s\tremaining: 24.5s\n",
      "177:\tlearn: 0.0045297\ttotal: 13.5s\tremaining: 24.4s\n",
      "178:\tlearn: 0.0044746\ttotal: 13.6s\tremaining: 24.3s\n",
      "179:\tlearn: 0.0044343\ttotal: 13.6s\tremaining: 24.2s\n",
      "180:\tlearn: 0.0043851\ttotal: 13.7s\tremaining: 24.2s\n",
      "181:\tlearn: 0.0043363\ttotal: 13.8s\tremaining: 24.1s\n",
      "182:\tlearn: 0.0042980\ttotal: 13.9s\tremaining: 24s\n",
      "183:\tlearn: 0.0042499\ttotal: 13.9s\tremaining: 23.9s\n",
      "184:\tlearn: 0.0042108\ttotal: 14s\tremaining: 23.8s\n",
      "185:\tlearn: 0.0041528\ttotal: 14.1s\tremaining: 23.8s\n",
      "186:\tlearn: 0.0040957\ttotal: 14.1s\tremaining: 23.7s\n",
      "187:\tlearn: 0.0040629\ttotal: 14.2s\tremaining: 23.6s\n",
      "188:\tlearn: 0.0040355\ttotal: 14.3s\tremaining: 23.5s\n",
      "189:\tlearn: 0.0039899\ttotal: 14.4s\tremaining: 23.5s\n",
      "190:\tlearn: 0.0039510\ttotal: 14.5s\tremaining: 23.4s\n",
      "191:\tlearn: 0.0039166\ttotal: 14.5s\tremaining: 23.3s\n",
      "192:\tlearn: 0.0038786\ttotal: 14.6s\tremaining: 23.3s\n",
      "193:\tlearn: 0.0038375\ttotal: 14.7s\tremaining: 23.2s\n",
      "194:\tlearn: 0.0037904\ttotal: 14.8s\tremaining: 23.2s\n",
      "195:\tlearn: 0.0037583\ttotal: 14.8s\tremaining: 23s\n",
      "196:\tlearn: 0.0037149\ttotal: 14.9s\tremaining: 23s\n",
      "197:\tlearn: 0.0036650\ttotal: 15s\tremaining: 22.9s\n",
      "198:\tlearn: 0.0036331\ttotal: 15.1s\tremaining: 22.8s\n",
      "199:\tlearn: 0.0036102\ttotal: 15.2s\tremaining: 22.8s\n",
      "200:\tlearn: 0.0035818\ttotal: 15.2s\tremaining: 22.6s\n",
      "201:\tlearn: 0.0035501\ttotal: 15.3s\tremaining: 22.6s\n",
      "202:\tlearn: 0.0035233\ttotal: 15.4s\tremaining: 22.5s\n",
      "203:\tlearn: 0.0034992\ttotal: 15.4s\tremaining: 22.4s\n",
      "204:\tlearn: 0.0034700\ttotal: 15.5s\tremaining: 22.4s\n",
      "205:\tlearn: 0.0034402\ttotal: 15.6s\tremaining: 22.2s\n",
      "206:\tlearn: 0.0034117\ttotal: 15.7s\tremaining: 22.2s\n",
      "207:\tlearn: 0.0033786\ttotal: 15.7s\tremaining: 22.1s\n",
      "208:\tlearn: 0.0033529\ttotal: 15.8s\tremaining: 22.1s\n",
      "209:\tlearn: 0.0033237\ttotal: 15.9s\tremaining: 22s\n",
      "210:\tlearn: 0.0032966\ttotal: 16s\tremaining: 21.9s\n",
      "211:\tlearn: 0.0032793\ttotal: 16.1s\tremaining: 21.8s\n",
      "212:\tlearn: 0.0032436\ttotal: 16.1s\tremaining: 21.7s\n",
      "213:\tlearn: 0.0032073\ttotal: 16.2s\tremaining: 21.7s\n",
      "214:\tlearn: 0.0031718\ttotal: 16.3s\tremaining: 21.6s\n",
      "215:\tlearn: 0.0031448\ttotal: 16.4s\tremaining: 21.5s\n",
      "216:\tlearn: 0.0031215\ttotal: 16.4s\tremaining: 21.4s\n",
      "217:\tlearn: 0.0030880\ttotal: 16.5s\tremaining: 21.3s\n",
      "218:\tlearn: 0.0030880\ttotal: 16.6s\tremaining: 21.3s\n",
      "219:\tlearn: 0.0030693\ttotal: 16.7s\tremaining: 21.2s\n",
      "220:\tlearn: 0.0030408\ttotal: 16.7s\tremaining: 21.1s\n",
      "221:\tlearn: 0.0030164\ttotal: 16.9s\tremaining: 21.1s\n",
      "222:\tlearn: 0.0029928\ttotal: 16.9s\tremaining: 21s\n",
      "223:\tlearn: 0.0029663\ttotal: 17s\tremaining: 21s\n",
      "224:\tlearn: 0.0029663\ttotal: 17.1s\tremaining: 20.9s\n",
      "225:\tlearn: 0.0029438\ttotal: 17.2s\tremaining: 20.8s\n",
      "226:\tlearn: 0.0029202\ttotal: 17.2s\tremaining: 20.7s\n",
      "227:\tlearn: 0.0028906\ttotal: 17.3s\tremaining: 20.7s\n",
      "228:\tlearn: 0.0028729\ttotal: 17.4s\tremaining: 20.6s\n",
      "229:\tlearn: 0.0028472\ttotal: 17.5s\tremaining: 20.5s\n",
      "230:\tlearn: 0.0028239\ttotal: 17.5s\tremaining: 20.4s\n",
      "231:\tlearn: 0.0028030\ttotal: 17.6s\tremaining: 20.3s\n",
      "232:\tlearn: 0.0028030\ttotal: 17.7s\tremaining: 20.3s\n",
      "233:\tlearn: 0.0027857\ttotal: 17.7s\tremaining: 20.2s\n",
      "234:\tlearn: 0.0027675\ttotal: 17.8s\tremaining: 20.1s\n",
      "235:\tlearn: 0.0027675\ttotal: 17.9s\tremaining: 20s\n",
      "236:\tlearn: 0.0027385\ttotal: 18s\tremaining: 19.9s\n",
      "237:\tlearn: 0.0027157\ttotal: 18.1s\tremaining: 19.9s\n",
      "238:\tlearn: 0.0026894\ttotal: 18.1s\tremaining: 19.8s\n",
      "239:\tlearn: 0.0026647\ttotal: 18.2s\tremaining: 19.7s\n",
      "240:\tlearn: 0.0026647\ttotal: 18.3s\tremaining: 19.6s\n",
      "241:\tlearn: 0.0026437\ttotal: 18.3s\tremaining: 19.5s\n",
      "242:\tlearn: 0.0026437\ttotal: 18.4s\tremaining: 19.5s\n",
      "243:\tlearn: 0.0026437\ttotal: 18.5s\tremaining: 19.4s\n",
      "244:\tlearn: 0.0026436\ttotal: 18.6s\tremaining: 19.3s\n",
      "245:\tlearn: 0.0026245\ttotal: 18.6s\tremaining: 19.2s\n",
      "246:\tlearn: 0.0026036\ttotal: 18.7s\tremaining: 19.1s\n",
      "247:\tlearn: 0.0025814\ttotal: 18.8s\tremaining: 19.1s\n",
      "248:\tlearn: 0.0025600\ttotal: 18.8s\tremaining: 19s\n",
      "249:\tlearn: 0.0025403\ttotal: 18.9s\tremaining: 18.9s\n",
      "250:\tlearn: 0.0025238\ttotal: 19s\tremaining: 18.8s\n",
      "251:\tlearn: 0.0025061\ttotal: 19.1s\tremaining: 18.8s\n",
      "252:\tlearn: 0.0024844\ttotal: 19.2s\tremaining: 18.7s\n",
      "253:\tlearn: 0.0024635\ttotal: 19.2s\tremaining: 18.6s\n",
      "254:\tlearn: 0.0024634\ttotal: 19.3s\tremaining: 18.6s\n",
      "255:\tlearn: 0.0024634\ttotal: 19.4s\tremaining: 18.5s\n",
      "256:\tlearn: 0.0024633\ttotal: 19.5s\tremaining: 18.4s\n",
      "257:\tlearn: 0.0024497\ttotal: 19.5s\tremaining: 18.3s\n",
      "258:\tlearn: 0.0024497\ttotal: 19.6s\tremaining: 18.2s\n",
      "259:\tlearn: 0.0024497\ttotal: 19.7s\tremaining: 18.2s\n",
      "260:\tlearn: 0.0024496\ttotal: 19.7s\tremaining: 18.1s\n",
      "261:\tlearn: 0.0024496\ttotal: 19.8s\tremaining: 18s\n",
      "262:\tlearn: 0.0024495\ttotal: 19.9s\tremaining: 17.9s\n",
      "263:\tlearn: 0.0024281\ttotal: 20s\tremaining: 17.9s\n",
      "264:\tlearn: 0.0024072\ttotal: 20.1s\tremaining: 17.8s\n",
      "265:\tlearn: 0.0024071\ttotal: 20.1s\tremaining: 17.7s\n",
      "266:\tlearn: 0.0024071\ttotal: 20.2s\tremaining: 17.6s\n",
      "267:\tlearn: 0.0024071\ttotal: 20.3s\tremaining: 17.5s\n",
      "268:\tlearn: 0.0024070\ttotal: 20.4s\tremaining: 17.5s\n",
      "269:\tlearn: 0.0023875\ttotal: 20.4s\tremaining: 17.4s\n",
      "270:\tlearn: 0.0023649\ttotal: 20.5s\tremaining: 17.3s\n",
      "271:\tlearn: 0.0023649\ttotal: 20.6s\tremaining: 17.3s\n",
      "272:\tlearn: 0.0023649\ttotal: 20.6s\tremaining: 17.2s\n",
      "273:\tlearn: 0.0023649\ttotal: 20.8s\tremaining: 17.1s\n",
      "274:\tlearn: 0.0023648\ttotal: 20.8s\tremaining: 17s\n",
      "275:\tlearn: 0.0023648\ttotal: 20.9s\tremaining: 17s\n",
      "276:\tlearn: 0.0023648\ttotal: 21s\tremaining: 16.9s\n",
      "277:\tlearn: 0.0023648\ttotal: 21s\tremaining: 16.8s\n",
      "278:\tlearn: 0.0023647\ttotal: 21.1s\tremaining: 16.7s\n",
      "279:\tlearn: 0.0023647\ttotal: 21.2s\tremaining: 16.6s\n",
      "280:\tlearn: 0.0023647\ttotal: 21.3s\tremaining: 16.6s\n",
      "281:\tlearn: 0.0023646\ttotal: 21.3s\tremaining: 16.5s\n",
      "282:\tlearn: 0.0023646\ttotal: 21.4s\tremaining: 16.4s\n",
      "283:\tlearn: 0.0023646\ttotal: 21.5s\tremaining: 16.3s\n",
      "284:\tlearn: 0.0023646\ttotal: 21.6s\tremaining: 16.3s\n",
      "285:\tlearn: 0.0023646\ttotal: 21.7s\tremaining: 16.2s\n",
      "286:\tlearn: 0.0023645\ttotal: 21.7s\tremaining: 16.1s\n",
      "287:\tlearn: 0.0023519\ttotal: 21.8s\tremaining: 16.1s\n",
      "288:\tlearn: 0.0023345\ttotal: 21.9s\tremaining: 16s\n",
      "289:\tlearn: 0.0023176\ttotal: 22s\tremaining: 15.9s\n",
      "290:\tlearn: 0.0023176\ttotal: 22s\tremaining: 15.8s\n",
      "291:\tlearn: 0.0023176\ttotal: 22.1s\tremaining: 15.7s\n",
      "292:\tlearn: 0.0023176\ttotal: 22.2s\tremaining: 15.7s\n",
      "293:\tlearn: 0.0023176\ttotal: 22.2s\tremaining: 15.6s\n",
      "294:\tlearn: 0.0022999\ttotal: 22.3s\tremaining: 15.5s\n",
      "295:\tlearn: 0.0022998\ttotal: 22.4s\tremaining: 15.4s\n",
      "296:\tlearn: 0.0022998\ttotal: 22.5s\tremaining: 15.4s\n",
      "297:\tlearn: 0.0022998\ttotal: 22.5s\tremaining: 15.3s\n",
      "298:\tlearn: 0.0022998\ttotal: 22.6s\tremaining: 15.2s\n",
      "299:\tlearn: 0.0022998\ttotal: 22.7s\tremaining: 15.1s\n",
      "300:\tlearn: 0.0022828\ttotal: 22.7s\tremaining: 15s\n",
      "301:\tlearn: 0.0022828\ttotal: 22.9s\tremaining: 15s\n",
      "302:\tlearn: 0.0022828\ttotal: 22.9s\tremaining: 14.9s\n",
      "303:\tlearn: 0.0022709\ttotal: 23s\tremaining: 14.8s\n",
      "304:\tlearn: 0.0022563\ttotal: 23.1s\tremaining: 14.7s\n",
      "305:\tlearn: 0.0022563\ttotal: 23.1s\tremaining: 14.7s\n",
      "306:\tlearn: 0.0022563\ttotal: 23.2s\tremaining: 14.6s\n",
      "307:\tlearn: 0.0022562\ttotal: 23.3s\tremaining: 14.5s\n",
      "308:\tlearn: 0.0022562\ttotal: 23.4s\tremaining: 14.5s\n",
      "309:\tlearn: 0.0022562\ttotal: 23.4s\tremaining: 14.4s\n",
      "310:\tlearn: 0.0022562\ttotal: 23.5s\tremaining: 14.3s\n",
      "311:\tlearn: 0.0022562\ttotal: 23.6s\tremaining: 14.2s\n",
      "312:\tlearn: 0.0022394\ttotal: 23.6s\tremaining: 14.1s\n",
      "313:\tlearn: 0.0022394\ttotal: 23.7s\tremaining: 14.1s\n",
      "314:\tlearn: 0.0022394\ttotal: 23.8s\tremaining: 14s\n",
      "315:\tlearn: 0.0022394\ttotal: 23.8s\tremaining: 13.9s\n",
      "316:\tlearn: 0.0022394\ttotal: 24s\tremaining: 13.8s\n",
      "317:\tlearn: 0.0022394\ttotal: 24s\tremaining: 13.7s\n",
      "318:\tlearn: 0.0022394\ttotal: 24.1s\tremaining: 13.7s\n",
      "319:\tlearn: 0.0022393\ttotal: 24.2s\tremaining: 13.6s\n",
      "320:\tlearn: 0.0022392\ttotal: 24.2s\tremaining: 13.5s\n",
      "321:\tlearn: 0.0022391\ttotal: 24.3s\tremaining: 13.4s\n",
      "322:\tlearn: 0.0022391\ttotal: 24.4s\tremaining: 13.4s\n",
      "323:\tlearn: 0.0022391\ttotal: 24.5s\tremaining: 13.3s\n",
      "324:\tlearn: 0.0022391\ttotal: 24.5s\tremaining: 13.2s\n",
      "325:\tlearn: 0.0022390\ttotal: 24.6s\tremaining: 13.1s\n",
      "326:\tlearn: 0.0022390\ttotal: 24.7s\tremaining: 13.1s\n",
      "327:\tlearn: 0.0022284\ttotal: 24.7s\tremaining: 13s\n",
      "328:\tlearn: 0.0022284\ttotal: 24.9s\tremaining: 12.9s\n",
      "329:\tlearn: 0.0022130\ttotal: 24.9s\tremaining: 12.8s\n",
      "330:\tlearn: 0.0022130\ttotal: 25s\tremaining: 12.8s\n",
      "331:\tlearn: 0.0022130\ttotal: 25.1s\tremaining: 12.7s\n",
      "332:\tlearn: 0.0022129\ttotal: 25.1s\tremaining: 12.6s\n",
      "333:\tlearn: 0.0021967\ttotal: 25.2s\tremaining: 12.5s\n",
      "334:\tlearn: 0.0021815\ttotal: 25.3s\tremaining: 12.4s\n",
      "335:\tlearn: 0.0021782\ttotal: 25.4s\tremaining: 12.4s\n",
      "336:\tlearn: 0.0021782\ttotal: 25.4s\tremaining: 12.3s\n",
      "337:\tlearn: 0.0021781\ttotal: 25.5s\tremaining: 12.2s\n",
      "338:\tlearn: 0.0021781\ttotal: 25.6s\tremaining: 12.2s\n",
      "339:\tlearn: 0.0021781\ttotal: 25.6s\tremaining: 12.1s\n",
      "340:\tlearn: 0.0021781\ttotal: 25.7s\tremaining: 12s\n",
      "341:\tlearn: 0.0021780\ttotal: 25.8s\tremaining: 11.9s\n",
      "342:\tlearn: 0.0021562\ttotal: 25.8s\tremaining: 11.8s\n",
      "343:\tlearn: 0.0021560\ttotal: 26s\tremaining: 11.8s\n",
      "344:\tlearn: 0.0021419\ttotal: 26s\tremaining: 11.7s\n",
      "345:\tlearn: 0.0021419\ttotal: 26.1s\tremaining: 11.6s\n",
      "346:\tlearn: 0.0021419\ttotal: 26.2s\tremaining: 11.5s\n",
      "347:\tlearn: 0.0021296\ttotal: 26.3s\tremaining: 11.5s\n",
      "348:\tlearn: 0.0021099\ttotal: 26.3s\tremaining: 11.4s\n",
      "349:\tlearn: 0.0021098\ttotal: 26.4s\tremaining: 11.3s\n",
      "350:\tlearn: 0.0021098\ttotal: 26.5s\tremaining: 11.2s\n",
      "351:\tlearn: 0.0021099\ttotal: 26.5s\tremaining: 11.2s\n",
      "352:\tlearn: 0.0021098\ttotal: 26.6s\tremaining: 11.1s\n",
      "353:\tlearn: 0.0021095\ttotal: 26.7s\tremaining: 11s\n",
      "354:\tlearn: 0.0021095\ttotal: 26.8s\tremaining: 10.9s\n",
      "355:\tlearn: 0.0021095\ttotal: 26.9s\tremaining: 10.9s\n",
      "356:\tlearn: 0.0021094\ttotal: 26.9s\tremaining: 10.8s\n",
      "357:\tlearn: 0.0021094\ttotal: 27s\tremaining: 10.7s\n",
      "358:\tlearn: 0.0021094\ttotal: 27.1s\tremaining: 10.6s\n",
      "359:\tlearn: 0.0021094\ttotal: 27.2s\tremaining: 10.6s\n",
      "360:\tlearn: 0.0020909\ttotal: 27.3s\tremaining: 10.5s\n",
      "361:\tlearn: 0.0020909\ttotal: 27.4s\tremaining: 10.4s\n",
      "362:\tlearn: 0.0020909\ttotal: 27.4s\tremaining: 10.4s\n",
      "363:\tlearn: 0.0020909\ttotal: 27.5s\tremaining: 10.3s\n",
      "364:\tlearn: 0.0020909\ttotal: 27.5s\tremaining: 10.2s\n",
      "365:\tlearn: 0.0020909\ttotal: 27.6s\tremaining: 10.1s\n",
      "366:\tlearn: 0.0020909\ttotal: 27.6s\tremaining: 10s\n",
      "367:\tlearn: 0.0020703\ttotal: 27.7s\tremaining: 9.92s\n",
      "368:\tlearn: 0.0020702\ttotal: 27.7s\tremaining: 9.84s\n",
      "369:\tlearn: 0.0020702\ttotal: 27.8s\tremaining: 9.78s\n",
      "370:\tlearn: 0.0020702\ttotal: 27.9s\tremaining: 9.69s\n",
      "371:\tlearn: 0.0020702\ttotal: 27.9s\tremaining: 9.61s\n",
      "372:\tlearn: 0.0020702\ttotal: 28s\tremaining: 9.54s\n",
      "373:\tlearn: 0.0020547\ttotal: 28.1s\tremaining: 9.46s\n",
      "374:\tlearn: 0.0020547\ttotal: 28.2s\tremaining: 9.4s\n",
      "375:\tlearn: 0.0020548\ttotal: 28.2s\tremaining: 9.31s\n",
      "376:\tlearn: 0.0020547\ttotal: 28.3s\tremaining: 9.23s\n",
      "377:\tlearn: 0.0020547\ttotal: 28.4s\tremaining: 9.16s\n",
      "378:\tlearn: 0.0020547\ttotal: 28.4s\tremaining: 9.07s\n",
      "379:\tlearn: 0.0020547\ttotal: 28.5s\tremaining: 9.01s\n",
      "380:\tlearn: 0.0020546\ttotal: 28.6s\tremaining: 8.93s\n",
      "381:\tlearn: 0.0020546\ttotal: 28.7s\tremaining: 8.87s\n",
      "382:\tlearn: 0.0020546\ttotal: 28.8s\tremaining: 8.79s\n",
      "383:\tlearn: 0.0020546\ttotal: 28.8s\tremaining: 8.7s\n",
      "384:\tlearn: 0.0020545\ttotal: 28.9s\tremaining: 8.64s\n",
      "385:\tlearn: 0.0020546\ttotal: 29s\tremaining: 8.55s\n",
      "386:\tlearn: 0.0020429\ttotal: 29.1s\tremaining: 8.49s\n",
      "387:\tlearn: 0.0020429\ttotal: 29.1s\tremaining: 8.41s\n",
      "388:\tlearn: 0.0020429\ttotal: 29.2s\tremaining: 8.32s\n",
      "389:\tlearn: 0.0020429\ttotal: 29.3s\tremaining: 8.26s\n",
      "390:\tlearn: 0.0020429\ttotal: 29.3s\tremaining: 8.17s\n",
      "391:\tlearn: 0.0020429\ttotal: 29.4s\tremaining: 8.11s\n",
      "392:\tlearn: 0.0020351\ttotal: 29.5s\tremaining: 8.03s\n",
      "393:\tlearn: 0.0020181\ttotal: 29.5s\tremaining: 7.95s\n",
      "394:\tlearn: 0.0020181\ttotal: 29.6s\tremaining: 7.88s\n",
      "395:\tlearn: 0.0020181\ttotal: 29.7s\tremaining: 7.79s\n",
      "396:\tlearn: 0.0020180\ttotal: 29.8s\tremaining: 7.73s\n",
      "397:\tlearn: 0.0020180\ttotal: 29.8s\tremaining: 7.65s\n",
      "398:\tlearn: 0.0020180\ttotal: 29.9s\tremaining: 7.56s\n",
      "399:\tlearn: 0.0020180\ttotal: 30s\tremaining: 7.5s\n",
      "400:\tlearn: 0.0020180\ttotal: 30s\tremaining: 7.41s\n",
      "401:\tlearn: 0.0020180\ttotal: 30.1s\tremaining: 7.35s\n",
      "402:\tlearn: 0.0020180\ttotal: 30.2s\tremaining: 7.27s\n",
      "403:\tlearn: 0.0020180\ttotal: 30.3s\tremaining: 7.19s\n",
      "404:\tlearn: 0.0020179\ttotal: 30.3s\tremaining: 7.12s\n",
      "405:\tlearn: 0.0020029\ttotal: 30.4s\tremaining: 7.04s\n",
      "406:\tlearn: 0.0020029\ttotal: 30.5s\tremaining: 6.97s\n",
      "407:\tlearn: 0.0020029\ttotal: 30.6s\tremaining: 6.89s\n",
      "408:\tlearn: 0.0020028\ttotal: 30.7s\tremaining: 6.83s\n",
      "409:\tlearn: 0.0020028\ttotal: 30.7s\tremaining: 6.75s\n",
      "410:\tlearn: 0.0020028\ttotal: 30.8s\tremaining: 6.67s\n",
      "411:\tlearn: 0.0019899\ttotal: 30.9s\tremaining: 6.6s\n",
      "412:\tlearn: 0.0019899\ttotal: 30.9s\tremaining: 6.51s\n",
      "413:\tlearn: 0.0019899\ttotal: 31s\tremaining: 6.45s\n",
      "414:\tlearn: 0.0019898\ttotal: 31.1s\tremaining: 6.37s\n",
      "415:\tlearn: 0.0019898\ttotal: 31.1s\tremaining: 6.29s\n",
      "416:\tlearn: 0.0019898\ttotal: 31.3s\tremaining: 6.22s\n",
      "417:\tlearn: 0.0019898\ttotal: 31.3s\tremaining: 6.14s\n",
      "418:\tlearn: 0.0019898\ttotal: 31.4s\tremaining: 6.07s\n",
      "419:\tlearn: 0.0019898\ttotal: 31.5s\tremaining: 5.99s\n",
      "420:\tlearn: 0.0019897\ttotal: 31.5s\tremaining: 5.91s\n",
      "421:\tlearn: 0.0019897\ttotal: 31.6s\tremaining: 5.84s\n",
      "422:\tlearn: 0.0019896\ttotal: 31.7s\tremaining: 5.76s\n",
      "423:\tlearn: 0.0019896\ttotal: 31.7s\tremaining: 5.69s\n",
      "424:\tlearn: 0.0019896\ttotal: 31.8s\tremaining: 5.62s\n",
      "425:\tlearn: 0.0019895\ttotal: 31.9s\tremaining: 5.54s\n",
      "426:\tlearn: 0.0019895\ttotal: 32s\tremaining: 5.46s\n",
      "427:\tlearn: 0.0019895\ttotal: 32s\tremaining: 5.38s\n",
      "428:\tlearn: 0.0019894\ttotal: 32.1s\tremaining: 5.31s\n",
      "429:\tlearn: 0.0019895\ttotal: 32.2s\tremaining: 5.24s\n",
      "430:\tlearn: 0.0019894\ttotal: 32.2s\tremaining: 5.16s\n",
      "431:\tlearn: 0.0019894\ttotal: 32.3s\tremaining: 5.09s\n",
      "432:\tlearn: 0.0019894\ttotal: 32.4s\tremaining: 5.01s\n",
      "433:\tlearn: 0.0019893\ttotal: 32.5s\tremaining: 4.93s\n",
      "434:\tlearn: 0.0019893\ttotal: 32.5s\tremaining: 4.86s\n",
      "435:\tlearn: 0.0019893\ttotal: 32.6s\tremaining: 4.78s\n",
      "436:\tlearn: 0.0019893\ttotal: 32.7s\tremaining: 4.71s\n",
      "437:\tlearn: 0.0019893\ttotal: 32.7s\tremaining: 4.63s\n",
      "438:\tlearn: 0.0019893\ttotal: 32.8s\tremaining: 4.56s\n",
      "439:\tlearn: 0.0019893\ttotal: 32.9s\tremaining: 4.49s\n",
      "440:\tlearn: 0.0019892\ttotal: 32.9s\tremaining: 4.41s\n",
      "441:\tlearn: 0.0019892\ttotal: 33s\tremaining: 4.33s\n",
      "442:\tlearn: 0.0019892\ttotal: 33.1s\tremaining: 4.26s\n",
      "443:\tlearn: 0.0019892\ttotal: 33.2s\tremaining: 4.18s\n",
      "444:\tlearn: 0.0019892\ttotal: 33.2s\tremaining: 4.11s\n",
      "445:\tlearn: 0.0019892\ttotal: 33.3s\tremaining: 4.03s\n",
      "446:\tlearn: 0.0019892\ttotal: 33.4s\tremaining: 3.96s\n",
      "447:\tlearn: 0.0019891\ttotal: 33.4s\tremaining: 3.88s\n",
      "448:\tlearn: 0.0019891\ttotal: 33.6s\tremaining: 3.81s\n",
      "449:\tlearn: 0.0019891\ttotal: 33.6s\tremaining: 3.73s\n",
      "450:\tlearn: 0.0019795\ttotal: 33.7s\tremaining: 3.66s\n",
      "451:\tlearn: 0.0019795\ttotal: 33.8s\tremaining: 3.59s\n",
      "452:\tlearn: 0.0019795\ttotal: 33.8s\tremaining: 3.51s\n",
      "453:\tlearn: 0.0019745\ttotal: 33.9s\tremaining: 3.44s\n",
      "454:\tlearn: 0.0019745\ttotal: 34s\tremaining: 3.36s\n",
      "455:\tlearn: 0.0019745\ttotal: 34s\tremaining: 3.28s\n",
      "456:\tlearn: 0.0019744\ttotal: 34.1s\tremaining: 3.21s\n",
      "457:\tlearn: 0.0019744\ttotal: 34.2s\tremaining: 3.13s\n",
      "458:\tlearn: 0.0019744\ttotal: 34.3s\tremaining: 3.06s\n",
      "459:\tlearn: 0.0019743\ttotal: 34.4s\tremaining: 2.99s\n",
      "460:\tlearn: 0.0019743\ttotal: 34.4s\tremaining: 2.91s\n",
      "461:\tlearn: 0.0019743\ttotal: 34.5s\tremaining: 2.84s\n",
      "462:\tlearn: 0.0019743\ttotal: 34.5s\tremaining: 2.76s\n",
      "463:\tlearn: 0.0019743\ttotal: 34.6s\tremaining: 2.69s\n",
      "464:\tlearn: 0.0019743\ttotal: 34.7s\tremaining: 2.61s\n",
      "465:\tlearn: 0.0019742\ttotal: 34.8s\tremaining: 2.54s\n",
      "466:\tlearn: 0.0019742\ttotal: 34.9s\tremaining: 2.46s\n",
      "467:\tlearn: 0.0019742\ttotal: 34.9s\tremaining: 2.39s\n",
      "468:\tlearn: 0.0019742\ttotal: 35s\tremaining: 2.31s\n",
      "469:\tlearn: 0.0019742\ttotal: 35.1s\tremaining: 2.24s\n",
      "470:\tlearn: 0.0019742\ttotal: 35.2s\tremaining: 2.17s\n",
      "471:\tlearn: 0.0019742\ttotal: 35.2s\tremaining: 2.09s\n",
      "472:\tlearn: 0.0019742\ttotal: 35.3s\tremaining: 2.02s\n",
      "473:\tlearn: 0.0019742\ttotal: 35.4s\tremaining: 1.94s\n",
      "474:\tlearn: 0.0019742\ttotal: 35.5s\tremaining: 1.87s\n",
      "475:\tlearn: 0.0019741\ttotal: 35.6s\tremaining: 1.79s\n",
      "476:\tlearn: 0.0019741\ttotal: 35.6s\tremaining: 1.72s\n",
      "477:\tlearn: 0.0019741\ttotal: 35.7s\tremaining: 1.64s\n",
      "478:\tlearn: 0.0019741\ttotal: 35.7s\tremaining: 1.57s\n",
      "479:\tlearn: 0.0019633\ttotal: 35.8s\tremaining: 1.49s\n",
      "480:\tlearn: 0.0019633\ttotal: 35.9s\tremaining: 1.42s\n",
      "481:\tlearn: 0.0019632\ttotal: 36s\tremaining: 1.34s\n",
      "482:\tlearn: 0.0019632\ttotal: 36s\tremaining: 1.27s\n",
      "483:\tlearn: 0.0019632\ttotal: 36.1s\tremaining: 1.19s\n",
      "484:\tlearn: 0.0019632\ttotal: 36.2s\tremaining: 1.12s\n",
      "485:\tlearn: 0.0019632\ttotal: 36.3s\tremaining: 1.04s\n",
      "486:\tlearn: 0.0019632\ttotal: 36.4s\tremaining: 970ms\n",
      "487:\tlearn: 0.0019632\ttotal: 36.4s\tremaining: 896ms\n",
      "488:\tlearn: 0.0019632\ttotal: 36.5s\tremaining: 821ms\n",
      "489:\tlearn: 0.0019455\ttotal: 36.6s\tremaining: 746ms\n",
      "490:\tlearn: 0.0019455\ttotal: 36.7s\tremaining: 672ms\n",
      "491:\tlearn: 0.0019453\ttotal: 36.7s\tremaining: 597ms\n",
      "492:\tlearn: 0.0019453\ttotal: 36.8s\tremaining: 523ms\n",
      "493:\tlearn: 0.0019453\ttotal: 36.9s\tremaining: 448ms\n",
      "494:\tlearn: 0.0019452\ttotal: 36.9s\tremaining: 373ms\n",
      "495:\tlearn: 0.0019452\ttotal: 37s\tremaining: 299ms\n",
      "496:\tlearn: 0.0019452\ttotal: 37.1s\tremaining: 224ms\n",
      "497:\tlearn: 0.0019452\ttotal: 37.2s\tremaining: 149ms\n",
      "498:\tlearn: 0.0019452\ttotal: 37.2s\tremaining: 74.6ms\n",
      "499:\tlearn: 0.0019452\ttotal: 37.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6485171\ttotal: 87.3ms\tremaining: 43.6s\n",
      "1:\tlearn: 0.6074905\ttotal: 149ms\tremaining: 37.1s\n",
      "2:\tlearn: 0.5708742\ttotal: 230ms\tremaining: 38.1s\n",
      "3:\tlearn: 0.5369257\ttotal: 298ms\tremaining: 37s\n",
      "4:\tlearn: 0.5079745\ttotal: 381ms\tremaining: 37.7s\n",
      "5:\tlearn: 0.4816771\ttotal: 458ms\tremaining: 37.7s\n",
      "6:\tlearn: 0.4527072\ttotal: 500ms\tremaining: 35.2s\n",
      "7:\tlearn: 0.4344645\ttotal: 619ms\tremaining: 38.1s\n",
      "8:\tlearn: 0.4181233\ttotal: 665ms\tremaining: 36.3s\n",
      "9:\tlearn: 0.3973841\ttotal: 757ms\tremaining: 37.1s\n",
      "10:\tlearn: 0.3754043\ttotal: 822ms\tremaining: 36.6s\n",
      "11:\tlearn: 0.3596328\ttotal: 871ms\tremaining: 35.4s\n",
      "12:\tlearn: 0.3460245\ttotal: 984ms\tremaining: 36.9s\n",
      "13:\tlearn: 0.3316153\ttotal: 1.03s\tremaining: 35.8s\n",
      "14:\tlearn: 0.3203616\ttotal: 1.13s\tremaining: 36.4s\n",
      "15:\tlearn: 0.2948620\ttotal: 1.18s\tremaining: 35.8s\n",
      "16:\tlearn: 0.2778736\ttotal: 1.23s\tremaining: 34.9s\n",
      "17:\tlearn: 0.2642534\ttotal: 1.34s\tremaining: 35.9s\n",
      "18:\tlearn: 0.2524674\ttotal: 1.39s\tremaining: 35.2s\n",
      "19:\tlearn: 0.2432162\ttotal: 1.51s\tremaining: 36.2s\n",
      "20:\tlearn: 0.2328804\ttotal: 1.55s\tremaining: 35.4s\n",
      "21:\tlearn: 0.2256523\ttotal: 1.65s\tremaining: 35.8s\n",
      "22:\tlearn: 0.2165410\ttotal: 1.71s\tremaining: 35.6s\n",
      "23:\tlearn: 0.2059559\ttotal: 1.77s\tremaining: 35.1s\n",
      "24:\tlearn: 0.1960568\ttotal: 1.87s\tremaining: 35.6s\n",
      "25:\tlearn: 0.1870435\ttotal: 1.92s\tremaining: 35s\n",
      "26:\tlearn: 0.1820706\ttotal: 2.03s\tremaining: 35.6s\n",
      "27:\tlearn: 0.1757655\ttotal: 2.09s\tremaining: 35.2s\n",
      "28:\tlearn: 0.1688613\ttotal: 2.18s\tremaining: 35.4s\n",
      "29:\tlearn: 0.1628906\ttotal: 2.25s\tremaining: 35.3s\n",
      "30:\tlearn: 0.1572089\ttotal: 2.29s\tremaining: 34.7s\n",
      "31:\tlearn: 0.1510096\ttotal: 2.4s\tremaining: 35.2s\n",
      "32:\tlearn: 0.1439125\ttotal: 2.45s\tremaining: 34.7s\n",
      "33:\tlearn: 0.1375885\ttotal: 2.55s\tremaining: 35s\n",
      "34:\tlearn: 0.1320879\ttotal: 2.6s\tremaining: 34.6s\n",
      "35:\tlearn: 0.1284742\ttotal: 2.64s\tremaining: 34.1s\n",
      "36:\tlearn: 0.1251497\ttotal: 2.76s\tremaining: 34.5s\n",
      "37:\tlearn: 0.1213767\ttotal: 2.81s\tremaining: 34.1s\n",
      "38:\tlearn: 0.1195546\ttotal: 2.92s\tremaining: 34.5s\n",
      "39:\tlearn: 0.1147209\ttotal: 2.98s\tremaining: 34.2s\n",
      "40:\tlearn: 0.1094463\ttotal: 3.07s\tremaining: 34.4s\n",
      "41:\tlearn: 0.1051221\ttotal: 3.14s\tremaining: 34.2s\n",
      "42:\tlearn: 0.1016167\ttotal: 3.18s\tremaining: 33.8s\n",
      "43:\tlearn: 0.0990862\ttotal: 3.3s\tremaining: 34.2s\n",
      "44:\tlearn: 0.0953471\ttotal: 3.35s\tremaining: 33.8s\n",
      "45:\tlearn: 0.0919915\ttotal: 3.44s\tremaining: 33.9s\n",
      "46:\tlearn: 0.0874586\ttotal: 3.5s\tremaining: 33.8s\n",
      "47:\tlearn: 0.0847444\ttotal: 3.54s\tremaining: 33.4s\n",
      "48:\tlearn: 0.0826771\ttotal: 3.66s\tremaining: 33.7s\n",
      "49:\tlearn: 0.0797120\ttotal: 3.7s\tremaining: 33.3s\n",
      "50:\tlearn: 0.0759275\ttotal: 3.83s\tremaining: 33.7s\n",
      "51:\tlearn: 0.0738688\ttotal: 3.88s\tremaining: 33.4s\n",
      "52:\tlearn: 0.0718898\ttotal: 3.96s\tremaining: 33.4s\n",
      "53:\tlearn: 0.0693847\ttotal: 4.04s\tremaining: 33.3s\n",
      "54:\tlearn: 0.0673214\ttotal: 4.08s\tremaining: 33s\n",
      "55:\tlearn: 0.0653756\ttotal: 4.19s\tremaining: 33.2s\n",
      "56:\tlearn: 0.0629023\ttotal: 4.24s\tremaining: 32.9s\n",
      "57:\tlearn: 0.0607274\ttotal: 4.33s\tremaining: 33s\n",
      "58:\tlearn: 0.0586058\ttotal: 4.4s\tremaining: 32.9s\n",
      "59:\tlearn: 0.0567198\ttotal: 4.44s\tremaining: 32.6s\n",
      "60:\tlearn: 0.0554110\ttotal: 4.56s\tremaining: 32.8s\n",
      "61:\tlearn: 0.0531213\ttotal: 4.61s\tremaining: 32.6s\n",
      "62:\tlearn: 0.0514858\ttotal: 4.71s\tremaining: 32.6s\n",
      "63:\tlearn: 0.0499731\ttotal: 4.78s\tremaining: 32.5s\n",
      "64:\tlearn: 0.0482416\ttotal: 4.82s\tremaining: 32.3s\n",
      "65:\tlearn: 0.0473596\ttotal: 4.94s\tremaining: 32.5s\n",
      "66:\tlearn: 0.0462713\ttotal: 4.98s\tremaining: 32.2s\n",
      "67:\tlearn: 0.0454131\ttotal: 5.08s\tremaining: 32.3s\n",
      "68:\tlearn: 0.0443256\ttotal: 5.14s\tremaining: 32.1s\n",
      "69:\tlearn: 0.0430294\ttotal: 5.18s\tremaining: 31.8s\n",
      "70:\tlearn: 0.0416327\ttotal: 5.3s\tremaining: 32s\n",
      "71:\tlearn: 0.0405180\ttotal: 5.35s\tremaining: 31.8s\n",
      "72:\tlearn: 0.0390741\ttotal: 5.46s\tremaining: 32s\n",
      "73:\tlearn: 0.0372105\ttotal: 5.51s\tremaining: 31.7s\n",
      "74:\tlearn: 0.0361811\ttotal: 5.61s\tremaining: 31.8s\n",
      "75:\tlearn: 0.0354320\ttotal: 5.68s\tremaining: 31.7s\n",
      "76:\tlearn: 0.0344352\ttotal: 5.72s\tremaining: 31.4s\n",
      "77:\tlearn: 0.0334827\ttotal: 5.81s\tremaining: 31.4s\n",
      "78:\tlearn: 0.0327609\ttotal: 5.85s\tremaining: 31.2s\n",
      "79:\tlearn: 0.0318083\ttotal: 5.97s\tremaining: 31.3s\n",
      "80:\tlearn: 0.0310215\ttotal: 6.02s\tremaining: 31.1s\n",
      "81:\tlearn: 0.0301395\ttotal: 6.13s\tremaining: 31.3s\n",
      "82:\tlearn: 0.0291699\ttotal: 6.19s\tremaining: 31.1s\n",
      "83:\tlearn: 0.0286099\ttotal: 6.23s\tremaining: 30.8s\n",
      "84:\tlearn: 0.0276483\ttotal: 6.33s\tremaining: 30.9s\n",
      "85:\tlearn: 0.0271385\ttotal: 6.38s\tremaining: 30.7s\n",
      "86:\tlearn: 0.0264676\ttotal: 6.49s\tremaining: 30.8s\n",
      "87:\tlearn: 0.0258212\ttotal: 6.55s\tremaining: 30.7s\n",
      "88:\tlearn: 0.0253056\ttotal: 6.64s\tremaining: 30.7s\n",
      "89:\tlearn: 0.0244076\ttotal: 6.71s\tremaining: 30.6s\n",
      "90:\tlearn: 0.0235306\ttotal: 6.75s\tremaining: 30.4s\n",
      "91:\tlearn: 0.0229788\ttotal: 6.87s\tremaining: 30.5s\n",
      "92:\tlearn: 0.0224803\ttotal: 6.91s\tremaining: 30.3s\n",
      "93:\tlearn: 0.0219372\ttotal: 7.03s\tremaining: 30.4s\n",
      "94:\tlearn: 0.0210795\ttotal: 7.1s\tremaining: 30.3s\n",
      "95:\tlearn: 0.0204799\ttotal: 7.14s\tremaining: 30s\n",
      "96:\tlearn: 0.0199465\ttotal: 7.26s\tremaining: 30.1s\n",
      "97:\tlearn: 0.0193563\ttotal: 7.3s\tremaining: 29.9s\n",
      "98:\tlearn: 0.0189642\ttotal: 7.42s\tremaining: 30s\n",
      "99:\tlearn: 0.0184366\ttotal: 7.47s\tremaining: 29.9s\n",
      "100:\tlearn: 0.0179735\ttotal: 7.57s\tremaining: 29.9s\n",
      "101:\tlearn: 0.0175469\ttotal: 7.64s\tremaining: 29.8s\n",
      "102:\tlearn: 0.0171911\ttotal: 7.68s\tremaining: 29.6s\n",
      "103:\tlearn: 0.0166729\ttotal: 7.79s\tremaining: 29.7s\n",
      "104:\tlearn: 0.0163772\ttotal: 7.84s\tremaining: 29.5s\n",
      "105:\tlearn: 0.0160720\ttotal: 7.93s\tremaining: 29.5s\n",
      "106:\tlearn: 0.0157014\ttotal: 7.99s\tremaining: 29.4s\n",
      "107:\tlearn: 0.0152879\ttotal: 8.03s\tremaining: 29.2s\n",
      "108:\tlearn: 0.0149557\ttotal: 8.15s\tremaining: 29.2s\n",
      "109:\tlearn: 0.0145714\ttotal: 8.2s\tremaining: 29.1s\n",
      "110:\tlearn: 0.0142340\ttotal: 8.29s\tremaining: 29.1s\n",
      "111:\tlearn: 0.0139075\ttotal: 8.35s\tremaining: 28.9s\n",
      "112:\tlearn: 0.0136080\ttotal: 8.39s\tremaining: 28.8s\n",
      "113:\tlearn: 0.0133341\ttotal: 8.51s\tremaining: 28.8s\n",
      "114:\tlearn: 0.0130383\ttotal: 8.56s\tremaining: 28.7s\n",
      "115:\tlearn: 0.0127576\ttotal: 8.68s\tremaining: 28.7s\n",
      "116:\tlearn: 0.0124810\ttotal: 8.73s\tremaining: 28.6s\n",
      "117:\tlearn: 0.0122197\ttotal: 8.83s\tremaining: 28.6s\n",
      "118:\tlearn: 0.0119992\ttotal: 8.9s\tremaining: 28.5s\n",
      "119:\tlearn: 0.0116962\ttotal: 8.99s\tremaining: 28.5s\n",
      "120:\tlearn: 0.0114657\ttotal: 9.07s\tremaining: 28.4s\n",
      "121:\tlearn: 0.0112701\ttotal: 9.11s\tremaining: 28.2s\n",
      "122:\tlearn: 0.0110508\ttotal: 9.23s\tremaining: 28.3s\n",
      "123:\tlearn: 0.0108883\ttotal: 9.28s\tremaining: 28.1s\n",
      "124:\tlearn: 0.0106957\ttotal: 9.39s\tremaining: 28.2s\n",
      "125:\tlearn: 0.0105081\ttotal: 9.44s\tremaining: 28s\n",
      "126:\tlearn: 0.0102787\ttotal: 9.55s\tremaining: 28s\n",
      "127:\tlearn: 0.0100571\ttotal: 9.61s\tremaining: 27.9s\n",
      "128:\tlearn: 0.0098515\ttotal: 9.65s\tremaining: 27.8s\n",
      "129:\tlearn: 0.0096565\ttotal: 9.77s\tremaining: 27.8s\n",
      "130:\tlearn: 0.0094693\ttotal: 9.81s\tremaining: 27.6s\n",
      "131:\tlearn: 0.0093262\ttotal: 9.92s\tremaining: 27.6s\n",
      "132:\tlearn: 0.0091737\ttotal: 9.97s\tremaining: 27.5s\n",
      "133:\tlearn: 0.0090148\ttotal: 10s\tremaining: 27.4s\n",
      "134:\tlearn: 0.0088052\ttotal: 10.1s\tremaining: 27.4s\n",
      "135:\tlearn: 0.0086901\ttotal: 10.2s\tremaining: 27.2s\n",
      "136:\tlearn: 0.0085169\ttotal: 10.3s\tremaining: 27.3s\n",
      "137:\tlearn: 0.0083942\ttotal: 10.4s\tremaining: 27.3s\n",
      "138:\tlearn: 0.0082731\ttotal: 10.5s\tremaining: 27.2s\n",
      "139:\tlearn: 0.0081565\ttotal: 10.6s\tremaining: 27.1s\n",
      "140:\tlearn: 0.0080056\ttotal: 10.6s\tremaining: 27s\n",
      "141:\tlearn: 0.0079032\ttotal: 10.7s\tremaining: 27s\n",
      "142:\tlearn: 0.0077831\ttotal: 10.8s\tremaining: 26.9s\n",
      "143:\tlearn: 0.0076911\ttotal: 10.8s\tremaining: 26.8s\n",
      "144:\tlearn: 0.0076025\ttotal: 10.9s\tremaining: 26.8s\n",
      "145:\tlearn: 0.0074573\ttotal: 11s\tremaining: 26.6s\n",
      "146:\tlearn: 0.0073474\ttotal: 11s\tremaining: 26.5s\n",
      "147:\tlearn: 0.0072435\ttotal: 11.1s\tremaining: 26.5s\n",
      "148:\tlearn: 0.0071128\ttotal: 11.2s\tremaining: 26.3s\n",
      "149:\tlearn: 0.0070301\ttotal: 11.3s\tremaining: 26.3s\n",
      "150:\tlearn: 0.0069307\ttotal: 11.3s\tremaining: 26.1s\n",
      "151:\tlearn: 0.0068291\ttotal: 11.4s\tremaining: 26.2s\n",
      "152:\tlearn: 0.0067257\ttotal: 11.5s\tremaining: 26s\n",
      "153:\tlearn: 0.0066595\ttotal: 11.6s\tremaining: 26s\n",
      "154:\tlearn: 0.0065102\ttotal: 11.6s\tremaining: 25.9s\n",
      "155:\tlearn: 0.0064279\ttotal: 11.7s\tremaining: 25.8s\n",
      "156:\tlearn: 0.0063136\ttotal: 11.8s\tremaining: 25.7s\n",
      "157:\tlearn: 0.0062027\ttotal: 11.8s\tremaining: 25.6s\n",
      "158:\tlearn: 0.0061327\ttotal: 11.9s\tremaining: 25.6s\n",
      "159:\tlearn: 0.0060529\ttotal: 12s\tremaining: 25.5s\n",
      "160:\tlearn: 0.0059750\ttotal: 12s\tremaining: 25.4s\n",
      "161:\tlearn: 0.0058681\ttotal: 12.1s\tremaining: 25.3s\n",
      "162:\tlearn: 0.0057943\ttotal: 12.2s\tremaining: 25.2s\n",
      "163:\tlearn: 0.0057263\ttotal: 12.3s\tremaining: 25.2s\n",
      "164:\tlearn: 0.0056622\ttotal: 12.4s\tremaining: 25.1s\n",
      "165:\tlearn: 0.0055712\ttotal: 12.4s\tremaining: 25s\n",
      "166:\tlearn: 0.0054870\ttotal: 12.5s\tremaining: 25s\n",
      "167:\tlearn: 0.0054357\ttotal: 12.6s\tremaining: 24.8s\n",
      "168:\tlearn: 0.0053609\ttotal: 12.7s\tremaining: 24.8s\n",
      "169:\tlearn: 0.0052989\ttotal: 12.7s\tremaining: 24.7s\n",
      "170:\tlearn: 0.0052340\ttotal: 12.8s\tremaining: 24.6s\n",
      "171:\tlearn: 0.0051661\ttotal: 12.9s\tremaining: 24.6s\n",
      "172:\tlearn: 0.0050924\ttotal: 12.9s\tremaining: 24.4s\n",
      "173:\tlearn: 0.0050292\ttotal: 13s\tremaining: 24.4s\n",
      "174:\tlearn: 0.0049728\ttotal: 13.1s\tremaining: 24.3s\n",
      "175:\tlearn: 0.0049182\ttotal: 13.1s\tremaining: 24.2s\n",
      "176:\tlearn: 0.0048768\ttotal: 13.2s\tremaining: 24.2s\n",
      "177:\tlearn: 0.0048349\ttotal: 13.3s\tremaining: 24s\n",
      "178:\tlearn: 0.0047944\ttotal: 13.4s\tremaining: 24s\n",
      "179:\tlearn: 0.0047621\ttotal: 13.4s\tremaining: 23.9s\n",
      "180:\tlearn: 0.0047257\ttotal: 13.5s\tremaining: 23.8s\n",
      "181:\tlearn: 0.0046551\ttotal: 13.6s\tremaining: 23.8s\n",
      "182:\tlearn: 0.0045685\ttotal: 13.6s\tremaining: 23.6s\n",
      "183:\tlearn: 0.0045175\ttotal: 13.7s\tremaining: 23.6s\n",
      "184:\tlearn: 0.0044711\ttotal: 13.8s\tremaining: 23.5s\n",
      "185:\tlearn: 0.0044222\ttotal: 13.8s\tremaining: 23.4s\n",
      "186:\tlearn: 0.0043826\ttotal: 14s\tremaining: 23.4s\n",
      "187:\tlearn: 0.0043077\ttotal: 14s\tremaining: 23.2s\n",
      "188:\tlearn: 0.0042597\ttotal: 14.1s\tremaining: 23.2s\n",
      "189:\tlearn: 0.0042240\ttotal: 14.1s\tremaining: 23.1s\n",
      "190:\tlearn: 0.0041784\ttotal: 14.2s\tremaining: 23s\n",
      "191:\tlearn: 0.0041279\ttotal: 14.3s\tremaining: 22.9s\n",
      "192:\tlearn: 0.0040711\ttotal: 14.3s\tremaining: 22.8s\n",
      "193:\tlearn: 0.0040213\ttotal: 14.4s\tremaining: 22.7s\n",
      "194:\tlearn: 0.0039904\ttotal: 14.5s\tremaining: 22.7s\n",
      "195:\tlearn: 0.0039523\ttotal: 14.5s\tremaining: 22.5s\n",
      "196:\tlearn: 0.0039137\ttotal: 14.6s\tremaining: 22.5s\n",
      "197:\tlearn: 0.0038697\ttotal: 14.7s\tremaining: 22.4s\n",
      "198:\tlearn: 0.0038434\ttotal: 14.8s\tremaining: 22.4s\n",
      "199:\tlearn: 0.0038026\ttotal: 14.9s\tremaining: 22.3s\n",
      "200:\tlearn: 0.0037759\ttotal: 14.9s\tremaining: 22.2s\n",
      "201:\tlearn: 0.0037348\ttotal: 15s\tremaining: 22.2s\n",
      "202:\tlearn: 0.0036972\ttotal: 15.1s\tremaining: 22s\n",
      "203:\tlearn: 0.0036593\ttotal: 15.2s\tremaining: 22s\n",
      "204:\tlearn: 0.0036248\ttotal: 15.2s\tremaining: 21.9s\n",
      "205:\tlearn: 0.0035894\ttotal: 15.3s\tremaining: 21.8s\n",
      "206:\tlearn: 0.0035545\ttotal: 15.4s\tremaining: 21.8s\n",
      "207:\tlearn: 0.0035116\ttotal: 15.4s\tremaining: 21.6s\n",
      "208:\tlearn: 0.0034715\ttotal: 15.5s\tremaining: 21.6s\n",
      "209:\tlearn: 0.0034277\ttotal: 15.6s\tremaining: 21.5s\n",
      "210:\tlearn: 0.0034015\ttotal: 15.6s\tremaining: 21.4s\n",
      "211:\tlearn: 0.0033762\ttotal: 15.7s\tremaining: 21.4s\n",
      "212:\tlearn: 0.0033503\ttotal: 15.8s\tremaining: 21.3s\n",
      "213:\tlearn: 0.0033192\ttotal: 15.9s\tremaining: 21.2s\n",
      "214:\tlearn: 0.0032883\ttotal: 15.9s\tremaining: 21.1s\n",
      "215:\tlearn: 0.0032585\ttotal: 16s\tremaining: 21s\n",
      "216:\tlearn: 0.0032353\ttotal: 16.1s\tremaining: 21s\n",
      "217:\tlearn: 0.0032050\ttotal: 16.1s\tremaining: 20.9s\n",
      "218:\tlearn: 0.0031753\ttotal: 16.3s\tremaining: 20.9s\n",
      "219:\tlearn: 0.0031537\ttotal: 16.3s\tremaining: 20.8s\n",
      "220:\tlearn: 0.0031536\ttotal: 16.4s\tremaining: 20.7s\n",
      "221:\tlearn: 0.0031282\ttotal: 16.5s\tremaining: 20.6s\n",
      "222:\tlearn: 0.0031037\ttotal: 16.5s\tremaining: 20.5s\n",
      "223:\tlearn: 0.0031037\ttotal: 16.6s\tremaining: 20.5s\n",
      "224:\tlearn: 0.0030791\ttotal: 16.7s\tremaining: 20.4s\n",
      "225:\tlearn: 0.0030549\ttotal: 16.8s\tremaining: 20.3s\n",
      "226:\tlearn: 0.0030348\ttotal: 16.8s\tremaining: 20.2s\n",
      "227:\tlearn: 0.0029803\ttotal: 16.9s\tremaining: 20.1s\n",
      "228:\tlearn: 0.0029502\ttotal: 17s\tremaining: 20.1s\n",
      "229:\tlearn: 0.0029180\ttotal: 17s\tremaining: 20s\n",
      "230:\tlearn: 0.0028893\ttotal: 17.1s\tremaining: 20s\n",
      "231:\tlearn: 0.0028712\ttotal: 17.2s\tremaining: 19.9s\n",
      "232:\tlearn: 0.0028515\ttotal: 17.2s\tremaining: 19.8s\n",
      "233:\tlearn: 0.0028233\ttotal: 17.3s\tremaining: 19.7s\n",
      "234:\tlearn: 0.0027994\ttotal: 17.4s\tremaining: 19.6s\n",
      "235:\tlearn: 0.0027744\ttotal: 17.5s\tremaining: 19.6s\n",
      "236:\tlearn: 0.0027493\ttotal: 17.6s\tremaining: 19.5s\n",
      "237:\tlearn: 0.0027233\ttotal: 17.7s\tremaining: 19.4s\n",
      "238:\tlearn: 0.0027233\ttotal: 17.7s\tremaining: 19.4s\n",
      "239:\tlearn: 0.0027232\ttotal: 17.8s\tremaining: 19.3s\n",
      "240:\tlearn: 0.0027231\ttotal: 17.9s\tremaining: 19.2s\n",
      "241:\tlearn: 0.0027032\ttotal: 17.9s\tremaining: 19.1s\n",
      "242:\tlearn: 0.0027032\ttotal: 18s\tremaining: 19s\n",
      "243:\tlearn: 0.0027032\ttotal: 18.1s\tremaining: 19s\n",
      "244:\tlearn: 0.0027031\ttotal: 18.1s\tremaining: 18.9s\n",
      "245:\tlearn: 0.0027031\ttotal: 18.2s\tremaining: 18.8s\n",
      "246:\tlearn: 0.0027031\ttotal: 18.3s\tremaining: 18.7s\n",
      "247:\tlearn: 0.0026943\ttotal: 18.3s\tremaining: 18.6s\n",
      "248:\tlearn: 0.0026745\ttotal: 18.4s\tremaining: 18.6s\n",
      "249:\tlearn: 0.0026512\ttotal: 18.5s\tremaining: 18.5s\n",
      "250:\tlearn: 0.0026287\ttotal: 18.6s\tremaining: 18.4s\n",
      "251:\tlearn: 0.0026079\ttotal: 18.6s\tremaining: 18.4s\n",
      "252:\tlearn: 0.0025910\ttotal: 18.7s\tremaining: 18.2s\n",
      "253:\tlearn: 0.0025714\ttotal: 18.8s\tremaining: 18.2s\n",
      "254:\tlearn: 0.0025573\ttotal: 18.8s\tremaining: 18.1s\n",
      "255:\tlearn: 0.0025572\ttotal: 18.9s\tremaining: 18s\n",
      "256:\tlearn: 0.0025362\ttotal: 19s\tremaining: 17.9s\n",
      "257:\tlearn: 0.0025362\ttotal: 19.1s\tremaining: 17.9s\n",
      "258:\tlearn: 0.0025264\ttotal: 19.1s\tremaining: 17.8s\n",
      "259:\tlearn: 0.0025264\ttotal: 19.2s\tremaining: 17.7s\n",
      "260:\tlearn: 0.0025264\ttotal: 19.3s\tremaining: 17.7s\n",
      "261:\tlearn: 0.0025060\ttotal: 19.4s\tremaining: 17.6s\n",
      "262:\tlearn: 0.0024904\ttotal: 19.5s\tremaining: 17.5s\n",
      "266:\tlearn: 0.0024903\ttotal: 19.8s\tremaining: 17.3s\n",
      "267:\tlearn: 0.0024903\ttotal: 23.5s\tremaining: 20.3s\n",
      "268:\tlearn: 0.0024903\ttotal: 23.5s\tremaining: 20.2s\n",
      "269:\tlearn: 0.0024730\ttotal: 23.5s\tremaining: 20s\n",
      "270:\tlearn: 0.0024730\ttotal: 23.5s\tremaining: 19.9s\n",
      "271:\tlearn: 0.0024728\ttotal: 23.6s\tremaining: 19.8s\n",
      "272:\tlearn: 0.0024727\ttotal: 23.6s\tremaining: 19.6s\n",
      "273:\tlearn: 0.0024726\ttotal: 23.6s\tremaining: 19.5s\n",
      "274:\tlearn: 0.0024726\ttotal: 23.6s\tremaining: 19.3s\n",
      "275:\tlearn: 0.0024726\ttotal: 23.6s\tremaining: 19.2s\n",
      "276:\tlearn: 0.0024725\ttotal: 23.7s\tremaining: 19s\n",
      "277:\tlearn: 0.0024725\ttotal: 23.7s\tremaining: 18.9s\n",
      "278:\tlearn: 0.0024725\ttotal: 23.7s\tremaining: 18.8s\n",
      "279:\tlearn: 0.0024724\ttotal: 23.7s\tremaining: 18.6s\n",
      "280:\tlearn: 0.0024724\ttotal: 23.7s\tremaining: 18.5s\n",
      "281:\tlearn: 0.0024724\ttotal: 23.7s\tremaining: 18.4s\n",
      "282:\tlearn: 0.0024723\ttotal: 23.8s\tremaining: 18.2s\n",
      "283:\tlearn: 0.0024723\ttotal: 23.8s\tremaining: 18.1s\n",
      "284:\tlearn: 0.0024723\ttotal: 23.8s\tremaining: 18s\n",
      "285:\tlearn: 0.0024721\ttotal: 23.9s\tremaining: 17.9s\n",
      "286:\tlearn: 0.0024721\ttotal: 24s\tremaining: 17.8s\n",
      "287:\tlearn: 0.0024721\ttotal: 24s\tremaining: 17.7s\n",
      "288:\tlearn: 0.0024721\ttotal: 24.1s\tremaining: 17.6s\n",
      "289:\tlearn: 0.0024521\ttotal: 24.2s\tremaining: 17.5s\n",
      "290:\tlearn: 0.0024341\ttotal: 24.2s\tremaining: 17.4s\n",
      "291:\tlearn: 0.0024340\ttotal: 24.2s\tremaining: 17.3s\n",
      "292:\tlearn: 0.0024340\ttotal: 24.2s\tremaining: 17.1s\n",
      "293:\tlearn: 0.0024239\ttotal: 24.3s\tremaining: 17s\n",
      "294:\tlearn: 0.0024038\ttotal: 24.3s\tremaining: 16.9s\n",
      "295:\tlearn: 0.0024038\ttotal: 24.3s\tremaining: 16.8s\n",
      "296:\tlearn: 0.0024038\ttotal: 24.3s\tremaining: 16.6s\n",
      "297:\tlearn: 0.0024037\ttotal: 24.3s\tremaining: 16.5s\n",
      "298:\tlearn: 0.0024037\ttotal: 24.4s\tremaining: 16.4s\n",
      "299:\tlearn: 0.0024037\ttotal: 24.4s\tremaining: 16.3s\n",
      "300:\tlearn: 0.0023869\ttotal: 24.4s\tremaining: 16.1s\n",
      "301:\tlearn: 0.0023869\ttotal: 24.4s\tremaining: 16s\n",
      "302:\tlearn: 0.0023870\ttotal: 24.5s\tremaining: 15.9s\n",
      "303:\tlearn: 0.0023757\ttotal: 24.5s\tremaining: 15.8s\n",
      "304:\tlearn: 0.0023756\ttotal: 24.5s\tremaining: 15.7s\n",
      "305:\tlearn: 0.0023756\ttotal: 24.5s\tremaining: 15.5s\n",
      "306:\tlearn: 0.0023756\ttotal: 24.5s\tremaining: 15.4s\n",
      "307:\tlearn: 0.0023757\ttotal: 24.6s\tremaining: 15.3s\n",
      "308:\tlearn: 0.0023663\ttotal: 24.6s\tremaining: 15.2s\n",
      "309:\tlearn: 0.0023503\ttotal: 24.6s\tremaining: 15.1s\n",
      "310:\tlearn: 0.0023358\ttotal: 24.6s\tremaining: 15s\n",
      "311:\tlearn: 0.0023357\ttotal: 24.7s\tremaining: 14.9s\n",
      "312:\tlearn: 0.0023207\ttotal: 24.7s\tremaining: 14.7s\n",
      "313:\tlearn: 0.0023207\ttotal: 24.7s\tremaining: 14.6s\n",
      "314:\tlearn: 0.0023207\ttotal: 24.7s\tremaining: 14.5s\n",
      "315:\tlearn: 0.0023207\ttotal: 24.7s\tremaining: 14.4s\n",
      "316:\tlearn: 0.0023207\ttotal: 24.8s\tremaining: 14.3s\n",
      "317:\tlearn: 0.0023207\ttotal: 24.8s\tremaining: 14.2s\n",
      "318:\tlearn: 0.0023207\ttotal: 24.8s\tremaining: 14.1s\n",
      "319:\tlearn: 0.0023207\ttotal: 24.8s\tremaining: 14s\n",
      "320:\tlearn: 0.0023207\ttotal: 24.8s\tremaining: 13.8s\n",
      "321:\tlearn: 0.0023207\ttotal: 24.8s\tremaining: 13.7s\n",
      "322:\tlearn: 0.0023207\ttotal: 24.9s\tremaining: 13.6s\n",
      "323:\tlearn: 0.0023207\ttotal: 24.9s\tremaining: 13.5s\n",
      "324:\tlearn: 0.0023207\ttotal: 24.9s\tremaining: 13.4s\n",
      "325:\tlearn: 0.0023052\ttotal: 24.9s\tremaining: 13.3s\n",
      "326:\tlearn: 0.0023052\ttotal: 24.9s\tremaining: 13.2s\n",
      "327:\tlearn: 0.0023052\ttotal: 25s\tremaining: 13.1s\n",
      "328:\tlearn: 0.0023052\ttotal: 25s\tremaining: 13s\n",
      "329:\tlearn: 0.0023051\ttotal: 25s\tremaining: 12.9s\n",
      "330:\tlearn: 0.0023051\ttotal: 25s\tremaining: 12.8s\n",
      "331:\tlearn: 0.0023051\ttotal: 25s\tremaining: 12.7s\n",
      "332:\tlearn: 0.0023051\ttotal: 25.1s\tremaining: 12.6s\n",
      "333:\tlearn: 0.0023051\ttotal: 25.1s\tremaining: 12.5s\n",
      "334:\tlearn: 0.0022948\ttotal: 25.1s\tremaining: 12.4s\n",
      "335:\tlearn: 0.0022948\ttotal: 25.1s\tremaining: 12.3s\n",
      "336:\tlearn: 0.0022947\ttotal: 25.2s\tremaining: 12.2s\n",
      "337:\tlearn: 0.0022947\ttotal: 25.2s\tremaining: 12.1s\n",
      "338:\tlearn: 0.0022947\ttotal: 25.2s\tremaining: 12s\n",
      "339:\tlearn: 0.0022947\ttotal: 25.2s\tremaining: 11.9s\n",
      "340:\tlearn: 0.0022870\ttotal: 25.2s\tremaining: 11.8s\n",
      "341:\tlearn: 0.0022870\ttotal: 25.3s\tremaining: 11.7s\n",
      "342:\tlearn: 0.0022870\ttotal: 25.3s\tremaining: 11.6s\n",
      "343:\tlearn: 0.0022747\ttotal: 25.3s\tremaining: 11.5s\n",
      "344:\tlearn: 0.0022712\ttotal: 25.3s\tremaining: 11.4s\n",
      "345:\tlearn: 0.0022712\ttotal: 25.3s\tremaining: 11.3s\n",
      "346:\tlearn: 0.0022712\ttotal: 25.3s\tremaining: 11.2s\n",
      "347:\tlearn: 0.0022712\ttotal: 25.4s\tremaining: 11.1s\n",
      "348:\tlearn: 0.0022711\ttotal: 25.4s\tremaining: 11s\n",
      "349:\tlearn: 0.0022711\ttotal: 25.4s\tremaining: 10.9s\n",
      "350:\tlearn: 0.0022711\ttotal: 25.4s\tremaining: 10.8s\n",
      "351:\tlearn: 0.0022711\ttotal: 25.4s\tremaining: 10.7s\n",
      "352:\tlearn: 0.0022711\ttotal: 25.4s\tremaining: 10.6s\n",
      "353:\tlearn: 0.0022711\ttotal: 25.5s\tremaining: 10.5s\n",
      "354:\tlearn: 0.0022711\ttotal: 25.5s\tremaining: 10.4s\n",
      "355:\tlearn: 0.0022643\ttotal: 25.5s\tremaining: 10.3s\n",
      "356:\tlearn: 0.0022642\ttotal: 25.5s\tremaining: 10.2s\n",
      "357:\tlearn: 0.0022642\ttotal: 25.5s\tremaining: 10.1s\n",
      "358:\tlearn: 0.0022643\ttotal: 25.5s\tremaining: 10s\n",
      "359:\tlearn: 0.0022643\ttotal: 25.6s\tremaining: 9.94s\n",
      "360:\tlearn: 0.0022642\ttotal: 25.6s\tremaining: 9.85s\n",
      "361:\tlearn: 0.0022639\ttotal: 25.6s\tremaining: 9.76s\n",
      "362:\tlearn: 0.0022639\ttotal: 25.6s\tremaining: 9.66s\n",
      "363:\tlearn: 0.0022638\ttotal: 25.6s\tremaining: 9.57s\n",
      "364:\tlearn: 0.0022639\ttotal: 25.6s\tremaining: 9.48s\n",
      "365:\tlearn: 0.0022638\ttotal: 25.7s\tremaining: 9.39s\n",
      "366:\tlearn: 0.0022638\ttotal: 25.7s\tremaining: 9.3s\n",
      "367:\tlearn: 0.0022638\ttotal: 25.7s\tremaining: 9.21s\n",
      "368:\tlearn: 0.0022637\ttotal: 25.7s\tremaining: 9.13s\n",
      "369:\tlearn: 0.0022638\ttotal: 25.7s\tremaining: 9.04s\n",
      "370:\tlearn: 0.0022637\ttotal: 25.7s\tremaining: 8.95s\n",
      "371:\tlearn: 0.0022636\ttotal: 25.8s\tremaining: 8.86s\n",
      "372:\tlearn: 0.0022636\ttotal: 25.8s\tremaining: 8.78s\n",
      "373:\tlearn: 0.0022636\ttotal: 25.8s\tremaining: 8.69s\n",
      "374:\tlearn: 0.0022393\ttotal: 25.8s\tremaining: 8.6s\n",
      "375:\tlearn: 0.0022248\ttotal: 25.8s\tremaining: 8.52s\n",
      "376:\tlearn: 0.0022248\ttotal: 25.8s\tremaining: 8.43s\n",
      "377:\tlearn: 0.0022248\ttotal: 25.9s\tremaining: 8.35s\n",
      "378:\tlearn: 0.0022247\ttotal: 25.9s\tremaining: 8.26s\n",
      "379:\tlearn: 0.0022247\ttotal: 25.9s\tremaining: 8.18s\n",
      "380:\tlearn: 0.0022247\ttotal: 25.9s\tremaining: 8.09s\n",
      "381:\tlearn: 0.0022247\ttotal: 25.9s\tremaining: 8.01s\n",
      "382:\tlearn: 0.0022247\ttotal: 25.9s\tremaining: 7.93s\n",
      "383:\tlearn: 0.0022246\ttotal: 26s\tremaining: 7.84s\n",
      "384:\tlearn: 0.0022246\ttotal: 26s\tremaining: 7.76s\n",
      "385:\tlearn: 0.0022246\ttotal: 26s\tremaining: 7.68s\n",
      "386:\tlearn: 0.0022245\ttotal: 26s\tremaining: 7.59s\n",
      "387:\tlearn: 0.0022245\ttotal: 26s\tremaining: 7.51s\n",
      "388:\tlearn: 0.0022245\ttotal: 26s\tremaining: 7.43s\n",
      "389:\tlearn: 0.0022245\ttotal: 26.1s\tremaining: 7.35s\n",
      "390:\tlearn: 0.0022245\ttotal: 26.1s\tremaining: 7.27s\n",
      "391:\tlearn: 0.0022244\ttotal: 26.1s\tremaining: 7.19s\n",
      "392:\tlearn: 0.0022244\ttotal: 26.1s\tremaining: 7.11s\n",
      "393:\tlearn: 0.0022244\ttotal: 26.1s\tremaining: 7.03s\n",
      "394:\tlearn: 0.0022244\ttotal: 26.1s\tremaining: 6.95s\n",
      "395:\tlearn: 0.0022243\ttotal: 26.2s\tremaining: 6.87s\n",
      "396:\tlearn: 0.0022243\ttotal: 26.2s\tremaining: 6.79s\n",
      "397:\tlearn: 0.0022243\ttotal: 26.2s\tremaining: 6.71s\n",
      "398:\tlearn: 0.0022243\ttotal: 26.2s\tremaining: 6.63s\n",
      "399:\tlearn: 0.0022243\ttotal: 26.2s\tremaining: 6.56s\n",
      "400:\tlearn: 0.0022118\ttotal: 26.2s\tremaining: 6.48s\n",
      "401:\tlearn: 0.0022117\ttotal: 26.3s\tremaining: 6.4s\n",
      "402:\tlearn: 0.0022117\ttotal: 26.3s\tremaining: 6.32s\n",
      "403:\tlearn: 0.0021978\ttotal: 26.3s\tremaining: 6.25s\n",
      "404:\tlearn: 0.0021978\ttotal: 26.3s\tremaining: 6.17s\n",
      "405:\tlearn: 0.0021978\ttotal: 26.3s\tremaining: 6.1s\n",
      "406:\tlearn: 0.0021962\ttotal: 26.3s\tremaining: 6.02s\n",
      "407:\tlearn: 0.0021962\ttotal: 26.4s\tremaining: 5.94s\n",
      "408:\tlearn: 0.0021962\ttotal: 26.4s\tremaining: 5.87s\n",
      "409:\tlearn: 0.0021962\ttotal: 26.4s\tremaining: 5.79s\n",
      "410:\tlearn: 0.0021962\ttotal: 26.4s\tremaining: 5.72s\n",
      "411:\tlearn: 0.0021962\ttotal: 26.4s\tremaining: 5.64s\n",
      "412:\tlearn: 0.0021962\ttotal: 26.4s\tremaining: 5.57s\n",
      "413:\tlearn: 0.0021961\ttotal: 26.5s\tremaining: 5.5s\n",
      "414:\tlearn: 0.0021961\ttotal: 26.5s\tremaining: 5.42s\n",
      "415:\tlearn: 0.0021960\ttotal: 26.5s\tremaining: 5.35s\n",
      "416:\tlearn: 0.0021960\ttotal: 26.5s\tremaining: 5.28s\n",
      "417:\tlearn: 0.0021788\ttotal: 26.5s\tremaining: 5.2s\n",
      "418:\tlearn: 0.0021788\ttotal: 26.5s\tremaining: 5.13s\n",
      "419:\tlearn: 0.0021788\ttotal: 26.6s\tremaining: 5.06s\n",
      "420:\tlearn: 0.0021788\ttotal: 26.6s\tremaining: 4.99s\n",
      "421:\tlearn: 0.0021787\ttotal: 26.6s\tremaining: 4.91s\n",
      "422:\tlearn: 0.0021787\ttotal: 26.6s\tremaining: 4.84s\n",
      "423:\tlearn: 0.0021787\ttotal: 26.6s\tremaining: 4.77s\n",
      "424:\tlearn: 0.0021787\ttotal: 26.6s\tremaining: 4.7s\n",
      "425:\tlearn: 0.0021788\ttotal: 26.7s\tremaining: 4.63s\n",
      "426:\tlearn: 0.0021760\ttotal: 26.7s\tremaining: 4.56s\n",
      "427:\tlearn: 0.0021759\ttotal: 26.7s\tremaining: 4.49s\n",
      "428:\tlearn: 0.0021759\ttotal: 26.7s\tremaining: 4.42s\n",
      "429:\tlearn: 0.0021759\ttotal: 26.7s\tremaining: 4.35s\n",
      "430:\tlearn: 0.0021759\ttotal: 26.7s\tremaining: 4.28s\n",
      "431:\tlearn: 0.0021758\ttotal: 26.8s\tremaining: 4.21s\n",
      "432:\tlearn: 0.0021758\ttotal: 26.8s\tremaining: 4.14s\n",
      "433:\tlearn: 0.0021758\ttotal: 26.8s\tremaining: 4.07s\n",
      "434:\tlearn: 0.0021758\ttotal: 26.8s\tremaining: 4s\n",
      "435:\tlearn: 0.0021758\ttotal: 26.8s\tremaining: 3.94s\n",
      "436:\tlearn: 0.0021758\ttotal: 26.8s\tremaining: 3.87s\n",
      "437:\tlearn: 0.0021757\ttotal: 26.8s\tremaining: 3.8s\n",
      "438:\tlearn: 0.0021757\ttotal: 26.9s\tremaining: 3.73s\n",
      "439:\tlearn: 0.0021694\ttotal: 26.9s\tremaining: 3.67s\n",
      "440:\tlearn: 0.0021693\ttotal: 26.9s\tremaining: 3.6s\n",
      "441:\tlearn: 0.0021693\ttotal: 26.9s\tremaining: 3.53s\n",
      "442:\tlearn: 0.0021693\ttotal: 26.9s\tremaining: 3.46s\n",
      "443:\tlearn: 0.0021693\ttotal: 26.9s\tremaining: 3.4s\n",
      "444:\tlearn: 0.0021693\ttotal: 27s\tremaining: 3.33s\n",
      "445:\tlearn: 0.0021693\ttotal: 27s\tremaining: 3.27s\n",
      "446:\tlearn: 0.0021693\ttotal: 27s\tremaining: 3.2s\n",
      "447:\tlearn: 0.0021634\ttotal: 27s\tremaining: 3.13s\n",
      "448:\tlearn: 0.0021437\ttotal: 27s\tremaining: 3.07s\n",
      "449:\tlearn: 0.0021437\ttotal: 27s\tremaining: 3s\n",
      "450:\tlearn: 0.0021437\ttotal: 27.1s\tremaining: 2.94s\n",
      "451:\tlearn: 0.0021438\ttotal: 27.1s\tremaining: 2.87s\n",
      "452:\tlearn: 0.0021438\ttotal: 27.1s\tremaining: 2.81s\n",
      "453:\tlearn: 0.0021438\ttotal: 27.1s\tremaining: 2.75s\n",
      "454:\tlearn: 0.0021437\ttotal: 27.1s\tremaining: 2.68s\n",
      "455:\tlearn: 0.0021436\ttotal: 27.1s\tremaining: 2.62s\n",
      "456:\tlearn: 0.0021436\ttotal: 27.2s\tremaining: 2.56s\n",
      "457:\tlearn: 0.0021358\ttotal: 27.2s\tremaining: 2.49s\n",
      "458:\tlearn: 0.0021357\ttotal: 27.2s\tremaining: 2.43s\n",
      "459:\tlearn: 0.0021358\ttotal: 27.2s\tremaining: 2.37s\n",
      "460:\tlearn: 0.0021355\ttotal: 27.2s\tremaining: 2.3s\n",
      "461:\tlearn: 0.0021355\ttotal: 27.2s\tremaining: 2.24s\n",
      "462:\tlearn: 0.0021355\ttotal: 27.3s\tremaining: 2.18s\n",
      "463:\tlearn: 0.0021355\ttotal: 27.3s\tremaining: 2.12s\n",
      "464:\tlearn: 0.0021354\ttotal: 27.3s\tremaining: 2.05s\n",
      "465:\tlearn: 0.0021354\ttotal: 27.3s\tremaining: 1.99s\n",
      "466:\tlearn: 0.0021354\ttotal: 27.3s\tremaining: 1.93s\n",
      "467:\tlearn: 0.0021354\ttotal: 27.3s\tremaining: 1.87s\n",
      "468:\tlearn: 0.0021354\ttotal: 27.4s\tremaining: 1.81s\n",
      "469:\tlearn: 0.0021353\ttotal: 27.4s\tremaining: 1.75s\n",
      "470:\tlearn: 0.0021353\ttotal: 27.4s\tremaining: 1.69s\n",
      "471:\tlearn: 0.0021353\ttotal: 27.4s\tremaining: 1.63s\n",
      "472:\tlearn: 0.0021353\ttotal: 27.4s\tremaining: 1.56s\n",
      "473:\tlearn: 0.0021352\ttotal: 27.4s\tremaining: 1.5s\n",
      "474:\tlearn: 0.0021352\ttotal: 27.4s\tremaining: 1.44s\n",
      "475:\tlearn: 0.0021352\ttotal: 27.5s\tremaining: 1.38s\n",
      "476:\tlearn: 0.0021352\ttotal: 27.5s\tremaining: 1.32s\n",
      "477:\tlearn: 0.0021351\ttotal: 27.5s\tremaining: 1.26s\n",
      "478:\tlearn: 0.0021352\ttotal: 27.5s\tremaining: 1.21s\n",
      "479:\tlearn: 0.0021352\ttotal: 27.5s\tremaining: 1.15s\n",
      "480:\tlearn: 0.0021205\ttotal: 27.5s\tremaining: 1.09s\n",
      "481:\tlearn: 0.0021204\ttotal: 27.6s\tremaining: 1.03s\n",
      "482:\tlearn: 0.0021204\ttotal: 27.6s\tremaining: 971ms\n",
      "483:\tlearn: 0.0021027\ttotal: 27.6s\tremaining: 912ms\n",
      "484:\tlearn: 0.0021027\ttotal: 27.6s\tremaining: 854ms\n",
      "485:\tlearn: 0.0021027\ttotal: 27.6s\tremaining: 796ms\n",
      "486:\tlearn: 0.0021026\ttotal: 27.6s\tremaining: 738ms\n",
      "487:\tlearn: 0.0021026\ttotal: 27.7s\tremaining: 680ms\n",
      "488:\tlearn: 0.0021026\ttotal: 27.7s\tremaining: 622ms\n",
      "489:\tlearn: 0.0021026\ttotal: 27.7s\tremaining: 565ms\n",
      "490:\tlearn: 0.0021026\ttotal: 27.7s\tremaining: 508ms\n",
      "491:\tlearn: 0.0021026\ttotal: 27.7s\tremaining: 451ms\n",
      "492:\tlearn: 0.0021026\ttotal: 27.7s\tremaining: 394ms\n",
      "493:\tlearn: 0.0021026\ttotal: 27.8s\tremaining: 337ms\n",
      "494:\tlearn: 0.0021026\ttotal: 27.8s\tremaining: 280ms\n",
      "495:\tlearn: 0.0021026\ttotal: 27.8s\tremaining: 224ms\n",
      "496:\tlearn: 0.0021025\ttotal: 27.8s\tremaining: 168ms\n",
      "497:\tlearn: 0.0021025\ttotal: 27.8s\tremaining: 112ms\n",
      "498:\tlearn: 0.0021025\ttotal: 27.8s\tremaining: 55.8ms\n",
      "499:\tlearn: 0.0021025\ttotal: 27.8s\tremaining: 0us\n",
      "0:\tlearn: 0.6446859\ttotal: 16.7ms\tremaining: 8.33s\n",
      "1:\tlearn: 0.6066409\ttotal: 33.6ms\tremaining: 8.36s\n",
      "2:\tlearn: 0.5725362\ttotal: 50.1ms\tremaining: 8.3s\n",
      "3:\tlearn: 0.5387799\ttotal: 67.1ms\tremaining: 8.31s\n",
      "4:\tlearn: 0.4991350\ttotal: 84.2ms\tremaining: 8.34s\n",
      "5:\tlearn: 0.4710460\ttotal: 101ms\tremaining: 8.32s\n",
      "6:\tlearn: 0.4413266\ttotal: 119ms\tremaining: 8.37s\n",
      "7:\tlearn: 0.4245620\ttotal: 135ms\tremaining: 8.32s\n",
      "8:\tlearn: 0.4062397\ttotal: 152ms\tremaining: 8.32s\n",
      "9:\tlearn: 0.3863092\ttotal: 169ms\tremaining: 8.3s\n",
      "10:\tlearn: 0.3702369\ttotal: 186ms\tremaining: 8.27s\n",
      "11:\tlearn: 0.3535585\ttotal: 202ms\tremaining: 8.23s\n",
      "12:\tlearn: 0.3400699\ttotal: 222ms\tremaining: 8.32s\n",
      "13:\tlearn: 0.3242779\ttotal: 239ms\tremaining: 8.28s\n",
      "14:\tlearn: 0.3002506\ttotal: 256ms\tremaining: 8.26s\n",
      "15:\tlearn: 0.2831270\ttotal: 275ms\tremaining: 8.32s\n",
      "16:\tlearn: 0.2711636\ttotal: 300ms\tremaining: 8.52s\n",
      "17:\tlearn: 0.2574821\ttotal: 325ms\tremaining: 8.71s\n",
      "18:\tlearn: 0.2469400\ttotal: 352ms\tremaining: 8.91s\n",
      "19:\tlearn: 0.2353547\ttotal: 393ms\tremaining: 9.44s\n",
      "20:\tlearn: 0.2238291\ttotal: 437ms\tremaining: 9.98s\n",
      "21:\tlearn: 0.2171809\ttotal: 513ms\tremaining: 11.2s\n",
      "22:\tlearn: 0.2090634\ttotal: 563ms\tremaining: 11.7s\n",
      "23:\tlearn: 0.2000173\ttotal: 640ms\tremaining: 12.7s\n",
      "24:\tlearn: 0.1929056\ttotal: 705ms\tremaining: 13.4s\n",
      "25:\tlearn: 0.1860397\ttotal: 753ms\tremaining: 13.7s\n",
      "26:\tlearn: 0.1765934\ttotal: 865ms\tremaining: 15.2s\n",
      "27:\tlearn: 0.1707668\ttotal: 910ms\tremaining: 15.3s\n",
      "28:\tlearn: 0.1621550\ttotal: 1.03s\tremaining: 16.7s\n",
      "29:\tlearn: 0.1561009\ttotal: 1.08s\tremaining: 16.9s\n",
      "30:\tlearn: 0.1490604\ttotal: 1.2s\tremaining: 18.1s\n",
      "31:\tlearn: 0.1445935\ttotal: 1.25s\tremaining: 18.3s\n",
      "32:\tlearn: 0.1394094\ttotal: 1.29s\tremaining: 18.2s\n",
      "33:\tlearn: 0.1337309\ttotal: 1.38s\tremaining: 18.9s\n",
      "34:\tlearn: 0.1286718\ttotal: 1.43s\tremaining: 19s\n",
      "35:\tlearn: 0.1234735\ttotal: 1.54s\tremaining: 19.9s\n",
      "36:\tlearn: 0.1205902\ttotal: 1.59s\tremaining: 19.9s\n",
      "37:\tlearn: 0.1152160\ttotal: 1.71s\tremaining: 20.8s\n",
      "38:\tlearn: 0.1113209\ttotal: 1.75s\tremaining: 20.8s\n",
      "39:\tlearn: 0.1067060\ttotal: 1.85s\tremaining: 21.3s\n",
      "40:\tlearn: 0.1026450\ttotal: 1.92s\tremaining: 21.5s\n",
      "41:\tlearn: 0.0975302\ttotal: 1.96s\tremaining: 21.4s\n",
      "42:\tlearn: 0.0939410\ttotal: 2.05s\tremaining: 21.8s\n",
      "43:\tlearn: 0.0915678\ttotal: 2.09s\tremaining: 21.7s\n",
      "44:\tlearn: 0.0894580\ttotal: 2.2s\tremaining: 22.2s\n",
      "45:\tlearn: 0.0859141\ttotal: 2.24s\tremaining: 22.1s\n",
      "46:\tlearn: 0.0829112\ttotal: 2.34s\tremaining: 22.6s\n",
      "47:\tlearn: 0.0801490\ttotal: 2.4s\tremaining: 22.6s\n",
      "48:\tlearn: 0.0770155\ttotal: 2.44s\tremaining: 22.5s\n",
      "49:\tlearn: 0.0746316\ttotal: 2.55s\tremaining: 23s\n",
      "50:\tlearn: 0.0712191\ttotal: 2.6s\tremaining: 22.9s\n",
      "51:\tlearn: 0.0693280\ttotal: 2.72s\tremaining: 23.5s\n",
      "52:\tlearn: 0.0677879\ttotal: 2.77s\tremaining: 23.4s\n",
      "53:\tlearn: 0.0658481\ttotal: 2.89s\tremaining: 23.9s\n",
      "54:\tlearn: 0.0631683\ttotal: 2.94s\tremaining: 23.8s\n",
      "55:\tlearn: 0.0615842\ttotal: 3.03s\tremaining: 24s\n",
      "56:\tlearn: 0.0603693\ttotal: 3.11s\tremaining: 24.2s\n",
      "57:\tlearn: 0.0579828\ttotal: 3.16s\tremaining: 24.1s\n",
      "58:\tlearn: 0.0554872\ttotal: 3.25s\tremaining: 24.3s\n",
      "59:\tlearn: 0.0538387\ttotal: 3.3s\tremaining: 24.2s\n",
      "60:\tlearn: 0.0523567\ttotal: 3.39s\tremaining: 24.4s\n",
      "61:\tlearn: 0.0506737\ttotal: 3.43s\tremaining: 24.2s\n",
      "62:\tlearn: 0.0492328\ttotal: 3.52s\tremaining: 24.4s\n",
      "63:\tlearn: 0.0474407\ttotal: 3.61s\tremaining: 24.6s\n",
      "64:\tlearn: 0.0458493\ttotal: 3.68s\tremaining: 24.6s\n",
      "65:\tlearn: 0.0448455\ttotal: 3.72s\tremaining: 24.5s\n",
      "66:\tlearn: 0.0434493\ttotal: 3.84s\tremaining: 24.8s\n",
      "67:\tlearn: 0.0417659\ttotal: 3.89s\tremaining: 24.7s\n",
      "68:\tlearn: 0.0411359\ttotal: 4s\tremaining: 25s\n",
      "69:\tlearn: 0.0401928\ttotal: 4.06s\tremaining: 24.9s\n",
      "70:\tlearn: 0.0389927\ttotal: 4.15s\tremaining: 25.1s\n",
      "71:\tlearn: 0.0378941\ttotal: 4.22s\tremaining: 25.1s\n",
      "72:\tlearn: 0.0370876\ttotal: 4.27s\tremaining: 25s\n",
      "73:\tlearn: 0.0362630\ttotal: 4.38s\tremaining: 25.2s\n",
      "74:\tlearn: 0.0356347\ttotal: 4.42s\tremaining: 25.1s\n",
      "75:\tlearn: 0.0346372\ttotal: 4.54s\tremaining: 25.3s\n",
      "76:\tlearn: 0.0335535\ttotal: 4.59s\tremaining: 25.2s\n",
      "77:\tlearn: 0.0325283\ttotal: 4.68s\tremaining: 25.3s\n",
      "78:\tlearn: 0.0316306\ttotal: 4.76s\tremaining: 25.4s\n",
      "79:\tlearn: 0.0306469\ttotal: 4.8s\tremaining: 25.2s\n",
      "80:\tlearn: 0.0299128\ttotal: 4.92s\tremaining: 25.4s\n",
      "81:\tlearn: 0.0289919\ttotal: 4.96s\tremaining: 25.3s\n",
      "82:\tlearn: 0.0281112\ttotal: 5.07s\tremaining: 25.5s\n",
      "83:\tlearn: 0.0272539\ttotal: 5.13s\tremaining: 25.4s\n",
      "84:\tlearn: 0.0266545\ttotal: 5.22s\tremaining: 25.5s\n",
      "85:\tlearn: 0.0261836\ttotal: 5.3s\tremaining: 25.5s\n",
      "86:\tlearn: 0.0257413\ttotal: 5.39s\tremaining: 25.6s\n",
      "87:\tlearn: 0.0249651\ttotal: 5.47s\tremaining: 25.6s\n",
      "88:\tlearn: 0.0243806\ttotal: 5.51s\tremaining: 25.4s\n",
      "89:\tlearn: 0.0235876\ttotal: 5.6s\tremaining: 25.5s\n",
      "90:\tlearn: 0.0229560\ttotal: 5.66s\tremaining: 25.4s\n",
      "91:\tlearn: 0.0222737\ttotal: 5.75s\tremaining: 25.5s\n",
      "92:\tlearn: 0.0218605\ttotal: 5.83s\tremaining: 25.5s\n",
      "93:\tlearn: 0.0214391\ttotal: 5.87s\tremaining: 25.4s\n",
      "94:\tlearn: 0.0209836\ttotal: 5.99s\tremaining: 25.5s\n",
      "95:\tlearn: 0.0203315\ttotal: 6.04s\tremaining: 25.4s\n",
      "96:\tlearn: 0.0199149\ttotal: 6.13s\tremaining: 25.5s\n",
      "97:\tlearn: 0.0192829\ttotal: 6.2s\tremaining: 25.4s\n",
      "98:\tlearn: 0.0186473\ttotal: 6.25s\tremaining: 25.3s\n",
      "99:\tlearn: 0.0182171\ttotal: 6.36s\tremaining: 25.4s\n",
      "100:\tlearn: 0.0175146\ttotal: 6.41s\tremaining: 25.3s\n",
      "101:\tlearn: 0.0171878\ttotal: 6.53s\tremaining: 25.5s\n",
      "102:\tlearn: 0.0167423\ttotal: 6.57s\tremaining: 25.3s\n",
      "103:\tlearn: 0.0163392\ttotal: 6.69s\tremaining: 25.5s\n",
      "104:\tlearn: 0.0160380\ttotal: 6.75s\tremaining: 25.4s\n",
      "105:\tlearn: 0.0155479\ttotal: 6.84s\tremaining: 25.4s\n",
      "106:\tlearn: 0.0150523\ttotal: 6.9s\tremaining: 25.3s\n",
      "107:\tlearn: 0.0146743\ttotal: 7.04s\tremaining: 25.6s\n",
      "108:\tlearn: 0.0143696\ttotal: 7.08s\tremaining: 25.4s\n",
      "109:\tlearn: 0.0140303\ttotal: 7.18s\tremaining: 25.5s\n",
      "110:\tlearn: 0.0137334\ttotal: 7.22s\tremaining: 25.3s\n",
      "111:\tlearn: 0.0134404\ttotal: 7.32s\tremaining: 25.3s\n",
      "112:\tlearn: 0.0131673\ttotal: 7.36s\tremaining: 25.2s\n",
      "113:\tlearn: 0.0128713\ttotal: 7.44s\tremaining: 25.2s\n",
      "114:\tlearn: 0.0126582\ttotal: 7.48s\tremaining: 25s\n",
      "115:\tlearn: 0.0124261\ttotal: 7.6s\tremaining: 25.1s\n",
      "116:\tlearn: 0.0122290\ttotal: 7.64s\tremaining: 25s\n",
      "117:\tlearn: 0.0120473\ttotal: 7.77s\tremaining: 25.1s\n",
      "118:\tlearn: 0.0118662\ttotal: 7.81s\tremaining: 25s\n",
      "119:\tlearn: 0.0115417\ttotal: 7.93s\tremaining: 25.1s\n",
      "120:\tlearn: 0.0112547\ttotal: 7.98s\tremaining: 25s\n",
      "121:\tlearn: 0.0110348\ttotal: 8.02s\tremaining: 24.9s\n",
      "122:\tlearn: 0.0108115\ttotal: 8.13s\tremaining: 24.9s\n",
      "123:\tlearn: 0.0106016\ttotal: 8.18s\tremaining: 24.8s\n",
      "124:\tlearn: 0.0103503\ttotal: 8.28s\tremaining: 24.9s\n",
      "125:\tlearn: 0.0101732\ttotal: 8.34s\tremaining: 24.8s\n",
      "126:\tlearn: 0.0099900\ttotal: 8.38s\tremaining: 24.6s\n",
      "127:\tlearn: 0.0097593\ttotal: 8.49s\tremaining: 24.7s\n",
      "128:\tlearn: 0.0095891\ttotal: 8.55s\tremaining: 24.6s\n",
      "129:\tlearn: 0.0094429\ttotal: 8.66s\tremaining: 24.7s\n",
      "130:\tlearn: 0.0092692\ttotal: 8.71s\tremaining: 24.5s\n",
      "131:\tlearn: 0.0091057\ttotal: 8.8s\tremaining: 24.5s\n",
      "132:\tlearn: 0.0089557\ttotal: 8.88s\tremaining: 24.5s\n",
      "133:\tlearn: 0.0088483\ttotal: 8.92s\tremaining: 24.4s\n",
      "134:\tlearn: 0.0087253\ttotal: 9.04s\tremaining: 24.4s\n",
      "135:\tlearn: 0.0085424\ttotal: 9.08s\tremaining: 24.3s\n",
      "136:\tlearn: 0.0084192\ttotal: 9.15s\tremaining: 24.2s\n",
      "137:\tlearn: 0.0082898\ttotal: 9.21s\tremaining: 24.2s\n",
      "138:\tlearn: 0.0081703\ttotal: 9.28s\tremaining: 24.1s\n",
      "139:\tlearn: 0.0080275\ttotal: 9.38s\tremaining: 24.1s\n",
      "140:\tlearn: 0.0079230\ttotal: 9.42s\tremaining: 24s\n",
      "141:\tlearn: 0.0078115\ttotal: 9.53s\tremaining: 24s\n",
      "142:\tlearn: 0.0077207\ttotal: 9.57s\tremaining: 23.9s\n",
      "143:\tlearn: 0.0076086\ttotal: 9.69s\tremaining: 23.9s\n",
      "144:\tlearn: 0.0074995\ttotal: 9.73s\tremaining: 23.8s\n",
      "145:\tlearn: 0.0073847\ttotal: 9.84s\tremaining: 23.9s\n",
      "146:\tlearn: 0.0073032\ttotal: 9.9s\tremaining: 23.8s\n",
      "147:\tlearn: 0.0071234\ttotal: 9.96s\tremaining: 23.7s\n",
      "148:\tlearn: 0.0069945\ttotal: 10.1s\tremaining: 23.7s\n",
      "149:\tlearn: 0.0069164\ttotal: 10.1s\tremaining: 23.6s\n",
      "150:\tlearn: 0.0068009\ttotal: 10.2s\tremaining: 23.6s\n",
      "151:\tlearn: 0.0066898\ttotal: 10.2s\tremaining: 23.5s\n",
      "152:\tlearn: 0.0065605\ttotal: 10.4s\tremaining: 23.5s\n",
      "153:\tlearn: 0.0064819\ttotal: 10.4s\tremaining: 23.4s\n",
      "154:\tlearn: 0.0063991\ttotal: 10.5s\tremaining: 23.4s\n",
      "155:\tlearn: 0.0062880\ttotal: 10.6s\tremaining: 23.3s\n",
      "156:\tlearn: 0.0061929\ttotal: 10.7s\tremaining: 23.4s\n",
      "157:\tlearn: 0.0061333\ttotal: 10.7s\tremaining: 23.3s\n",
      "158:\tlearn: 0.0060554\ttotal: 10.9s\tremaining: 23.3s\n",
      "159:\tlearn: 0.0059852\ttotal: 10.9s\tremaining: 23.2s\n",
      "160:\tlearn: 0.0059075\ttotal: 11s\tremaining: 23.2s\n",
      "161:\tlearn: 0.0058554\ttotal: 11.1s\tremaining: 23.1s\n",
      "162:\tlearn: 0.0057509\ttotal: 11.2s\tremaining: 23.1s\n",
      "163:\tlearn: 0.0056817\ttotal: 11.3s\tremaining: 23.1s\n",
      "164:\tlearn: 0.0056105\ttotal: 11.3s\tremaining: 22.9s\n",
      "165:\tlearn: 0.0055289\ttotal: 11.4s\tremaining: 22.9s\n",
      "166:\tlearn: 0.0054519\ttotal: 11.4s\tremaining: 22.8s\n",
      "167:\tlearn: 0.0053989\ttotal: 11.5s\tremaining: 22.8s\n",
      "168:\tlearn: 0.0053480\ttotal: 11.6s\tremaining: 22.7s\n",
      "169:\tlearn: 0.0052821\ttotal: 11.6s\tremaining: 22.6s\n",
      "170:\tlearn: 0.0052365\ttotal: 11.8s\tremaining: 22.6s\n",
      "171:\tlearn: 0.0051582\ttotal: 11.8s\tremaining: 22.5s\n",
      "172:\tlearn: 0.0051043\ttotal: 11.9s\tremaining: 22.5s\n",
      "173:\tlearn: 0.0050427\ttotal: 12s\tremaining: 22.4s\n",
      "174:\tlearn: 0.0049998\ttotal: 12.1s\tremaining: 22.4s\n",
      "175:\tlearn: 0.0049393\ttotal: 12.2s\tremaining: 22.4s\n",
      "176:\tlearn: 0.0048721\ttotal: 12.2s\tremaining: 22.3s\n",
      "177:\tlearn: 0.0047936\ttotal: 12.3s\tremaining: 22.3s\n",
      "178:\tlearn: 0.0047318\ttotal: 12.4s\tremaining: 22.2s\n",
      "179:\tlearn: 0.0046696\ttotal: 12.4s\tremaining: 22.1s\n",
      "180:\tlearn: 0.0045864\ttotal: 12.6s\tremaining: 22.1s\n",
      "181:\tlearn: 0.0045286\ttotal: 12.6s\tremaining: 22s\n",
      "182:\tlearn: 0.0044612\ttotal: 12.7s\tremaining: 22s\n",
      "183:\tlearn: 0.0043730\ttotal: 12.8s\tremaining: 21.9s\n",
      "184:\tlearn: 0.0043335\ttotal: 12.9s\tremaining: 21.9s\n",
      "185:\tlearn: 0.0042800\ttotal: 12.9s\tremaining: 21.8s\n",
      "186:\tlearn: 0.0042359\ttotal: 13s\tremaining: 21.8s\n",
      "187:\tlearn: 0.0041876\ttotal: 13.1s\tremaining: 21.7s\n",
      "188:\tlearn: 0.0041523\ttotal: 13.1s\tremaining: 21.6s\n",
      "189:\tlearn: 0.0041064\ttotal: 13.2s\tremaining: 21.6s\n",
      "190:\tlearn: 0.0040683\ttotal: 13.3s\tremaining: 21.5s\n",
      "191:\tlearn: 0.0040259\ttotal: 13.4s\tremaining: 21.5s\n",
      "192:\tlearn: 0.0039712\ttotal: 13.4s\tremaining: 21.4s\n",
      "193:\tlearn: 0.0039286\ttotal: 13.6s\tremaining: 21.4s\n",
      "194:\tlearn: 0.0038834\ttotal: 13.6s\tremaining: 21.3s\n",
      "195:\tlearn: 0.0038456\ttotal: 13.7s\tremaining: 21.2s\n",
      "196:\tlearn: 0.0038069\ttotal: 13.7s\tremaining: 21.1s\n",
      "197:\tlearn: 0.0037840\ttotal: 13.9s\tremaining: 21.1s\n",
      "198:\tlearn: 0.0037466\ttotal: 13.9s\tremaining: 21s\n",
      "199:\tlearn: 0.0037189\ttotal: 14s\tremaining: 21s\n",
      "200:\tlearn: 0.0036805\ttotal: 14.1s\tremaining: 20.9s\n",
      "201:\tlearn: 0.0036397\ttotal: 14.1s\tremaining: 20.8s\n",
      "202:\tlearn: 0.0036021\ttotal: 14.2s\tremaining: 20.8s\n",
      "203:\tlearn: 0.0035752\ttotal: 14.3s\tremaining: 20.7s\n",
      "204:\tlearn: 0.0035393\ttotal: 14.4s\tremaining: 20.7s\n",
      "205:\tlearn: 0.0035093\ttotal: 14.4s\tremaining: 20.6s\n",
      "206:\tlearn: 0.0034680\ttotal: 14.5s\tremaining: 20.6s\n",
      "207:\tlearn: 0.0034357\ttotal: 14.6s\tremaining: 20.5s\n",
      "208:\tlearn: 0.0034111\ttotal: 14.6s\tremaining: 20.4s\n",
      "209:\tlearn: 0.0033895\ttotal: 14.8s\tremaining: 20.4s\n",
      "210:\tlearn: 0.0033460\ttotal: 14.8s\tremaining: 20.3s\n",
      "211:\tlearn: 0.0033123\ttotal: 14.9s\tremaining: 20.2s\n",
      "212:\tlearn: 0.0032891\ttotal: 15s\tremaining: 20.2s\n",
      "213:\tlearn: 0.0032521\ttotal: 15s\tremaining: 20.1s\n",
      "214:\tlearn: 0.0032162\ttotal: 15.1s\tremaining: 20s\n",
      "215:\tlearn: 0.0031895\ttotal: 15.2s\tremaining: 19.9s\n",
      "216:\tlearn: 0.0031620\ttotal: 15.3s\tremaining: 19.9s\n",
      "217:\tlearn: 0.0031419\ttotal: 15.3s\tremaining: 19.8s\n",
      "218:\tlearn: 0.0031202\ttotal: 15.4s\tremaining: 19.7s\n",
      "219:\tlearn: 0.0030992\ttotal: 15.5s\tremaining: 19.7s\n",
      "220:\tlearn: 0.0030655\ttotal: 15.5s\tremaining: 19.6s\n",
      "221:\tlearn: 0.0030408\ttotal: 15.6s\tremaining: 19.6s\n",
      "222:\tlearn: 0.0030123\ttotal: 15.7s\tremaining: 19.5s\n",
      "223:\tlearn: 0.0029822\ttotal: 15.8s\tremaining: 19.4s\n",
      "224:\tlearn: 0.0029584\ttotal: 15.8s\tremaining: 19.3s\n",
      "225:\tlearn: 0.0029259\ttotal: 15.9s\tremaining: 19.2s\n",
      "226:\tlearn: 0.0028975\ttotal: 16s\tremaining: 19.2s\n",
      "227:\tlearn: 0.0028675\ttotal: 16s\tremaining: 19.1s\n",
      "228:\tlearn: 0.0028448\ttotal: 16.1s\tremaining: 19.1s\n",
      "229:\tlearn: 0.0028165\ttotal: 16.2s\tremaining: 19s\n",
      "230:\tlearn: 0.0028165\ttotal: 16.3s\tremaining: 19s\n",
      "231:\tlearn: 0.0028165\ttotal: 16.3s\tremaining: 18.9s\n",
      "232:\tlearn: 0.0027889\ttotal: 16.4s\tremaining: 18.8s\n",
      "233:\tlearn: 0.0027667\ttotal: 16.5s\tremaining: 18.7s\n",
      "234:\tlearn: 0.0027666\ttotal: 16.5s\tremaining: 18.6s\n",
      "235:\tlearn: 0.0027666\ttotal: 16.6s\tremaining: 18.6s\n",
      "236:\tlearn: 0.0027665\ttotal: 16.7s\tremaining: 18.5s\n",
      "237:\tlearn: 0.0027666\ttotal: 16.8s\tremaining: 18.5s\n",
      "238:\tlearn: 0.0027324\ttotal: 16.8s\tremaining: 18.4s\n",
      "239:\tlearn: 0.0027324\ttotal: 16.9s\tremaining: 18.3s\n",
      "240:\tlearn: 0.0027129\ttotal: 17s\tremaining: 18.2s\n",
      "241:\tlearn: 0.0026870\ttotal: 17.1s\tremaining: 18.2s\n",
      "242:\tlearn: 0.0026744\ttotal: 17.1s\tremaining: 18.1s\n",
      "243:\tlearn: 0.0026744\ttotal: 17.3s\tremaining: 18.1s\n",
      "244:\tlearn: 0.0026744\ttotal: 17.3s\tremaining: 18s\n",
      "245:\tlearn: 0.0026744\ttotal: 17.4s\tremaining: 18s\n",
      "246:\tlearn: 0.0026744\ttotal: 17.5s\tremaining: 17.9s\n",
      "247:\tlearn: 0.0026743\ttotal: 17.6s\tremaining: 17.9s\n",
      "248:\tlearn: 0.0026536\ttotal: 17.7s\tremaining: 17.8s\n",
      "249:\tlearn: 0.0026336\ttotal: 17.7s\tremaining: 17.7s\n",
      "250:\tlearn: 0.0026142\ttotal: 17.8s\tremaining: 17.7s\n",
      "251:\tlearn: 0.0026141\ttotal: 17.9s\tremaining: 17.6s\n",
      "252:\tlearn: 0.0025923\ttotal: 18s\tremaining: 17.5s\n",
      "253:\tlearn: 0.0025801\ttotal: 18s\tremaining: 17.5s\n",
      "254:\tlearn: 0.0025614\ttotal: 18.1s\tremaining: 17.4s\n",
      "255:\tlearn: 0.0025374\ttotal: 18.2s\tremaining: 17.3s\n",
      "256:\tlearn: 0.0025165\ttotal: 18.2s\tremaining: 17.2s\n",
      "257:\tlearn: 0.0025005\ttotal: 18.3s\tremaining: 17.2s\n",
      "258:\tlearn: 0.0025004\ttotal: 18.4s\tremaining: 17.1s\n",
      "259:\tlearn: 0.0024840\ttotal: 18.5s\tremaining: 17.1s\n",
      "260:\tlearn: 0.0024520\ttotal: 18.5s\tremaining: 17s\n",
      "261:\tlearn: 0.0024306\ttotal: 18.6s\tremaining: 16.9s\n",
      "262:\tlearn: 0.0024132\ttotal: 18.7s\tremaining: 16.9s\n",
      "263:\tlearn: 0.0023933\ttotal: 18.7s\tremaining: 16.8s\n",
      "264:\tlearn: 0.0023933\ttotal: 18.9s\tremaining: 16.7s\n",
      "265:\tlearn: 0.0023933\ttotal: 18.9s\tremaining: 16.6s\n",
      "266:\tlearn: 0.0023933\ttotal: 19s\tremaining: 16.6s\n",
      "267:\tlearn: 0.0023933\ttotal: 19.1s\tremaining: 16.5s\n",
      "268:\tlearn: 0.0023932\ttotal: 19.1s\tremaining: 16.4s\n",
      "269:\tlearn: 0.0023732\ttotal: 19.2s\tremaining: 16.4s\n",
      "270:\tlearn: 0.0023549\ttotal: 19.3s\tremaining: 16.3s\n",
      "271:\tlearn: 0.0023549\ttotal: 19.4s\tremaining: 16.2s\n",
      "272:\tlearn: 0.0023548\ttotal: 19.4s\tremaining: 16.2s\n",
      "273:\tlearn: 0.0023548\ttotal: 19.5s\tremaining: 16.1s\n",
      "274:\tlearn: 0.0023548\ttotal: 19.6s\tremaining: 16s\n",
      "275:\tlearn: 0.0023548\ttotal: 19.6s\tremaining: 15.9s\n",
      "276:\tlearn: 0.0023548\ttotal: 19.7s\tremaining: 15.8s\n",
      "277:\tlearn: 0.0023547\ttotal: 19.8s\tremaining: 15.8s\n",
      "278:\tlearn: 0.0023547\ttotal: 19.8s\tremaining: 15.7s\n",
      "279:\tlearn: 0.0023546\ttotal: 20s\tremaining: 15.7s\n",
      "280:\tlearn: 0.0023546\ttotal: 20s\tremaining: 15.6s\n",
      "281:\tlearn: 0.0023545\ttotal: 20.1s\tremaining: 15.5s\n",
      "282:\tlearn: 0.0023545\ttotal: 20.2s\tremaining: 15.5s\n",
      "283:\tlearn: 0.0023373\ttotal: 20.2s\tremaining: 15.4s\n",
      "284:\tlearn: 0.0023372\ttotal: 20.3s\tremaining: 15.3s\n",
      "285:\tlearn: 0.0023181\ttotal: 20.4s\tremaining: 15.2s\n",
      "286:\tlearn: 0.0023181\ttotal: 20.5s\tremaining: 15.2s\n",
      "287:\tlearn: 0.0022997\ttotal: 20.5s\tremaining: 15.1s\n",
      "288:\tlearn: 0.0022824\ttotal: 20.6s\tremaining: 15.1s\n",
      "289:\tlearn: 0.0022824\ttotal: 20.7s\tremaining: 15s\n",
      "290:\tlearn: 0.0022824\ttotal: 20.8s\tremaining: 14.9s\n",
      "291:\tlearn: 0.0022824\ttotal: 20.8s\tremaining: 14.8s\n",
      "292:\tlearn: 0.0022824\ttotal: 20.9s\tremaining: 14.8s\n",
      "293:\tlearn: 0.0022823\ttotal: 20.9s\tremaining: 14.7s\n",
      "294:\tlearn: 0.0022637\ttotal: 21s\tremaining: 14.6s\n",
      "295:\tlearn: 0.0022467\ttotal: 21.1s\tremaining: 14.5s\n",
      "296:\tlearn: 0.0022467\ttotal: 21.1s\tremaining: 14.5s\n",
      "297:\tlearn: 0.0022467\ttotal: 21.3s\tremaining: 14.4s\n",
      "298:\tlearn: 0.0022336\ttotal: 21.3s\tremaining: 14.3s\n",
      "299:\tlearn: 0.0022336\ttotal: 21.4s\tremaining: 14.3s\n",
      "300:\tlearn: 0.0022336\ttotal: 21.5s\tremaining: 14.2s\n",
      "301:\tlearn: 0.0022188\ttotal: 21.6s\tremaining: 14.1s\n",
      "302:\tlearn: 0.0022030\ttotal: 21.6s\tremaining: 14.1s\n",
      "303:\tlearn: 0.0022030\ttotal: 21.7s\tremaining: 14s\n",
      "304:\tlearn: 0.0022030\ttotal: 21.8s\tremaining: 13.9s\n",
      "305:\tlearn: 0.0022030\ttotal: 21.8s\tremaining: 13.8s\n",
      "306:\tlearn: 0.0022029\ttotal: 21.9s\tremaining: 13.8s\n",
      "307:\tlearn: 0.0021887\ttotal: 22s\tremaining: 13.7s\n",
      "308:\tlearn: 0.0021668\ttotal: 22.1s\tremaining: 13.6s\n",
      "309:\tlearn: 0.0021519\ttotal: 22.1s\tremaining: 13.6s\n",
      "310:\tlearn: 0.0021519\ttotal: 22.2s\tremaining: 13.5s\n",
      "311:\tlearn: 0.0021336\ttotal: 22.3s\tremaining: 13.4s\n",
      "312:\tlearn: 0.0021335\ttotal: 22.3s\tremaining: 13.3s\n",
      "313:\tlearn: 0.0021335\ttotal: 22.4s\tremaining: 13.3s\n",
      "314:\tlearn: 0.0021336\ttotal: 22.5s\tremaining: 13.2s\n",
      "315:\tlearn: 0.0021335\ttotal: 22.6s\tremaining: 13.2s\n",
      "316:\tlearn: 0.0021334\ttotal: 22.7s\tremaining: 13.1s\n",
      "317:\tlearn: 0.0021335\ttotal: 22.8s\tremaining: 13s\n",
      "318:\tlearn: 0.0021335\ttotal: 22.9s\tremaining: 13s\n",
      "319:\tlearn: 0.0021334\ttotal: 22.9s\tremaining: 12.9s\n",
      "320:\tlearn: 0.0021334\ttotal: 23s\tremaining: 12.8s\n",
      "321:\tlearn: 0.0021335\ttotal: 23.1s\tremaining: 12.8s\n",
      "322:\tlearn: 0.0021250\ttotal: 23.1s\tremaining: 12.7s\n",
      "323:\tlearn: 0.0021083\ttotal: 23.2s\tremaining: 12.6s\n",
      "324:\tlearn: 0.0020956\ttotal: 23.3s\tremaining: 12.5s\n",
      "325:\tlearn: 0.0020792\ttotal: 23.3s\tremaining: 12.5s\n",
      "326:\tlearn: 0.0020792\ttotal: 23.4s\tremaining: 12.4s\n",
      "327:\tlearn: 0.0020792\ttotal: 23.5s\tremaining: 12.3s\n",
      "328:\tlearn: 0.0020792\ttotal: 23.6s\tremaining: 12.3s\n",
      "329:\tlearn: 0.0020792\ttotal: 23.6s\tremaining: 12.2s\n",
      "330:\tlearn: 0.0020792\ttotal: 23.8s\tremaining: 12.1s\n",
      "331:\tlearn: 0.0020792\ttotal: 23.8s\tremaining: 12s\n",
      "332:\tlearn: 0.0020682\ttotal: 23.9s\tremaining: 12s\n",
      "333:\tlearn: 0.0020656\ttotal: 24s\tremaining: 11.9s\n",
      "334:\tlearn: 0.0020469\ttotal: 24s\tremaining: 11.8s\n",
      "335:\tlearn: 0.0020301\ttotal: 24.1s\tremaining: 11.8s\n",
      "336:\tlearn: 0.0020141\ttotal: 24.2s\tremaining: 11.7s\n",
      "337:\tlearn: 0.0020141\ttotal: 24.3s\tremaining: 11.6s\n",
      "338:\tlearn: 0.0020141\ttotal: 24.3s\tremaining: 11.5s\n",
      "339:\tlearn: 0.0020140\ttotal: 24.4s\tremaining: 11.5s\n",
      "340:\tlearn: 0.0020141\ttotal: 24.5s\tremaining: 11.4s\n",
      "341:\tlearn: 0.0020141\ttotal: 24.5s\tremaining: 11.3s\n",
      "342:\tlearn: 0.0020050\ttotal: 24.6s\tremaining: 11.3s\n",
      "343:\tlearn: 0.0020049\ttotal: 24.7s\tremaining: 11.2s\n",
      "344:\tlearn: 0.0020049\ttotal: 24.8s\tremaining: 11.1s\n",
      "345:\tlearn: 0.0020049\ttotal: 24.8s\tremaining: 11.1s\n",
      "346:\tlearn: 0.0020049\ttotal: 24.9s\tremaining: 11s\n",
      "347:\tlearn: 0.0019810\ttotal: 25s\tremaining: 10.9s\n",
      "348:\tlearn: 0.0019810\ttotal: 25.1s\tremaining: 10.9s\n",
      "349:\tlearn: 0.0019810\ttotal: 25.1s\tremaining: 10.8s\n",
      "350:\tlearn: 0.0019810\ttotal: 25.3s\tremaining: 10.7s\n",
      "351:\tlearn: 0.0019809\ttotal: 25.3s\tremaining: 10.7s\n",
      "352:\tlearn: 0.0019809\ttotal: 25.4s\tremaining: 10.6s\n",
      "353:\tlearn: 0.0019717\ttotal: 25.5s\tremaining: 10.5s\n",
      "354:\tlearn: 0.0019717\ttotal: 25.6s\tremaining: 10.5s\n",
      "355:\tlearn: 0.0019716\ttotal: 25.6s\tremaining: 10.4s\n",
      "356:\tlearn: 0.0019716\ttotal: 25.7s\tremaining: 10.3s\n",
      "357:\tlearn: 0.0019716\ttotal: 25.8s\tremaining: 10.2s\n",
      "358:\tlearn: 0.0019716\ttotal: 25.8s\tremaining: 10.2s\n",
      "359:\tlearn: 0.0019715\ttotal: 26s\tremaining: 10.1s\n",
      "360:\tlearn: 0.0019716\ttotal: 26s\tremaining: 10s\n",
      "361:\tlearn: 0.0019716\ttotal: 26.1s\tremaining: 9.96s\n",
      "362:\tlearn: 0.0019716\ttotal: 26.2s\tremaining: 9.88s\n",
      "363:\tlearn: 0.0019715\ttotal: 26.3s\tremaining: 9.81s\n",
      "364:\tlearn: 0.0019715\ttotal: 26.3s\tremaining: 9.74s\n",
      "365:\tlearn: 0.0019715\ttotal: 26.4s\tremaining: 9.66s\n",
      "366:\tlearn: 0.0019715\ttotal: 26.5s\tremaining: 9.6s\n",
      "367:\tlearn: 0.0019715\ttotal: 26.5s\tremaining: 9.52s\n",
      "368:\tlearn: 0.0019714\ttotal: 26.7s\tremaining: 9.47s\n",
      "369:\tlearn: 0.0019715\ttotal: 26.7s\tremaining: 9.38s\n",
      "370:\tlearn: 0.0019714\ttotal: 26.8s\tremaining: 9.32s\n",
      "371:\tlearn: 0.0019714\ttotal: 26.9s\tremaining: 9.25s\n",
      "372:\tlearn: 0.0019714\ttotal: 26.9s\tremaining: 9.16s\n",
      "373:\tlearn: 0.0019714\ttotal: 27s\tremaining: 9.11s\n",
      "374:\tlearn: 0.0019714\ttotal: 27.1s\tremaining: 9.02s\n",
      "375:\tlearn: 0.0019714\ttotal: 27.2s\tremaining: 8.96s\n",
      "376:\tlearn: 0.0019713\ttotal: 27.2s\tremaining: 8.88s\n",
      "377:\tlearn: 0.0019713\ttotal: 27.3s\tremaining: 8.8s\n",
      "378:\tlearn: 0.0019713\ttotal: 27.4s\tremaining: 8.74s\n",
      "379:\tlearn: 0.0019712\ttotal: 27.4s\tremaining: 8.66s\n",
      "380:\tlearn: 0.0019712\ttotal: 27.6s\tremaining: 8.62s\n",
      "381:\tlearn: 0.0019713\ttotal: 27.7s\tremaining: 8.55s\n",
      "382:\tlearn: 0.0019713\ttotal: 27.8s\tremaining: 8.48s\n",
      "383:\tlearn: 0.0019712\ttotal: 27.8s\tremaining: 8.4s\n",
      "384:\tlearn: 0.0019713\ttotal: 27.9s\tremaining: 8.34s\n",
      "385:\tlearn: 0.0019712\ttotal: 28s\tremaining: 8.26s\n",
      "386:\tlearn: 0.0019712\ttotal: 28s\tremaining: 8.18s\n",
      "387:\tlearn: 0.0019712\ttotal: 28.1s\tremaining: 8.11s\n",
      "388:\tlearn: 0.0019711\ttotal: 28.1s\tremaining: 8.03s\n",
      "389:\tlearn: 0.0019711\ttotal: 28.2s\tremaining: 7.95s\n",
      "390:\tlearn: 0.0019711\ttotal: 28.3s\tremaining: 7.89s\n",
      "391:\tlearn: 0.0019711\ttotal: 28.4s\tremaining: 7.81s\n",
      "392:\tlearn: 0.0019710\ttotal: 28.5s\tremaining: 7.75s\n",
      "393:\tlearn: 0.0019710\ttotal: 28.5s\tremaining: 7.67s\n",
      "394:\tlearn: 0.0019710\ttotal: 28.6s\tremaining: 7.59s\n",
      "395:\tlearn: 0.0019710\ttotal: 28.7s\tremaining: 7.53s\n",
      "396:\tlearn: 0.0019710\ttotal: 28.7s\tremaining: 7.45s\n",
      "397:\tlearn: 0.0019570\ttotal: 28.8s\tremaining: 7.39s\n",
      "398:\tlearn: 0.0019554\ttotal: 28.9s\tremaining: 7.31s\n",
      "399:\tlearn: 0.0019553\ttotal: 29s\tremaining: 7.25s\n",
      "400:\tlearn: 0.0019554\ttotal: 29.1s\tremaining: 7.17s\n",
      "401:\tlearn: 0.0019554\ttotal: 29.1s\tremaining: 7.09s\n",
      "402:\tlearn: 0.0019554\ttotal: 29.2s\tremaining: 7.03s\n",
      "403:\tlearn: 0.0019553\ttotal: 29.3s\tremaining: 6.95s\n",
      "404:\tlearn: 0.0019552\ttotal: 29.4s\tremaining: 6.89s\n",
      "405:\tlearn: 0.0019552\ttotal: 29.4s\tremaining: 6.81s\n",
      "406:\tlearn: 0.0019552\ttotal: 29.5s\tremaining: 6.74s\n",
      "407:\tlearn: 0.0019552\ttotal: 29.6s\tremaining: 6.67s\n",
      "408:\tlearn: 0.0019517\ttotal: 29.6s\tremaining: 6.59s\n",
      "409:\tlearn: 0.0019516\ttotal: 29.7s\tremaining: 6.53s\n",
      "410:\tlearn: 0.0019516\ttotal: 29.8s\tremaining: 6.45s\n",
      "411:\tlearn: 0.0019517\ttotal: 29.9s\tremaining: 6.39s\n",
      "412:\tlearn: 0.0019401\ttotal: 30s\tremaining: 6.31s\n",
      "413:\tlearn: 0.0019401\ttotal: 30s\tremaining: 6.24s\n",
      "414:\tlearn: 0.0019401\ttotal: 30.1s\tremaining: 6.17s\n",
      "415:\tlearn: 0.0019248\ttotal: 30.2s\tremaining: 6.09s\n",
      "416:\tlearn: 0.0019248\ttotal: 30.2s\tremaining: 6.01s\n",
      "417:\tlearn: 0.0019186\ttotal: 30.3s\tremaining: 5.94s\n",
      "418:\tlearn: 0.0019186\ttotal: 30.3s\tremaining: 5.87s\n",
      "419:\tlearn: 0.0019186\ttotal: 30.5s\tremaining: 5.8s\n",
      "420:\tlearn: 0.0019186\ttotal: 30.5s\tremaining: 5.73s\n",
      "421:\tlearn: 0.0019186\ttotal: 30.6s\tremaining: 5.66s\n",
      "422:\tlearn: 0.0019186\ttotal: 30.7s\tremaining: 5.59s\n",
      "423:\tlearn: 0.0019185\ttotal: 30.7s\tremaining: 5.51s\n",
      "424:\tlearn: 0.0019185\ttotal: 30.8s\tremaining: 5.44s\n",
      "425:\tlearn: 0.0019185\ttotal: 30.9s\tremaining: 5.37s\n",
      "426:\tlearn: 0.0019185\ttotal: 31s\tremaining: 5.3s\n",
      "427:\tlearn: 0.0019185\ttotal: 31.1s\tremaining: 5.22s\n",
      "428:\tlearn: 0.0019185\ttotal: 31.1s\tremaining: 5.14s\n",
      "429:\tlearn: 0.0019185\ttotal: 31.2s\tremaining: 5.08s\n",
      "430:\tlearn: 0.0019185\ttotal: 31.2s\tremaining: 5s\n",
      "431:\tlearn: 0.0019185\ttotal: 31.4s\tremaining: 4.94s\n",
      "432:\tlearn: 0.0019090\ttotal: 31.4s\tremaining: 4.86s\n",
      "433:\tlearn: 0.0019090\ttotal: 31.5s\tremaining: 4.79s\n",
      "434:\tlearn: 0.0019090\ttotal: 31.6s\tremaining: 4.72s\n",
      "435:\tlearn: 0.0019090\ttotal: 31.6s\tremaining: 4.64s\n",
      "436:\tlearn: 0.0019090\ttotal: 31.7s\tremaining: 4.57s\n",
      "437:\tlearn: 0.0019089\ttotal: 31.8s\tremaining: 4.5s\n",
      "438:\tlearn: 0.0019089\ttotal: 31.9s\tremaining: 4.43s\n",
      "439:\tlearn: 0.0019089\ttotal: 31.9s\tremaining: 4.35s\n",
      "440:\tlearn: 0.0019089\ttotal: 32s\tremaining: 4.29s\n",
      "441:\tlearn: 0.0019089\ttotal: 32.1s\tremaining: 4.21s\n",
      "442:\tlearn: 0.0019089\ttotal: 32.1s\tremaining: 4.13s\n",
      "443:\tlearn: 0.0019089\ttotal: 32.3s\tremaining: 4.07s\n",
      "444:\tlearn: 0.0019088\ttotal: 32.3s\tremaining: 3.99s\n",
      "445:\tlearn: 0.0019088\ttotal: 32.4s\tremaining: 3.92s\n",
      "446:\tlearn: 0.0019088\ttotal: 32.5s\tremaining: 3.85s\n",
      "447:\tlearn: 0.0019088\ttotal: 32.6s\tremaining: 3.78s\n",
      "448:\tlearn: 0.0019088\ttotal: 32.6s\tremaining: 3.71s\n",
      "449:\tlearn: 0.0019088\ttotal: 32.7s\tremaining: 3.63s\n",
      "450:\tlearn: 0.0019088\ttotal: 32.8s\tremaining: 3.56s\n",
      "451:\tlearn: 0.0019088\ttotal: 32.8s\tremaining: 3.49s\n",
      "452:\tlearn: 0.0019088\ttotal: 32.9s\tremaining: 3.41s\n",
      "453:\tlearn: 0.0019088\ttotal: 33s\tremaining: 3.34s\n",
      "454:\tlearn: 0.0019088\ttotal: 33s\tremaining: 3.27s\n",
      "455:\tlearn: 0.0019088\ttotal: 33.2s\tremaining: 3.2s\n",
      "456:\tlearn: 0.0019088\ttotal: 33.2s\tremaining: 3.13s\n",
      "457:\tlearn: 0.0019088\ttotal: 33.3s\tremaining: 3.06s\n",
      "458:\tlearn: 0.0019088\ttotal: 33.4s\tremaining: 2.98s\n",
      "459:\tlearn: 0.0019088\ttotal: 33.4s\tremaining: 2.91s\n",
      "460:\tlearn: 0.0019088\ttotal: 33.6s\tremaining: 2.84s\n",
      "461:\tlearn: 0.0019014\ttotal: 33.6s\tremaining: 2.76s\n",
      "462:\tlearn: 0.0019014\ttotal: 33.7s\tremaining: 2.69s\n",
      "463:\tlearn: 0.0019013\ttotal: 33.8s\tremaining: 2.62s\n",
      "464:\tlearn: 0.0019013\ttotal: 33.8s\tremaining: 2.54s\n",
      "465:\tlearn: 0.0019013\ttotal: 33.9s\tremaining: 2.47s\n",
      "466:\tlearn: 0.0019012\ttotal: 34s\tremaining: 2.4s\n",
      "467:\tlearn: 0.0019012\ttotal: 34s\tremaining: 2.33s\n",
      "468:\tlearn: 0.0019012\ttotal: 34.1s\tremaining: 2.25s\n",
      "469:\tlearn: 0.0019012\ttotal: 34.2s\tremaining: 2.18s\n",
      "470:\tlearn: 0.0019012\ttotal: 34.3s\tremaining: 2.11s\n",
      "471:\tlearn: 0.0019011\ttotal: 34.3s\tremaining: 2.04s\n",
      "472:\tlearn: 0.0019011\ttotal: 34.4s\tremaining: 1.97s\n",
      "473:\tlearn: 0.0019011\ttotal: 34.5s\tremaining: 1.89s\n",
      "474:\tlearn: 0.0019011\ttotal: 34.6s\tremaining: 1.82s\n",
      "475:\tlearn: 0.0019011\ttotal: 34.7s\tremaining: 1.75s\n",
      "476:\tlearn: 0.0019010\ttotal: 34.7s\tremaining: 1.67s\n",
      "477:\tlearn: 0.0019010\ttotal: 34.8s\tremaining: 1.6s\n",
      "478:\tlearn: 0.0019010\ttotal: 34.9s\tremaining: 1.53s\n",
      "479:\tlearn: 0.0019010\ttotal: 35s\tremaining: 1.46s\n",
      "480:\tlearn: 0.0019010\ttotal: 35.1s\tremaining: 1.38s\n",
      "481:\tlearn: 0.0019010\ttotal: 35.1s\tremaining: 1.31s\n",
      "482:\tlearn: 0.0019009\ttotal: 35.2s\tremaining: 1.24s\n",
      "483:\tlearn: 0.0019009\ttotal: 35.3s\tremaining: 1.17s\n",
      "484:\tlearn: 0.0019009\ttotal: 35.4s\tremaining: 1.09s\n",
      "485:\tlearn: 0.0019009\ttotal: 35.4s\tremaining: 1.02s\n",
      "486:\tlearn: 0.0019009\ttotal: 35.5s\tremaining: 947ms\n",
      "487:\tlearn: 0.0019008\ttotal: 35.6s\tremaining: 875ms\n",
      "488:\tlearn: 0.0019008\ttotal: 35.6s\tremaining: 801ms\n",
      "489:\tlearn: 0.0019008\ttotal: 35.7s\tremaining: 729ms\n",
      "490:\tlearn: 0.0019008\ttotal: 35.8s\tremaining: 656ms\n",
      "491:\tlearn: 0.0019008\ttotal: 35.9s\tremaining: 584ms\n",
      "492:\tlearn: 0.0019008\ttotal: 35.9s\tremaining: 510ms\n",
      "493:\tlearn: 0.0019007\ttotal: 36s\tremaining: 437ms\n",
      "494:\tlearn: 0.0019007\ttotal: 36.1s\tremaining: 365ms\n",
      "495:\tlearn: 0.0019007\ttotal: 36.2s\tremaining: 292ms\n",
      "496:\tlearn: 0.0019007\ttotal: 36.3s\tremaining: 219ms\n",
      "497:\tlearn: 0.0019007\ttotal: 36.3s\tremaining: 146ms\n",
      "498:\tlearn: 0.0019006\ttotal: 36.4s\tremaining: 73ms\n",
      "499:\tlearn: 0.0019007\ttotal: 36.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6512440\ttotal: 46.7ms\tremaining: 23.3s\n",
      "1:\tlearn: 0.6103374\ttotal: 157ms\tremaining: 39.1s\n",
      "2:\tlearn: 0.5696313\ttotal: 202ms\tremaining: 33.4s\n",
      "3:\tlearn: 0.5352437\ttotal: 244ms\tremaining: 30.3s\n",
      "4:\tlearn: 0.5077492\ttotal: 363ms\tremaining: 35.9s\n",
      "5:\tlearn: 0.4837882\ttotal: 426ms\tremaining: 35.1s\n",
      "6:\tlearn: 0.4578575\ttotal: 469ms\tremaining: 33.1s\n",
      "7:\tlearn: 0.4314863\ttotal: 587ms\tremaining: 36.1s\n",
      "8:\tlearn: 0.4152310\ttotal: 632ms\tremaining: 34.5s\n",
      "9:\tlearn: 0.3976270\ttotal: 714ms\tremaining: 35s\n",
      "10:\tlearn: 0.3805898\ttotal: 789ms\tremaining: 35.1s\n",
      "11:\tlearn: 0.3625357\ttotal: 834ms\tremaining: 33.9s\n",
      "12:\tlearn: 0.3463772\ttotal: 946ms\tremaining: 35.5s\n",
      "13:\tlearn: 0.3276532\ttotal: 989ms\tremaining: 34.3s\n",
      "14:\tlearn: 0.3057345\ttotal: 1.08s\tremaining: 35s\n",
      "15:\tlearn: 0.2917143\ttotal: 1.16s\tremaining: 35.1s\n",
      "16:\tlearn: 0.2786126\ttotal: 1.2s\tremaining: 34.2s\n",
      "17:\tlearn: 0.2684597\ttotal: 1.34s\tremaining: 36s\n",
      "18:\tlearn: 0.2589333\ttotal: 1.41s\tremaining: 35.7s\n",
      "19:\tlearn: 0.2464484\ttotal: 1.49s\tremaining: 35.7s\n",
      "20:\tlearn: 0.2373207\ttotal: 1.54s\tremaining: 35.2s\n",
      "21:\tlearn: 0.2273851\ttotal: 1.58s\tremaining: 34.4s\n",
      "22:\tlearn: 0.2179523\ttotal: 1.66s\tremaining: 34.5s\n",
      "23:\tlearn: 0.2115926\ttotal: 1.71s\tremaining: 33.9s\n",
      "24:\tlearn: 0.2014399\ttotal: 1.75s\tremaining: 33.2s\n",
      "25:\tlearn: 0.1938412\ttotal: 1.84s\tremaining: 33.6s\n",
      "26:\tlearn: 0.1870260\ttotal: 1.91s\tremaining: 33.5s\n",
      "27:\tlearn: 0.1812370\ttotal: 1.96s\tremaining: 33s\n",
      "28:\tlearn: 0.1762690\ttotal: 2.06s\tremaining: 33.5s\n",
      "29:\tlearn: 0.1708598\ttotal: 2.11s\tremaining: 33s\n",
      "30:\tlearn: 0.1603907\ttotal: 2.21s\tremaining: 33.5s\n",
      "31:\tlearn: 0.1540721\ttotal: 2.29s\tremaining: 33.5s\n",
      "32:\tlearn: 0.1450200\ttotal: 2.33s\tremaining: 33s\n",
      "33:\tlearn: 0.1409505\ttotal: 2.44s\tremaining: 33.5s\n",
      "34:\tlearn: 0.1370464\ttotal: 2.49s\tremaining: 33.1s\n",
      "35:\tlearn: 0.1287676\ttotal: 2.6s\tremaining: 33.5s\n",
      "36:\tlearn: 0.1264029\ttotal: 2.65s\tremaining: 33.2s\n",
      "37:\tlearn: 0.1233348\ttotal: 2.73s\tremaining: 33.2s\n",
      "38:\tlearn: 0.1197893\ttotal: 2.81s\tremaining: 33.3s\n",
      "39:\tlearn: 0.1148229\ttotal: 2.86s\tremaining: 32.9s\n",
      "40:\tlearn: 0.1091534\ttotal: 2.98s\tremaining: 33.4s\n",
      "41:\tlearn: 0.1050113\ttotal: 3.03s\tremaining: 33s\n",
      "42:\tlearn: 0.1018180\ttotal: 3.11s\tremaining: 33.1s\n",
      "43:\tlearn: 0.0988098\ttotal: 3.18s\tremaining: 33s\n",
      "44:\tlearn: 0.0942770\ttotal: 3.23s\tremaining: 32.7s\n",
      "45:\tlearn: 0.0922533\ttotal: 3.34s\tremaining: 33s\n",
      "46:\tlearn: 0.0887660\ttotal: 3.39s\tremaining: 32.6s\n",
      "47:\tlearn: 0.0847117\ttotal: 3.51s\tremaining: 33s\n",
      "48:\tlearn: 0.0827804\ttotal: 3.56s\tremaining: 32.7s\n",
      "49:\tlearn: 0.0798713\ttotal: 3.65s\tremaining: 32.9s\n",
      "50:\tlearn: 0.0771308\ttotal: 3.72s\tremaining: 32.7s\n",
      "51:\tlearn: 0.0743328\ttotal: 3.76s\tremaining: 32.4s\n",
      "52:\tlearn: 0.0727761\ttotal: 3.88s\tremaining: 32.7s\n",
      "53:\tlearn: 0.0697764\ttotal: 3.92s\tremaining: 32.4s\n",
      "54:\tlearn: 0.0678182\ttotal: 4.04s\tremaining: 32.7s\n",
      "55:\tlearn: 0.0656324\ttotal: 4.09s\tremaining: 32.4s\n",
      "56:\tlearn: 0.0639652\ttotal: 4.2s\tremaining: 32.7s\n",
      "57:\tlearn: 0.0613595\ttotal: 4.28s\tremaining: 32.6s\n",
      "58:\tlearn: 0.0595325\ttotal: 4.33s\tremaining: 32.4s\n",
      "59:\tlearn: 0.0570455\ttotal: 4.44s\tremaining: 32.6s\n",
      "60:\tlearn: 0.0544899\ttotal: 4.49s\tremaining: 32.3s\n",
      "61:\tlearn: 0.0527729\ttotal: 4.61s\tremaining: 32.6s\n",
      "62:\tlearn: 0.0507974\ttotal: 4.66s\tremaining: 32.3s\n",
      "63:\tlearn: 0.0491154\ttotal: 4.71s\tremaining: 32.1s\n",
      "64:\tlearn: 0.0470256\ttotal: 4.82s\tremaining: 32.2s\n",
      "65:\tlearn: 0.0460377\ttotal: 4.86s\tremaining: 32s\n",
      "66:\tlearn: 0.0445618\ttotal: 4.97s\tremaining: 32.1s\n",
      "67:\tlearn: 0.0429486\ttotal: 5.03s\tremaining: 31.9s\n",
      "68:\tlearn: 0.0416440\ttotal: 5.08s\tremaining: 31.7s\n",
      "69:\tlearn: 0.0406110\ttotal: 5.18s\tremaining: 31.9s\n",
      "70:\tlearn: 0.0398892\ttotal: 5.23s\tremaining: 31.6s\n",
      "71:\tlearn: 0.0388247\ttotal: 5.32s\tremaining: 31.6s\n",
      "72:\tlearn: 0.0376446\ttotal: 5.4s\tremaining: 31.6s\n",
      "73:\tlearn: 0.0369474\ttotal: 5.44s\tremaining: 31.3s\n",
      "74:\tlearn: 0.0362705\ttotal: 5.55s\tremaining: 31.5s\n",
      "75:\tlearn: 0.0354936\ttotal: 5.6s\tremaining: 31.3s\n",
      "76:\tlearn: 0.0344986\ttotal: 5.64s\tremaining: 31s\n",
      "77:\tlearn: 0.0332760\ttotal: 5.76s\tremaining: 31.2s\n",
      "78:\tlearn: 0.0322107\ttotal: 5.81s\tremaining: 31s\n",
      "79:\tlearn: 0.0313330\ttotal: 5.91s\tremaining: 31s\n",
      "80:\tlearn: 0.0305102\ttotal: 5.97s\tremaining: 30.9s\n",
      "81:\tlearn: 0.0296745\ttotal: 6.02s\tremaining: 30.7s\n",
      "82:\tlearn: 0.0287330\ttotal: 6.14s\tremaining: 30.8s\n",
      "83:\tlearn: 0.0276899\ttotal: 6.19s\tremaining: 30.7s\n",
      "84:\tlearn: 0.0270492\ttotal: 6.27s\tremaining: 30.6s\n",
      "85:\tlearn: 0.0266347\ttotal: 6.35s\tremaining: 30.6s\n",
      "86:\tlearn: 0.0260612\ttotal: 6.39s\tremaining: 30.4s\n",
      "87:\tlearn: 0.0252730\ttotal: 6.5s\tremaining: 30.4s\n",
      "88:\tlearn: 0.0246711\ttotal: 6.54s\tremaining: 30.2s\n",
      "89:\tlearn: 0.0237924\ttotal: 6.64s\tremaining: 30.3s\n",
      "90:\tlearn: 0.0230708\ttotal: 6.7s\tremaining: 30.1s\n",
      "91:\tlearn: 0.0225714\ttotal: 6.8s\tremaining: 30.1s\n",
      "92:\tlearn: 0.0220452\ttotal: 6.86s\tremaining: 30s\n",
      "93:\tlearn: 0.0213987\ttotal: 6.91s\tremaining: 29.8s\n",
      "94:\tlearn: 0.0209219\ttotal: 7.03s\tremaining: 30s\n",
      "95:\tlearn: 0.0204117\ttotal: 7.08s\tremaining: 29.8s\n",
      "96:\tlearn: 0.0199219\ttotal: 7.12s\tremaining: 29.6s\n",
      "97:\tlearn: 0.0193358\ttotal: 7.22s\tremaining: 29.6s\n",
      "98:\tlearn: 0.0187287\ttotal: 7.27s\tremaining: 29.4s\n",
      "99:\tlearn: 0.0183077\ttotal: 7.36s\tremaining: 29.5s\n",
      "100:\tlearn: 0.0177461\ttotal: 7.43s\tremaining: 29.4s\n",
      "101:\tlearn: 0.0174042\ttotal: 7.48s\tremaining: 29.2s\n",
      "102:\tlearn: 0.0170825\ttotal: 7.58s\tremaining: 29.2s\n",
      "103:\tlearn: 0.0167899\ttotal: 7.63s\tremaining: 29s\n",
      "104:\tlearn: 0.0163460\ttotal: 7.74s\tremaining: 29.1s\n",
      "105:\tlearn: 0.0159158\ttotal: 7.79s\tremaining: 29s\n",
      "106:\tlearn: 0.0155364\ttotal: 7.88s\tremaining: 28.9s\n",
      "107:\tlearn: 0.0150708\ttotal: 7.96s\tremaining: 28.9s\n",
      "108:\tlearn: 0.0147661\ttotal: 8s\tremaining: 28.7s\n",
      "109:\tlearn: 0.0144669\ttotal: 8.12s\tremaining: 28.8s\n",
      "110:\tlearn: 0.0140836\ttotal: 8.17s\tremaining: 28.6s\n",
      "111:\tlearn: 0.0137685\ttotal: 8.28s\tremaining: 28.7s\n",
      "112:\tlearn: 0.0134511\ttotal: 8.33s\tremaining: 28.5s\n",
      "113:\tlearn: 0.0131608\ttotal: 8.45s\tremaining: 28.6s\n",
      "114:\tlearn: 0.0128433\ttotal: 8.5s\tremaining: 28.5s\n",
      "115:\tlearn: 0.0126589\ttotal: 8.59s\tremaining: 28.4s\n",
      "116:\tlearn: 0.0123707\ttotal: 8.67s\tremaining: 28.4s\n",
      "117:\tlearn: 0.0120554\ttotal: 8.73s\tremaining: 28.3s\n",
      "118:\tlearn: 0.0117944\ttotal: 8.83s\tremaining: 28.3s\n",
      "119:\tlearn: 0.0115791\ttotal: 8.88s\tremaining: 28.1s\n",
      "120:\tlearn: 0.0113619\ttotal: 9s\tremaining: 28.2s\n",
      "121:\tlearn: 0.0111927\ttotal: 9.05s\tremaining: 28s\n",
      "122:\tlearn: 0.0109797\ttotal: 9.14s\tremaining: 28s\n",
      "123:\tlearn: 0.0107088\ttotal: 9.21s\tremaining: 27.9s\n",
      "124:\tlearn: 0.0104446\ttotal: 9.25s\tremaining: 27.7s\n",
      "125:\tlearn: 0.0102293\ttotal: 9.37s\tremaining: 27.8s\n",
      "126:\tlearn: 0.0100694\ttotal: 9.41s\tremaining: 27.6s\n",
      "127:\tlearn: 0.0099049\ttotal: 9.53s\tremaining: 27.7s\n",
      "128:\tlearn: 0.0097347\ttotal: 9.6s\tremaining: 27.6s\n",
      "129:\tlearn: 0.0095535\ttotal: 9.64s\tremaining: 27.4s\n",
      "130:\tlearn: 0.0093677\ttotal: 9.73s\tremaining: 27.4s\n",
      "131:\tlearn: 0.0091590\ttotal: 9.79s\tremaining: 27.3s\n",
      "132:\tlearn: 0.0090147\ttotal: 9.84s\tremaining: 27.1s\n",
      "133:\tlearn: 0.0089023\ttotal: 9.95s\tremaining: 27.2s\n",
      "134:\tlearn: 0.0087833\ttotal: 10s\tremaining: 27s\n",
      "135:\tlearn: 0.0086603\ttotal: 10.1s\tremaining: 27.1s\n",
      "136:\tlearn: 0.0085514\ttotal: 10.2s\tremaining: 27s\n",
      "137:\tlearn: 0.0084489\ttotal: 10.3s\tremaining: 27s\n",
      "138:\tlearn: 0.0083135\ttotal: 10.3s\tremaining: 26.9s\n",
      "139:\tlearn: 0.0081475\ttotal: 10.4s\tremaining: 26.9s\n",
      "140:\tlearn: 0.0079654\ttotal: 10.5s\tremaining: 26.8s\n",
      "141:\tlearn: 0.0078204\ttotal: 10.6s\tremaining: 26.6s\n",
      "142:\tlearn: 0.0076977\ttotal: 10.7s\tremaining: 26.6s\n",
      "143:\tlearn: 0.0075879\ttotal: 10.7s\tremaining: 26.5s\n",
      "144:\tlearn: 0.0074659\ttotal: 10.8s\tremaining: 26.4s\n",
      "145:\tlearn: 0.0073410\ttotal: 10.9s\tremaining: 26.3s\n",
      "146:\tlearn: 0.0072504\ttotal: 10.9s\tremaining: 26.2s\n",
      "147:\tlearn: 0.0071589\ttotal: 11s\tremaining: 26.2s\n",
      "148:\tlearn: 0.0070657\ttotal: 11s\tremaining: 26s\n",
      "149:\tlearn: 0.0069638\ttotal: 11.1s\tremaining: 26s\n",
      "150:\tlearn: 0.0068363\ttotal: 11.2s\tremaining: 25.9s\n",
      "151:\tlearn: 0.0067248\ttotal: 11.3s\tremaining: 25.8s\n",
      "152:\tlearn: 0.0066067\ttotal: 11.4s\tremaining: 25.8s\n",
      "153:\tlearn: 0.0064932\ttotal: 11.4s\tremaining: 25.6s\n",
      "154:\tlearn: 0.0064054\ttotal: 11.5s\tremaining: 25.6s\n",
      "155:\tlearn: 0.0062627\ttotal: 11.6s\tremaining: 25.5s\n",
      "156:\tlearn: 0.0061509\ttotal: 11.7s\tremaining: 25.5s\n",
      "157:\tlearn: 0.0060614\ttotal: 11.8s\tremaining: 25.5s\n",
      "158:\tlearn: 0.0059497\ttotal: 11.9s\tremaining: 25.5s\n",
      "159:\tlearn: 0.0058602\ttotal: 12s\tremaining: 25.4s\n",
      "160:\tlearn: 0.0057776\ttotal: 12s\tremaining: 25.3s\n",
      "161:\tlearn: 0.0057070\ttotal: 12.1s\tremaining: 25.2s\n",
      "162:\tlearn: 0.0056427\ttotal: 12.1s\tremaining: 25s\n",
      "163:\tlearn: 0.0055632\ttotal: 12.1s\tremaining: 24.9s\n",
      "164:\tlearn: 0.0055083\ttotal: 12.2s\tremaining: 24.7s\n",
      "165:\tlearn: 0.0054325\ttotal: 12.2s\tremaining: 24.6s\n",
      "166:\tlearn: 0.0053708\ttotal: 12.3s\tremaining: 24.6s\n",
      "167:\tlearn: 0.0052969\ttotal: 12.4s\tremaining: 24.5s\n",
      "168:\tlearn: 0.0052458\ttotal: 12.5s\tremaining: 24.4s\n",
      "169:\tlearn: 0.0051924\ttotal: 12.6s\tremaining: 24.4s\n",
      "170:\tlearn: 0.0051266\ttotal: 12.6s\tremaining: 24.2s\n",
      "171:\tlearn: 0.0050495\ttotal: 12.7s\tremaining: 24.2s\n",
      "172:\tlearn: 0.0049879\ttotal: 12.8s\tremaining: 24.1s\n",
      "173:\tlearn: 0.0049187\ttotal: 12.9s\tremaining: 24.1s\n",
      "174:\tlearn: 0.0048531\ttotal: 12.9s\tremaining: 24s\n",
      "175:\tlearn: 0.0048015\ttotal: 13s\tremaining: 24s\n",
      "176:\tlearn: 0.0047569\ttotal: 13.1s\tremaining: 23.9s\n",
      "177:\tlearn: 0.0046787\ttotal: 13.1s\tremaining: 23.8s\n",
      "178:\tlearn: 0.0046309\ttotal: 13.3s\tremaining: 23.8s\n",
      "179:\tlearn: 0.0045687\ttotal: 13.3s\tremaining: 23.6s\n",
      "180:\tlearn: 0.0045214\ttotal: 13.4s\tremaining: 23.6s\n",
      "181:\tlearn: 0.0044728\ttotal: 13.5s\tremaining: 23.5s\n",
      "182:\tlearn: 0.0044407\ttotal: 13.6s\tremaining: 23.5s\n",
      "183:\tlearn: 0.0043936\ttotal: 13.6s\tremaining: 23.4s\n",
      "184:\tlearn: 0.0043459\ttotal: 13.7s\tremaining: 23.3s\n",
      "185:\tlearn: 0.0042990\ttotal: 13.7s\tremaining: 23.2s\n",
      "186:\tlearn: 0.0042528\ttotal: 13.8s\tremaining: 23.1s\n",
      "187:\tlearn: 0.0042151\ttotal: 13.9s\tremaining: 23s\n",
      "188:\tlearn: 0.0041663\ttotal: 14s\tremaining: 23s\n",
      "189:\tlearn: 0.0041187\ttotal: 14s\tremaining: 22.9s\n",
      "190:\tlearn: 0.0040880\ttotal: 14.1s\tremaining: 22.8s\n",
      "191:\tlearn: 0.0040482\ttotal: 14.2s\tremaining: 22.8s\n",
      "192:\tlearn: 0.0040116\ttotal: 14.2s\tremaining: 22.6s\n",
      "193:\tlearn: 0.0039830\ttotal: 14.3s\tremaining: 22.6s\n",
      "194:\tlearn: 0.0039532\ttotal: 14.4s\tremaining: 22.5s\n",
      "195:\tlearn: 0.0039071\ttotal: 14.5s\tremaining: 22.5s\n",
      "196:\tlearn: 0.0038612\ttotal: 14.6s\tremaining: 22.4s\n",
      "197:\tlearn: 0.0038192\ttotal: 14.7s\tremaining: 22.4s\n",
      "198:\tlearn: 0.0037856\ttotal: 14.7s\tremaining: 22.3s\n",
      "199:\tlearn: 0.0037647\ttotal: 14.8s\tremaining: 22.2s\n",
      "200:\tlearn: 0.0037302\ttotal: 14.9s\tremaining: 22.1s\n",
      "201:\tlearn: 0.0036960\ttotal: 14.9s\tremaining: 22s\n",
      "202:\tlearn: 0.0036626\ttotal: 15s\tremaining: 22s\n",
      "203:\tlearn: 0.0036244\ttotal: 15.1s\tremaining: 21.8s\n",
      "204:\tlearn: 0.0035927\ttotal: 15.2s\tremaining: 21.8s\n",
      "205:\tlearn: 0.0035461\ttotal: 15.2s\tremaining: 21.7s\n",
      "206:\tlearn: 0.0035072\ttotal: 15.3s\tremaining: 21.6s\n",
      "207:\tlearn: 0.0034720\ttotal: 15.4s\tremaining: 21.6s\n",
      "208:\tlearn: 0.0034399\ttotal: 15.4s\tremaining: 21.5s\n",
      "209:\tlearn: 0.0034026\ttotal: 15.5s\tremaining: 21.5s\n",
      "210:\tlearn: 0.0033791\ttotal: 15.6s\tremaining: 21.4s\n",
      "211:\tlearn: 0.0033554\ttotal: 15.7s\tremaining: 21.3s\n",
      "212:\tlearn: 0.0033236\ttotal: 15.8s\tremaining: 21.2s\n",
      "213:\tlearn: 0.0032857\ttotal: 15.8s\tremaining: 21.1s\n",
      "214:\tlearn: 0.0032490\ttotal: 15.9s\tremaining: 21.1s\n",
      "215:\tlearn: 0.0032204\ttotal: 16s\tremaining: 21s\n",
      "216:\tlearn: 0.0031927\ttotal: 16.1s\tremaining: 20.9s\n",
      "217:\tlearn: 0.0031554\ttotal: 16.1s\tremaining: 20.9s\n",
      "218:\tlearn: 0.0031246\ttotal: 16.2s\tremaining: 20.8s\n",
      "219:\tlearn: 0.0031036\ttotal: 16.3s\tremaining: 20.7s\n",
      "220:\tlearn: 0.0030781\ttotal: 16.3s\tremaining: 20.6s\n",
      "221:\tlearn: 0.0030513\ttotal: 16.4s\tremaining: 20.5s\n",
      "222:\tlearn: 0.0030512\ttotal: 16.5s\tremaining: 20.5s\n",
      "223:\tlearn: 0.0030278\ttotal: 16.5s\tremaining: 20.4s\n",
      "224:\tlearn: 0.0030016\ttotal: 16.6s\tremaining: 20.3s\n",
      "225:\tlearn: 0.0029754\ttotal: 16.7s\tremaining: 20.3s\n",
      "226:\tlearn: 0.0029419\ttotal: 16.8s\tremaining: 20.1s\n",
      "227:\tlearn: 0.0029199\ttotal: 16.9s\tremaining: 20.1s\n",
      "228:\tlearn: 0.0028903\ttotal: 16.9s\tremaining: 20s\n",
      "229:\tlearn: 0.0028730\ttotal: 17s\tremaining: 20s\n",
      "230:\tlearn: 0.0028496\ttotal: 17.1s\tremaining: 19.9s\n",
      "231:\tlearn: 0.0028257\ttotal: 17.2s\tremaining: 19.8s\n",
      "232:\tlearn: 0.0027979\ttotal: 17.2s\tremaining: 19.8s\n",
      "233:\tlearn: 0.0027762\ttotal: 17.3s\tremaining: 19.7s\n",
      "234:\tlearn: 0.0027762\ttotal: 17.4s\tremaining: 19.6s\n",
      "235:\tlearn: 0.0027562\ttotal: 17.4s\tremaining: 19.5s\n",
      "236:\tlearn: 0.0027275\ttotal: 17.6s\tremaining: 19.5s\n",
      "237:\tlearn: 0.0027032\ttotal: 17.6s\tremaining: 19.4s\n",
      "238:\tlearn: 0.0026769\ttotal: 17.7s\tremaining: 19.4s\n",
      "239:\tlearn: 0.0026768\ttotal: 17.8s\tremaining: 19.2s\n",
      "240:\tlearn: 0.0026767\ttotal: 17.9s\tremaining: 19.2s\n",
      "241:\tlearn: 0.0026767\ttotal: 17.9s\tremaining: 19.1s\n",
      "242:\tlearn: 0.0026570\ttotal: 18s\tremaining: 19.1s\n",
      "243:\tlearn: 0.0026344\ttotal: 18.1s\tremaining: 19s\n",
      "244:\tlearn: 0.0026174\ttotal: 18.2s\tremaining: 18.9s\n",
      "245:\tlearn: 0.0025827\ttotal: 18.3s\tremaining: 18.9s\n",
      "246:\tlearn: 0.0025616\ttotal: 18.3s\tremaining: 18.8s\n",
      "247:\tlearn: 0.0025406\ttotal: 18.4s\tremaining: 18.7s\n",
      "248:\tlearn: 0.0025406\ttotal: 18.5s\tremaining: 18.6s\n",
      "249:\tlearn: 0.0025404\ttotal: 18.6s\tremaining: 18.6s\n",
      "250:\tlearn: 0.0025208\ttotal: 18.6s\tremaining: 18.5s\n",
      "251:\tlearn: 0.0024982\ttotal: 18.7s\tremaining: 18.4s\n",
      "252:\tlearn: 0.0024789\ttotal: 18.8s\tremaining: 18.3s\n",
      "253:\tlearn: 0.0024788\ttotal: 18.9s\tremaining: 18.3s\n",
      "254:\tlearn: 0.0024593\ttotal: 19s\tremaining: 18.2s\n",
      "255:\tlearn: 0.0024332\ttotal: 19s\tremaining: 18.1s\n",
      "256:\tlearn: 0.0024331\ttotal: 19.1s\tremaining: 18.1s\n",
      "257:\tlearn: 0.0024113\ttotal: 19.2s\tremaining: 18s\n",
      "258:\tlearn: 0.0023992\ttotal: 19.2s\tremaining: 17.9s\n",
      "259:\tlearn: 0.0023748\ttotal: 19.3s\tremaining: 17.9s\n",
      "260:\tlearn: 0.0023747\ttotal: 19.4s\tremaining: 17.8s\n",
      "261:\tlearn: 0.0023552\ttotal: 19.5s\tremaining: 17.7s\n",
      "262:\tlearn: 0.0023552\ttotal: 19.5s\tremaining: 17.6s\n",
      "263:\tlearn: 0.0023390\ttotal: 19.6s\tremaining: 17.5s\n",
      "264:\tlearn: 0.0023265\ttotal: 19.7s\tremaining: 17.5s\n",
      "265:\tlearn: 0.0023035\ttotal: 19.7s\tremaining: 17.4s\n",
      "266:\tlearn: 0.0022904\ttotal: 19.9s\tremaining: 17.3s\n",
      "267:\tlearn: 0.0022903\ttotal: 19.9s\tremaining: 17.2s\n",
      "268:\tlearn: 0.0022738\ttotal: 20s\tremaining: 17.2s\n",
      "269:\tlearn: 0.0022552\ttotal: 20.1s\tremaining: 17.1s\n",
      "270:\tlearn: 0.0022375\ttotal: 20.1s\tremaining: 17s\n",
      "271:\tlearn: 0.0022190\ttotal: 20.2s\tremaining: 17s\n",
      "272:\tlearn: 0.0022190\ttotal: 20.3s\tremaining: 16.9s\n",
      "273:\tlearn: 0.0022190\ttotal: 20.4s\tremaining: 16.8s\n",
      "274:\tlearn: 0.0022190\ttotal: 20.4s\tremaining: 16.7s\n",
      "275:\tlearn: 0.0022189\ttotal: 20.5s\tremaining: 16.6s\n",
      "276:\tlearn: 0.0022189\ttotal: 20.6s\tremaining: 16.6s\n",
      "277:\tlearn: 0.0022189\ttotal: 20.6s\tremaining: 16.5s\n",
      "278:\tlearn: 0.0022188\ttotal: 20.7s\tremaining: 16.4s\n",
      "279:\tlearn: 0.0022189\ttotal: 20.8s\tremaining: 16.3s\n",
      "280:\tlearn: 0.0022186\ttotal: 20.9s\tremaining: 16.3s\n",
      "281:\tlearn: 0.0022011\ttotal: 21s\tremaining: 16.2s\n",
      "282:\tlearn: 0.0021873\ttotal: 21s\tremaining: 16.1s\n",
      "283:\tlearn: 0.0021668\ttotal: 21.1s\tremaining: 16.1s\n",
      "284:\tlearn: 0.0021667\ttotal: 21.2s\tremaining: 16s\n",
      "285:\tlearn: 0.0021499\ttotal: 21.3s\tremaining: 15.9s\n",
      "286:\tlearn: 0.0021499\ttotal: 21.3s\tremaining: 15.8s\n",
      "287:\tlearn: 0.0021499\ttotal: 21.4s\tremaining: 15.8s\n",
      "288:\tlearn: 0.0021498\ttotal: 21.5s\tremaining: 15.7s\n",
      "289:\tlearn: 0.0021498\ttotal: 21.5s\tremaining: 15.6s\n",
      "290:\tlearn: 0.0021498\ttotal: 21.6s\tremaining: 15.5s\n",
      "291:\tlearn: 0.0021497\ttotal: 21.7s\tremaining: 15.4s\n",
      "292:\tlearn: 0.0021332\ttotal: 21.8s\tremaining: 15.4s\n",
      "293:\tlearn: 0.0021332\ttotal: 21.8s\tremaining: 15.3s\n",
      "294:\tlearn: 0.0021332\ttotal: 22s\tremaining: 15.3s\n",
      "295:\tlearn: 0.0021332\ttotal: 22.1s\tremaining: 15.2s\n",
      "296:\tlearn: 0.0021332\ttotal: 22.1s\tremaining: 15.1s\n",
      "297:\tlearn: 0.0021332\ttotal: 22.2s\tremaining: 15.1s\n",
      "298:\tlearn: 0.0021332\ttotal: 22.2s\tremaining: 15s\n",
      "299:\tlearn: 0.0021332\ttotal: 22.4s\tremaining: 14.9s\n",
      "300:\tlearn: 0.0021332\ttotal: 22.4s\tremaining: 14.8s\n",
      "301:\tlearn: 0.0021331\ttotal: 22.5s\tremaining: 14.7s\n",
      "302:\tlearn: 0.0021328\ttotal: 22.6s\tremaining: 14.7s\n",
      "303:\tlearn: 0.0021328\ttotal: 22.6s\tremaining: 14.6s\n",
      "304:\tlearn: 0.0021328\ttotal: 22.7s\tremaining: 14.5s\n",
      "305:\tlearn: 0.0021328\ttotal: 22.8s\tremaining: 14.4s\n",
      "306:\tlearn: 0.0021328\ttotal: 22.8s\tremaining: 14.3s\n",
      "307:\tlearn: 0.0021327\ttotal: 22.9s\tremaining: 14.3s\n",
      "308:\tlearn: 0.0021327\ttotal: 23s\tremaining: 14.2s\n",
      "309:\tlearn: 0.0021191\ttotal: 23.1s\tremaining: 14.1s\n",
      "310:\tlearn: 0.0021029\ttotal: 23.1s\tremaining: 14.1s\n",
      "311:\tlearn: 0.0021029\ttotal: 23.2s\tremaining: 14s\n",
      "312:\tlearn: 0.0021029\ttotal: 23.3s\tremaining: 13.9s\n",
      "313:\tlearn: 0.0021029\ttotal: 23.3s\tremaining: 13.8s\n",
      "314:\tlearn: 0.0021028\ttotal: 23.4s\tremaining: 13.8s\n",
      "315:\tlearn: 0.0021028\ttotal: 23.5s\tremaining: 13.7s\n",
      "316:\tlearn: 0.0021028\ttotal: 23.6s\tremaining: 13.6s\n",
      "317:\tlearn: 0.0021028\ttotal: 23.6s\tremaining: 13.5s\n",
      "318:\tlearn: 0.0021029\ttotal: 23.7s\tremaining: 13.4s\n",
      "319:\tlearn: 0.0021028\ttotal: 23.8s\tremaining: 13.4s\n",
      "320:\tlearn: 0.0021028\ttotal: 23.8s\tremaining: 13.3s\n",
      "321:\tlearn: 0.0021028\ttotal: 24s\tremaining: 13.2s\n",
      "322:\tlearn: 0.0021028\ttotal: 24s\tremaining: 13.2s\n",
      "323:\tlearn: 0.0021027\ttotal: 24.1s\tremaining: 13.1s\n",
      "324:\tlearn: 0.0021027\ttotal: 24.2s\tremaining: 13s\n",
      "325:\tlearn: 0.0020889\ttotal: 24.2s\tremaining: 12.9s\n",
      "326:\tlearn: 0.0020889\ttotal: 24.3s\tremaining: 12.9s\n",
      "327:\tlearn: 0.0020888\ttotal: 24.4s\tremaining: 12.8s\n",
      "328:\tlearn: 0.0020888\ttotal: 24.4s\tremaining: 12.7s\n",
      "329:\tlearn: 0.0020888\ttotal: 24.5s\tremaining: 12.6s\n",
      "330:\tlearn: 0.0020889\ttotal: 24.6s\tremaining: 12.6s\n",
      "331:\tlearn: 0.0020888\ttotal: 24.7s\tremaining: 12.5s\n",
      "332:\tlearn: 0.0020888\ttotal: 24.8s\tremaining: 12.4s\n",
      "333:\tlearn: 0.0020888\ttotal: 24.9s\tremaining: 12.4s\n",
      "334:\tlearn: 0.0020701\ttotal: 24.9s\tremaining: 12.3s\n",
      "335:\tlearn: 0.0020700\ttotal: 25s\tremaining: 12.2s\n",
      "336:\tlearn: 0.0020700\ttotal: 25.1s\tremaining: 12.1s\n",
      "337:\tlearn: 0.0020567\ttotal: 25.1s\tremaining: 12s\n",
      "338:\tlearn: 0.0020567\ttotal: 25.2s\tremaining: 12s\n",
      "339:\tlearn: 0.0020567\ttotal: 25.3s\tremaining: 11.9s\n",
      "340:\tlearn: 0.0020567\ttotal: 25.3s\tremaining: 11.8s\n",
      "341:\tlearn: 0.0020567\ttotal: 25.4s\tremaining: 11.8s\n",
      "342:\tlearn: 0.0020567\ttotal: 25.5s\tremaining: 11.7s\n",
      "343:\tlearn: 0.0020567\ttotal: 25.6s\tremaining: 11.6s\n",
      "344:\tlearn: 0.0020412\ttotal: 25.7s\tremaining: 11.5s\n",
      "345:\tlearn: 0.0020412\ttotal: 25.8s\tremaining: 11.5s\n",
      "346:\tlearn: 0.0020412\ttotal: 25.8s\tremaining: 11.4s\n",
      "347:\tlearn: 0.0020412\ttotal: 25.9s\tremaining: 11.3s\n",
      "348:\tlearn: 0.0020412\ttotal: 26s\tremaining: 11.2s\n",
      "349:\tlearn: 0.0020412\ttotal: 26.1s\tremaining: 11.2s\n",
      "350:\tlearn: 0.0020250\ttotal: 26.1s\tremaining: 11.1s\n",
      "351:\tlearn: 0.0020249\ttotal: 26.2s\tremaining: 11s\n",
      "352:\tlearn: 0.0020250\ttotal: 26.3s\tremaining: 10.9s\n",
      "353:\tlearn: 0.0020250\ttotal: 26.4s\tremaining: 10.9s\n",
      "354:\tlearn: 0.0020250\ttotal: 26.4s\tremaining: 10.8s\n",
      "355:\tlearn: 0.0020250\ttotal: 26.5s\tremaining: 10.7s\n",
      "356:\tlearn: 0.0020249\ttotal: 26.6s\tremaining: 10.7s\n",
      "357:\tlearn: 0.0020249\ttotal: 26.7s\tremaining: 10.6s\n",
      "358:\tlearn: 0.0020249\ttotal: 26.7s\tremaining: 10.5s\n",
      "359:\tlearn: 0.0020249\ttotal: 26.8s\tremaining: 10.4s\n",
      "360:\tlearn: 0.0020248\ttotal: 26.9s\tremaining: 10.3s\n",
      "361:\tlearn: 0.0020248\ttotal: 27s\tremaining: 10.3s\n",
      "362:\tlearn: 0.0020248\ttotal: 27s\tremaining: 10.2s\n",
      "363:\tlearn: 0.0020248\ttotal: 27.1s\tremaining: 10.1s\n",
      "364:\tlearn: 0.0020248\ttotal: 27.2s\tremaining: 10.1s\n",
      "365:\tlearn: 0.0020037\ttotal: 27.2s\tremaining: 9.97s\n",
      "366:\tlearn: 0.0020037\ttotal: 27.3s\tremaining: 9.9s\n",
      "367:\tlearn: 0.0020037\ttotal: 27.4s\tremaining: 9.82s\n",
      "368:\tlearn: 0.0020037\ttotal: 27.4s\tremaining: 9.73s\n",
      "369:\tlearn: 0.0020036\ttotal: 27.5s\tremaining: 9.67s\n",
      "370:\tlearn: 0.0020036\ttotal: 27.6s\tremaining: 9.59s\n",
      "371:\tlearn: 0.0020036\ttotal: 27.7s\tremaining: 9.53s\n",
      "372:\tlearn: 0.0020036\ttotal: 27.7s\tremaining: 9.45s\n",
      "373:\tlearn: 0.0020035\ttotal: 27.9s\tremaining: 9.39s\n",
      "374:\tlearn: 0.0019871\ttotal: 27.9s\tremaining: 9.31s\n",
      "375:\tlearn: 0.0019871\ttotal: 28.1s\tremaining: 9.25s\n",
      "376:\tlearn: 0.0019871\ttotal: 28.1s\tremaining: 9.17s\n",
      "377:\tlearn: 0.0019871\ttotal: 28.1s\tremaining: 9.08s\n",
      "378:\tlearn: 0.0019871\ttotal: 28.2s\tremaining: 9.02s\n",
      "379:\tlearn: 0.0019871\ttotal: 28.3s\tremaining: 8.93s\n",
      "380:\tlearn: 0.0019871\ttotal: 28.4s\tremaining: 8.86s\n",
      "381:\tlearn: 0.0019871\ttotal: 28.4s\tremaining: 8.79s\n",
      "382:\tlearn: 0.0019871\ttotal: 28.5s\tremaining: 8.7s\n",
      "383:\tlearn: 0.0019870\ttotal: 28.6s\tremaining: 8.64s\n",
      "384:\tlearn: 0.0019871\ttotal: 28.6s\tremaining: 8.56s\n",
      "385:\tlearn: 0.0019845\ttotal: 28.8s\tremaining: 8.49s\n",
      "386:\tlearn: 0.0019845\ttotal: 28.8s\tremaining: 8.41s\n",
      "387:\tlearn: 0.0019845\ttotal: 28.9s\tremaining: 8.34s\n",
      "388:\tlearn: 0.0019844\ttotal: 29s\tremaining: 8.27s\n",
      "389:\tlearn: 0.0019844\ttotal: 29s\tremaining: 8.19s\n",
      "390:\tlearn: 0.0019844\ttotal: 29.1s\tremaining: 8.11s\n",
      "391:\tlearn: 0.0019844\ttotal: 29.2s\tremaining: 8.04s\n",
      "392:\tlearn: 0.0019844\ttotal: 29.2s\tremaining: 7.96s\n",
      "393:\tlearn: 0.0019844\ttotal: 29.3s\tremaining: 7.89s\n",
      "394:\tlearn: 0.0019844\ttotal: 29.4s\tremaining: 7.82s\n",
      "395:\tlearn: 0.0019843\ttotal: 29.5s\tremaining: 7.75s\n",
      "396:\tlearn: 0.0019843\ttotal: 29.6s\tremaining: 7.67s\n",
      "397:\tlearn: 0.0019678\ttotal: 29.6s\tremaining: 7.59s\n",
      "398:\tlearn: 0.0019677\ttotal: 29.7s\tremaining: 7.52s\n",
      "399:\tlearn: 0.0019677\ttotal: 29.8s\tremaining: 7.44s\n",
      "400:\tlearn: 0.0019677\ttotal: 29.8s\tremaining: 7.36s\n",
      "401:\tlearn: 0.0019676\ttotal: 29.9s\tremaining: 7.3s\n",
      "402:\tlearn: 0.0019676\ttotal: 30s\tremaining: 7.22s\n",
      "403:\tlearn: 0.0019544\ttotal: 30.1s\tremaining: 7.15s\n",
      "404:\tlearn: 0.0019544\ttotal: 30.2s\tremaining: 7.08s\n",
      "405:\tlearn: 0.0019544\ttotal: 30.2s\tremaining: 6.99s\n",
      "406:\tlearn: 0.0019544\ttotal: 30.3s\tremaining: 6.93s\n",
      "407:\tlearn: 0.0019544\ttotal: 30.4s\tremaining: 6.85s\n",
      "408:\tlearn: 0.0019543\ttotal: 30.5s\tremaining: 6.78s\n",
      "409:\tlearn: 0.0019397\ttotal: 30.5s\tremaining: 6.7s\n",
      "410:\tlearn: 0.0019397\ttotal: 30.6s\tremaining: 6.63s\n",
      "411:\tlearn: 0.0019397\ttotal: 30.7s\tremaining: 6.56s\n",
      "412:\tlearn: 0.0019397\ttotal: 30.8s\tremaining: 6.48s\n",
      "413:\tlearn: 0.0019397\ttotal: 30.9s\tremaining: 6.41s\n",
      "414:\tlearn: 0.0019397\ttotal: 30.9s\tremaining: 6.33s\n",
      "415:\tlearn: 0.0019397\ttotal: 31s\tremaining: 6.26s\n",
      "416:\tlearn: 0.0019397\ttotal: 31.1s\tremaining: 6.18s\n",
      "417:\tlearn: 0.0019253\ttotal: 31.1s\tremaining: 6.1s\n",
      "418:\tlearn: 0.0019066\ttotal: 31.2s\tremaining: 6.04s\n",
      "419:\tlearn: 0.0019066\ttotal: 31.3s\tremaining: 5.96s\n",
      "420:\tlearn: 0.0019066\ttotal: 31.4s\tremaining: 5.89s\n",
      "421:\tlearn: 0.0019066\ttotal: 31.5s\tremaining: 5.81s\n",
      "422:\tlearn: 0.0019066\ttotal: 31.6s\tremaining: 5.74s\n",
      "423:\tlearn: 0.0019066\ttotal: 31.6s\tremaining: 5.67s\n",
      "424:\tlearn: 0.0019066\ttotal: 31.7s\tremaining: 5.6s\n",
      "425:\tlearn: 0.0019066\ttotal: 31.8s\tremaining: 5.53s\n",
      "426:\tlearn: 0.0019066\ttotal: 31.8s\tremaining: 5.44s\n",
      "427:\tlearn: 0.0019066\ttotal: 31.9s\tremaining: 5.37s\n",
      "428:\tlearn: 0.0018963\ttotal: 32s\tremaining: 5.29s\n",
      "429:\tlearn: 0.0018829\ttotal: 32.1s\tremaining: 5.22s\n",
      "430:\tlearn: 0.0018829\ttotal: 32.1s\tremaining: 5.15s\n",
      "431:\tlearn: 0.0018828\ttotal: 32.2s\tremaining: 5.07s\n",
      "432:\tlearn: 0.0018828\ttotal: 32.4s\tremaining: 5.01s\n",
      "433:\tlearn: 0.0018828\ttotal: 32.4s\tremaining: 4.93s\n",
      "434:\tlearn: 0.0018828\ttotal: 32.6s\tremaining: 4.87s\n",
      "435:\tlearn: 0.0018769\ttotal: 32.6s\tremaining: 4.79s\n",
      "436:\tlearn: 0.0018769\ttotal: 32.7s\tremaining: 4.71s\n",
      "437:\tlearn: 0.0018768\ttotal: 32.7s\tremaining: 4.63s\n",
      "438:\tlearn: 0.0018767\ttotal: 32.8s\tremaining: 4.55s\n",
      "439:\tlearn: 0.0018672\ttotal: 32.9s\tremaining: 4.49s\n",
      "440:\tlearn: 0.0018672\ttotal: 32.9s\tremaining: 4.41s\n",
      "441:\tlearn: 0.0018671\ttotal: 33s\tremaining: 4.33s\n",
      "442:\tlearn: 0.0018670\ttotal: 33.1s\tremaining: 4.26s\n",
      "443:\tlearn: 0.0018671\ttotal: 33.2s\tremaining: 4.18s\n",
      "444:\tlearn: 0.0018670\ttotal: 33.3s\tremaining: 4.11s\n",
      "445:\tlearn: 0.0018669\ttotal: 33.3s\tremaining: 4.03s\n",
      "446:\tlearn: 0.0018669\ttotal: 33.4s\tremaining: 3.96s\n",
      "447:\tlearn: 0.0018669\ttotal: 33.5s\tremaining: 3.88s\n",
      "448:\tlearn: 0.0018668\ttotal: 33.6s\tremaining: 3.81s\n",
      "449:\tlearn: 0.0018668\ttotal: 33.7s\tremaining: 3.74s\n",
      "450:\tlearn: 0.0018668\ttotal: 33.8s\tremaining: 3.67s\n",
      "451:\tlearn: 0.0018668\ttotal: 33.8s\tremaining: 3.59s\n",
      "452:\tlearn: 0.0018562\ttotal: 33.9s\tremaining: 3.52s\n",
      "453:\tlearn: 0.0018561\ttotal: 34s\tremaining: 3.44s\n",
      "454:\tlearn: 0.0018561\ttotal: 34s\tremaining: 3.37s\n",
      "455:\tlearn: 0.0018561\ttotal: 34.1s\tremaining: 3.29s\n",
      "456:\tlearn: 0.0018561\ttotal: 34.2s\tremaining: 3.22s\n",
      "457:\tlearn: 0.0018560\ttotal: 34.3s\tremaining: 3.15s\n",
      "458:\tlearn: 0.0018560\ttotal: 34.3s\tremaining: 3.07s\n",
      "459:\tlearn: 0.0018560\ttotal: 34.5s\tremaining: 3s\n",
      "460:\tlearn: 0.0018560\ttotal: 34.5s\tremaining: 2.92s\n",
      "461:\tlearn: 0.0018560\ttotal: 34.6s\tremaining: 2.85s\n",
      "462:\tlearn: 0.0018560\ttotal: 34.7s\tremaining: 2.77s\n",
      "463:\tlearn: 0.0018560\ttotal: 34.7s\tremaining: 2.69s\n",
      "464:\tlearn: 0.0018559\ttotal: 34.8s\tremaining: 2.62s\n",
      "465:\tlearn: 0.0018559\ttotal: 34.9s\tremaining: 2.54s\n",
      "466:\tlearn: 0.0018559\ttotal: 35s\tremaining: 2.47s\n",
      "467:\tlearn: 0.0018559\ttotal: 35s\tremaining: 2.4s\n",
      "468:\tlearn: 0.0018559\ttotal: 35.1s\tremaining: 2.32s\n",
      "469:\tlearn: 0.0018559\ttotal: 35.2s\tremaining: 2.25s\n",
      "470:\tlearn: 0.0018558\ttotal: 35.2s\tremaining: 2.17s\n",
      "471:\tlearn: 0.0018558\ttotal: 35.4s\tremaining: 2.1s\n",
      "472:\tlearn: 0.0018558\ttotal: 35.4s\tremaining: 2.02s\n",
      "473:\tlearn: 0.0018558\ttotal: 35.5s\tremaining: 1.95s\n",
      "474:\tlearn: 0.0018558\ttotal: 35.6s\tremaining: 1.87s\n",
      "475:\tlearn: 0.0018558\ttotal: 35.6s\tremaining: 1.79s\n",
      "476:\tlearn: 0.0018558\ttotal: 35.7s\tremaining: 1.72s\n",
      "477:\tlearn: 0.0018558\ttotal: 35.8s\tremaining: 1.65s\n",
      "478:\tlearn: 0.0018558\ttotal: 35.9s\tremaining: 1.57s\n",
      "479:\tlearn: 0.0018557\ttotal: 36s\tremaining: 1.5s\n",
      "480:\tlearn: 0.0018557\ttotal: 36s\tremaining: 1.42s\n",
      "481:\tlearn: 0.0018557\ttotal: 36.1s\tremaining: 1.35s\n",
      "482:\tlearn: 0.0018557\ttotal: 36.2s\tremaining: 1.27s\n",
      "483:\tlearn: 0.0018557\ttotal: 36.3s\tremaining: 1.2s\n",
      "484:\tlearn: 0.0018557\ttotal: 36.4s\tremaining: 1.12s\n",
      "485:\tlearn: 0.0018557\ttotal: 36.4s\tremaining: 1.05s\n",
      "486:\tlearn: 0.0018419\ttotal: 36.5s\tremaining: 975ms\n",
      "487:\tlearn: 0.0018418\ttotal: 36.6s\tremaining: 899ms\n",
      "488:\tlearn: 0.0018418\ttotal: 36.7s\tremaining: 825ms\n",
      "489:\tlearn: 0.0018417\ttotal: 36.7s\tremaining: 749ms\n",
      "490:\tlearn: 0.0018417\ttotal: 36.8s\tremaining: 675ms\n",
      "491:\tlearn: 0.0018417\ttotal: 36.9s\tremaining: 599ms\n",
      "492:\tlearn: 0.0018417\ttotal: 37s\tremaining: 525ms\n",
      "493:\tlearn: 0.0018417\ttotal: 37s\tremaining: 450ms\n",
      "494:\tlearn: 0.0018417\ttotal: 37.1s\tremaining: 375ms\n",
      "495:\tlearn: 0.0018417\ttotal: 37.2s\tremaining: 300ms\n",
      "496:\tlearn: 0.0018417\ttotal: 37.2s\tremaining: 225ms\n",
      "497:\tlearn: 0.0018417\ttotal: 37.4s\tremaining: 150ms\n",
      "498:\tlearn: 0.0018417\ttotal: 37.4s\tremaining: 75ms\n",
      "499:\tlearn: 0.0018417\ttotal: 37.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6568969\ttotal: 49.5ms\tremaining: 24.7s\n",
      "1:\tlearn: 0.6145058\ttotal: 164ms\tremaining: 40.8s\n",
      "2:\tlearn: 0.5793754\ttotal: 212ms\tremaining: 35.2s\n",
      "3:\tlearn: 0.5474520\ttotal: 254ms\tremaining: 31.5s\n",
      "4:\tlearn: 0.5236806\ttotal: 364ms\tremaining: 36s\n",
      "5:\tlearn: 0.4900109\ttotal: 410ms\tremaining: 33.8s\n",
      "6:\tlearn: 0.4651137\ttotal: 526ms\tremaining: 37s\n",
      "7:\tlearn: 0.4420392\ttotal: 580ms\tremaining: 35.7s\n",
      "8:\tlearn: 0.4156128\ttotal: 669ms\tremaining: 36.5s\n",
      "9:\tlearn: 0.3987840\ttotal: 729ms\tremaining: 35.7s\n",
      "10:\tlearn: 0.3812363\ttotal: 834ms\tremaining: 37.1s\n",
      "11:\tlearn: 0.3639299\ttotal: 902ms\tremaining: 36.7s\n",
      "12:\tlearn: 0.3478085\ttotal: 995ms\tremaining: 37.3s\n",
      "13:\tlearn: 0.3321573\ttotal: 1.07s\tremaining: 37.2s\n",
      "14:\tlearn: 0.3152275\ttotal: 1.13s\tremaining: 36.6s\n",
      "15:\tlearn: 0.2959174\ttotal: 1.24s\tremaining: 37.4s\n",
      "16:\tlearn: 0.2810570\ttotal: 1.28s\tremaining: 36.4s\n",
      "17:\tlearn: 0.2681951\ttotal: 1.41s\tremaining: 37.8s\n",
      "18:\tlearn: 0.2573277\ttotal: 1.46s\tremaining: 36.9s\n",
      "19:\tlearn: 0.2434130\ttotal: 1.58s\tremaining: 38s\n",
      "20:\tlearn: 0.2368761\ttotal: 1.63s\tremaining: 37.1s\n",
      "21:\tlearn: 0.2251866\ttotal: 1.74s\tremaining: 37.9s\n",
      "22:\tlearn: 0.2167803\ttotal: 1.81s\tremaining: 37.6s\n",
      "23:\tlearn: 0.2057029\ttotal: 1.85s\tremaining: 36.7s\n",
      "24:\tlearn: 0.1994093\ttotal: 1.97s\tremaining: 37.4s\n",
      "25:\tlearn: 0.1923363\ttotal: 2.02s\tremaining: 36.8s\n",
      "26:\tlearn: 0.1846505\ttotal: 2.06s\tremaining: 36.1s\n",
      "27:\tlearn: 0.1780078\ttotal: 2.19s\tremaining: 36.9s\n",
      "28:\tlearn: 0.1699685\ttotal: 2.24s\tremaining: 36.4s\n",
      "29:\tlearn: 0.1640639\ttotal: 2.33s\tremaining: 36.5s\n",
      "30:\tlearn: 0.1580215\ttotal: 2.42s\tremaining: 36.7s\n",
      "31:\tlearn: 0.1510870\ttotal: 2.47s\tremaining: 36.1s\n",
      "32:\tlearn: 0.1442921\ttotal: 2.59s\tremaining: 36.6s\n",
      "33:\tlearn: 0.1392557\ttotal: 2.63s\tremaining: 36.1s\n",
      "34:\tlearn: 0.1330746\ttotal: 2.73s\tremaining: 36.2s\n",
      "35:\tlearn: 0.1303053\ttotal: 2.8s\tremaining: 36.1s\n",
      "36:\tlearn: 0.1240518\ttotal: 2.85s\tremaining: 35.6s\n",
      "37:\tlearn: 0.1203196\ttotal: 2.96s\tremaining: 35.9s\n",
      "38:\tlearn: 0.1150216\ttotal: 3s\tremaining: 35.5s\n",
      "39:\tlearn: 0.1096807\ttotal: 3.13s\tremaining: 36s\n",
      "40:\tlearn: 0.1070712\ttotal: 3.17s\tremaining: 35.5s\n",
      "41:\tlearn: 0.1037543\ttotal: 3.26s\tremaining: 35.6s\n",
      "42:\tlearn: 0.1012381\ttotal: 3.34s\tremaining: 35.5s\n",
      "43:\tlearn: 0.0988499\ttotal: 3.38s\tremaining: 35s\n",
      "44:\tlearn: 0.0939167\ttotal: 3.5s\tremaining: 35.3s\n",
      "45:\tlearn: 0.0910354\ttotal: 3.54s\tremaining: 35s\n",
      "46:\tlearn: 0.0880196\ttotal: 3.67s\tremaining: 35.4s\n",
      "47:\tlearn: 0.0849998\ttotal: 3.71s\tremaining: 35s\n",
      "48:\tlearn: 0.0830073\ttotal: 3.81s\tremaining: 35.1s\n",
      "49:\tlearn: 0.0805970\ttotal: 3.88s\tremaining: 34.9s\n",
      "50:\tlearn: 0.0785756\ttotal: 3.94s\tremaining: 34.7s\n",
      "51:\tlearn: 0.0765902\ttotal: 4.04s\tremaining: 34.8s\n",
      "52:\tlearn: 0.0748482\ttotal: 4.08s\tremaining: 34.4s\n",
      "53:\tlearn: 0.0723217\ttotal: 4.21s\tremaining: 34.8s\n",
      "54:\tlearn: 0.0693453\ttotal: 4.26s\tremaining: 34.5s\n",
      "55:\tlearn: 0.0674137\ttotal: 4.3s\tremaining: 34.1s\n",
      "56:\tlearn: 0.0654671\ttotal: 4.42s\tremaining: 34.4s\n",
      "57:\tlearn: 0.0628807\ttotal: 4.48s\tremaining: 34.1s\n",
      "58:\tlearn: 0.0611609\ttotal: 4.59s\tremaining: 34.3s\n",
      "59:\tlearn: 0.0589041\ttotal: 4.64s\tremaining: 34s\n",
      "60:\tlearn: 0.0571361\ttotal: 4.74s\tremaining: 34.1s\n",
      "61:\tlearn: 0.0553161\ttotal: 4.8s\tremaining: 33.9s\n",
      "62:\tlearn: 0.0534128\ttotal: 4.85s\tremaining: 33.6s\n",
      "63:\tlearn: 0.0513284\ttotal: 4.96s\tremaining: 33.8s\n",
      "64:\tlearn: 0.0493676\ttotal: 5s\tremaining: 33.5s\n",
      "65:\tlearn: 0.0484030\ttotal: 5.12s\tremaining: 33.7s\n",
      "66:\tlearn: 0.0461420\ttotal: 5.2s\tremaining: 33.6s\n",
      "67:\tlearn: 0.0445286\ttotal: 5.24s\tremaining: 33.3s\n",
      "68:\tlearn: 0.0435638\ttotal: 5.33s\tremaining: 33.3s\n",
      "69:\tlearn: 0.0421831\ttotal: 5.38s\tremaining: 33.1s\n",
      "70:\tlearn: 0.0408095\ttotal: 5.49s\tremaining: 33.2s\n",
      "71:\tlearn: 0.0399154\ttotal: 5.55s\tremaining: 33s\n",
      "72:\tlearn: 0.0386808\ttotal: 5.6s\tremaining: 32.8s\n",
      "73:\tlearn: 0.0371357\ttotal: 5.72s\tremaining: 32.9s\n",
      "74:\tlearn: 0.0364233\ttotal: 5.76s\tremaining: 32.7s\n",
      "75:\tlearn: 0.0354432\ttotal: 5.86s\tremaining: 32.7s\n",
      "76:\tlearn: 0.0344541\ttotal: 5.92s\tremaining: 32.5s\n",
      "77:\tlearn: 0.0334621\ttotal: 5.96s\tremaining: 32.3s\n",
      "78:\tlearn: 0.0326898\ttotal: 6.07s\tremaining: 32.3s\n",
      "79:\tlearn: 0.0314220\ttotal: 6.11s\tremaining: 32.1s\n",
      "80:\tlearn: 0.0309369\ttotal: 6.23s\tremaining: 32.2s\n",
      "81:\tlearn: 0.0301100\ttotal: 6.27s\tremaining: 32s\n",
      "82:\tlearn: 0.0293648\ttotal: 6.37s\tremaining: 32s\n",
      "83:\tlearn: 0.0282125\ttotal: 6.42s\tremaining: 31.8s\n",
      "84:\tlearn: 0.0274935\ttotal: 6.52s\tremaining: 31.8s\n",
      "85:\tlearn: 0.0271288\ttotal: 6.58s\tremaining: 31.7s\n",
      "86:\tlearn: 0.0261930\ttotal: 6.69s\tremaining: 31.8s\n",
      "87:\tlearn: 0.0251625\ttotal: 6.74s\tremaining: 31.6s\n",
      "88:\tlearn: 0.0243053\ttotal: 6.85s\tremaining: 31.6s\n",
      "89:\tlearn: 0.0234935\ttotal: 6.91s\tremaining: 31.5s\n",
      "90:\tlearn: 0.0228799\ttotal: 7.01s\tremaining: 31.5s\n",
      "91:\tlearn: 0.0220457\ttotal: 7.08s\tremaining: 31.4s\n",
      "92:\tlearn: 0.0212736\ttotal: 7.12s\tremaining: 31.2s\n",
      "93:\tlearn: 0.0206253\ttotal: 7.24s\tremaining: 31.3s\n",
      "94:\tlearn: 0.0202211\ttotal: 7.29s\tremaining: 31.1s\n",
      "95:\tlearn: 0.0196756\ttotal: 7.38s\tremaining: 31.1s\n",
      "96:\tlearn: 0.0191474\ttotal: 7.43s\tremaining: 30.9s\n",
      "97:\tlearn: 0.0187646\ttotal: 7.47s\tremaining: 30.7s\n",
      "98:\tlearn: 0.0182743\ttotal: 7.59s\tremaining: 30.8s\n",
      "99:\tlearn: 0.0178321\ttotal: 7.64s\tremaining: 30.6s\n",
      "100:\tlearn: 0.0172996\ttotal: 7.77s\tremaining: 30.7s\n",
      "101:\tlearn: 0.0168300\ttotal: 7.82s\tremaining: 30.5s\n",
      "102:\tlearn: 0.0164937\ttotal: 7.91s\tremaining: 30.5s\n",
      "103:\tlearn: 0.0162136\ttotal: 7.97s\tremaining: 30.4s\n",
      "104:\tlearn: 0.0157279\ttotal: 8.02s\tremaining: 30.2s\n",
      "105:\tlearn: 0.0152416\ttotal: 8.14s\tremaining: 30.3s\n",
      "106:\tlearn: 0.0149679\ttotal: 8.18s\tremaining: 30.1s\n",
      "107:\tlearn: 0.0147352\ttotal: 8.29s\tremaining: 30.1s\n",
      "108:\tlearn: 0.0144029\ttotal: 8.36s\tremaining: 30s\n",
      "109:\tlearn: 0.0141036\ttotal: 8.4s\tremaining: 29.8s\n",
      "110:\tlearn: 0.0137271\ttotal: 8.52s\tremaining: 29.9s\n",
      "111:\tlearn: 0.0134732\ttotal: 8.57s\tremaining: 29.7s\n",
      "112:\tlearn: 0.0131768\ttotal: 8.68s\tremaining: 29.7s\n",
      "113:\tlearn: 0.0129830\ttotal: 8.73s\tremaining: 29.6s\n",
      "114:\tlearn: 0.0127107\ttotal: 8.83s\tremaining: 29.6s\n",
      "115:\tlearn: 0.0124532\ttotal: 8.9s\tremaining: 29.5s\n",
      "116:\tlearn: 0.0122793\ttotal: 8.95s\tremaining: 29.3s\n",
      "117:\tlearn: 0.0119660\ttotal: 9.06s\tremaining: 29.3s\n",
      "118:\tlearn: 0.0117431\ttotal: 9.11s\tremaining: 29.2s\n",
      "119:\tlearn: 0.0115367\ttotal: 9.21s\tremaining: 29.2s\n",
      "120:\tlearn: 0.0113265\ttotal: 9.27s\tremaining: 29s\n",
      "121:\tlearn: 0.0111102\ttotal: 9.31s\tremaining: 28.8s\n",
      "122:\tlearn: 0.0108354\ttotal: 9.42s\tremaining: 28.9s\n",
      "123:\tlearn: 0.0106371\ttotal: 9.46s\tremaining: 28.7s\n",
      "124:\tlearn: 0.0104515\ttotal: 9.59s\tremaining: 28.8s\n",
      "125:\tlearn: 0.0103151\ttotal: 9.63s\tremaining: 28.6s\n",
      "126:\tlearn: 0.0101031\ttotal: 9.68s\tremaining: 28.4s\n",
      "127:\tlearn: 0.0099575\ttotal: 9.8s\tremaining: 28.5s\n",
      "128:\tlearn: 0.0097815\ttotal: 9.84s\tremaining: 28.3s\n",
      "129:\tlearn: 0.0095837\ttotal: 9.95s\tremaining: 28.3s\n",
      "130:\tlearn: 0.0093991\ttotal: 10s\tremaining: 28.2s\n",
      "131:\tlearn: 0.0091809\ttotal: 10.1s\tremaining: 28.1s\n",
      "132:\tlearn: 0.0089984\ttotal: 10.2s\tremaining: 28.1s\n",
      "133:\tlearn: 0.0088308\ttotal: 10.2s\tremaining: 27.9s\n",
      "134:\tlearn: 0.0086846\ttotal: 10.3s\tremaining: 27.9s\n",
      "135:\tlearn: 0.0085532\ttotal: 10.4s\tremaining: 27.8s\n",
      "136:\tlearn: 0.0084138\ttotal: 10.4s\tremaining: 27.6s\n",
      "137:\tlearn: 0.0082842\ttotal: 10.5s\tremaining: 27.6s\n",
      "138:\tlearn: 0.0081482\ttotal: 10.6s\tremaining: 27.5s\n",
      "139:\tlearn: 0.0079860\ttotal: 10.7s\tremaining: 27.5s\n",
      "140:\tlearn: 0.0078899\ttotal: 10.7s\tremaining: 27.3s\n",
      "141:\tlearn: 0.0077928\ttotal: 10.8s\tremaining: 27.3s\n",
      "142:\tlearn: 0.0076358\ttotal: 10.9s\tremaining: 27.2s\n",
      "143:\tlearn: 0.0075522\ttotal: 11s\tremaining: 27.2s\n",
      "144:\tlearn: 0.0074574\ttotal: 11.1s\tremaining: 27.1s\n",
      "145:\tlearn: 0.0073047\ttotal: 11.1s\tremaining: 27s\n",
      "146:\tlearn: 0.0071942\ttotal: 11.2s\tremaining: 26.9s\n",
      "147:\tlearn: 0.0070568\ttotal: 11.3s\tremaining: 26.8s\n",
      "148:\tlearn: 0.0069338\ttotal: 11.3s\tremaining: 26.7s\n",
      "149:\tlearn: 0.0068138\ttotal: 11.4s\tremaining: 26.6s\n",
      "150:\tlearn: 0.0067087\ttotal: 11.5s\tremaining: 26.6s\n",
      "151:\tlearn: 0.0066143\ttotal: 11.6s\tremaining: 26.5s\n",
      "152:\tlearn: 0.0065456\ttotal: 11.6s\tremaining: 26.4s\n",
      "153:\tlearn: 0.0064727\ttotal: 11.7s\tremaining: 26.3s\n",
      "154:\tlearn: 0.0063791\ttotal: 11.8s\tremaining: 26.2s\n",
      "155:\tlearn: 0.0063006\ttotal: 11.9s\tremaining: 26.2s\n",
      "156:\tlearn: 0.0062407\ttotal: 11.9s\tremaining: 26.1s\n",
      "157:\tlearn: 0.0061531\ttotal: 12s\tremaining: 26s\n",
      "158:\tlearn: 0.0060726\ttotal: 12.1s\tremaining: 25.9s\n",
      "159:\tlearn: 0.0059684\ttotal: 12.2s\tremaining: 25.8s\n",
      "160:\tlearn: 0.0059100\ttotal: 12.3s\tremaining: 25.8s\n",
      "161:\tlearn: 0.0058133\ttotal: 12.3s\tremaining: 25.6s\n",
      "162:\tlearn: 0.0057446\ttotal: 12.4s\tremaining: 25.7s\n",
      "163:\tlearn: 0.0056563\ttotal: 12.5s\tremaining: 25.5s\n",
      "164:\tlearn: 0.0055833\ttotal: 12.5s\tremaining: 25.4s\n",
      "165:\tlearn: 0.0055148\ttotal: 12.6s\tremaining: 25.4s\n",
      "166:\tlearn: 0.0054351\ttotal: 12.7s\tremaining: 25.3s\n",
      "167:\tlearn: 0.0053753\ttotal: 12.8s\tremaining: 25.3s\n",
      "168:\tlearn: 0.0052924\ttotal: 12.8s\tremaining: 25.1s\n",
      "169:\tlearn: 0.0052337\ttotal: 12.9s\tremaining: 25.1s\n",
      "170:\tlearn: 0.0051508\ttotal: 13s\tremaining: 25s\n",
      "171:\tlearn: 0.0050798\ttotal: 13.1s\tremaining: 24.9s\n",
      "172:\tlearn: 0.0050211\ttotal: 13.2s\tremaining: 24.9s\n",
      "173:\tlearn: 0.0049548\ttotal: 13.2s\tremaining: 24.7s\n",
      "174:\tlearn: 0.0049053\ttotal: 13.3s\tremaining: 24.7s\n",
      "175:\tlearn: 0.0048474\ttotal: 13.4s\tremaining: 24.6s\n",
      "176:\tlearn: 0.0047734\ttotal: 13.5s\tremaining: 24.6s\n",
      "177:\tlearn: 0.0047300\ttotal: 13.5s\tremaining: 24.5s\n",
      "178:\tlearn: 0.0046609\ttotal: 13.6s\tremaining: 24.5s\n",
      "179:\tlearn: 0.0046147\ttotal: 13.7s\tremaining: 24.4s\n",
      "180:\tlearn: 0.0045640\ttotal: 13.8s\tremaining: 24.4s\n",
      "181:\tlearn: 0.0045067\ttotal: 13.9s\tremaining: 24.2s\n",
      "182:\tlearn: 0.0044587\ttotal: 13.9s\tremaining: 24.1s\n",
      "183:\tlearn: 0.0044276\ttotal: 14s\tremaining: 24.1s\n",
      "184:\tlearn: 0.0043715\ttotal: 14.1s\tremaining: 24s\n",
      "185:\tlearn: 0.0043180\ttotal: 14.2s\tremaining: 23.9s\n",
      "186:\tlearn: 0.0042628\ttotal: 14.2s\tremaining: 23.8s\n",
      "187:\tlearn: 0.0042082\ttotal: 14.3s\tremaining: 23.7s\n",
      "188:\tlearn: 0.0041711\ttotal: 14.4s\tremaining: 23.7s\n",
      "189:\tlearn: 0.0041155\ttotal: 14.4s\tremaining: 23.6s\n",
      "190:\tlearn: 0.0040722\ttotal: 14.5s\tremaining: 23.5s\n",
      "191:\tlearn: 0.0040304\ttotal: 14.6s\tremaining: 23.4s\n",
      "192:\tlearn: 0.0039938\ttotal: 14.6s\tremaining: 23.3s\n",
      "193:\tlearn: 0.0039412\ttotal: 14.8s\tremaining: 23.3s\n",
      "194:\tlearn: 0.0038925\ttotal: 14.8s\tremaining: 23.2s\n",
      "195:\tlearn: 0.0038388\ttotal: 14.9s\tremaining: 23.1s\n",
      "196:\tlearn: 0.0038042\ttotal: 15s\tremaining: 23s\n",
      "197:\tlearn: 0.0037621\ttotal: 15s\tremaining: 22.9s\n",
      "198:\tlearn: 0.0037336\ttotal: 15.1s\tremaining: 22.8s\n",
      "199:\tlearn: 0.0036929\ttotal: 15.1s\tremaining: 22.7s\n",
      "200:\tlearn: 0.0036511\ttotal: 15.3s\tremaining: 22.7s\n",
      "201:\tlearn: 0.0036235\ttotal: 15.3s\tremaining: 22.6s\n",
      "202:\tlearn: 0.0035989\ttotal: 15.4s\tremaining: 22.6s\n",
      "203:\tlearn: 0.0035652\ttotal: 15.5s\tremaining: 22.5s\n",
      "204:\tlearn: 0.0035323\ttotal: 15.6s\tremaining: 22.5s\n",
      "205:\tlearn: 0.0034979\ttotal: 15.7s\tremaining: 22.3s\n",
      "206:\tlearn: 0.0034620\ttotal: 15.8s\tremaining: 22.3s\n",
      "207:\tlearn: 0.0034192\ttotal: 15.8s\tremaining: 22.2s\n",
      "208:\tlearn: 0.0033827\ttotal: 15.9s\tremaining: 22.1s\n",
      "209:\tlearn: 0.0033435\ttotal: 15.9s\tremaining: 22s\n",
      "210:\tlearn: 0.0033016\ttotal: 16s\tremaining: 21.9s\n",
      "211:\tlearn: 0.0032601\ttotal: 16s\tremaining: 21.8s\n",
      "212:\tlearn: 0.0032326\ttotal: 16.1s\tremaining: 21.8s\n",
      "213:\tlearn: 0.0032058\ttotal: 16.2s\tremaining: 21.6s\n",
      "214:\tlearn: 0.0031711\ttotal: 16.3s\tremaining: 21.6s\n",
      "215:\tlearn: 0.0031477\ttotal: 16.4s\tremaining: 21.5s\n",
      "216:\tlearn: 0.0031194\ttotal: 16.5s\tremaining: 21.5s\n",
      "217:\tlearn: 0.0030957\ttotal: 16.5s\tremaining: 21.4s\n",
      "218:\tlearn: 0.0030585\ttotal: 16.6s\tremaining: 21.3s\n",
      "219:\tlearn: 0.0030347\ttotal: 16.7s\tremaining: 21.2s\n",
      "220:\tlearn: 0.0030046\ttotal: 16.7s\tremaining: 21.1s\n",
      "221:\tlearn: 0.0029603\ttotal: 16.8s\tremaining: 21.1s\n",
      "222:\tlearn: 0.0029400\ttotal: 16.9s\tremaining: 21s\n",
      "223:\tlearn: 0.0029127\ttotal: 17s\tremaining: 20.9s\n",
      "224:\tlearn: 0.0028909\ttotal: 17s\tremaining: 20.8s\n",
      "225:\tlearn: 0.0028908\ttotal: 17.1s\tremaining: 20.7s\n",
      "226:\tlearn: 0.0028761\ttotal: 17.2s\tremaining: 20.7s\n",
      "227:\tlearn: 0.0028540\ttotal: 17.2s\tremaining: 20.6s\n",
      "228:\tlearn: 0.0028540\ttotal: 17.3s\tremaining: 20.5s\n",
      "229:\tlearn: 0.0028539\ttotal: 17.4s\tremaining: 20.4s\n",
      "230:\tlearn: 0.0028539\ttotal: 17.5s\tremaining: 20.3s\n",
      "231:\tlearn: 0.0028539\ttotal: 17.5s\tremaining: 20.3s\n",
      "232:\tlearn: 0.0028538\ttotal: 17.6s\tremaining: 20.1s\n",
      "233:\tlearn: 0.0028267\ttotal: 17.7s\tremaining: 20.1s\n",
      "234:\tlearn: 0.0027955\ttotal: 17.7s\tremaining: 20s\n",
      "235:\tlearn: 0.0027631\ttotal: 17.8s\tremaining: 19.9s\n",
      "236:\tlearn: 0.0027373\ttotal: 17.9s\tremaining: 19.9s\n",
      "237:\tlearn: 0.0027164\ttotal: 17.9s\tremaining: 19.8s\n",
      "238:\tlearn: 0.0026932\ttotal: 18.1s\tremaining: 19.7s\n",
      "239:\tlearn: 0.0026932\ttotal: 18.1s\tremaining: 19.6s\n",
      "240:\tlearn: 0.0026932\ttotal: 18.2s\tremaining: 19.5s\n",
      "241:\tlearn: 0.0026715\ttotal: 18.3s\tremaining: 19.5s\n",
      "242:\tlearn: 0.0026508\ttotal: 18.3s\tremaining: 19.4s\n",
      "243:\tlearn: 0.0026508\ttotal: 18.4s\tremaining: 19.3s\n",
      "244:\tlearn: 0.0026335\ttotal: 18.5s\tremaining: 19.2s\n",
      "245:\tlearn: 0.0026086\ttotal: 18.6s\tremaining: 19.2s\n",
      "246:\tlearn: 0.0025924\ttotal: 18.6s\tremaining: 19.1s\n",
      "247:\tlearn: 0.0025700\ttotal: 18.7s\tremaining: 19s\n",
      "248:\tlearn: 0.0025698\ttotal: 18.8s\tremaining: 18.9s\n",
      "249:\tlearn: 0.0025698\ttotal: 18.8s\tremaining: 18.8s\n",
      "250:\tlearn: 0.0025695\ttotal: 19s\tremaining: 18.8s\n",
      "251:\tlearn: 0.0025695\ttotal: 19s\tremaining: 18.7s\n",
      "252:\tlearn: 0.0025695\ttotal: 19.1s\tremaining: 18.7s\n",
      "253:\tlearn: 0.0025695\ttotal: 19.2s\tremaining: 18.6s\n",
      "254:\tlearn: 0.0025694\ttotal: 19.2s\tremaining: 18.5s\n",
      "255:\tlearn: 0.0025585\ttotal: 19.3s\tremaining: 18.4s\n",
      "256:\tlearn: 0.0025384\ttotal: 19.4s\tremaining: 18.3s\n",
      "257:\tlearn: 0.0025384\ttotal: 19.5s\tremaining: 18.3s\n",
      "258:\tlearn: 0.0025171\ttotal: 19.5s\tremaining: 18.2s\n",
      "259:\tlearn: 0.0024946\ttotal: 19.6s\tremaining: 18.1s\n",
      "260:\tlearn: 0.0024734\ttotal: 19.7s\tremaining: 18s\n",
      "261:\tlearn: 0.0024531\ttotal: 19.8s\tremaining: 17.9s\n",
      "262:\tlearn: 0.0024269\ttotal: 19.9s\tremaining: 17.9s\n",
      "263:\tlearn: 0.0024269\ttotal: 19.9s\tremaining: 17.8s\n",
      "264:\tlearn: 0.0024269\ttotal: 20s\tremaining: 17.8s\n",
      "265:\tlearn: 0.0024269\ttotal: 20.1s\tremaining: 17.7s\n",
      "266:\tlearn: 0.0024081\ttotal: 20.2s\tremaining: 17.6s\n",
      "267:\tlearn: 0.0023975\ttotal: 20.2s\tremaining: 17.5s\n",
      "268:\tlearn: 0.0023809\ttotal: 20.3s\tremaining: 17.4s\n",
      "269:\tlearn: 0.0023809\ttotal: 20.4s\tremaining: 17.4s\n",
      "270:\tlearn: 0.0023808\ttotal: 20.4s\tremaining: 17.3s\n",
      "271:\tlearn: 0.0023808\ttotal: 20.5s\tremaining: 17.2s\n",
      "272:\tlearn: 0.0023808\ttotal: 20.6s\tremaining: 17.1s\n",
      "273:\tlearn: 0.0023808\ttotal: 20.6s\tremaining: 17s\n",
      "274:\tlearn: 0.0023808\ttotal: 20.8s\tremaining: 17s\n",
      "275:\tlearn: 0.0023808\ttotal: 20.8s\tremaining: 16.9s\n",
      "276:\tlearn: 0.0023807\ttotal: 20.9s\tremaining: 16.8s\n",
      "277:\tlearn: 0.0023807\ttotal: 21s\tremaining: 16.7s\n",
      "278:\tlearn: 0.0023807\ttotal: 21s\tremaining: 16.6s\n",
      "279:\tlearn: 0.0023688\ttotal: 21.1s\tremaining: 16.6s\n",
      "280:\tlearn: 0.0023483\ttotal: 21.2s\tremaining: 16.5s\n",
      "281:\tlearn: 0.0023482\ttotal: 21.3s\tremaining: 16.5s\n",
      "282:\tlearn: 0.0023278\ttotal: 21.3s\tremaining: 16.4s\n",
      "283:\tlearn: 0.0023113\ttotal: 21.4s\tremaining: 16.3s\n",
      "284:\tlearn: 0.0023042\ttotal: 21.5s\tremaining: 16.2s\n",
      "285:\tlearn: 0.0023041\ttotal: 21.5s\tremaining: 16.1s\n",
      "286:\tlearn: 0.0023042\ttotal: 21.7s\tremaining: 16.1s\n",
      "287:\tlearn: 0.0022868\ttotal: 21.7s\tremaining: 16s\n",
      "288:\tlearn: 0.0022867\ttotal: 21.7s\tremaining: 15.9s\n",
      "289:\tlearn: 0.0022823\ttotal: 21.9s\tremaining: 15.8s\n",
      "290:\tlearn: 0.0022640\ttotal: 21.9s\tremaining: 15.7s\n",
      "291:\tlearn: 0.0022620\ttotal: 22s\tremaining: 15.7s\n",
      "292:\tlearn: 0.0022512\ttotal: 22.1s\tremaining: 15.6s\n",
      "293:\tlearn: 0.0022512\ttotal: 22.2s\tremaining: 15.5s\n",
      "294:\tlearn: 0.0022425\ttotal: 22.3s\tremaining: 15.5s\n",
      "295:\tlearn: 0.0022288\ttotal: 22.3s\tremaining: 15.4s\n",
      "296:\tlearn: 0.0022287\ttotal: 22.4s\tremaining: 15.3s\n",
      "297:\tlearn: 0.0022105\ttotal: 22.5s\tremaining: 15.2s\n",
      "298:\tlearn: 0.0022104\ttotal: 22.5s\tremaining: 15.1s\n",
      "299:\tlearn: 0.0022104\ttotal: 22.6s\tremaining: 15s\n",
      "300:\tlearn: 0.0022104\ttotal: 22.6s\tremaining: 15s\n",
      "301:\tlearn: 0.0022103\ttotal: 22.7s\tremaining: 14.9s\n",
      "302:\tlearn: 0.0022104\ttotal: 22.7s\tremaining: 14.8s\n",
      "303:\tlearn: 0.0021972\ttotal: 22.8s\tremaining: 14.7s\n",
      "304:\tlearn: 0.0021782\ttotal: 22.9s\tremaining: 14.6s\n",
      "305:\tlearn: 0.0021782\ttotal: 23s\tremaining: 14.6s\n",
      "306:\tlearn: 0.0021782\ttotal: 23s\tremaining: 14.5s\n",
      "307:\tlearn: 0.0021782\ttotal: 23.1s\tremaining: 14.4s\n",
      "308:\tlearn: 0.0021617\ttotal: 23.2s\tremaining: 14.3s\n",
      "309:\tlearn: 0.0021617\ttotal: 23.2s\tremaining: 14.2s\n",
      "310:\tlearn: 0.0021617\ttotal: 23.3s\tremaining: 14.2s\n",
      "311:\tlearn: 0.0021617\ttotal: 23.4s\tremaining: 14.1s\n",
      "312:\tlearn: 0.0021616\ttotal: 23.4s\tremaining: 14s\n",
      "313:\tlearn: 0.0021616\ttotal: 23.6s\tremaining: 14s\n",
      "314:\tlearn: 0.0021616\ttotal: 23.6s\tremaining: 13.9s\n",
      "315:\tlearn: 0.0021616\ttotal: 23.7s\tremaining: 13.8s\n",
      "316:\tlearn: 0.0021616\ttotal: 23.8s\tremaining: 13.7s\n",
      "317:\tlearn: 0.0021615\ttotal: 23.8s\tremaining: 13.6s\n",
      "318:\tlearn: 0.0021615\ttotal: 23.9s\tremaining: 13.6s\n",
      "319:\tlearn: 0.0021615\ttotal: 24s\tremaining: 13.5s\n",
      "320:\tlearn: 0.0021615\ttotal: 24.1s\tremaining: 13.4s\n",
      "321:\tlearn: 0.0021614\ttotal: 24.1s\tremaining: 13.3s\n",
      "322:\tlearn: 0.0021614\ttotal: 24.2s\tremaining: 13.2s\n",
      "323:\tlearn: 0.0021614\ttotal: 24.3s\tremaining: 13.2s\n",
      "324:\tlearn: 0.0021614\ttotal: 24.3s\tremaining: 13.1s\n",
      "325:\tlearn: 0.0021614\ttotal: 24.4s\tremaining: 13s\n",
      "326:\tlearn: 0.0021613\ttotal: 24.5s\tremaining: 12.9s\n",
      "327:\tlearn: 0.0021614\ttotal: 24.5s\tremaining: 12.9s\n",
      "328:\tlearn: 0.0021434\ttotal: 24.6s\tremaining: 12.8s\n",
      "329:\tlearn: 0.0021434\ttotal: 24.7s\tremaining: 12.7s\n",
      "330:\tlearn: 0.0021434\ttotal: 24.8s\tremaining: 12.6s\n",
      "331:\tlearn: 0.0021434\ttotal: 24.8s\tremaining: 12.6s\n",
      "332:\tlearn: 0.0021434\ttotal: 24.9s\tremaining: 12.5s\n",
      "333:\tlearn: 0.0021434\ttotal: 25s\tremaining: 12.4s\n",
      "334:\tlearn: 0.0021434\ttotal: 25s\tremaining: 12.3s\n",
      "335:\tlearn: 0.0021434\ttotal: 25.1s\tremaining: 12.3s\n",
      "336:\tlearn: 0.0021433\ttotal: 25.2s\tremaining: 12.2s\n",
      "337:\tlearn: 0.0021433\ttotal: 25.3s\tremaining: 12.1s\n",
      "338:\tlearn: 0.0021433\ttotal: 25.4s\tremaining: 12s\n",
      "339:\tlearn: 0.0021433\ttotal: 25.5s\tremaining: 12s\n",
      "340:\tlearn: 0.0021329\ttotal: 25.5s\tremaining: 11.9s\n",
      "341:\tlearn: 0.0021328\ttotal: 25.6s\tremaining: 11.8s\n",
      "342:\tlearn: 0.0021329\ttotal: 25.7s\tremaining: 11.8s\n",
      "343:\tlearn: 0.0021328\ttotal: 25.8s\tremaining: 11.7s\n",
      "344:\tlearn: 0.0021328\ttotal: 25.9s\tremaining: 11.6s\n",
      "345:\tlearn: 0.0021328\ttotal: 25.9s\tremaining: 11.5s\n",
      "346:\tlearn: 0.0021281\ttotal: 26s\tremaining: 11.5s\n",
      "347:\tlearn: 0.0021281\ttotal: 26.1s\tremaining: 11.4s\n",
      "348:\tlearn: 0.0021281\ttotal: 26.2s\tremaining: 11.3s\n",
      "349:\tlearn: 0.0021281\ttotal: 26.2s\tremaining: 11.2s\n",
      "350:\tlearn: 0.0021280\ttotal: 26.3s\tremaining: 11.2s\n",
      "351:\tlearn: 0.0021246\ttotal: 26.4s\tremaining: 11.1s\n",
      "352:\tlearn: 0.0021243\ttotal: 26.4s\tremaining: 11s\n",
      "353:\tlearn: 0.0021243\ttotal: 26.6s\tremaining: 11s\n",
      "354:\tlearn: 0.0021243\ttotal: 26.7s\tremaining: 10.9s\n",
      "355:\tlearn: 0.0021101\ttotal: 26.7s\tremaining: 10.8s\n",
      "356:\tlearn: 0.0021101\ttotal: 26.8s\tremaining: 10.7s\n",
      "357:\tlearn: 0.0021100\ttotal: 26.9s\tremaining: 10.7s\n",
      "358:\tlearn: 0.0021100\ttotal: 26.9s\tremaining: 10.6s\n",
      "359:\tlearn: 0.0021100\ttotal: 27s\tremaining: 10.5s\n",
      "360:\tlearn: 0.0021100\ttotal: 27.1s\tremaining: 10.4s\n",
      "361:\tlearn: 0.0021100\ttotal: 27.1s\tremaining: 10.3s\n",
      "362:\tlearn: 0.0021100\ttotal: 27.3s\tremaining: 10.3s\n",
      "363:\tlearn: 0.0021099\ttotal: 27.3s\tremaining: 10.2s\n",
      "364:\tlearn: 0.0021099\ttotal: 27.4s\tremaining: 10.1s\n",
      "365:\tlearn: 0.0021099\ttotal: 27.5s\tremaining: 10.1s\n",
      "366:\tlearn: 0.0021099\ttotal: 27.5s\tremaining: 9.96s\n",
      "367:\tlearn: 0.0021099\ttotal: 27.6s\tremaining: 9.9s\n",
      "368:\tlearn: 0.0021099\ttotal: 27.6s\tremaining: 9.81s\n",
      "369:\tlearn: 0.0021099\ttotal: 27.7s\tremaining: 9.75s\n",
      "370:\tlearn: 0.0021099\ttotal: 27.8s\tremaining: 9.67s\n",
      "371:\tlearn: 0.0021099\ttotal: 27.9s\tremaining: 9.6s\n",
      "372:\tlearn: 0.0021099\ttotal: 28s\tremaining: 9.53s\n",
      "373:\tlearn: 0.0021099\ttotal: 28s\tremaining: 9.44s\n",
      "374:\tlearn: 0.0021098\ttotal: 28.1s\tremaining: 9.37s\n",
      "375:\tlearn: 0.0021098\ttotal: 28.2s\tremaining: 9.3s\n",
      "376:\tlearn: 0.0021098\ttotal: 28.3s\tremaining: 9.22s\n",
      "377:\tlearn: 0.0021098\ttotal: 28.3s\tremaining: 9.14s\n",
      "378:\tlearn: 0.0021098\ttotal: 28.4s\tremaining: 9.07s\n",
      "379:\tlearn: 0.0021005\ttotal: 28.5s\tremaining: 8.99s\n",
      "380:\tlearn: 0.0020863\ttotal: 28.6s\tremaining: 8.92s\n",
      "381:\tlearn: 0.0020863\ttotal: 28.6s\tremaining: 8.84s\n",
      "382:\tlearn: 0.0020862\ttotal: 28.7s\tremaining: 8.76s\n",
      "383:\tlearn: 0.0020863\ttotal: 28.8s\tremaining: 8.7s\n",
      "384:\tlearn: 0.0020862\ttotal: 28.8s\tremaining: 8.61s\n",
      "385:\tlearn: 0.0020861\ttotal: 28.9s\tremaining: 8.54s\n",
      "386:\tlearn: 0.0020837\ttotal: 29s\tremaining: 8.47s\n",
      "387:\tlearn: 0.0020837\ttotal: 29s\tremaining: 8.38s\n",
      "388:\tlearn: 0.0020837\ttotal: 29.1s\tremaining: 8.32s\n",
      "389:\tlearn: 0.0020836\ttotal: 29.2s\tremaining: 8.23s\n",
      "390:\tlearn: 0.0020836\ttotal: 29.3s\tremaining: 8.17s\n",
      "391:\tlearn: 0.0020836\ttotal: 29.4s\tremaining: 8.09s\n",
      "392:\tlearn: 0.0020836\ttotal: 29.4s\tremaining: 8s\n",
      "393:\tlearn: 0.0020836\ttotal: 29.5s\tremaining: 7.94s\n",
      "394:\tlearn: 0.0020836\ttotal: 29.6s\tremaining: 7.86s\n",
      "395:\tlearn: 0.0020836\ttotal: 29.7s\tremaining: 7.79s\n",
      "396:\tlearn: 0.0020835\ttotal: 29.7s\tremaining: 7.71s\n",
      "397:\tlearn: 0.0020658\ttotal: 29.8s\tremaining: 7.63s\n",
      "398:\tlearn: 0.0020658\ttotal: 29.9s\tremaining: 7.56s\n",
      "399:\tlearn: 0.0020658\ttotal: 29.9s\tremaining: 7.48s\n",
      "400:\tlearn: 0.0020658\ttotal: 30s\tremaining: 7.42s\n",
      "401:\tlearn: 0.0020658\ttotal: 30.1s\tremaining: 7.33s\n",
      "402:\tlearn: 0.0020658\ttotal: 30.2s\tremaining: 7.26s\n",
      "403:\tlearn: 0.0020658\ttotal: 30.2s\tremaining: 7.19s\n",
      "404:\tlearn: 0.0020657\ttotal: 30.3s\tremaining: 7.1s\n",
      "405:\tlearn: 0.0020657\ttotal: 30.4s\tremaining: 7.04s\n",
      "406:\tlearn: 0.0020657\ttotal: 30.4s\tremaining: 6.96s\n",
      "407:\tlearn: 0.0020657\ttotal: 30.6s\tremaining: 6.89s\n",
      "408:\tlearn: 0.0020497\ttotal: 30.6s\tremaining: 6.81s\n",
      "409:\tlearn: 0.0020233\ttotal: 30.7s\tremaining: 6.73s\n",
      "410:\tlearn: 0.0020233\ttotal: 30.8s\tremaining: 6.66s\n",
      "411:\tlearn: 0.0020233\ttotal: 30.8s\tremaining: 6.58s\n",
      "412:\tlearn: 0.0020233\ttotal: 30.9s\tremaining: 6.51s\n",
      "413:\tlearn: 0.0020232\ttotal: 31s\tremaining: 6.43s\n",
      "414:\tlearn: 0.0020232\ttotal: 31s\tremaining: 6.36s\n",
      "415:\tlearn: 0.0020232\ttotal: 31.1s\tremaining: 6.28s\n",
      "416:\tlearn: 0.0020232\ttotal: 31.2s\tremaining: 6.2s\n",
      "417:\tlearn: 0.0020232\ttotal: 31.3s\tremaining: 6.14s\n",
      "418:\tlearn: 0.0020232\ttotal: 31.3s\tremaining: 6.06s\n",
      "419:\tlearn: 0.0020232\ttotal: 31.4s\tremaining: 5.99s\n",
      "420:\tlearn: 0.0020232\ttotal: 31.5s\tremaining: 5.91s\n",
      "421:\tlearn: 0.0020231\ttotal: 31.5s\tremaining: 5.83s\n",
      "422:\tlearn: 0.0020231\ttotal: 31.6s\tremaining: 5.76s\n",
      "423:\tlearn: 0.0020231\ttotal: 31.7s\tremaining: 5.68s\n",
      "424:\tlearn: 0.0020231\ttotal: 31.8s\tremaining: 5.61s\n",
      "425:\tlearn: 0.0020231\ttotal: 31.9s\tremaining: 5.53s\n",
      "426:\tlearn: 0.0020231\ttotal: 32s\tremaining: 5.47s\n",
      "427:\tlearn: 0.0020231\ttotal: 32s\tremaining: 5.39s\n",
      "428:\tlearn: 0.0020230\ttotal: 32.1s\tremaining: 5.31s\n",
      "429:\tlearn: 0.0020230\ttotal: 32.2s\tremaining: 5.24s\n",
      "430:\tlearn: 0.0020093\ttotal: 32.2s\tremaining: 5.16s\n",
      "431:\tlearn: 0.0019886\ttotal: 32.3s\tremaining: 5.09s\n",
      "432:\tlearn: 0.0019886\ttotal: 32.4s\tremaining: 5.01s\n",
      "433:\tlearn: 0.0019886\ttotal: 32.5s\tremaining: 4.94s\n",
      "434:\tlearn: 0.0019886\ttotal: 32.6s\tremaining: 4.86s\n",
      "435:\tlearn: 0.0019886\ttotal: 32.6s\tremaining: 4.78s\n",
      "436:\tlearn: 0.0019886\ttotal: 32.7s\tremaining: 4.71s\n",
      "437:\tlearn: 0.0019886\ttotal: 32.8s\tremaining: 4.64s\n",
      "438:\tlearn: 0.0019886\ttotal: 32.9s\tremaining: 4.56s\n",
      "439:\tlearn: 0.0019884\ttotal: 32.9s\tremaining: 4.49s\n",
      "440:\tlearn: 0.0019884\ttotal: 33s\tremaining: 4.41s\n",
      "441:\tlearn: 0.0019884\ttotal: 33.1s\tremaining: 4.34s\n",
      "442:\tlearn: 0.0019883\ttotal: 33.1s\tremaining: 4.26s\n",
      "443:\tlearn: 0.0019883\ttotal: 33.2s\tremaining: 4.19s\n",
      "444:\tlearn: 0.0019883\ttotal: 33.3s\tremaining: 4.11s\n",
      "445:\tlearn: 0.0019883\ttotal: 33.3s\tremaining: 4.04s\n",
      "446:\tlearn: 0.0019883\ttotal: 33.4s\tremaining: 3.96s\n",
      "447:\tlearn: 0.0019882\ttotal: 33.5s\tremaining: 3.88s\n",
      "448:\tlearn: 0.0019882\ttotal: 33.6s\tremaining: 3.81s\n",
      "449:\tlearn: 0.0019801\ttotal: 33.6s\tremaining: 3.74s\n",
      "450:\tlearn: 0.0019801\ttotal: 33.7s\tremaining: 3.67s\n",
      "451:\tlearn: 0.0019801\ttotal: 33.8s\tremaining: 3.59s\n",
      "452:\tlearn: 0.0019801\ttotal: 33.8s\tremaining: 3.51s\n",
      "453:\tlearn: 0.0019801\ttotal: 33.9s\tremaining: 3.44s\n",
      "454:\tlearn: 0.0019801\ttotal: 34s\tremaining: 3.36s\n",
      "455:\tlearn: 0.0019801\ttotal: 34s\tremaining: 3.29s\n",
      "456:\tlearn: 0.0019802\ttotal: 34.2s\tremaining: 3.21s\n",
      "457:\tlearn: 0.0019623\ttotal: 34.2s\tremaining: 3.14s\n",
      "458:\tlearn: 0.0019623\ttotal: 34.3s\tremaining: 3.06s\n",
      "459:\tlearn: 0.0019623\ttotal: 34.4s\tremaining: 2.99s\n",
      "460:\tlearn: 0.0019623\ttotal: 34.4s\tremaining: 2.91s\n",
      "461:\tlearn: 0.0019623\ttotal: 34.5s\tremaining: 2.84s\n",
      "462:\tlearn: 0.0019622\ttotal: 34.6s\tremaining: 2.76s\n",
      "463:\tlearn: 0.0019622\ttotal: 34.7s\tremaining: 2.69s\n",
      "464:\tlearn: 0.0019622\ttotal: 34.7s\tremaining: 2.61s\n",
      "465:\tlearn: 0.0019621\ttotal: 34.8s\tremaining: 2.54s\n",
      "466:\tlearn: 0.0019621\ttotal: 34.9s\tremaining: 2.47s\n",
      "467:\tlearn: 0.0019622\ttotal: 34.9s\tremaining: 2.39s\n",
      "468:\tlearn: 0.0019622\ttotal: 35.1s\tremaining: 2.32s\n",
      "469:\tlearn: 0.0019622\ttotal: 35.1s\tremaining: 2.24s\n",
      "470:\tlearn: 0.0019622\ttotal: 35.2s\tremaining: 2.17s\n",
      "471:\tlearn: 0.0019622\ttotal: 35.3s\tremaining: 2.09s\n",
      "472:\tlearn: 0.0019622\ttotal: 35.4s\tremaining: 2.02s\n",
      "473:\tlearn: 0.0019622\ttotal: 35.4s\tremaining: 1.94s\n",
      "474:\tlearn: 0.0019621\ttotal: 35.5s\tremaining: 1.87s\n",
      "475:\tlearn: 0.0019621\ttotal: 35.6s\tremaining: 1.79s\n",
      "476:\tlearn: 0.0019621\ttotal: 35.6s\tremaining: 1.72s\n",
      "477:\tlearn: 0.0019621\ttotal: 35.7s\tremaining: 1.65s\n",
      "478:\tlearn: 0.0019621\ttotal: 35.8s\tremaining: 1.57s\n",
      "479:\tlearn: 0.0019621\ttotal: 35.9s\tremaining: 1.5s\n",
      "480:\tlearn: 0.0019620\ttotal: 36s\tremaining: 1.42s\n",
      "481:\tlearn: 0.0019620\ttotal: 36.1s\tremaining: 1.35s\n",
      "482:\tlearn: 0.0019620\ttotal: 36.1s\tremaining: 1.27s\n",
      "483:\tlearn: 0.0019620\ttotal: 36.2s\tremaining: 1.2s\n",
      "484:\tlearn: 0.0019620\ttotal: 36.3s\tremaining: 1.12s\n",
      "485:\tlearn: 0.0019620\ttotal: 36.3s\tremaining: 1.04s\n",
      "486:\tlearn: 0.0019620\ttotal: 36.4s\tremaining: 972ms\n",
      "487:\tlearn: 0.0019619\ttotal: 36.5s\tremaining: 897ms\n",
      "488:\tlearn: 0.0019619\ttotal: 36.6s\tremaining: 822ms\n",
      "489:\tlearn: 0.0019619\ttotal: 36.6s\tremaining: 748ms\n",
      "490:\tlearn: 0.0019618\ttotal: 36.7s\tremaining: 672ms\n",
      "491:\tlearn: 0.0019618\ttotal: 36.8s\tremaining: 598ms\n",
      "492:\tlearn: 0.0019618\ttotal: 36.9s\tremaining: 523ms\n",
      "493:\tlearn: 0.0019618\ttotal: 37s\tremaining: 449ms\n",
      "494:\tlearn: 0.0019618\ttotal: 37s\tremaining: 374ms\n",
      "495:\tlearn: 0.0019619\ttotal: 37.1s\tremaining: 299ms\n",
      "496:\tlearn: 0.0019619\ttotal: 37.2s\tremaining: 224ms\n",
      "497:\tlearn: 0.0019619\ttotal: 37.2s\tremaining: 150ms\n",
      "498:\tlearn: 0.0019618\ttotal: 37.3s\tremaining: 74.8ms\n",
      "499:\tlearn: 0.0019618\ttotal: 37.4s\tremaining: 0us\n",
      "0:\tlearn: 0.6566069\ttotal: 53.4ms\tremaining: 26.6s\n",
      "1:\tlearn: 0.6161850\ttotal: 174ms\tremaining: 43.3s\n",
      "2:\tlearn: 0.5813182\ttotal: 227ms\tremaining: 37.6s\n",
      "3:\tlearn: 0.5474909\ttotal: 319ms\tremaining: 39.6s\n",
      "4:\tlearn: 0.5118299\ttotal: 370ms\tremaining: 36.6s\n",
      "5:\tlearn: 0.4852712\ttotal: 467ms\tremaining: 38.5s\n",
      "6:\tlearn: 0.4646807\ttotal: 536ms\tremaining: 37.8s\n",
      "7:\tlearn: 0.4426994\ttotal: 581ms\tremaining: 35.8s\n",
      "8:\tlearn: 0.4256463\ttotal: 699ms\tremaining: 38.1s\n",
      "9:\tlearn: 0.4022161\ttotal: 742ms\tremaining: 36.3s\n",
      "10:\tlearn: 0.3859693\ttotal: 850ms\tremaining: 37.8s\n",
      "11:\tlearn: 0.3669132\ttotal: 900ms\tremaining: 36.6s\n",
      "12:\tlearn: 0.3522085\ttotal: 946ms\tremaining: 35.4s\n",
      "13:\tlearn: 0.3334125\ttotal: 1.05s\tremaining: 36.5s\n",
      "14:\tlearn: 0.3158674\ttotal: 1.1s\tremaining: 35.5s\n",
      "15:\tlearn: 0.3017765\ttotal: 1.2s\tremaining: 36.4s\n",
      "16:\tlearn: 0.2877163\ttotal: 1.25s\tremaining: 35.4s\n",
      "17:\tlearn: 0.2779069\ttotal: 1.34s\tremaining: 36s\n",
      "18:\tlearn: 0.2606054\ttotal: 1.4s\tremaining: 35.6s\n",
      "19:\tlearn: 0.2478753\ttotal: 1.45s\tremaining: 34.7s\n",
      "20:\tlearn: 0.2405220\ttotal: 1.55s\tremaining: 35.4s\n",
      "21:\tlearn: 0.2334506\ttotal: 1.6s\tremaining: 34.7s\n",
      "22:\tlearn: 0.2238241\ttotal: 1.71s\tremaining: 35.4s\n",
      "23:\tlearn: 0.2104365\ttotal: 1.75s\tremaining: 34.8s\n",
      "24:\tlearn: 0.2008248\ttotal: 1.83s\tremaining: 34.8s\n",
      "25:\tlearn: 0.1938921\ttotal: 1.92s\tremaining: 35s\n",
      "26:\tlearn: 0.1880092\ttotal: 1.97s\tremaining: 34.6s\n",
      "27:\tlearn: 0.1821947\ttotal: 2.07s\tremaining: 34.9s\n",
      "28:\tlearn: 0.1770843\ttotal: 2.12s\tremaining: 34.4s\n",
      "29:\tlearn: 0.1729988\ttotal: 2.22s\tremaining: 34.8s\n",
      "30:\tlearn: 0.1679293\ttotal: 2.33s\tremaining: 35.3s\n",
      "31:\tlearn: 0.1631211\ttotal: 2.38s\tremaining: 34.8s\n",
      "32:\tlearn: 0.1534444\ttotal: 2.42s\tremaining: 34.3s\n",
      "33:\tlearn: 0.1463819\ttotal: 2.53s\tremaining: 34.7s\n",
      "34:\tlearn: 0.1412575\ttotal: 2.58s\tremaining: 34.2s\n",
      "35:\tlearn: 0.1357393\ttotal: 2.67s\tremaining: 34.5s\n",
      "36:\tlearn: 0.1324280\ttotal: 2.76s\tremaining: 34.5s\n",
      "37:\tlearn: 0.1243109\ttotal: 2.8s\tremaining: 34s\n",
      "38:\tlearn: 0.1183969\ttotal: 2.91s\tremaining: 34.5s\n",
      "39:\tlearn: 0.1149744\ttotal: 2.97s\tremaining: 34.1s\n",
      "40:\tlearn: 0.1103320\ttotal: 3.08s\tremaining: 34.5s\n",
      "41:\tlearn: 0.1050552\ttotal: 3.15s\tremaining: 34.3s\n",
      "42:\tlearn: 0.1022360\ttotal: 3.25s\tremaining: 34.6s\n",
      "43:\tlearn: 0.1002427\ttotal: 3.3s\tremaining: 34.2s\n",
      "44:\tlearn: 0.0961579\ttotal: 3.4s\tremaining: 34.4s\n",
      "45:\tlearn: 0.0926475\ttotal: 3.46s\tremaining: 34.2s\n",
      "46:\tlearn: 0.0900617\ttotal: 3.55s\tremaining: 34.2s\n",
      "47:\tlearn: 0.0871370\ttotal: 3.62s\tremaining: 34.1s\n",
      "48:\tlearn: 0.0845304\ttotal: 3.67s\tremaining: 33.8s\n",
      "49:\tlearn: 0.0815512\ttotal: 3.78s\tremaining: 34.1s\n",
      "50:\tlearn: 0.0791553\ttotal: 3.83s\tremaining: 33.7s\n",
      "51:\tlearn: 0.0771688\ttotal: 3.95s\tremaining: 34s\n",
      "52:\tlearn: 0.0754630\ttotal: 4s\tremaining: 33.7s\n",
      "53:\tlearn: 0.0730482\ttotal: 4.04s\tremaining: 33.3s\n",
      "54:\tlearn: 0.0698688\ttotal: 4.14s\tremaining: 33.5s\n",
      "55:\tlearn: 0.0668837\ttotal: 4.18s\tremaining: 33.2s\n",
      "56:\tlearn: 0.0648655\ttotal: 4.29s\tremaining: 33.3s\n",
      "57:\tlearn: 0.0625176\ttotal: 4.34s\tremaining: 33s\n",
      "58:\tlearn: 0.0597672\ttotal: 4.44s\tremaining: 33.2s\n",
      "59:\tlearn: 0.0580310\ttotal: 4.49s\tremaining: 32.9s\n",
      "60:\tlearn: 0.0566372\ttotal: 4.61s\tremaining: 33.2s\n",
      "61:\tlearn: 0.0542206\ttotal: 4.65s\tremaining: 32.9s\n",
      "62:\tlearn: 0.0525899\ttotal: 4.75s\tremaining: 32.9s\n",
      "63:\tlearn: 0.0503606\ttotal: 4.81s\tremaining: 32.8s\n",
      "64:\tlearn: 0.0486659\ttotal: 4.85s\tremaining: 32.5s\n",
      "65:\tlearn: 0.0473319\ttotal: 4.97s\tremaining: 32.7s\n",
      "66:\tlearn: 0.0461066\ttotal: 5.01s\tremaining: 32.4s\n",
      "67:\tlearn: 0.0441758\ttotal: 5.12s\tremaining: 32.5s\n",
      "68:\tlearn: 0.0428168\ttotal: 5.18s\tremaining: 32.3s\n",
      "69:\tlearn: 0.0417715\ttotal: 5.23s\tremaining: 32.1s\n",
      "70:\tlearn: 0.0408638\ttotal: 5.33s\tremaining: 32.2s\n",
      "71:\tlearn: 0.0398185\ttotal: 5.37s\tremaining: 31.9s\n",
      "72:\tlearn: 0.0381873\ttotal: 5.41s\tremaining: 31.7s\n",
      "73:\tlearn: 0.0370544\ttotal: 5.53s\tremaining: 31.8s\n",
      "74:\tlearn: 0.0364600\ttotal: 5.58s\tremaining: 31.6s\n",
      "75:\tlearn: 0.0357277\ttotal: 5.67s\tremaining: 31.6s\n",
      "76:\tlearn: 0.0346487\ttotal: 5.72s\tremaining: 31.4s\n",
      "77:\tlearn: 0.0338976\ttotal: 5.76s\tremaining: 31.2s\n",
      "78:\tlearn: 0.0330594\ttotal: 5.88s\tremaining: 31.3s\n",
      "79:\tlearn: 0.0319701\ttotal: 5.92s\tremaining: 31.1s\n",
      "80:\tlearn: 0.0309096\ttotal: 6.03s\tremaining: 31.2s\n",
      "81:\tlearn: 0.0302617\ttotal: 6.09s\tremaining: 31s\n",
      "82:\tlearn: 0.0292265\ttotal: 6.14s\tremaining: 30.8s\n",
      "83:\tlearn: 0.0282490\ttotal: 6.25s\tremaining: 30.9s\n",
      "84:\tlearn: 0.0276673\ttotal: 6.29s\tremaining: 30.7s\n",
      "85:\tlearn: 0.0271286\ttotal: 6.41s\tremaining: 30.9s\n",
      "86:\tlearn: 0.0262353\ttotal: 6.46s\tremaining: 30.7s\n",
      "87:\tlearn: 0.0254142\ttotal: 6.55s\tremaining: 30.7s\n",
      "88:\tlearn: 0.0245846\ttotal: 6.62s\tremaining: 30.6s\n",
      "89:\tlearn: 0.0238929\ttotal: 6.66s\tremaining: 30.3s\n",
      "90:\tlearn: 0.0230231\ttotal: 6.78s\tremaining: 30.5s\n",
      "91:\tlearn: 0.0222291\ttotal: 6.82s\tremaining: 30.2s\n",
      "92:\tlearn: 0.0214639\ttotal: 6.91s\tremaining: 30.2s\n",
      "93:\tlearn: 0.0208988\ttotal: 6.98s\tremaining: 30.1s\n",
      "94:\tlearn: 0.0203184\ttotal: 7.07s\tremaining: 30.1s\n",
      "95:\tlearn: 0.0198949\ttotal: 7.15s\tremaining: 30.1s\n",
      "96:\tlearn: 0.0193122\ttotal: 7.19s\tremaining: 29.9s\n",
      "97:\tlearn: 0.0188316\ttotal: 7.31s\tremaining: 30s\n",
      "98:\tlearn: 0.0183736\ttotal: 7.36s\tremaining: 29.8s\n",
      "99:\tlearn: 0.0179543\ttotal: 7.47s\tremaining: 29.9s\n",
      "100:\tlearn: 0.0174145\ttotal: 7.52s\tremaining: 29.7s\n",
      "101:\tlearn: 0.0169456\ttotal: 7.62s\tremaining: 29.7s\n",
      "102:\tlearn: 0.0165021\ttotal: 7.69s\tremaining: 29.6s\n",
      "103:\tlearn: 0.0161274\ttotal: 7.74s\tremaining: 29.5s\n",
      "104:\tlearn: 0.0156440\ttotal: 7.85s\tremaining: 29.5s\n",
      "105:\tlearn: 0.0153008\ttotal: 7.89s\tremaining: 29.3s\n",
      "106:\tlearn: 0.0150532\ttotal: 8.01s\tremaining: 29.4s\n",
      "107:\tlearn: 0.0147328\ttotal: 8.06s\tremaining: 29.3s\n",
      "108:\tlearn: 0.0143481\ttotal: 8.11s\tremaining: 29.1s\n",
      "109:\tlearn: 0.0140691\ttotal: 8.21s\tremaining: 29.1s\n",
      "110:\tlearn: 0.0138107\ttotal: 8.25s\tremaining: 28.9s\n",
      "111:\tlearn: 0.0135361\ttotal: 8.36s\tremaining: 29s\n",
      "112:\tlearn: 0.0131987\ttotal: 8.4s\tremaining: 28.8s\n",
      "113:\tlearn: 0.0129394\ttotal: 8.49s\tremaining: 28.8s\n",
      "114:\tlearn: 0.0126965\ttotal: 8.56s\tremaining: 28.7s\n",
      "115:\tlearn: 0.0124314\ttotal: 8.61s\tremaining: 28.5s\n",
      "116:\tlearn: 0.0122162\ttotal: 8.75s\tremaining: 28.6s\n",
      "117:\tlearn: 0.0120290\ttotal: 8.79s\tremaining: 28.5s\n",
      "118:\tlearn: 0.0118180\ttotal: 8.88s\tremaining: 28.4s\n",
      "119:\tlearn: 0.0116451\ttotal: 8.93s\tremaining: 28.3s\n",
      "120:\tlearn: 0.0114287\ttotal: 9.03s\tremaining: 28.3s\n",
      "121:\tlearn: 0.0112926\ttotal: 9.09s\tremaining: 28.2s\n",
      "122:\tlearn: 0.0110505\ttotal: 9.13s\tremaining: 28s\n",
      "123:\tlearn: 0.0107992\ttotal: 9.2s\tremaining: 27.9s\n",
      "124:\tlearn: 0.0106205\ttotal: 9.28s\tremaining: 27.8s\n",
      "125:\tlearn: 0.0104392\ttotal: 9.32s\tremaining: 27.7s\n",
      "126:\tlearn: 0.0102655\ttotal: 9.43s\tremaining: 27.7s\n",
      "127:\tlearn: 0.0100988\ttotal: 9.48s\tremaining: 27.6s\n",
      "128:\tlearn: 0.0099125\ttotal: 9.61s\tremaining: 27.6s\n",
      "129:\tlearn: 0.0097196\ttotal: 9.67s\tremaining: 27.5s\n",
      "130:\tlearn: 0.0095409\ttotal: 9.79s\tremaining: 27.6s\n",
      "131:\tlearn: 0.0093667\ttotal: 9.84s\tremaining: 27.4s\n",
      "132:\tlearn: 0.0092273\ttotal: 9.94s\tremaining: 27.4s\n",
      "133:\tlearn: 0.0090847\ttotal: 10s\tremaining: 27.3s\n",
      "134:\tlearn: 0.0089188\ttotal: 10s\tremaining: 27.2s\n",
      "135:\tlearn: 0.0087735\ttotal: 10.2s\tremaining: 27.2s\n",
      "136:\tlearn: 0.0086588\ttotal: 10.2s\tremaining: 27s\n",
      "137:\tlearn: 0.0085414\ttotal: 10.3s\tremaining: 27.1s\n",
      "138:\tlearn: 0.0083507\ttotal: 10.4s\tremaining: 26.9s\n",
      "139:\tlearn: 0.0082010\ttotal: 10.5s\tremaining: 26.9s\n",
      "140:\tlearn: 0.0080556\ttotal: 10.5s\tremaining: 26.8s\n",
      "141:\tlearn: 0.0079597\ttotal: 10.6s\tremaining: 26.7s\n",
      "142:\tlearn: 0.0078347\ttotal: 10.7s\tremaining: 26.7s\n",
      "143:\tlearn: 0.0076969\ttotal: 10.7s\tremaining: 26.5s\n",
      "144:\tlearn: 0.0075767\ttotal: 10.8s\tremaining: 26.6s\n",
      "145:\tlearn: 0.0075024\ttotal: 10.9s\tremaining: 26.4s\n",
      "146:\tlearn: 0.0073820\ttotal: 11s\tremaining: 26.4s\n",
      "147:\tlearn: 0.0072790\ttotal: 11.1s\tremaining: 26.3s\n",
      "148:\tlearn: 0.0071498\ttotal: 11.1s\tremaining: 26.2s\n",
      "149:\tlearn: 0.0070285\ttotal: 11.1s\tremaining: 26s\n",
      "150:\tlearn: 0.0068760\ttotal: 11.3s\tremaining: 26s\n",
      "151:\tlearn: 0.0068012\ttotal: 11.3s\tremaining: 25.9s\n",
      "152:\tlearn: 0.0067057\ttotal: 11.4s\tremaining: 25.9s\n",
      "153:\tlearn: 0.0066244\ttotal: 11.5s\tremaining: 25.8s\n",
      "154:\tlearn: 0.0065480\ttotal: 11.5s\tremaining: 25.6s\n",
      "155:\tlearn: 0.0064776\ttotal: 11.6s\tremaining: 25.6s\n",
      "156:\tlearn: 0.0064048\ttotal: 11.7s\tremaining: 25.5s\n",
      "157:\tlearn: 0.0063243\ttotal: 11.8s\tremaining: 25.5s\n",
      "158:\tlearn: 0.0062534\ttotal: 11.9s\tremaining: 25.4s\n",
      "159:\tlearn: 0.0061609\ttotal: 12s\tremaining: 25.5s\n",
      "160:\tlearn: 0.0060891\ttotal: 12s\tremaining: 25.3s\n",
      "161:\tlearn: 0.0060328\ttotal: 12.1s\tremaining: 25.3s\n",
      "162:\tlearn: 0.0059461\ttotal: 12.2s\tremaining: 25.2s\n",
      "163:\tlearn: 0.0058514\ttotal: 12.2s\tremaining: 25.1s\n",
      "164:\tlearn: 0.0057524\ttotal: 12.3s\tremaining: 25.1s\n",
      "165:\tlearn: 0.0056560\ttotal: 12.4s\tremaining: 24.9s\n",
      "166:\tlearn: 0.0055736\ttotal: 12.5s\tremaining: 24.9s\n",
      "167:\tlearn: 0.0054752\ttotal: 12.5s\tremaining: 24.8s\n",
      "168:\tlearn: 0.0054058\ttotal: 12.6s\tremaining: 24.8s\n",
      "169:\tlearn: 0.0053395\ttotal: 12.7s\tremaining: 24.6s\n",
      "170:\tlearn: 0.0052798\ttotal: 12.8s\tremaining: 24.6s\n",
      "171:\tlearn: 0.0052135\ttotal: 12.8s\tremaining: 24.5s\n",
      "172:\tlearn: 0.0051185\ttotal: 12.9s\tremaining: 24.5s\n",
      "173:\tlearn: 0.0050698\ttotal: 13s\tremaining: 24.4s\n",
      "174:\tlearn: 0.0049960\ttotal: 13.1s\tremaining: 24.3s\n",
      "175:\tlearn: 0.0049160\ttotal: 13.2s\tremaining: 24.3s\n",
      "176:\tlearn: 0.0048449\ttotal: 13.2s\tremaining: 24.1s\n",
      "177:\tlearn: 0.0047921\ttotal: 13.3s\tremaining: 24.1s\n",
      "178:\tlearn: 0.0047501\ttotal: 13.4s\tremaining: 24s\n",
      "179:\tlearn: 0.0046869\ttotal: 13.5s\tremaining: 24s\n",
      "180:\tlearn: 0.0046218\ttotal: 13.6s\tremaining: 23.9s\n",
      "181:\tlearn: 0.0045597\ttotal: 13.6s\tremaining: 23.8s\n",
      "182:\tlearn: 0.0044696\ttotal: 13.7s\tremaining: 23.8s\n",
      "183:\tlearn: 0.0044179\ttotal: 13.8s\tremaining: 23.7s\n",
      "184:\tlearn: 0.0043846\ttotal: 13.8s\tremaining: 23.5s\n",
      "185:\tlearn: 0.0043429\ttotal: 13.9s\tremaining: 23.5s\n",
      "186:\tlearn: 0.0042848\ttotal: 14s\tremaining: 23.4s\n",
      "187:\tlearn: 0.0042314\ttotal: 14.1s\tremaining: 23.4s\n",
      "188:\tlearn: 0.0041827\ttotal: 14.2s\tremaining: 23.3s\n",
      "189:\tlearn: 0.0041450\ttotal: 14.3s\tremaining: 23.3s\n",
      "190:\tlearn: 0.0041092\ttotal: 14.3s\tremaining: 23.2s\n",
      "191:\tlearn: 0.0040768\ttotal: 14.4s\tremaining: 23s\n",
      "192:\tlearn: 0.0040487\ttotal: 14.5s\tremaining: 23s\n",
      "193:\tlearn: 0.0040105\ttotal: 14.5s\tremaining: 22.9s\n",
      "194:\tlearn: 0.0039816\ttotal: 14.6s\tremaining: 22.9s\n",
      "195:\tlearn: 0.0039172\ttotal: 14.7s\tremaining: 22.8s\n",
      "196:\tlearn: 0.0038654\ttotal: 14.7s\tremaining: 22.7s\n",
      "197:\tlearn: 0.0038378\ttotal: 14.8s\tremaining: 22.6s\n",
      "198:\tlearn: 0.0038032\ttotal: 14.9s\tremaining: 22.5s\n",
      "199:\tlearn: 0.0037680\ttotal: 15s\tremaining: 22.5s\n",
      "200:\tlearn: 0.0037298\ttotal: 15s\tremaining: 22.4s\n",
      "201:\tlearn: 0.0036944\ttotal: 15.2s\tremaining: 22.4s\n",
      "202:\tlearn: 0.0036486\ttotal: 15.2s\tremaining: 22.3s\n",
      "203:\tlearn: 0.0036094\ttotal: 15.3s\tremaining: 22.2s\n",
      "204:\tlearn: 0.0036094\ttotal: 15.4s\tremaining: 22.1s\n",
      "205:\tlearn: 0.0035804\ttotal: 15.4s\tremaining: 22s\n",
      "206:\tlearn: 0.0035497\ttotal: 15.5s\tremaining: 22s\n",
      "207:\tlearn: 0.0035200\ttotal: 15.6s\tremaining: 21.9s\n",
      "208:\tlearn: 0.0034853\ttotal: 15.7s\tremaining: 21.8s\n",
      "209:\tlearn: 0.0034528\ttotal: 15.7s\tremaining: 21.7s\n",
      "210:\tlearn: 0.0034251\ttotal: 15.8s\tremaining: 21.6s\n",
      "211:\tlearn: 0.0033887\ttotal: 15.9s\tremaining: 21.6s\n",
      "212:\tlearn: 0.0033654\ttotal: 15.9s\tremaining: 21.5s\n",
      "213:\tlearn: 0.0033392\ttotal: 16.1s\tremaining: 21.5s\n",
      "214:\tlearn: 0.0033076\ttotal: 16.1s\tremaining: 21.4s\n",
      "215:\tlearn: 0.0032720\ttotal: 16.2s\tremaining: 21.3s\n",
      "216:\tlearn: 0.0032470\ttotal: 16.3s\tremaining: 21.2s\n",
      "217:\tlearn: 0.0032074\ttotal: 16.4s\tremaining: 21.2s\n",
      "218:\tlearn: 0.0031732\ttotal: 16.4s\tremaining: 21.1s\n",
      "219:\tlearn: 0.0031366\ttotal: 16.5s\tremaining: 21s\n",
      "220:\tlearn: 0.0031092\ttotal: 16.6s\tremaining: 21s\n",
      "221:\tlearn: 0.0030802\ttotal: 16.7s\tremaining: 20.9s\n",
      "222:\tlearn: 0.0030546\ttotal: 16.8s\tremaining: 20.8s\n",
      "223:\tlearn: 0.0030279\ttotal: 16.8s\tremaining: 20.7s\n",
      "224:\tlearn: 0.0030017\ttotal: 16.9s\tremaining: 20.6s\n",
      "225:\tlearn: 0.0030017\ttotal: 17s\tremaining: 20.6s\n",
      "226:\tlearn: 0.0029759\ttotal: 17s\tremaining: 20.5s\n",
      "227:\tlearn: 0.0029461\ttotal: 17.1s\tremaining: 20.4s\n",
      "228:\tlearn: 0.0029230\ttotal: 17.2s\tremaining: 20.3s\n",
      "229:\tlearn: 0.0028995\ttotal: 17.2s\tremaining: 20.2s\n",
      "230:\tlearn: 0.0028694\ttotal: 17.3s\tremaining: 20.2s\n",
      "231:\tlearn: 0.0028499\ttotal: 17.4s\tremaining: 20.1s\n",
      "232:\tlearn: 0.0028289\ttotal: 17.5s\tremaining: 20s\n",
      "233:\tlearn: 0.0028042\ttotal: 17.5s\tremaining: 19.9s\n",
      "234:\tlearn: 0.0028041\ttotal: 17.6s\tremaining: 19.8s\n",
      "235:\tlearn: 0.0028041\ttotal: 17.7s\tremaining: 19.8s\n",
      "236:\tlearn: 0.0027770\ttotal: 17.7s\tremaining: 19.7s\n",
      "237:\tlearn: 0.0027477\ttotal: 17.8s\tremaining: 19.6s\n",
      "238:\tlearn: 0.0027227\ttotal: 17.9s\tremaining: 19.5s\n",
      "239:\tlearn: 0.0027039\ttotal: 18s\tremaining: 19.5s\n",
      "240:\tlearn: 0.0026739\ttotal: 18s\tremaining: 19.4s\n",
      "241:\tlearn: 0.0026555\ttotal: 18.1s\tremaining: 19.3s\n",
      "242:\tlearn: 0.0026396\ttotal: 18.2s\tremaining: 19.3s\n",
      "243:\tlearn: 0.0026168\ttotal: 18.3s\tremaining: 19.2s\n",
      "244:\tlearn: 0.0025963\ttotal: 18.4s\tremaining: 19.1s\n",
      "245:\tlearn: 0.0025743\ttotal: 18.4s\tremaining: 19s\n",
      "246:\tlearn: 0.0025559\ttotal: 18.5s\tremaining: 19s\n",
      "247:\tlearn: 0.0025320\ttotal: 18.6s\tremaining: 18.9s\n",
      "248:\tlearn: 0.0025320\ttotal: 18.6s\tremaining: 18.8s\n",
      "249:\tlearn: 0.0025319\ttotal: 18.7s\tremaining: 18.7s\n",
      "250:\tlearn: 0.0025319\ttotal: 18.8s\tremaining: 18.6s\n",
      "251:\tlearn: 0.0025319\ttotal: 18.9s\tremaining: 18.6s\n",
      "252:\tlearn: 0.0025319\ttotal: 18.9s\tremaining: 18.5s\n",
      "253:\tlearn: 0.0025319\ttotal: 19s\tremaining: 18.4s\n",
      "254:\tlearn: 0.0025319\ttotal: 19.1s\tremaining: 18.4s\n",
      "255:\tlearn: 0.0025148\ttotal: 19.2s\tremaining: 18.3s\n",
      "256:\tlearn: 0.0025148\ttotal: 19.2s\tremaining: 18.2s\n",
      "257:\tlearn: 0.0025148\ttotal: 19.3s\tremaining: 18.1s\n",
      "258:\tlearn: 0.0025148\ttotal: 19.3s\tremaining: 18s\n",
      "259:\tlearn: 0.0024913\ttotal: 19.4s\tremaining: 17.9s\n",
      "260:\tlearn: 0.0024695\ttotal: 19.5s\tremaining: 17.9s\n",
      "261:\tlearn: 0.0024550\ttotal: 19.5s\tremaining: 17.8s\n",
      "262:\tlearn: 0.0024320\ttotal: 19.6s\tremaining: 17.7s\n",
      "263:\tlearn: 0.0024320\ttotal: 19.6s\tremaining: 17.6s\n",
      "264:\tlearn: 0.0024320\ttotal: 19.7s\tremaining: 17.5s\n",
      "265:\tlearn: 0.0024320\ttotal: 19.8s\tremaining: 17.4s\n",
      "266:\tlearn: 0.0024320\ttotal: 19.9s\tremaining: 17.3s\n",
      "267:\tlearn: 0.0024104\ttotal: 19.9s\tremaining: 17.3s\n",
      "268:\tlearn: 0.0024103\ttotal: 20s\tremaining: 17.2s\n",
      "269:\tlearn: 0.0024103\ttotal: 20.1s\tremaining: 17.1s\n",
      "270:\tlearn: 0.0024103\ttotal: 20.1s\tremaining: 17s\n",
      "271:\tlearn: 0.0024101\ttotal: 20.3s\tremaining: 17s\n",
      "272:\tlearn: 0.0024102\ttotal: 20.3s\tremaining: 16.9s\n",
      "273:\tlearn: 0.0024101\ttotal: 20.4s\tremaining: 16.8s\n",
      "274:\tlearn: 0.0024101\ttotal: 20.5s\tremaining: 16.8s\n",
      "275:\tlearn: 0.0024101\ttotal: 20.5s\tremaining: 16.7s\n",
      "276:\tlearn: 0.0023890\ttotal: 20.6s\tremaining: 16.6s\n",
      "277:\tlearn: 0.0023693\ttotal: 20.7s\tremaining: 16.5s\n",
      "278:\tlearn: 0.0023693\ttotal: 20.8s\tremaining: 16.5s\n",
      "279:\tlearn: 0.0023692\ttotal: 20.8s\tremaining: 16.4s\n",
      "280:\tlearn: 0.0023692\ttotal: 21s\tremaining: 16.3s\n",
      "281:\tlearn: 0.0023692\ttotal: 21s\tremaining: 16.2s\n",
      "282:\tlearn: 0.0023692\ttotal: 21.1s\tremaining: 16.2s\n",
      "283:\tlearn: 0.0023692\ttotal: 21.2s\tremaining: 16.1s\n",
      "284:\tlearn: 0.0023692\ttotal: 21.2s\tremaining: 16s\n",
      "285:\tlearn: 0.0023512\ttotal: 21.3s\tremaining: 16s\n",
      "286:\tlearn: 0.0023512\ttotal: 21.4s\tremaining: 15.9s\n",
      "287:\tlearn: 0.0023512\ttotal: 21.5s\tremaining: 15.8s\n",
      "288:\tlearn: 0.0023321\ttotal: 21.5s\tremaining: 15.7s\n",
      "289:\tlearn: 0.0023101\ttotal: 21.6s\tremaining: 15.6s\n",
      "290:\tlearn: 0.0023101\ttotal: 21.7s\tremaining: 15.6s\n",
      "291:\tlearn: 0.0023100\ttotal: 21.7s\tremaining: 15.5s\n",
      "292:\tlearn: 0.0023100\ttotal: 21.8s\tremaining: 15.4s\n",
      "293:\tlearn: 0.0023100\ttotal: 21.9s\tremaining: 15.3s\n",
      "294:\tlearn: 0.0023100\ttotal: 21.9s\tremaining: 15.2s\n",
      "295:\tlearn: 0.0023100\ttotal: 22s\tremaining: 15.2s\n",
      "296:\tlearn: 0.0023100\ttotal: 22.1s\tremaining: 15.1s\n",
      "297:\tlearn: 0.0022976\ttotal: 22.2s\tremaining: 15s\n",
      "298:\tlearn: 0.0022977\ttotal: 22.2s\tremaining: 14.9s\n",
      "299:\tlearn: 0.0022976\ttotal: 22.3s\tremaining: 14.8s\n",
      "300:\tlearn: 0.0022976\ttotal: 22.4s\tremaining: 14.8s\n",
      "301:\tlearn: 0.0022976\ttotal: 22.4s\tremaining: 14.7s\n",
      "302:\tlearn: 0.0022975\ttotal: 22.6s\tremaining: 14.7s\n",
      "303:\tlearn: 0.0022975\ttotal: 22.6s\tremaining: 14.6s\n",
      "304:\tlearn: 0.0022865\ttotal: 22.7s\tremaining: 14.5s\n",
      "305:\tlearn: 0.0022864\ttotal: 22.8s\tremaining: 14.4s\n",
      "306:\tlearn: 0.0022864\ttotal: 22.8s\tremaining: 14.3s\n",
      "307:\tlearn: 0.0022864\ttotal: 22.9s\tremaining: 14.3s\n",
      "308:\tlearn: 0.0022864\ttotal: 23s\tremaining: 14.2s\n",
      "309:\tlearn: 0.0022863\ttotal: 23s\tremaining: 14.1s\n",
      "310:\tlearn: 0.0022699\ttotal: 23.1s\tremaining: 14.1s\n",
      "311:\tlearn: 0.0022577\ttotal: 23.2s\tremaining: 14s\n",
      "312:\tlearn: 0.0022577\ttotal: 23.3s\tremaining: 13.9s\n",
      "313:\tlearn: 0.0022498\ttotal: 23.3s\tremaining: 13.8s\n",
      "314:\tlearn: 0.0022497\ttotal: 23.4s\tremaining: 13.8s\n",
      "315:\tlearn: 0.0022497\ttotal: 23.5s\tremaining: 13.7s\n",
      "316:\tlearn: 0.0022497\ttotal: 23.6s\tremaining: 13.6s\n",
      "317:\tlearn: 0.0022497\ttotal: 23.7s\tremaining: 13.5s\n",
      "318:\tlearn: 0.0022496\ttotal: 23.7s\tremaining: 13.5s\n",
      "319:\tlearn: 0.0022496\ttotal: 23.8s\tremaining: 13.4s\n",
      "320:\tlearn: 0.0022396\ttotal: 23.9s\tremaining: 13.3s\n",
      "321:\tlearn: 0.0022221\ttotal: 24s\tremaining: 13.2s\n",
      "322:\tlearn: 0.0022020\ttotal: 24s\tremaining: 13.2s\n",
      "323:\tlearn: 0.0022019\ttotal: 24.1s\tremaining: 13.1s\n",
      "324:\tlearn: 0.0022019\ttotal: 24.2s\tremaining: 13s\n",
      "325:\tlearn: 0.0022019\ttotal: 24.2s\tremaining: 12.9s\n",
      "326:\tlearn: 0.0022019\ttotal: 24.3s\tremaining: 12.9s\n",
      "327:\tlearn: 0.0022019\ttotal: 24.4s\tremaining: 12.8s\n",
      "328:\tlearn: 0.0022019\ttotal: 24.4s\tremaining: 12.7s\n",
      "329:\tlearn: 0.0022019\ttotal: 24.5s\tremaining: 12.6s\n",
      "330:\tlearn: 0.0022019\ttotal: 24.6s\tremaining: 12.6s\n",
      "331:\tlearn: 0.0022019\ttotal: 24.7s\tremaining: 12.5s\n",
      "332:\tlearn: 0.0022018\ttotal: 24.8s\tremaining: 12.4s\n",
      "333:\tlearn: 0.0022017\ttotal: 24.9s\tremaining: 12.4s\n",
      "334:\tlearn: 0.0021832\ttotal: 24.9s\tremaining: 12.3s\n",
      "335:\tlearn: 0.0021736\ttotal: 25s\tremaining: 12.2s\n",
      "336:\tlearn: 0.0021567\ttotal: 25.1s\tremaining: 12.1s\n",
      "337:\tlearn: 0.0021393\ttotal: 25.1s\tremaining: 12s\n",
      "338:\tlearn: 0.0021392\ttotal: 25.2s\tremaining: 12s\n",
      "339:\tlearn: 0.0021377\ttotal: 25.3s\tremaining: 11.9s\n",
      "340:\tlearn: 0.0021375\ttotal: 25.4s\tremaining: 11.8s\n",
      "341:\tlearn: 0.0021374\ttotal: 25.5s\tremaining: 11.8s\n",
      "342:\tlearn: 0.0021374\ttotal: 25.5s\tremaining: 11.7s\n",
      "343:\tlearn: 0.0021374\ttotal: 25.6s\tremaining: 11.6s\n",
      "344:\tlearn: 0.0021374\ttotal: 25.7s\tremaining: 11.5s\n",
      "345:\tlearn: 0.0021374\ttotal: 25.8s\tremaining: 11.5s\n",
      "346:\tlearn: 0.0021374\ttotal: 25.8s\tremaining: 11.4s\n",
      "347:\tlearn: 0.0021374\ttotal: 25.9s\tremaining: 11.3s\n",
      "348:\tlearn: 0.0021373\ttotal: 26s\tremaining: 11.2s\n",
      "349:\tlearn: 0.0021373\ttotal: 26s\tremaining: 11.1s\n",
      "350:\tlearn: 0.0021373\ttotal: 26.1s\tremaining: 11.1s\n",
      "351:\tlearn: 0.0021373\ttotal: 26.2s\tremaining: 11s\n",
      "352:\tlearn: 0.0021373\ttotal: 26.3s\tremaining: 10.9s\n",
      "353:\tlearn: 0.0021372\ttotal: 26.3s\tremaining: 10.9s\n",
      "354:\tlearn: 0.0021372\ttotal: 26.4s\tremaining: 10.8s\n",
      "355:\tlearn: 0.0021172\ttotal: 26.5s\tremaining: 10.7s\n",
      "356:\tlearn: 0.0021025\ttotal: 26.5s\tremaining: 10.6s\n",
      "357:\tlearn: 0.0021025\ttotal: 26.7s\tremaining: 10.6s\n",
      "358:\tlearn: 0.0021024\ttotal: 26.7s\tremaining: 10.5s\n",
      "359:\tlearn: 0.0021024\ttotal: 26.8s\tremaining: 10.4s\n",
      "360:\tlearn: 0.0021024\ttotal: 26.9s\tremaining: 10.3s\n",
      "361:\tlearn: 0.0021023\ttotal: 26.9s\tremaining: 10.3s\n",
      "362:\tlearn: 0.0021023\ttotal: 27s\tremaining: 10.2s\n",
      "363:\tlearn: 0.0021022\ttotal: 27.1s\tremaining: 10.1s\n",
      "364:\tlearn: 0.0020948\ttotal: 27.2s\tremaining: 10.1s\n",
      "365:\tlearn: 0.0020948\ttotal: 27.2s\tremaining: 9.97s\n",
      "366:\tlearn: 0.0020948\ttotal: 27.3s\tremaining: 9.89s\n",
      "367:\tlearn: 0.0020947\ttotal: 27.4s\tremaining: 9.83s\n",
      "368:\tlearn: 0.0020793\ttotal: 27.4s\tremaining: 9.74s\n",
      "369:\tlearn: 0.0020792\ttotal: 27.6s\tremaining: 9.68s\n",
      "370:\tlearn: 0.0020793\ttotal: 27.6s\tremaining: 9.6s\n",
      "371:\tlearn: 0.0020793\ttotal: 27.7s\tremaining: 9.53s\n",
      "372:\tlearn: 0.0020793\ttotal: 27.8s\tremaining: 9.46s\n",
      "373:\tlearn: 0.0020792\ttotal: 27.8s\tremaining: 9.37s\n",
      "374:\tlearn: 0.0020792\ttotal: 27.9s\tremaining: 9.31s\n",
      "375:\tlearn: 0.0020791\ttotal: 28s\tremaining: 9.23s\n",
      "376:\tlearn: 0.0020790\ttotal: 28.1s\tremaining: 9.16s\n",
      "377:\tlearn: 0.0020631\ttotal: 28.1s\tremaining: 9.08s\n",
      "378:\tlearn: 0.0020465\ttotal: 28.2s\tremaining: 9.01s\n",
      "379:\tlearn: 0.0020464\ttotal: 28.3s\tremaining: 8.94s\n",
      "380:\tlearn: 0.0020464\ttotal: 28.3s\tremaining: 8.85s\n",
      "381:\tlearn: 0.0020464\ttotal: 28.5s\tremaining: 8.79s\n",
      "382:\tlearn: 0.0020464\ttotal: 28.5s\tremaining: 8.71s\n",
      "383:\tlearn: 0.0020464\ttotal: 28.5s\tremaining: 8.62s\n",
      "384:\tlearn: 0.0020464\ttotal: 28.7s\tremaining: 8.56s\n",
      "385:\tlearn: 0.0020464\ttotal: 28.7s\tremaining: 8.48s\n",
      "386:\tlearn: 0.0020465\ttotal: 28.8s\tremaining: 8.42s\n",
      "387:\tlearn: 0.0020465\ttotal: 28.9s\tremaining: 8.35s\n",
      "388:\tlearn: 0.0020464\ttotal: 29s\tremaining: 8.27s\n",
      "389:\tlearn: 0.0020464\ttotal: 29.1s\tremaining: 8.2s\n",
      "390:\tlearn: 0.0020464\ttotal: 29.1s\tremaining: 8.12s\n",
      "391:\tlearn: 0.0020463\ttotal: 29.2s\tremaining: 8.05s\n",
      "392:\tlearn: 0.0020463\ttotal: 29.3s\tremaining: 7.97s\n",
      "393:\tlearn: 0.0020288\ttotal: 29.3s\tremaining: 7.89s\n",
      "394:\tlearn: 0.0020288\ttotal: 29.4s\tremaining: 7.81s\n",
      "395:\tlearn: 0.0020289\ttotal: 29.4s\tremaining: 7.73s\n",
      "396:\tlearn: 0.0020288\ttotal: 29.5s\tremaining: 7.65s\n",
      "397:\tlearn: 0.0020288\ttotal: 29.6s\tremaining: 7.58s\n",
      "398:\tlearn: 0.0020288\ttotal: 29.6s\tremaining: 7.5s\n",
      "399:\tlearn: 0.0020288\ttotal: 29.7s\tremaining: 7.43s\n",
      "400:\tlearn: 0.0020287\ttotal: 29.8s\tremaining: 7.35s\n",
      "401:\tlearn: 0.0020287\ttotal: 29.8s\tremaining: 7.27s\n",
      "402:\tlearn: 0.0020287\ttotal: 29.9s\tremaining: 7.19s\n",
      "403:\tlearn: 0.0020287\ttotal: 30s\tremaining: 7.13s\n",
      "404:\tlearn: 0.0020287\ttotal: 30.1s\tremaining: 7.05s\n",
      "405:\tlearn: 0.0020287\ttotal: 30.1s\tremaining: 6.97s\n",
      "406:\tlearn: 0.0020287\ttotal: 30.2s\tremaining: 6.9s\n",
      "407:\tlearn: 0.0020286\ttotal: 30.3s\tremaining: 6.82s\n",
      "408:\tlearn: 0.0020286\ttotal: 30.4s\tremaining: 6.76s\n",
      "409:\tlearn: 0.0020286\ttotal: 30.4s\tremaining: 6.68s\n",
      "410:\tlearn: 0.0020286\ttotal: 30.5s\tremaining: 6.61s\n",
      "411:\tlearn: 0.0020090\ttotal: 30.6s\tremaining: 6.53s\n",
      "412:\tlearn: 0.0019975\ttotal: 30.7s\tremaining: 6.46s\n",
      "413:\tlearn: 0.0019975\ttotal: 30.8s\tremaining: 6.39s\n",
      "414:\tlearn: 0.0019975\ttotal: 30.8s\tremaining: 6.31s\n",
      "415:\tlearn: 0.0019974\ttotal: 30.9s\tremaining: 6.24s\n",
      "416:\tlearn: 0.0019974\ttotal: 31s\tremaining: 6.16s\n",
      "417:\tlearn: 0.0019974\ttotal: 31.1s\tremaining: 6.09s\n",
      "418:\tlearn: 0.0019872\ttotal: 31.1s\tremaining: 6.02s\n",
      "419:\tlearn: 0.0019872\ttotal: 31.2s\tremaining: 5.94s\n",
      "420:\tlearn: 0.0019872\ttotal: 31.3s\tremaining: 5.87s\n",
      "421:\tlearn: 0.0019872\ttotal: 31.3s\tremaining: 5.79s\n",
      "422:\tlearn: 0.0019871\ttotal: 31.4s\tremaining: 5.72s\n",
      "423:\tlearn: 0.0019871\ttotal: 31.5s\tremaining: 5.64s\n",
      "424:\tlearn: 0.0019871\ttotal: 31.6s\tremaining: 5.57s\n",
      "425:\tlearn: 0.0019872\ttotal: 31.6s\tremaining: 5.49s\n",
      "426:\tlearn: 0.0019871\ttotal: 31.7s\tremaining: 5.42s\n",
      "427:\tlearn: 0.0019871\ttotal: 31.8s\tremaining: 5.35s\n",
      "428:\tlearn: 0.0019870\ttotal: 31.8s\tremaining: 5.27s\n",
      "429:\tlearn: 0.0019871\ttotal: 32s\tremaining: 5.2s\n",
      "430:\tlearn: 0.0019870\ttotal: 32s\tremaining: 5.12s\n",
      "431:\tlearn: 0.0019870\ttotal: 32.1s\tremaining: 5.05s\n",
      "432:\tlearn: 0.0019712\ttotal: 32.2s\tremaining: 4.97s\n",
      "433:\tlearn: 0.0019712\ttotal: 32.3s\tremaining: 4.91s\n",
      "434:\tlearn: 0.0019712\ttotal: 32.3s\tremaining: 4.83s\n",
      "435:\tlearn: 0.0019594\ttotal: 32.4s\tremaining: 4.76s\n",
      "436:\tlearn: 0.0019541\ttotal: 32.5s\tremaining: 4.68s\n",
      "437:\tlearn: 0.0019541\ttotal: 32.6s\tremaining: 4.61s\n",
      "438:\tlearn: 0.0019541\ttotal: 32.6s\tremaining: 4.53s\n",
      "439:\tlearn: 0.0019541\ttotal: 32.7s\tremaining: 4.46s\n",
      "440:\tlearn: 0.0019540\ttotal: 32.8s\tremaining: 4.38s\n",
      "441:\tlearn: 0.0019540\ttotal: 32.8s\tremaining: 4.31s\n",
      "442:\tlearn: 0.0019540\ttotal: 32.9s\tremaining: 4.24s\n",
      "443:\tlearn: 0.0019540\ttotal: 33s\tremaining: 4.16s\n",
      "444:\tlearn: 0.0019539\ttotal: 33s\tremaining: 4.08s\n",
      "445:\tlearn: 0.0019539\ttotal: 33.1s\tremaining: 4.01s\n",
      "446:\tlearn: 0.0019540\ttotal: 33.2s\tremaining: 3.94s\n",
      "447:\tlearn: 0.0019540\ttotal: 33.3s\tremaining: 3.86s\n",
      "448:\tlearn: 0.0019540\ttotal: 33.4s\tremaining: 3.79s\n",
      "449:\tlearn: 0.0019539\ttotal: 33.5s\tremaining: 3.72s\n",
      "450:\tlearn: 0.0019539\ttotal: 33.5s\tremaining: 3.64s\n",
      "451:\tlearn: 0.0019539\ttotal: 33.6s\tremaining: 3.57s\n",
      "452:\tlearn: 0.0019539\ttotal: 33.7s\tremaining: 3.49s\n",
      "453:\tlearn: 0.0019539\ttotal: 33.8s\tremaining: 3.42s\n",
      "454:\tlearn: 0.0019539\ttotal: 33.8s\tremaining: 3.34s\n",
      "455:\tlearn: 0.0019539\ttotal: 33.9s\tremaining: 3.27s\n",
      "456:\tlearn: 0.0019539\ttotal: 34s\tremaining: 3.2s\n",
      "457:\tlearn: 0.0019539\ttotal: 34.1s\tremaining: 3.13s\n",
      "458:\tlearn: 0.0019539\ttotal: 34.2s\tremaining: 3.05s\n",
      "459:\tlearn: 0.0019539\ttotal: 34.2s\tremaining: 2.97s\n",
      "460:\tlearn: 0.0019539\ttotal: 34.3s\tremaining: 2.9s\n",
      "461:\tlearn: 0.0019413\ttotal: 34.4s\tremaining: 2.83s\n",
      "462:\tlearn: 0.0019413\ttotal: 34.5s\tremaining: 2.75s\n",
      "463:\tlearn: 0.0019369\ttotal: 34.5s\tremaining: 2.68s\n",
      "464:\tlearn: 0.0019369\ttotal: 34.6s\tremaining: 2.6s\n",
      "465:\tlearn: 0.0019369\ttotal: 34.7s\tremaining: 2.53s\n",
      "466:\tlearn: 0.0019368\ttotal: 34.7s\tremaining: 2.45s\n",
      "467:\tlearn: 0.0019368\ttotal: 34.8s\tremaining: 2.38s\n",
      "468:\tlearn: 0.0019368\ttotal: 34.9s\tremaining: 2.31s\n",
      "469:\tlearn: 0.0019367\ttotal: 35s\tremaining: 2.23s\n",
      "470:\tlearn: 0.0019367\ttotal: 35.1s\tremaining: 2.16s\n",
      "471:\tlearn: 0.0019366\ttotal: 35.1s\tremaining: 2.08s\n",
      "472:\tlearn: 0.0019366\ttotal: 35.2s\tremaining: 2.01s\n",
      "473:\tlearn: 0.0019366\ttotal: 35.3s\tremaining: 1.93s\n",
      "474:\tlearn: 0.0019366\ttotal: 35.3s\tremaining: 1.86s\n",
      "475:\tlearn: 0.0019366\ttotal: 35.4s\tremaining: 1.78s\n",
      "476:\tlearn: 0.0019366\ttotal: 35.5s\tremaining: 1.71s\n",
      "477:\tlearn: 0.0019366\ttotal: 35.6s\tremaining: 1.64s\n",
      "478:\tlearn: 0.0019366\ttotal: 35.7s\tremaining: 1.56s\n",
      "479:\tlearn: 0.0019365\ttotal: 35.7s\tremaining: 1.49s\n",
      "480:\tlearn: 0.0019365\ttotal: 35.8s\tremaining: 1.41s\n",
      "481:\tlearn: 0.0019365\ttotal: 35.9s\tremaining: 1.34s\n",
      "482:\tlearn: 0.0019365\ttotal: 35.9s\tremaining: 1.26s\n",
      "483:\tlearn: 0.0019365\ttotal: 36s\tremaining: 1.19s\n",
      "484:\tlearn: 0.0019365\ttotal: 36.1s\tremaining: 1.11s\n",
      "485:\tlearn: 0.0019365\ttotal: 36.2s\tremaining: 1.04s\n",
      "486:\tlearn: 0.0019364\ttotal: 36.3s\tremaining: 968ms\n",
      "487:\tlearn: 0.0019365\ttotal: 36.3s\tremaining: 893ms\n",
      "488:\tlearn: 0.0019364\ttotal: 36.4s\tremaining: 819ms\n",
      "489:\tlearn: 0.0019365\ttotal: 36.5s\tremaining: 744ms\n",
      "490:\tlearn: 0.0019364\ttotal: 36.6s\tremaining: 671ms\n",
      "491:\tlearn: 0.0019364\ttotal: 36.6s\tremaining: 596ms\n",
      "492:\tlearn: 0.0019261\ttotal: 36.7s\tremaining: 521ms\n",
      "493:\tlearn: 0.0019261\ttotal: 36.8s\tremaining: 447ms\n",
      "494:\tlearn: 0.0019260\ttotal: 36.8s\tremaining: 372ms\n",
      "495:\tlearn: 0.0019260\ttotal: 36.9s\tremaining: 298ms\n",
      "496:\tlearn: 0.0019261\ttotal: 37s\tremaining: 223ms\n",
      "497:\tlearn: 0.0019261\ttotal: 37s\tremaining: 149ms\n",
      "498:\tlearn: 0.0019260\ttotal: 37.1s\tremaining: 74.4ms\n",
      "499:\tlearn: 0.0019260\ttotal: 37.2s\tremaining: 0us\n",
      "0:\tlearn: 0.6547755\ttotal: 46.3ms\tremaining: 23.1s\n",
      "1:\tlearn: 0.6124309\ttotal: 167ms\tremaining: 41.5s\n",
      "2:\tlearn: 0.5784018\ttotal: 213ms\tremaining: 35.3s\n",
      "3:\tlearn: 0.5438862\ttotal: 304ms\tremaining: 37.7s\n",
      "4:\tlearn: 0.5115564\ttotal: 372ms\tremaining: 36.8s\n",
      "5:\tlearn: 0.4817899\ttotal: 416ms\tremaining: 34.2s\n",
      "6:\tlearn: 0.4577532\ttotal: 539ms\tremaining: 38s\n",
      "7:\tlearn: 0.4358253\ttotal: 577ms\tremaining: 35.5s\n",
      "8:\tlearn: 0.4219351\ttotal: 618ms\tremaining: 33.7s\n",
      "9:\tlearn: 0.3912446\ttotal: 726ms\tremaining: 35.6s\n",
      "10:\tlearn: 0.3799252\ttotal: 785ms\tremaining: 34.9s\n",
      "11:\tlearn: 0.3636569\ttotal: 828ms\tremaining: 33.7s\n",
      "12:\tlearn: 0.3485487\ttotal: 937ms\tremaining: 35.1s\n",
      "13:\tlearn: 0.3338641\ttotal: 985ms\tremaining: 34.2s\n",
      "14:\tlearn: 0.3173287\ttotal: 1.11s\tremaining: 35.9s\n",
      "15:\tlearn: 0.3009955\ttotal: 1.16s\tremaining: 35s\n",
      "16:\tlearn: 0.2869647\ttotal: 1.27s\tremaining: 36.2s\n",
      "17:\tlearn: 0.2761672\ttotal: 1.33s\tremaining: 35.6s\n",
      "18:\tlearn: 0.2638366\ttotal: 1.38s\tremaining: 34.8s\n",
      "19:\tlearn: 0.2511302\ttotal: 1.48s\tremaining: 35.6s\n",
      "20:\tlearn: 0.2424289\ttotal: 1.52s\tremaining: 34.8s\n",
      "21:\tlearn: 0.2290248\ttotal: 1.64s\tremaining: 35.6s\n",
      "22:\tlearn: 0.2200579\ttotal: 1.69s\tremaining: 35.1s\n",
      "23:\tlearn: 0.2070230\ttotal: 1.81s\tremaining: 35.9s\n",
      "24:\tlearn: 0.1971154\ttotal: 1.86s\tremaining: 35.4s\n",
      "25:\tlearn: 0.1873496\ttotal: 1.95s\tremaining: 35.6s\n",
      "26:\tlearn: 0.1821695\ttotal: 2.03s\tremaining: 35.5s\n",
      "27:\tlearn: 0.1752008\ttotal: 2.07s\tremaining: 34.9s\n",
      "28:\tlearn: 0.1680327\ttotal: 2.2s\tremaining: 35.7s\n",
      "29:\tlearn: 0.1643660\ttotal: 2.24s\tremaining: 35.1s\n",
      "30:\tlearn: 0.1585187\ttotal: 2.39s\tremaining: 36.2s\n",
      "31:\tlearn: 0.1496120\ttotal: 2.47s\tremaining: 36.2s\n",
      "32:\tlearn: 0.1449972\ttotal: 2.59s\tremaining: 36.6s\n",
      "33:\tlearn: 0.1390177\ttotal: 2.63s\tremaining: 36s\n",
      "34:\tlearn: 0.1339971\ttotal: 2.74s\tremaining: 36.4s\n",
      "35:\tlearn: 0.1272585\ttotal: 2.78s\tremaining: 35.9s\n",
      "36:\tlearn: 0.1242062\ttotal: 2.84s\tremaining: 35.5s\n",
      "37:\tlearn: 0.1204518\ttotal: 2.91s\tremaining: 35.4s\n",
      "38:\tlearn: 0.1163524\ttotal: 2.95s\tremaining: 34.9s\n",
      "39:\tlearn: 0.1118899\ttotal: 3.07s\tremaining: 35.3s\n",
      "40:\tlearn: 0.1087076\ttotal: 3.12s\tremaining: 34.9s\n",
      "41:\tlearn: 0.1058913\ttotal: 3.16s\tremaining: 34.5s\n",
      "42:\tlearn: 0.1026082\ttotal: 3.26s\tremaining: 34.7s\n",
      "43:\tlearn: 0.0998590\ttotal: 3.33s\tremaining: 34.5s\n",
      "44:\tlearn: 0.0961624\ttotal: 3.36s\tremaining: 34s\n",
      "45:\tlearn: 0.0938131\ttotal: 3.48s\tremaining: 34.3s\n",
      "46:\tlearn: 0.0906658\ttotal: 3.52s\tremaining: 33.9s\n",
      "47:\tlearn: 0.0870265\ttotal: 3.63s\tremaining: 34.2s\n",
      "48:\tlearn: 0.0839725\ttotal: 3.69s\tremaining: 33.9s\n",
      "49:\tlearn: 0.0799694\ttotal: 3.77s\tremaining: 34s\n",
      "50:\tlearn: 0.0777034\ttotal: 3.85s\tremaining: 33.9s\n",
      "51:\tlearn: 0.0752118\ttotal: 3.9s\tremaining: 33.6s\n",
      "52:\tlearn: 0.0727040\ttotal: 4.01s\tremaining: 33.8s\n",
      "53:\tlearn: 0.0705027\ttotal: 4.05s\tremaining: 33.5s\n",
      "54:\tlearn: 0.0684356\ttotal: 4.14s\tremaining: 33.5s\n",
      "55:\tlearn: 0.0664416\ttotal: 4.21s\tremaining: 33.4s\n",
      "56:\tlearn: 0.0637679\ttotal: 4.25s\tremaining: 33s\n",
      "57:\tlearn: 0.0618488\ttotal: 4.37s\tremaining: 33.3s\n",
      "58:\tlearn: 0.0589549\ttotal: 4.41s\tremaining: 33s\n",
      "59:\tlearn: 0.0572649\ttotal: 4.5s\tremaining: 33s\n",
      "60:\tlearn: 0.0556088\ttotal: 4.56s\tremaining: 32.8s\n",
      "61:\tlearn: 0.0535236\ttotal: 4.61s\tremaining: 32.5s\n",
      "62:\tlearn: 0.0510042\ttotal: 4.7s\tremaining: 32.6s\n",
      "63:\tlearn: 0.0496481\ttotal: 4.75s\tremaining: 32.3s\n",
      "64:\tlearn: 0.0480306\ttotal: 4.87s\tremaining: 32.6s\n",
      "65:\tlearn: 0.0471389\ttotal: 4.91s\tremaining: 32.3s\n",
      "66:\tlearn: 0.0452167\ttotal: 5.02s\tremaining: 32.5s\n",
      "67:\tlearn: 0.0440379\ttotal: 5.08s\tremaining: 32.3s\n",
      "68:\tlearn: 0.0429865\ttotal: 5.12s\tremaining: 32s\n",
      "69:\tlearn: 0.0418493\ttotal: 5.23s\tremaining: 32.1s\n",
      "70:\tlearn: 0.0410864\ttotal: 5.28s\tremaining: 31.9s\n",
      "71:\tlearn: 0.0400856\ttotal: 5.4s\tremaining: 32.1s\n",
      "72:\tlearn: 0.0387856\ttotal: 5.44s\tremaining: 31.8s\n",
      "73:\tlearn: 0.0376954\ttotal: 5.55s\tremaining: 32s\n",
      "74:\tlearn: 0.0367167\ttotal: 5.61s\tremaining: 31.8s\n",
      "75:\tlearn: 0.0359246\ttotal: 5.7s\tremaining: 31.8s\n",
      "76:\tlearn: 0.0347327\ttotal: 5.79s\tremaining: 31.8s\n",
      "77:\tlearn: 0.0337172\ttotal: 5.83s\tremaining: 31.5s\n",
      "78:\tlearn: 0.0325758\ttotal: 5.94s\tremaining: 31.7s\n",
      "79:\tlearn: 0.0315890\ttotal: 5.99s\tremaining: 31.5s\n",
      "80:\tlearn: 0.0307814\ttotal: 6.04s\tremaining: 31.3s\n",
      "81:\tlearn: 0.0294829\ttotal: 6.14s\tremaining: 31.3s\n",
      "82:\tlearn: 0.0286025\ttotal: 6.19s\tremaining: 31.1s\n",
      "83:\tlearn: 0.0280323\ttotal: 6.31s\tremaining: 31.2s\n",
      "84:\tlearn: 0.0272416\ttotal: 6.36s\tremaining: 31.1s\n",
      "85:\tlearn: 0.0264379\ttotal: 6.46s\tremaining: 31.1s\n",
      "86:\tlearn: 0.0257395\ttotal: 6.53s\tremaining: 31s\n",
      "87:\tlearn: 0.0253182\ttotal: 6.57s\tremaining: 30.8s\n",
      "88:\tlearn: 0.0246801\ttotal: 6.69s\tremaining: 30.9s\n",
      "89:\tlearn: 0.0239596\ttotal: 6.73s\tremaining: 30.7s\n",
      "90:\tlearn: 0.0234486\ttotal: 6.84s\tremaining: 30.8s\n",
      "91:\tlearn: 0.0227761\ttotal: 6.9s\tremaining: 30.6s\n",
      "92:\tlearn: 0.0220956\ttotal: 6.99s\tremaining: 30.6s\n",
      "93:\tlearn: 0.0215392\ttotal: 7.06s\tremaining: 30.5s\n",
      "94:\tlearn: 0.0208704\ttotal: 7.1s\tremaining: 30.3s\n",
      "95:\tlearn: 0.0204243\ttotal: 7.21s\tremaining: 30.4s\n",
      "96:\tlearn: 0.0199470\ttotal: 7.26s\tremaining: 30.2s\n",
      "97:\tlearn: 0.0193183\ttotal: 7.31s\tremaining: 30s\n",
      "98:\tlearn: 0.0189097\ttotal: 7.42s\tremaining: 30.1s\n",
      "99:\tlearn: 0.0184928\ttotal: 7.47s\tremaining: 29.9s\n",
      "100:\tlearn: 0.0180895\ttotal: 7.58s\tremaining: 29.9s\n",
      "101:\tlearn: 0.0176524\ttotal: 7.63s\tremaining: 29.8s\n",
      "102:\tlearn: 0.0173640\ttotal: 7.67s\tremaining: 29.6s\n",
      "103:\tlearn: 0.0169465\ttotal: 7.78s\tremaining: 29.6s\n",
      "104:\tlearn: 0.0165924\ttotal: 7.82s\tremaining: 29.4s\n",
      "105:\tlearn: 0.0161831\ttotal: 7.91s\tremaining: 29.4s\n",
      "106:\tlearn: 0.0157618\ttotal: 7.97s\tremaining: 29.3s\n",
      "107:\tlearn: 0.0154370\ttotal: 8.02s\tremaining: 29.1s\n",
      "108:\tlearn: 0.0149979\ttotal: 8.13s\tremaining: 29.2s\n",
      "109:\tlearn: 0.0145196\ttotal: 8.18s\tremaining: 29s\n",
      "110:\tlearn: 0.0142030\ttotal: 8.29s\tremaining: 29s\n",
      "111:\tlearn: 0.0139314\ttotal: 8.34s\tremaining: 28.9s\n",
      "112:\tlearn: 0.0136674\ttotal: 8.38s\tremaining: 28.7s\n",
      "113:\tlearn: 0.0133564\ttotal: 8.49s\tremaining: 28.8s\n",
      "114:\tlearn: 0.0129686\ttotal: 8.54s\tremaining: 28.6s\n",
      "115:\tlearn: 0.0126122\ttotal: 8.64s\tremaining: 28.6s\n",
      "116:\tlearn: 0.0123670\ttotal: 8.69s\tremaining: 28.5s\n",
      "117:\tlearn: 0.0121512\ttotal: 8.75s\tremaining: 28.3s\n",
      "118:\tlearn: 0.0119627\ttotal: 8.85s\tremaining: 28.3s\n",
      "119:\tlearn: 0.0117474\ttotal: 8.9s\tremaining: 28.2s\n",
      "120:\tlearn: 0.0114440\ttotal: 9.02s\tremaining: 28.3s\n",
      "121:\tlearn: 0.0112788\ttotal: 9.07s\tremaining: 28.1s\n",
      "122:\tlearn: 0.0111203\ttotal: 9.19s\tremaining: 28.2s\n",
      "123:\tlearn: 0.0109247\ttotal: 9.23s\tremaining: 28s\n",
      "124:\tlearn: 0.0107004\ttotal: 9.33s\tremaining: 28s\n",
      "125:\tlearn: 0.0104831\ttotal: 9.4s\tremaining: 27.9s\n",
      "126:\tlearn: 0.0102629\ttotal: 9.44s\tremaining: 27.7s\n",
      "127:\tlearn: 0.0100783\ttotal: 9.55s\tremaining: 27.8s\n",
      "128:\tlearn: 0.0099179\ttotal: 9.6s\tremaining: 27.6s\n",
      "129:\tlearn: 0.0097520\ttotal: 9.72s\tremaining: 27.7s\n",
      "130:\tlearn: 0.0095154\ttotal: 9.77s\tremaining: 27.5s\n",
      "131:\tlearn: 0.0093805\ttotal: 9.81s\tremaining: 27.3s\n",
      "132:\tlearn: 0.0091938\ttotal: 9.91s\tremaining: 27.4s\n",
      "133:\tlearn: 0.0090526\ttotal: 9.96s\tremaining: 27.2s\n",
      "134:\tlearn: 0.0088922\ttotal: 10.1s\tremaining: 27.2s\n",
      "135:\tlearn: 0.0087535\ttotal: 10.1s\tremaining: 27.1s\n",
      "136:\tlearn: 0.0086057\ttotal: 10.2s\tremaining: 27.1s\n",
      "137:\tlearn: 0.0084340\ttotal: 10.3s\tremaining: 27s\n",
      "138:\tlearn: 0.0082867\ttotal: 10.3s\tremaining: 26.8s\n",
      "139:\tlearn: 0.0081670\ttotal: 10.5s\tremaining: 26.9s\n",
      "140:\tlearn: 0.0080673\ttotal: 10.5s\tremaining: 26.7s\n",
      "141:\tlearn: 0.0079503\ttotal: 10.6s\tremaining: 26.8s\n",
      "142:\tlearn: 0.0078279\ttotal: 10.7s\tremaining: 26.6s\n",
      "143:\tlearn: 0.0076864\ttotal: 10.8s\tremaining: 26.6s\n",
      "144:\tlearn: 0.0075888\ttotal: 10.8s\tremaining: 26.5s\n",
      "145:\tlearn: 0.0074884\ttotal: 10.9s\tremaining: 26.4s\n",
      "146:\tlearn: 0.0073897\ttotal: 11s\tremaining: 26.4s\n",
      "147:\tlearn: 0.0072984\ttotal: 11s\tremaining: 26.2s\n",
      "148:\tlearn: 0.0072092\ttotal: 11.1s\tremaining: 26.2s\n",
      "149:\tlearn: 0.0070836\ttotal: 11.2s\tremaining: 26.1s\n",
      "150:\tlearn: 0.0069693\ttotal: 11.3s\tremaining: 26s\n",
      "151:\tlearn: 0.0068497\ttotal: 11.3s\tremaining: 26s\n",
      "152:\tlearn: 0.0067547\ttotal: 11.4s\tremaining: 26s\n",
      "153:\tlearn: 0.0066677\ttotal: 11.5s\tremaining: 25.9s\n",
      "154:\tlearn: 0.0065584\ttotal: 11.6s\tremaining: 25.7s\n",
      "155:\tlearn: 0.0064605\ttotal: 11.7s\tremaining: 25.8s\n",
      "156:\tlearn: 0.0064042\ttotal: 11.7s\tremaining: 25.7s\n",
      "157:\tlearn: 0.0063283\ttotal: 11.8s\tremaining: 25.5s\n",
      "158:\tlearn: 0.0062692\ttotal: 11.9s\tremaining: 25.5s\n",
      "159:\tlearn: 0.0062146\ttotal: 12s\tremaining: 25.4s\n",
      "160:\tlearn: 0.0060975\ttotal: 12s\tremaining: 25.4s\n",
      "161:\tlearn: 0.0060135\ttotal: 12.1s\tremaining: 25.3s\n",
      "162:\tlearn: 0.0059110\ttotal: 12.2s\tremaining: 25.1s\n",
      "163:\tlearn: 0.0058456\ttotal: 12.3s\tremaining: 25.1s\n",
      "164:\tlearn: 0.0057538\ttotal: 12.3s\tremaining: 25s\n",
      "165:\tlearn: 0.0056922\ttotal: 12.4s\tremaining: 25s\n",
      "166:\tlearn: 0.0056246\ttotal: 12.5s\tremaining: 24.9s\n",
      "167:\tlearn: 0.0055543\ttotal: 12.6s\tremaining: 24.8s\n",
      "168:\tlearn: 0.0054756\ttotal: 12.7s\tremaining: 24.9s\n",
      "169:\tlearn: 0.0054120\ttotal: 12.8s\tremaining: 24.8s\n",
      "170:\tlearn: 0.0053408\ttotal: 12.8s\tremaining: 24.7s\n",
      "171:\tlearn: 0.0052992\ttotal: 12.9s\tremaining: 24.6s\n",
      "172:\tlearn: 0.0052458\ttotal: 13s\tremaining: 24.5s\n",
      "173:\tlearn: 0.0051484\ttotal: 13s\tremaining: 24.4s\n",
      "174:\tlearn: 0.0050723\ttotal: 13.1s\tremaining: 24.3s\n",
      "175:\tlearn: 0.0050269\ttotal: 13.2s\tremaining: 24.3s\n",
      "176:\tlearn: 0.0049780\ttotal: 13.2s\tremaining: 24.1s\n",
      "177:\tlearn: 0.0049112\ttotal: 13.3s\tremaining: 24.1s\n",
      "178:\tlearn: 0.0048498\ttotal: 13.4s\tremaining: 24s\n",
      "179:\tlearn: 0.0047875\ttotal: 13.4s\tremaining: 23.9s\n",
      "180:\tlearn: 0.0047264\ttotal: 13.6s\tremaining: 23.9s\n",
      "181:\tlearn: 0.0046590\ttotal: 13.6s\tremaining: 23.8s\n",
      "182:\tlearn: 0.0046044\ttotal: 13.7s\tremaining: 23.8s\n",
      "183:\tlearn: 0.0045544\ttotal: 13.8s\tremaining: 23.7s\n",
      "184:\tlearn: 0.0045106\ttotal: 13.9s\tremaining: 23.6s\n",
      "185:\tlearn: 0.0044628\ttotal: 13.9s\tremaining: 23.5s\n",
      "186:\tlearn: 0.0044171\ttotal: 14s\tremaining: 23.5s\n",
      "187:\tlearn: 0.0043800\ttotal: 14.1s\tremaining: 23.4s\n",
      "188:\tlearn: 0.0043378\ttotal: 14.1s\tremaining: 23.3s\n",
      "189:\tlearn: 0.0043033\ttotal: 14.2s\tremaining: 23.2s\n",
      "190:\tlearn: 0.0042475\ttotal: 14.3s\tremaining: 23.1s\n",
      "191:\tlearn: 0.0042085\ttotal: 14.4s\tremaining: 23.1s\n",
      "192:\tlearn: 0.0041563\ttotal: 14.5s\tremaining: 23s\n",
      "193:\tlearn: 0.0041103\ttotal: 14.5s\tremaining: 22.9s\n",
      "194:\tlearn: 0.0040730\ttotal: 14.6s\tremaining: 22.9s\n",
      "195:\tlearn: 0.0040386\ttotal: 14.7s\tremaining: 22.7s\n",
      "196:\tlearn: 0.0040094\ttotal: 14.8s\tremaining: 22.7s\n",
      "197:\tlearn: 0.0039831\ttotal: 14.8s\tremaining: 22.6s\n",
      "198:\tlearn: 0.0039509\ttotal: 14.9s\tremaining: 22.5s\n",
      "199:\tlearn: 0.0039230\ttotal: 15s\tremaining: 22.4s\n",
      "200:\tlearn: 0.0038764\ttotal: 15s\tremaining: 22.3s\n",
      "201:\tlearn: 0.0038314\ttotal: 15.1s\tremaining: 22.3s\n",
      "202:\tlearn: 0.0037951\ttotal: 15.2s\tremaining: 22.2s\n",
      "203:\tlearn: 0.0037594\ttotal: 15.3s\tremaining: 22.2s\n",
      "204:\tlearn: 0.0037306\ttotal: 15.3s\tremaining: 22s\n",
      "205:\tlearn: 0.0036886\ttotal: 15.4s\tremaining: 22s\n",
      "206:\tlearn: 0.0036456\ttotal: 15.5s\tremaining: 21.9s\n",
      "207:\tlearn: 0.0035951\ttotal: 15.5s\tremaining: 21.8s\n",
      "208:\tlearn: 0.0035722\ttotal: 15.6s\tremaining: 21.8s\n",
      "209:\tlearn: 0.0035453\ttotal: 15.7s\tremaining: 21.6s\n",
      "210:\tlearn: 0.0035148\ttotal: 15.8s\tremaining: 21.6s\n",
      "211:\tlearn: 0.0034867\ttotal: 15.8s\tremaining: 21.5s\n",
      "212:\tlearn: 0.0034401\ttotal: 15.9s\tremaining: 21.5s\n",
      "213:\tlearn: 0.0034105\ttotal: 16s\tremaining: 21.4s\n",
      "214:\tlearn: 0.0033802\ttotal: 16.1s\tremaining: 21.3s\n",
      "215:\tlearn: 0.0033500\ttotal: 16.2s\tremaining: 21.3s\n",
      "216:\tlearn: 0.0033191\ttotal: 16.2s\tremaining: 21.2s\n",
      "217:\tlearn: 0.0032761\ttotal: 16.3s\tremaining: 21.1s\n",
      "218:\tlearn: 0.0032497\ttotal: 16.4s\tremaining: 21s\n",
      "219:\tlearn: 0.0032053\ttotal: 16.5s\tremaining: 21s\n",
      "220:\tlearn: 0.0031806\ttotal: 16.5s\tremaining: 20.9s\n",
      "221:\tlearn: 0.0031476\ttotal: 16.6s\tremaining: 20.8s\n",
      "222:\tlearn: 0.0031073\ttotal: 16.7s\tremaining: 20.7s\n",
      "223:\tlearn: 0.0030868\ttotal: 16.7s\tremaining: 20.6s\n",
      "224:\tlearn: 0.0030678\ttotal: 16.8s\tremaining: 20.5s\n",
      "225:\tlearn: 0.0030385\ttotal: 16.9s\tremaining: 20.5s\n",
      "226:\tlearn: 0.0030058\ttotal: 16.9s\tremaining: 20.4s\n",
      "227:\tlearn: 0.0029843\ttotal: 17.1s\tremaining: 20.4s\n",
      "228:\tlearn: 0.0029600\ttotal: 17.1s\tremaining: 20.3s\n",
      "229:\tlearn: 0.0029388\ttotal: 17.2s\tremaining: 20.2s\n",
      "230:\tlearn: 0.0029110\ttotal: 17.3s\tremaining: 20.1s\n",
      "231:\tlearn: 0.0028909\ttotal: 17.3s\tremaining: 20s\n",
      "232:\tlearn: 0.0028520\ttotal: 17.4s\tremaining: 20s\n",
      "233:\tlearn: 0.0028263\ttotal: 17.5s\tremaining: 19.9s\n",
      "234:\tlearn: 0.0028091\ttotal: 17.6s\tremaining: 19.9s\n",
      "235:\tlearn: 0.0027895\ttotal: 17.7s\tremaining: 19.8s\n",
      "236:\tlearn: 0.0027715\ttotal: 17.7s\tremaining: 19.7s\n",
      "237:\tlearn: 0.0027483\ttotal: 17.8s\tremaining: 19.6s\n",
      "238:\tlearn: 0.0027229\ttotal: 17.9s\tremaining: 19.5s\n",
      "239:\tlearn: 0.0026999\ttotal: 18s\tremaining: 19.5s\n",
      "240:\tlearn: 0.0026815\ttotal: 18s\tremaining: 19.4s\n",
      "241:\tlearn: 0.0026814\ttotal: 18.1s\tremaining: 19.3s\n",
      "242:\tlearn: 0.0026597\ttotal: 18.2s\tremaining: 19.2s\n",
      "243:\tlearn: 0.0026357\ttotal: 18.3s\tremaining: 19.2s\n",
      "244:\tlearn: 0.0026099\ttotal: 18.3s\tremaining: 19.1s\n",
      "245:\tlearn: 0.0026098\ttotal: 18.4s\tremaining: 19s\n",
      "246:\tlearn: 0.0026098\ttotal: 18.5s\tremaining: 19s\n",
      "247:\tlearn: 0.0026099\ttotal: 18.6s\tremaining: 18.8s\n",
      "248:\tlearn: 0.0025905\ttotal: 18.7s\tremaining: 18.8s\n",
      "249:\tlearn: 0.0025905\ttotal: 18.7s\tremaining: 18.7s\n",
      "250:\tlearn: 0.0025905\ttotal: 18.8s\tremaining: 18.7s\n",
      "251:\tlearn: 0.0025904\ttotal: 18.9s\tremaining: 18.6s\n",
      "252:\tlearn: 0.0025904\ttotal: 18.9s\tremaining: 18.5s\n",
      "253:\tlearn: 0.0025903\ttotal: 19s\tremaining: 18.4s\n",
      "254:\tlearn: 0.0025903\ttotal: 19.1s\tremaining: 18.3s\n",
      "255:\tlearn: 0.0025688\ttotal: 19.2s\tremaining: 18.3s\n",
      "256:\tlearn: 0.0025472\ttotal: 19.3s\tremaining: 18.2s\n",
      "257:\tlearn: 0.0025472\ttotal: 19.3s\tremaining: 18.1s\n",
      "258:\tlearn: 0.0025315\ttotal: 19.4s\tremaining: 18.1s\n",
      "259:\tlearn: 0.0025315\ttotal: 19.5s\tremaining: 18s\n",
      "260:\tlearn: 0.0025315\ttotal: 19.5s\tremaining: 17.9s\n",
      "261:\tlearn: 0.0025315\ttotal: 19.6s\tremaining: 17.8s\n",
      "262:\tlearn: 0.0025315\ttotal: 19.7s\tremaining: 17.7s\n",
      "263:\tlearn: 0.0025314\ttotal: 19.8s\tremaining: 17.7s\n",
      "264:\tlearn: 0.0025314\ttotal: 19.8s\tremaining: 17.6s\n",
      "265:\tlearn: 0.0025312\ttotal: 19.9s\tremaining: 17.5s\n",
      "266:\tlearn: 0.0025312\ttotal: 20s\tremaining: 17.4s\n",
      "267:\tlearn: 0.0025312\ttotal: 20s\tremaining: 17.4s\n",
      "268:\tlearn: 0.0025312\ttotal: 20.1s\tremaining: 17.3s\n",
      "269:\tlearn: 0.0025133\ttotal: 20.2s\tremaining: 17.2s\n",
      "270:\tlearn: 0.0025133\ttotal: 20.3s\tremaining: 17.2s\n",
      "271:\tlearn: 0.0025132\ttotal: 20.4s\tremaining: 17.1s\n",
      "272:\tlearn: 0.0025132\ttotal: 20.4s\tremaining: 17s\n",
      "273:\tlearn: 0.0025132\ttotal: 20.5s\tremaining: 16.9s\n",
      "274:\tlearn: 0.0025132\ttotal: 20.6s\tremaining: 16.8s\n",
      "275:\tlearn: 0.0025132\ttotal: 20.7s\tremaining: 16.8s\n",
      "276:\tlearn: 0.0024934\ttotal: 20.7s\tremaining: 16.7s\n",
      "277:\tlearn: 0.0024933\ttotal: 20.8s\tremaining: 16.6s\n",
      "278:\tlearn: 0.0024933\ttotal: 20.9s\tremaining: 16.5s\n",
      "279:\tlearn: 0.0024846\ttotal: 21s\tremaining: 16.5s\n",
      "280:\tlearn: 0.0024575\ttotal: 21s\tremaining: 16.4s\n",
      "281:\tlearn: 0.0024381\ttotal: 21.1s\tremaining: 16.3s\n",
      "282:\tlearn: 0.0024187\ttotal: 21.2s\tremaining: 16.3s\n",
      "283:\tlearn: 0.0024000\ttotal: 21.2s\tremaining: 16.2s\n",
      "284:\tlearn: 0.0024000\ttotal: 21.4s\tremaining: 16.1s\n",
      "285:\tlearn: 0.0023752\ttotal: 21.4s\tremaining: 16s\n",
      "286:\tlearn: 0.0023514\ttotal: 21.5s\tremaining: 15.9s\n",
      "287:\tlearn: 0.0023332\ttotal: 21.6s\tremaining: 15.9s\n",
      "288:\tlearn: 0.0023144\ttotal: 21.6s\tremaining: 15.8s\n",
      "289:\tlearn: 0.0022965\ttotal: 21.7s\tremaining: 15.7s\n",
      "290:\tlearn: 0.0022834\ttotal: 21.8s\tremaining: 15.6s\n",
      "291:\tlearn: 0.0022834\ttotal: 21.9s\tremaining: 15.6s\n",
      "292:\tlearn: 0.0022632\ttotal: 21.9s\tremaining: 15.5s\n",
      "293:\tlearn: 0.0022434\ttotal: 22s\tremaining: 15.4s\n",
      "294:\tlearn: 0.0022104\ttotal: 22.1s\tremaining: 15.3s\n",
      "295:\tlearn: 0.0021921\ttotal: 22.1s\tremaining: 15.2s\n",
      "296:\tlearn: 0.0021921\ttotal: 22.2s\tremaining: 15.2s\n",
      "297:\tlearn: 0.0021769\ttotal: 22.3s\tremaining: 15.1s\n",
      "298:\tlearn: 0.0021620\ttotal: 22.4s\tremaining: 15.1s\n",
      "299:\tlearn: 0.0021476\ttotal: 22.5s\tremaining: 15s\n",
      "300:\tlearn: 0.0021476\ttotal: 22.5s\tremaining: 14.9s\n",
      "301:\tlearn: 0.0021342\ttotal: 22.6s\tremaining: 14.8s\n",
      "302:\tlearn: 0.0021341\ttotal: 22.6s\tremaining: 14.7s\n",
      "303:\tlearn: 0.0021247\ttotal: 22.8s\tremaining: 14.7s\n",
      "304:\tlearn: 0.0021053\ttotal: 22.8s\tremaining: 14.6s\n",
      "305:\tlearn: 0.0021053\ttotal: 23s\tremaining: 14.6s\n",
      "306:\tlearn: 0.0020895\ttotal: 23s\tremaining: 14.5s\n",
      "307:\tlearn: 0.0020729\ttotal: 23.1s\tremaining: 14.4s\n",
      "308:\tlearn: 0.0020728\ttotal: 23.2s\tremaining: 14.3s\n",
      "309:\tlearn: 0.0020728\ttotal: 23.3s\tremaining: 14.3s\n",
      "310:\tlearn: 0.0020575\ttotal: 23.4s\tremaining: 14.2s\n",
      "311:\tlearn: 0.0020576\ttotal: 23.5s\tremaining: 14.1s\n",
      "312:\tlearn: 0.0020574\ttotal: 23.5s\tremaining: 14.1s\n",
      "313:\tlearn: 0.0020575\ttotal: 23.6s\tremaining: 14s\n",
      "314:\tlearn: 0.0020575\ttotal: 23.7s\tremaining: 13.9s\n",
      "315:\tlearn: 0.0020575\ttotal: 23.7s\tremaining: 13.8s\n",
      "316:\tlearn: 0.0020575\ttotal: 23.9s\tremaining: 13.8s\n",
      "317:\tlearn: 0.0020574\ttotal: 23.9s\tremaining: 13.7s\n",
      "318:\tlearn: 0.0020435\ttotal: 24s\tremaining: 13.6s\n",
      "319:\tlearn: 0.0020435\ttotal: 24.1s\tremaining: 13.5s\n",
      "320:\tlearn: 0.0020435\ttotal: 24.2s\tremaining: 13.5s\n",
      "321:\tlearn: 0.0020435\ttotal: 24.2s\tremaining: 13.4s\n",
      "322:\tlearn: 0.0020435\ttotal: 24.3s\tremaining: 13.3s\n",
      "323:\tlearn: 0.0020435\ttotal: 24.4s\tremaining: 13.3s\n",
      "324:\tlearn: 0.0020203\ttotal: 24.4s\tremaining: 13.2s\n",
      "325:\tlearn: 0.0020203\ttotal: 24.6s\tremaining: 13.1s\n",
      "326:\tlearn: 0.0020202\ttotal: 24.6s\tremaining: 13s\n",
      "327:\tlearn: 0.0020202\ttotal: 24.7s\tremaining: 12.9s\n",
      "328:\tlearn: 0.0020202\ttotal: 24.8s\tremaining: 12.9s\n",
      "329:\tlearn: 0.0020202\ttotal: 24.8s\tremaining: 12.8s\n",
      "330:\tlearn: 0.0020036\ttotal: 24.9s\tremaining: 12.7s\n",
      "331:\tlearn: 0.0020036\ttotal: 25s\tremaining: 12.6s\n",
      "332:\tlearn: 0.0020036\ttotal: 25s\tremaining: 12.6s\n",
      "333:\tlearn: 0.0020036\ttotal: 25.1s\tremaining: 12.5s\n",
      "334:\tlearn: 0.0020035\ttotal: 25.2s\tremaining: 12.4s\n",
      "335:\tlearn: 0.0020035\ttotal: 25.3s\tremaining: 12.3s\n",
      "336:\tlearn: 0.0020036\ttotal: 25.3s\tremaining: 12.3s\n",
      "337:\tlearn: 0.0020035\ttotal: 25.4s\tremaining: 12.2s\n",
      "338:\tlearn: 0.0020035\ttotal: 25.5s\tremaining: 12.1s\n",
      "339:\tlearn: 0.0020035\ttotal: 25.6s\tremaining: 12s\n",
      "340:\tlearn: 0.0020035\ttotal: 25.7s\tremaining: 12s\n",
      "341:\tlearn: 0.0020035\ttotal: 25.8s\tremaining: 11.9s\n",
      "342:\tlearn: 0.0020035\ttotal: 25.8s\tremaining: 11.8s\n",
      "343:\tlearn: 0.0020034\ttotal: 25.9s\tremaining: 11.7s\n",
      "344:\tlearn: 0.0020034\ttotal: 26s\tremaining: 11.7s\n",
      "345:\tlearn: 0.0019896\ttotal: 26s\tremaining: 11.6s\n",
      "346:\tlearn: 0.0019895\ttotal: 26.1s\tremaining: 11.5s\n",
      "347:\tlearn: 0.0019895\ttotal: 26.2s\tremaining: 11.4s\n",
      "348:\tlearn: 0.0019761\ttotal: 26.3s\tremaining: 11.4s\n",
      "349:\tlearn: 0.0019761\ttotal: 26.4s\tremaining: 11.3s\n",
      "350:\tlearn: 0.0019761\ttotal: 26.4s\tremaining: 11.2s\n",
      "351:\tlearn: 0.0019761\ttotal: 26.5s\tremaining: 11.1s\n",
      "352:\tlearn: 0.0019607\ttotal: 26.5s\tremaining: 11s\n",
      "353:\tlearn: 0.0019607\ttotal: 26.6s\tremaining: 11s\n",
      "354:\tlearn: 0.0019607\ttotal: 26.7s\tremaining: 10.9s\n",
      "355:\tlearn: 0.0019607\ttotal: 26.8s\tremaining: 10.8s\n",
      "356:\tlearn: 0.0019567\ttotal: 26.8s\tremaining: 10.7s\n",
      "357:\tlearn: 0.0019567\ttotal: 26.9s\tremaining: 10.7s\n",
      "358:\tlearn: 0.0019567\ttotal: 27s\tremaining: 10.6s\n",
      "359:\tlearn: 0.0019356\ttotal: 27s\tremaining: 10.5s\n",
      "360:\tlearn: 0.0019356\ttotal: 27.2s\tremaining: 10.5s\n",
      "361:\tlearn: 0.0019356\ttotal: 27.2s\tremaining: 10.4s\n",
      "362:\tlearn: 0.0019356\ttotal: 27.3s\tremaining: 10.3s\n",
      "363:\tlearn: 0.0019356\ttotal: 27.4s\tremaining: 10.2s\n",
      "364:\tlearn: 0.0019356\ttotal: 27.5s\tremaining: 10.2s\n",
      "365:\tlearn: 0.0019356\ttotal: 27.5s\tremaining: 10.1s\n",
      "366:\tlearn: 0.0019355\ttotal: 27.6s\tremaining: 9.99s\n",
      "367:\tlearn: 0.0019356\ttotal: 27.7s\tremaining: 9.93s\n",
      "368:\tlearn: 0.0019356\ttotal: 27.7s\tremaining: 9.85s\n",
      "369:\tlearn: 0.0019356\ttotal: 27.9s\tremaining: 9.79s\n",
      "370:\tlearn: 0.0019356\ttotal: 27.9s\tremaining: 9.7s\n",
      "371:\tlearn: 0.0019355\ttotal: 27.9s\tremaining: 9.62s\n",
      "372:\tlearn: 0.0019355\ttotal: 28s\tremaining: 9.55s\n",
      "373:\tlearn: 0.0019355\ttotal: 28.1s\tremaining: 9.46s\n",
      "374:\tlearn: 0.0019355\ttotal: 28.2s\tremaining: 9.4s\n",
      "375:\tlearn: 0.0019355\ttotal: 28.3s\tremaining: 9.32s\n",
      "376:\tlearn: 0.0019355\ttotal: 28.3s\tremaining: 9.23s\n",
      "377:\tlearn: 0.0019355\ttotal: 28.4s\tremaining: 9.17s\n",
      "378:\tlearn: 0.0019355\ttotal: 28.4s\tremaining: 9.08s\n",
      "379:\tlearn: 0.0019354\ttotal: 28.5s\tremaining: 9.01s\n",
      "380:\tlearn: 0.0019354\ttotal: 28.6s\tremaining: 8.93s\n",
      "381:\tlearn: 0.0019354\ttotal: 28.6s\tremaining: 8.85s\n",
      "382:\tlearn: 0.0019353\ttotal: 28.8s\tremaining: 8.79s\n",
      "383:\tlearn: 0.0019353\ttotal: 28.8s\tremaining: 8.7s\n",
      "384:\tlearn: 0.0019352\ttotal: 28.9s\tremaining: 8.63s\n",
      "385:\tlearn: 0.0019353\ttotal: 28.9s\tremaining: 8.55s\n",
      "386:\tlearn: 0.0019352\ttotal: 29.1s\tremaining: 8.48s\n",
      "387:\tlearn: 0.0019352\ttotal: 29.1s\tremaining: 8.4s\n",
      "388:\tlearn: 0.0019352\ttotal: 29.2s\tremaining: 8.32s\n",
      "389:\tlearn: 0.0019351\ttotal: 29.3s\tremaining: 8.26s\n",
      "390:\tlearn: 0.0019221\ttotal: 29.3s\tremaining: 8.17s\n",
      "391:\tlearn: 0.0019221\ttotal: 29.4s\tremaining: 8.11s\n",
      "392:\tlearn: 0.0019221\ttotal: 29.5s\tremaining: 8.02s\n",
      "393:\tlearn: 0.0019221\ttotal: 29.6s\tremaining: 7.96s\n",
      "394:\tlearn: 0.0019221\ttotal: 29.6s\tremaining: 7.87s\n",
      "395:\tlearn: 0.0019221\ttotal: 29.7s\tremaining: 7.81s\n",
      "396:\tlearn: 0.0019220\ttotal: 29.8s\tremaining: 7.73s\n",
      "397:\tlearn: 0.0019220\ttotal: 29.9s\tremaining: 7.66s\n",
      "398:\tlearn: 0.0019221\ttotal: 30s\tremaining: 7.58s\n",
      "399:\tlearn: 0.0019220\ttotal: 30s\tremaining: 7.5s\n",
      "400:\tlearn: 0.0019220\ttotal: 30.1s\tremaining: 7.44s\n",
      "401:\tlearn: 0.0019220\ttotal: 30.2s\tremaining: 7.35s\n",
      "402:\tlearn: 0.0019219\ttotal: 30.3s\tremaining: 7.28s\n",
      "403:\tlearn: 0.0019100\ttotal: 30.3s\tremaining: 7.21s\n",
      "404:\tlearn: 0.0019101\ttotal: 30.4s\tremaining: 7.13s\n",
      "405:\tlearn: 0.0019100\ttotal: 30.5s\tremaining: 7.06s\n",
      "406:\tlearn: 0.0019100\ttotal: 30.5s\tremaining: 6.98s\n",
      "407:\tlearn: 0.0019100\ttotal: 30.6s\tremaining: 6.91s\n",
      "408:\tlearn: 0.0019099\ttotal: 30.7s\tremaining: 6.83s\n",
      "409:\tlearn: 0.0019100\ttotal: 30.8s\tremaining: 6.76s\n",
      "410:\tlearn: 0.0019099\ttotal: 30.9s\tremaining: 6.68s\n",
      "411:\tlearn: 0.0019099\ttotal: 30.9s\tremaining: 6.61s\n",
      "412:\tlearn: 0.0019100\ttotal: 31s\tremaining: 6.54s\n",
      "413:\tlearn: 0.0019099\ttotal: 31.1s\tremaining: 6.46s\n",
      "414:\tlearn: 0.0019099\ttotal: 31.2s\tremaining: 6.39s\n",
      "415:\tlearn: 0.0019098\ttotal: 31.2s\tremaining: 6.31s\n",
      "416:\tlearn: 0.0019098\ttotal: 31.3s\tremaining: 6.24s\n",
      "417:\tlearn: 0.0019098\ttotal: 31.4s\tremaining: 6.16s\n",
      "418:\tlearn: 0.0019098\ttotal: 31.4s\tremaining: 6.08s\n",
      "419:\tlearn: 0.0019098\ttotal: 31.5s\tremaining: 6.01s\n",
      "420:\tlearn: 0.0019097\ttotal: 31.6s\tremaining: 5.92s\n",
      "421:\tlearn: 0.0019098\ttotal: 31.7s\tremaining: 5.86s\n",
      "422:\tlearn: 0.0019097\ttotal: 31.7s\tremaining: 5.78s\n",
      "423:\tlearn: 0.0019097\ttotal: 31.8s\tremaining: 5.7s\n",
      "424:\tlearn: 0.0018959\ttotal: 31.9s\tremaining: 5.63s\n",
      "425:\tlearn: 0.0018959\ttotal: 31.9s\tremaining: 5.55s\n",
      "426:\tlearn: 0.0018959\ttotal: 32.1s\tremaining: 5.48s\n",
      "427:\tlearn: 0.0018958\ttotal: 32.1s\tremaining: 5.4s\n",
      "428:\tlearn: 0.0018957\ttotal: 32.2s\tremaining: 5.33s\n",
      "429:\tlearn: 0.0018858\ttotal: 32.3s\tremaining: 5.25s\n",
      "430:\tlearn: 0.0018744\ttotal: 32.3s\tremaining: 5.18s\n",
      "431:\tlearn: 0.0018745\ttotal: 32.4s\tremaining: 5.1s\n",
      "432:\tlearn: 0.0018745\ttotal: 32.5s\tremaining: 5.02s\n",
      "433:\tlearn: 0.0018744\ttotal: 32.6s\tremaining: 4.96s\n",
      "434:\tlearn: 0.0018744\ttotal: 32.6s\tremaining: 4.88s\n",
      "435:\tlearn: 0.0018744\ttotal: 32.8s\tremaining: 4.81s\n",
      "436:\tlearn: 0.0018744\ttotal: 32.8s\tremaining: 4.73s\n",
      "437:\tlearn: 0.0018742\ttotal: 32.9s\tremaining: 4.65s\n",
      "438:\tlearn: 0.0018741\ttotal: 33s\tremaining: 4.58s\n",
      "439:\tlearn: 0.0018741\ttotal: 33s\tremaining: 4.5s\n",
      "440:\tlearn: 0.0018741\ttotal: 33.2s\tremaining: 4.44s\n",
      "441:\tlearn: 0.0018741\ttotal: 33.2s\tremaining: 4.36s\n",
      "442:\tlearn: 0.0018741\ttotal: 33.3s\tremaining: 4.29s\n",
      "443:\tlearn: 0.0018741\ttotal: 33.4s\tremaining: 4.21s\n",
      "444:\tlearn: 0.0018741\ttotal: 33.4s\tremaining: 4.13s\n",
      "445:\tlearn: 0.0018740\ttotal: 33.5s\tremaining: 4.05s\n",
      "446:\tlearn: 0.0018740\ttotal: 33.5s\tremaining: 3.98s\n",
      "447:\tlearn: 0.0018740\ttotal: 33.6s\tremaining: 3.9s\n",
      "448:\tlearn: 0.0018741\ttotal: 33.6s\tremaining: 3.82s\n",
      "449:\tlearn: 0.0018654\ttotal: 33.7s\tremaining: 3.74s\n",
      "450:\tlearn: 0.0018654\ttotal: 33.8s\tremaining: 3.67s\n",
      "451:\tlearn: 0.0018654\ttotal: 33.8s\tremaining: 3.59s\n",
      "452:\tlearn: 0.0018652\ttotal: 33.9s\tremaining: 3.52s\n",
      "453:\tlearn: 0.0018652\ttotal: 34s\tremaining: 3.44s\n",
      "454:\tlearn: 0.0018651\ttotal: 34.1s\tremaining: 3.37s\n",
      "455:\tlearn: 0.0018652\ttotal: 34.1s\tremaining: 3.29s\n",
      "456:\tlearn: 0.0018651\ttotal: 34.2s\tremaining: 3.22s\n",
      "457:\tlearn: 0.0018651\ttotal: 34.3s\tremaining: 3.15s\n",
      "458:\tlearn: 0.0018651\ttotal: 34.3s\tremaining: 3.07s\n",
      "459:\tlearn: 0.0018651\ttotal: 34.5s\tremaining: 3s\n",
      "460:\tlearn: 0.0018651\ttotal: 34.5s\tremaining: 2.92s\n",
      "461:\tlearn: 0.0018651\ttotal: 34.6s\tremaining: 2.85s\n",
      "462:\tlearn: 0.0018650\ttotal: 34.7s\tremaining: 2.77s\n",
      "463:\tlearn: 0.0018650\ttotal: 34.8s\tremaining: 2.7s\n",
      "464:\tlearn: 0.0018650\ttotal: 34.8s\tremaining: 2.62s\n",
      "465:\tlearn: 0.0018650\ttotal: 34.9s\tremaining: 2.54s\n",
      "466:\tlearn: 0.0018649\ttotal: 35s\tremaining: 2.47s\n",
      "467:\tlearn: 0.0018649\ttotal: 35s\tremaining: 2.4s\n",
      "468:\tlearn: 0.0018648\ttotal: 35.1s\tremaining: 2.32s\n",
      "469:\tlearn: 0.0018649\ttotal: 35.2s\tremaining: 2.25s\n",
      "470:\tlearn: 0.0018649\ttotal: 35.3s\tremaining: 2.17s\n",
      "471:\tlearn: 0.0018649\ttotal: 35.4s\tremaining: 2.1s\n",
      "472:\tlearn: 0.0018649\ttotal: 35.5s\tremaining: 2.02s\n",
      "473:\tlearn: 0.0018648\ttotal: 35.5s\tremaining: 1.95s\n",
      "474:\tlearn: 0.0018648\ttotal: 35.6s\tremaining: 1.87s\n",
      "475:\tlearn: 0.0018648\ttotal: 35.7s\tremaining: 1.8s\n",
      "476:\tlearn: 0.0018648\ttotal: 35.7s\tremaining: 1.72s\n",
      "477:\tlearn: 0.0018648\ttotal: 35.8s\tremaining: 1.65s\n",
      "478:\tlearn: 0.0018648\ttotal: 35.9s\tremaining: 1.57s\n",
      "479:\tlearn: 0.0018648\ttotal: 35.9s\tremaining: 1.5s\n",
      "480:\tlearn: 0.0018648\ttotal: 36s\tremaining: 1.42s\n",
      "481:\tlearn: 0.0018647\ttotal: 36.1s\tremaining: 1.35s\n",
      "482:\tlearn: 0.0018647\ttotal: 36.2s\tremaining: 1.27s\n",
      "483:\tlearn: 0.0018645\ttotal: 36.2s\tremaining: 1.2s\n",
      "484:\tlearn: 0.0018645\ttotal: 36.3s\tremaining: 1.12s\n",
      "485:\tlearn: 0.0018645\ttotal: 36.4s\tremaining: 1.05s\n",
      "486:\tlearn: 0.0018645\ttotal: 36.5s\tremaining: 976ms\n",
      "487:\tlearn: 0.0018505\ttotal: 36.7s\tremaining: 902ms\n",
      "488:\tlearn: 0.0018505\ttotal: 36.8s\tremaining: 827ms\n",
      "489:\tlearn: 0.0018504\ttotal: 36.8s\tremaining: 752ms\n",
      "490:\tlearn: 0.0018504\ttotal: 36.9s\tremaining: 677ms\n",
      "491:\tlearn: 0.0018504\ttotal: 37.1s\tremaining: 603ms\n",
      "492:\tlearn: 0.0018504\ttotal: 37.1s\tremaining: 527ms\n",
      "493:\tlearn: 0.0018504\ttotal: 37.2s\tremaining: 452ms\n",
      "494:\tlearn: 0.0018504\ttotal: 37.3s\tremaining: 376ms\n",
      "495:\tlearn: 0.0018504\ttotal: 37.4s\tremaining: 301ms\n",
      "496:\tlearn: 0.0018504\ttotal: 37.4s\tremaining: 226ms\n",
      "497:\tlearn: 0.0018503\ttotal: 37.5s\tremaining: 151ms\n",
      "498:\tlearn: 0.0018503\ttotal: 37.6s\tremaining: 75.4ms\n",
      "499:\tlearn: 0.0018503\ttotal: 37.7s\tremaining: 0us\n",
      "0:\tlearn: 0.6402265\ttotal: 89.9ms\tremaining: 44.9s\n",
      "1:\tlearn: 0.5968111\ttotal: 204ms\tremaining: 50.7s\n",
      "2:\tlearn: 0.5596229\ttotal: 281ms\tremaining: 46.6s\n",
      "3:\tlearn: 0.5286438\ttotal: 382ms\tremaining: 47.3s\n",
      "4:\tlearn: 0.5089595\ttotal: 425ms\tremaining: 42.1s\n",
      "5:\tlearn: 0.4880598\ttotal: 529ms\tremaining: 43.5s\n",
      "6:\tlearn: 0.4631076\ttotal: 573ms\tremaining: 40.3s\n",
      "7:\tlearn: 0.4422788\ttotal: 662ms\tremaining: 40.7s\n",
      "8:\tlearn: 0.4273722\ttotal: 727ms\tremaining: 39.6s\n",
      "9:\tlearn: 0.4066470\ttotal: 766ms\tremaining: 37.5s\n",
      "10:\tlearn: 0.3890987\ttotal: 889ms\tremaining: 39.5s\n",
      "11:\tlearn: 0.3647683\ttotal: 931ms\tremaining: 37.9s\n",
      "12:\tlearn: 0.3514358\ttotal: 1.04s\tremaining: 39.1s\n",
      "13:\tlearn: 0.3373638\ttotal: 1.1s\tremaining: 38.1s\n",
      "14:\tlearn: 0.3180365\ttotal: 1.16s\tremaining: 37.6s\n",
      "15:\tlearn: 0.3034393\ttotal: 1.25s\tremaining: 37.9s\n",
      "16:\tlearn: 0.2897328\ttotal: 1.3s\tremaining: 36.9s\n",
      "17:\tlearn: 0.2784389\ttotal: 1.4s\tremaining: 37.4s\n",
      "18:\tlearn: 0.2623931\ttotal: 1.44s\tremaining: 36.5s\n",
      "19:\tlearn: 0.2504476\ttotal: 1.55s\tremaining: 37.3s\n",
      "20:\tlearn: 0.2405068\ttotal: 1.61s\tremaining: 36.7s\n",
      "21:\tlearn: 0.2307187\ttotal: 1.65s\tremaining: 35.9s\n",
      "22:\tlearn: 0.2211692\ttotal: 1.75s\tremaining: 36.3s\n",
      "23:\tlearn: 0.2146954\ttotal: 1.8s\tremaining: 35.7s\n",
      "24:\tlearn: 0.2058298\ttotal: 1.84s\tremaining: 34.9s\n",
      "25:\tlearn: 0.1983971\ttotal: 1.95s\tremaining: 35.5s\n",
      "26:\tlearn: 0.1932071\ttotal: 1.99s\tremaining: 34.9s\n",
      "27:\tlearn: 0.1857073\ttotal: 2.1s\tremaining: 35.4s\n",
      "28:\tlearn: 0.1798059\ttotal: 2.16s\tremaining: 35.1s\n",
      "29:\tlearn: 0.1740107\ttotal: 2.2s\tremaining: 34.4s\n",
      "30:\tlearn: 0.1686394\ttotal: 2.31s\tremaining: 35s\n",
      "31:\tlearn: 0.1617384\ttotal: 2.36s\tremaining: 34.5s\n",
      "32:\tlearn: 0.1556470\ttotal: 2.48s\tremaining: 35.1s\n",
      "33:\tlearn: 0.1493447\ttotal: 2.52s\tremaining: 34.6s\n",
      "34:\tlearn: 0.1446144\ttotal: 2.61s\tremaining: 34.7s\n",
      "35:\tlearn: 0.1398763\ttotal: 2.69s\tremaining: 34.6s\n",
      "36:\tlearn: 0.1324036\ttotal: 2.73s\tremaining: 34.2s\n",
      "37:\tlearn: 0.1274125\ttotal: 2.85s\tremaining: 34.6s\n",
      "38:\tlearn: 0.1240835\ttotal: 2.89s\tremaining: 34.2s\n",
      "39:\tlearn: 0.1188910\ttotal: 2.98s\tremaining: 34.3s\n",
      "40:\tlearn: 0.1151119\ttotal: 3.04s\tremaining: 34.1s\n",
      "41:\tlearn: 0.1108463\ttotal: 3.09s\tremaining: 33.7s\n",
      "42:\tlearn: 0.1084328\ttotal: 3.21s\tremaining: 34.1s\n",
      "43:\tlearn: 0.1061756\ttotal: 3.25s\tremaining: 33.7s\n",
      "44:\tlearn: 0.1016476\ttotal: 3.37s\tremaining: 34.1s\n",
      "45:\tlearn: 0.0982683\ttotal: 3.42s\tremaining: 33.7s\n",
      "46:\tlearn: 0.0949131\ttotal: 3.5s\tremaining: 33.8s\n",
      "47:\tlearn: 0.0906955\ttotal: 3.58s\tremaining: 33.7s\n",
      "48:\tlearn: 0.0876512\ttotal: 3.62s\tremaining: 33.3s\n",
      "49:\tlearn: 0.0851369\ttotal: 3.73s\tremaining: 33.6s\n",
      "50:\tlearn: 0.0818888\ttotal: 3.78s\tremaining: 33.3s\n",
      "51:\tlearn: 0.0795896\ttotal: 3.87s\tremaining: 33.3s\n",
      "52:\tlearn: 0.0777703\ttotal: 3.94s\tremaining: 33.2s\n",
      "53:\tlearn: 0.0739004\ttotal: 3.98s\tremaining: 32.8s\n",
      "54:\tlearn: 0.0708586\ttotal: 4.1s\tremaining: 33.1s\n",
      "55:\tlearn: 0.0678025\ttotal: 4.14s\tremaining: 32.8s\n",
      "56:\tlearn: 0.0661222\ttotal: 4.23s\tremaining: 32.9s\n",
      "57:\tlearn: 0.0633765\ttotal: 4.3s\tremaining: 32.8s\n",
      "58:\tlearn: 0.0607016\ttotal: 4.34s\tremaining: 32.5s\n",
      "59:\tlearn: 0.0587597\ttotal: 4.43s\tremaining: 32.5s\n",
      "60:\tlearn: 0.0570558\ttotal: 4.5s\tremaining: 32.4s\n",
      "61:\tlearn: 0.0556371\ttotal: 4.57s\tremaining: 32.3s\n",
      "62:\tlearn: 0.0540049\ttotal: 4.66s\tremaining: 32.4s\n",
      "63:\tlearn: 0.0515590\ttotal: 4.71s\tremaining: 32.1s\n",
      "64:\tlearn: 0.0498853\ttotal: 4.82s\tremaining: 32.3s\n",
      "65:\tlearn: 0.0483588\ttotal: 4.87s\tremaining: 32s\n",
      "66:\tlearn: 0.0473770\ttotal: 4.96s\tremaining: 32.1s\n",
      "67:\tlearn: 0.0455430\ttotal: 5.04s\tremaining: 32s\n",
      "68:\tlearn: 0.0442135\ttotal: 5.08s\tremaining: 31.7s\n",
      "69:\tlearn: 0.0434264\ttotal: 5.2s\tremaining: 31.9s\n",
      "70:\tlearn: 0.0422488\ttotal: 5.24s\tremaining: 31.6s\n",
      "71:\tlearn: 0.0406189\ttotal: 5.35s\tremaining: 31.8s\n",
      "72:\tlearn: 0.0393165\ttotal: 5.39s\tremaining: 31.6s\n",
      "73:\tlearn: 0.0385946\ttotal: 5.44s\tremaining: 31.3s\n",
      "74:\tlearn: 0.0377048\ttotal: 5.58s\tremaining: 31.6s\n",
      "75:\tlearn: 0.0370527\ttotal: 5.67s\tremaining: 31.7s\n",
      "76:\tlearn: 0.0360370\ttotal: 5.73s\tremaining: 31.5s\n",
      "77:\tlearn: 0.0347641\ttotal: 5.82s\tremaining: 31.5s\n",
      "78:\tlearn: 0.0337282\ttotal: 5.88s\tremaining: 31.4s\n",
      "79:\tlearn: 0.0327867\ttotal: 5.92s\tremaining: 31.1s\n",
      "80:\tlearn: 0.0319140\ttotal: 6.05s\tremaining: 31.3s\n",
      "81:\tlearn: 0.0313223\ttotal: 6.1s\tremaining: 31.1s\n",
      "82:\tlearn: 0.0306420\ttotal: 6.21s\tremaining: 31.2s\n",
      "83:\tlearn: 0.0301830\ttotal: 6.26s\tremaining: 31s\n",
      "84:\tlearn: 0.0295499\ttotal: 6.3s\tremaining: 30.8s\n",
      "85:\tlearn: 0.0288249\ttotal: 6.41s\tremaining: 30.9s\n",
      "86:\tlearn: 0.0276231\ttotal: 6.46s\tremaining: 30.7s\n",
      "87:\tlearn: 0.0268585\ttotal: 6.57s\tremaining: 30.8s\n",
      "88:\tlearn: 0.0259726\ttotal: 6.62s\tremaining: 30.6s\n",
      "89:\tlearn: 0.0249647\ttotal: 6.71s\tremaining: 30.6s\n",
      "90:\tlearn: 0.0239751\ttotal: 6.79s\tremaining: 30.5s\n",
      "91:\tlearn: 0.0232505\ttotal: 6.83s\tremaining: 30.3s\n",
      "92:\tlearn: 0.0226878\ttotal: 6.94s\tremaining: 30.4s\n",
      "93:\tlearn: 0.0221785\ttotal: 6.99s\tremaining: 30.2s\n",
      "94:\tlearn: 0.0217000\ttotal: 7.1s\tremaining: 30.3s\n",
      "95:\tlearn: 0.0210962\ttotal: 7.16s\tremaining: 30.1s\n",
      "96:\tlearn: 0.0206548\ttotal: 7.26s\tremaining: 30.2s\n",
      "97:\tlearn: 0.0201296\ttotal: 7.33s\tremaining: 30.1s\n",
      "98:\tlearn: 0.0196916\ttotal: 7.37s\tremaining: 29.9s\n",
      "99:\tlearn: 0.0190568\ttotal: 7.48s\tremaining: 29.9s\n",
      "100:\tlearn: 0.0186547\ttotal: 7.53s\tremaining: 29.7s\n",
      "101:\tlearn: 0.0181941\ttotal: 7.64s\tremaining: 29.8s\n",
      "102:\tlearn: 0.0177355\ttotal: 7.7s\tremaining: 29.7s\n",
      "103:\tlearn: 0.0172901\ttotal: 7.79s\tremaining: 29.7s\n",
      "104:\tlearn: 0.0167988\ttotal: 7.86s\tremaining: 29.6s\n",
      "105:\tlearn: 0.0164453\ttotal: 7.9s\tremaining: 29.4s\n",
      "106:\tlearn: 0.0161049\ttotal: 8.02s\tremaining: 29.4s\n",
      "107:\tlearn: 0.0156382\ttotal: 8.06s\tremaining: 29.3s\n",
      "108:\tlearn: 0.0152334\ttotal: 8.16s\tremaining: 29.3s\n",
      "109:\tlearn: 0.0148455\ttotal: 8.22s\tremaining: 29.1s\n",
      "110:\tlearn: 0.0144747\ttotal: 8.27s\tremaining: 29s\n",
      "111:\tlearn: 0.0141159\ttotal: 8.38s\tremaining: 29s\n",
      "112:\tlearn: 0.0137960\ttotal: 8.42s\tremaining: 28.8s\n",
      "113:\tlearn: 0.0135080\ttotal: 8.53s\tremaining: 28.9s\n",
      "114:\tlearn: 0.0131900\ttotal: 8.6s\tremaining: 28.8s\n",
      "115:\tlearn: 0.0128799\ttotal: 8.71s\tremaining: 28.8s\n",
      "116:\tlearn: 0.0126228\ttotal: 8.76s\tremaining: 28.7s\n",
      "117:\tlearn: 0.0123999\ttotal: 8.86s\tremaining: 28.7s\n",
      "118:\tlearn: 0.0120629\ttotal: 8.94s\tremaining: 28.6s\n",
      "119:\tlearn: 0.0118154\ttotal: 8.98s\tremaining: 28.4s\n",
      "120:\tlearn: 0.0115731\ttotal: 9.09s\tremaining: 28.5s\n",
      "121:\tlearn: 0.0113896\ttotal: 9.14s\tremaining: 28.3s\n",
      "122:\tlearn: 0.0111327\ttotal: 9.2s\tremaining: 28.2s\n",
      "123:\tlearn: 0.0108520\ttotal: 9.26s\tremaining: 28.1s\n",
      "124:\tlearn: 0.0106466\ttotal: 9.35s\tremaining: 28.1s\n",
      "125:\tlearn: 0.0105128\ttotal: 9.43s\tremaining: 28s\n",
      "126:\tlearn: 0.0103020\ttotal: 9.48s\tremaining: 27.8s\n",
      "127:\tlearn: 0.0100920\ttotal: 9.59s\tremaining: 27.9s\n",
      "128:\tlearn: 0.0098973\ttotal: 9.63s\tremaining: 27.7s\n",
      "129:\tlearn: 0.0097491\ttotal: 9.75s\tremaining: 27.8s\n",
      "130:\tlearn: 0.0096115\ttotal: 9.79s\tremaining: 27.6s\n",
      "131:\tlearn: 0.0094464\ttotal: 9.91s\tremaining: 27.6s\n",
      "132:\tlearn: 0.0092988\ttotal: 9.96s\tremaining: 27.5s\n",
      "133:\tlearn: 0.0091583\ttotal: 10.1s\tremaining: 27.5s\n",
      "134:\tlearn: 0.0089760\ttotal: 10.1s\tremaining: 27.4s\n",
      "135:\tlearn: 0.0088556\ttotal: 10.2s\tremaining: 27.2s\n",
      "136:\tlearn: 0.0086839\ttotal: 10.3s\tremaining: 27.2s\n",
      "137:\tlearn: 0.0085454\ttotal: 10.3s\tremaining: 27.1s\n",
      "138:\tlearn: 0.0084051\ttotal: 10.4s\tremaining: 27.1s\n",
      "139:\tlearn: 0.0082849\ttotal: 10.5s\tremaining: 27s\n",
      "140:\tlearn: 0.0081384\ttotal: 10.6s\tremaining: 26.9s\n",
      "141:\tlearn: 0.0080248\ttotal: 10.7s\tremaining: 26.9s\n",
      "142:\tlearn: 0.0079056\ttotal: 10.7s\tremaining: 26.7s\n",
      "143:\tlearn: 0.0077607\ttotal: 10.8s\tremaining: 26.7s\n",
      "144:\tlearn: 0.0076352\ttotal: 10.9s\tremaining: 26.6s\n",
      "145:\tlearn: 0.0074963\ttotal: 11s\tremaining: 26.6s\n",
      "146:\tlearn: 0.0074160\ttotal: 11s\tremaining: 26.5s\n",
      "147:\tlearn: 0.0072750\ttotal: 11.1s\tremaining: 26.3s\n",
      "148:\tlearn: 0.0071678\ttotal: 11.2s\tremaining: 26.3s\n",
      "149:\tlearn: 0.0070628\ttotal: 11.2s\tremaining: 26.2s\n",
      "150:\tlearn: 0.0069448\ttotal: 11.3s\tremaining: 26.2s\n",
      "151:\tlearn: 0.0068310\ttotal: 11.4s\tremaining: 26.1s\n",
      "152:\tlearn: 0.0067307\ttotal: 11.5s\tremaining: 26.1s\n",
      "153:\tlearn: 0.0066538\ttotal: 11.6s\tremaining: 26s\n",
      "154:\tlearn: 0.0065791\ttotal: 11.6s\tremaining: 25.8s\n",
      "155:\tlearn: 0.0064829\ttotal: 11.7s\tremaining: 25.8s\n",
      "156:\tlearn: 0.0063960\ttotal: 11.8s\tremaining: 25.7s\n",
      "157:\tlearn: 0.0062964\ttotal: 11.9s\tremaining: 25.7s\n",
      "158:\tlearn: 0.0061974\ttotal: 11.9s\tremaining: 25.6s\n",
      "159:\tlearn: 0.0061324\ttotal: 12s\tremaining: 25.5s\n",
      "160:\tlearn: 0.0060748\ttotal: 12.1s\tremaining: 25.4s\n",
      "161:\tlearn: 0.0060195\ttotal: 12.1s\tremaining: 25.3s\n",
      "162:\tlearn: 0.0059363\ttotal: 12.2s\tremaining: 25.3s\n",
      "163:\tlearn: 0.0058423\ttotal: 12.3s\tremaining: 25.2s\n",
      "164:\tlearn: 0.0057604\ttotal: 12.4s\tremaining: 25.2s\n",
      "165:\tlearn: 0.0057027\ttotal: 12.4s\tremaining: 25s\n",
      "166:\tlearn: 0.0056276\ttotal: 12.5s\tremaining: 25s\n",
      "167:\tlearn: 0.0055616\ttotal: 12.6s\tremaining: 24.9s\n",
      "168:\tlearn: 0.0055070\ttotal: 12.6s\tremaining: 24.7s\n",
      "169:\tlearn: 0.0054239\ttotal: 12.7s\tremaining: 24.7s\n",
      "170:\tlearn: 0.0053557\ttotal: 12.8s\tremaining: 24.6s\n",
      "171:\tlearn: 0.0052728\ttotal: 12.9s\tremaining: 24.6s\n",
      "172:\tlearn: 0.0051985\ttotal: 13s\tremaining: 24.5s\n",
      "173:\tlearn: 0.0051418\ttotal: 13s\tremaining: 24.4s\n",
      "174:\tlearn: 0.0050913\ttotal: 13.1s\tremaining: 24.4s\n",
      "175:\tlearn: 0.0050302\ttotal: 13.2s\tremaining: 24.2s\n",
      "176:\tlearn: 0.0049644\ttotal: 13.3s\tremaining: 24.2s\n",
      "177:\tlearn: 0.0049116\ttotal: 13.3s\tremaining: 24.1s\n",
      "178:\tlearn: 0.0048666\ttotal: 13.4s\tremaining: 24s\n",
      "179:\tlearn: 0.0048042\ttotal: 13.5s\tremaining: 23.9s\n",
      "180:\tlearn: 0.0047531\ttotal: 13.5s\tremaining: 23.8s\n",
      "181:\tlearn: 0.0047055\ttotal: 13.6s\tremaining: 23.8s\n",
      "182:\tlearn: 0.0046567\ttotal: 13.7s\tremaining: 23.7s\n",
      "183:\tlearn: 0.0046063\ttotal: 13.8s\tremaining: 23.7s\n",
      "184:\tlearn: 0.0045619\ttotal: 13.8s\tremaining: 23.6s\n",
      "185:\tlearn: 0.0045171\ttotal: 13.9s\tremaining: 23.5s\n",
      "186:\tlearn: 0.0044676\ttotal: 14s\tremaining: 23.4s\n",
      "187:\tlearn: 0.0044060\ttotal: 14.1s\tremaining: 23.4s\n",
      "188:\tlearn: 0.0043330\ttotal: 14.2s\tremaining: 23.3s\n",
      "189:\tlearn: 0.0042968\ttotal: 14.2s\tremaining: 23.2s\n",
      "190:\tlearn: 0.0042561\ttotal: 14.3s\tremaining: 23.2s\n",
      "191:\tlearn: 0.0042131\ttotal: 14.4s\tremaining: 23.1s\n",
      "192:\tlearn: 0.0041765\ttotal: 14.5s\tremaining: 23.1s\n",
      "193:\tlearn: 0.0041276\ttotal: 14.5s\tremaining: 22.9s\n",
      "194:\tlearn: 0.0040979\ttotal: 14.7s\tremaining: 22.9s\n",
      "195:\tlearn: 0.0040599\ttotal: 14.7s\tremaining: 22.8s\n",
      "196:\tlearn: 0.0040194\ttotal: 14.8s\tremaining: 22.7s\n",
      "197:\tlearn: 0.0039715\ttotal: 14.9s\tremaining: 22.7s\n",
      "198:\tlearn: 0.0039430\ttotal: 14.9s\tremaining: 22.6s\n",
      "199:\tlearn: 0.0038895\ttotal: 15s\tremaining: 22.5s\n",
      "200:\tlearn: 0.0038483\ttotal: 15.1s\tremaining: 22.4s\n",
      "201:\tlearn: 0.0038107\ttotal: 15.2s\tremaining: 22.4s\n",
      "202:\tlearn: 0.0037816\ttotal: 15.2s\tremaining: 22.3s\n",
      "203:\tlearn: 0.0037381\ttotal: 15.3s\tremaining: 22.2s\n",
      "204:\tlearn: 0.0037007\ttotal: 15.4s\tremaining: 22.2s\n",
      "205:\tlearn: 0.0036559\ttotal: 15.5s\tremaining: 22.1s\n",
      "206:\tlearn: 0.0036132\ttotal: 15.6s\tremaining: 22s\n",
      "207:\tlearn: 0.0035807\ttotal: 15.6s\tremaining: 21.9s\n",
      "208:\tlearn: 0.0035377\ttotal: 15.7s\tremaining: 21.9s\n",
      "209:\tlearn: 0.0035118\ttotal: 15.8s\tremaining: 21.8s\n",
      "210:\tlearn: 0.0034880\ttotal: 15.8s\tremaining: 21.7s\n",
      "211:\tlearn: 0.0034479\ttotal: 16s\tremaining: 21.7s\n",
      "212:\tlearn: 0.0034220\ttotal: 16.1s\tremaining: 21.6s\n",
      "213:\tlearn: 0.0033830\ttotal: 16.1s\tremaining: 21.5s\n",
      "214:\tlearn: 0.0033564\ttotal: 16.2s\tremaining: 21.4s\n",
      "215:\tlearn: 0.0033131\ttotal: 16.3s\tremaining: 21.4s\n",
      "216:\tlearn: 0.0032838\ttotal: 16.3s\tremaining: 21.3s\n",
      "217:\tlearn: 0.0032501\ttotal: 16.4s\tremaining: 21.2s\n",
      "218:\tlearn: 0.0032116\ttotal: 16.5s\tremaining: 21.1s\n",
      "219:\tlearn: 0.0031803\ttotal: 16.5s\tremaining: 21s\n",
      "220:\tlearn: 0.0031471\ttotal: 16.6s\tremaining: 21s\n",
      "221:\tlearn: 0.0031196\ttotal: 16.7s\tremaining: 20.9s\n",
      "222:\tlearn: 0.0030892\ttotal: 16.8s\tremaining: 20.8s\n",
      "223:\tlearn: 0.0030652\ttotal: 16.8s\tremaining: 20.7s\n",
      "224:\tlearn: 0.0030380\ttotal: 17s\tremaining: 20.7s\n",
      "225:\tlearn: 0.0030019\ttotal: 17s\tremaining: 20.6s\n",
      "226:\tlearn: 0.0029736\ttotal: 17.1s\tremaining: 20.6s\n",
      "227:\tlearn: 0.0029477\ttotal: 17.2s\tremaining: 20.5s\n",
      "228:\tlearn: 0.0029250\ttotal: 17.2s\tremaining: 20.4s\n",
      "229:\tlearn: 0.0029002\ttotal: 17.3s\tremaining: 20.3s\n",
      "230:\tlearn: 0.0028766\ttotal: 17.4s\tremaining: 20.2s\n",
      "231:\tlearn: 0.0028546\ttotal: 17.5s\tremaining: 20.2s\n",
      "232:\tlearn: 0.0028316\ttotal: 17.5s\tremaining: 20.1s\n",
      "233:\tlearn: 0.0028070\ttotal: 17.6s\tremaining: 20s\n",
      "234:\tlearn: 0.0027795\ttotal: 17.7s\tremaining: 20s\n",
      "235:\tlearn: 0.0027795\ttotal: 17.7s\tremaining: 19.9s\n",
      "236:\tlearn: 0.0027583\ttotal: 17.9s\tremaining: 19.8s\n",
      "237:\tlearn: 0.0027402\ttotal: 17.9s\tremaining: 19.7s\n",
      "238:\tlearn: 0.0027252\ttotal: 18s\tremaining: 19.6s\n",
      "239:\tlearn: 0.0027034\ttotal: 18.1s\tremaining: 19.6s\n",
      "240:\tlearn: 0.0026827\ttotal: 18.1s\tremaining: 19.4s\n",
      "241:\tlearn: 0.0026520\ttotal: 18.2s\tremaining: 19.4s\n",
      "242:\tlearn: 0.0026476\ttotal: 18.3s\tremaining: 19.3s\n",
      "243:\tlearn: 0.0026273\ttotal: 18.3s\tremaining: 19.2s\n",
      "244:\tlearn: 0.0026038\ttotal: 18.4s\tremaining: 19.2s\n",
      "245:\tlearn: 0.0025801\ttotal: 18.5s\tremaining: 19.1s\n",
      "246:\tlearn: 0.0025595\ttotal: 18.6s\tremaining: 19s\n",
      "247:\tlearn: 0.0025594\ttotal: 18.6s\tremaining: 18.9s\n",
      "248:\tlearn: 0.0025594\ttotal: 18.7s\tremaining: 18.9s\n",
      "249:\tlearn: 0.0025349\ttotal: 18.8s\tremaining: 18.8s\n",
      "250:\tlearn: 0.0025077\ttotal: 18.9s\tremaining: 18.7s\n",
      "251:\tlearn: 0.0024877\ttotal: 19s\tremaining: 18.7s\n",
      "252:\tlearn: 0.0024877\ttotal: 19s\tremaining: 18.6s\n",
      "253:\tlearn: 0.0024877\ttotal: 19.1s\tremaining: 18.5s\n",
      "254:\tlearn: 0.0024876\ttotal: 19.2s\tremaining: 18.4s\n",
      "255:\tlearn: 0.0024876\ttotal: 19.3s\tremaining: 18.4s\n",
      "256:\tlearn: 0.0024876\ttotal: 19.3s\tremaining: 18.3s\n",
      "257:\tlearn: 0.0024876\ttotal: 19.4s\tremaining: 18.2s\n",
      "258:\tlearn: 0.0024717\ttotal: 19.5s\tremaining: 18.1s\n",
      "259:\tlearn: 0.0024717\ttotal: 19.5s\tremaining: 18s\n",
      "260:\tlearn: 0.0024717\ttotal: 19.6s\tremaining: 18s\n",
      "261:\tlearn: 0.0024540\ttotal: 19.7s\tremaining: 17.9s\n",
      "262:\tlearn: 0.0024540\ttotal: 19.8s\tremaining: 17.8s\n",
      "263:\tlearn: 0.0024540\ttotal: 19.8s\tremaining: 17.7s\n",
      "264:\tlearn: 0.0024297\ttotal: 19.9s\tremaining: 17.7s\n",
      "265:\tlearn: 0.0024168\ttotal: 20s\tremaining: 17.6s\n",
      "266:\tlearn: 0.0023958\ttotal: 20s\tremaining: 17.5s\n",
      "267:\tlearn: 0.0023768\ttotal: 20.2s\tremaining: 17.4s\n",
      "268:\tlearn: 0.0023563\ttotal: 20.2s\tremaining: 17.3s\n",
      "269:\tlearn: 0.0023391\ttotal: 20.3s\tremaining: 17.3s\n",
      "270:\tlearn: 0.0023215\ttotal: 20.4s\tremaining: 17.2s\n",
      "271:\tlearn: 0.0023089\ttotal: 20.5s\tremaining: 17.1s\n",
      "272:\tlearn: 0.0022805\ttotal: 20.5s\tremaining: 17.1s\n",
      "273:\tlearn: 0.0022804\ttotal: 20.6s\tremaining: 17s\n",
      "274:\tlearn: 0.0022803\ttotal: 20.7s\tremaining: 16.9s\n",
      "275:\tlearn: 0.0022803\ttotal: 20.8s\tremaining: 16.8s\n",
      "276:\tlearn: 0.0022803\ttotal: 20.9s\tremaining: 16.8s\n",
      "277:\tlearn: 0.0022596\ttotal: 20.9s\tremaining: 16.7s\n",
      "278:\tlearn: 0.0022596\ttotal: 21s\tremaining: 16.6s\n",
      "279:\tlearn: 0.0022596\ttotal: 21.1s\tremaining: 16.6s\n",
      "280:\tlearn: 0.0022593\ttotal: 21.1s\tremaining: 16.5s\n",
      "281:\tlearn: 0.0022593\ttotal: 21.2s\tremaining: 16.4s\n",
      "282:\tlearn: 0.0022593\ttotal: 21.3s\tremaining: 16.3s\n",
      "283:\tlearn: 0.0022592\ttotal: 21.4s\tremaining: 16.3s\n",
      "284:\tlearn: 0.0022592\ttotal: 21.5s\tremaining: 16.2s\n",
      "285:\tlearn: 0.0022405\ttotal: 21.5s\tremaining: 16.1s\n",
      "286:\tlearn: 0.0022405\ttotal: 21.6s\tremaining: 16s\n",
      "287:\tlearn: 0.0022405\ttotal: 21.7s\tremaining: 15.9s\n",
      "288:\tlearn: 0.0022405\ttotal: 21.8s\tremaining: 15.9s\n",
      "289:\tlearn: 0.0022405\ttotal: 21.8s\tremaining: 15.8s\n",
      "290:\tlearn: 0.0022405\ttotal: 21.8s\tremaining: 15.7s\n",
      "291:\tlearn: 0.0022405\ttotal: 22s\tremaining: 15.6s\n",
      "292:\tlearn: 0.0022404\ttotal: 22s\tremaining: 15.5s\n",
      "293:\tlearn: 0.0022220\ttotal: 22.1s\tremaining: 15.5s\n",
      "294:\tlearn: 0.0022220\ttotal: 22.2s\tremaining: 15.4s\n",
      "295:\tlearn: 0.0022043\ttotal: 22.3s\tremaining: 15.3s\n",
      "296:\tlearn: 0.0022043\ttotal: 22.3s\tremaining: 15.3s\n",
      "297:\tlearn: 0.0022043\ttotal: 22.4s\tremaining: 15.2s\n",
      "298:\tlearn: 0.0022043\ttotal: 22.5s\tremaining: 15.1s\n",
      "299:\tlearn: 0.0022042\ttotal: 22.5s\tremaining: 15s\n",
      "300:\tlearn: 0.0021904\ttotal: 22.6s\tremaining: 15s\n",
      "301:\tlearn: 0.0021759\ttotal: 22.7s\tremaining: 14.9s\n",
      "302:\tlearn: 0.0021758\ttotal: 22.7s\tremaining: 14.8s\n",
      "303:\tlearn: 0.0021758\ttotal: 22.9s\tremaining: 14.7s\n",
      "304:\tlearn: 0.0021758\ttotal: 22.9s\tremaining: 14.6s\n",
      "305:\tlearn: 0.0021659\ttotal: 23s\tremaining: 14.6s\n",
      "306:\tlearn: 0.0021507\ttotal: 23.1s\tremaining: 14.5s\n",
      "307:\tlearn: 0.0021369\ttotal: 23.1s\tremaining: 14.4s\n",
      "308:\tlearn: 0.0021369\ttotal: 23.2s\tremaining: 14.3s\n",
      "309:\tlearn: 0.0021369\ttotal: 23.2s\tremaining: 14.2s\n",
      "310:\tlearn: 0.0021369\ttotal: 23.4s\tremaining: 14.2s\n",
      "311:\tlearn: 0.0021369\ttotal: 23.4s\tremaining: 14.1s\n",
      "312:\tlearn: 0.0021184\ttotal: 23.5s\tremaining: 14s\n",
      "313:\tlearn: 0.0021184\ttotal: 23.6s\tremaining: 14s\n",
      "314:\tlearn: 0.0021183\ttotal: 23.6s\tremaining: 13.9s\n",
      "315:\tlearn: 0.0021019\ttotal: 23.7s\tremaining: 13.8s\n",
      "316:\tlearn: 0.0021019\ttotal: 23.8s\tremaining: 13.7s\n",
      "317:\tlearn: 0.0021019\ttotal: 23.9s\tremaining: 13.7s\n",
      "318:\tlearn: 0.0021019\ttotal: 23.9s\tremaining: 13.6s\n",
      "319:\tlearn: 0.0021018\ttotal: 24s\tremaining: 13.5s\n",
      "320:\tlearn: 0.0021018\ttotal: 24.1s\tremaining: 13.4s\n",
      "321:\tlearn: 0.0021018\ttotal: 24.1s\tremaining: 13.3s\n",
      "322:\tlearn: 0.0021018\ttotal: 24.2s\tremaining: 13.3s\n",
      "323:\tlearn: 0.0020948\ttotal: 24.3s\tremaining: 13.2s\n",
      "324:\tlearn: 0.0020744\ttotal: 24.3s\tremaining: 13.1s\n",
      "325:\tlearn: 0.0020743\ttotal: 24.4s\tremaining: 13s\n",
      "326:\tlearn: 0.0020743\ttotal: 24.5s\tremaining: 13s\n",
      "327:\tlearn: 0.0020743\ttotal: 24.6s\tremaining: 12.9s\n",
      "328:\tlearn: 0.0020743\ttotal: 24.7s\tremaining: 12.8s\n",
      "329:\tlearn: 0.0020743\ttotal: 24.8s\tremaining: 12.8s\n",
      "330:\tlearn: 0.0020743\ttotal: 24.8s\tremaining: 12.7s\n",
      "331:\tlearn: 0.0020743\ttotal: 24.9s\tremaining: 12.6s\n",
      "332:\tlearn: 0.0020743\ttotal: 25s\tremaining: 12.5s\n",
      "333:\tlearn: 0.0020743\ttotal: 25s\tremaining: 12.4s\n",
      "334:\tlearn: 0.0020743\ttotal: 25.1s\tremaining: 12.4s\n",
      "335:\tlearn: 0.0020743\ttotal: 25.2s\tremaining: 12.3s\n",
      "336:\tlearn: 0.0020743\ttotal: 25.2s\tremaining: 12.2s\n",
      "337:\tlearn: 0.0020532\ttotal: 25.3s\tremaining: 12.1s\n",
      "338:\tlearn: 0.0020532\ttotal: 25.4s\tremaining: 12.1s\n",
      "339:\tlearn: 0.0020532\ttotal: 25.5s\tremaining: 12s\n",
      "340:\tlearn: 0.0020530\ttotal: 25.6s\tremaining: 11.9s\n",
      "341:\tlearn: 0.0020336\ttotal: 25.6s\tremaining: 11.8s\n",
      "342:\tlearn: 0.0020336\ttotal: 25.7s\tremaining: 11.8s\n",
      "343:\tlearn: 0.0020336\ttotal: 25.7s\tremaining: 11.7s\n",
      "344:\tlearn: 0.0020336\ttotal: 25.9s\tremaining: 11.6s\n",
      "345:\tlearn: 0.0020336\ttotal: 25.9s\tremaining: 11.5s\n",
      "346:\tlearn: 0.0020336\ttotal: 26s\tremaining: 11.5s\n",
      "347:\tlearn: 0.0020336\ttotal: 26.1s\tremaining: 11.4s\n",
      "348:\tlearn: 0.0020336\ttotal: 26.1s\tremaining: 11.3s\n",
      "349:\tlearn: 0.0020336\ttotal: 26.3s\tremaining: 11.3s\n",
      "350:\tlearn: 0.0020336\ttotal: 26.3s\tremaining: 11.2s\n",
      "351:\tlearn: 0.0020299\ttotal: 26.4s\tremaining: 11.1s\n",
      "352:\tlearn: 0.0020203\ttotal: 26.5s\tremaining: 11s\n",
      "353:\tlearn: 0.0020202\ttotal: 26.5s\tremaining: 10.9s\n",
      "354:\tlearn: 0.0020202\ttotal: 26.6s\tremaining: 10.9s\n",
      "355:\tlearn: 0.0020202\ttotal: 26.7s\tremaining: 10.8s\n",
      "356:\tlearn: 0.0020202\ttotal: 26.8s\tremaining: 10.7s\n",
      "357:\tlearn: 0.0020202\ttotal: 26.8s\tremaining: 10.6s\n",
      "358:\tlearn: 0.0020201\ttotal: 26.9s\tremaining: 10.6s\n",
      "359:\tlearn: 0.0020201\ttotal: 27s\tremaining: 10.5s\n",
      "360:\tlearn: 0.0020201\ttotal: 27s\tremaining: 10.4s\n",
      "361:\tlearn: 0.0020201\ttotal: 27.1s\tremaining: 10.3s\n",
      "362:\tlearn: 0.0020201\ttotal: 27.2s\tremaining: 10.3s\n",
      "363:\tlearn: 0.0020201\ttotal: 27.3s\tremaining: 10.2s\n",
      "364:\tlearn: 0.0020200\ttotal: 27.3s\tremaining: 10.1s\n",
      "365:\tlearn: 0.0020201\ttotal: 27.4s\tremaining: 10s\n",
      "366:\tlearn: 0.0020058\ttotal: 27.5s\tremaining: 9.96s\n",
      "367:\tlearn: 0.0020058\ttotal: 27.5s\tremaining: 9.88s\n",
      "368:\tlearn: 0.0020058\ttotal: 27.6s\tremaining: 9.81s\n",
      "369:\tlearn: 0.0020058\ttotal: 27.7s\tremaining: 9.73s\n",
      "370:\tlearn: 0.0020058\ttotal: 27.7s\tremaining: 9.64s\n",
      "371:\tlearn: 0.0020058\ttotal: 27.8s\tremaining: 9.58s\n",
      "372:\tlearn: 0.0019996\ttotal: 27.9s\tremaining: 9.5s\n",
      "373:\tlearn: 0.0019996\ttotal: 28s\tremaining: 9.43s\n",
      "374:\tlearn: 0.0019995\ttotal: 28.1s\tremaining: 9.35s\n",
      "375:\tlearn: 0.0019995\ttotal: 28.1s\tremaining: 9.27s\n",
      "376:\tlearn: 0.0019995\ttotal: 28.2s\tremaining: 9.2s\n",
      "377:\tlearn: 0.0019994\ttotal: 28.2s\tremaining: 9.12s\n",
      "378:\tlearn: 0.0019994\ttotal: 28.4s\tremaining: 9.06s\n",
      "379:\tlearn: 0.0019994\ttotal: 28.4s\tremaining: 8.97s\n",
      "380:\tlearn: 0.0019995\ttotal: 28.5s\tremaining: 8.91s\n",
      "381:\tlearn: 0.0019994\ttotal: 28.6s\tremaining: 8.83s\n",
      "382:\tlearn: 0.0019994\ttotal: 28.6s\tremaining: 8.75s\n",
      "383:\tlearn: 0.0019994\ttotal: 28.7s\tremaining: 8.68s\n",
      "384:\tlearn: 0.0019994\ttotal: 28.8s\tremaining: 8.6s\n",
      "385:\tlearn: 0.0019993\ttotal: 28.9s\tremaining: 8.53s\n",
      "386:\tlearn: 0.0019993\ttotal: 28.9s\tremaining: 8.45s\n",
      "387:\tlearn: 0.0019993\ttotal: 29s\tremaining: 8.37s\n",
      "388:\tlearn: 0.0019993\ttotal: 29.1s\tremaining: 8.3s\n",
      "389:\tlearn: 0.0019993\ttotal: 29.1s\tremaining: 8.22s\n",
      "390:\tlearn: 0.0019992\ttotal: 29.2s\tremaining: 8.15s\n",
      "391:\tlearn: 0.0019992\ttotal: 29.3s\tremaining: 8.07s\n",
      "392:\tlearn: 0.0019992\ttotal: 29.3s\tremaining: 7.99s\n",
      "393:\tlearn: 0.0019992\ttotal: 29.4s\tremaining: 7.92s\n",
      "394:\tlearn: 0.0019992\ttotal: 29.5s\tremaining: 7.84s\n",
      "395:\tlearn: 0.0019992\ttotal: 29.6s\tremaining: 7.77s\n",
      "396:\tlearn: 0.0019992\ttotal: 29.7s\tremaining: 7.69s\n",
      "397:\tlearn: 0.0019992\ttotal: 29.7s\tremaining: 7.61s\n",
      "398:\tlearn: 0.0019992\ttotal: 29.8s\tremaining: 7.55s\n",
      "399:\tlearn: 0.0019991\ttotal: 29.9s\tremaining: 7.46s\n",
      "400:\tlearn: 0.0019991\ttotal: 29.9s\tremaining: 7.38s\n",
      "401:\tlearn: 0.0019991\ttotal: 30s\tremaining: 7.31s\n",
      "402:\tlearn: 0.0019991\ttotal: 30.1s\tremaining: 7.23s\n",
      "403:\tlearn: 0.0019991\ttotal: 30.1s\tremaining: 7.15s\n",
      "404:\tlearn: 0.0019883\ttotal: 30.2s\tremaining: 7.09s\n",
      "405:\tlearn: 0.0019883\ttotal: 30.3s\tremaining: 7s\n",
      "406:\tlearn: 0.0019883\ttotal: 30.4s\tremaining: 6.94s\n",
      "407:\tlearn: 0.0019883\ttotal: 30.4s\tremaining: 6.86s\n",
      "408:\tlearn: 0.0019883\ttotal: 30.5s\tremaining: 6.79s\n",
      "409:\tlearn: 0.0019883\ttotal: 30.6s\tremaining: 6.71s\n",
      "410:\tlearn: 0.0019882\ttotal: 30.6s\tremaining: 6.63s\n",
      "411:\tlearn: 0.0019882\ttotal: 30.8s\tremaining: 6.57s\n",
      "412:\tlearn: 0.0019882\ttotal: 30.8s\tremaining: 6.49s\n",
      "413:\tlearn: 0.0019882\ttotal: 30.9s\tremaining: 6.42s\n",
      "414:\tlearn: 0.0019882\ttotal: 31s\tremaining: 6.34s\n",
      "415:\tlearn: 0.0019882\ttotal: 31.1s\tremaining: 6.27s\n",
      "416:\tlearn: 0.0019881\ttotal: 31.1s\tremaining: 6.2s\n",
      "417:\tlearn: 0.0019881\ttotal: 31.2s\tremaining: 6.12s\n",
      "418:\tlearn: 0.0019882\ttotal: 31.3s\tremaining: 6.05s\n",
      "419:\tlearn: 0.0019881\ttotal: 31.3s\tremaining: 5.97s\n",
      "420:\tlearn: 0.0019881\ttotal: 31.4s\tremaining: 5.9s\n",
      "421:\tlearn: 0.0019881\ttotal: 31.5s\tremaining: 5.82s\n",
      "422:\tlearn: 0.0019881\ttotal: 31.5s\tremaining: 5.74s\n",
      "423:\tlearn: 0.0019828\ttotal: 31.6s\tremaining: 5.67s\n",
      "424:\tlearn: 0.0019827\ttotal: 31.7s\tremaining: 5.59s\n",
      "425:\tlearn: 0.0019826\ttotal: 31.8s\tremaining: 5.53s\n",
      "426:\tlearn: 0.0019826\ttotal: 31.9s\tremaining: 5.45s\n",
      "427:\tlearn: 0.0019654\ttotal: 32s\tremaining: 5.38s\n",
      "428:\tlearn: 0.0019654\ttotal: 32s\tremaining: 5.3s\n",
      "429:\tlearn: 0.0019432\ttotal: 32.1s\tremaining: 5.22s\n",
      "430:\tlearn: 0.0019432\ttotal: 32.2s\tremaining: 5.15s\n",
      "431:\tlearn: 0.0019432\ttotal: 32.2s\tremaining: 5.07s\n",
      "432:\tlearn: 0.0019265\ttotal: 32.3s\tremaining: 5s\n",
      "433:\tlearn: 0.0019265\ttotal: 32.4s\tremaining: 4.93s\n",
      "434:\tlearn: 0.0019264\ttotal: 32.5s\tremaining: 4.85s\n",
      "435:\tlearn: 0.0019265\ttotal: 32.6s\tremaining: 4.78s\n",
      "436:\tlearn: 0.0019197\ttotal: 32.6s\tremaining: 4.7s\n",
      "437:\tlearn: 0.0019198\ttotal: 32.7s\tremaining: 4.63s\n",
      "438:\tlearn: 0.0019197\ttotal: 32.8s\tremaining: 4.55s\n",
      "439:\tlearn: 0.0019197\ttotal: 32.9s\tremaining: 4.48s\n",
      "440:\tlearn: 0.0019197\ttotal: 32.9s\tremaining: 4.41s\n",
      "441:\tlearn: 0.0019197\ttotal: 33s\tremaining: 4.33s\n",
      "442:\tlearn: 0.0019197\ttotal: 33.1s\tremaining: 4.26s\n",
      "443:\tlearn: 0.0019196\ttotal: 33.1s\tremaining: 4.18s\n",
      "444:\tlearn: 0.0019196\ttotal: 33.3s\tremaining: 4.11s\n",
      "445:\tlearn: 0.0019197\ttotal: 33.3s\tremaining: 4.03s\n",
      "446:\tlearn: 0.0019197\ttotal: 33.3s\tremaining: 3.95s\n",
      "447:\tlearn: 0.0019197\ttotal: 33.5s\tremaining: 3.88s\n",
      "448:\tlearn: 0.0019120\ttotal: 33.5s\tremaining: 3.8s\n",
      "449:\tlearn: 0.0019120\ttotal: 33.6s\tremaining: 3.73s\n",
      "450:\tlearn: 0.0019120\ttotal: 33.7s\tremaining: 3.66s\n",
      "451:\tlearn: 0.0019120\ttotal: 33.8s\tremaining: 3.59s\n",
      "452:\tlearn: 0.0019120\ttotal: 33.8s\tremaining: 3.51s\n",
      "453:\tlearn: 0.0019119\ttotal: 33.9s\tremaining: 3.43s\n",
      "454:\tlearn: 0.0019119\ttotal: 34s\tremaining: 3.36s\n",
      "455:\tlearn: 0.0019119\ttotal: 34s\tremaining: 3.28s\n",
      "456:\tlearn: 0.0019119\ttotal: 34.1s\tremaining: 3.21s\n",
      "457:\tlearn: 0.0019119\ttotal: 34.2s\tremaining: 3.13s\n",
      "458:\tlearn: 0.0019064\ttotal: 34.3s\tremaining: 3.06s\n",
      "459:\tlearn: 0.0019064\ttotal: 34.3s\tremaining: 2.99s\n",
      "460:\tlearn: 0.0019064\ttotal: 34.4s\tremaining: 2.91s\n",
      "461:\tlearn: 0.0019064\ttotal: 34.5s\tremaining: 2.84s\n",
      "462:\tlearn: 0.0019064\ttotal: 34.6s\tremaining: 2.76s\n",
      "463:\tlearn: 0.0019064\ttotal: 34.7s\tremaining: 2.69s\n",
      "464:\tlearn: 0.0019064\ttotal: 34.7s\tremaining: 2.61s\n",
      "465:\tlearn: 0.0019064\ttotal: 34.8s\tremaining: 2.54s\n",
      "466:\tlearn: 0.0019064\ttotal: 34.9s\tremaining: 2.46s\n",
      "467:\tlearn: 0.0019064\ttotal: 35s\tremaining: 2.39s\n",
      "468:\tlearn: 0.0019064\ttotal: 35s\tremaining: 2.31s\n",
      "469:\tlearn: 0.0019064\ttotal: 35.1s\tremaining: 2.24s\n",
      "470:\tlearn: 0.0018926\ttotal: 35.2s\tremaining: 2.17s\n",
      "471:\tlearn: 0.0018926\ttotal: 35.3s\tremaining: 2.09s\n",
      "472:\tlearn: 0.0018926\ttotal: 35.4s\tremaining: 2.02s\n",
      "473:\tlearn: 0.0018925\ttotal: 35.4s\tremaining: 1.94s\n",
      "474:\tlearn: 0.0018925\ttotal: 35.5s\tremaining: 1.87s\n",
      "475:\tlearn: 0.0018925\ttotal: 35.6s\tremaining: 1.79s\n",
      "476:\tlearn: 0.0018892\ttotal: 35.7s\tremaining: 1.72s\n",
      "477:\tlearn: 0.0018893\ttotal: 35.7s\tremaining: 1.64s\n",
      "478:\tlearn: 0.0018892\ttotal: 35.8s\tremaining: 1.57s\n",
      "479:\tlearn: 0.0018892\ttotal: 35.9s\tremaining: 1.5s\n",
      "480:\tlearn: 0.0018892\ttotal: 35.9s\tremaining: 1.42s\n",
      "481:\tlearn: 0.0018892\ttotal: 36s\tremaining: 1.34s\n",
      "482:\tlearn: 0.0018892\ttotal: 36.1s\tremaining: 1.27s\n",
      "483:\tlearn: 0.0018890\ttotal: 36.2s\tremaining: 1.2s\n",
      "484:\tlearn: 0.0018890\ttotal: 36.2s\tremaining: 1.12s\n",
      "485:\tlearn: 0.0018890\ttotal: 36.4s\tremaining: 1.05s\n",
      "486:\tlearn: 0.0018890\ttotal: 36.4s\tremaining: 972ms\n",
      "487:\tlearn: 0.0018890\ttotal: 36.5s\tremaining: 896ms\n",
      "488:\tlearn: 0.0018890\ttotal: 36.6s\tremaining: 823ms\n",
      "489:\tlearn: 0.0018890\ttotal: 36.7s\tremaining: 748ms\n",
      "490:\tlearn: 0.0018890\ttotal: 36.8s\tremaining: 674ms\n",
      "491:\tlearn: 0.0018890\ttotal: 36.8s\tremaining: 598ms\n",
      "492:\tlearn: 0.0018890\ttotal: 36.9s\tremaining: 524ms\n",
      "493:\tlearn: 0.0018890\ttotal: 37s\tremaining: 449ms\n",
      "494:\tlearn: 0.0018887\ttotal: 37s\tremaining: 374ms\n",
      "495:\tlearn: 0.0018887\ttotal: 37s\tremaining: 299ms\n",
      "496:\tlearn: 0.0018888\ttotal: 37.1s\tremaining: 224ms\n",
      "497:\tlearn: 0.0018887\ttotal: 37.2s\tremaining: 149ms\n",
      "498:\tlearn: 0.0018795\ttotal: 37.3s\tremaining: 74.7ms\n",
      "499:\tlearn: 0.0018795\ttotal: 37.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6549007\ttotal: 64.3ms\tremaining: 32.1s\n",
      "1:\tlearn: 0.6133138\ttotal: 176ms\tremaining: 43.8s\n",
      "2:\tlearn: 0.5747370\ttotal: 222ms\tremaining: 36.8s\n",
      "3:\tlearn: 0.5479093\ttotal: 329ms\tremaining: 40.8s\n",
      "4:\tlearn: 0.5145940\ttotal: 387ms\tremaining: 38.4s\n",
      "5:\tlearn: 0.4857197\ttotal: 430ms\tremaining: 35.4s\n",
      "6:\tlearn: 0.4624263\ttotal: 537ms\tremaining: 37.8s\n",
      "7:\tlearn: 0.4425685\ttotal: 579ms\tremaining: 35.6s\n",
      "8:\tlearn: 0.4194968\ttotal: 697ms\tremaining: 38s\n",
      "9:\tlearn: 0.4004784\ttotal: 746ms\tremaining: 36.6s\n",
      "10:\tlearn: 0.3857559\ttotal: 840ms\tremaining: 37.3s\n",
      "11:\tlearn: 0.3689195\ttotal: 909ms\tremaining: 36.9s\n",
      "12:\tlearn: 0.3559167\ttotal: 953ms\tremaining: 35.7s\n",
      "13:\tlearn: 0.3374162\ttotal: 1.07s\tremaining: 37s\n",
      "14:\tlearn: 0.3225855\ttotal: 1.11s\tremaining: 36s\n",
      "15:\tlearn: 0.3048838\ttotal: 1.2s\tremaining: 36.4s\n",
      "16:\tlearn: 0.2887846\ttotal: 1.27s\tremaining: 36.2s\n",
      "17:\tlearn: 0.2739687\ttotal: 1.31s\tremaining: 35.2s\n",
      "18:\tlearn: 0.2655255\ttotal: 1.44s\tremaining: 36.3s\n",
      "19:\tlearn: 0.2531626\ttotal: 1.48s\tremaining: 35.5s\n",
      "20:\tlearn: 0.2417112\ttotal: 1.6s\tremaining: 36.5s\n",
      "21:\tlearn: 0.2283225\ttotal: 1.65s\tremaining: 35.8s\n",
      "22:\tlearn: 0.2195527\ttotal: 1.74s\tremaining: 36.1s\n",
      "23:\tlearn: 0.2074854\ttotal: 1.81s\tremaining: 35.9s\n",
      "24:\tlearn: 0.1976127\ttotal: 1.86s\tremaining: 35.3s\n",
      "25:\tlearn: 0.1857313\ttotal: 1.97s\tremaining: 35.9s\n",
      "26:\tlearn: 0.1796371\ttotal: 2.03s\tremaining: 35.5s\n",
      "27:\tlearn: 0.1750752\ttotal: 2.12s\tremaining: 35.8s\n",
      "28:\tlearn: 0.1687274\ttotal: 2.19s\tremaining: 35.5s\n",
      "29:\tlearn: 0.1615441\ttotal: 2.24s\tremaining: 35s\n",
      "30:\tlearn: 0.1565232\ttotal: 2.35s\tremaining: 35.6s\n",
      "31:\tlearn: 0.1514092\ttotal: 2.4s\tremaining: 35s\n",
      "32:\tlearn: 0.1429326\ttotal: 2.52s\tremaining: 35.6s\n",
      "33:\tlearn: 0.1375364\ttotal: 2.57s\tremaining: 35.2s\n",
      "34:\tlearn: 0.1309940\ttotal: 2.68s\tremaining: 35.6s\n",
      "35:\tlearn: 0.1259372\ttotal: 2.73s\tremaining: 35.3s\n",
      "36:\tlearn: 0.1196533\ttotal: 2.81s\tremaining: 35.2s\n",
      "37:\tlearn: 0.1133867\ttotal: 2.89s\tremaining: 35.2s\n",
      "38:\tlearn: 0.1108056\ttotal: 2.94s\tremaining: 34.7s\n",
      "39:\tlearn: 0.1070396\ttotal: 3.04s\tremaining: 35s\n",
      "40:\tlearn: 0.1027240\ttotal: 3.1s\tremaining: 34.7s\n",
      "41:\tlearn: 0.0982601\ttotal: 3.19s\tremaining: 34.8s\n",
      "42:\tlearn: 0.0952139\ttotal: 3.27s\tremaining: 34.7s\n",
      "43:\tlearn: 0.0924047\ttotal: 3.31s\tremaining: 34.3s\n",
      "44:\tlearn: 0.0906009\ttotal: 3.42s\tremaining: 34.6s\n",
      "45:\tlearn: 0.0880992\ttotal: 3.47s\tremaining: 34.2s\n",
      "46:\tlearn: 0.0845105\ttotal: 3.59s\tremaining: 34.6s\n",
      "47:\tlearn: 0.0816312\ttotal: 3.64s\tremaining: 34.3s\n",
      "48:\tlearn: 0.0790304\ttotal: 3.73s\tremaining: 34.3s\n",
      "49:\tlearn: 0.0771430\ttotal: 3.8s\tremaining: 34.2s\n",
      "50:\tlearn: 0.0753655\ttotal: 3.84s\tremaining: 33.8s\n",
      "51:\tlearn: 0.0735910\ttotal: 3.96s\tremaining: 34.1s\n",
      "52:\tlearn: 0.0717968\ttotal: 4.01s\tremaining: 33.8s\n",
      "53:\tlearn: 0.0693974\ttotal: 4.13s\tremaining: 34.1s\n",
      "54:\tlearn: 0.0676104\ttotal: 4.18s\tremaining: 33.8s\n",
      "55:\tlearn: 0.0653746\ttotal: 4.29s\tremaining: 34s\n",
      "56:\tlearn: 0.0629002\ttotal: 4.35s\tremaining: 33.8s\n",
      "57:\tlearn: 0.0607668\ttotal: 4.44s\tremaining: 33.9s\n",
      "58:\tlearn: 0.0587221\ttotal: 4.51s\tremaining: 33.7s\n",
      "59:\tlearn: 0.0573510\ttotal: 4.55s\tremaining: 33.4s\n",
      "60:\tlearn: 0.0560032\ttotal: 4.67s\tremaining: 33.6s\n",
      "61:\tlearn: 0.0545451\ttotal: 4.72s\tremaining: 33.3s\n",
      "62:\tlearn: 0.0530462\ttotal: 4.82s\tremaining: 33.5s\n",
      "63:\tlearn: 0.0510448\ttotal: 4.88s\tremaining: 33.2s\n",
      "64:\tlearn: 0.0492713\ttotal: 4.95s\tremaining: 33.1s\n",
      "65:\tlearn: 0.0480487\ttotal: 5.04s\tremaining: 33.1s\n",
      "66:\tlearn: 0.0469321\ttotal: 5.08s\tremaining: 32.9s\n",
      "67:\tlearn: 0.0460493\ttotal: 5.21s\tremaining: 33.1s\n",
      "68:\tlearn: 0.0449816\ttotal: 5.25s\tremaining: 32.8s\n",
      "69:\tlearn: 0.0436271\ttotal: 5.34s\tremaining: 32.8s\n",
      "70:\tlearn: 0.0421803\ttotal: 5.41s\tremaining: 32.7s\n",
      "71:\tlearn: 0.0406023\ttotal: 5.45s\tremaining: 32.4s\n",
      "72:\tlearn: 0.0395960\ttotal: 5.57s\tremaining: 32.6s\n",
      "73:\tlearn: 0.0380066\ttotal: 5.61s\tremaining: 32.3s\n",
      "74:\tlearn: 0.0368726\ttotal: 5.72s\tremaining: 32.4s\n",
      "75:\tlearn: 0.0358502\ttotal: 5.78s\tremaining: 32.2s\n",
      "76:\tlearn: 0.0349601\ttotal: 5.88s\tremaining: 32.3s\n",
      "77:\tlearn: 0.0334312\ttotal: 5.93s\tremaining: 32.1s\n",
      "78:\tlearn: 0.0324283\ttotal: 6.05s\tremaining: 32.2s\n",
      "79:\tlearn: 0.0313955\ttotal: 6.11s\tremaining: 32.1s\n",
      "80:\tlearn: 0.0307997\ttotal: 6.22s\tremaining: 32.2s\n",
      "81:\tlearn: 0.0299058\ttotal: 6.28s\tremaining: 32s\n",
      "82:\tlearn: 0.0292814\ttotal: 6.32s\tremaining: 31.8s\n",
      "83:\tlearn: 0.0285410\ttotal: 6.43s\tremaining: 31.8s\n",
      "84:\tlearn: 0.0279431\ttotal: 6.47s\tremaining: 31.6s\n",
      "85:\tlearn: 0.0275287\ttotal: 6.59s\tremaining: 31.7s\n",
      "86:\tlearn: 0.0265732\ttotal: 6.64s\tremaining: 31.5s\n",
      "87:\tlearn: 0.0258195\ttotal: 6.74s\tremaining: 31.5s\n",
      "88:\tlearn: 0.0253457\ttotal: 6.81s\tremaining: 31.4s\n",
      "89:\tlearn: 0.0244310\ttotal: 6.85s\tremaining: 31.2s\n",
      "90:\tlearn: 0.0237725\ttotal: 6.97s\tremaining: 31.3s\n",
      "91:\tlearn: 0.0231367\ttotal: 7.02s\tremaining: 31.1s\n",
      "92:\tlearn: 0.0225053\ttotal: 7.14s\tremaining: 31.3s\n",
      "93:\tlearn: 0.0219422\ttotal: 7.19s\tremaining: 31s\n",
      "94:\tlearn: 0.0213035\ttotal: 7.31s\tremaining: 31.2s\n",
      "95:\tlearn: 0.0207111\ttotal: 7.36s\tremaining: 31s\n",
      "96:\tlearn: 0.0201061\ttotal: 7.45s\tremaining: 30.9s\n",
      "97:\tlearn: 0.0194805\ttotal: 7.53s\tremaining: 30.9s\n",
      "98:\tlearn: 0.0188957\ttotal: 7.58s\tremaining: 30.7s\n",
      "99:\tlearn: 0.0183788\ttotal: 7.68s\tremaining: 30.7s\n",
      "100:\tlearn: 0.0178447\ttotal: 7.73s\tremaining: 30.5s\n",
      "101:\tlearn: 0.0174044\ttotal: 7.78s\tremaining: 30.3s\n",
      "102:\tlearn: 0.0169882\ttotal: 7.89s\tremaining: 30.4s\n",
      "103:\tlearn: 0.0166677\ttotal: 7.94s\tremaining: 30.2s\n",
      "104:\tlearn: 0.0161928\ttotal: 8.06s\tremaining: 30.3s\n",
      "105:\tlearn: 0.0157162\ttotal: 8.11s\tremaining: 30.1s\n",
      "106:\tlearn: 0.0153088\ttotal: 8.2s\tremaining: 30.1s\n",
      "107:\tlearn: 0.0150192\ttotal: 8.26s\tremaining: 30s\n",
      "108:\tlearn: 0.0147250\ttotal: 8.32s\tremaining: 29.8s\n",
      "109:\tlearn: 0.0144777\ttotal: 8.42s\tremaining: 29.9s\n",
      "110:\tlearn: 0.0140941\ttotal: 8.47s\tremaining: 29.7s\n",
      "111:\tlearn: 0.0137198\ttotal: 8.58s\tremaining: 29.7s\n",
      "112:\tlearn: 0.0134071\ttotal: 8.63s\tremaining: 29.6s\n",
      "113:\tlearn: 0.0131711\ttotal: 8.73s\tremaining: 29.6s\n",
      "114:\tlearn: 0.0128963\ttotal: 8.8s\tremaining: 29.5s\n",
      "115:\tlearn: 0.0126047\ttotal: 8.84s\tremaining: 29.3s\n",
      "116:\tlearn: 0.0123886\ttotal: 8.96s\tremaining: 29.3s\n",
      "117:\tlearn: 0.0121868\ttotal: 9s\tremaining: 29.1s\n",
      "118:\tlearn: 0.0119615\ttotal: 9.1s\tremaining: 29.1s\n",
      "119:\tlearn: 0.0116906\ttotal: 9.16s\tremaining: 29s\n",
      "120:\tlearn: 0.0115017\ttotal: 9.24s\tremaining: 28.9s\n",
      "121:\tlearn: 0.0111844\ttotal: 9.33s\tremaining: 28.9s\n",
      "122:\tlearn: 0.0109685\ttotal: 9.38s\tremaining: 28.7s\n",
      "123:\tlearn: 0.0108355\ttotal: 9.53s\tremaining: 28.9s\n",
      "124:\tlearn: 0.0106346\ttotal: 9.57s\tremaining: 28.7s\n",
      "125:\tlearn: 0.0104452\ttotal: 9.66s\tremaining: 28.7s\n",
      "126:\tlearn: 0.0103015\ttotal: 9.7s\tremaining: 28.5s\n",
      "127:\tlearn: 0.0101008\ttotal: 9.85s\tremaining: 28.6s\n",
      "128:\tlearn: 0.0099073\ttotal: 9.92s\tremaining: 28.5s\n",
      "129:\tlearn: 0.0097709\ttotal: 10s\tremaining: 28.5s\n",
      "130:\tlearn: 0.0096338\ttotal: 10.1s\tremaining: 28.4s\n",
      "131:\tlearn: 0.0095121\ttotal: 10.1s\tremaining: 28.3s\n",
      "132:\tlearn: 0.0093466\ttotal: 10.2s\tremaining: 28.2s\n",
      "133:\tlearn: 0.0091812\ttotal: 10.3s\tremaining: 28.1s\n",
      "134:\tlearn: 0.0089759\ttotal: 10.4s\tremaining: 28.1s\n",
      "135:\tlearn: 0.0088329\ttotal: 10.5s\tremaining: 28s\n",
      "136:\tlearn: 0.0087283\ttotal: 10.6s\tremaining: 28s\n",
      "137:\tlearn: 0.0086245\ttotal: 10.6s\tremaining: 27.9s\n",
      "138:\tlearn: 0.0084475\ttotal: 10.7s\tremaining: 27.9s\n",
      "139:\tlearn: 0.0082874\ttotal: 10.8s\tremaining: 27.8s\n",
      "140:\tlearn: 0.0081919\ttotal: 10.8s\tremaining: 27.6s\n",
      "141:\tlearn: 0.0080933\ttotal: 10.9s\tremaining: 27.6s\n",
      "142:\tlearn: 0.0079764\ttotal: 11s\tremaining: 27.4s\n",
      "143:\tlearn: 0.0078400\ttotal: 11.1s\tremaining: 27.5s\n",
      "144:\tlearn: 0.0076925\ttotal: 11.2s\tremaining: 27.3s\n",
      "145:\tlearn: 0.0075896\ttotal: 11.2s\tremaining: 27.2s\n",
      "146:\tlearn: 0.0074663\ttotal: 11.3s\tremaining: 27.2s\n",
      "147:\tlearn: 0.0073513\ttotal: 11.4s\tremaining: 27s\n",
      "148:\tlearn: 0.0072121\ttotal: 11.5s\tremaining: 27s\n",
      "149:\tlearn: 0.0070817\ttotal: 11.5s\tremaining: 26.9s\n",
      "150:\tlearn: 0.0069722\ttotal: 11.6s\tremaining: 26.9s\n",
      "151:\tlearn: 0.0068489\ttotal: 11.7s\tremaining: 26.8s\n",
      "152:\tlearn: 0.0067568\ttotal: 11.7s\tremaining: 26.6s\n",
      "153:\tlearn: 0.0066641\ttotal: 11.9s\tremaining: 26.6s\n",
      "154:\tlearn: 0.0065363\ttotal: 11.9s\tremaining: 26.5s\n",
      "155:\tlearn: 0.0064532\ttotal: 12s\tremaining: 26.5s\n",
      "156:\tlearn: 0.0063739\ttotal: 12.1s\tremaining: 26.4s\n",
      "157:\tlearn: 0.0062889\ttotal: 12.1s\tremaining: 26.3s\n",
      "158:\tlearn: 0.0062122\ttotal: 12.2s\tremaining: 26.2s\n",
      "159:\tlearn: 0.0061180\ttotal: 12.3s\tremaining: 26.1s\n",
      "160:\tlearn: 0.0060236\ttotal: 12.4s\tremaining: 26.1s\n",
      "161:\tlearn: 0.0059189\ttotal: 12.4s\tremaining: 25.9s\n",
      "162:\tlearn: 0.0058202\ttotal: 12.5s\tremaining: 25.9s\n",
      "163:\tlearn: 0.0057498\ttotal: 12.6s\tremaining: 25.8s\n",
      "164:\tlearn: 0.0056401\ttotal: 12.6s\tremaining: 25.6s\n",
      "165:\tlearn: 0.0055774\ttotal: 12.7s\tremaining: 25.7s\n",
      "166:\tlearn: 0.0054749\ttotal: 12.8s\tremaining: 25.5s\n",
      "167:\tlearn: 0.0054002\ttotal: 12.9s\tremaining: 25.5s\n",
      "168:\tlearn: 0.0053305\ttotal: 13s\tremaining: 25.4s\n",
      "169:\tlearn: 0.0052613\ttotal: 13s\tremaining: 25.2s\n",
      "170:\tlearn: 0.0051988\ttotal: 13.1s\tremaining: 25.2s\n",
      "171:\tlearn: 0.0051239\ttotal: 13.2s\tremaining: 25.1s\n",
      "172:\tlearn: 0.0050634\ttotal: 13.2s\tremaining: 25s\n",
      "173:\tlearn: 0.0049933\ttotal: 13.3s\tremaining: 24.9s\n",
      "174:\tlearn: 0.0049307\ttotal: 13.4s\tremaining: 24.8s\n",
      "175:\tlearn: 0.0048787\ttotal: 13.5s\tremaining: 24.8s\n",
      "176:\tlearn: 0.0048343\ttotal: 13.5s\tremaining: 24.7s\n",
      "177:\tlearn: 0.0047890\ttotal: 13.6s\tremaining: 24.7s\n",
      "178:\tlearn: 0.0047257\ttotal: 13.7s\tremaining: 24.5s\n",
      "179:\tlearn: 0.0046734\ttotal: 13.8s\tremaining: 24.5s\n",
      "180:\tlearn: 0.0046309\ttotal: 13.9s\tremaining: 24.4s\n",
      "181:\tlearn: 0.0045731\ttotal: 13.9s\tremaining: 24.4s\n",
      "182:\tlearn: 0.0045293\ttotal: 14s\tremaining: 24.3s\n",
      "183:\tlearn: 0.0044813\ttotal: 14.1s\tremaining: 24.2s\n",
      "184:\tlearn: 0.0044390\ttotal: 14.2s\tremaining: 24.1s\n",
      "185:\tlearn: 0.0043951\ttotal: 14.2s\tremaining: 24s\n",
      "186:\tlearn: 0.0043524\ttotal: 14.3s\tremaining: 23.9s\n",
      "187:\tlearn: 0.0043076\ttotal: 14.4s\tremaining: 23.9s\n",
      "188:\tlearn: 0.0042618\ttotal: 14.4s\tremaining: 23.7s\n",
      "189:\tlearn: 0.0042178\ttotal: 14.5s\tremaining: 23.7s\n",
      "190:\tlearn: 0.0041722\ttotal: 14.6s\tremaining: 23.6s\n",
      "191:\tlearn: 0.0041169\ttotal: 14.7s\tremaining: 23.5s\n",
      "192:\tlearn: 0.0040671\ttotal: 14.7s\tremaining: 23.4s\n",
      "193:\tlearn: 0.0040067\ttotal: 14.8s\tremaining: 23.4s\n",
      "194:\tlearn: 0.0039734\ttotal: 14.9s\tremaining: 23.3s\n",
      "195:\tlearn: 0.0039156\ttotal: 14.9s\tremaining: 23.2s\n",
      "196:\tlearn: 0.0038821\ttotal: 15.1s\tremaining: 23.2s\n",
      "197:\tlearn: 0.0038568\ttotal: 15.1s\tremaining: 23s\n",
      "198:\tlearn: 0.0038108\ttotal: 15.2s\tremaining: 23s\n",
      "199:\tlearn: 0.0037637\ttotal: 15.3s\tremaining: 22.9s\n",
      "200:\tlearn: 0.0037225\ttotal: 15.3s\tremaining: 22.8s\n",
      "201:\tlearn: 0.0036777\ttotal: 15.4s\tremaining: 22.7s\n",
      "202:\tlearn: 0.0036476\ttotal: 15.5s\tremaining: 22.6s\n",
      "203:\tlearn: 0.0035988\ttotal: 15.6s\tremaining: 22.6s\n",
      "204:\tlearn: 0.0035650\ttotal: 15.6s\tremaining: 22.5s\n",
      "205:\tlearn: 0.0035303\ttotal: 15.7s\tremaining: 22.4s\n",
      "206:\tlearn: 0.0035046\ttotal: 15.8s\tremaining: 22.3s\n",
      "207:\tlearn: 0.0034654\ttotal: 15.8s\tremaining: 22.2s\n",
      "208:\tlearn: 0.0034305\ttotal: 15.9s\tremaining: 22.2s\n",
      "209:\tlearn: 0.0034074\ttotal: 16s\tremaining: 22.1s\n",
      "210:\tlearn: 0.0033732\ttotal: 16.1s\tremaining: 22s\n",
      "211:\tlearn: 0.0033484\ttotal: 16.1s\tremaining: 21.9s\n",
      "212:\tlearn: 0.0033259\ttotal: 16.2s\tremaining: 21.9s\n",
      "213:\tlearn: 0.0032970\ttotal: 16.3s\tremaining: 21.8s\n",
      "214:\tlearn: 0.0032645\ttotal: 16.4s\tremaining: 21.7s\n",
      "215:\tlearn: 0.0032299\ttotal: 16.5s\tremaining: 21.6s\n",
      "216:\tlearn: 0.0032021\ttotal: 16.6s\tremaining: 21.6s\n",
      "217:\tlearn: 0.0031778\ttotal: 16.6s\tremaining: 21.5s\n",
      "218:\tlearn: 0.0031422\ttotal: 16.7s\tremaining: 21.4s\n",
      "219:\tlearn: 0.0031084\ttotal: 16.8s\tremaining: 21.4s\n",
      "220:\tlearn: 0.0030722\ttotal: 16.8s\tremaining: 21.2s\n",
      "221:\tlearn: 0.0030490\ttotal: 16.9s\tremaining: 21.2s\n",
      "222:\tlearn: 0.0030212\ttotal: 17s\tremaining: 21.1s\n",
      "223:\tlearn: 0.0030211\ttotal: 17.1s\tremaining: 21s\n",
      "224:\tlearn: 0.0030010\ttotal: 17.1s\tremaining: 21s\n",
      "225:\tlearn: 0.0029816\ttotal: 17.2s\tremaining: 20.8s\n",
      "226:\tlearn: 0.0029557\ttotal: 17.3s\tremaining: 20.8s\n",
      "227:\tlearn: 0.0029264\ttotal: 17.3s\tremaining: 20.7s\n",
      "228:\tlearn: 0.0028976\ttotal: 17.5s\tremaining: 20.7s\n",
      "229:\tlearn: 0.0028763\ttotal: 17.6s\tremaining: 20.6s\n",
      "230:\tlearn: 0.0028543\ttotal: 17.6s\tremaining: 20.5s\n",
      "231:\tlearn: 0.0028270\ttotal: 17.7s\tremaining: 20.4s\n",
      "232:\tlearn: 0.0028032\ttotal: 17.8s\tremaining: 20.4s\n",
      "233:\tlearn: 0.0027748\ttotal: 17.8s\tremaining: 20.2s\n",
      "234:\tlearn: 0.0027490\ttotal: 17.9s\tremaining: 20.2s\n",
      "235:\tlearn: 0.0027260\ttotal: 18s\tremaining: 20.1s\n",
      "236:\tlearn: 0.0027260\ttotal: 18s\tremaining: 20s\n",
      "237:\tlearn: 0.0027078\ttotal: 18.1s\tremaining: 19.9s\n",
      "238:\tlearn: 0.0027077\ttotal: 18.2s\tremaining: 19.8s\n",
      "239:\tlearn: 0.0026902\ttotal: 18.3s\tremaining: 19.8s\n",
      "240:\tlearn: 0.0026693\ttotal: 18.3s\tremaining: 19.7s\n",
      "241:\tlearn: 0.0026692\ttotal: 18.4s\tremaining: 19.6s\n",
      "242:\tlearn: 0.0026510\ttotal: 18.5s\tremaining: 19.6s\n",
      "243:\tlearn: 0.0026370\ttotal: 18.5s\tremaining: 19.5s\n",
      "244:\tlearn: 0.0026176\ttotal: 18.7s\tremaining: 19.4s\n",
      "245:\tlearn: 0.0026022\ttotal: 18.7s\tremaining: 19.3s\n",
      "246:\tlearn: 0.0025828\ttotal: 18.8s\tremaining: 19.3s\n",
      "247:\tlearn: 0.0025828\ttotal: 18.9s\tremaining: 19.2s\n",
      "248:\tlearn: 0.0025634\ttotal: 19s\tremaining: 19.1s\n",
      "249:\tlearn: 0.0025397\ttotal: 19s\tremaining: 19s\n",
      "250:\tlearn: 0.0025138\ttotal: 19.1s\tremaining: 18.9s\n",
      "251:\tlearn: 0.0024976\ttotal: 19.2s\tremaining: 18.9s\n",
      "252:\tlearn: 0.0024796\ttotal: 19.3s\tremaining: 18.8s\n",
      "253:\tlearn: 0.0024577\ttotal: 19.4s\tremaining: 18.7s\n",
      "254:\tlearn: 0.0024333\ttotal: 19.4s\tremaining: 18.7s\n",
      "255:\tlearn: 0.0024332\ttotal: 19.5s\tremaining: 18.5s\n",
      "256:\tlearn: 0.0024157\ttotal: 19.6s\tremaining: 18.5s\n",
      "257:\tlearn: 0.0023992\ttotal: 19.6s\tremaining: 18.4s\n",
      "258:\tlearn: 0.0023775\ttotal: 19.8s\tremaining: 18.4s\n",
      "259:\tlearn: 0.0023570\ttotal: 19.9s\tremaining: 18.3s\n",
      "260:\tlearn: 0.0023570\ttotal: 19.9s\tremaining: 18.2s\n",
      "261:\tlearn: 0.0023401\ttotal: 20s\tremaining: 18.2s\n",
      "262:\tlearn: 0.0023401\ttotal: 20.1s\tremaining: 18.1s\n",
      "263:\tlearn: 0.0023401\ttotal: 20.1s\tremaining: 18s\n",
      "264:\tlearn: 0.0023209\ttotal: 20.2s\tremaining: 17.9s\n",
      "265:\tlearn: 0.0023209\ttotal: 20.3s\tremaining: 17.8s\n",
      "266:\tlearn: 0.0023209\ttotal: 20.4s\tremaining: 17.8s\n",
      "267:\tlearn: 0.0023209\ttotal: 20.4s\tremaining: 17.7s\n",
      "268:\tlearn: 0.0023209\ttotal: 20.6s\tremaining: 17.7s\n",
      "269:\tlearn: 0.0023066\ttotal: 20.6s\tremaining: 17.6s\n",
      "270:\tlearn: 0.0023066\ttotal: 20.7s\tremaining: 17.5s\n",
      "271:\tlearn: 0.0023066\ttotal: 20.8s\tremaining: 17.4s\n",
      "272:\tlearn: 0.0022901\ttotal: 20.8s\tremaining: 17.3s\n",
      "273:\tlearn: 0.0022901\ttotal: 20.9s\tremaining: 17.2s\n",
      "274:\tlearn: 0.0022901\ttotal: 21s\tremaining: 17.1s\n",
      "275:\tlearn: 0.0022720\ttotal: 21.1s\tremaining: 17.1s\n",
      "276:\tlearn: 0.0022610\ttotal: 21.1s\tremaining: 17s\n",
      "277:\tlearn: 0.0022532\ttotal: 21.2s\tremaining: 17s\n",
      "278:\tlearn: 0.0022306\ttotal: 21.3s\tremaining: 16.9s\n",
      "279:\tlearn: 0.0022131\ttotal: 21.4s\tremaining: 16.8s\n",
      "280:\tlearn: 0.0022131\ttotal: 21.5s\tremaining: 16.7s\n",
      "281:\tlearn: 0.0022131\ttotal: 21.5s\tremaining: 16.6s\n",
      "282:\tlearn: 0.0022131\ttotal: 21.6s\tremaining: 16.6s\n",
      "283:\tlearn: 0.0022131\ttotal: 21.7s\tremaining: 16.5s\n",
      "284:\tlearn: 0.0022131\ttotal: 21.8s\tremaining: 16.4s\n",
      "285:\tlearn: 0.0022131\ttotal: 21.8s\tremaining: 16.3s\n",
      "286:\tlearn: 0.0022130\ttotal: 21.9s\tremaining: 16.3s\n",
      "287:\tlearn: 0.0022130\ttotal: 22s\tremaining: 16.2s\n",
      "288:\tlearn: 0.0022130\ttotal: 22.1s\tremaining: 16.1s\n",
      "289:\tlearn: 0.0022129\ttotal: 22.1s\tremaining: 16s\n",
      "290:\tlearn: 0.0021998\ttotal: 22.2s\tremaining: 16s\n",
      "291:\tlearn: 0.0021999\ttotal: 22.3s\tremaining: 15.9s\n",
      "292:\tlearn: 0.0021998\ttotal: 22.4s\tremaining: 15.8s\n",
      "293:\tlearn: 0.0021818\ttotal: 22.5s\tremaining: 15.7s\n",
      "294:\tlearn: 0.0021818\ttotal: 22.5s\tremaining: 15.7s\n",
      "295:\tlearn: 0.0021818\ttotal: 22.6s\tremaining: 15.6s\n",
      "296:\tlearn: 0.0021817\ttotal: 22.7s\tremaining: 15.5s\n",
      "297:\tlearn: 0.0021817\ttotal: 22.7s\tremaining: 15.4s\n",
      "298:\tlearn: 0.0021658\ttotal: 22.8s\tremaining: 15.4s\n",
      "299:\tlearn: 0.0021658\ttotal: 22.9s\tremaining: 15.3s\n",
      "300:\tlearn: 0.0021658\ttotal: 23s\tremaining: 15.2s\n",
      "301:\tlearn: 0.0021657\ttotal: 23s\tremaining: 15.1s\n",
      "302:\tlearn: 0.0021657\ttotal: 23.1s\tremaining: 15s\n",
      "303:\tlearn: 0.0021656\ttotal: 23.2s\tremaining: 15s\n",
      "304:\tlearn: 0.0021656\ttotal: 23.3s\tremaining: 14.9s\n",
      "305:\tlearn: 0.0021656\ttotal: 23.4s\tremaining: 14.8s\n",
      "306:\tlearn: 0.0021605\ttotal: 23.4s\tremaining: 14.7s\n",
      "307:\tlearn: 0.0021371\ttotal: 23.5s\tremaining: 14.7s\n",
      "308:\tlearn: 0.0021371\ttotal: 23.6s\tremaining: 14.6s\n",
      "309:\tlearn: 0.0021372\ttotal: 23.6s\tremaining: 14.5s\n",
      "310:\tlearn: 0.0021371\ttotal: 23.7s\tremaining: 14.4s\n",
      "311:\tlearn: 0.0021183\ttotal: 23.8s\tremaining: 14.3s\n",
      "312:\tlearn: 0.0021183\ttotal: 23.9s\tremaining: 14.3s\n",
      "313:\tlearn: 0.0021182\ttotal: 23.9s\tremaining: 14.2s\n",
      "314:\tlearn: 0.0021182\ttotal: 24s\tremaining: 14.1s\n",
      "315:\tlearn: 0.0021182\ttotal: 24.1s\tremaining: 14s\n",
      "316:\tlearn: 0.0021182\ttotal: 24.1s\tremaining: 13.9s\n",
      "317:\tlearn: 0.0021182\ttotal: 24.3s\tremaining: 13.9s\n",
      "318:\tlearn: 0.0021182\ttotal: 24.3s\tremaining: 13.8s\n",
      "319:\tlearn: 0.0021182\ttotal: 24.4s\tremaining: 13.7s\n",
      "320:\tlearn: 0.0021182\ttotal: 24.5s\tremaining: 13.6s\n",
      "321:\tlearn: 0.0021181\ttotal: 24.6s\tremaining: 13.6s\n",
      "322:\tlearn: 0.0021182\ttotal: 24.6s\tremaining: 13.5s\n",
      "323:\tlearn: 0.0021179\ttotal: 24.7s\tremaining: 13.4s\n",
      "324:\tlearn: 0.0021179\ttotal: 24.8s\tremaining: 13.3s\n",
      "325:\tlearn: 0.0021179\ttotal: 24.9s\tremaining: 13.3s\n",
      "326:\tlearn: 0.0021035\ttotal: 25s\tremaining: 13.2s\n",
      "327:\tlearn: 0.0021035\ttotal: 25s\tremaining: 13.1s\n",
      "328:\tlearn: 0.0021035\ttotal: 25.1s\tremaining: 13.1s\n",
      "329:\tlearn: 0.0021035\ttotal: 25.2s\tremaining: 13s\n",
      "330:\tlearn: 0.0021035\ttotal: 25.3s\tremaining: 12.9s\n",
      "331:\tlearn: 0.0021035\ttotal: 25.3s\tremaining: 12.8s\n",
      "332:\tlearn: 0.0021035\ttotal: 25.4s\tremaining: 12.7s\n",
      "333:\tlearn: 0.0021035\ttotal: 25.5s\tremaining: 12.7s\n",
      "334:\tlearn: 0.0021035\ttotal: 25.5s\tremaining: 12.6s\n",
      "335:\tlearn: 0.0021034\ttotal: 25.7s\tremaining: 12.5s\n",
      "336:\tlearn: 0.0021034\ttotal: 25.7s\tremaining: 12.4s\n",
      "337:\tlearn: 0.0021034\ttotal: 25.8s\tremaining: 12.4s\n",
      "338:\tlearn: 0.0021034\ttotal: 25.9s\tremaining: 12.3s\n",
      "339:\tlearn: 0.0021034\ttotal: 25.9s\tremaining: 12.2s\n",
      "340:\tlearn: 0.0021034\ttotal: 26s\tremaining: 12.1s\n",
      "341:\tlearn: 0.0021033\ttotal: 26.1s\tremaining: 12s\n",
      "342:\tlearn: 0.0021033\ttotal: 26.2s\tremaining: 12s\n",
      "343:\tlearn: 0.0021033\ttotal: 26.2s\tremaining: 11.9s\n",
      "344:\tlearn: 0.0021033\ttotal: 26.3s\tremaining: 11.8s\n",
      "345:\tlearn: 0.0021033\ttotal: 26.4s\tremaining: 11.7s\n",
      "346:\tlearn: 0.0020857\ttotal: 26.4s\tremaining: 11.7s\n",
      "347:\tlearn: 0.0020658\ttotal: 26.5s\tremaining: 11.6s\n",
      "348:\tlearn: 0.0020504\ttotal: 26.6s\tremaining: 11.5s\n",
      "349:\tlearn: 0.0020503\ttotal: 26.7s\tremaining: 11.4s\n",
      "350:\tlearn: 0.0020503\ttotal: 26.8s\tremaining: 11.4s\n",
      "351:\tlearn: 0.0020503\ttotal: 26.8s\tremaining: 11.3s\n",
      "352:\tlearn: 0.0020503\ttotal: 26.9s\tremaining: 11.2s\n",
      "353:\tlearn: 0.0020503\ttotal: 27s\tremaining: 11.1s\n",
      "354:\tlearn: 0.0020503\ttotal: 27.1s\tremaining: 11.1s\n",
      "355:\tlearn: 0.0020503\ttotal: 27.1s\tremaining: 11s\n",
      "356:\tlearn: 0.0020503\ttotal: 27.2s\tremaining: 10.9s\n",
      "357:\tlearn: 0.0020503\ttotal: 27.3s\tremaining: 10.8s\n",
      "358:\tlearn: 0.0020503\ttotal: 27.4s\tremaining: 10.7s\n",
      "359:\tlearn: 0.0020503\ttotal: 27.4s\tremaining: 10.7s\n",
      "360:\tlearn: 0.0020503\ttotal: 27.5s\tremaining: 10.6s\n",
      "361:\tlearn: 0.0020331\ttotal: 27.6s\tremaining: 10.5s\n",
      "362:\tlearn: 0.0020331\ttotal: 27.6s\tremaining: 10.4s\n",
      "363:\tlearn: 0.0020330\ttotal: 27.8s\tremaining: 10.4s\n",
      "364:\tlearn: 0.0020330\ttotal: 27.8s\tremaining: 10.3s\n",
      "365:\tlearn: 0.0020330\ttotal: 27.9s\tremaining: 10.2s\n",
      "366:\tlearn: 0.0020199\ttotal: 28s\tremaining: 10.1s\n",
      "367:\tlearn: 0.0020199\ttotal: 28s\tremaining: 10.1s\n",
      "368:\tlearn: 0.0020199\ttotal: 28.1s\tremaining: 9.99s\n",
      "369:\tlearn: 0.0020199\ttotal: 28.2s\tremaining: 9.9s\n",
      "370:\tlearn: 0.0020128\ttotal: 28.3s\tremaining: 9.83s\n",
      "371:\tlearn: 0.0019998\ttotal: 28.3s\tremaining: 9.74s\n",
      "372:\tlearn: 0.0019804\ttotal: 28.4s\tremaining: 9.68s\n",
      "373:\tlearn: 0.0019804\ttotal: 28.5s\tremaining: 9.59s\n",
      "374:\tlearn: 0.0019804\ttotal: 28.6s\tremaining: 9.52s\n",
      "375:\tlearn: 0.0019804\ttotal: 28.6s\tremaining: 9.45s\n",
      "376:\tlearn: 0.0019804\ttotal: 28.7s\tremaining: 9.36s\n",
      "377:\tlearn: 0.0019802\ttotal: 28.8s\tremaining: 9.29s\n",
      "378:\tlearn: 0.0019802\ttotal: 28.8s\tremaining: 9.21s\n",
      "379:\tlearn: 0.0019801\ttotal: 29s\tremaining: 9.14s\n",
      "380:\tlearn: 0.0019801\ttotal: 29s\tremaining: 9.06s\n",
      "381:\tlearn: 0.0019800\ttotal: 29s\tremaining: 8.97s\n",
      "382:\tlearn: 0.0019801\ttotal: 29.2s\tremaining: 8.91s\n",
      "383:\tlearn: 0.0019800\ttotal: 29.2s\tremaining: 8.82s\n",
      "384:\tlearn: 0.0019800\ttotal: 29.3s\tremaining: 8.75s\n",
      "385:\tlearn: 0.0019800\ttotal: 29.4s\tremaining: 8.67s\n",
      "386:\tlearn: 0.0019799\ttotal: 29.5s\tremaining: 8.6s\n",
      "387:\tlearn: 0.0019799\ttotal: 29.5s\tremaining: 8.53s\n",
      "388:\tlearn: 0.0019799\ttotal: 29.6s\tremaining: 8.45s\n",
      "389:\tlearn: 0.0019799\ttotal: 29.7s\tremaining: 8.38s\n",
      "390:\tlearn: 0.0019799\ttotal: 29.7s\tremaining: 8.29s\n",
      "391:\tlearn: 0.0019799\ttotal: 29.9s\tremaining: 8.23s\n",
      "392:\tlearn: 0.0019798\ttotal: 29.9s\tremaining: 8.14s\n",
      "393:\tlearn: 0.0019798\ttotal: 30s\tremaining: 8.07s\n",
      "394:\tlearn: 0.0019798\ttotal: 30.1s\tremaining: 7.99s\n",
      "395:\tlearn: 0.0019798\ttotal: 30.1s\tremaining: 7.91s\n",
      "396:\tlearn: 0.0019797\ttotal: 30.3s\tremaining: 7.85s\n",
      "397:\tlearn: 0.0019797\ttotal: 30.3s\tremaining: 7.76s\n",
      "398:\tlearn: 0.0019798\ttotal: 30.3s\tremaining: 7.68s\n",
      "399:\tlearn: 0.0019798\ttotal: 30.4s\tremaining: 7.61s\n",
      "400:\tlearn: 0.0019798\ttotal: 30.5s\tremaining: 7.52s\n",
      "401:\tlearn: 0.0019797\ttotal: 30.6s\tremaining: 7.45s\n",
      "402:\tlearn: 0.0019797\ttotal: 30.6s\tremaining: 7.37s\n",
      "403:\tlearn: 0.0019797\ttotal: 30.7s\tremaining: 7.29s\n",
      "404:\tlearn: 0.0019797\ttotal: 30.8s\tremaining: 7.22s\n",
      "405:\tlearn: 0.0019797\ttotal: 30.8s\tremaining: 7.14s\n",
      "406:\tlearn: 0.0019796\ttotal: 30.9s\tremaining: 7.05s\n",
      "407:\tlearn: 0.0019796\ttotal: 31s\tremaining: 6.98s\n",
      "408:\tlearn: 0.0019796\ttotal: 31s\tremaining: 6.9s\n",
      "409:\tlearn: 0.0019796\ttotal: 31.1s\tremaining: 6.83s\n",
      "410:\tlearn: 0.0019796\ttotal: 31.2s\tremaining: 6.75s\n",
      "411:\tlearn: 0.0019796\ttotal: 31.3s\tremaining: 6.68s\n",
      "412:\tlearn: 0.0019796\ttotal: 31.3s\tremaining: 6.6s\n",
      "413:\tlearn: 0.0019796\ttotal: 31.4s\tremaining: 6.53s\n",
      "414:\tlearn: 0.0019795\ttotal: 31.5s\tremaining: 6.46s\n",
      "415:\tlearn: 0.0019795\ttotal: 31.6s\tremaining: 6.37s\n",
      "416:\tlearn: 0.0019795\ttotal: 31.7s\tremaining: 6.3s\n",
      "417:\tlearn: 0.0019795\ttotal: 31.7s\tremaining: 6.22s\n",
      "418:\tlearn: 0.0019795\ttotal: 31.8s\tremaining: 6.14s\n",
      "419:\tlearn: 0.0019794\ttotal: 31.9s\tremaining: 6.07s\n",
      "420:\tlearn: 0.0019794\ttotal: 31.9s\tremaining: 5.99s\n",
      "421:\tlearn: 0.0019794\ttotal: 32s\tremaining: 5.91s\n",
      "422:\tlearn: 0.0019793\ttotal: 32.1s\tremaining: 5.84s\n",
      "423:\tlearn: 0.0019793\ttotal: 32.1s\tremaining: 5.76s\n",
      "424:\tlearn: 0.0019793\ttotal: 32.2s\tremaining: 5.69s\n",
      "425:\tlearn: 0.0019793\ttotal: 32.3s\tremaining: 5.61s\n",
      "426:\tlearn: 0.0019632\ttotal: 32.4s\tremaining: 5.54s\n",
      "427:\tlearn: 0.0019632\ttotal: 32.4s\tremaining: 5.46s\n",
      "428:\tlearn: 0.0019632\ttotal: 32.6s\tremaining: 5.39s\n",
      "429:\tlearn: 0.0019632\ttotal: 32.6s\tremaining: 5.31s\n",
      "430:\tlearn: 0.0019632\ttotal: 32.7s\tremaining: 5.24s\n",
      "431:\tlearn: 0.0019631\ttotal: 32.8s\tremaining: 5.16s\n",
      "432:\tlearn: 0.0019631\ttotal: 32.8s\tremaining: 5.08s\n",
      "433:\tlearn: 0.0019632\ttotal: 32.9s\tremaining: 5.01s\n",
      "434:\tlearn: 0.0019631\ttotal: 33s\tremaining: 4.93s\n",
      "435:\tlearn: 0.0019632\ttotal: 33.1s\tremaining: 4.86s\n",
      "436:\tlearn: 0.0019631\ttotal: 33.1s\tremaining: 4.78s\n",
      "437:\tlearn: 0.0019630\ttotal: 33.2s\tremaining: 4.7s\n",
      "438:\tlearn: 0.0019631\ttotal: 33.3s\tremaining: 4.63s\n",
      "439:\tlearn: 0.0019631\ttotal: 33.3s\tremaining: 4.55s\n",
      "440:\tlearn: 0.0019631\ttotal: 33.5s\tremaining: 4.47s\n",
      "441:\tlearn: 0.0019631\ttotal: 33.5s\tremaining: 4.4s\n",
      "442:\tlearn: 0.0019631\ttotal: 33.6s\tremaining: 4.32s\n",
      "443:\tlearn: 0.0019630\ttotal: 33.7s\tremaining: 4.25s\n",
      "444:\tlearn: 0.0019630\ttotal: 33.7s\tremaining: 4.17s\n",
      "445:\tlearn: 0.0019629\ttotal: 33.8s\tremaining: 4.1s\n",
      "446:\tlearn: 0.0019630\ttotal: 33.9s\tremaining: 4.02s\n",
      "447:\tlearn: 0.0019629\ttotal: 34s\tremaining: 3.94s\n",
      "448:\tlearn: 0.0019629\ttotal: 34s\tremaining: 3.87s\n",
      "449:\tlearn: 0.0019631\ttotal: 34.1s\tremaining: 3.79s\n",
      "450:\tlearn: 0.0019628\ttotal: 34.2s\tremaining: 3.71s\n",
      "451:\tlearn: 0.0019627\ttotal: 34.3s\tremaining: 3.64s\n",
      "452:\tlearn: 0.0019628\ttotal: 34.4s\tremaining: 3.57s\n",
      "453:\tlearn: 0.0019628\ttotal: 34.5s\tremaining: 3.49s\n",
      "454:\tlearn: 0.0019628\ttotal: 34.6s\tremaining: 3.42s\n",
      "455:\tlearn: 0.0019627\ttotal: 34.7s\tremaining: 3.35s\n",
      "456:\tlearn: 0.0019626\ttotal: 34.7s\tremaining: 3.27s\n",
      "457:\tlearn: 0.0019626\ttotal: 34.8s\tremaining: 3.19s\n",
      "458:\tlearn: 0.0019626\ttotal: 34.9s\tremaining: 3.12s\n",
      "459:\tlearn: 0.0019626\ttotal: 34.9s\tremaining: 3.04s\n",
      "460:\tlearn: 0.0019626\ttotal: 35s\tremaining: 2.96s\n",
      "461:\tlearn: 0.0019627\ttotal: 35.1s\tremaining: 2.89s\n",
      "462:\tlearn: 0.0019563\ttotal: 35.1s\tremaining: 2.81s\n",
      "463:\tlearn: 0.0019563\ttotal: 35.2s\tremaining: 2.73s\n",
      "464:\tlearn: 0.0019563\ttotal: 35.3s\tremaining: 2.66s\n",
      "465:\tlearn: 0.0019563\ttotal: 35.4s\tremaining: 2.58s\n",
      "466:\tlearn: 0.0019563\ttotal: 35.4s\tremaining: 2.5s\n",
      "467:\tlearn: 0.0019563\ttotal: 35.5s\tremaining: 2.43s\n",
      "468:\tlearn: 0.0019563\ttotal: 35.6s\tremaining: 2.35s\n",
      "469:\tlearn: 0.0019563\ttotal: 35.7s\tremaining: 2.28s\n",
      "470:\tlearn: 0.0019563\ttotal: 35.8s\tremaining: 2.2s\n",
      "471:\tlearn: 0.0019563\ttotal: 35.8s\tremaining: 2.13s\n",
      "472:\tlearn: 0.0019457\ttotal: 35.9s\tremaining: 2.05s\n",
      "473:\tlearn: 0.0019457\ttotal: 36s\tremaining: 1.97s\n",
      "474:\tlearn: 0.0019457\ttotal: 36.1s\tremaining: 1.9s\n",
      "475:\tlearn: 0.0019457\ttotal: 36.1s\tremaining: 1.82s\n",
      "476:\tlearn: 0.0019457\ttotal: 36.2s\tremaining: 1.75s\n",
      "477:\tlearn: 0.0019457\ttotal: 36.3s\tremaining: 1.67s\n",
      "478:\tlearn: 0.0019457\ttotal: 36.4s\tremaining: 1.59s\n",
      "479:\tlearn: 0.0019373\ttotal: 36.5s\tremaining: 1.52s\n",
      "480:\tlearn: 0.0019247\ttotal: 36.5s\tremaining: 1.44s\n",
      "481:\tlearn: 0.0019247\ttotal: 36.6s\tremaining: 1.37s\n",
      "482:\tlearn: 0.0019185\ttotal: 36.7s\tremaining: 1.29s\n",
      "483:\tlearn: 0.0019184\ttotal: 36.8s\tremaining: 1.22s\n",
      "484:\tlearn: 0.0019183\ttotal: 36.8s\tremaining: 1.14s\n",
      "485:\tlearn: 0.0019184\ttotal: 36.9s\tremaining: 1.06s\n",
      "486:\tlearn: 0.0019183\ttotal: 37s\tremaining: 987ms\n",
      "487:\tlearn: 0.0019183\ttotal: 37s\tremaining: 910ms\n",
      "488:\tlearn: 0.0019183\ttotal: 37.1s\tremaining: 835ms\n",
      "489:\tlearn: 0.0019183\ttotal: 37.2s\tremaining: 759ms\n",
      "490:\tlearn: 0.0019183\ttotal: 37.3s\tremaining: 683ms\n",
      "491:\tlearn: 0.0019182\ttotal: 37.3s\tremaining: 607ms\n",
      "492:\tlearn: 0.0019182\ttotal: 37.4s\tremaining: 530ms\n",
      "493:\tlearn: 0.0019182\ttotal: 37.5s\tremaining: 455ms\n",
      "494:\tlearn: 0.0019182\ttotal: 37.5s\tremaining: 379ms\n",
      "495:\tlearn: 0.0019182\ttotal: 37.6s\tremaining: 303ms\n",
      "496:\tlearn: 0.0019182\ttotal: 37.7s\tremaining: 227ms\n",
      "497:\tlearn: 0.0019182\ttotal: 37.7s\tremaining: 151ms\n",
      "498:\tlearn: 0.0019182\ttotal: 37.8s\tremaining: 75.8ms\n",
      "499:\tlearn: 0.0019182\ttotal: 37.9s\tremaining: 0us\n",
      "0:\tlearn: 0.6827599\ttotal: 4.88ms\tremaining: 2.44s\n",
      "1:\tlearn: 0.6729768\ttotal: 9.55ms\tremaining: 2.38s\n",
      "2:\tlearn: 0.6606964\ttotal: 14.2ms\tremaining: 2.35s\n",
      "3:\tlearn: 0.6500808\ttotal: 19.1ms\tremaining: 2.37s\n",
      "4:\tlearn: 0.6423513\ttotal: 23.8ms\tremaining: 2.35s\n",
      "5:\tlearn: 0.6326770\ttotal: 28.4ms\tremaining: 2.34s\n",
      "6:\tlearn: 0.6239207\ttotal: 33.1ms\tremaining: 2.33s\n",
      "7:\tlearn: 0.6155561\ttotal: 37.8ms\tremaining: 2.32s\n",
      "8:\tlearn: 0.6093298\ttotal: 41.9ms\tremaining: 2.28s\n",
      "9:\tlearn: 0.6032259\ttotal: 45.4ms\tremaining: 2.22s\n",
      "10:\tlearn: 0.5949627\ttotal: 49.7ms\tremaining: 2.21s\n",
      "11:\tlearn: 0.5874213\ttotal: 54.2ms\tremaining: 2.21s\n",
      "12:\tlearn: 0.5810452\ttotal: 58.5ms\tremaining: 2.19s\n",
      "13:\tlearn: 0.5757135\ttotal: 62.1ms\tremaining: 2.16s\n",
      "14:\tlearn: 0.5690352\ttotal: 66.6ms\tremaining: 2.15s\n",
      "15:\tlearn: 0.5628528\ttotal: 70.8ms\tremaining: 2.14s\n",
      "16:\tlearn: 0.5554769\ttotal: 80.3ms\tremaining: 2.28s\n",
      "17:\tlearn: 0.5472333\ttotal: 90.1ms\tremaining: 2.41s\n",
      "18:\tlearn: 0.5388906\ttotal: 99.5ms\tremaining: 2.52s\n",
      "19:\tlearn: 0.5356598\ttotal: 109ms\tremaining: 2.62s\n",
      "20:\tlearn: 0.5308378\ttotal: 119ms\tremaining: 2.7s\n",
      "21:\tlearn: 0.5249889\ttotal: 128ms\tremaining: 2.78s\n",
      "22:\tlearn: 0.5202711\ttotal: 137ms\tremaining: 2.85s\n",
      "23:\tlearn: 0.5150311\ttotal: 147ms\tremaining: 2.92s\n",
      "24:\tlearn: 0.5109074\ttotal: 157ms\tremaining: 2.97s\n",
      "25:\tlearn: 0.5068274\ttotal: 163ms\tremaining: 2.98s\n",
      "26:\tlearn: 0.5041250\ttotal: 170ms\tremaining: 2.97s\n",
      "27:\tlearn: 0.5012291\ttotal: 176ms\tremaining: 2.96s\n",
      "28:\tlearn: 0.4976198\ttotal: 182ms\tremaining: 2.96s\n",
      "29:\tlearn: 0.4916390\ttotal: 188ms\tremaining: 2.95s\n",
      "30:\tlearn: 0.4846138\ttotal: 193ms\tremaining: 2.92s\n",
      "31:\tlearn: 0.4801668\ttotal: 198ms\tremaining: 2.9s\n",
      "32:\tlearn: 0.4769635\ttotal: 203ms\tremaining: 2.87s\n",
      "33:\tlearn: 0.4715302\ttotal: 207ms\tremaining: 2.84s\n",
      "34:\tlearn: 0.4681150\ttotal: 213ms\tremaining: 2.82s\n",
      "35:\tlearn: 0.4644415\ttotal: 217ms\tremaining: 2.79s\n",
      "36:\tlearn: 0.4605815\ttotal: 222ms\tremaining: 2.77s\n",
      "37:\tlearn: 0.4563982\ttotal: 227ms\tremaining: 2.75s\n",
      "38:\tlearn: 0.4523866\ttotal: 231ms\tremaining: 2.73s\n",
      "39:\tlearn: 0.4493889\ttotal: 235ms\tremaining: 2.7s\n",
      "40:\tlearn: 0.4449483\ttotal: 242ms\tremaining: 2.71s\n",
      "41:\tlearn: 0.4414667\ttotal: 252ms\tremaining: 2.75s\n",
      "42:\tlearn: 0.4384330\ttotal: 261ms\tremaining: 2.78s\n",
      "43:\tlearn: 0.4340507\ttotal: 271ms\tremaining: 2.81s\n",
      "44:\tlearn: 0.4317613\ttotal: 281ms\tremaining: 2.84s\n",
      "45:\tlearn: 0.4292141\ttotal: 290ms\tremaining: 2.87s\n",
      "46:\tlearn: 0.4263764\ttotal: 300ms\tremaining: 2.89s\n",
      "47:\tlearn: 0.4232499\ttotal: 310ms\tremaining: 2.92s\n",
      "48:\tlearn: 0.4208582\ttotal: 319ms\tremaining: 2.94s\n",
      "49:\tlearn: 0.4189340\ttotal: 329ms\tremaining: 2.96s\n",
      "50:\tlearn: 0.4163285\ttotal: 336ms\tremaining: 2.96s\n",
      "51:\tlearn: 0.4127766\ttotal: 342ms\tremaining: 2.94s\n",
      "52:\tlearn: 0.4100508\ttotal: 348ms\tremaining: 2.94s\n",
      "53:\tlearn: 0.4072023\ttotal: 354ms\tremaining: 2.93s\n",
      "54:\tlearn: 0.4048055\ttotal: 360ms\tremaining: 2.91s\n",
      "55:\tlearn: 0.4023285\ttotal: 365ms\tremaining: 2.89s\n",
      "56:\tlearn: 0.3989684\ttotal: 369ms\tremaining: 2.87s\n",
      "57:\tlearn: 0.3968908\ttotal: 374ms\tremaining: 2.85s\n",
      "58:\tlearn: 0.3943784\ttotal: 378ms\tremaining: 2.83s\n",
      "59:\tlearn: 0.3911840\ttotal: 383ms\tremaining: 2.81s\n",
      "60:\tlearn: 0.3889361\ttotal: 388ms\tremaining: 2.79s\n",
      "61:\tlearn: 0.3851664\ttotal: 392ms\tremaining: 2.77s\n",
      "62:\tlearn: 0.3831408\ttotal: 396ms\tremaining: 2.74s\n",
      "63:\tlearn: 0.3799236\ttotal: 399ms\tremaining: 2.72s\n",
      "64:\tlearn: 0.3769830\ttotal: 404ms\tremaining: 2.7s\n",
      "65:\tlearn: 0.3749945\ttotal: 408ms\tremaining: 2.68s\n",
      "66:\tlearn: 0.3728903\ttotal: 418ms\tremaining: 2.7s\n",
      "67:\tlearn: 0.3702791\ttotal: 428ms\tremaining: 2.72s\n",
      "68:\tlearn: 0.3682920\ttotal: 437ms\tremaining: 2.73s\n",
      "69:\tlearn: 0.3658802\ttotal: 447ms\tremaining: 2.75s\n",
      "70:\tlearn: 0.3638545\ttotal: 457ms\tremaining: 2.76s\n",
      "71:\tlearn: 0.3612001\ttotal: 467ms\tremaining: 2.77s\n",
      "72:\tlearn: 0.3567918\ttotal: 476ms\tremaining: 2.79s\n",
      "73:\tlearn: 0.3541560\ttotal: 486ms\tremaining: 2.79s\n",
      "74:\tlearn: 0.3516810\ttotal: 495ms\tremaining: 2.81s\n",
      "75:\tlearn: 0.3493623\ttotal: 502ms\tremaining: 2.8s\n",
      "76:\tlearn: 0.3472381\ttotal: 508ms\tremaining: 2.79s\n",
      "77:\tlearn: 0.3450483\ttotal: 514ms\tremaining: 2.78s\n",
      "78:\tlearn: 0.3427241\ttotal: 520ms\tremaining: 2.77s\n",
      "79:\tlearn: 0.3404900\ttotal: 526ms\tremaining: 2.76s\n",
      "80:\tlearn: 0.3384691\ttotal: 531ms\tremaining: 2.75s\n",
      "81:\tlearn: 0.3369916\ttotal: 536ms\tremaining: 2.73s\n",
      "82:\tlearn: 0.3347395\ttotal: 540ms\tremaining: 2.71s\n",
      "83:\tlearn: 0.3321073\ttotal: 545ms\tremaining: 2.7s\n",
      "84:\tlearn: 0.3298157\ttotal: 549ms\tremaining: 2.68s\n",
      "85:\tlearn: 0.3278645\ttotal: 554ms\tremaining: 2.67s\n",
      "86:\tlearn: 0.3248362\ttotal: 558ms\tremaining: 2.65s\n",
      "87:\tlearn: 0.3223193\ttotal: 563ms\tremaining: 2.63s\n",
      "88:\tlearn: 0.3208674\ttotal: 567ms\tremaining: 2.62s\n",
      "89:\tlearn: 0.3186009\ttotal: 571ms\tremaining: 2.6s\n",
      "90:\tlearn: 0.3147476\ttotal: 576ms\tremaining: 2.59s\n",
      "91:\tlearn: 0.3111726\ttotal: 580ms\tremaining: 2.57s\n",
      "92:\tlearn: 0.3091184\ttotal: 584ms\tremaining: 2.56s\n",
      "93:\tlearn: 0.3066716\ttotal: 594ms\tremaining: 2.56s\n",
      "94:\tlearn: 0.3048599\ttotal: 603ms\tremaining: 2.57s\n",
      "95:\tlearn: 0.3031265\ttotal: 613ms\tremaining: 2.58s\n",
      "96:\tlearn: 0.2996324\ttotal: 623ms\tremaining: 2.59s\n",
      "97:\tlearn: 0.2975830\ttotal: 632ms\tremaining: 2.59s\n",
      "98:\tlearn: 0.2953897\ttotal: 642ms\tremaining: 2.6s\n",
      "99:\tlearn: 0.2918415\ttotal: 652ms\tremaining: 2.61s\n",
      "100:\tlearn: 0.2899684\ttotal: 662ms\tremaining: 2.61s\n",
      "101:\tlearn: 0.2879125\ttotal: 670ms\tremaining: 2.62s\n",
      "102:\tlearn: 0.2864409\ttotal: 677ms\tremaining: 2.61s\n",
      "103:\tlearn: 0.2824731\ttotal: 683ms\tremaining: 2.6s\n",
      "104:\tlearn: 0.2807977\ttotal: 689ms\tremaining: 2.59s\n",
      "105:\tlearn: 0.2792123\ttotal: 695ms\tremaining: 2.58s\n",
      "106:\tlearn: 0.2773516\ttotal: 701ms\tremaining: 2.57s\n",
      "107:\tlearn: 0.2758211\ttotal: 705ms\tremaining: 2.56s\n",
      "108:\tlearn: 0.2718577\ttotal: 710ms\tremaining: 2.54s\n",
      "109:\tlearn: 0.2689974\ttotal: 714ms\tremaining: 2.53s\n",
      "110:\tlearn: 0.2674449\ttotal: 719ms\tremaining: 2.52s\n",
      "111:\tlearn: 0.2642124\ttotal: 724ms\tremaining: 2.51s\n",
      "112:\tlearn: 0.2618133\ttotal: 729ms\tremaining: 2.5s\n",
      "113:\tlearn: 0.2596681\ttotal: 733ms\tremaining: 2.48s\n",
      "114:\tlearn: 0.2580885\ttotal: 737ms\tremaining: 2.47s\n",
      "115:\tlearn: 0.2548584\ttotal: 742ms\tremaining: 2.45s\n",
      "116:\tlearn: 0.2534451\ttotal: 747ms\tremaining: 2.44s\n",
      "117:\tlearn: 0.2519935\ttotal: 750ms\tremaining: 2.43s\n",
      "118:\tlearn: 0.2505215\ttotal: 760ms\tremaining: 2.43s\n",
      "119:\tlearn: 0.2491585\ttotal: 770ms\tremaining: 2.44s\n",
      "120:\tlearn: 0.2448043\ttotal: 780ms\tremaining: 2.44s\n",
      "121:\tlearn: 0.2419678\ttotal: 789ms\tremaining: 2.44s\n",
      "122:\tlearn: 0.2397247\ttotal: 799ms\tremaining: 2.45s\n",
      "123:\tlearn: 0.2383348\ttotal: 808ms\tremaining: 2.45s\n",
      "124:\tlearn: 0.2368922\ttotal: 819ms\tremaining: 2.46s\n",
      "125:\tlearn: 0.2353798\ttotal: 828ms\tremaining: 2.46s\n",
      "126:\tlearn: 0.2336234\ttotal: 838ms\tremaining: 2.46s\n",
      "127:\tlearn: 0.2319314\ttotal: 851ms\tremaining: 2.47s\n",
      "128:\tlearn: 0.2305911\ttotal: 857ms\tremaining: 2.46s\n",
      "129:\tlearn: 0.2292602\ttotal: 865ms\tremaining: 2.46s\n",
      "130:\tlearn: 0.2280142\ttotal: 870ms\tremaining: 2.45s\n",
      "131:\tlearn: 0.2267398\ttotal: 875ms\tremaining: 2.44s\n",
      "132:\tlearn: 0.2253835\ttotal: 879ms\tremaining: 2.43s\n",
      "133:\tlearn: 0.2240991\ttotal: 884ms\tremaining: 2.41s\n",
      "134:\tlearn: 0.2227349\ttotal: 889ms\tremaining: 2.4s\n",
      "135:\tlearn: 0.2214699\ttotal: 894ms\tremaining: 2.39s\n",
      "136:\tlearn: 0.2199962\ttotal: 898ms\tremaining: 2.38s\n",
      "137:\tlearn: 0.2176371\ttotal: 903ms\tremaining: 2.37s\n",
      "138:\tlearn: 0.2161992\ttotal: 907ms\tremaining: 2.36s\n",
      "139:\tlearn: 0.2148709\ttotal: 912ms\tremaining: 2.35s\n",
      "140:\tlearn: 0.2134382\ttotal: 918ms\tremaining: 2.34s\n",
      "141:\tlearn: 0.2123910\ttotal: 923ms\tremaining: 2.33s\n",
      "142:\tlearn: 0.2113742\ttotal: 928ms\tremaining: 2.32s\n",
      "143:\tlearn: 0.2101852\ttotal: 933ms\tremaining: 2.31s\n",
      "144:\tlearn: 0.2088646\ttotal: 946ms\tremaining: 2.31s\n",
      "145:\tlearn: 0.2078231\ttotal: 955ms\tremaining: 2.32s\n",
      "146:\tlearn: 0.2065356\ttotal: 965ms\tremaining: 2.32s\n",
      "147:\tlearn: 0.2055040\ttotal: 975ms\tremaining: 2.32s\n",
      "148:\tlearn: 0.2038561\ttotal: 986ms\tremaining: 2.32s\n",
      "149:\tlearn: 0.2022510\ttotal: 996ms\tremaining: 2.32s\n",
      "150:\tlearn: 0.2009328\ttotal: 1s\tremaining: 2.32s\n",
      "151:\tlearn: 0.1997278\ttotal: 1.01s\tremaining: 2.33s\n",
      "152:\tlearn: 0.1984263\ttotal: 1.02s\tremaining: 2.32s\n",
      "153:\tlearn: 0.1966825\ttotal: 1.03s\tremaining: 2.31s\n",
      "154:\tlearn: 0.1941539\ttotal: 1.03s\tremaining: 2.3s\n",
      "155:\tlearn: 0.1930584\ttotal: 1.04s\tremaining: 2.29s\n",
      "156:\tlearn: 0.1918948\ttotal: 1.05s\tremaining: 2.29s\n",
      "157:\tlearn: 0.1908104\ttotal: 1.05s\tremaining: 2.27s\n",
      "158:\tlearn: 0.1897185\ttotal: 1.05s\tremaining: 2.26s\n",
      "159:\tlearn: 0.1884721\ttotal: 1.06s\tremaining: 2.25s\n",
      "160:\tlearn: 0.1860786\ttotal: 1.06s\tremaining: 2.24s\n",
      "161:\tlearn: 0.1851827\ttotal: 1.07s\tremaining: 2.23s\n",
      "162:\tlearn: 0.1840866\ttotal: 1.07s\tremaining: 2.22s\n",
      "163:\tlearn: 0.1830644\ttotal: 1.08s\tremaining: 2.21s\n",
      "164:\tlearn: 0.1819203\ttotal: 1.08s\tremaining: 2.2s\n",
      "165:\tlearn: 0.1809577\ttotal: 1.09s\tremaining: 2.19s\n",
      "166:\tlearn: 0.1799297\ttotal: 1.09s\tremaining: 2.18s\n",
      "167:\tlearn: 0.1787276\ttotal: 1.1s\tremaining: 2.17s\n",
      "168:\tlearn: 0.1776835\ttotal: 1.1s\tremaining: 2.15s\n",
      "169:\tlearn: 0.1767219\ttotal: 1.1s\tremaining: 2.14s\n",
      "170:\tlearn: 0.1754733\ttotal: 1.11s\tremaining: 2.14s\n",
      "171:\tlearn: 0.1732183\ttotal: 1.12s\tremaining: 2.14s\n",
      "172:\tlearn: 0.1724233\ttotal: 1.13s\tremaining: 2.14s\n",
      "173:\tlearn: 0.1714259\ttotal: 1.14s\tremaining: 2.14s\n",
      "174:\tlearn: 0.1703398\ttotal: 1.15s\tremaining: 2.14s\n",
      "175:\tlearn: 0.1694871\ttotal: 1.16s\tremaining: 2.14s\n",
      "176:\tlearn: 0.1675959\ttotal: 1.17s\tremaining: 2.14s\n",
      "177:\tlearn: 0.1666240\ttotal: 1.18s\tremaining: 2.14s\n",
      "178:\tlearn: 0.1652506\ttotal: 1.19s\tremaining: 2.13s\n",
      "179:\tlearn: 0.1645418\ttotal: 1.19s\tremaining: 2.12s\n",
      "180:\tlearn: 0.1634141\ttotal: 1.2s\tremaining: 2.12s\n",
      "181:\tlearn: 0.1625712\ttotal: 1.21s\tremaining: 2.11s\n",
      "182:\tlearn: 0.1616608\ttotal: 1.21s\tremaining: 2.1s\n",
      "183:\tlearn: 0.1605337\ttotal: 1.21s\tremaining: 2.09s\n",
      "184:\tlearn: 0.1596638\ttotal: 1.22s\tremaining: 2.08s\n",
      "185:\tlearn: 0.1588373\ttotal: 1.22s\tremaining: 2.07s\n",
      "186:\tlearn: 0.1581347\ttotal: 1.23s\tremaining: 2.06s\n",
      "187:\tlearn: 0.1572590\ttotal: 1.23s\tremaining: 2.05s\n",
      "188:\tlearn: 0.1564739\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.1555308\ttotal: 1.24s\tremaining: 2.03s\n",
      "190:\tlearn: 0.1545366\ttotal: 1.25s\tremaining: 2.02s\n",
      "191:\tlearn: 0.1537924\ttotal: 1.25s\tremaining: 2.01s\n",
      "192:\tlearn: 0.1529132\ttotal: 1.25s\tremaining: 2s\n",
      "193:\tlearn: 0.1521428\ttotal: 1.26s\tremaining: 1.99s\n",
      "194:\tlearn: 0.1513042\ttotal: 1.26s\tremaining: 1.97s\n",
      "195:\tlearn: 0.1503885\ttotal: 1.27s\tremaining: 1.97s\n",
      "196:\tlearn: 0.1494714\ttotal: 1.28s\tremaining: 1.97s\n",
      "197:\tlearn: 0.1487888\ttotal: 1.29s\tremaining: 1.97s\n",
      "198:\tlearn: 0.1476555\ttotal: 1.3s\tremaining: 1.97s\n",
      "199:\tlearn: 0.1465963\ttotal: 1.31s\tremaining: 1.97s\n",
      "200:\tlearn: 0.1458384\ttotal: 1.32s\tremaining: 1.96s\n",
      "201:\tlearn: 0.1450710\ttotal: 1.33s\tremaining: 1.96s\n",
      "202:\tlearn: 0.1442340\ttotal: 1.34s\tremaining: 1.96s\n",
      "203:\tlearn: 0.1434647\ttotal: 1.34s\tremaining: 1.95s\n",
      "204:\tlearn: 0.1427393\ttotal: 1.35s\tremaining: 1.94s\n",
      "205:\tlearn: 0.1420307\ttotal: 1.35s\tremaining: 1.93s\n",
      "206:\tlearn: 0.1413095\ttotal: 1.36s\tremaining: 1.92s\n",
      "207:\tlearn: 0.1407233\ttotal: 1.36s\tremaining: 1.91s\n",
      "208:\tlearn: 0.1396927\ttotal: 1.37s\tremaining: 1.91s\n",
      "209:\tlearn: 0.1389703\ttotal: 1.37s\tremaining: 1.9s\n",
      "210:\tlearn: 0.1382689\ttotal: 1.38s\tremaining: 1.89s\n",
      "211:\tlearn: 0.1368790\ttotal: 1.38s\tremaining: 1.88s\n",
      "212:\tlearn: 0.1360878\ttotal: 1.39s\tremaining: 1.87s\n",
      "213:\tlearn: 0.1354450\ttotal: 1.39s\tremaining: 1.86s\n",
      "214:\tlearn: 0.1337801\ttotal: 1.4s\tremaining: 1.85s\n",
      "215:\tlearn: 0.1331824\ttotal: 1.4s\tremaining: 1.84s\n",
      "216:\tlearn: 0.1325288\ttotal: 1.4s\tremaining: 1.83s\n",
      "217:\tlearn: 0.1317486\ttotal: 1.41s\tremaining: 1.82s\n",
      "218:\tlearn: 0.1310243\ttotal: 1.41s\tremaining: 1.81s\n",
      "219:\tlearn: 0.1304364\ttotal: 1.42s\tremaining: 1.81s\n",
      "220:\tlearn: 0.1297240\ttotal: 1.43s\tremaining: 1.81s\n",
      "221:\tlearn: 0.1287935\ttotal: 1.44s\tremaining: 1.8s\n",
      "222:\tlearn: 0.1281972\ttotal: 1.45s\tremaining: 1.8s\n",
      "223:\tlearn: 0.1276309\ttotal: 1.46s\tremaining: 1.8s\n",
      "224:\tlearn: 0.1269046\ttotal: 1.47s\tremaining: 1.8s\n",
      "225:\tlearn: 0.1263663\ttotal: 1.48s\tremaining: 1.79s\n",
      "226:\tlearn: 0.1258385\ttotal: 1.49s\tremaining: 1.79s\n",
      "227:\tlearn: 0.1251699\ttotal: 1.5s\tremaining: 1.78s\n",
      "228:\tlearn: 0.1241652\ttotal: 1.5s\tremaining: 1.78s\n",
      "229:\tlearn: 0.1235724\ttotal: 1.51s\tremaining: 1.77s\n",
      "230:\tlearn: 0.1229279\ttotal: 1.52s\tremaining: 1.76s\n",
      "231:\tlearn: 0.1224085\ttotal: 1.52s\tremaining: 1.76s\n",
      "232:\tlearn: 0.1219104\ttotal: 1.53s\tremaining: 1.75s\n",
      "233:\tlearn: 0.1213859\ttotal: 1.53s\tremaining: 1.74s\n",
      "234:\tlearn: 0.1206562\ttotal: 1.54s\tremaining: 1.73s\n",
      "235:\tlearn: 0.1199879\ttotal: 1.54s\tremaining: 1.72s\n",
      "236:\tlearn: 0.1193309\ttotal: 1.55s\tremaining: 1.72s\n",
      "237:\tlearn: 0.1185003\ttotal: 1.55s\tremaining: 1.71s\n",
      "238:\tlearn: 0.1178430\ttotal: 1.56s\tremaining: 1.7s\n",
      "239:\tlearn: 0.1172887\ttotal: 1.56s\tremaining: 1.69s\n",
      "240:\tlearn: 0.1168443\ttotal: 1.57s\tremaining: 1.68s\n",
      "241:\tlearn: 0.1163270\ttotal: 1.57s\tremaining: 1.68s\n",
      "242:\tlearn: 0.1158475\ttotal: 1.57s\tremaining: 1.67s\n",
      "243:\tlearn: 0.1151204\ttotal: 1.58s\tremaining: 1.66s\n",
      "244:\tlearn: 0.1145692\ttotal: 1.58s\tremaining: 1.65s\n",
      "245:\tlearn: 0.1139939\ttotal: 1.59s\tremaining: 1.64s\n",
      "246:\tlearn: 0.1134033\ttotal: 1.59s\tremaining: 1.63s\n",
      "247:\tlearn: 0.1127950\ttotal: 1.6s\tremaining: 1.62s\n",
      "248:\tlearn: 0.1122393\ttotal: 1.6s\tremaining: 1.61s\n",
      "249:\tlearn: 0.1113155\ttotal: 1.6s\tremaining: 1.6s\n",
      "250:\tlearn: 0.1108393\ttotal: 1.61s\tremaining: 1.6s\n",
      "251:\tlearn: 0.1101814\ttotal: 1.63s\tremaining: 1.6s\n",
      "252:\tlearn: 0.1095490\ttotal: 1.64s\tremaining: 1.6s\n",
      "253:\tlearn: 0.1090228\ttotal: 1.64s\tremaining: 1.59s\n",
      "254:\tlearn: 0.1085255\ttotal: 1.65s\tremaining: 1.59s\n",
      "255:\tlearn: 0.1079670\ttotal: 1.66s\tremaining: 1.59s\n",
      "256:\tlearn: 0.1071977\ttotal: 1.67s\tremaining: 1.58s\n",
      "257:\tlearn: 0.1068645\ttotal: 1.68s\tremaining: 1.58s\n",
      "258:\tlearn: 0.1063926\ttotal: 1.69s\tremaining: 1.57s\n",
      "259:\tlearn: 0.1060821\ttotal: 1.7s\tremaining: 1.56s\n",
      "260:\tlearn: 0.1055532\ttotal: 1.7s\tremaining: 1.56s\n",
      "261:\tlearn: 0.1047877\ttotal: 1.71s\tremaining: 1.55s\n",
      "262:\tlearn: 0.1043367\ttotal: 1.71s\tremaining: 1.54s\n",
      "263:\tlearn: 0.1038801\ttotal: 1.72s\tremaining: 1.53s\n",
      "264:\tlearn: 0.1034644\ttotal: 1.72s\tremaining: 1.53s\n",
      "265:\tlearn: 0.1029589\ttotal: 1.73s\tremaining: 1.52s\n",
      "266:\tlearn: 0.1024438\ttotal: 1.73s\tremaining: 1.51s\n",
      "267:\tlearn: 0.1017408\ttotal: 1.74s\tremaining: 1.5s\n",
      "268:\tlearn: 0.1011823\ttotal: 1.74s\tremaining: 1.49s\n",
      "269:\tlearn: 0.1004200\ttotal: 1.75s\tremaining: 1.49s\n",
      "270:\tlearn: 0.1000148\ttotal: 1.75s\tremaining: 1.48s\n",
      "271:\tlearn: 0.0995197\ttotal: 1.75s\tremaining: 1.47s\n",
      "272:\tlearn: 0.0990199\ttotal: 1.76s\tremaining: 1.46s\n",
      "273:\tlearn: 0.0986110\ttotal: 1.76s\tremaining: 1.45s\n",
      "274:\tlearn: 0.0981329\ttotal: 1.77s\tremaining: 1.45s\n",
      "275:\tlearn: 0.0977923\ttotal: 1.77s\tremaining: 1.44s\n",
      "276:\tlearn: 0.0972906\ttotal: 1.78s\tremaining: 1.43s\n",
      "277:\tlearn: 0.0968275\ttotal: 1.78s\tremaining: 1.43s\n",
      "278:\tlearn: 0.0963572\ttotal: 1.79s\tremaining: 1.42s\n",
      "279:\tlearn: 0.0959069\ttotal: 1.8s\tremaining: 1.42s\n",
      "280:\tlearn: 0.0954749\ttotal: 1.81s\tremaining: 1.41s\n",
      "281:\tlearn: 0.0951036\ttotal: 1.82s\tremaining: 1.41s\n",
      "282:\tlearn: 0.0944975\ttotal: 1.83s\tremaining: 1.41s\n",
      "283:\tlearn: 0.0942122\ttotal: 1.84s\tremaining: 1.4s\n",
      "284:\tlearn: 0.0937485\ttotal: 1.85s\tremaining: 1.4s\n",
      "285:\tlearn: 0.0932585\ttotal: 1.86s\tremaining: 1.39s\n",
      "286:\tlearn: 0.0929111\ttotal: 1.86s\tremaining: 1.38s\n",
      "287:\tlearn: 0.0924433\ttotal: 1.87s\tremaining: 1.38s\n",
      "288:\tlearn: 0.0919442\ttotal: 1.88s\tremaining: 1.37s\n",
      "289:\tlearn: 0.0914573\ttotal: 1.89s\tremaining: 1.36s\n",
      "290:\tlearn: 0.0908626\ttotal: 1.89s\tremaining: 1.36s\n",
      "291:\tlearn: 0.0904159\ttotal: 1.89s\tremaining: 1.35s\n",
      "292:\tlearn: 0.0899616\ttotal: 1.9s\tremaining: 1.34s\n",
      "293:\tlearn: 0.0895557\ttotal: 1.9s\tremaining: 1.33s\n",
      "294:\tlearn: 0.0890716\ttotal: 1.91s\tremaining: 1.32s\n",
      "295:\tlearn: 0.0886735\ttotal: 1.91s\tremaining: 1.32s\n",
      "296:\tlearn: 0.0881845\ttotal: 1.92s\tremaining: 1.31s\n",
      "297:\tlearn: 0.0874495\ttotal: 1.92s\tremaining: 1.3s\n",
      "298:\tlearn: 0.0870562\ttotal: 1.92s\tremaining: 1.29s\n",
      "299:\tlearn: 0.0867030\ttotal: 1.93s\tremaining: 1.28s\n",
      "300:\tlearn: 0.0860219\ttotal: 1.93s\tremaining: 1.28s\n",
      "301:\tlearn: 0.0856442\ttotal: 1.94s\tremaining: 1.27s\n",
      "302:\tlearn: 0.0852150\ttotal: 1.94s\tremaining: 1.26s\n",
      "303:\tlearn: 0.0850230\ttotal: 1.95s\tremaining: 1.25s\n",
      "304:\tlearn: 0.0845801\ttotal: 1.95s\tremaining: 1.25s\n",
      "305:\tlearn: 0.0841996\ttotal: 1.96s\tremaining: 1.24s\n",
      "306:\tlearn: 0.0837639\ttotal: 1.97s\tremaining: 1.24s\n",
      "307:\tlearn: 0.0832878\ttotal: 1.98s\tremaining: 1.23s\n",
      "308:\tlearn: 0.0829589\ttotal: 1.99s\tremaining: 1.23s\n",
      "309:\tlearn: 0.0826443\ttotal: 2s\tremaining: 1.23s\n",
      "310:\tlearn: 0.0823140\ttotal: 2.01s\tremaining: 1.22s\n",
      "311:\tlearn: 0.0819603\ttotal: 2.02s\tremaining: 1.22s\n",
      "312:\tlearn: 0.0815165\ttotal: 2.03s\tremaining: 1.21s\n",
      "313:\tlearn: 0.0810253\ttotal: 2.03s\tremaining: 1.2s\n",
      "314:\tlearn: 0.0806771\ttotal: 2.04s\tremaining: 1.2s\n",
      "315:\tlearn: 0.0802961\ttotal: 2.04s\tremaining: 1.19s\n",
      "316:\tlearn: 0.0799766\ttotal: 2.05s\tremaining: 1.18s\n",
      "317:\tlearn: 0.0797138\ttotal: 2.06s\tremaining: 1.18s\n",
      "318:\tlearn: 0.0793574\ttotal: 2.06s\tremaining: 1.17s\n",
      "319:\tlearn: 0.0788399\ttotal: 2.07s\tremaining: 1.16s\n",
      "320:\tlearn: 0.0784743\ttotal: 2.07s\tremaining: 1.16s\n",
      "321:\tlearn: 0.0781446\ttotal: 2.08s\tremaining: 1.15s\n",
      "322:\tlearn: 0.0779668\ttotal: 2.08s\tremaining: 1.14s\n",
      "323:\tlearn: 0.0775466\ttotal: 2.08s\tremaining: 1.13s\n",
      "324:\tlearn: 0.0771789\ttotal: 2.09s\tremaining: 1.13s\n",
      "325:\tlearn: 0.0767410\ttotal: 2.09s\tremaining: 1.12s\n",
      "326:\tlearn: 0.0763704\ttotal: 2.1s\tremaining: 1.11s\n",
      "327:\tlearn: 0.0759178\ttotal: 2.1s\tremaining: 1.1s\n",
      "328:\tlearn: 0.0755487\ttotal: 2.11s\tremaining: 1.09s\n",
      "329:\tlearn: 0.0751386\ttotal: 2.12s\tremaining: 1.09s\n",
      "330:\tlearn: 0.0746539\ttotal: 2.13s\tremaining: 1.09s\n",
      "331:\tlearn: 0.0743109\ttotal: 2.14s\tremaining: 1.08s\n",
      "332:\tlearn: 0.0740547\ttotal: 2.15s\tremaining: 1.08s\n",
      "333:\tlearn: 0.0737498\ttotal: 2.16s\tremaining: 1.07s\n",
      "334:\tlearn: 0.0733405\ttotal: 2.17s\tremaining: 1.07s\n",
      "335:\tlearn: 0.0731473\ttotal: 2.17s\tremaining: 1.06s\n",
      "336:\tlearn: 0.0727866\ttotal: 2.19s\tremaining: 1.06s\n",
      "337:\tlearn: 0.0724367\ttotal: 2.19s\tremaining: 1.05s\n",
      "338:\tlearn: 0.0721772\ttotal: 2.2s\tremaining: 1.04s\n",
      "339:\tlearn: 0.0718777\ttotal: 2.21s\tremaining: 1.04s\n",
      "340:\tlearn: 0.0715837\ttotal: 2.21s\tremaining: 1.03s\n",
      "341:\tlearn: 0.0712848\ttotal: 2.22s\tremaining: 1.02s\n",
      "342:\tlearn: 0.0706814\ttotal: 2.22s\tremaining: 1.02s\n",
      "343:\tlearn: 0.0704205\ttotal: 2.23s\tremaining: 1.01s\n",
      "344:\tlearn: 0.0700905\ttotal: 2.23s\tremaining: 1s\n",
      "345:\tlearn: 0.0698050\ttotal: 2.24s\tremaining: 997ms\n",
      "346:\tlearn: 0.0695006\ttotal: 2.24s\tremaining: 989ms\n",
      "347:\tlearn: 0.0690528\ttotal: 2.25s\tremaining: 983ms\n",
      "348:\tlearn: 0.0687383\ttotal: 2.25s\tremaining: 975ms\n",
      "349:\tlearn: 0.0684398\ttotal: 2.25s\tremaining: 967ms\n",
      "350:\tlearn: 0.0681540\ttotal: 2.26s\tremaining: 959ms\n",
      "351:\tlearn: 0.0678609\ttotal: 2.26s\tremaining: 951ms\n",
      "352:\tlearn: 0.0675542\ttotal: 2.27s\tremaining: 944ms\n",
      "353:\tlearn: 0.0673159\ttotal: 2.27s\tremaining: 937ms\n",
      "354:\tlearn: 0.0670419\ttotal: 2.27s\tremaining: 930ms\n",
      "355:\tlearn: 0.0666836\ttotal: 2.28s\tremaining: 922ms\n",
      "356:\tlearn: 0.0663203\ttotal: 2.29s\tremaining: 917ms\n",
      "357:\tlearn: 0.0660979\ttotal: 2.3s\tremaining: 911ms\n",
      "358:\tlearn: 0.0658358\ttotal: 2.31s\tremaining: 906ms\n",
      "359:\tlearn: 0.0655221\ttotal: 2.31s\tremaining: 900ms\n",
      "360:\tlearn: 0.0651931\ttotal: 2.32s\tremaining: 895ms\n",
      "361:\tlearn: 0.0647163\ttotal: 2.33s\tremaining: 890ms\n",
      "362:\tlearn: 0.0643208\ttotal: 2.35s\tremaining: 887ms\n",
      "363:\tlearn: 0.0639400\ttotal: 2.36s\tremaining: 882ms\n",
      "364:\tlearn: 0.0635683\ttotal: 2.37s\tremaining: 876ms\n",
      "365:\tlearn: 0.0632483\ttotal: 2.38s\tremaining: 871ms\n",
      "366:\tlearn: 0.0629143\ttotal: 2.39s\tremaining: 866ms\n",
      "367:\tlearn: 0.0625055\ttotal: 2.4s\tremaining: 860ms\n",
      "368:\tlearn: 0.0622470\ttotal: 2.41s\tremaining: 855ms\n",
      "369:\tlearn: 0.0620137\ttotal: 2.42s\tremaining: 849ms\n",
      "370:\tlearn: 0.0617450\ttotal: 2.42s\tremaining: 843ms\n",
      "371:\tlearn: 0.0614525\ttotal: 2.43s\tremaining: 836ms\n",
      "372:\tlearn: 0.0611139\ttotal: 2.43s\tremaining: 829ms\n",
      "373:\tlearn: 0.0608322\ttotal: 2.44s\tremaining: 822ms\n",
      "374:\tlearn: 0.0605893\ttotal: 2.44s\tremaining: 814ms\n",
      "375:\tlearn: 0.0603036\ttotal: 2.45s\tremaining: 807ms\n",
      "376:\tlearn: 0.0600469\ttotal: 2.45s\tremaining: 800ms\n",
      "377:\tlearn: 0.0598339\ttotal: 2.46s\tremaining: 793ms\n",
      "378:\tlearn: 0.0595670\ttotal: 2.46s\tremaining: 785ms\n",
      "379:\tlearn: 0.0592872\ttotal: 2.46s\tremaining: 778ms\n",
      "380:\tlearn: 0.0590274\ttotal: 2.47s\tremaining: 771ms\n",
      "381:\tlearn: 0.0587433\ttotal: 2.47s\tremaining: 764ms\n",
      "382:\tlearn: 0.0584075\ttotal: 2.48s\tremaining: 757ms\n",
      "383:\tlearn: 0.0580631\ttotal: 2.49s\tremaining: 751ms\n",
      "384:\tlearn: 0.0577519\ttotal: 2.5s\tremaining: 746ms\n",
      "385:\tlearn: 0.0574420\ttotal: 2.51s\tremaining: 740ms\n",
      "386:\tlearn: 0.0571954\ttotal: 2.52s\tremaining: 735ms\n",
      "387:\tlearn: 0.0569732\ttotal: 2.52s\tremaining: 729ms\n",
      "388:\tlearn: 0.0566929\ttotal: 2.53s\tremaining: 723ms\n",
      "389:\tlearn: 0.0564549\ttotal: 2.54s\tremaining: 718ms\n",
      "390:\tlearn: 0.0562390\ttotal: 2.55s\tremaining: 712ms\n",
      "391:\tlearn: 0.0559819\ttotal: 2.57s\tremaining: 707ms\n",
      "392:\tlearn: 0.0556735\ttotal: 2.57s\tremaining: 700ms\n",
      "393:\tlearn: 0.0553888\ttotal: 2.58s\tremaining: 693ms\n",
      "394:\tlearn: 0.0550946\ttotal: 2.58s\tremaining: 686ms\n",
      "395:\tlearn: 0.0548740\ttotal: 2.58s\tremaining: 679ms\n",
      "396:\tlearn: 0.0544501\ttotal: 2.59s\tremaining: 672ms\n",
      "397:\tlearn: 0.0542320\ttotal: 2.6s\tremaining: 665ms\n",
      "398:\tlearn: 0.0540088\ttotal: 2.6s\tremaining: 659ms\n",
      "399:\tlearn: 0.0537475\ttotal: 2.61s\tremaining: 654ms\n",
      "400:\tlearn: 0.0535956\ttotal: 2.62s\tremaining: 648ms\n",
      "401:\tlearn: 0.0533270\ttotal: 2.63s\tremaining: 642ms\n",
      "402:\tlearn: 0.0531801\ttotal: 2.64s\tremaining: 636ms\n",
      "403:\tlearn: 0.0530118\ttotal: 2.65s\tremaining: 631ms\n",
      "404:\tlearn: 0.0527005\ttotal: 2.66s\tremaining: 624ms\n",
      "405:\tlearn: 0.0524742\ttotal: 2.67s\tremaining: 617ms\n",
      "406:\tlearn: 0.0522789\ttotal: 2.67s\tremaining: 611ms\n",
      "407:\tlearn: 0.0520299\ttotal: 2.68s\tremaining: 604ms\n",
      "408:\tlearn: 0.0517530\ttotal: 2.68s\tremaining: 597ms\n",
      "409:\tlearn: 0.0513674\ttotal: 2.69s\tremaining: 591ms\n",
      "410:\tlearn: 0.0511812\ttotal: 2.7s\tremaining: 584ms\n",
      "411:\tlearn: 0.0509135\ttotal: 2.7s\tremaining: 577ms\n",
      "412:\tlearn: 0.0507409\ttotal: 2.71s\tremaining: 571ms\n",
      "413:\tlearn: 0.0505039\ttotal: 2.72s\tremaining: 564ms\n",
      "414:\tlearn: 0.0503585\ttotal: 2.72s\tremaining: 558ms\n",
      "415:\tlearn: 0.0501676\ttotal: 2.73s\tremaining: 551ms\n",
      "416:\tlearn: 0.0500126\ttotal: 2.73s\tremaining: 544ms\n",
      "417:\tlearn: 0.0495786\ttotal: 2.74s\tremaining: 537ms\n",
      "418:\tlearn: 0.0493658\ttotal: 2.74s\tremaining: 530ms\n",
      "419:\tlearn: 0.0491437\ttotal: 2.75s\tremaining: 524ms\n",
      "420:\tlearn: 0.0489328\ttotal: 2.75s\tremaining: 517ms\n",
      "421:\tlearn: 0.0485199\ttotal: 2.76s\tremaining: 510ms\n",
      "422:\tlearn: 0.0483461\ttotal: 2.76s\tremaining: 503ms\n",
      "423:\tlearn: 0.0481444\ttotal: 2.77s\tremaining: 496ms\n",
      "424:\tlearn: 0.0479862\ttotal: 2.77s\tremaining: 489ms\n",
      "425:\tlearn: 0.0478021\ttotal: 2.77s\tremaining: 482ms\n",
      "426:\tlearn: 0.0475637\ttotal: 2.78s\tremaining: 475ms\n",
      "427:\tlearn: 0.0473313\ttotal: 2.78s\tremaining: 468ms\n",
      "428:\tlearn: 0.0472132\ttotal: 2.79s\tremaining: 461ms\n",
      "429:\tlearn: 0.0469112\ttotal: 2.8s\tremaining: 455ms\n",
      "430:\tlearn: 0.0466200\ttotal: 2.81s\tremaining: 450ms\n",
      "431:\tlearn: 0.0464101\ttotal: 2.82s\tremaining: 443ms\n",
      "432:\tlearn: 0.0461189\ttotal: 2.83s\tremaining: 437ms\n",
      "433:\tlearn: 0.0459141\ttotal: 2.84s\tremaining: 431ms\n",
      "434:\tlearn: 0.0457133\ttotal: 2.85s\tremaining: 425ms\n",
      "435:\tlearn: 0.0455030\ttotal: 2.86s\tremaining: 419ms\n",
      "436:\tlearn: 0.0452908\ttotal: 2.87s\tremaining: 413ms\n",
      "437:\tlearn: 0.0451158\ttotal: 2.88s\tremaining: 407ms\n",
      "438:\tlearn: 0.0449825\ttotal: 2.88s\tremaining: 401ms\n",
      "439:\tlearn: 0.0447480\ttotal: 2.89s\tremaining: 394ms\n",
      "440:\tlearn: 0.0445170\ttotal: 2.9s\tremaining: 388ms\n",
      "441:\tlearn: 0.0443478\ttotal: 2.9s\tremaining: 381ms\n",
      "442:\tlearn: 0.0441213\ttotal: 2.91s\tremaining: 374ms\n",
      "443:\tlearn: 0.0438931\ttotal: 2.91s\tremaining: 367ms\n",
      "444:\tlearn: 0.0437178\ttotal: 2.92s\tremaining: 361ms\n",
      "445:\tlearn: 0.0434475\ttotal: 2.92s\tremaining: 354ms\n",
      "446:\tlearn: 0.0432908\ttotal: 2.93s\tremaining: 347ms\n",
      "447:\tlearn: 0.0430912\ttotal: 2.93s\tremaining: 340ms\n",
      "448:\tlearn: 0.0428653\ttotal: 2.94s\tremaining: 333ms\n",
      "449:\tlearn: 0.0426658\ttotal: 2.94s\tremaining: 327ms\n",
      "450:\tlearn: 0.0425083\ttotal: 2.94s\tremaining: 320ms\n",
      "451:\tlearn: 0.0423048\ttotal: 2.95s\tremaining: 313ms\n",
      "452:\tlearn: 0.0421660\ttotal: 2.95s\tremaining: 306ms\n",
      "453:\tlearn: 0.0418632\ttotal: 2.96s\tremaining: 300ms\n",
      "454:\tlearn: 0.0417038\ttotal: 2.97s\tremaining: 293ms\n",
      "455:\tlearn: 0.0414969\ttotal: 2.98s\tremaining: 287ms\n",
      "456:\tlearn: 0.0413669\ttotal: 2.98s\tremaining: 281ms\n",
      "457:\tlearn: 0.0411232\ttotal: 3s\tremaining: 275ms\n",
      "458:\tlearn: 0.0409664\ttotal: 3s\tremaining: 268ms\n",
      "459:\tlearn: 0.0407425\ttotal: 3.01s\tremaining: 262ms\n",
      "460:\tlearn: 0.0404903\ttotal: 3.02s\tremaining: 256ms\n",
      "461:\tlearn: 0.0403482\ttotal: 3.03s\tremaining: 250ms\n",
      "462:\tlearn: 0.0401751\ttotal: 3.04s\tremaining: 243ms\n",
      "463:\tlearn: 0.0399210\ttotal: 3.05s\tremaining: 236ms\n",
      "464:\tlearn: 0.0396878\ttotal: 3.05s\tremaining: 230ms\n",
      "465:\tlearn: 0.0394638\ttotal: 3.06s\tremaining: 223ms\n",
      "466:\tlearn: 0.0392860\ttotal: 3.07s\tremaining: 217ms\n",
      "467:\tlearn: 0.0391532\ttotal: 3.07s\tremaining: 210ms\n",
      "468:\tlearn: 0.0388623\ttotal: 3.08s\tremaining: 203ms\n",
      "469:\tlearn: 0.0386310\ttotal: 3.08s\tremaining: 197ms\n",
      "470:\tlearn: 0.0386170\ttotal: 3.08s\tremaining: 190ms\n",
      "471:\tlearn: 0.0384740\ttotal: 3.09s\tremaining: 183ms\n",
      "472:\tlearn: 0.0382035\ttotal: 3.1s\tremaining: 177ms\n",
      "473:\tlearn: 0.0380364\ttotal: 3.1s\tremaining: 170ms\n",
      "474:\tlearn: 0.0378949\ttotal: 3.1s\tremaining: 163ms\n",
      "475:\tlearn: 0.0377509\ttotal: 3.11s\tremaining: 157ms\n",
      "476:\tlearn: 0.0375755\ttotal: 3.11s\tremaining: 150ms\n",
      "477:\tlearn: 0.0373363\ttotal: 3.12s\tremaining: 143ms\n",
      "478:\tlearn: 0.0371557\ttotal: 3.12s\tremaining: 137ms\n",
      "479:\tlearn: 0.0369970\ttotal: 3.13s\tremaining: 130ms\n",
      "480:\tlearn: 0.0368582\ttotal: 3.13s\tremaining: 124ms\n",
      "481:\tlearn: 0.0367113\ttotal: 3.14s\tremaining: 117ms\n",
      "482:\tlearn: 0.0365333\ttotal: 3.15s\tremaining: 111ms\n",
      "483:\tlearn: 0.0364292\ttotal: 3.16s\tremaining: 104ms\n",
      "484:\tlearn: 0.0362614\ttotal: 3.17s\tremaining: 98ms\n",
      "485:\tlearn: 0.0360689\ttotal: 3.18s\tremaining: 91.6ms\n",
      "486:\tlearn: 0.0359421\ttotal: 3.19s\tremaining: 85.1ms\n",
      "487:\tlearn: 0.0357476\ttotal: 3.2s\tremaining: 78.6ms\n",
      "488:\tlearn: 0.0355679\ttotal: 3.21s\tremaining: 72.2ms\n",
      "489:\tlearn: 0.0354410\ttotal: 3.22s\tremaining: 65.7ms\n",
      "490:\tlearn: 0.0352174\ttotal: 3.22s\tremaining: 59.1ms\n",
      "491:\tlearn: 0.0350441\ttotal: 3.23s\tremaining: 52.5ms\n",
      "492:\tlearn: 0.0348941\ttotal: 3.24s\tremaining: 46ms\n",
      "493:\tlearn: 0.0347285\ttotal: 3.24s\tremaining: 39.4ms\n",
      "494:\tlearn: 0.0344826\ttotal: 3.25s\tremaining: 32.8ms\n",
      "495:\tlearn: 0.0343101\ttotal: 3.25s\tremaining: 26.2ms\n",
      "496:\tlearn: 0.0341842\ttotal: 3.26s\tremaining: 19.7ms\n",
      "497:\tlearn: 0.0340983\ttotal: 3.26s\tremaining: 13.1ms\n",
      "498:\tlearn: 0.0339208\ttotal: 3.27s\tremaining: 6.54ms\n",
      "499:\tlearn: 0.0337447\ttotal: 3.27s\tremaining: 0us\n",
      "0:\tlearn: 0.6820607\ttotal: 6.53ms\tremaining: 3.26s\n",
      "1:\tlearn: 0.6711683\ttotal: 11.4ms\tremaining: 2.85s\n",
      "2:\tlearn: 0.6604415\ttotal: 16ms\tremaining: 2.65s\n",
      "3:\tlearn: 0.6501429\ttotal: 20.7ms\tremaining: 2.57s\n",
      "4:\tlearn: 0.6414586\ttotal: 25.5ms\tremaining: 2.53s\n",
      "5:\tlearn: 0.6327213\ttotal: 30.1ms\tremaining: 2.48s\n",
      "6:\tlearn: 0.6236137\ttotal: 34.9ms\tremaining: 2.46s\n",
      "7:\tlearn: 0.6148512\ttotal: 39.4ms\tremaining: 2.42s\n",
      "8:\tlearn: 0.6075868\ttotal: 43.6ms\tremaining: 2.38s\n",
      "9:\tlearn: 0.5986712\ttotal: 48ms\tremaining: 2.35s\n",
      "10:\tlearn: 0.5904850\ttotal: 52.3ms\tremaining: 2.32s\n",
      "11:\tlearn: 0.5849807\ttotal: 56.4ms\tremaining: 2.29s\n",
      "12:\tlearn: 0.5770630\ttotal: 60.5ms\tremaining: 2.27s\n",
      "13:\tlearn: 0.5700626\ttotal: 64.7ms\tremaining: 2.25s\n",
      "14:\tlearn: 0.5626125\ttotal: 74.4ms\tremaining: 2.41s\n",
      "15:\tlearn: 0.5562034\ttotal: 84.1ms\tremaining: 2.54s\n",
      "16:\tlearn: 0.5522858\ttotal: 93.6ms\tremaining: 2.66s\n",
      "17:\tlearn: 0.5455152\ttotal: 103ms\tremaining: 2.76s\n",
      "18:\tlearn: 0.5338107\ttotal: 113ms\tremaining: 2.86s\n",
      "19:\tlearn: 0.5285044\ttotal: 122ms\tremaining: 2.94s\n",
      "20:\tlearn: 0.5233910\ttotal: 132ms\tremaining: 3.01s\n",
      "21:\tlearn: 0.5183732\ttotal: 142ms\tremaining: 3.09s\n",
      "22:\tlearn: 0.5122247\ttotal: 149ms\tremaining: 3.1s\n",
      "23:\tlearn: 0.5075456\ttotal: 155ms\tremaining: 3.08s\n",
      "24:\tlearn: 0.5039008\ttotal: 162ms\tremaining: 3.07s\n",
      "25:\tlearn: 0.4981766\ttotal: 167ms\tremaining: 3.05s\n",
      "26:\tlearn: 0.4933846\ttotal: 172ms\tremaining: 3.01s\n",
      "27:\tlearn: 0.4889451\ttotal: 177ms\tremaining: 2.99s\n",
      "28:\tlearn: 0.4842061\ttotal: 181ms\tremaining: 2.95s\n",
      "29:\tlearn: 0.4802601\ttotal: 185ms\tremaining: 2.9s\n",
      "30:\tlearn: 0.4774436\ttotal: 188ms\tremaining: 2.85s\n",
      "31:\tlearn: 0.4732785\ttotal: 194ms\tremaining: 2.83s\n",
      "32:\tlearn: 0.4694715\ttotal: 199ms\tremaining: 2.81s\n",
      "33:\tlearn: 0.4643119\ttotal: 204ms\tremaining: 2.79s\n",
      "34:\tlearn: 0.4596121\ttotal: 208ms\tremaining: 2.77s\n",
      "35:\tlearn: 0.4554692\ttotal: 213ms\tremaining: 2.75s\n",
      "36:\tlearn: 0.4528838\ttotal: 218ms\tremaining: 2.73s\n",
      "37:\tlearn: 0.4501599\ttotal: 222ms\tremaining: 2.7s\n",
      "38:\tlearn: 0.4429439\ttotal: 232ms\tremaining: 2.74s\n",
      "39:\tlearn: 0.4393201\ttotal: 241ms\tremaining: 2.77s\n",
      "40:\tlearn: 0.4350097\ttotal: 251ms\tremaining: 2.81s\n",
      "41:\tlearn: 0.4316056\ttotal: 261ms\tremaining: 2.84s\n",
      "42:\tlearn: 0.4283218\ttotal: 270ms\tremaining: 2.87s\n",
      "43:\tlearn: 0.4253216\ttotal: 280ms\tremaining: 2.9s\n",
      "44:\tlearn: 0.4229964\ttotal: 290ms\tremaining: 2.93s\n",
      "45:\tlearn: 0.4173168\ttotal: 299ms\tremaining: 2.95s\n",
      "46:\tlearn: 0.4141868\ttotal: 309ms\tremaining: 2.97s\n",
      "47:\tlearn: 0.4111487\ttotal: 318ms\tremaining: 2.99s\n",
      "48:\tlearn: 0.4080882\ttotal: 324ms\tremaining: 2.98s\n",
      "49:\tlearn: 0.4055688\ttotal: 330ms\tremaining: 2.97s\n",
      "50:\tlearn: 0.4026556\ttotal: 336ms\tremaining: 2.96s\n",
      "51:\tlearn: 0.3996648\ttotal: 342ms\tremaining: 2.95s\n",
      "52:\tlearn: 0.3975272\ttotal: 348ms\tremaining: 2.93s\n",
      "53:\tlearn: 0.3952801\ttotal: 353ms\tremaining: 2.91s\n",
      "54:\tlearn: 0.3926233\ttotal: 357ms\tremaining: 2.89s\n",
      "55:\tlearn: 0.3890856\ttotal: 362ms\tremaining: 2.87s\n",
      "56:\tlearn: 0.3867397\ttotal: 368ms\tremaining: 2.86s\n",
      "57:\tlearn: 0.3840601\ttotal: 372ms\tremaining: 2.83s\n",
      "58:\tlearn: 0.3814869\ttotal: 375ms\tremaining: 2.8s\n",
      "59:\tlearn: 0.3785064\ttotal: 379ms\tremaining: 2.78s\n",
      "60:\tlearn: 0.3771306\ttotal: 383ms\tremaining: 2.76s\n",
      "61:\tlearn: 0.3741180\ttotal: 388ms\tremaining: 2.74s\n",
      "62:\tlearn: 0.3696296\ttotal: 392ms\tremaining: 2.72s\n",
      "63:\tlearn: 0.3674381\ttotal: 397ms\tremaining: 2.7s\n",
      "64:\tlearn: 0.3645144\ttotal: 406ms\tremaining: 2.72s\n",
      "65:\tlearn: 0.3618483\ttotal: 416ms\tremaining: 2.73s\n",
      "66:\tlearn: 0.3593464\ttotal: 425ms\tremaining: 2.75s\n",
      "67:\tlearn: 0.3568624\ttotal: 435ms\tremaining: 2.77s\n",
      "68:\tlearn: 0.3543342\ttotal: 445ms\tremaining: 2.78s\n",
      "69:\tlearn: 0.3521563\ttotal: 454ms\tremaining: 2.79s\n",
      "70:\tlearn: 0.3492940\ttotal: 464ms\tremaining: 2.81s\n",
      "71:\tlearn: 0.3469883\ttotal: 474ms\tremaining: 2.82s\n",
      "72:\tlearn: 0.3415724\ttotal: 484ms\tremaining: 2.83s\n",
      "73:\tlearn: 0.3393781\ttotal: 490ms\tremaining: 2.82s\n",
      "74:\tlearn: 0.3373835\ttotal: 496ms\tremaining: 2.81s\n",
      "75:\tlearn: 0.3350470\ttotal: 502ms\tremaining: 2.8s\n",
      "76:\tlearn: 0.3326160\ttotal: 509ms\tremaining: 2.8s\n",
      "77:\tlearn: 0.3301251\ttotal: 516ms\tremaining: 2.79s\n",
      "78:\tlearn: 0.3275340\ttotal: 520ms\tremaining: 2.77s\n",
      "79:\tlearn: 0.3250551\ttotal: 527ms\tremaining: 2.77s\n",
      "80:\tlearn: 0.3230739\ttotal: 533ms\tremaining: 2.75s\n",
      "81:\tlearn: 0.3213352\ttotal: 538ms\tremaining: 2.74s\n",
      "82:\tlearn: 0.3173425\ttotal: 542ms\tremaining: 2.73s\n",
      "83:\tlearn: 0.3153970\ttotal: 547ms\tremaining: 2.71s\n",
      "84:\tlearn: 0.3135064\ttotal: 552ms\tremaining: 2.69s\n",
      "85:\tlearn: 0.3111613\ttotal: 556ms\tremaining: 2.68s\n",
      "86:\tlearn: 0.3085820\ttotal: 561ms\tremaining: 2.66s\n",
      "87:\tlearn: 0.3064594\ttotal: 565ms\tremaining: 2.64s\n",
      "88:\tlearn: 0.3031829\ttotal: 569ms\tremaining: 2.63s\n",
      "89:\tlearn: 0.3011760\ttotal: 572ms\tremaining: 2.61s\n",
      "90:\tlearn: 0.2984601\ttotal: 577ms\tremaining: 2.59s\n",
      "91:\tlearn: 0.2962902\ttotal: 581ms\tremaining: 2.58s\n",
      "92:\tlearn: 0.2942976\ttotal: 585ms\tremaining: 2.56s\n",
      "93:\tlearn: 0.2899616\ttotal: 590ms\tremaining: 2.55s\n",
      "94:\tlearn: 0.2846939\ttotal: 594ms\tremaining: 2.53s\n",
      "95:\tlearn: 0.2827456\ttotal: 599ms\tremaining: 2.52s\n",
      "96:\tlearn: 0.2807797\ttotal: 606ms\tremaining: 2.52s\n",
      "97:\tlearn: 0.2768886\ttotal: 616ms\tremaining: 2.53s\n",
      "98:\tlearn: 0.2751675\ttotal: 626ms\tremaining: 2.53s\n",
      "99:\tlearn: 0.2732412\ttotal: 635ms\tremaining: 2.54s\n",
      "100:\tlearn: 0.2715819\ttotal: 645ms\tremaining: 2.55s\n",
      "101:\tlearn: 0.2689308\ttotal: 655ms\tremaining: 2.55s\n",
      "102:\tlearn: 0.2672641\ttotal: 664ms\tremaining: 2.56s\n",
      "103:\tlearn: 0.2656918\ttotal: 674ms\tremaining: 2.56s\n",
      "104:\tlearn: 0.2640255\ttotal: 681ms\tremaining: 2.56s\n",
      "105:\tlearn: 0.2624122\ttotal: 687ms\tremaining: 2.55s\n",
      "106:\tlearn: 0.2603142\ttotal: 693ms\tremaining: 2.54s\n",
      "107:\tlearn: 0.2588256\ttotal: 699ms\tremaining: 2.54s\n",
      "108:\tlearn: 0.2563977\ttotal: 705ms\tremaining: 2.53s\n",
      "109:\tlearn: 0.2546573\ttotal: 712ms\tremaining: 2.52s\n",
      "110:\tlearn: 0.2532587\ttotal: 717ms\tremaining: 2.51s\n",
      "111:\tlearn: 0.2518618\ttotal: 722ms\tremaining: 2.5s\n",
      "112:\tlearn: 0.2498290\ttotal: 726ms\tremaining: 2.49s\n",
      "113:\tlearn: 0.2483113\ttotal: 731ms\tremaining: 2.47s\n",
      "114:\tlearn: 0.2465828\ttotal: 736ms\tremaining: 2.46s\n",
      "115:\tlearn: 0.2448818\ttotal: 740ms\tremaining: 2.45s\n",
      "116:\tlearn: 0.2436511\ttotal: 744ms\tremaining: 2.44s\n",
      "117:\tlearn: 0.2421065\ttotal: 749ms\tremaining: 2.42s\n",
      "118:\tlearn: 0.2394152\ttotal: 753ms\tremaining: 2.41s\n",
      "119:\tlearn: 0.2376366\ttotal: 758ms\tremaining: 2.4s\n",
      "120:\tlearn: 0.2360316\ttotal: 762ms\tremaining: 2.38s\n",
      "121:\tlearn: 0.2347151\ttotal: 771ms\tremaining: 2.39s\n",
      "122:\tlearn: 0.2334742\ttotal: 781ms\tremaining: 2.39s\n",
      "123:\tlearn: 0.2317356\ttotal: 791ms\tremaining: 2.4s\n",
      "124:\tlearn: 0.2295665\ttotal: 800ms\tremaining: 2.4s\n",
      "125:\tlearn: 0.2282153\ttotal: 810ms\tremaining: 2.4s\n",
      "126:\tlearn: 0.2268709\ttotal: 819ms\tremaining: 2.4s\n",
      "127:\tlearn: 0.2250195\ttotal: 829ms\tremaining: 2.41s\n",
      "128:\tlearn: 0.2234858\ttotal: 839ms\tremaining: 2.41s\n",
      "129:\tlearn: 0.2220612\ttotal: 848ms\tremaining: 2.41s\n",
      "130:\tlearn: 0.2205385\ttotal: 856ms\tremaining: 2.41s\n",
      "131:\tlearn: 0.2191283\ttotal: 862ms\tremaining: 2.4s\n",
      "132:\tlearn: 0.2178111\ttotal: 868ms\tremaining: 2.39s\n",
      "133:\tlearn: 0.2166587\ttotal: 874ms\tremaining: 2.39s\n",
      "134:\tlearn: 0.2150884\ttotal: 881ms\tremaining: 2.38s\n",
      "135:\tlearn: 0.2138952\ttotal: 886ms\tremaining: 2.37s\n",
      "136:\tlearn: 0.2127821\ttotal: 892ms\tremaining: 2.36s\n",
      "137:\tlearn: 0.2115607\ttotal: 896ms\tremaining: 2.35s\n",
      "138:\tlearn: 0.2098698\ttotal: 901ms\tremaining: 2.34s\n",
      "139:\tlearn: 0.2082357\ttotal: 905ms\tremaining: 2.33s\n",
      "140:\tlearn: 0.2071539\ttotal: 910ms\tremaining: 2.32s\n",
      "141:\tlearn: 0.2058893\ttotal: 914ms\tremaining: 2.3s\n",
      "142:\tlearn: 0.2045934\ttotal: 918ms\tremaining: 2.29s\n",
      "143:\tlearn: 0.2031747\ttotal: 922ms\tremaining: 2.28s\n",
      "144:\tlearn: 0.2019749\ttotal: 927ms\tremaining: 2.27s\n",
      "145:\tlearn: 0.2009055\ttotal: 931ms\tremaining: 2.26s\n",
      "146:\tlearn: 0.1995929\ttotal: 936ms\tremaining: 2.25s\n",
      "147:\tlearn: 0.1982541\ttotal: 946ms\tremaining: 2.25s\n",
      "148:\tlearn: 0.1967651\ttotal: 956ms\tremaining: 2.25s\n",
      "149:\tlearn: 0.1942219\ttotal: 965ms\tremaining: 2.25s\n",
      "150:\tlearn: 0.1917049\ttotal: 975ms\tremaining: 2.25s\n",
      "151:\tlearn: 0.1906902\ttotal: 985ms\tremaining: 2.25s\n",
      "152:\tlearn: 0.1895852\ttotal: 995ms\tremaining: 2.25s\n",
      "153:\tlearn: 0.1886020\ttotal: 1s\tremaining: 2.25s\n",
      "154:\tlearn: 0.1871779\ttotal: 1.01s\tremaining: 2.26s\n",
      "155:\tlearn: 0.1856737\ttotal: 1.02s\tremaining: 2.25s\n",
      "156:\tlearn: 0.1843649\ttotal: 1.03s\tremaining: 2.25s\n",
      "157:\tlearn: 0.1834393\ttotal: 1.03s\tremaining: 2.24s\n",
      "158:\tlearn: 0.1823271\ttotal: 1.04s\tremaining: 2.23s\n",
      "159:\tlearn: 0.1814489\ttotal: 1.05s\tremaining: 2.23s\n",
      "160:\tlearn: 0.1805063\ttotal: 1.05s\tremaining: 2.22s\n",
      "161:\tlearn: 0.1791410\ttotal: 1.06s\tremaining: 2.21s\n",
      "162:\tlearn: 0.1782240\ttotal: 1.06s\tremaining: 2.2s\n",
      "163:\tlearn: 0.1771865\ttotal: 1.07s\tremaining: 2.19s\n",
      "164:\tlearn: 0.1761142\ttotal: 1.07s\tremaining: 2.18s\n",
      "165:\tlearn: 0.1752662\ttotal: 1.08s\tremaining: 2.17s\n",
      "166:\tlearn: 0.1744169\ttotal: 1.08s\tremaining: 2.15s\n",
      "167:\tlearn: 0.1733214\ttotal: 1.08s\tremaining: 2.14s\n",
      "168:\tlearn: 0.1724823\ttotal: 1.09s\tremaining: 2.13s\n",
      "169:\tlearn: 0.1715642\ttotal: 1.09s\tremaining: 2.12s\n",
      "170:\tlearn: 0.1702945\ttotal: 1.1s\tremaining: 2.11s\n",
      "171:\tlearn: 0.1694330\ttotal: 1.1s\tremaining: 2.1s\n",
      "172:\tlearn: 0.1685637\ttotal: 1.1s\tremaining: 2.09s\n",
      "173:\tlearn: 0.1676856\ttotal: 1.11s\tremaining: 2.08s\n",
      "174:\tlearn: 0.1667973\ttotal: 1.12s\tremaining: 2.08s\n",
      "175:\tlearn: 0.1656801\ttotal: 1.13s\tremaining: 2.08s\n",
      "176:\tlearn: 0.1648207\ttotal: 1.14s\tremaining: 2.08s\n",
      "177:\tlearn: 0.1638565\ttotal: 1.15s\tremaining: 2.08s\n",
      "178:\tlearn: 0.1629110\ttotal: 1.16s\tremaining: 2.08s\n",
      "179:\tlearn: 0.1620570\ttotal: 1.17s\tremaining: 2.08s\n",
      "180:\tlearn: 0.1611077\ttotal: 1.18s\tremaining: 2.07s\n",
      "181:\tlearn: 0.1596672\ttotal: 1.19s\tremaining: 2.07s\n",
      "182:\tlearn: 0.1590009\ttotal: 1.19s\tremaining: 2.06s\n",
      "183:\tlearn: 0.1583638\ttotal: 1.2s\tremaining: 2.05s\n",
      "184:\tlearn: 0.1567883\ttotal: 1.2s\tremaining: 2.04s\n",
      "185:\tlearn: 0.1560046\ttotal: 1.21s\tremaining: 2.04s\n",
      "186:\tlearn: 0.1550605\ttotal: 1.21s\tremaining: 2.03s\n",
      "187:\tlearn: 0.1541002\ttotal: 1.22s\tremaining: 2.02s\n",
      "188:\tlearn: 0.1532261\ttotal: 1.22s\tremaining: 2.01s\n",
      "189:\tlearn: 0.1521726\ttotal: 1.22s\tremaining: 2s\n",
      "190:\tlearn: 0.1514709\ttotal: 1.23s\tremaining: 1.99s\n",
      "191:\tlearn: 0.1505804\ttotal: 1.23s\tremaining: 1.98s\n",
      "192:\tlearn: 0.1498840\ttotal: 1.24s\tremaining: 1.97s\n",
      "193:\tlearn: 0.1491391\ttotal: 1.24s\tremaining: 1.96s\n",
      "194:\tlearn: 0.1482348\ttotal: 1.25s\tremaining: 1.95s\n",
      "195:\tlearn: 0.1473616\ttotal: 1.25s\tremaining: 1.94s\n",
      "196:\tlearn: 0.1465982\ttotal: 1.25s\tremaining: 1.93s\n",
      "197:\tlearn: 0.1461449\ttotal: 1.27s\tremaining: 1.93s\n",
      "198:\tlearn: 0.1455352\ttotal: 1.28s\tremaining: 1.93s\n",
      "199:\tlearn: 0.1447210\ttotal: 1.29s\tremaining: 1.93s\n",
      "200:\tlearn: 0.1439304\ttotal: 1.3s\tremaining: 1.93s\n",
      "201:\tlearn: 0.1432406\ttotal: 1.31s\tremaining: 1.93s\n",
      "202:\tlearn: 0.1422096\ttotal: 1.32s\tremaining: 1.93s\n",
      "203:\tlearn: 0.1415446\ttotal: 1.33s\tremaining: 1.92s\n",
      "204:\tlearn: 0.1411069\ttotal: 1.34s\tremaining: 1.92s\n",
      "205:\tlearn: 0.1404009\ttotal: 1.34s\tremaining: 1.92s\n",
      "206:\tlearn: 0.1397311\ttotal: 1.35s\tremaining: 1.91s\n",
      "207:\tlearn: 0.1389640\ttotal: 1.36s\tremaining: 1.91s\n",
      "208:\tlearn: 0.1379414\ttotal: 1.36s\tremaining: 1.9s\n",
      "209:\tlearn: 0.1370586\ttotal: 1.37s\tremaining: 1.89s\n",
      "210:\tlearn: 0.1364412\ttotal: 1.37s\tremaining: 1.88s\n",
      "211:\tlearn: 0.1350888\ttotal: 1.38s\tremaining: 1.87s\n",
      "212:\tlearn: 0.1344671\ttotal: 1.38s\tremaining: 1.86s\n",
      "213:\tlearn: 0.1330261\ttotal: 1.39s\tremaining: 1.85s\n",
      "214:\tlearn: 0.1321764\ttotal: 1.39s\tremaining: 1.84s\n",
      "215:\tlearn: 0.1314169\ttotal: 1.39s\tremaining: 1.83s\n",
      "216:\tlearn: 0.1308260\ttotal: 1.4s\tremaining: 1.82s\n",
      "217:\tlearn: 0.1299853\ttotal: 1.4s\tremaining: 1.81s\n",
      "218:\tlearn: 0.1293758\ttotal: 1.41s\tremaining: 1.81s\n",
      "219:\tlearn: 0.1286673\ttotal: 1.41s\tremaining: 1.8s\n",
      "220:\tlearn: 0.1279815\ttotal: 1.42s\tremaining: 1.79s\n",
      "221:\tlearn: 0.1274124\ttotal: 1.42s\tremaining: 1.78s\n",
      "222:\tlearn: 0.1258358\ttotal: 1.43s\tremaining: 1.78s\n",
      "223:\tlearn: 0.1251245\ttotal: 1.44s\tremaining: 1.77s\n",
      "224:\tlearn: 0.1244383\ttotal: 1.45s\tremaining: 1.77s\n",
      "225:\tlearn: 0.1239012\ttotal: 1.46s\tremaining: 1.77s\n",
      "226:\tlearn: 0.1232436\ttotal: 1.47s\tremaining: 1.77s\n",
      "227:\tlearn: 0.1226277\ttotal: 1.48s\tremaining: 1.76s\n",
      "228:\tlearn: 0.1218972\ttotal: 1.49s\tremaining: 1.76s\n",
      "229:\tlearn: 0.1207378\ttotal: 1.5s\tremaining: 1.76s\n",
      "230:\tlearn: 0.1200091\ttotal: 1.5s\tremaining: 1.75s\n",
      "231:\tlearn: 0.1193746\ttotal: 1.51s\tremaining: 1.75s\n",
      "232:\tlearn: 0.1186485\ttotal: 1.52s\tremaining: 1.74s\n",
      "233:\tlearn: 0.1178645\ttotal: 1.52s\tremaining: 1.73s\n",
      "234:\tlearn: 0.1172780\ttotal: 1.53s\tremaining: 1.73s\n",
      "235:\tlearn: 0.1166789\ttotal: 1.54s\tremaining: 1.72s\n",
      "236:\tlearn: 0.1160837\ttotal: 1.54s\tremaining: 1.71s\n",
      "237:\tlearn: 0.1154851\ttotal: 1.55s\tremaining: 1.7s\n",
      "238:\tlearn: 0.1149178\ttotal: 1.56s\tremaining: 1.7s\n",
      "239:\tlearn: 0.1144256\ttotal: 1.56s\tremaining: 1.69s\n",
      "240:\tlearn: 0.1134636\ttotal: 1.56s\tremaining: 1.68s\n",
      "241:\tlearn: 0.1129762\ttotal: 1.57s\tremaining: 1.67s\n",
      "242:\tlearn: 0.1123970\ttotal: 1.57s\tremaining: 1.66s\n",
      "243:\tlearn: 0.1119451\ttotal: 1.58s\tremaining: 1.66s\n",
      "244:\tlearn: 0.1113529\ttotal: 1.58s\tremaining: 1.65s\n",
      "245:\tlearn: 0.1108380\ttotal: 1.59s\tremaining: 1.64s\n",
      "246:\tlearn: 0.1103566\ttotal: 1.59s\tremaining: 1.63s\n",
      "247:\tlearn: 0.1098251\ttotal: 1.6s\tremaining: 1.63s\n",
      "248:\tlearn: 0.1090406\ttotal: 1.61s\tremaining: 1.62s\n",
      "249:\tlearn: 0.1084500\ttotal: 1.62s\tremaining: 1.62s\n",
      "250:\tlearn: 0.1079086\ttotal: 1.63s\tremaining: 1.62s\n",
      "251:\tlearn: 0.1072621\ttotal: 1.64s\tremaining: 1.61s\n",
      "252:\tlearn: 0.1067222\ttotal: 1.65s\tremaining: 1.61s\n",
      "253:\tlearn: 0.1059324\ttotal: 1.66s\tremaining: 1.61s\n",
      "254:\tlearn: 0.1055934\ttotal: 1.67s\tremaining: 1.6s\n",
      "255:\tlearn: 0.1050619\ttotal: 1.67s\tremaining: 1.59s\n",
      "256:\tlearn: 0.1042687\ttotal: 1.68s\tremaining: 1.59s\n",
      "257:\tlearn: 0.1038063\ttotal: 1.68s\tremaining: 1.58s\n",
      "258:\tlearn: 0.1031352\ttotal: 1.69s\tremaining: 1.57s\n",
      "259:\tlearn: 0.1026066\ttotal: 1.69s\tremaining: 1.56s\n",
      "260:\tlearn: 0.1021378\ttotal: 1.7s\tremaining: 1.55s\n",
      "261:\tlearn: 0.1016386\ttotal: 1.7s\tremaining: 1.54s\n",
      "262:\tlearn: 0.1007539\ttotal: 1.7s\tremaining: 1.54s\n",
      "263:\tlearn: 0.1003114\ttotal: 1.71s\tremaining: 1.53s\n",
      "264:\tlearn: 0.0999115\ttotal: 1.71s\tremaining: 1.52s\n",
      "265:\tlearn: 0.0993492\ttotal: 1.72s\tremaining: 1.51s\n",
      "266:\tlearn: 0.0987352\ttotal: 1.72s\tremaining: 1.5s\n",
      "267:\tlearn: 0.0982894\ttotal: 1.73s\tremaining: 1.5s\n",
      "268:\tlearn: 0.0976568\ttotal: 1.74s\tremaining: 1.5s\n",
      "269:\tlearn: 0.0972348\ttotal: 1.75s\tremaining: 1.49s\n",
      "270:\tlearn: 0.0964012\ttotal: 1.76s\tremaining: 1.49s\n",
      "271:\tlearn: 0.0959929\ttotal: 1.77s\tremaining: 1.49s\n",
      "272:\tlearn: 0.0955264\ttotal: 1.78s\tremaining: 1.48s\n",
      "273:\tlearn: 0.0950839\ttotal: 1.79s\tremaining: 1.48s\n",
      "274:\tlearn: 0.0945441\ttotal: 1.8s\tremaining: 1.47s\n",
      "275:\tlearn: 0.0941405\ttotal: 1.8s\tremaining: 1.46s\n",
      "276:\tlearn: 0.0936209\ttotal: 1.81s\tremaining: 1.45s\n",
      "277:\tlearn: 0.0931717\ttotal: 1.81s\tremaining: 1.45s\n",
      "278:\tlearn: 0.0926584\ttotal: 1.82s\tremaining: 1.44s\n",
      "279:\tlearn: 0.0921849\ttotal: 1.82s\tremaining: 1.43s\n",
      "280:\tlearn: 0.0918175\ttotal: 1.82s\tremaining: 1.42s\n",
      "281:\tlearn: 0.0911635\ttotal: 1.83s\tremaining: 1.41s\n",
      "282:\tlearn: 0.0907974\ttotal: 1.83s\tremaining: 1.41s\n",
      "283:\tlearn: 0.0902721\ttotal: 1.84s\tremaining: 1.4s\n",
      "284:\tlearn: 0.0898894\ttotal: 1.84s\tremaining: 1.39s\n",
      "285:\tlearn: 0.0893844\ttotal: 1.85s\tremaining: 1.38s\n",
      "286:\tlearn: 0.0888291\ttotal: 1.85s\tremaining: 1.38s\n",
      "287:\tlearn: 0.0885161\ttotal: 1.86s\tremaining: 1.37s\n",
      "288:\tlearn: 0.0879878\ttotal: 1.87s\tremaining: 1.36s\n",
      "289:\tlearn: 0.0875726\ttotal: 1.88s\tremaining: 1.36s\n",
      "290:\tlearn: 0.0871585\ttotal: 1.89s\tremaining: 1.35s\n",
      "291:\tlearn: 0.0869807\ttotal: 1.9s\tremaining: 1.35s\n",
      "292:\tlearn: 0.0865214\ttotal: 1.91s\tremaining: 1.34s\n",
      "293:\tlearn: 0.0860709\ttotal: 1.91s\tremaining: 1.34s\n",
      "294:\tlearn: 0.0856892\ttotal: 1.92s\tremaining: 1.34s\n",
      "295:\tlearn: 0.0852456\ttotal: 1.93s\tremaining: 1.33s\n",
      "296:\tlearn: 0.0850121\ttotal: 1.94s\tremaining: 1.33s\n",
      "297:\tlearn: 0.0845952\ttotal: 1.95s\tremaining: 1.32s\n",
      "298:\tlearn: 0.0842109\ttotal: 1.96s\tremaining: 1.32s\n",
      "299:\tlearn: 0.0837799\ttotal: 1.97s\tremaining: 1.31s\n",
      "300:\tlearn: 0.0830832\ttotal: 1.97s\tremaining: 1.3s\n",
      "301:\tlearn: 0.0826295\ttotal: 1.98s\tremaining: 1.3s\n",
      "302:\tlearn: 0.0822015\ttotal: 1.98s\tremaining: 1.29s\n",
      "303:\tlearn: 0.0818306\ttotal: 1.99s\tremaining: 1.28s\n",
      "304:\tlearn: 0.0814174\ttotal: 1.99s\tremaining: 1.27s\n",
      "305:\tlearn: 0.0811753\ttotal: 2s\tremaining: 1.26s\n",
      "306:\tlearn: 0.0807499\ttotal: 2s\tremaining: 1.26s\n",
      "307:\tlearn: 0.0804001\ttotal: 2s\tremaining: 1.25s\n",
      "308:\tlearn: 0.0799988\ttotal: 2.01s\tremaining: 1.24s\n",
      "309:\tlearn: 0.0796641\ttotal: 2.01s\tremaining: 1.23s\n",
      "310:\tlearn: 0.0792110\ttotal: 2.02s\tremaining: 1.23s\n",
      "311:\tlearn: 0.0787453\ttotal: 2.02s\tremaining: 1.22s\n",
      "312:\tlearn: 0.0785153\ttotal: 2.03s\tremaining: 1.21s\n",
      "313:\tlearn: 0.0781727\ttotal: 2.03s\tremaining: 1.2s\n",
      "314:\tlearn: 0.0778539\ttotal: 2.03s\tremaining: 1.2s\n",
      "315:\tlearn: 0.0774547\ttotal: 2.04s\tremaining: 1.19s\n",
      "316:\tlearn: 0.0768848\ttotal: 2.05s\tremaining: 1.19s\n",
      "317:\tlearn: 0.0766000\ttotal: 2.06s\tremaining: 1.18s\n",
      "318:\tlearn: 0.0761608\ttotal: 2.07s\tremaining: 1.18s\n",
      "319:\tlearn: 0.0758486\ttotal: 2.08s\tremaining: 1.17s\n",
      "320:\tlearn: 0.0755178\ttotal: 2.09s\tremaining: 1.17s\n",
      "321:\tlearn: 0.0752050\ttotal: 2.1s\tremaining: 1.16s\n",
      "322:\tlearn: 0.0748275\ttotal: 2.11s\tremaining: 1.16s\n",
      "323:\tlearn: 0.0743798\ttotal: 2.12s\tremaining: 1.15s\n",
      "324:\tlearn: 0.0741211\ttotal: 2.13s\tremaining: 1.15s\n",
      "325:\tlearn: 0.0737612\ttotal: 2.13s\tremaining: 1.14s\n",
      "326:\tlearn: 0.0734716\ttotal: 2.14s\tremaining: 1.13s\n",
      "327:\tlearn: 0.0731163\ttotal: 2.15s\tremaining: 1.13s\n",
      "328:\tlearn: 0.0727443\ttotal: 2.15s\tremaining: 1.12s\n",
      "329:\tlearn: 0.0724133\ttotal: 2.16s\tremaining: 1.11s\n",
      "330:\tlearn: 0.0719819\ttotal: 2.16s\tremaining: 1.1s\n",
      "331:\tlearn: 0.0714450\ttotal: 2.17s\tremaining: 1.1s\n",
      "332:\tlearn: 0.0710493\ttotal: 2.17s\tremaining: 1.09s\n",
      "333:\tlearn: 0.0706707\ttotal: 2.18s\tremaining: 1.08s\n",
      "334:\tlearn: 0.0702518\ttotal: 2.18s\tremaining: 1.07s\n",
      "335:\tlearn: 0.0699040\ttotal: 2.18s\tremaining: 1.07s\n",
      "336:\tlearn: 0.0696129\ttotal: 2.19s\tremaining: 1.06s\n",
      "337:\tlearn: 0.0692181\ttotal: 2.19s\tremaining: 1.05s\n",
      "338:\tlearn: 0.0689324\ttotal: 2.2s\tremaining: 1.04s\n",
      "339:\tlearn: 0.0686331\ttotal: 2.2s\tremaining: 1.04s\n",
      "340:\tlearn: 0.0683462\ttotal: 2.21s\tremaining: 1.03s\n",
      "341:\tlearn: 0.0679999\ttotal: 2.22s\tremaining: 1.03s\n",
      "342:\tlearn: 0.0677875\ttotal: 2.23s\tremaining: 1.02s\n",
      "343:\tlearn: 0.0675090\ttotal: 2.24s\tremaining: 1.02s\n",
      "344:\tlearn: 0.0672288\ttotal: 2.25s\tremaining: 1.01s\n",
      "345:\tlearn: 0.0668365\ttotal: 2.26s\tremaining: 1s\n",
      "346:\tlearn: 0.0664879\ttotal: 2.27s\tremaining: 1s\n",
      "347:\tlearn: 0.0659161\ttotal: 2.28s\tremaining: 996ms\n",
      "348:\tlearn: 0.0656257\ttotal: 2.29s\tremaining: 990ms\n",
      "349:\tlearn: 0.0653103\ttotal: 2.3s\tremaining: 985ms\n",
      "350:\tlearn: 0.0649733\ttotal: 2.31s\tremaining: 979ms\n",
      "351:\tlearn: 0.0646553\ttotal: 2.31s\tremaining: 972ms\n",
      "352:\tlearn: 0.0643321\ttotal: 2.32s\tremaining: 965ms\n",
      "353:\tlearn: 0.0637419\ttotal: 2.32s\tremaining: 958ms\n",
      "354:\tlearn: 0.0634968\ttotal: 2.33s\tremaining: 950ms\n",
      "355:\tlearn: 0.0633290\ttotal: 2.33s\tremaining: 943ms\n",
      "356:\tlearn: 0.0630188\ttotal: 2.34s\tremaining: 937ms\n",
      "357:\tlearn: 0.0627429\ttotal: 2.34s\tremaining: 929ms\n",
      "358:\tlearn: 0.0624926\ttotal: 2.35s\tremaining: 922ms\n",
      "359:\tlearn: 0.0621899\ttotal: 2.35s\tremaining: 914ms\n",
      "360:\tlearn: 0.0619493\ttotal: 2.35s\tremaining: 906ms\n",
      "361:\tlearn: 0.0617165\ttotal: 2.36s\tremaining: 899ms\n",
      "362:\tlearn: 0.0613901\ttotal: 2.36s\tremaining: 892ms\n",
      "363:\tlearn: 0.0611402\ttotal: 2.37s\tremaining: 884ms\n",
      "364:\tlearn: 0.0607716\ttotal: 2.37s\tremaining: 877ms\n",
      "365:\tlearn: 0.0605273\ttotal: 2.38s\tremaining: 870ms\n",
      "366:\tlearn: 0.0601089\ttotal: 2.38s\tremaining: 863ms\n",
      "367:\tlearn: 0.0599129\ttotal: 2.39s\tremaining: 857ms\n",
      "368:\tlearn: 0.0596718\ttotal: 2.4s\tremaining: 852ms\n",
      "369:\tlearn: 0.0593357\ttotal: 2.41s\tremaining: 847ms\n",
      "370:\tlearn: 0.0590528\ttotal: 2.42s\tremaining: 841ms\n",
      "371:\tlearn: 0.0585535\ttotal: 2.43s\tremaining: 836ms\n",
      "372:\tlearn: 0.0582440\ttotal: 2.44s\tremaining: 830ms\n",
      "373:\tlearn: 0.0580435\ttotal: 2.45s\tremaining: 825ms\n",
      "374:\tlearn: 0.0578101\ttotal: 2.46s\tremaining: 819ms\n",
      "375:\tlearn: 0.0576017\ttotal: 2.46s\tremaining: 813ms\n",
      "376:\tlearn: 0.0573397\ttotal: 2.47s\tremaining: 806ms\n",
      "377:\tlearn: 0.0571866\ttotal: 2.48s\tremaining: 799ms\n",
      "378:\tlearn: 0.0568989\ttotal: 2.48s\tremaining: 793ms\n",
      "379:\tlearn: 0.0565820\ttotal: 2.49s\tremaining: 786ms\n",
      "380:\tlearn: 0.0562079\ttotal: 2.49s\tremaining: 779ms\n",
      "381:\tlearn: 0.0559589\ttotal: 2.5s\tremaining: 772ms\n",
      "382:\tlearn: 0.0554970\ttotal: 2.5s\tremaining: 765ms\n",
      "383:\tlearn: 0.0552682\ttotal: 2.51s\tremaining: 758ms\n",
      "384:\tlearn: 0.0549754\ttotal: 2.52s\tremaining: 752ms\n",
      "385:\tlearn: 0.0547471\ttotal: 2.52s\tremaining: 744ms\n",
      "386:\tlearn: 0.0544945\ttotal: 2.52s\tremaining: 737ms\n",
      "387:\tlearn: 0.0541813\ttotal: 2.53s\tremaining: 730ms\n",
      "388:\tlearn: 0.0538799\ttotal: 2.53s\tremaining: 723ms\n",
      "389:\tlearn: 0.0535444\ttotal: 2.54s\tremaining: 716ms\n",
      "390:\tlearn: 0.0532908\ttotal: 2.54s\tremaining: 709ms\n",
      "391:\tlearn: 0.0531071\ttotal: 2.55s\tremaining: 703ms\n",
      "392:\tlearn: 0.0528905\ttotal: 2.56s\tremaining: 697ms\n",
      "393:\tlearn: 0.0526068\ttotal: 2.57s\tremaining: 692ms\n",
      "394:\tlearn: 0.0523633\ttotal: 2.58s\tremaining: 686ms\n",
      "395:\tlearn: 0.0521510\ttotal: 2.59s\tremaining: 680ms\n",
      "396:\tlearn: 0.0519293\ttotal: 2.6s\tremaining: 675ms\n",
      "397:\tlearn: 0.0517306\ttotal: 2.61s\tremaining: 669ms\n",
      "398:\tlearn: 0.0514901\ttotal: 2.62s\tremaining: 663ms\n",
      "399:\tlearn: 0.0513066\ttotal: 2.63s\tremaining: 657ms\n",
      "400:\tlearn: 0.0510876\ttotal: 2.64s\tremaining: 651ms\n",
      "401:\tlearn: 0.0508017\ttotal: 2.64s\tremaining: 645ms\n",
      "402:\tlearn: 0.0505790\ttotal: 2.65s\tremaining: 638ms\n",
      "403:\tlearn: 0.0504164\ttotal: 2.66s\tremaining: 631ms\n",
      "404:\tlearn: 0.0501667\ttotal: 2.66s\tremaining: 625ms\n",
      "405:\tlearn: 0.0499789\ttotal: 2.67s\tremaining: 618ms\n",
      "406:\tlearn: 0.0497686\ttotal: 2.67s\tremaining: 611ms\n",
      "407:\tlearn: 0.0495628\ttotal: 2.68s\tremaining: 605ms\n",
      "408:\tlearn: 0.0493754\ttotal: 2.69s\tremaining: 598ms\n",
      "409:\tlearn: 0.0492302\ttotal: 2.69s\tremaining: 591ms\n",
      "410:\tlearn: 0.0489681\ttotal: 2.7s\tremaining: 585ms\n",
      "411:\tlearn: 0.0488152\ttotal: 2.71s\tremaining: 578ms\n",
      "412:\tlearn: 0.0486363\ttotal: 2.71s\tremaining: 571ms\n",
      "413:\tlearn: 0.0483656\ttotal: 2.71s\tremaining: 564ms\n",
      "414:\tlearn: 0.0481197\ttotal: 2.72s\tremaining: 557ms\n",
      "415:\tlearn: 0.0479165\ttotal: 2.72s\tremaining: 550ms\n",
      "416:\tlearn: 0.0477083\ttotal: 2.73s\tremaining: 543ms\n",
      "417:\tlearn: 0.0475227\ttotal: 2.73s\tremaining: 536ms\n",
      "418:\tlearn: 0.0472876\ttotal: 2.74s\tremaining: 529ms\n",
      "419:\tlearn: 0.0470594\ttotal: 2.74s\tremaining: 522ms\n",
      "420:\tlearn: 0.0469206\ttotal: 2.75s\tremaining: 515ms\n",
      "421:\tlearn: 0.0467004\ttotal: 2.75s\tremaining: 509ms\n",
      "422:\tlearn: 0.0465246\ttotal: 2.77s\tremaining: 503ms\n",
      "423:\tlearn: 0.0463146\ttotal: 2.77s\tremaining: 497ms\n",
      "424:\tlearn: 0.0460743\ttotal: 2.78s\tremaining: 491ms\n",
      "425:\tlearn: 0.0458932\ttotal: 2.79s\tremaining: 485ms\n",
      "426:\tlearn: 0.0456878\ttotal: 2.8s\tremaining: 479ms\n",
      "427:\tlearn: 0.0454640\ttotal: 2.81s\tremaining: 473ms\n",
      "428:\tlearn: 0.0452808\ttotal: 2.82s\tremaining: 467ms\n",
      "429:\tlearn: 0.0451612\ttotal: 2.83s\tremaining: 461ms\n",
      "430:\tlearn: 0.0449617\ttotal: 2.84s\tremaining: 455ms\n",
      "431:\tlearn: 0.0447931\ttotal: 2.85s\tremaining: 448ms\n",
      "432:\tlearn: 0.0446193\ttotal: 2.85s\tremaining: 441ms\n",
      "433:\tlearn: 0.0444537\ttotal: 2.86s\tremaining: 435ms\n",
      "434:\tlearn: 0.0441800\ttotal: 2.87s\tremaining: 428ms\n",
      "435:\tlearn: 0.0439486\ttotal: 2.87s\tremaining: 422ms\n",
      "436:\tlearn: 0.0437301\ttotal: 2.88s\tremaining: 415ms\n",
      "437:\tlearn: 0.0435809\ttotal: 2.88s\tremaining: 408ms\n",
      "438:\tlearn: 0.0433067\ttotal: 2.89s\tremaining: 401ms\n",
      "439:\tlearn: 0.0431093\ttotal: 2.89s\tremaining: 394ms\n",
      "440:\tlearn: 0.0429055\ttotal: 2.9s\tremaining: 387ms\n",
      "441:\tlearn: 0.0427082\ttotal: 2.9s\tremaining: 381ms\n",
      "442:\tlearn: 0.0425754\ttotal: 2.9s\tremaining: 374ms\n",
      "443:\tlearn: 0.0423873\ttotal: 2.91s\tremaining: 367ms\n",
      "444:\tlearn: 0.0422679\ttotal: 2.91s\tremaining: 360ms\n",
      "445:\tlearn: 0.0420281\ttotal: 2.92s\tremaining: 353ms\n",
      "446:\tlearn: 0.0418414\ttotal: 2.92s\tremaining: 346ms\n",
      "447:\tlearn: 0.0417289\ttotal: 2.93s\tremaining: 340ms\n",
      "448:\tlearn: 0.0415284\ttotal: 2.94s\tremaining: 334ms\n",
      "449:\tlearn: 0.0413013\ttotal: 2.95s\tremaining: 328ms\n",
      "450:\tlearn: 0.0410934\ttotal: 2.96s\tremaining: 322ms\n",
      "451:\tlearn: 0.0409007\ttotal: 2.97s\tremaining: 315ms\n",
      "452:\tlearn: 0.0406750\ttotal: 2.98s\tremaining: 309ms\n",
      "453:\tlearn: 0.0404934\ttotal: 2.99s\tremaining: 303ms\n",
      "454:\tlearn: 0.0403033\ttotal: 3s\tremaining: 297ms\n",
      "455:\tlearn: 0.0400975\ttotal: 3.01s\tremaining: 290ms\n",
      "456:\tlearn: 0.0398553\ttotal: 3.02s\tremaining: 284ms\n",
      "457:\tlearn: 0.0396379\ttotal: 3.02s\tremaining: 277ms\n",
      "458:\tlearn: 0.0393536\ttotal: 3.03s\tremaining: 271ms\n",
      "459:\tlearn: 0.0391948\ttotal: 3.04s\tremaining: 264ms\n",
      "460:\tlearn: 0.0389491\ttotal: 3.04s\tremaining: 258ms\n",
      "461:\tlearn: 0.0388128\ttotal: 3.05s\tremaining: 251ms\n",
      "462:\tlearn: 0.0386281\ttotal: 3.06s\tremaining: 244ms\n",
      "463:\tlearn: 0.0384772\ttotal: 3.06s\tremaining: 238ms\n",
      "464:\tlearn: 0.0382942\ttotal: 3.07s\tremaining: 231ms\n",
      "465:\tlearn: 0.0380966\ttotal: 3.07s\tremaining: 224ms\n",
      "466:\tlearn: 0.0379752\ttotal: 3.08s\tremaining: 217ms\n",
      "467:\tlearn: 0.0378170\ttotal: 3.08s\tremaining: 211ms\n",
      "468:\tlearn: 0.0376257\ttotal: 3.08s\tremaining: 204ms\n",
      "469:\tlearn: 0.0375106\ttotal: 3.09s\tremaining: 197ms\n",
      "470:\tlearn: 0.0373494\ttotal: 3.09s\tremaining: 191ms\n",
      "471:\tlearn: 0.0370413\ttotal: 3.1s\tremaining: 184ms\n",
      "472:\tlearn: 0.0368229\ttotal: 3.1s\tremaining: 177ms\n",
      "473:\tlearn: 0.0366359\ttotal: 3.11s\tremaining: 170ms\n",
      "474:\tlearn: 0.0364886\ttotal: 3.11s\tremaining: 164ms\n",
      "475:\tlearn: 0.0363216\ttotal: 3.12s\tremaining: 157ms\n",
      "476:\tlearn: 0.0362009\ttotal: 3.12s\tremaining: 150ms\n",
      "477:\tlearn: 0.0360672\ttotal: 3.12s\tremaining: 144ms\n",
      "478:\tlearn: 0.0359394\ttotal: 3.13s\tremaining: 137ms\n",
      "479:\tlearn: 0.0357945\ttotal: 3.14s\tremaining: 131ms\n",
      "480:\tlearn: 0.0356201\ttotal: 3.15s\tremaining: 125ms\n",
      "481:\tlearn: 0.0354746\ttotal: 3.16s\tremaining: 118ms\n",
      "482:\tlearn: 0.0353230\ttotal: 3.17s\tremaining: 112ms\n",
      "483:\tlearn: 0.0351148\ttotal: 3.18s\tremaining: 105ms\n",
      "484:\tlearn: 0.0349259\ttotal: 3.19s\tremaining: 98.7ms\n",
      "485:\tlearn: 0.0347844\ttotal: 3.2s\tremaining: 92.2ms\n",
      "486:\tlearn: 0.0346143\ttotal: 3.21s\tremaining: 85.6ms\n",
      "487:\tlearn: 0.0344514\ttotal: 3.21s\tremaining: 79ms\n",
      "488:\tlearn: 0.0342653\ttotal: 3.22s\tremaining: 72.5ms\n",
      "489:\tlearn: 0.0341080\ttotal: 3.23s\tremaining: 65.9ms\n",
      "490:\tlearn: 0.0339701\ttotal: 3.23s\tremaining: 59.3ms\n",
      "491:\tlearn: 0.0338046\ttotal: 3.24s\tremaining: 52.7ms\n",
      "492:\tlearn: 0.0336734\ttotal: 3.25s\tremaining: 46.1ms\n",
      "493:\tlearn: 0.0335053\ttotal: 3.25s\tremaining: 39.5ms\n",
      "494:\tlearn: 0.0333535\ttotal: 3.26s\tremaining: 32.9ms\n",
      "495:\tlearn: 0.0331946\ttotal: 3.26s\tremaining: 26.3ms\n",
      "496:\tlearn: 0.0330768\ttotal: 3.27s\tremaining: 19.7ms\n",
      "497:\tlearn: 0.0329529\ttotal: 3.27s\tremaining: 13.1ms\n",
      "498:\tlearn: 0.0328601\ttotal: 3.27s\tremaining: 6.56ms\n",
      "499:\tlearn: 0.0327242\ttotal: 3.28s\tremaining: 0us\n",
      "0:\tlearn: 0.6819887\ttotal: 5.26ms\tremaining: 2.63s\n",
      "1:\tlearn: 0.6676348\ttotal: 10.3ms\tremaining: 2.56s\n",
      "2:\tlearn: 0.6599043\ttotal: 15.5ms\tremaining: 2.57s\n",
      "3:\tlearn: 0.6491897\ttotal: 23.4ms\tremaining: 2.91s\n",
      "4:\tlearn: 0.6405332\ttotal: 33.8ms\tremaining: 3.35s\n",
      "5:\tlearn: 0.6338576\ttotal: 43.1ms\tremaining: 3.55s\n",
      "6:\tlearn: 0.6245664\ttotal: 53.3ms\tremaining: 3.75s\n",
      "7:\tlearn: 0.6154632\ttotal: 62.9ms\tremaining: 3.87s\n",
      "8:\tlearn: 0.6103185\ttotal: 72.3ms\tremaining: 3.95s\n",
      "9:\tlearn: 0.6033677\ttotal: 81.9ms\tremaining: 4.01s\n",
      "10:\tlearn: 0.5957741\ttotal: 91.7ms\tremaining: 4.08s\n",
      "11:\tlearn: 0.5890464\ttotal: 101ms\tremaining: 4.11s\n",
      "12:\tlearn: 0.5811304\ttotal: 111ms\tremaining: 4.15s\n",
      "13:\tlearn: 0.5744953\ttotal: 118ms\tremaining: 4.08s\n",
      "14:\tlearn: 0.5689053\ttotal: 124ms\tremaining: 4s\n",
      "15:\tlearn: 0.5640376\ttotal: 130ms\tremaining: 3.93s\n",
      "16:\tlearn: 0.5587445\ttotal: 136ms\tremaining: 3.86s\n",
      "17:\tlearn: 0.5509151\ttotal: 142ms\tremaining: 3.8s\n",
      "18:\tlearn: 0.5459677\ttotal: 147ms\tremaining: 3.71s\n",
      "19:\tlearn: 0.5408030\ttotal: 151ms\tremaining: 3.63s\n",
      "20:\tlearn: 0.5318042\ttotal: 156ms\tremaining: 3.55s\n",
      "21:\tlearn: 0.5259634\ttotal: 160ms\tremaining: 3.48s\n",
      "22:\tlearn: 0.5191082\ttotal: 165ms\tremaining: 3.42s\n",
      "23:\tlearn: 0.5151582\ttotal: 170ms\tremaining: 3.37s\n",
      "24:\tlearn: 0.5112440\ttotal: 175ms\tremaining: 3.32s\n",
      "25:\tlearn: 0.5059516\ttotal: 179ms\tremaining: 3.25s\n",
      "26:\tlearn: 0.5008111\ttotal: 183ms\tremaining: 3.21s\n",
      "27:\tlearn: 0.4945395\ttotal: 187ms\tremaining: 3.16s\n",
      "28:\tlearn: 0.4901978\ttotal: 192ms\tremaining: 3.11s\n",
      "29:\tlearn: 0.4857066\ttotal: 196ms\tremaining: 3.06s\n",
      "30:\tlearn: 0.4787166\ttotal: 200ms\tremaining: 3.02s\n",
      "31:\tlearn: 0.4742117\ttotal: 204ms\tremaining: 2.98s\n",
      "32:\tlearn: 0.4707662\ttotal: 217ms\tremaining: 3.06s\n",
      "33:\tlearn: 0.4675634\ttotal: 226ms\tremaining: 3.1s\n",
      "34:\tlearn: 0.4637331\ttotal: 236ms\tremaining: 3.13s\n",
      "35:\tlearn: 0.4581749\ttotal: 246ms\tremaining: 3.17s\n",
      "36:\tlearn: 0.4536497\ttotal: 256ms\tremaining: 3.2s\n",
      "37:\tlearn: 0.4504121\ttotal: 265ms\tremaining: 3.23s\n",
      "38:\tlearn: 0.4456465\ttotal: 275ms\tremaining: 3.25s\n",
      "39:\tlearn: 0.4429873\ttotal: 285ms\tremaining: 3.27s\n",
      "40:\tlearn: 0.4408378\ttotal: 293ms\tremaining: 3.27s\n",
      "41:\tlearn: 0.4377247\ttotal: 299ms\tremaining: 3.26s\n",
      "42:\tlearn: 0.4352071\ttotal: 305ms\tremaining: 3.24s\n",
      "43:\tlearn: 0.4300026\ttotal: 311ms\tremaining: 3.23s\n",
      "44:\tlearn: 0.4244670\ttotal: 318ms\tremaining: 3.21s\n",
      "45:\tlearn: 0.4205321\ttotal: 324ms\tremaining: 3.19s\n",
      "46:\tlearn: 0.4178996\ttotal: 330ms\tremaining: 3.18s\n",
      "47:\tlearn: 0.4141844\ttotal: 335ms\tremaining: 3.15s\n",
      "48:\tlearn: 0.4113408\ttotal: 340ms\tremaining: 3.13s\n",
      "49:\tlearn: 0.4084868\ttotal: 345ms\tremaining: 3.1s\n",
      "50:\tlearn: 0.4060132\ttotal: 352ms\tremaining: 3.1s\n",
      "51:\tlearn: 0.4029926\ttotal: 356ms\tremaining: 3.07s\n",
      "52:\tlearn: 0.3996142\ttotal: 361ms\tremaining: 3.05s\n",
      "53:\tlearn: 0.3965293\ttotal: 366ms\tremaining: 3.02s\n",
      "54:\tlearn: 0.3942803\ttotal: 371ms\tremaining: 3s\n",
      "55:\tlearn: 0.3919880\ttotal: 375ms\tremaining: 2.98s\n",
      "56:\tlearn: 0.3897017\ttotal: 380ms\tremaining: 2.95s\n",
      "57:\tlearn: 0.3872072\ttotal: 384ms\tremaining: 2.92s\n",
      "58:\tlearn: 0.3849232\ttotal: 388ms\tremaining: 2.9s\n",
      "59:\tlearn: 0.3830086\ttotal: 392ms\tremaining: 2.88s\n",
      "60:\tlearn: 0.3779000\ttotal: 405ms\tremaining: 2.92s\n",
      "61:\tlearn: 0.3746462\ttotal: 414ms\tremaining: 2.93s\n",
      "62:\tlearn: 0.3710138\ttotal: 424ms\tremaining: 2.94s\n",
      "63:\tlearn: 0.3687133\ttotal: 434ms\tremaining: 2.95s\n",
      "64:\tlearn: 0.3665711\ttotal: 443ms\tremaining: 2.97s\n",
      "65:\tlearn: 0.3644653\ttotal: 453ms\tremaining: 2.98s\n",
      "66:\tlearn: 0.3621982\ttotal: 463ms\tremaining: 2.99s\n",
      "67:\tlearn: 0.3593749\ttotal: 472ms\tremaining: 3s\n",
      "68:\tlearn: 0.3569954\ttotal: 482ms\tremaining: 3.01s\n",
      "69:\tlearn: 0.3549812\ttotal: 489ms\tremaining: 3s\n",
      "70:\tlearn: 0.3523937\ttotal: 495ms\tremaining: 2.99s\n",
      "71:\tlearn: 0.3503305\ttotal: 502ms\tremaining: 2.98s\n",
      "72:\tlearn: 0.3484662\ttotal: 507ms\tremaining: 2.96s\n",
      "73:\tlearn: 0.3448958\ttotal: 512ms\tremaining: 2.94s\n",
      "74:\tlearn: 0.3421071\ttotal: 516ms\tremaining: 2.92s\n",
      "75:\tlearn: 0.3402113\ttotal: 521ms\tremaining: 2.91s\n",
      "76:\tlearn: 0.3378619\ttotal: 526ms\tremaining: 2.89s\n",
      "77:\tlearn: 0.3358211\ttotal: 530ms\tremaining: 2.87s\n",
      "78:\tlearn: 0.3331930\ttotal: 535ms\tremaining: 2.85s\n",
      "79:\tlearn: 0.3304277\ttotal: 539ms\tremaining: 2.83s\n",
      "80:\tlearn: 0.3277503\ttotal: 544ms\tremaining: 2.81s\n",
      "81:\tlearn: 0.3255437\ttotal: 548ms\tremaining: 2.79s\n",
      "82:\tlearn: 0.3235180\ttotal: 552ms\tremaining: 2.77s\n",
      "83:\tlearn: 0.3199192\ttotal: 556ms\tremaining: 2.75s\n",
      "84:\tlearn: 0.3177880\ttotal: 560ms\tremaining: 2.73s\n",
      "85:\tlearn: 0.3156609\ttotal: 565ms\tremaining: 2.72s\n",
      "86:\tlearn: 0.3137114\ttotal: 569ms\tremaining: 2.7s\n",
      "87:\tlearn: 0.3105339\ttotal: 573ms\tremaining: 2.68s\n",
      "88:\tlearn: 0.3086486\ttotal: 586ms\tremaining: 2.71s\n",
      "89:\tlearn: 0.3062188\ttotal: 596ms\tremaining: 2.71s\n",
      "90:\tlearn: 0.3044253\ttotal: 606ms\tremaining: 2.72s\n",
      "91:\tlearn: 0.3024056\ttotal: 615ms\tremaining: 2.73s\n",
      "92:\tlearn: 0.3007245\ttotal: 626ms\tremaining: 2.74s\n",
      "93:\tlearn: 0.2987518\ttotal: 635ms\tremaining: 2.74s\n",
      "94:\tlearn: 0.2962322\ttotal: 645ms\tremaining: 2.75s\n",
      "95:\tlearn: 0.2941883\ttotal: 652ms\tremaining: 2.74s\n",
      "96:\tlearn: 0.2918282\ttotal: 658ms\tremaining: 2.73s\n",
      "97:\tlearn: 0.2900236\ttotal: 665ms\tremaining: 2.73s\n",
      "98:\tlearn: 0.2880212\ttotal: 671ms\tremaining: 2.72s\n",
      "99:\tlearn: 0.2859231\ttotal: 677ms\tremaining: 2.71s\n",
      "100:\tlearn: 0.2842746\ttotal: 682ms\tremaining: 2.69s\n",
      "101:\tlearn: 0.2824266\ttotal: 687ms\tremaining: 2.68s\n",
      "102:\tlearn: 0.2808851\ttotal: 692ms\tremaining: 2.67s\n",
      "103:\tlearn: 0.2791256\ttotal: 696ms\tremaining: 2.65s\n",
      "104:\tlearn: 0.2773588\ttotal: 700ms\tremaining: 2.63s\n",
      "105:\tlearn: 0.2752843\ttotal: 705ms\tremaining: 2.62s\n",
      "106:\tlearn: 0.2726957\ttotal: 710ms\tremaining: 2.61s\n",
      "107:\tlearn: 0.2707857\ttotal: 714ms\tremaining: 2.59s\n",
      "108:\tlearn: 0.2688304\ttotal: 718ms\tremaining: 2.58s\n",
      "109:\tlearn: 0.2668125\ttotal: 722ms\tremaining: 2.56s\n",
      "110:\tlearn: 0.2650918\ttotal: 727ms\tremaining: 2.55s\n",
      "111:\tlearn: 0.2633632\ttotal: 731ms\tremaining: 2.53s\n",
      "112:\tlearn: 0.2617596\ttotal: 735ms\tremaining: 2.52s\n",
      "113:\tlearn: 0.2603045\ttotal: 739ms\tremaining: 2.5s\n",
      "114:\tlearn: 0.2587984\ttotal: 749ms\tremaining: 2.51s\n",
      "115:\tlearn: 0.2556728\ttotal: 759ms\tremaining: 2.51s\n",
      "116:\tlearn: 0.2534651\ttotal: 768ms\tremaining: 2.52s\n",
      "117:\tlearn: 0.2513428\ttotal: 778ms\tremaining: 2.52s\n",
      "118:\tlearn: 0.2495644\ttotal: 787ms\tremaining: 2.52s\n",
      "119:\tlearn: 0.2479284\ttotal: 797ms\tremaining: 2.52s\n",
      "120:\tlearn: 0.2461973\ttotal: 807ms\tremaining: 2.53s\n",
      "121:\tlearn: 0.2434506\ttotal: 817ms\tremaining: 2.53s\n",
      "122:\tlearn: 0.2418846\ttotal: 823ms\tremaining: 2.52s\n",
      "123:\tlearn: 0.2405215\ttotal: 829ms\tremaining: 2.51s\n",
      "124:\tlearn: 0.2392300\ttotal: 835ms\tremaining: 2.5s\n",
      "125:\tlearn: 0.2379550\ttotal: 842ms\tremaining: 2.5s\n",
      "126:\tlearn: 0.2363647\ttotal: 848ms\tremaining: 2.49s\n",
      "127:\tlearn: 0.2351838\ttotal: 854ms\tremaining: 2.48s\n",
      "128:\tlearn: 0.2334626\ttotal: 859ms\tremaining: 2.47s\n",
      "129:\tlearn: 0.2316172\ttotal: 863ms\tremaining: 2.46s\n",
      "130:\tlearn: 0.2299672\ttotal: 868ms\tremaining: 2.44s\n",
      "131:\tlearn: 0.2288365\ttotal: 872ms\tremaining: 2.43s\n",
      "132:\tlearn: 0.2261770\ttotal: 877ms\tremaining: 2.42s\n",
      "133:\tlearn: 0.2243942\ttotal: 881ms\tremaining: 2.4s\n",
      "134:\tlearn: 0.2226271\ttotal: 885ms\tremaining: 2.39s\n",
      "135:\tlearn: 0.2213984\ttotal: 890ms\tremaining: 2.38s\n",
      "136:\tlearn: 0.2197409\ttotal: 895ms\tremaining: 2.37s\n",
      "137:\tlearn: 0.2184102\ttotal: 899ms\tremaining: 2.36s\n",
      "138:\tlearn: 0.2171715\ttotal: 909ms\tremaining: 2.36s\n",
      "139:\tlearn: 0.2158031\ttotal: 918ms\tremaining: 2.36s\n",
      "140:\tlearn: 0.2142226\ttotal: 928ms\tremaining: 2.36s\n",
      "141:\tlearn: 0.2122346\ttotal: 938ms\tremaining: 2.36s\n",
      "142:\tlearn: 0.2100167\ttotal: 948ms\tremaining: 2.37s\n",
      "143:\tlearn: 0.2087898\ttotal: 956ms\tremaining: 2.36s\n",
      "144:\tlearn: 0.2076882\ttotal: 961ms\tremaining: 2.35s\n",
      "145:\tlearn: 0.2064136\ttotal: 966ms\tremaining: 2.34s\n",
      "146:\tlearn: 0.2052441\ttotal: 971ms\tremaining: 2.33s\n",
      "147:\tlearn: 0.2036635\ttotal: 976ms\tremaining: 2.32s\n",
      "148:\tlearn: 0.2020857\ttotal: 981ms\tremaining: 2.31s\n",
      "149:\tlearn: 0.2009108\ttotal: 986ms\tremaining: 2.3s\n",
      "150:\tlearn: 0.1977025\ttotal: 991ms\tremaining: 2.29s\n",
      "151:\tlearn: 0.1968182\ttotal: 996ms\tremaining: 2.28s\n",
      "152:\tlearn: 0.1958641\ttotal: 1s\tremaining: 2.27s\n",
      "153:\tlearn: 0.1949054\ttotal: 1s\tremaining: 2.26s\n",
      "154:\tlearn: 0.1937347\ttotal: 1.01s\tremaining: 2.25s\n",
      "155:\tlearn: 0.1913223\ttotal: 1.01s\tremaining: 2.23s\n",
      "156:\tlearn: 0.1902454\ttotal: 1.02s\tremaining: 2.22s\n",
      "157:\tlearn: 0.1892106\ttotal: 1.02s\tremaining: 2.21s\n",
      "158:\tlearn: 0.1881021\ttotal: 1.03s\tremaining: 2.2s\n",
      "159:\tlearn: 0.1860419\ttotal: 1.03s\tremaining: 2.19s\n",
      "160:\tlearn: 0.1846168\ttotal: 1.03s\tremaining: 2.18s\n",
      "161:\tlearn: 0.1835392\ttotal: 1.04s\tremaining: 2.17s\n",
      "162:\tlearn: 0.1826210\ttotal: 1.04s\tremaining: 2.16s\n",
      "163:\tlearn: 0.1816271\ttotal: 1.05s\tremaining: 2.16s\n",
      "164:\tlearn: 0.1806010\ttotal: 1.06s\tremaining: 2.16s\n",
      "165:\tlearn: 0.1795660\ttotal: 1.07s\tremaining: 2.16s\n",
      "166:\tlearn: 0.1785845\ttotal: 1.08s\tremaining: 2.16s\n",
      "167:\tlearn: 0.1776679\ttotal: 1.09s\tremaining: 2.16s\n",
      "168:\tlearn: 0.1767258\ttotal: 1.1s\tremaining: 2.16s\n",
      "169:\tlearn: 0.1755901\ttotal: 1.11s\tremaining: 2.16s\n",
      "170:\tlearn: 0.1746941\ttotal: 1.12s\tremaining: 2.15s\n",
      "171:\tlearn: 0.1737412\ttotal: 1.13s\tremaining: 2.15s\n",
      "172:\tlearn: 0.1727948\ttotal: 1.13s\tremaining: 2.13s\n",
      "173:\tlearn: 0.1716844\ttotal: 1.13s\tremaining: 2.12s\n",
      "174:\tlearn: 0.1711327\ttotal: 1.14s\tremaining: 2.11s\n",
      "175:\tlearn: 0.1702557\ttotal: 1.14s\tremaining: 2.1s\n",
      "176:\tlearn: 0.1691090\ttotal: 1.15s\tremaining: 2.09s\n",
      "177:\tlearn: 0.1682832\ttotal: 1.15s\tremaining: 2.08s\n",
      "178:\tlearn: 0.1665834\ttotal: 1.16s\tremaining: 2.07s\n",
      "179:\tlearn: 0.1659729\ttotal: 1.16s\tremaining: 2.06s\n",
      "180:\tlearn: 0.1652097\ttotal: 1.17s\tremaining: 2.05s\n",
      "181:\tlearn: 0.1643102\ttotal: 1.17s\tremaining: 2.04s\n",
      "182:\tlearn: 0.1633961\ttotal: 1.17s\tremaining: 2.03s\n",
      "183:\tlearn: 0.1619881\ttotal: 1.18s\tremaining: 2.02s\n",
      "184:\tlearn: 0.1612131\ttotal: 1.18s\tremaining: 2.01s\n",
      "185:\tlearn: 0.1602164\ttotal: 1.19s\tremaining: 2.01s\n",
      "186:\tlearn: 0.1590952\ttotal: 1.2s\tremaining: 2.01s\n",
      "187:\tlearn: 0.1574511\ttotal: 1.21s\tremaining: 2.01s\n",
      "188:\tlearn: 0.1566550\ttotal: 1.22s\tremaining: 2.01s\n",
      "189:\tlearn: 0.1558843\ttotal: 1.23s\tremaining: 2.01s\n",
      "190:\tlearn: 0.1550060\ttotal: 1.24s\tremaining: 2.01s\n",
      "191:\tlearn: 0.1541424\ttotal: 1.25s\tremaining: 2.01s\n",
      "192:\tlearn: 0.1532384\ttotal: 1.26s\tremaining: 2s\n",
      "193:\tlearn: 0.1524886\ttotal: 1.26s\tremaining: 2s\n",
      "194:\tlearn: 0.1514733\ttotal: 1.27s\tremaining: 1.99s\n",
      "195:\tlearn: 0.1505352\ttotal: 1.28s\tremaining: 1.98s\n",
      "196:\tlearn: 0.1495792\ttotal: 1.28s\tremaining: 1.98s\n",
      "197:\tlearn: 0.1487992\ttotal: 1.29s\tremaining: 1.97s\n",
      "198:\tlearn: 0.1480233\ttotal: 1.29s\tremaining: 1.96s\n",
      "199:\tlearn: 0.1470813\ttotal: 1.3s\tremaining: 1.95s\n",
      "200:\tlearn: 0.1462374\ttotal: 1.3s\tremaining: 1.94s\n",
      "201:\tlearn: 0.1453396\ttotal: 1.31s\tremaining: 1.93s\n",
      "202:\tlearn: 0.1436635\ttotal: 1.31s\tremaining: 1.92s\n",
      "203:\tlearn: 0.1426903\ttotal: 1.32s\tremaining: 1.92s\n",
      "204:\tlearn: 0.1412278\ttotal: 1.32s\tremaining: 1.91s\n",
      "205:\tlearn: 0.1403026\ttotal: 1.33s\tremaining: 1.9s\n",
      "206:\tlearn: 0.1395833\ttotal: 1.33s\tremaining: 1.89s\n",
      "207:\tlearn: 0.1388860\ttotal: 1.34s\tremaining: 1.88s\n",
      "208:\tlearn: 0.1381827\ttotal: 1.34s\tremaining: 1.87s\n",
      "209:\tlearn: 0.1372318\ttotal: 1.35s\tremaining: 1.86s\n",
      "210:\tlearn: 0.1364517\ttotal: 1.35s\tremaining: 1.85s\n",
      "211:\tlearn: 0.1356809\ttotal: 1.36s\tremaining: 1.85s\n",
      "212:\tlearn: 0.1349624\ttotal: 1.37s\tremaining: 1.84s\n",
      "213:\tlearn: 0.1343008\ttotal: 1.38s\tremaining: 1.84s\n",
      "214:\tlearn: 0.1335135\ttotal: 1.39s\tremaining: 1.84s\n",
      "215:\tlearn: 0.1328346\ttotal: 1.4s\tremaining: 1.84s\n",
      "216:\tlearn: 0.1321165\ttotal: 1.41s\tremaining: 1.84s\n",
      "217:\tlearn: 0.1314196\ttotal: 1.42s\tremaining: 1.83s\n",
      "218:\tlearn: 0.1308176\ttotal: 1.43s\tremaining: 1.83s\n",
      "219:\tlearn: 0.1297198\ttotal: 1.43s\tremaining: 1.82s\n",
      "220:\tlearn: 0.1282941\ttotal: 1.44s\tremaining: 1.82s\n",
      "221:\tlearn: 0.1276785\ttotal: 1.45s\tremaining: 1.81s\n",
      "222:\tlearn: 0.1269064\ttotal: 1.45s\tremaining: 1.8s\n",
      "223:\tlearn: 0.1263345\ttotal: 1.46s\tremaining: 1.8s\n",
      "224:\tlearn: 0.1257351\ttotal: 1.46s\tremaining: 1.79s\n",
      "225:\tlearn: 0.1253710\ttotal: 1.47s\tremaining: 1.78s\n",
      "226:\tlearn: 0.1246390\ttotal: 1.48s\tremaining: 1.77s\n",
      "227:\tlearn: 0.1240325\ttotal: 1.48s\tremaining: 1.76s\n",
      "228:\tlearn: 0.1234495\ttotal: 1.48s\tremaining: 1.76s\n",
      "229:\tlearn: 0.1226143\ttotal: 1.49s\tremaining: 1.75s\n",
      "230:\tlearn: 0.1220320\ttotal: 1.49s\tremaining: 1.74s\n",
      "231:\tlearn: 0.1214328\ttotal: 1.5s\tremaining: 1.73s\n",
      "232:\tlearn: 0.1208356\ttotal: 1.5s\tremaining: 1.72s\n",
      "233:\tlearn: 0.1198271\ttotal: 1.51s\tremaining: 1.71s\n",
      "234:\tlearn: 0.1193159\ttotal: 1.51s\tremaining: 1.7s\n",
      "235:\tlearn: 0.1186909\ttotal: 1.51s\tremaining: 1.69s\n",
      "236:\tlearn: 0.1178200\ttotal: 1.52s\tremaining: 1.69s\n",
      "237:\tlearn: 0.1172560\ttotal: 1.53s\tremaining: 1.69s\n",
      "238:\tlearn: 0.1166823\ttotal: 1.54s\tremaining: 1.69s\n",
      "239:\tlearn: 0.1158228\ttotal: 1.55s\tremaining: 1.68s\n",
      "240:\tlearn: 0.1153018\ttotal: 1.56s\tremaining: 1.68s\n",
      "241:\tlearn: 0.1147555\ttotal: 1.57s\tremaining: 1.68s\n",
      "242:\tlearn: 0.1142055\ttotal: 1.58s\tremaining: 1.67s\n",
      "243:\tlearn: 0.1136301\ttotal: 1.59s\tremaining: 1.67s\n",
      "244:\tlearn: 0.1130744\ttotal: 1.6s\tremaining: 1.67s\n",
      "245:\tlearn: 0.1121917\ttotal: 1.61s\tremaining: 1.66s\n",
      "246:\tlearn: 0.1114568\ttotal: 1.61s\tremaining: 1.65s\n",
      "247:\tlearn: 0.1102769\ttotal: 1.62s\tremaining: 1.65s\n",
      "248:\tlearn: 0.1097802\ttotal: 1.63s\tremaining: 1.64s\n",
      "249:\tlearn: 0.1092660\ttotal: 1.63s\tremaining: 1.63s\n",
      "250:\tlearn: 0.1085891\ttotal: 1.64s\tremaining: 1.63s\n",
      "251:\tlearn: 0.1080569\ttotal: 1.64s\tremaining: 1.62s\n",
      "252:\tlearn: 0.1076179\ttotal: 1.65s\tremaining: 1.61s\n",
      "253:\tlearn: 0.1071202\ttotal: 1.65s\tremaining: 1.6s\n",
      "254:\tlearn: 0.1065611\ttotal: 1.66s\tremaining: 1.59s\n",
      "255:\tlearn: 0.1061317\ttotal: 1.66s\tremaining: 1.58s\n",
      "256:\tlearn: 0.1055339\ttotal: 1.67s\tremaining: 1.58s\n",
      "257:\tlearn: 0.1049422\ttotal: 1.67s\tremaining: 1.57s\n",
      "258:\tlearn: 0.1044040\ttotal: 1.68s\tremaining: 1.56s\n",
      "259:\tlearn: 0.1034957\ttotal: 1.68s\tremaining: 1.55s\n",
      "260:\tlearn: 0.1030055\ttotal: 1.68s\tremaining: 1.54s\n",
      "261:\tlearn: 0.1025381\ttotal: 1.69s\tremaining: 1.54s\n",
      "262:\tlearn: 0.1020257\ttotal: 1.7s\tremaining: 1.53s\n",
      "263:\tlearn: 0.1014729\ttotal: 1.71s\tremaining: 1.53s\n",
      "264:\tlearn: 0.1010855\ttotal: 1.72s\tremaining: 1.53s\n",
      "265:\tlearn: 0.1004011\ttotal: 1.73s\tremaining: 1.52s\n",
      "266:\tlearn: 0.1000672\ttotal: 1.74s\tremaining: 1.52s\n",
      "267:\tlearn: 0.0994815\ttotal: 1.75s\tremaining: 1.52s\n",
      "268:\tlearn: 0.0989420\ttotal: 1.76s\tremaining: 1.51s\n",
      "269:\tlearn: 0.0985046\ttotal: 1.77s\tremaining: 1.51s\n",
      "270:\tlearn: 0.0980126\ttotal: 1.78s\tremaining: 1.5s\n",
      "271:\tlearn: 0.0971291\ttotal: 1.79s\tremaining: 1.5s\n",
      "272:\tlearn: 0.0966369\ttotal: 1.79s\tremaining: 1.49s\n",
      "273:\tlearn: 0.0960853\ttotal: 1.8s\tremaining: 1.48s\n",
      "274:\tlearn: 0.0956642\ttotal: 1.8s\tremaining: 1.48s\n",
      "275:\tlearn: 0.0953462\ttotal: 1.81s\tremaining: 1.47s\n",
      "276:\tlearn: 0.0948574\ttotal: 1.81s\tremaining: 1.46s\n",
      "277:\tlearn: 0.0944659\ttotal: 1.82s\tremaining: 1.45s\n",
      "278:\tlearn: 0.0940033\ttotal: 1.82s\tremaining: 1.45s\n",
      "279:\tlearn: 0.0935847\ttotal: 1.83s\tremaining: 1.44s\n",
      "280:\tlearn: 0.0931300\ttotal: 1.84s\tremaining: 1.43s\n",
      "281:\tlearn: 0.0926483\ttotal: 1.84s\tremaining: 1.42s\n",
      "282:\tlearn: 0.0921701\ttotal: 1.84s\tremaining: 1.42s\n",
      "283:\tlearn: 0.0917491\ttotal: 1.85s\tremaining: 1.41s\n",
      "284:\tlearn: 0.0913442\ttotal: 1.85s\tremaining: 1.4s\n",
      "285:\tlearn: 0.0909656\ttotal: 1.86s\tremaining: 1.39s\n",
      "286:\tlearn: 0.0907368\ttotal: 1.86s\tremaining: 1.38s\n",
      "287:\tlearn: 0.0902233\ttotal: 1.87s\tremaining: 1.37s\n",
      "288:\tlearn: 0.0897756\ttotal: 1.87s\tremaining: 1.37s\n",
      "289:\tlearn: 0.0893358\ttotal: 1.88s\tremaining: 1.36s\n",
      "290:\tlearn: 0.0890695\ttotal: 1.88s\tremaining: 1.35s\n",
      "291:\tlearn: 0.0886148\ttotal: 1.89s\tremaining: 1.34s\n",
      "292:\tlearn: 0.0882378\ttotal: 1.89s\tremaining: 1.33s\n",
      "293:\tlearn: 0.0878389\ttotal: 1.9s\tremaining: 1.33s\n",
      "294:\tlearn: 0.0873760\ttotal: 1.91s\tremaining: 1.33s\n",
      "295:\tlearn: 0.0871584\ttotal: 1.92s\tremaining: 1.32s\n",
      "296:\tlearn: 0.0868272\ttotal: 1.93s\tremaining: 1.32s\n",
      "297:\tlearn: 0.0862884\ttotal: 1.94s\tremaining: 1.31s\n",
      "298:\tlearn: 0.0857240\ttotal: 1.95s\tremaining: 1.31s\n",
      "299:\tlearn: 0.0853319\ttotal: 1.96s\tremaining: 1.3s\n",
      "300:\tlearn: 0.0848886\ttotal: 1.97s\tremaining: 1.3s\n",
      "301:\tlearn: 0.0845418\ttotal: 1.97s\tremaining: 1.29s\n",
      "302:\tlearn: 0.0841521\ttotal: 1.98s\tremaining: 1.29s\n",
      "303:\tlearn: 0.0835954\ttotal: 1.99s\tremaining: 1.28s\n",
      "304:\tlearn: 0.0831635\ttotal: 1.99s\tremaining: 1.27s\n",
      "305:\tlearn: 0.0828122\ttotal: 2s\tremaining: 1.27s\n",
      "306:\tlearn: 0.0824115\ttotal: 2s\tremaining: 1.26s\n",
      "307:\tlearn: 0.0815777\ttotal: 2.01s\tremaining: 1.25s\n",
      "308:\tlearn: 0.0811956\ttotal: 2.01s\tremaining: 1.24s\n",
      "309:\tlearn: 0.0807952\ttotal: 2.02s\tremaining: 1.24s\n",
      "310:\tlearn: 0.0803604\ttotal: 2.02s\tremaining: 1.23s\n",
      "311:\tlearn: 0.0800066\ttotal: 2.03s\tremaining: 1.22s\n",
      "312:\tlearn: 0.0795176\ttotal: 2.03s\tremaining: 1.21s\n",
      "313:\tlearn: 0.0790982\ttotal: 2.04s\tremaining: 1.21s\n",
      "314:\tlearn: 0.0787959\ttotal: 2.04s\tremaining: 1.2s\n",
      "315:\tlearn: 0.0784403\ttotal: 2.04s\tremaining: 1.19s\n",
      "316:\tlearn: 0.0780302\ttotal: 2.05s\tremaining: 1.18s\n",
      "317:\tlearn: 0.0776548\ttotal: 2.05s\tremaining: 1.18s\n",
      "318:\tlearn: 0.0769595\ttotal: 2.06s\tremaining: 1.17s\n",
      "319:\tlearn: 0.0765279\ttotal: 2.06s\tremaining: 1.16s\n",
      "320:\tlearn: 0.0761221\ttotal: 2.07s\tremaining: 1.16s\n",
      "321:\tlearn: 0.0757677\ttotal: 2.08s\tremaining: 1.15s\n",
      "322:\tlearn: 0.0754698\ttotal: 2.09s\tremaining: 1.15s\n",
      "323:\tlearn: 0.0747582\ttotal: 2.1s\tremaining: 1.14s\n",
      "324:\tlearn: 0.0743944\ttotal: 2.11s\tremaining: 1.14s\n",
      "325:\tlearn: 0.0740657\ttotal: 2.12s\tremaining: 1.13s\n",
      "326:\tlearn: 0.0737679\ttotal: 2.13s\tremaining: 1.13s\n",
      "327:\tlearn: 0.0734872\ttotal: 2.14s\tremaining: 1.12s\n",
      "328:\tlearn: 0.0731621\ttotal: 2.15s\tremaining: 1.12s\n",
      "329:\tlearn: 0.0728396\ttotal: 2.16s\tremaining: 1.11s\n",
      "330:\tlearn: 0.0724890\ttotal: 2.16s\tremaining: 1.1s\n",
      "331:\tlearn: 0.0721853\ttotal: 2.17s\tremaining: 1.1s\n",
      "332:\tlearn: 0.0719073\ttotal: 2.18s\tremaining: 1.09s\n",
      "333:\tlearn: 0.0715814\ttotal: 2.18s\tremaining: 1.08s\n",
      "334:\tlearn: 0.0712119\ttotal: 2.19s\tremaining: 1.08s\n",
      "335:\tlearn: 0.0708911\ttotal: 2.19s\tremaining: 1.07s\n",
      "336:\tlearn: 0.0705950\ttotal: 2.2s\tremaining: 1.06s\n",
      "337:\tlearn: 0.0702574\ttotal: 2.2s\tremaining: 1.05s\n",
      "338:\tlearn: 0.0699077\ttotal: 2.21s\tremaining: 1.05s\n",
      "339:\tlearn: 0.0696178\ttotal: 2.21s\tremaining: 1.04s\n",
      "340:\tlearn: 0.0693087\ttotal: 2.21s\tremaining: 1.03s\n",
      "341:\tlearn: 0.0689504\ttotal: 2.22s\tremaining: 1.02s\n",
      "342:\tlearn: 0.0685294\ttotal: 2.22s\tremaining: 1.02s\n",
      "343:\tlearn: 0.0681890\ttotal: 2.23s\tremaining: 1.01s\n",
      "344:\tlearn: 0.0679271\ttotal: 2.23s\tremaining: 1s\n",
      "345:\tlearn: 0.0674692\ttotal: 2.24s\tremaining: 995ms\n",
      "346:\tlearn: 0.0671700\ttotal: 2.24s\tremaining: 988ms\n",
      "347:\tlearn: 0.0669199\ttotal: 2.24s\tremaining: 981ms\n",
      "348:\tlearn: 0.0666148\ttotal: 2.25s\tremaining: 973ms\n",
      "349:\tlearn: 0.0664580\ttotal: 2.25s\tremaining: 966ms\n",
      "350:\tlearn: 0.0661535\ttotal: 2.26s\tremaining: 961ms\n",
      "351:\tlearn: 0.0657365\ttotal: 2.27s\tremaining: 955ms\n",
      "352:\tlearn: 0.0653758\ttotal: 2.28s\tremaining: 950ms\n",
      "353:\tlearn: 0.0650809\ttotal: 2.29s\tremaining: 945ms\n",
      "354:\tlearn: 0.0648268\ttotal: 2.3s\tremaining: 940ms\n",
      "355:\tlearn: 0.0643555\ttotal: 2.31s\tremaining: 935ms\n",
      "356:\tlearn: 0.0641691\ttotal: 2.32s\tremaining: 930ms\n",
      "357:\tlearn: 0.0639857\ttotal: 2.33s\tremaining: 924ms\n",
      "358:\tlearn: 0.0637344\ttotal: 2.34s\tremaining: 919ms\n",
      "359:\tlearn: 0.0633958\ttotal: 2.35s\tremaining: 913ms\n",
      "360:\tlearn: 0.0630412\ttotal: 2.35s\tremaining: 906ms\n",
      "361:\tlearn: 0.0627772\ttotal: 2.36s\tremaining: 900ms\n",
      "362:\tlearn: 0.0624643\ttotal: 2.37s\tremaining: 893ms\n",
      "363:\tlearn: 0.0620947\ttotal: 2.37s\tremaining: 887ms\n",
      "364:\tlearn: 0.0618264\ttotal: 2.38s\tremaining: 880ms\n",
      "365:\tlearn: 0.0616009\ttotal: 2.38s\tremaining: 873ms\n",
      "366:\tlearn: 0.0612680\ttotal: 2.39s\tremaining: 866ms\n",
      "367:\tlearn: 0.0608608\ttotal: 2.4s\tremaining: 859ms\n",
      "368:\tlearn: 0.0605819\ttotal: 2.4s\tremaining: 852ms\n",
      "369:\tlearn: 0.0603301\ttotal: 2.4s\tremaining: 845ms\n",
      "370:\tlearn: 0.0600908\ttotal: 2.41s\tremaining: 837ms\n",
      "371:\tlearn: 0.0596885\ttotal: 2.41s\tremaining: 830ms\n",
      "372:\tlearn: 0.0596631\ttotal: 2.42s\tremaining: 823ms\n",
      "373:\tlearn: 0.0593827\ttotal: 2.42s\tremaining: 815ms\n",
      "374:\tlearn: 0.0590773\ttotal: 2.42s\tremaining: 808ms\n",
      "375:\tlearn: 0.0588056\ttotal: 2.43s\tremaining: 801ms\n",
      "376:\tlearn: 0.0585906\ttotal: 2.44s\tremaining: 796ms\n",
      "377:\tlearn: 0.0583411\ttotal: 2.45s\tremaining: 790ms\n",
      "378:\tlearn: 0.0580673\ttotal: 2.46s\tremaining: 785ms\n",
      "379:\tlearn: 0.0577984\ttotal: 2.47s\tremaining: 779ms\n",
      "380:\tlearn: 0.0575672\ttotal: 2.48s\tremaining: 774ms\n",
      "381:\tlearn: 0.0572761\ttotal: 2.49s\tremaining: 768ms\n",
      "382:\tlearn: 0.0570999\ttotal: 2.5s\tremaining: 763ms\n",
      "383:\tlearn: 0.0567485\ttotal: 2.51s\tremaining: 757ms\n",
      "384:\tlearn: 0.0564832\ttotal: 2.51s\tremaining: 751ms\n",
      "385:\tlearn: 0.0564639\ttotal: 2.52s\tremaining: 744ms\n",
      "386:\tlearn: 0.0558753\ttotal: 2.53s\tremaining: 738ms\n",
      "387:\tlearn: 0.0555380\ttotal: 2.53s\tremaining: 731ms\n",
      "388:\tlearn: 0.0552068\ttotal: 2.54s\tremaining: 724ms\n",
      "389:\tlearn: 0.0549753\ttotal: 2.54s\tremaining: 717ms\n",
      "390:\tlearn: 0.0547123\ttotal: 2.55s\tremaining: 710ms\n",
      "391:\tlearn: 0.0544782\ttotal: 2.55s\tremaining: 703ms\n",
      "392:\tlearn: 0.0542739\ttotal: 2.56s\tremaining: 696ms\n",
      "393:\tlearn: 0.0539859\ttotal: 2.56s\tremaining: 690ms\n",
      "394:\tlearn: 0.0537568\ttotal: 2.57s\tremaining: 682ms\n",
      "395:\tlearn: 0.0533560\ttotal: 2.57s\tremaining: 675ms\n",
      "396:\tlearn: 0.0531319\ttotal: 2.57s\tremaining: 668ms\n",
      "397:\tlearn: 0.0527022\ttotal: 2.58s\tremaining: 661ms\n",
      "398:\tlearn: 0.0523090\ttotal: 2.58s\tremaining: 654ms\n",
      "399:\tlearn: 0.0521202\ttotal: 2.59s\tremaining: 647ms\n",
      "400:\tlearn: 0.0518540\ttotal: 2.59s\tremaining: 640ms\n",
      "401:\tlearn: 0.0516314\ttotal: 2.6s\tremaining: 633ms\n",
      "402:\tlearn: 0.0514026\ttotal: 2.6s\tremaining: 627ms\n",
      "403:\tlearn: 0.0512013\ttotal: 2.61s\tremaining: 621ms\n",
      "404:\tlearn: 0.0509214\ttotal: 2.62s\tremaining: 616ms\n",
      "405:\tlearn: 0.0506928\ttotal: 2.63s\tremaining: 610ms\n",
      "406:\tlearn: 0.0505087\ttotal: 2.64s\tremaining: 604ms\n",
      "407:\tlearn: 0.0503212\ttotal: 2.65s\tremaining: 598ms\n",
      "408:\tlearn: 0.0499963\ttotal: 2.66s\tremaining: 592ms\n",
      "409:\tlearn: 0.0497480\ttotal: 2.67s\tremaining: 587ms\n",
      "410:\tlearn: 0.0495207\ttotal: 2.68s\tremaining: 581ms\n",
      "411:\tlearn: 0.0492763\ttotal: 2.69s\tremaining: 574ms\n",
      "412:\tlearn: 0.0490958\ttotal: 2.69s\tremaining: 568ms\n",
      "413:\tlearn: 0.0488882\ttotal: 2.7s\tremaining: 561ms\n",
      "414:\tlearn: 0.0486072\ttotal: 2.71s\tremaining: 555ms\n",
      "415:\tlearn: 0.0483846\ttotal: 2.71s\tremaining: 548ms\n",
      "416:\tlearn: 0.0481608\ttotal: 2.72s\tremaining: 541ms\n",
      "417:\tlearn: 0.0479341\ttotal: 2.72s\tremaining: 534ms\n",
      "418:\tlearn: 0.0476427\ttotal: 2.73s\tremaining: 528ms\n",
      "419:\tlearn: 0.0474534\ttotal: 2.73s\tremaining: 521ms\n",
      "420:\tlearn: 0.0472525\ttotal: 2.74s\tremaining: 514ms\n",
      "421:\tlearn: 0.0471639\ttotal: 2.74s\tremaining: 507ms\n",
      "422:\tlearn: 0.0469837\ttotal: 2.75s\tremaining: 500ms\n",
      "423:\tlearn: 0.0468060\ttotal: 2.75s\tremaining: 493ms\n",
      "424:\tlearn: 0.0466563\ttotal: 2.75s\tremaining: 486ms\n",
      "425:\tlearn: 0.0464571\ttotal: 2.76s\tremaining: 479ms\n",
      "426:\tlearn: 0.0463003\ttotal: 2.76s\tremaining: 473ms\n",
      "427:\tlearn: 0.0461609\ttotal: 2.77s\tremaining: 466ms\n",
      "428:\tlearn: 0.0459362\ttotal: 2.78s\tremaining: 460ms\n",
      "429:\tlearn: 0.0457406\ttotal: 2.79s\tremaining: 454ms\n",
      "430:\tlearn: 0.0455390\ttotal: 2.8s\tremaining: 448ms\n",
      "431:\tlearn: 0.0453267\ttotal: 2.81s\tremaining: 442ms\n",
      "432:\tlearn: 0.0451391\ttotal: 2.82s\tremaining: 436ms\n",
      "433:\tlearn: 0.0449264\ttotal: 2.83s\tremaining: 430ms\n",
      "434:\tlearn: 0.0447067\ttotal: 2.84s\tremaining: 424ms\n",
      "435:\tlearn: 0.0445335\ttotal: 2.85s\tremaining: 418ms\n",
      "436:\tlearn: 0.0443460\ttotal: 2.85s\tremaining: 412ms\n",
      "437:\tlearn: 0.0441514\ttotal: 2.86s\tremaining: 405ms\n",
      "438:\tlearn: 0.0440420\ttotal: 2.87s\tremaining: 399ms\n",
      "439:\tlearn: 0.0438416\ttotal: 2.88s\tremaining: 392ms\n",
      "440:\tlearn: 0.0436907\ttotal: 2.88s\tremaining: 385ms\n",
      "441:\tlearn: 0.0435375\ttotal: 2.89s\tremaining: 379ms\n",
      "442:\tlearn: 0.0434722\ttotal: 2.89s\tremaining: 372ms\n",
      "443:\tlearn: 0.0432788\ttotal: 2.9s\tremaining: 365ms\n",
      "444:\tlearn: 0.0430079\ttotal: 2.9s\tremaining: 359ms\n",
      "445:\tlearn: 0.0428358\ttotal: 2.91s\tremaining: 352ms\n",
      "446:\tlearn: 0.0425978\ttotal: 2.91s\tremaining: 345ms\n",
      "447:\tlearn: 0.0422651\ttotal: 2.92s\tremaining: 338ms\n",
      "448:\tlearn: 0.0420919\ttotal: 2.92s\tremaining: 332ms\n",
      "449:\tlearn: 0.0419010\ttotal: 2.92s\tremaining: 325ms\n",
      "450:\tlearn: 0.0417279\ttotal: 2.93s\tremaining: 318ms\n",
      "451:\tlearn: 0.0415699\ttotal: 2.93s\tremaining: 311ms\n",
      "452:\tlearn: 0.0413865\ttotal: 2.94s\tremaining: 305ms\n",
      "453:\tlearn: 0.0410824\ttotal: 2.95s\tremaining: 299ms\n",
      "454:\tlearn: 0.0408991\ttotal: 2.96s\tremaining: 293ms\n",
      "455:\tlearn: 0.0407451\ttotal: 2.97s\tremaining: 286ms\n",
      "456:\tlearn: 0.0406883\ttotal: 2.98s\tremaining: 280ms\n",
      "457:\tlearn: 0.0405061\ttotal: 2.99s\tremaining: 274ms\n",
      "458:\tlearn: 0.0403591\ttotal: 3s\tremaining: 268ms\n",
      "459:\tlearn: 0.0401670\ttotal: 3.01s\tremaining: 261ms\n",
      "460:\tlearn: 0.0400108\ttotal: 3.02s\tremaining: 255ms\n",
      "461:\tlearn: 0.0398250\ttotal: 3.02s\tremaining: 249ms\n",
      "462:\tlearn: 0.0397306\ttotal: 3.03s\tremaining: 243ms\n",
      "463:\tlearn: 0.0395802\ttotal: 3.04s\tremaining: 236ms\n",
      "464:\tlearn: 0.0394388\ttotal: 3.05s\tremaining: 229ms\n",
      "465:\tlearn: 0.0392154\ttotal: 3.05s\tremaining: 223ms\n",
      "466:\tlearn: 0.0390211\ttotal: 3.06s\tremaining: 216ms\n",
      "467:\tlearn: 0.0388086\ttotal: 3.06s\tremaining: 210ms\n",
      "468:\tlearn: 0.0386281\ttotal: 3.07s\tremaining: 203ms\n",
      "469:\tlearn: 0.0384503\ttotal: 3.07s\tremaining: 196ms\n",
      "470:\tlearn: 0.0382113\ttotal: 3.08s\tremaining: 190ms\n",
      "471:\tlearn: 0.0379462\ttotal: 3.08s\tremaining: 183ms\n",
      "472:\tlearn: 0.0377554\ttotal: 3.09s\tremaining: 176ms\n",
      "473:\tlearn: 0.0376112\ttotal: 3.09s\tremaining: 170ms\n",
      "474:\tlearn: 0.0373807\ttotal: 3.1s\tremaining: 163ms\n",
      "475:\tlearn: 0.0372348\ttotal: 3.1s\tremaining: 156ms\n",
      "476:\tlearn: 0.0370517\ttotal: 3.11s\tremaining: 150ms\n",
      "477:\tlearn: 0.0368768\ttotal: 3.11s\tremaining: 143ms\n",
      "478:\tlearn: 0.0366895\ttotal: 3.12s\tremaining: 137ms\n",
      "479:\tlearn: 0.0364874\ttotal: 3.13s\tremaining: 131ms\n",
      "480:\tlearn: 0.0363804\ttotal: 3.14s\tremaining: 124ms\n",
      "481:\tlearn: 0.0362926\ttotal: 3.15s\tremaining: 118ms\n",
      "482:\tlearn: 0.0361376\ttotal: 3.16s\tremaining: 111ms\n",
      "483:\tlearn: 0.0360517\ttotal: 3.17s\tremaining: 105ms\n",
      "484:\tlearn: 0.0359088\ttotal: 3.18s\tremaining: 98.4ms\n",
      "485:\tlearn: 0.0357707\ttotal: 3.19s\tremaining: 92ms\n",
      "486:\tlearn: 0.0356400\ttotal: 3.2s\tremaining: 85.5ms\n",
      "487:\tlearn: 0.0354858\ttotal: 3.21s\tremaining: 78.9ms\n",
      "488:\tlearn: 0.0353444\ttotal: 3.21s\tremaining: 72.3ms\n",
      "489:\tlearn: 0.0350808\ttotal: 3.22s\tremaining: 65.7ms\n",
      "490:\tlearn: 0.0349488\ttotal: 3.23s\tremaining: 59.2ms\n",
      "491:\tlearn: 0.0347798\ttotal: 3.23s\tremaining: 52.6ms\n",
      "492:\tlearn: 0.0345886\ttotal: 3.24s\tremaining: 46ms\n",
      "493:\tlearn: 0.0344645\ttotal: 3.24s\tremaining: 39.4ms\n",
      "494:\tlearn: 0.0343203\ttotal: 3.25s\tremaining: 32.8ms\n",
      "495:\tlearn: 0.0341878\ttotal: 3.25s\tremaining: 26.2ms\n",
      "496:\tlearn: 0.0340736\ttotal: 3.26s\tremaining: 19.7ms\n",
      "497:\tlearn: 0.0338806\ttotal: 3.26s\tremaining: 13.1ms\n",
      "498:\tlearn: 0.0337481\ttotal: 3.27s\tremaining: 6.54ms\n",
      "499:\tlearn: 0.0335734\ttotal: 3.27s\tremaining: 0us\n",
      "0:\tlearn: 0.6806276\ttotal: 4.71ms\tremaining: 2.35s\n",
      "1:\tlearn: 0.6675337\ttotal: 8.84ms\tremaining: 2.2s\n",
      "2:\tlearn: 0.6540761\ttotal: 12.9ms\tremaining: 2.14s\n",
      "3:\tlearn: 0.6443040\ttotal: 17.5ms\tremaining: 2.17s\n",
      "4:\tlearn: 0.6364167\ttotal: 21.9ms\tremaining: 2.17s\n",
      "5:\tlearn: 0.6259309\ttotal: 26.2ms\tremaining: 2.16s\n",
      "6:\tlearn: 0.6145344\ttotal: 30.4ms\tremaining: 2.14s\n",
      "7:\tlearn: 0.6066004\ttotal: 40.1ms\tremaining: 2.46s\n",
      "8:\tlearn: 0.6001347\ttotal: 49.8ms\tremaining: 2.72s\n",
      "9:\tlearn: 0.5946575\ttotal: 59.4ms\tremaining: 2.91s\n",
      "10:\tlearn: 0.5870284\ttotal: 69.4ms\tremaining: 3.08s\n",
      "11:\tlearn: 0.5780008\ttotal: 78.9ms\tremaining: 3.21s\n",
      "12:\tlearn: 0.5703831\ttotal: 88.2ms\tremaining: 3.3s\n",
      "13:\tlearn: 0.5627239\ttotal: 97.7ms\tremaining: 3.39s\n",
      "14:\tlearn: 0.5570877\ttotal: 107ms\tremaining: 3.47s\n",
      "15:\tlearn: 0.5479584\ttotal: 117ms\tremaining: 3.53s\n",
      "16:\tlearn: 0.5424436\ttotal: 127ms\tremaining: 3.6s\n",
      "17:\tlearn: 0.5387876\ttotal: 133ms\tremaining: 3.56s\n",
      "18:\tlearn: 0.5347085\ttotal: 139ms\tremaining: 3.51s\n",
      "19:\tlearn: 0.5289781\ttotal: 145ms\tremaining: 3.47s\n",
      "20:\tlearn: 0.5240136\ttotal: 151ms\tremaining: 3.44s\n",
      "21:\tlearn: 0.5189676\ttotal: 157ms\tremaining: 3.4s\n",
      "22:\tlearn: 0.5144322\ttotal: 162ms\tremaining: 3.35s\n",
      "23:\tlearn: 0.5086644\ttotal: 166ms\tremaining: 3.3s\n",
      "24:\tlearn: 0.5053384\ttotal: 171ms\tremaining: 3.25s\n",
      "25:\tlearn: 0.5004860\ttotal: 176ms\tremaining: 3.2s\n",
      "26:\tlearn: 0.4947347\ttotal: 180ms\tremaining: 3.15s\n",
      "27:\tlearn: 0.4909647\ttotal: 184ms\tremaining: 3.1s\n",
      "28:\tlearn: 0.4866395\ttotal: 188ms\tremaining: 3.05s\n",
      "29:\tlearn: 0.4815874\ttotal: 192ms\tremaining: 3.01s\n",
      "30:\tlearn: 0.4778978\ttotal: 195ms\tremaining: 2.96s\n",
      "31:\tlearn: 0.4751746\ttotal: 199ms\tremaining: 2.91s\n",
      "32:\tlearn: 0.4715839\ttotal: 209ms\tremaining: 2.96s\n",
      "33:\tlearn: 0.4676768\ttotal: 219ms\tremaining: 3s\n",
      "34:\tlearn: 0.4645293\ttotal: 228ms\tremaining: 3.03s\n",
      "35:\tlearn: 0.4608034\ttotal: 238ms\tremaining: 3.07s\n",
      "36:\tlearn: 0.4582915\ttotal: 248ms\tremaining: 3.1s\n",
      "37:\tlearn: 0.4534222\ttotal: 257ms\tremaining: 3.13s\n",
      "38:\tlearn: 0.4489520\ttotal: 268ms\tremaining: 3.17s\n",
      "39:\tlearn: 0.4457208\ttotal: 278ms\tremaining: 3.2s\n",
      "40:\tlearn: 0.4427381\ttotal: 287ms\tremaining: 3.22s\n",
      "41:\tlearn: 0.4396111\ttotal: 295ms\tremaining: 3.21s\n",
      "42:\tlearn: 0.4349899\ttotal: 301ms\tremaining: 3.2s\n",
      "43:\tlearn: 0.4297028\ttotal: 307ms\tremaining: 3.18s\n",
      "44:\tlearn: 0.4273143\ttotal: 313ms\tremaining: 3.17s\n",
      "45:\tlearn: 0.4244096\ttotal: 318ms\tremaining: 3.14s\n",
      "46:\tlearn: 0.4206379\ttotal: 323ms\tremaining: 3.12s\n",
      "47:\tlearn: 0.4170106\ttotal: 328ms\tremaining: 3.09s\n",
      "48:\tlearn: 0.4147224\ttotal: 333ms\tremaining: 3.06s\n",
      "49:\tlearn: 0.4114939\ttotal: 337ms\tremaining: 3.04s\n",
      "50:\tlearn: 0.4087153\ttotal: 343ms\tremaining: 3.02s\n",
      "51:\tlearn: 0.4045983\ttotal: 348ms\tremaining: 3s\n",
      "52:\tlearn: 0.4010245\ttotal: 353ms\tremaining: 2.97s\n",
      "53:\tlearn: 0.3982334\ttotal: 357ms\tremaining: 2.95s\n",
      "54:\tlearn: 0.3948597\ttotal: 361ms\tremaining: 2.92s\n",
      "55:\tlearn: 0.3919523\ttotal: 365ms\tremaining: 2.9s\n",
      "56:\tlearn: 0.3896402\ttotal: 371ms\tremaining: 2.88s\n",
      "57:\tlearn: 0.3867662\ttotal: 381ms\tremaining: 2.9s\n",
      "58:\tlearn: 0.3845437\ttotal: 390ms\tremaining: 2.92s\n",
      "59:\tlearn: 0.3825432\ttotal: 400ms\tremaining: 2.93s\n",
      "60:\tlearn: 0.3796207\ttotal: 410ms\tremaining: 2.95s\n",
      "61:\tlearn: 0.3772759\ttotal: 419ms\tremaining: 2.96s\n",
      "62:\tlearn: 0.3755663\ttotal: 429ms\tremaining: 2.97s\n",
      "63:\tlearn: 0.3731969\ttotal: 439ms\tremaining: 2.99s\n",
      "64:\tlearn: 0.3700856\ttotal: 448ms\tremaining: 3s\n",
      "65:\tlearn: 0.3661108\ttotal: 458ms\tremaining: 3.01s\n",
      "66:\tlearn: 0.3641961\ttotal: 466ms\tremaining: 3.01s\n",
      "67:\tlearn: 0.3620394\ttotal: 473ms\tremaining: 3s\n",
      "68:\tlearn: 0.3577437\ttotal: 480ms\tremaining: 3s\n",
      "69:\tlearn: 0.3552413\ttotal: 487ms\tremaining: 2.99s\n",
      "70:\tlearn: 0.3534556\ttotal: 504ms\tremaining: 3.05s\n",
      "71:\tlearn: 0.3506725\ttotal: 509ms\tremaining: 3.02s\n",
      "72:\tlearn: 0.3474900\ttotal: 513ms\tremaining: 3s\n",
      "73:\tlearn: 0.3449048\ttotal: 518ms\tremaining: 2.98s\n",
      "74:\tlearn: 0.3423780\ttotal: 522ms\tremaining: 2.96s\n",
      "75:\tlearn: 0.3398788\ttotal: 525ms\tremaining: 2.93s\n",
      "76:\tlearn: 0.3373310\ttotal: 529ms\tremaining: 2.91s\n",
      "77:\tlearn: 0.3350787\ttotal: 534ms\tremaining: 2.89s\n",
      "78:\tlearn: 0.3322490\ttotal: 539ms\tremaining: 2.87s\n",
      "79:\tlearn: 0.3293903\ttotal: 543ms\tremaining: 2.85s\n",
      "80:\tlearn: 0.3266049\ttotal: 547ms\tremaining: 2.83s\n",
      "81:\tlearn: 0.3241779\ttotal: 551ms\tremaining: 2.81s\n",
      "82:\tlearn: 0.3222727\ttotal: 565ms\tremaining: 2.84s\n",
      "83:\tlearn: 0.3202461\ttotal: 574ms\tremaining: 2.84s\n",
      "84:\tlearn: 0.3182765\ttotal: 584ms\tremaining: 2.85s\n",
      "85:\tlearn: 0.3161472\ttotal: 594ms\tremaining: 2.86s\n",
      "86:\tlearn: 0.3140707\ttotal: 604ms\tremaining: 2.87s\n",
      "87:\tlearn: 0.3119710\ttotal: 613ms\tremaining: 2.87s\n",
      "88:\tlearn: 0.3094936\ttotal: 622ms\tremaining: 2.87s\n",
      "89:\tlearn: 0.3076103\ttotal: 630ms\tremaining: 2.87s\n",
      "90:\tlearn: 0.3054781\ttotal: 634ms\tremaining: 2.85s\n",
      "91:\tlearn: 0.3030335\ttotal: 639ms\tremaining: 2.83s\n",
      "92:\tlearn: 0.3010439\ttotal: 644ms\tremaining: 2.82s\n",
      "93:\tlearn: 0.2987888\ttotal: 649ms\tremaining: 2.8s\n",
      "94:\tlearn: 0.2968859\ttotal: 653ms\tremaining: 2.78s\n",
      "95:\tlearn: 0.2940692\ttotal: 658ms\tremaining: 2.77s\n",
      "96:\tlearn: 0.2920526\ttotal: 662ms\tremaining: 2.75s\n",
      "97:\tlearn: 0.2903949\ttotal: 666ms\tremaining: 2.73s\n",
      "98:\tlearn: 0.2883247\ttotal: 671ms\tremaining: 2.72s\n",
      "99:\tlearn: 0.2861680\ttotal: 675ms\tremaining: 2.7s\n",
      "100:\tlearn: 0.2841945\ttotal: 679ms\tremaining: 2.68s\n",
      "101:\tlearn: 0.2821216\ttotal: 683ms\tremaining: 2.67s\n",
      "102:\tlearn: 0.2802777\ttotal: 688ms\tremaining: 2.65s\n",
      "103:\tlearn: 0.2784043\ttotal: 697ms\tremaining: 2.65s\n",
      "104:\tlearn: 0.2762529\ttotal: 707ms\tremaining: 2.66s\n",
      "105:\tlearn: 0.2732111\ttotal: 717ms\tremaining: 2.66s\n",
      "106:\tlearn: 0.2718062\ttotal: 726ms\tremaining: 2.67s\n",
      "107:\tlearn: 0.2699368\ttotal: 736ms\tremaining: 2.67s\n",
      "108:\tlearn: 0.2684961\ttotal: 745ms\tremaining: 2.67s\n",
      "109:\tlearn: 0.2665651\ttotal: 755ms\tremaining: 2.68s\n",
      "110:\tlearn: 0.2647857\ttotal: 764ms\tremaining: 2.68s\n",
      "111:\tlearn: 0.2632128\ttotal: 772ms\tremaining: 2.67s\n",
      "112:\tlearn: 0.2608561\ttotal: 778ms\tremaining: 2.67s\n",
      "113:\tlearn: 0.2594045\ttotal: 785ms\tremaining: 2.66s\n",
      "114:\tlearn: 0.2579785\ttotal: 791ms\tremaining: 2.65s\n",
      "115:\tlearn: 0.2546475\ttotal: 796ms\tremaining: 2.63s\n",
      "116:\tlearn: 0.2530834\ttotal: 801ms\tremaining: 2.62s\n",
      "117:\tlearn: 0.2508236\ttotal: 805ms\tremaining: 2.61s\n",
      "118:\tlearn: 0.2494129\ttotal: 810ms\tremaining: 2.59s\n",
      "119:\tlearn: 0.2478322\ttotal: 815ms\tremaining: 2.58s\n",
      "120:\tlearn: 0.2464526\ttotal: 820ms\tremaining: 2.57s\n",
      "121:\tlearn: 0.2435282\ttotal: 824ms\tremaining: 2.55s\n",
      "122:\tlearn: 0.2413167\ttotal: 828ms\tremaining: 2.54s\n",
      "123:\tlearn: 0.2393638\ttotal: 833ms\tremaining: 2.52s\n",
      "124:\tlearn: 0.2381874\ttotal: 837ms\tremaining: 2.51s\n",
      "125:\tlearn: 0.2366717\ttotal: 842ms\tremaining: 2.5s\n",
      "126:\tlearn: 0.2341976\ttotal: 846ms\tremaining: 2.48s\n",
      "127:\tlearn: 0.2323944\ttotal: 850ms\tremaining: 2.47s\n",
      "128:\tlearn: 0.2308931\ttotal: 860ms\tremaining: 2.47s\n",
      "129:\tlearn: 0.2296608\ttotal: 870ms\tremaining: 2.48s\n",
      "130:\tlearn: 0.2278853\ttotal: 879ms\tremaining: 2.48s\n",
      "131:\tlearn: 0.2266820\ttotal: 889ms\tremaining: 2.48s\n",
      "132:\tlearn: 0.2253210\ttotal: 898ms\tremaining: 2.48s\n",
      "133:\tlearn: 0.2239615\ttotal: 908ms\tremaining: 2.48s\n",
      "134:\tlearn: 0.2226046\ttotal: 918ms\tremaining: 2.48s\n",
      "135:\tlearn: 0.2207759\ttotal: 927ms\tremaining: 2.48s\n",
      "136:\tlearn: 0.2192747\ttotal: 936ms\tremaining: 2.48s\n",
      "137:\tlearn: 0.2177254\ttotal: 941ms\tremaining: 2.47s\n",
      "138:\tlearn: 0.2167809\ttotal: 946ms\tremaining: 2.46s\n",
      "139:\tlearn: 0.2155789\ttotal: 951ms\tremaining: 2.44s\n",
      "140:\tlearn: 0.2138944\ttotal: 955ms\tremaining: 2.43s\n",
      "141:\tlearn: 0.2124918\ttotal: 960ms\tremaining: 2.42s\n",
      "142:\tlearn: 0.2115716\ttotal: 965ms\tremaining: 2.41s\n",
      "143:\tlearn: 0.2105337\ttotal: 969ms\tremaining: 2.4s\n",
      "144:\tlearn: 0.2093835\ttotal: 973ms\tremaining: 2.38s\n",
      "145:\tlearn: 0.2068071\ttotal: 978ms\tremaining: 2.37s\n",
      "146:\tlearn: 0.2057639\ttotal: 982ms\tremaining: 2.36s\n",
      "147:\tlearn: 0.2041353\ttotal: 987ms\tremaining: 2.35s\n",
      "148:\tlearn: 0.2028379\ttotal: 992ms\tremaining: 2.34s\n",
      "149:\tlearn: 0.2007326\ttotal: 1s\tremaining: 2.34s\n",
      "150:\tlearn: 0.1992050\ttotal: 1.01s\tremaining: 2.34s\n",
      "151:\tlearn: 0.1980173\ttotal: 1.02s\tremaining: 2.34s\n",
      "152:\tlearn: 0.1960911\ttotal: 1.03s\tremaining: 2.34s\n",
      "153:\tlearn: 0.1948928\ttotal: 1.04s\tremaining: 2.34s\n",
      "154:\tlearn: 0.1934200\ttotal: 1.05s\tremaining: 2.34s\n",
      "155:\tlearn: 0.1923522\ttotal: 1.06s\tremaining: 2.34s\n",
      "156:\tlearn: 0.1913764\ttotal: 1.07s\tremaining: 2.34s\n",
      "157:\tlearn: 0.1904061\ttotal: 1.08s\tremaining: 2.34s\n",
      "158:\tlearn: 0.1882556\ttotal: 1.08s\tremaining: 2.33s\n",
      "159:\tlearn: 0.1870056\ttotal: 1.09s\tremaining: 2.32s\n",
      "160:\tlearn: 0.1860199\ttotal: 1.1s\tremaining: 2.31s\n",
      "161:\tlearn: 0.1848555\ttotal: 1.1s\tremaining: 2.3s\n",
      "162:\tlearn: 0.1838528\ttotal: 1.11s\tremaining: 2.3s\n",
      "163:\tlearn: 0.1829974\ttotal: 1.12s\tremaining: 2.29s\n",
      "164:\tlearn: 0.1815927\ttotal: 1.12s\tremaining: 2.28s\n",
      "165:\tlearn: 0.1807299\ttotal: 1.13s\tremaining: 2.27s\n",
      "166:\tlearn: 0.1796122\ttotal: 1.13s\tremaining: 2.25s\n",
      "167:\tlearn: 0.1786585\ttotal: 1.13s\tremaining: 2.24s\n",
      "168:\tlearn: 0.1775338\ttotal: 1.14s\tremaining: 2.23s\n",
      "169:\tlearn: 0.1764605\ttotal: 1.14s\tremaining: 2.22s\n",
      "170:\tlearn: 0.1754393\ttotal: 1.15s\tremaining: 2.21s\n",
      "171:\tlearn: 0.1743836\ttotal: 1.15s\tremaining: 2.19s\n",
      "172:\tlearn: 0.1730836\ttotal: 1.16s\tremaining: 2.18s\n",
      "173:\tlearn: 0.1713993\ttotal: 1.16s\tremaining: 2.17s\n",
      "174:\tlearn: 0.1704799\ttotal: 1.16s\tremaining: 2.16s\n",
      "175:\tlearn: 0.1693486\ttotal: 1.17s\tremaining: 2.16s\n",
      "176:\tlearn: 0.1685590\ttotal: 1.18s\tremaining: 2.16s\n",
      "177:\tlearn: 0.1677329\ttotal: 1.19s\tremaining: 2.16s\n",
      "178:\tlearn: 0.1668361\ttotal: 1.2s\tremaining: 2.16s\n",
      "179:\tlearn: 0.1658642\ttotal: 1.21s\tremaining: 2.15s\n",
      "180:\tlearn: 0.1650446\ttotal: 1.22s\tremaining: 2.15s\n",
      "181:\tlearn: 0.1641563\ttotal: 1.23s\tremaining: 2.15s\n",
      "182:\tlearn: 0.1633666\ttotal: 1.24s\tremaining: 2.15s\n",
      "183:\tlearn: 0.1619076\ttotal: 1.25s\tremaining: 2.15s\n",
      "184:\tlearn: 0.1608518\ttotal: 1.26s\tremaining: 2.14s\n",
      "185:\tlearn: 0.1598697\ttotal: 1.26s\tremaining: 2.13s\n",
      "186:\tlearn: 0.1587843\ttotal: 1.27s\tremaining: 2.13s\n",
      "187:\tlearn: 0.1578330\ttotal: 1.28s\tremaining: 2.12s\n",
      "188:\tlearn: 0.1570082\ttotal: 1.28s\tremaining: 2.11s\n",
      "189:\tlearn: 0.1559983\ttotal: 1.29s\tremaining: 2.1s\n",
      "190:\tlearn: 0.1552397\ttotal: 1.29s\tremaining: 2.09s\n",
      "191:\tlearn: 0.1543875\ttotal: 1.3s\tremaining: 2.08s\n",
      "192:\tlearn: 0.1533825\ttotal: 1.3s\tremaining: 2.07s\n",
      "193:\tlearn: 0.1525524\ttotal: 1.31s\tremaining: 2.06s\n",
      "194:\tlearn: 0.1516912\ttotal: 1.31s\tremaining: 2.05s\n",
      "195:\tlearn: 0.1510199\ttotal: 1.31s\tremaining: 2.04s\n",
      "196:\tlearn: 0.1495306\ttotal: 1.32s\tremaining: 2.02s\n",
      "197:\tlearn: 0.1477591\ttotal: 1.32s\tremaining: 2.01s\n",
      "198:\tlearn: 0.1471823\ttotal: 1.32s\tremaining: 2s\n",
      "199:\tlearn: 0.1462765\ttotal: 1.33s\tremaining: 1.99s\n",
      "200:\tlearn: 0.1453391\ttotal: 1.33s\tremaining: 1.98s\n",
      "201:\tlearn: 0.1441365\ttotal: 1.34s\tremaining: 1.97s\n",
      "202:\tlearn: 0.1433790\ttotal: 1.35s\tremaining: 1.97s\n",
      "203:\tlearn: 0.1428116\ttotal: 1.36s\tremaining: 1.97s\n",
      "204:\tlearn: 0.1419498\ttotal: 1.36s\tremaining: 1.97s\n",
      "205:\tlearn: 0.1412805\ttotal: 1.38s\tremaining: 1.96s\n",
      "206:\tlearn: 0.1405487\ttotal: 1.39s\tremaining: 1.96s\n",
      "207:\tlearn: 0.1396900\ttotal: 1.4s\tremaining: 1.96s\n",
      "208:\tlearn: 0.1386147\ttotal: 1.4s\tremaining: 1.95s\n",
      "209:\tlearn: 0.1379079\ttotal: 1.41s\tremaining: 1.95s\n",
      "210:\tlearn: 0.1372464\ttotal: 1.42s\tremaining: 1.94s\n",
      "211:\tlearn: 0.1357466\ttotal: 1.42s\tremaining: 1.93s\n",
      "212:\tlearn: 0.1350723\ttotal: 1.43s\tremaining: 1.92s\n",
      "213:\tlearn: 0.1344179\ttotal: 1.43s\tremaining: 1.91s\n",
      "214:\tlearn: 0.1335844\ttotal: 1.44s\tremaining: 1.91s\n",
      "215:\tlearn: 0.1330041\ttotal: 1.44s\tremaining: 1.9s\n",
      "216:\tlearn: 0.1322829\ttotal: 1.45s\tremaining: 1.89s\n",
      "217:\tlearn: 0.1317739\ttotal: 1.45s\tremaining: 1.88s\n",
      "218:\tlearn: 0.1311376\ttotal: 1.46s\tremaining: 1.87s\n",
      "219:\tlearn: 0.1291412\ttotal: 1.46s\tremaining: 1.86s\n",
      "220:\tlearn: 0.1282580\ttotal: 1.46s\tremaining: 1.85s\n",
      "221:\tlearn: 0.1276090\ttotal: 1.47s\tremaining: 1.84s\n",
      "222:\tlearn: 0.1267744\ttotal: 1.47s\tremaining: 1.83s\n",
      "223:\tlearn: 0.1259610\ttotal: 1.48s\tremaining: 1.82s\n",
      "224:\tlearn: 0.1253738\ttotal: 1.49s\tremaining: 1.81s\n",
      "225:\tlearn: 0.1244755\ttotal: 1.5s\tremaining: 1.81s\n",
      "226:\tlearn: 0.1237150\ttotal: 1.5s\tremaining: 1.81s\n",
      "227:\tlearn: 0.1229220\ttotal: 1.51s\tremaining: 1.81s\n",
      "228:\tlearn: 0.1220121\ttotal: 1.52s\tremaining: 1.8s\n",
      "229:\tlearn: 0.1213451\ttotal: 1.53s\tremaining: 1.8s\n",
      "230:\tlearn: 0.1205443\ttotal: 1.54s\tremaining: 1.8s\n",
      "231:\tlearn: 0.1199439\ttotal: 1.55s\tremaining: 1.79s\n",
      "232:\tlearn: 0.1193239\ttotal: 1.56s\tremaining: 1.79s\n",
      "233:\tlearn: 0.1186642\ttotal: 1.57s\tremaining: 1.78s\n",
      "234:\tlearn: 0.1181288\ttotal: 1.57s\tremaining: 1.77s\n",
      "235:\tlearn: 0.1174539\ttotal: 1.58s\tremaining: 1.76s\n",
      "236:\tlearn: 0.1169631\ttotal: 1.58s\tremaining: 1.75s\n",
      "237:\tlearn: 0.1156542\ttotal: 1.59s\tremaining: 1.75s\n",
      "238:\tlearn: 0.1151618\ttotal: 1.59s\tremaining: 1.74s\n",
      "239:\tlearn: 0.1146744\ttotal: 1.6s\tremaining: 1.73s\n",
      "240:\tlearn: 0.1140467\ttotal: 1.6s\tremaining: 1.72s\n",
      "241:\tlearn: 0.1135803\ttotal: 1.6s\tremaining: 1.71s\n",
      "242:\tlearn: 0.1130807\ttotal: 1.61s\tremaining: 1.7s\n",
      "243:\tlearn: 0.1124239\ttotal: 1.61s\tremaining: 1.69s\n",
      "244:\tlearn: 0.1119214\ttotal: 1.62s\tremaining: 1.68s\n",
      "245:\tlearn: 0.1110813\ttotal: 1.62s\tremaining: 1.68s\n",
      "246:\tlearn: 0.1105717\ttotal: 1.64s\tremaining: 1.68s\n",
      "247:\tlearn: 0.1100080\ttotal: 1.65s\tremaining: 1.67s\n",
      "248:\tlearn: 0.1094879\ttotal: 1.66s\tremaining: 1.67s\n",
      "249:\tlearn: 0.1088422\ttotal: 1.67s\tremaining: 1.67s\n",
      "250:\tlearn: 0.1084084\ttotal: 1.68s\tremaining: 1.66s\n",
      "251:\tlearn: 0.1079596\ttotal: 1.69s\tremaining: 1.66s\n",
      "252:\tlearn: 0.1073023\ttotal: 1.69s\tremaining: 1.65s\n",
      "253:\tlearn: 0.1068343\ttotal: 1.7s\tremaining: 1.65s\n",
      "254:\tlearn: 0.1057019\ttotal: 1.71s\tremaining: 1.64s\n",
      "255:\tlearn: 0.1052593\ttotal: 1.72s\tremaining: 1.64s\n",
      "256:\tlearn: 0.1041350\ttotal: 1.72s\tremaining: 1.63s\n",
      "257:\tlearn: 0.1037087\ttotal: 1.73s\tremaining: 1.62s\n",
      "258:\tlearn: 0.1031571\ttotal: 1.74s\tremaining: 1.62s\n",
      "259:\tlearn: 0.1026308\ttotal: 1.74s\tremaining: 1.61s\n",
      "260:\tlearn: 0.1021802\ttotal: 1.75s\tremaining: 1.6s\n",
      "261:\tlearn: 0.1015667\ttotal: 1.75s\tremaining: 1.59s\n",
      "262:\tlearn: 0.1010472\ttotal: 1.75s\tremaining: 1.58s\n",
      "263:\tlearn: 0.1004972\ttotal: 1.76s\tremaining: 1.57s\n",
      "264:\tlearn: 0.0994787\ttotal: 1.76s\tremaining: 1.56s\n",
      "265:\tlearn: 0.0988281\ttotal: 1.77s\tremaining: 1.56s\n",
      "266:\tlearn: 0.0982912\ttotal: 1.77s\tremaining: 1.55s\n",
      "267:\tlearn: 0.0978491\ttotal: 1.78s\tremaining: 1.54s\n",
      "268:\tlearn: 0.0970005\ttotal: 1.78s\tremaining: 1.53s\n",
      "269:\tlearn: 0.0965641\ttotal: 1.79s\tremaining: 1.52s\n",
      "270:\tlearn: 0.0961316\ttotal: 1.79s\tremaining: 1.51s\n",
      "271:\tlearn: 0.0955236\ttotal: 1.79s\tremaining: 1.5s\n",
      "272:\tlearn: 0.0948747\ttotal: 1.8s\tremaining: 1.5s\n",
      "273:\tlearn: 0.0942994\ttotal: 1.81s\tremaining: 1.49s\n",
      "274:\tlearn: 0.0938959\ttotal: 1.82s\tremaining: 1.49s\n",
      "275:\tlearn: 0.0934378\ttotal: 1.83s\tremaining: 1.49s\n",
      "276:\tlearn: 0.0929351\ttotal: 1.84s\tremaining: 1.48s\n",
      "277:\tlearn: 0.0924057\ttotal: 1.85s\tremaining: 1.48s\n",
      "278:\tlearn: 0.0919944\ttotal: 1.86s\tremaining: 1.48s\n",
      "279:\tlearn: 0.0913860\ttotal: 1.87s\tremaining: 1.47s\n",
      "280:\tlearn: 0.0909324\ttotal: 1.88s\tremaining: 1.47s\n",
      "281:\tlearn: 0.0905540\ttotal: 1.89s\tremaining: 1.46s\n",
      "282:\tlearn: 0.0899639\ttotal: 1.9s\tremaining: 1.46s\n",
      "283:\tlearn: 0.0895497\ttotal: 1.91s\tremaining: 1.45s\n",
      "284:\tlearn: 0.0890243\ttotal: 1.92s\tremaining: 1.45s\n",
      "285:\tlearn: 0.0883344\ttotal: 1.93s\tremaining: 1.44s\n",
      "286:\tlearn: 0.0879000\ttotal: 1.94s\tremaining: 1.44s\n",
      "287:\tlearn: 0.0875272\ttotal: 1.95s\tremaining: 1.43s\n",
      "288:\tlearn: 0.0870848\ttotal: 1.96s\tremaining: 1.43s\n",
      "289:\tlearn: 0.0865736\ttotal: 1.96s\tremaining: 1.42s\n",
      "290:\tlearn: 0.0861521\ttotal: 1.97s\tremaining: 1.41s\n",
      "291:\tlearn: 0.0858046\ttotal: 1.97s\tremaining: 1.4s\n",
      "292:\tlearn: 0.0850724\ttotal: 1.98s\tremaining: 1.4s\n",
      "293:\tlearn: 0.0846975\ttotal: 1.98s\tremaining: 1.39s\n",
      "294:\tlearn: 0.0842146\ttotal: 1.99s\tremaining: 1.38s\n",
      "295:\tlearn: 0.0837696\ttotal: 1.99s\tremaining: 1.37s\n",
      "296:\tlearn: 0.0834058\ttotal: 1.99s\tremaining: 1.36s\n",
      "297:\tlearn: 0.0831308\ttotal: 2s\tremaining: 1.35s\n",
      "298:\tlearn: 0.0826828\ttotal: 2s\tremaining: 1.34s\n",
      "299:\tlearn: 0.0823647\ttotal: 2s\tremaining: 1.33s\n",
      "300:\tlearn: 0.0820057\ttotal: 2.01s\tremaining: 1.33s\n",
      "301:\tlearn: 0.0816423\ttotal: 2.01s\tremaining: 1.32s\n",
      "302:\tlearn: 0.0812615\ttotal: 2.02s\tremaining: 1.31s\n",
      "303:\tlearn: 0.0806087\ttotal: 2.02s\tremaining: 1.3s\n",
      "304:\tlearn: 0.0800847\ttotal: 2.03s\tremaining: 1.3s\n",
      "305:\tlearn: 0.0796472\ttotal: 2.04s\tremaining: 1.29s\n",
      "306:\tlearn: 0.0792616\ttotal: 2.05s\tremaining: 1.29s\n",
      "307:\tlearn: 0.0787671\ttotal: 2.06s\tremaining: 1.28s\n",
      "308:\tlearn: 0.0783209\ttotal: 2.07s\tremaining: 1.28s\n",
      "309:\tlearn: 0.0779553\ttotal: 2.08s\tremaining: 1.27s\n",
      "310:\tlearn: 0.0774979\ttotal: 2.09s\tremaining: 1.27s\n",
      "311:\tlearn: 0.0769831\ttotal: 2.1s\tremaining: 1.26s\n",
      "312:\tlearn: 0.0766215\ttotal: 2.1s\tremaining: 1.26s\n",
      "313:\tlearn: 0.0762555\ttotal: 2.11s\tremaining: 1.25s\n",
      "314:\tlearn: 0.0758725\ttotal: 2.12s\tremaining: 1.24s\n",
      "315:\tlearn: 0.0755443\ttotal: 2.12s\tremaining: 1.23s\n",
      "316:\tlearn: 0.0752060\ttotal: 2.12s\tremaining: 1.23s\n",
      "317:\tlearn: 0.0748842\ttotal: 2.13s\tremaining: 1.22s\n",
      "318:\tlearn: 0.0744444\ttotal: 2.13s\tremaining: 1.21s\n",
      "319:\tlearn: 0.0740766\ttotal: 2.14s\tremaining: 1.21s\n",
      "320:\tlearn: 0.0737042\ttotal: 2.15s\tremaining: 1.2s\n",
      "321:\tlearn: 0.0733250\ttotal: 2.16s\tremaining: 1.2s\n",
      "322:\tlearn: 0.0729739\ttotal: 2.17s\tremaining: 1.19s\n",
      "323:\tlearn: 0.0725503\ttotal: 2.18s\tremaining: 1.18s\n",
      "324:\tlearn: 0.0722023\ttotal: 2.19s\tremaining: 1.18s\n",
      "325:\tlearn: 0.0718637\ttotal: 2.2s\tremaining: 1.17s\n",
      "326:\tlearn: 0.0712221\ttotal: 2.21s\tremaining: 1.17s\n",
      "327:\tlearn: 0.0708212\ttotal: 2.22s\tremaining: 1.16s\n",
      "328:\tlearn: 0.0705545\ttotal: 2.22s\tremaining: 1.15s\n",
      "329:\tlearn: 0.0700855\ttotal: 2.22s\tremaining: 1.15s\n",
      "330:\tlearn: 0.0698112\ttotal: 2.23s\tremaining: 1.14s\n",
      "331:\tlearn: 0.0694347\ttotal: 2.23s\tremaining: 1.13s\n",
      "332:\tlearn: 0.0690573\ttotal: 2.23s\tremaining: 1.12s\n",
      "333:\tlearn: 0.0687369\ttotal: 2.24s\tremaining: 1.11s\n",
      "334:\tlearn: 0.0685503\ttotal: 2.24s\tremaining: 1.1s\n",
      "335:\tlearn: 0.0682787\ttotal: 2.24s\tremaining: 1.09s\n",
      "336:\tlearn: 0.0678814\ttotal: 2.25s\tremaining: 1.09s\n",
      "337:\tlearn: 0.0675748\ttotal: 2.25s\tremaining: 1.08s\n",
      "338:\tlearn: 0.0671868\ttotal: 2.25s\tremaining: 1.07s\n",
      "339:\tlearn: 0.0669248\ttotal: 2.26s\tremaining: 1.06s\n",
      "340:\tlearn: 0.0666409\ttotal: 2.26s\tremaining: 1.05s\n",
      "341:\tlearn: 0.0661667\ttotal: 2.27s\tremaining: 1.05s\n",
      "342:\tlearn: 0.0657390\ttotal: 2.27s\tremaining: 1.04s\n",
      "343:\tlearn: 0.0654097\ttotal: 2.27s\tremaining: 1.03s\n",
      "344:\tlearn: 0.0651276\ttotal: 2.28s\tremaining: 1.02s\n",
      "345:\tlearn: 0.0648005\ttotal: 2.28s\tremaining: 1.01s\n",
      "346:\tlearn: 0.0644442\ttotal: 2.29s\tremaining: 1.01s\n",
      "347:\tlearn: 0.0641936\ttotal: 2.29s\tremaining: 1000ms\n",
      "348:\tlearn: 0.0639203\ttotal: 2.29s\tremaining: 992ms\n",
      "349:\tlearn: 0.0636858\ttotal: 2.3s\tremaining: 985ms\n",
      "350:\tlearn: 0.0633355\ttotal: 2.3s\tremaining: 978ms\n",
      "351:\tlearn: 0.0630964\ttotal: 2.31s\tremaining: 972ms\n",
      "352:\tlearn: 0.0627896\ttotal: 2.32s\tremaining: 965ms\n",
      "353:\tlearn: 0.0624605\ttotal: 2.32s\tremaining: 958ms\n",
      "354:\tlearn: 0.0622182\ttotal: 2.33s\tremaining: 952ms\n",
      "355:\tlearn: 0.0619672\ttotal: 2.34s\tremaining: 945ms\n",
      "356:\tlearn: 0.0617008\ttotal: 2.34s\tremaining: 939ms\n",
      "357:\tlearn: 0.0613930\ttotal: 2.35s\tremaining: 932ms\n",
      "358:\tlearn: 0.0611637\ttotal: 2.36s\tremaining: 925ms\n",
      "359:\tlearn: 0.0609320\ttotal: 2.36s\tremaining: 919ms\n",
      "360:\tlearn: 0.0606578\ttotal: 2.37s\tremaining: 912ms\n",
      "361:\tlearn: 0.0603864\ttotal: 2.38s\tremaining: 906ms\n",
      "362:\tlearn: 0.0600682\ttotal: 2.38s\tremaining: 899ms\n",
      "363:\tlearn: 0.0597610\ttotal: 2.39s\tremaining: 894ms\n",
      "364:\tlearn: 0.0595430\ttotal: 2.4s\tremaining: 889ms\n",
      "365:\tlearn: 0.0590519\ttotal: 2.41s\tremaining: 883ms\n",
      "366:\tlearn: 0.0587357\ttotal: 2.42s\tremaining: 878ms\n",
      "367:\tlearn: 0.0584777\ttotal: 2.43s\tremaining: 872ms\n",
      "368:\tlearn: 0.0582547\ttotal: 2.44s\tremaining: 867ms\n",
      "369:\tlearn: 0.0579519\ttotal: 2.45s\tremaining: 861ms\n",
      "370:\tlearn: 0.0576753\ttotal: 2.46s\tremaining: 856ms\n",
      "371:\tlearn: 0.0574093\ttotal: 2.47s\tremaining: 850ms\n",
      "372:\tlearn: 0.0571144\ttotal: 2.48s\tremaining: 844ms\n",
      "373:\tlearn: 0.0566727\ttotal: 2.49s\tremaining: 838ms\n",
      "374:\tlearn: 0.0563862\ttotal: 2.49s\tremaining: 831ms\n",
      "375:\tlearn: 0.0561577\ttotal: 2.5s\tremaining: 824ms\n",
      "376:\tlearn: 0.0558458\ttotal: 2.5s\tremaining: 816ms\n",
      "377:\tlearn: 0.0556601\ttotal: 2.51s\tremaining: 809ms\n",
      "378:\tlearn: 0.0553141\ttotal: 2.51s\tremaining: 802ms\n",
      "379:\tlearn: 0.0550610\ttotal: 2.52s\tremaining: 795ms\n",
      "380:\tlearn: 0.0548175\ttotal: 2.52s\tremaining: 788ms\n",
      "381:\tlearn: 0.0546257\ttotal: 2.53s\tremaining: 781ms\n",
      "382:\tlearn: 0.0544091\ttotal: 2.53s\tremaining: 773ms\n",
      "383:\tlearn: 0.0540872\ttotal: 2.53s\tremaining: 765ms\n",
      "384:\tlearn: 0.0537618\ttotal: 2.54s\tremaining: 758ms\n",
      "385:\tlearn: 0.0535215\ttotal: 2.54s\tremaining: 751ms\n",
      "386:\tlearn: 0.0533104\ttotal: 2.55s\tremaining: 744ms\n",
      "387:\tlearn: 0.0530898\ttotal: 2.55s\tremaining: 736ms\n",
      "388:\tlearn: 0.0528519\ttotal: 2.56s\tremaining: 731ms\n",
      "389:\tlearn: 0.0526524\ttotal: 2.57s\tremaining: 725ms\n",
      "390:\tlearn: 0.0524707\ttotal: 2.58s\tremaining: 719ms\n",
      "391:\tlearn: 0.0522570\ttotal: 2.59s\tremaining: 713ms\n",
      "392:\tlearn: 0.0520301\ttotal: 2.6s\tremaining: 708ms\n",
      "393:\tlearn: 0.0518614\ttotal: 2.61s\tremaining: 702ms\n",
      "394:\tlearn: 0.0515878\ttotal: 2.62s\tremaining: 696ms\n",
      "395:\tlearn: 0.0513669\ttotal: 2.63s\tremaining: 690ms\n",
      "396:\tlearn: 0.0510059\ttotal: 2.64s\tremaining: 684ms\n",
      "397:\tlearn: 0.0507478\ttotal: 2.65s\tremaining: 678ms\n",
      "398:\tlearn: 0.0504766\ttotal: 2.65s\tremaining: 671ms\n",
      "399:\tlearn: 0.0502731\ttotal: 2.66s\tremaining: 664ms\n",
      "400:\tlearn: 0.0500464\ttotal: 2.66s\tremaining: 658ms\n",
      "401:\tlearn: 0.0498337\ttotal: 2.67s\tremaining: 651ms\n",
      "402:\tlearn: 0.0494695\ttotal: 2.68s\tremaining: 644ms\n",
      "403:\tlearn: 0.0492805\ttotal: 2.68s\tremaining: 637ms\n",
      "404:\tlearn: 0.0490433\ttotal: 2.69s\tremaining: 631ms\n",
      "405:\tlearn: 0.0488541\ttotal: 2.69s\tremaining: 624ms\n",
      "406:\tlearn: 0.0485055\ttotal: 2.7s\tremaining: 616ms\n",
      "407:\tlearn: 0.0483380\ttotal: 2.7s\tremaining: 609ms\n",
      "408:\tlearn: 0.0481416\ttotal: 2.71s\tremaining: 602ms\n",
      "409:\tlearn: 0.0478591\ttotal: 2.71s\tremaining: 595ms\n",
      "410:\tlearn: 0.0475383\ttotal: 2.72s\tremaining: 588ms\n",
      "411:\tlearn: 0.0472553\ttotal: 2.72s\tremaining: 581ms\n",
      "412:\tlearn: 0.0470490\ttotal: 2.73s\tremaining: 574ms\n",
      "413:\tlearn: 0.0468180\ttotal: 2.73s\tremaining: 567ms\n",
      "414:\tlearn: 0.0466062\ttotal: 2.74s\tremaining: 560ms\n",
      "415:\tlearn: 0.0463735\ttotal: 2.74s\tremaining: 554ms\n",
      "416:\tlearn: 0.0462029\ttotal: 2.75s\tremaining: 547ms\n",
      "417:\tlearn: 0.0460028\ttotal: 2.75s\tremaining: 540ms\n",
      "418:\tlearn: 0.0459080\ttotal: 2.76s\tremaining: 534ms\n",
      "419:\tlearn: 0.0457539\ttotal: 2.77s\tremaining: 528ms\n",
      "420:\tlearn: 0.0456160\ttotal: 2.78s\tremaining: 522ms\n",
      "421:\tlearn: 0.0454005\ttotal: 2.79s\tremaining: 516ms\n",
      "422:\tlearn: 0.0452634\ttotal: 2.8s\tremaining: 510ms\n",
      "423:\tlearn: 0.0451154\ttotal: 2.81s\tremaining: 504ms\n",
      "424:\tlearn: 0.0448918\ttotal: 2.82s\tremaining: 498ms\n",
      "425:\tlearn: 0.0447261\ttotal: 2.83s\tremaining: 492ms\n",
      "426:\tlearn: 0.0445043\ttotal: 2.84s\tremaining: 486ms\n",
      "427:\tlearn: 0.0443560\ttotal: 2.85s\tremaining: 479ms\n",
      "428:\tlearn: 0.0440114\ttotal: 2.86s\tremaining: 473ms\n",
      "429:\tlearn: 0.0437989\ttotal: 2.86s\tremaining: 466ms\n",
      "430:\tlearn: 0.0436273\ttotal: 2.87s\tremaining: 460ms\n",
      "431:\tlearn: 0.0434600\ttotal: 2.88s\tremaining: 453ms\n",
      "432:\tlearn: 0.0432435\ttotal: 2.88s\tremaining: 446ms\n",
      "433:\tlearn: 0.0429960\ttotal: 2.89s\tremaining: 439ms\n",
      "434:\tlearn: 0.0428031\ttotal: 2.89s\tremaining: 433ms\n",
      "435:\tlearn: 0.0425838\ttotal: 2.9s\tremaining: 426ms\n",
      "436:\tlearn: 0.0424001\ttotal: 2.9s\tremaining: 419ms\n",
      "437:\tlearn: 0.0421785\ttotal: 2.91s\tremaining: 412ms\n",
      "438:\tlearn: 0.0420564\ttotal: 2.91s\tremaining: 405ms\n",
      "439:\tlearn: 0.0418379\ttotal: 2.92s\tremaining: 398ms\n",
      "440:\tlearn: 0.0415918\ttotal: 2.92s\tremaining: 391ms\n",
      "441:\tlearn: 0.0414077\ttotal: 2.93s\tremaining: 384ms\n",
      "442:\tlearn: 0.0411825\ttotal: 2.93s\tremaining: 377ms\n",
      "443:\tlearn: 0.0409623\ttotal: 2.94s\tremaining: 370ms\n",
      "444:\tlearn: 0.0408155\ttotal: 2.94s\tremaining: 363ms\n",
      "445:\tlearn: 0.0405913\ttotal: 2.94s\tremaining: 356ms\n",
      "446:\tlearn: 0.0405049\ttotal: 2.95s\tremaining: 350ms\n",
      "447:\tlearn: 0.0402797\ttotal: 2.96s\tremaining: 344ms\n",
      "448:\tlearn: 0.0401683\ttotal: 2.97s\tremaining: 338ms\n",
      "449:\tlearn: 0.0400039\ttotal: 2.98s\tremaining: 331ms\n",
      "450:\tlearn: 0.0398518\ttotal: 2.99s\tremaining: 325ms\n",
      "451:\tlearn: 0.0397027\ttotal: 3s\tremaining: 319ms\n",
      "452:\tlearn: 0.0395607\ttotal: 3.01s\tremaining: 313ms\n",
      "453:\tlearn: 0.0393675\ttotal: 3.02s\tremaining: 306ms\n",
      "454:\tlearn: 0.0392028\ttotal: 3.03s\tremaining: 300ms\n",
      "455:\tlearn: 0.0389936\ttotal: 3.04s\tremaining: 293ms\n",
      "456:\tlearn: 0.0388032\ttotal: 3.05s\tremaining: 287ms\n",
      "457:\tlearn: 0.0386074\ttotal: 3.06s\tremaining: 280ms\n",
      "458:\tlearn: 0.0384515\ttotal: 3.07s\tremaining: 274ms\n",
      "459:\tlearn: 0.0382248\ttotal: 3.07s\tremaining: 267ms\n",
      "460:\tlearn: 0.0380924\ttotal: 3.08s\tremaining: 261ms\n",
      "461:\tlearn: 0.0379117\ttotal: 3.08s\tremaining: 254ms\n",
      "462:\tlearn: 0.0377424\ttotal: 3.09s\tremaining: 247ms\n",
      "463:\tlearn: 0.0375738\ttotal: 3.1s\tremaining: 240ms\n",
      "464:\tlearn: 0.0374369\ttotal: 3.1s\tremaining: 233ms\n",
      "465:\tlearn: 0.0372302\ttotal: 3.1s\tremaining: 227ms\n",
      "466:\tlearn: 0.0369844\ttotal: 3.11s\tremaining: 220ms\n",
      "467:\tlearn: 0.0368435\ttotal: 3.12s\tremaining: 213ms\n",
      "468:\tlearn: 0.0366581\ttotal: 3.12s\tremaining: 206ms\n",
      "469:\tlearn: 0.0364507\ttotal: 3.12s\tremaining: 199ms\n",
      "470:\tlearn: 0.0362678\ttotal: 3.13s\tremaining: 193ms\n",
      "471:\tlearn: 0.0360812\ttotal: 3.13s\tremaining: 186ms\n",
      "472:\tlearn: 0.0359765\ttotal: 3.14s\tremaining: 179ms\n",
      "473:\tlearn: 0.0357686\ttotal: 3.14s\tremaining: 172ms\n",
      "474:\tlearn: 0.0355592\ttotal: 3.15s\tremaining: 166ms\n",
      "475:\tlearn: 0.0354350\ttotal: 3.15s\tremaining: 159ms\n",
      "476:\tlearn: 0.0352884\ttotal: 3.16s\tremaining: 152ms\n",
      "477:\tlearn: 0.0351194\ttotal: 3.17s\tremaining: 146ms\n",
      "478:\tlearn: 0.0349305\ttotal: 3.18s\tremaining: 139ms\n",
      "479:\tlearn: 0.0347576\ttotal: 3.19s\tremaining: 133ms\n",
      "480:\tlearn: 0.0345998\ttotal: 3.2s\tremaining: 126ms\n",
      "481:\tlearn: 0.0344430\ttotal: 3.21s\tremaining: 120ms\n",
      "482:\tlearn: 0.0342225\ttotal: 3.22s\tremaining: 113ms\n",
      "483:\tlearn: 0.0340198\ttotal: 3.23s\tremaining: 107ms\n",
      "484:\tlearn: 0.0338385\ttotal: 3.23s\tremaining: 100ms\n",
      "485:\tlearn: 0.0337554\ttotal: 3.24s\tremaining: 93.4ms\n",
      "486:\tlearn: 0.0336033\ttotal: 3.25s\tremaining: 86.7ms\n",
      "487:\tlearn: 0.0334314\ttotal: 3.26s\tremaining: 80.1ms\n",
      "488:\tlearn: 0.0332014\ttotal: 3.26s\tremaining: 73.4ms\n",
      "489:\tlearn: 0.0330328\ttotal: 3.27s\tremaining: 66.6ms\n",
      "490:\tlearn: 0.0328916\ttotal: 3.27s\tremaining: 59.9ms\n",
      "491:\tlearn: 0.0327717\ttotal: 3.27s\tremaining: 53.2ms\n",
      "492:\tlearn: 0.0326181\ttotal: 3.28s\tremaining: 46.6ms\n",
      "493:\tlearn: 0.0324955\ttotal: 3.28s\tremaining: 39.9ms\n",
      "494:\tlearn: 0.0323641\ttotal: 3.29s\tremaining: 33.2ms\n",
      "495:\tlearn: 0.0322427\ttotal: 3.29s\tremaining: 26.6ms\n",
      "496:\tlearn: 0.0321490\ttotal: 3.3s\tremaining: 19.9ms\n",
      "497:\tlearn: 0.0320159\ttotal: 3.3s\tremaining: 13.3ms\n",
      "498:\tlearn: 0.0318614\ttotal: 3.31s\tremaining: 6.63ms\n",
      "499:\tlearn: 0.0317407\ttotal: 3.31s\tremaining: 0us\n",
      "0:\tlearn: 0.6823160\ttotal: 4.35ms\tremaining: 2.17s\n",
      "1:\tlearn: 0.6714235\ttotal: 9.84ms\tremaining: 2.45s\n",
      "2:\tlearn: 0.6589568\ttotal: 16.6ms\tremaining: 2.76s\n",
      "3:\tlearn: 0.6495756\ttotal: 22.3ms\tremaining: 2.77s\n",
      "4:\tlearn: 0.6403084\ttotal: 27ms\tremaining: 2.68s\n",
      "5:\tlearn: 0.6305998\ttotal: 31.8ms\tremaining: 2.62s\n",
      "6:\tlearn: 0.6191067\ttotal: 36.7ms\tremaining: 2.59s\n",
      "7:\tlearn: 0.6115957\ttotal: 41.6ms\tremaining: 2.56s\n",
      "8:\tlearn: 0.6044720\ttotal: 45.7ms\tremaining: 2.49s\n",
      "9:\tlearn: 0.5969163\ttotal: 50.1ms\tremaining: 2.46s\n",
      "10:\tlearn: 0.5899724\ttotal: 54.3ms\tremaining: 2.42s\n",
      "11:\tlearn: 0.5831134\ttotal: 58.5ms\tremaining: 2.38s\n",
      "12:\tlearn: 0.5754308\ttotal: 62.7ms\tremaining: 2.35s\n",
      "13:\tlearn: 0.5683937\ttotal: 66.9ms\tremaining: 2.32s\n",
      "14:\tlearn: 0.5592937\ttotal: 71.2ms\tremaining: 2.3s\n",
      "15:\tlearn: 0.5545364\ttotal: 75.4ms\tremaining: 2.28s\n",
      "16:\tlearn: 0.5491438\ttotal: 84.9ms\tremaining: 2.41s\n",
      "17:\tlearn: 0.5405234\ttotal: 94.6ms\tremaining: 2.53s\n",
      "18:\tlearn: 0.5345217\ttotal: 104ms\tremaining: 2.64s\n",
      "19:\tlearn: 0.5284354\ttotal: 114ms\tremaining: 2.73s\n",
      "20:\tlearn: 0.5242061\ttotal: 123ms\tremaining: 2.81s\n",
      "21:\tlearn: 0.5195439\ttotal: 133ms\tremaining: 2.89s\n",
      "22:\tlearn: 0.5141056\ttotal: 142ms\tremaining: 2.95s\n",
      "23:\tlearn: 0.5083864\ttotal: 152ms\tremaining: 3.02s\n",
      "24:\tlearn: 0.5038422\ttotal: 162ms\tremaining: 3.07s\n",
      "25:\tlearn: 0.4986001\ttotal: 168ms\tremaining: 3.06s\n",
      "26:\tlearn: 0.4935376\ttotal: 174ms\tremaining: 3.05s\n",
      "27:\tlearn: 0.4882791\ttotal: 180ms\tremaining: 3.04s\n",
      "28:\tlearn: 0.4846026\ttotal: 188ms\tremaining: 3.05s\n",
      "29:\tlearn: 0.4795532\ttotal: 193ms\tremaining: 3.02s\n",
      "30:\tlearn: 0.4741132\ttotal: 197ms\tremaining: 2.98s\n",
      "31:\tlearn: 0.4714088\ttotal: 203ms\tremaining: 2.97s\n",
      "32:\tlearn: 0.4672833\ttotal: 207ms\tremaining: 2.93s\n",
      "33:\tlearn: 0.4631996\ttotal: 212ms\tremaining: 2.9s\n",
      "34:\tlearn: 0.4576200\ttotal: 217ms\tremaining: 2.88s\n",
      "35:\tlearn: 0.4534834\ttotal: 221ms\tremaining: 2.85s\n",
      "36:\tlearn: 0.4499818\ttotal: 225ms\tremaining: 2.82s\n",
      "37:\tlearn: 0.4477185\ttotal: 230ms\tremaining: 2.79s\n",
      "38:\tlearn: 0.4418181\ttotal: 233ms\tremaining: 2.76s\n",
      "39:\tlearn: 0.4391171\ttotal: 238ms\tremaining: 2.73s\n",
      "40:\tlearn: 0.4362083\ttotal: 242ms\tremaining: 2.71s\n",
      "41:\tlearn: 0.4326726\ttotal: 246ms\tremaining: 2.68s\n",
      "42:\tlearn: 0.4290161\ttotal: 250ms\tremaining: 2.66s\n",
      "43:\tlearn: 0.4260450\ttotal: 260ms\tremaining: 2.69s\n",
      "44:\tlearn: 0.4226606\ttotal: 269ms\tremaining: 2.72s\n",
      "45:\tlearn: 0.4198570\ttotal: 279ms\tremaining: 2.75s\n",
      "46:\tlearn: 0.4176257\ttotal: 289ms\tremaining: 2.78s\n",
      "47:\tlearn: 0.4147275\ttotal: 298ms\tremaining: 2.81s\n",
      "48:\tlearn: 0.4130361\ttotal: 308ms\tremaining: 2.83s\n",
      "49:\tlearn: 0.4100991\ttotal: 317ms\tremaining: 2.85s\n",
      "50:\tlearn: 0.4066316\ttotal: 327ms\tremaining: 2.87s\n",
      "51:\tlearn: 0.4038250\ttotal: 336ms\tremaining: 2.89s\n",
      "52:\tlearn: 0.4009416\ttotal: 342ms\tremaining: 2.88s\n",
      "53:\tlearn: 0.3970471\ttotal: 347ms\tremaining: 2.86s\n",
      "54:\tlearn: 0.3934325\ttotal: 352ms\tremaining: 2.85s\n",
      "55:\tlearn: 0.3909256\ttotal: 356ms\tremaining: 2.83s\n",
      "56:\tlearn: 0.3873648\ttotal: 361ms\tremaining: 2.81s\n",
      "57:\tlearn: 0.3844975\ttotal: 366ms\tremaining: 2.79s\n",
      "58:\tlearn: 0.3816340\ttotal: 370ms\tremaining: 2.77s\n",
      "59:\tlearn: 0.3789611\ttotal: 375ms\tremaining: 2.75s\n",
      "60:\tlearn: 0.3743253\ttotal: 379ms\tremaining: 2.73s\n",
      "61:\tlearn: 0.3720350\ttotal: 383ms\tremaining: 2.71s\n",
      "62:\tlearn: 0.3665520\ttotal: 387ms\tremaining: 2.69s\n",
      "63:\tlearn: 0.3636530\ttotal: 397ms\tremaining: 2.7s\n",
      "64:\tlearn: 0.3608346\ttotal: 407ms\tremaining: 2.72s\n",
      "65:\tlearn: 0.3589349\ttotal: 416ms\tremaining: 2.74s\n",
      "66:\tlearn: 0.3568871\ttotal: 426ms\tremaining: 2.75s\n",
      "67:\tlearn: 0.3550042\ttotal: 436ms\tremaining: 2.77s\n",
      "68:\tlearn: 0.3526940\ttotal: 445ms\tremaining: 2.78s\n",
      "69:\tlearn: 0.3503353\ttotal: 455ms\tremaining: 2.79s\n",
      "70:\tlearn: 0.3483110\ttotal: 462ms\tremaining: 2.79s\n",
      "71:\tlearn: 0.3455537\ttotal: 468ms\tremaining: 2.78s\n",
      "72:\tlearn: 0.3421947\ttotal: 475ms\tremaining: 2.77s\n",
      "73:\tlearn: 0.3396166\ttotal: 481ms\tremaining: 2.77s\n",
      "74:\tlearn: 0.3371540\ttotal: 487ms\tremaining: 2.76s\n",
      "75:\tlearn: 0.3320151\ttotal: 493ms\tremaining: 2.75s\n",
      "76:\tlearn: 0.3296468\ttotal: 498ms\tremaining: 2.74s\n",
      "77:\tlearn: 0.3254324\ttotal: 503ms\tremaining: 2.72s\n",
      "78:\tlearn: 0.3230963\ttotal: 508ms\tremaining: 2.71s\n",
      "79:\tlearn: 0.3212542\ttotal: 512ms\tremaining: 2.69s\n",
      "80:\tlearn: 0.3181782\ttotal: 517ms\tremaining: 2.67s\n",
      "81:\tlearn: 0.3160485\ttotal: 522ms\tremaining: 2.66s\n",
      "82:\tlearn: 0.3140311\ttotal: 527ms\tremaining: 2.65s\n",
      "83:\tlearn: 0.3116762\ttotal: 532ms\tremaining: 2.63s\n",
      "84:\tlearn: 0.3096799\ttotal: 536ms\tremaining: 2.62s\n",
      "85:\tlearn: 0.3075941\ttotal: 539ms\tremaining: 2.59s\n",
      "86:\tlearn: 0.3054433\ttotal: 543ms\tremaining: 2.58s\n",
      "87:\tlearn: 0.3035329\ttotal: 548ms\tremaining: 2.56s\n",
      "88:\tlearn: 0.3014647\ttotal: 552ms\tremaining: 2.55s\n",
      "89:\tlearn: 0.2992483\ttotal: 557ms\tremaining: 2.54s\n",
      "90:\tlearn: 0.2961293\ttotal: 566ms\tremaining: 2.55s\n",
      "91:\tlearn: 0.2930897\ttotal: 576ms\tremaining: 2.56s\n",
      "92:\tlearn: 0.2910420\ttotal: 586ms\tremaining: 2.56s\n",
      "93:\tlearn: 0.2887719\ttotal: 596ms\tremaining: 2.57s\n",
      "94:\tlearn: 0.2870360\ttotal: 605ms\tremaining: 2.58s\n",
      "95:\tlearn: 0.2850341\ttotal: 614ms\tremaining: 2.58s\n",
      "96:\tlearn: 0.2836271\ttotal: 624ms\tremaining: 2.59s\n",
      "97:\tlearn: 0.2819176\ttotal: 634ms\tremaining: 2.6s\n",
      "98:\tlearn: 0.2799620\ttotal: 643ms\tremaining: 2.61s\n",
      "99:\tlearn: 0.2780806\ttotal: 650ms\tremaining: 2.6s\n",
      "100:\tlearn: 0.2760599\ttotal: 656ms\tremaining: 2.59s\n",
      "101:\tlearn: 0.2746073\ttotal: 663ms\tremaining: 2.59s\n",
      "102:\tlearn: 0.2713113\ttotal: 669ms\tremaining: 2.58s\n",
      "103:\tlearn: 0.2697633\ttotal: 674ms\tremaining: 2.56s\n",
      "104:\tlearn: 0.2682113\ttotal: 679ms\tremaining: 2.55s\n",
      "105:\tlearn: 0.2665979\ttotal: 683ms\tremaining: 2.54s\n",
      "106:\tlearn: 0.2629476\ttotal: 688ms\tremaining: 2.53s\n",
      "107:\tlearn: 0.2614831\ttotal: 693ms\tremaining: 2.52s\n",
      "108:\tlearn: 0.2597488\ttotal: 698ms\tremaining: 2.5s\n",
      "109:\tlearn: 0.2569756\ttotal: 703ms\tremaining: 2.49s\n",
      "110:\tlearn: 0.2555956\ttotal: 707ms\tremaining: 2.48s\n",
      "111:\tlearn: 0.2535229\ttotal: 713ms\tremaining: 2.47s\n",
      "112:\tlearn: 0.2512499\ttotal: 717ms\tremaining: 2.46s\n",
      "113:\tlearn: 0.2498383\ttotal: 720ms\tremaining: 2.44s\n",
      "114:\tlearn: 0.2478867\ttotal: 727ms\tremaining: 2.43s\n",
      "115:\tlearn: 0.2464157\ttotal: 736ms\tremaining: 2.44s\n",
      "116:\tlearn: 0.2450010\ttotal: 746ms\tremaining: 2.44s\n",
      "117:\tlearn: 0.2435478\ttotal: 756ms\tremaining: 2.45s\n",
      "118:\tlearn: 0.2420362\ttotal: 765ms\tremaining: 2.45s\n",
      "119:\tlearn: 0.2405709\ttotal: 775ms\tremaining: 2.45s\n",
      "120:\tlearn: 0.2390654\ttotal: 785ms\tremaining: 2.46s\n",
      "121:\tlearn: 0.2367221\ttotal: 794ms\tremaining: 2.46s\n",
      "122:\tlearn: 0.2353569\ttotal: 804ms\tremaining: 2.46s\n",
      "123:\tlearn: 0.2339051\ttotal: 813ms\tremaining: 2.47s\n",
      "124:\tlearn: 0.2320211\ttotal: 822ms\tremaining: 2.47s\n",
      "125:\tlearn: 0.2306642\ttotal: 828ms\tremaining: 2.46s\n",
      "126:\tlearn: 0.2291544\ttotal: 834ms\tremaining: 2.45s\n",
      "127:\tlearn: 0.2277399\ttotal: 840ms\tremaining: 2.44s\n",
      "128:\tlearn: 0.2259946\ttotal: 847ms\tremaining: 2.43s\n",
      "129:\tlearn: 0.2247713\ttotal: 852ms\tremaining: 2.42s\n",
      "130:\tlearn: 0.2232353\ttotal: 857ms\tremaining: 2.41s\n",
      "131:\tlearn: 0.2218653\ttotal: 862ms\tremaining: 2.4s\n",
      "132:\tlearn: 0.2200860\ttotal: 866ms\tremaining: 2.39s\n",
      "133:\tlearn: 0.2189398\ttotal: 870ms\tremaining: 2.38s\n",
      "134:\tlearn: 0.2174881\ttotal: 875ms\tremaining: 2.37s\n",
      "135:\tlearn: 0.2152610\ttotal: 879ms\tremaining: 2.35s\n",
      "136:\tlearn: 0.2143014\ttotal: 885ms\tremaining: 2.34s\n",
      "137:\tlearn: 0.2131178\ttotal: 888ms\tremaining: 2.33s\n",
      "138:\tlearn: 0.2117968\ttotal: 892ms\tremaining: 2.31s\n",
      "139:\tlearn: 0.2103501\ttotal: 896ms\tremaining: 2.3s\n",
      "140:\tlearn: 0.2081157\ttotal: 906ms\tremaining: 2.31s\n",
      "141:\tlearn: 0.2069379\ttotal: 916ms\tremaining: 2.31s\n",
      "142:\tlearn: 0.2053501\ttotal: 925ms\tremaining: 2.31s\n",
      "143:\tlearn: 0.2038065\ttotal: 935ms\tremaining: 2.31s\n",
      "144:\tlearn: 0.2027160\ttotal: 945ms\tremaining: 2.31s\n",
      "145:\tlearn: 0.2015688\ttotal: 954ms\tremaining: 2.31s\n",
      "146:\tlearn: 0.2004458\ttotal: 964ms\tremaining: 2.31s\n",
      "147:\tlearn: 0.1984306\ttotal: 974ms\tremaining: 2.31s\n",
      "148:\tlearn: 0.1974178\ttotal: 983ms\tremaining: 2.31s\n",
      "149:\tlearn: 0.1965697\ttotal: 991ms\tremaining: 2.31s\n",
      "150:\tlearn: 0.1950230\ttotal: 997ms\tremaining: 2.31s\n",
      "151:\tlearn: 0.1939552\ttotal: 1s\tremaining: 2.3s\n",
      "152:\tlearn: 0.1926618\ttotal: 1.01s\tremaining: 2.29s\n",
      "153:\tlearn: 0.1917152\ttotal: 1.01s\tremaining: 2.28s\n",
      "154:\tlearn: 0.1905643\ttotal: 1.02s\tremaining: 2.27s\n",
      "155:\tlearn: 0.1893447\ttotal: 1.02s\tremaining: 2.26s\n",
      "156:\tlearn: 0.1882918\ttotal: 1.03s\tremaining: 2.25s\n",
      "157:\tlearn: 0.1870195\ttotal: 1.03s\tremaining: 2.24s\n",
      "158:\tlearn: 0.1859232\ttotal: 1.04s\tremaining: 2.23s\n",
      "159:\tlearn: 0.1850705\ttotal: 1.04s\tremaining: 2.22s\n",
      "160:\tlearn: 0.1828909\ttotal: 1.05s\tremaining: 2.21s\n",
      "161:\tlearn: 0.1819166\ttotal: 1.05s\tremaining: 2.2s\n",
      "162:\tlearn: 0.1809495\ttotal: 1.06s\tremaining: 2.19s\n",
      "163:\tlearn: 0.1799133\ttotal: 1.06s\tremaining: 2.17s\n",
      "164:\tlearn: 0.1790728\ttotal: 1.07s\tremaining: 2.17s\n",
      "165:\tlearn: 0.1781413\ttotal: 1.08s\tremaining: 2.17s\n",
      "166:\tlearn: 0.1770598\ttotal: 1.09s\tremaining: 2.17s\n",
      "167:\tlearn: 0.1760407\ttotal: 1.1s\tremaining: 2.17s\n",
      "168:\tlearn: 0.1749742\ttotal: 1.11s\tremaining: 2.17s\n",
      "169:\tlearn: 0.1732734\ttotal: 1.12s\tremaining: 2.17s\n",
      "170:\tlearn: 0.1723594\ttotal: 1.13s\tremaining: 2.17s\n",
      "171:\tlearn: 0.1714241\ttotal: 1.14s\tremaining: 2.17s\n",
      "172:\tlearn: 0.1705153\ttotal: 1.15s\tremaining: 2.17s\n",
      "173:\tlearn: 0.1695214\ttotal: 1.16s\tremaining: 2.16s\n",
      "174:\tlearn: 0.1686379\ttotal: 1.16s\tremaining: 2.16s\n",
      "175:\tlearn: 0.1670234\ttotal: 1.17s\tremaining: 2.15s\n",
      "176:\tlearn: 0.1661460\ttotal: 1.17s\tremaining: 2.14s\n",
      "177:\tlearn: 0.1653146\ttotal: 1.18s\tremaining: 2.13s\n",
      "178:\tlearn: 0.1641033\ttotal: 1.19s\tremaining: 2.13s\n",
      "179:\tlearn: 0.1633955\ttotal: 1.19s\tremaining: 2.12s\n",
      "180:\tlearn: 0.1626595\ttotal: 1.2s\tremaining: 2.11s\n",
      "181:\tlearn: 0.1616026\ttotal: 1.21s\tremaining: 2.11s\n",
      "182:\tlearn: 0.1600723\ttotal: 1.21s\tremaining: 2.1s\n",
      "183:\tlearn: 0.1592914\ttotal: 1.22s\tremaining: 2.09s\n",
      "184:\tlearn: 0.1585950\ttotal: 1.22s\tremaining: 2.08s\n",
      "185:\tlearn: 0.1561089\ttotal: 1.23s\tremaining: 2.07s\n",
      "186:\tlearn: 0.1551792\ttotal: 1.23s\tremaining: 2.06s\n",
      "187:\tlearn: 0.1542978\ttotal: 1.24s\tremaining: 2.05s\n",
      "188:\tlearn: 0.1535608\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.1527507\ttotal: 1.25s\tremaining: 2.03s\n",
      "190:\tlearn: 0.1518395\ttotal: 1.25s\tremaining: 2.02s\n",
      "191:\tlearn: 0.1509784\ttotal: 1.25s\tremaining: 2.01s\n",
      "192:\tlearn: 0.1498818\ttotal: 1.25s\tremaining: 2s\n",
      "193:\tlearn: 0.1490754\ttotal: 1.26s\tremaining: 1.99s\n",
      "194:\tlearn: 0.1484910\ttotal: 1.26s\tremaining: 1.98s\n",
      "195:\tlearn: 0.1478038\ttotal: 1.27s\tremaining: 1.98s\n",
      "196:\tlearn: 0.1470617\ttotal: 1.28s\tremaining: 1.98s\n",
      "197:\tlearn: 0.1463747\ttotal: 1.29s\tremaining: 1.97s\n",
      "198:\tlearn: 0.1456681\ttotal: 1.3s\tremaining: 1.97s\n",
      "199:\tlearn: 0.1449875\ttotal: 1.31s\tremaining: 1.97s\n",
      "200:\tlearn: 0.1434395\ttotal: 1.32s\tremaining: 1.97s\n",
      "201:\tlearn: 0.1426415\ttotal: 1.33s\tremaining: 1.97s\n",
      "202:\tlearn: 0.1419658\ttotal: 1.34s\tremaining: 1.96s\n",
      "203:\tlearn: 0.1412813\ttotal: 1.35s\tremaining: 1.96s\n",
      "204:\tlearn: 0.1406178\ttotal: 1.36s\tremaining: 1.96s\n",
      "205:\tlearn: 0.1398104\ttotal: 1.37s\tremaining: 1.95s\n",
      "206:\tlearn: 0.1393639\ttotal: 1.38s\tremaining: 1.95s\n",
      "207:\tlearn: 0.1384452\ttotal: 1.38s\tremaining: 1.94s\n",
      "208:\tlearn: 0.1377823\ttotal: 1.39s\tremaining: 1.93s\n",
      "209:\tlearn: 0.1367585\ttotal: 1.39s\tremaining: 1.93s\n",
      "210:\tlearn: 0.1359148\ttotal: 1.4s\tremaining: 1.92s\n",
      "211:\tlearn: 0.1345285\ttotal: 1.4s\tremaining: 1.91s\n",
      "212:\tlearn: 0.1339260\ttotal: 1.41s\tremaining: 1.9s\n",
      "213:\tlearn: 0.1332877\ttotal: 1.41s\tremaining: 1.89s\n",
      "214:\tlearn: 0.1325453\ttotal: 1.42s\tremaining: 1.88s\n",
      "215:\tlearn: 0.1320885\ttotal: 1.42s\tremaining: 1.87s\n",
      "216:\tlearn: 0.1313427\ttotal: 1.43s\tremaining: 1.86s\n",
      "217:\tlearn: 0.1306750\ttotal: 1.43s\tremaining: 1.85s\n",
      "218:\tlearn: 0.1298538\ttotal: 1.43s\tremaining: 1.84s\n",
      "219:\tlearn: 0.1291739\ttotal: 1.44s\tremaining: 1.83s\n",
      "220:\tlearn: 0.1285604\ttotal: 1.45s\tremaining: 1.82s\n",
      "221:\tlearn: 0.1281606\ttotal: 1.46s\tremaining: 1.82s\n",
      "222:\tlearn: 0.1274222\ttotal: 1.47s\tremaining: 1.82s\n",
      "223:\tlearn: 0.1268344\ttotal: 1.47s\tremaining: 1.82s\n",
      "224:\tlearn: 0.1261769\ttotal: 1.48s\tremaining: 1.81s\n",
      "225:\tlearn: 0.1254874\ttotal: 1.49s\tremaining: 1.81s\n",
      "226:\tlearn: 0.1247830\ttotal: 1.5s\tremaining: 1.81s\n",
      "227:\tlearn: 0.1241469\ttotal: 1.51s\tremaining: 1.8s\n",
      "228:\tlearn: 0.1234614\ttotal: 1.52s\tremaining: 1.8s\n",
      "229:\tlearn: 0.1228329\ttotal: 1.53s\tremaining: 1.8s\n",
      "230:\tlearn: 0.1221305\ttotal: 1.54s\tremaining: 1.79s\n",
      "231:\tlearn: 0.1215524\ttotal: 1.54s\tremaining: 1.78s\n",
      "232:\tlearn: 0.1207271\ttotal: 1.55s\tremaining: 1.78s\n",
      "233:\tlearn: 0.1202737\ttotal: 1.56s\tremaining: 1.77s\n",
      "234:\tlearn: 0.1190715\ttotal: 1.56s\tremaining: 1.76s\n",
      "235:\tlearn: 0.1183184\ttotal: 1.57s\tremaining: 1.76s\n",
      "236:\tlearn: 0.1176806\ttotal: 1.58s\tremaining: 1.75s\n",
      "237:\tlearn: 0.1170810\ttotal: 1.59s\tremaining: 1.75s\n",
      "238:\tlearn: 0.1164651\ttotal: 1.59s\tremaining: 1.74s\n",
      "239:\tlearn: 0.1158425\ttotal: 1.6s\tremaining: 1.73s\n",
      "240:\tlearn: 0.1153096\ttotal: 1.6s\tremaining: 1.72s\n",
      "241:\tlearn: 0.1148286\ttotal: 1.61s\tremaining: 1.71s\n",
      "242:\tlearn: 0.1142902\ttotal: 1.61s\tremaining: 1.7s\n",
      "243:\tlearn: 0.1135549\ttotal: 1.62s\tremaining: 1.7s\n",
      "244:\tlearn: 0.1130374\ttotal: 1.62s\tremaining: 1.69s\n",
      "245:\tlearn: 0.1123965\ttotal: 1.63s\tremaining: 1.68s\n",
      "246:\tlearn: 0.1117921\ttotal: 1.63s\tremaining: 1.67s\n",
      "247:\tlearn: 0.1114036\ttotal: 1.63s\tremaining: 1.66s\n",
      "248:\tlearn: 0.1108451\ttotal: 1.64s\tremaining: 1.65s\n",
      "249:\tlearn: 0.1102597\ttotal: 1.64s\tremaining: 1.64s\n",
      "250:\tlearn: 0.1097287\ttotal: 1.65s\tremaining: 1.64s\n",
      "251:\tlearn: 0.1091752\ttotal: 1.66s\tremaining: 1.63s\n",
      "252:\tlearn: 0.1086546\ttotal: 1.67s\tremaining: 1.63s\n",
      "253:\tlearn: 0.1080470\ttotal: 1.68s\tremaining: 1.63s\n",
      "254:\tlearn: 0.1074337\ttotal: 1.69s\tremaining: 1.62s\n",
      "255:\tlearn: 0.1069627\ttotal: 1.7s\tremaining: 1.62s\n",
      "256:\tlearn: 0.1064232\ttotal: 1.71s\tremaining: 1.61s\n",
      "257:\tlearn: 0.1060756\ttotal: 1.72s\tremaining: 1.61s\n",
      "258:\tlearn: 0.1054387\ttotal: 1.73s\tremaining: 1.61s\n",
      "259:\tlearn: 0.1049755\ttotal: 1.73s\tremaining: 1.6s\n",
      "260:\tlearn: 0.1045675\ttotal: 1.74s\tremaining: 1.59s\n",
      "261:\tlearn: 0.1041805\ttotal: 1.75s\tremaining: 1.59s\n",
      "262:\tlearn: 0.1037122\ttotal: 1.75s\tremaining: 1.58s\n",
      "263:\tlearn: 0.1030516\ttotal: 1.76s\tremaining: 1.57s\n",
      "264:\tlearn: 0.1026532\ttotal: 1.76s\tremaining: 1.56s\n",
      "265:\tlearn: 0.1019825\ttotal: 1.77s\tremaining: 1.56s\n",
      "266:\tlearn: 0.1015492\ttotal: 1.78s\tremaining: 1.55s\n",
      "267:\tlearn: 0.1005491\ttotal: 1.78s\tremaining: 1.54s\n",
      "268:\tlearn: 0.1000793\ttotal: 1.78s\tremaining: 1.53s\n",
      "269:\tlearn: 0.0996490\ttotal: 1.79s\tremaining: 1.52s\n",
      "270:\tlearn: 0.0992051\ttotal: 1.79s\tremaining: 1.52s\n",
      "271:\tlearn: 0.0987156\ttotal: 1.8s\tremaining: 1.51s\n",
      "272:\tlearn: 0.0982860\ttotal: 1.8s\tremaining: 1.5s\n",
      "273:\tlearn: 0.0978163\ttotal: 1.81s\tremaining: 1.49s\n",
      "274:\tlearn: 0.0974718\ttotal: 1.81s\tremaining: 1.48s\n",
      "275:\tlearn: 0.0969615\ttotal: 1.82s\tremaining: 1.47s\n",
      "276:\tlearn: 0.0962941\ttotal: 1.82s\tremaining: 1.47s\n",
      "277:\tlearn: 0.0957813\ttotal: 1.82s\tremaining: 1.46s\n",
      "278:\tlearn: 0.0954275\ttotal: 1.83s\tremaining: 1.45s\n",
      "279:\tlearn: 0.0949215\ttotal: 1.83s\tremaining: 1.44s\n",
      "280:\tlearn: 0.0944762\ttotal: 1.84s\tremaining: 1.44s\n",
      "281:\tlearn: 0.0941216\ttotal: 1.85s\tremaining: 1.43s\n",
      "282:\tlearn: 0.0937080\ttotal: 1.86s\tremaining: 1.43s\n",
      "283:\tlearn: 0.0931911\ttotal: 1.87s\tremaining: 1.42s\n",
      "284:\tlearn: 0.0926083\ttotal: 1.88s\tremaining: 1.42s\n",
      "285:\tlearn: 0.0921859\ttotal: 1.89s\tremaining: 1.42s\n",
      "286:\tlearn: 0.0916840\ttotal: 1.9s\tremaining: 1.41s\n",
      "287:\tlearn: 0.0913281\ttotal: 1.91s\tremaining: 1.41s\n",
      "288:\tlearn: 0.0908638\ttotal: 1.92s\tremaining: 1.4s\n",
      "289:\tlearn: 0.0904375\ttotal: 1.93s\tremaining: 1.4s\n",
      "290:\tlearn: 0.0899741\ttotal: 1.93s\tremaining: 1.39s\n",
      "291:\tlearn: 0.0895255\ttotal: 1.94s\tremaining: 1.38s\n",
      "292:\tlearn: 0.0890689\ttotal: 1.95s\tremaining: 1.38s\n",
      "293:\tlearn: 0.0886941\ttotal: 1.95s\tremaining: 1.37s\n",
      "294:\tlearn: 0.0881056\ttotal: 1.96s\tremaining: 1.36s\n",
      "295:\tlearn: 0.0876783\ttotal: 1.97s\tremaining: 1.35s\n",
      "296:\tlearn: 0.0873702\ttotal: 1.97s\tremaining: 1.35s\n",
      "297:\tlearn: 0.0869871\ttotal: 1.98s\tremaining: 1.34s\n",
      "298:\tlearn: 0.0865624\ttotal: 1.98s\tremaining: 1.33s\n",
      "299:\tlearn: 0.0861621\ttotal: 1.98s\tremaining: 1.32s\n",
      "300:\tlearn: 0.0858076\ttotal: 1.99s\tremaining: 1.31s\n",
      "301:\tlearn: 0.0852836\ttotal: 1.99s\tremaining: 1.31s\n",
      "302:\tlearn: 0.0849002\ttotal: 2s\tremaining: 1.3s\n",
      "303:\tlearn: 0.0845042\ttotal: 2s\tremaining: 1.29s\n",
      "304:\tlearn: 0.0839514\ttotal: 2.01s\tremaining: 1.28s\n",
      "305:\tlearn: 0.0836515\ttotal: 2.02s\tremaining: 1.28s\n",
      "306:\tlearn: 0.0832316\ttotal: 2.03s\tremaining: 1.27s\n",
      "307:\tlearn: 0.0827680\ttotal: 2.04s\tremaining: 1.27s\n",
      "308:\tlearn: 0.0824335\ttotal: 2.05s\tremaining: 1.26s\n",
      "309:\tlearn: 0.0821076\ttotal: 2.06s\tremaining: 1.26s\n",
      "310:\tlearn: 0.0817902\ttotal: 2.07s\tremaining: 1.25s\n",
      "311:\tlearn: 0.0813488\ttotal: 2.08s\tremaining: 1.25s\n",
      "312:\tlearn: 0.0809722\ttotal: 2.08s\tremaining: 1.25s\n",
      "313:\tlearn: 0.0806203\ttotal: 2.1s\tremaining: 1.24s\n",
      "314:\tlearn: 0.0800479\ttotal: 2.1s\tremaining: 1.23s\n",
      "315:\tlearn: 0.0795971\ttotal: 2.11s\tremaining: 1.23s\n",
      "316:\tlearn: 0.0790351\ttotal: 2.12s\tremaining: 1.22s\n",
      "317:\tlearn: 0.0787088\ttotal: 2.12s\tremaining: 1.21s\n",
      "318:\tlearn: 0.0783149\ttotal: 2.13s\tremaining: 1.21s\n",
      "319:\tlearn: 0.0779650\ttotal: 2.13s\tremaining: 1.2s\n",
      "320:\tlearn: 0.0776212\ttotal: 2.14s\tremaining: 1.19s\n",
      "321:\tlearn: 0.0772648\ttotal: 2.15s\tremaining: 1.19s\n",
      "322:\tlearn: 0.0768657\ttotal: 2.15s\tremaining: 1.18s\n",
      "323:\tlearn: 0.0765035\ttotal: 2.16s\tremaining: 1.17s\n",
      "324:\tlearn: 0.0761392\ttotal: 2.16s\tremaining: 1.16s\n",
      "325:\tlearn: 0.0754243\ttotal: 2.17s\tremaining: 1.16s\n",
      "326:\tlearn: 0.0752544\ttotal: 2.17s\tremaining: 1.15s\n",
      "327:\tlearn: 0.0749071\ttotal: 2.18s\tremaining: 1.14s\n",
      "328:\tlearn: 0.0745612\ttotal: 2.18s\tremaining: 1.13s\n",
      "329:\tlearn: 0.0741910\ttotal: 2.19s\tremaining: 1.13s\n",
      "330:\tlearn: 0.0738801\ttotal: 2.19s\tremaining: 1.12s\n",
      "331:\tlearn: 0.0735077\ttotal: 2.19s\tremaining: 1.11s\n",
      "332:\tlearn: 0.0731436\ttotal: 2.2s\tremaining: 1.1s\n",
      "333:\tlearn: 0.0728442\ttotal: 2.2s\tremaining: 1.09s\n",
      "334:\tlearn: 0.0724198\ttotal: 2.21s\tremaining: 1.09s\n",
      "335:\tlearn: 0.0721445\ttotal: 2.22s\tremaining: 1.08s\n",
      "336:\tlearn: 0.0718071\ttotal: 2.23s\tremaining: 1.08s\n",
      "337:\tlearn: 0.0715724\ttotal: 2.23s\tremaining: 1.07s\n",
      "338:\tlearn: 0.0712247\ttotal: 2.25s\tremaining: 1.07s\n",
      "339:\tlearn: 0.0709670\ttotal: 2.25s\tremaining: 1.06s\n",
      "340:\tlearn: 0.0705739\ttotal: 2.26s\tremaining: 1.05s\n",
      "341:\tlearn: 0.0703275\ttotal: 2.27s\tremaining: 1.05s\n",
      "342:\tlearn: 0.0700421\ttotal: 2.28s\tremaining: 1.04s\n",
      "343:\tlearn: 0.0696904\ttotal: 2.29s\tremaining: 1.04s\n",
      "344:\tlearn: 0.0693640\ttotal: 2.3s\tremaining: 1.03s\n",
      "345:\tlearn: 0.0690011\ttotal: 2.31s\tremaining: 1.02s\n",
      "346:\tlearn: 0.0682438\ttotal: 2.31s\tremaining: 1.02s\n",
      "347:\tlearn: 0.0679199\ttotal: 2.32s\tremaining: 1.01s\n",
      "348:\tlearn: 0.0674979\ttotal: 2.32s\tremaining: 1s\n",
      "349:\tlearn: 0.0671721\ttotal: 2.33s\tremaining: 999ms\n",
      "350:\tlearn: 0.0669045\ttotal: 2.34s\tremaining: 992ms\n",
      "351:\tlearn: 0.0665921\ttotal: 2.34s\tremaining: 986ms\n",
      "352:\tlearn: 0.0662352\ttotal: 2.35s\tremaining: 978ms\n",
      "353:\tlearn: 0.0657317\ttotal: 2.35s\tremaining: 970ms\n",
      "354:\tlearn: 0.0654773\ttotal: 2.36s\tremaining: 963ms\n",
      "355:\tlearn: 0.0651410\ttotal: 2.36s\tremaining: 955ms\n",
      "356:\tlearn: 0.0648546\ttotal: 2.37s\tremaining: 948ms\n",
      "357:\tlearn: 0.0647279\ttotal: 2.37s\tremaining: 940ms\n",
      "358:\tlearn: 0.0645693\ttotal: 2.38s\tremaining: 933ms\n",
      "359:\tlearn: 0.0642435\ttotal: 2.38s\tremaining: 925ms\n",
      "360:\tlearn: 0.0639631\ttotal: 2.38s\tremaining: 918ms\n",
      "361:\tlearn: 0.0636393\ttotal: 2.39s\tremaining: 910ms\n",
      "362:\tlearn: 0.0632382\ttotal: 2.39s\tremaining: 903ms\n",
      "363:\tlearn: 0.0630082\ttotal: 2.4s\tremaining: 896ms\n",
      "364:\tlearn: 0.0627289\ttotal: 2.4s\tremaining: 888ms\n",
      "365:\tlearn: 0.0624736\ttotal: 2.4s\tremaining: 881ms\n",
      "366:\tlearn: 0.0622435\ttotal: 2.42s\tremaining: 875ms\n",
      "367:\tlearn: 0.0619868\ttotal: 2.42s\tremaining: 870ms\n",
      "368:\tlearn: 0.0617419\ttotal: 2.43s\tremaining: 864ms\n",
      "369:\tlearn: 0.0613455\ttotal: 2.44s\tremaining: 859ms\n",
      "370:\tlearn: 0.0610218\ttotal: 2.45s\tremaining: 853ms\n",
      "371:\tlearn: 0.0607358\ttotal: 2.46s\tremaining: 847ms\n",
      "372:\tlearn: 0.0603910\ttotal: 2.47s\tremaining: 842ms\n",
      "373:\tlearn: 0.0602428\ttotal: 2.48s\tremaining: 836ms\n",
      "374:\tlearn: 0.0599841\ttotal: 2.49s\tremaining: 831ms\n",
      "375:\tlearn: 0.0596857\ttotal: 2.5s\tremaining: 824ms\n",
      "376:\tlearn: 0.0592635\ttotal: 2.5s\tremaining: 817ms\n",
      "377:\tlearn: 0.0589908\ttotal: 2.51s\tremaining: 810ms\n",
      "378:\tlearn: 0.0587189\ttotal: 2.52s\tremaining: 804ms\n",
      "379:\tlearn: 0.0584123\ttotal: 2.52s\tremaining: 797ms\n",
      "380:\tlearn: 0.0581877\ttotal: 2.53s\tremaining: 790ms\n",
      "381:\tlearn: 0.0578338\ttotal: 2.53s\tremaining: 782ms\n",
      "382:\tlearn: 0.0575404\ttotal: 2.54s\tremaining: 775ms\n",
      "383:\tlearn: 0.0572591\ttotal: 2.54s\tremaining: 768ms\n",
      "384:\tlearn: 0.0570622\ttotal: 2.55s\tremaining: 761ms\n",
      "385:\tlearn: 0.0566891\ttotal: 2.55s\tremaining: 753ms\n",
      "386:\tlearn: 0.0564620\ttotal: 2.56s\tremaining: 746ms\n",
      "387:\tlearn: 0.0561702\ttotal: 2.56s\tremaining: 739ms\n",
      "388:\tlearn: 0.0559403\ttotal: 2.56s\tremaining: 732ms\n",
      "389:\tlearn: 0.0556902\ttotal: 2.57s\tremaining: 725ms\n",
      "390:\tlearn: 0.0555334\ttotal: 2.57s\tremaining: 717ms\n",
      "391:\tlearn: 0.0554215\ttotal: 2.58s\tremaining: 710ms\n",
      "392:\tlearn: 0.0551592\ttotal: 2.59s\tremaining: 705ms\n",
      "393:\tlearn: 0.0549267\ttotal: 2.6s\tremaining: 699ms\n",
      "394:\tlearn: 0.0546995\ttotal: 2.61s\tremaining: 693ms\n",
      "395:\tlearn: 0.0544387\ttotal: 2.62s\tremaining: 687ms\n",
      "396:\tlearn: 0.0541872\ttotal: 2.63s\tremaining: 681ms\n",
      "397:\tlearn: 0.0539853\ttotal: 2.64s\tremaining: 676ms\n",
      "398:\tlearn: 0.0537770\ttotal: 2.65s\tremaining: 670ms\n",
      "399:\tlearn: 0.0534687\ttotal: 2.65s\tremaining: 664ms\n",
      "400:\tlearn: 0.0531755\ttotal: 2.67s\tremaining: 658ms\n",
      "401:\tlearn: 0.0530174\ttotal: 2.67s\tremaining: 652ms\n",
      "402:\tlearn: 0.0527483\ttotal: 2.68s\tremaining: 645ms\n",
      "403:\tlearn: 0.0525373\ttotal: 2.69s\tremaining: 638ms\n",
      "404:\tlearn: 0.0523311\ttotal: 2.69s\tremaining: 632ms\n",
      "405:\tlearn: 0.0521009\ttotal: 2.7s\tremaining: 625ms\n",
      "406:\tlearn: 0.0519214\ttotal: 2.7s\tremaining: 618ms\n",
      "407:\tlearn: 0.0516175\ttotal: 2.71s\tremaining: 611ms\n",
      "408:\tlearn: 0.0514061\ttotal: 2.72s\tremaining: 605ms\n",
      "409:\tlearn: 0.0512092\ttotal: 2.72s\tremaining: 597ms\n",
      "410:\tlearn: 0.0509788\ttotal: 2.73s\tremaining: 590ms\n",
      "411:\tlearn: 0.0507800\ttotal: 2.73s\tremaining: 583ms\n",
      "412:\tlearn: 0.0505853\ttotal: 2.73s\tremaining: 576ms\n",
      "413:\tlearn: 0.0504308\ttotal: 2.74s\tremaining: 569ms\n",
      "414:\tlearn: 0.0501821\ttotal: 2.74s\tremaining: 562ms\n",
      "415:\tlearn: 0.0499967\ttotal: 2.75s\tremaining: 555ms\n",
      "416:\tlearn: 0.0497343\ttotal: 2.76s\tremaining: 549ms\n",
      "417:\tlearn: 0.0494958\ttotal: 2.77s\tremaining: 543ms\n",
      "418:\tlearn: 0.0493544\ttotal: 2.78s\tremaining: 537ms\n",
      "419:\tlearn: 0.0491457\ttotal: 2.79s\tremaining: 531ms\n",
      "420:\tlearn: 0.0489023\ttotal: 2.79s\tremaining: 525ms\n",
      "421:\tlearn: 0.0486770\ttotal: 2.81s\tremaining: 519ms\n",
      "422:\tlearn: 0.0484716\ttotal: 2.81s\tremaining: 512ms\n",
      "423:\tlearn: 0.0484501\ttotal: 2.82s\tremaining: 506ms\n",
      "424:\tlearn: 0.0482532\ttotal: 2.83s\tremaining: 500ms\n",
      "425:\tlearn: 0.0480398\ttotal: 2.84s\tremaining: 494ms\n",
      "426:\tlearn: 0.0478554\ttotal: 2.85s\tremaining: 487ms\n",
      "427:\tlearn: 0.0478354\ttotal: 2.85s\tremaining: 480ms\n",
      "428:\tlearn: 0.0476522\ttotal: 2.86s\tremaining: 473ms\n",
      "429:\tlearn: 0.0474274\ttotal: 2.87s\tremaining: 467ms\n",
      "430:\tlearn: 0.0472028\ttotal: 2.87s\tremaining: 460ms\n",
      "431:\tlearn: 0.0469971\ttotal: 2.88s\tremaining: 453ms\n",
      "432:\tlearn: 0.0467977\ttotal: 2.89s\tremaining: 447ms\n",
      "433:\tlearn: 0.0465825\ttotal: 2.89s\tremaining: 440ms\n",
      "434:\tlearn: 0.0463220\ttotal: 2.9s\tremaining: 433ms\n",
      "435:\tlearn: 0.0461096\ttotal: 2.9s\tremaining: 426ms\n",
      "436:\tlearn: 0.0459037\ttotal: 2.91s\tremaining: 419ms\n",
      "437:\tlearn: 0.0457823\ttotal: 2.91s\tremaining: 412ms\n",
      "438:\tlearn: 0.0456070\ttotal: 2.92s\tremaining: 405ms\n",
      "439:\tlearn: 0.0452090\ttotal: 2.92s\tremaining: 398ms\n",
      "440:\tlearn: 0.0451875\ttotal: 2.92s\tremaining: 391ms\n",
      "441:\tlearn: 0.0449404\ttotal: 2.93s\tremaining: 384ms\n",
      "442:\tlearn: 0.0447539\ttotal: 2.93s\tremaining: 377ms\n",
      "443:\tlearn: 0.0445549\ttotal: 2.94s\tremaining: 371ms\n",
      "444:\tlearn: 0.0441270\ttotal: 2.94s\tremaining: 364ms\n",
      "445:\tlearn: 0.0439077\ttotal: 2.95s\tremaining: 357ms\n",
      "446:\tlearn: 0.0438916\ttotal: 2.95s\tremaining: 350ms\n",
      "447:\tlearn: 0.0436613\ttotal: 2.96s\tremaining: 343ms\n",
      "448:\tlearn: 0.0434567\ttotal: 2.96s\tremaining: 336ms\n",
      "449:\tlearn: 0.0432423\ttotal: 2.97s\tremaining: 330ms\n",
      "450:\tlearn: 0.0430313\ttotal: 2.98s\tremaining: 324ms\n",
      "451:\tlearn: 0.0428541\ttotal: 2.99s\tremaining: 318ms\n",
      "452:\tlearn: 0.0427264\ttotal: 3s\tremaining: 311ms\n",
      "453:\tlearn: 0.0425368\ttotal: 3.01s\tremaining: 305ms\n",
      "454:\tlearn: 0.0423828\ttotal: 3.02s\tremaining: 299ms\n",
      "455:\tlearn: 0.0421234\ttotal: 3.03s\tremaining: 292ms\n",
      "456:\tlearn: 0.0419170\ttotal: 3.04s\tremaining: 286ms\n",
      "457:\tlearn: 0.0417199\ttotal: 3.04s\tremaining: 279ms\n",
      "458:\tlearn: 0.0414981\ttotal: 3.05s\tremaining: 272ms\n",
      "459:\tlearn: 0.0413311\ttotal: 3.05s\tremaining: 266ms\n",
      "460:\tlearn: 0.0411681\ttotal: 3.06s\tremaining: 259ms\n",
      "461:\tlearn: 0.0409565\ttotal: 3.07s\tremaining: 252ms\n",
      "462:\tlearn: 0.0407171\ttotal: 3.07s\tremaining: 245ms\n",
      "463:\tlearn: 0.0405341\ttotal: 3.08s\tremaining: 239ms\n",
      "464:\tlearn: 0.0403769\ttotal: 3.08s\tremaining: 232ms\n",
      "465:\tlearn: 0.0400160\ttotal: 3.08s\tremaining: 225ms\n",
      "466:\tlearn: 0.0398107\ttotal: 3.09s\tremaining: 218ms\n",
      "467:\tlearn: 0.0396154\ttotal: 3.09s\tremaining: 212ms\n",
      "468:\tlearn: 0.0394592\ttotal: 3.1s\tremaining: 205ms\n",
      "469:\tlearn: 0.0393590\ttotal: 3.1s\tremaining: 198ms\n",
      "470:\tlearn: 0.0391991\ttotal: 3.11s\tremaining: 191ms\n",
      "471:\tlearn: 0.0390361\ttotal: 3.11s\tremaining: 185ms\n",
      "472:\tlearn: 0.0388512\ttotal: 3.12s\tremaining: 178ms\n",
      "473:\tlearn: 0.0386767\ttotal: 3.12s\tremaining: 171ms\n",
      "474:\tlearn: 0.0385205\ttotal: 3.13s\tremaining: 165ms\n",
      "475:\tlearn: 0.0383232\ttotal: 3.14s\tremaining: 159ms\n",
      "476:\tlearn: 0.0381625\ttotal: 3.15s\tremaining: 152ms\n",
      "477:\tlearn: 0.0380026\ttotal: 3.16s\tremaining: 146ms\n",
      "478:\tlearn: 0.0378460\ttotal: 3.17s\tremaining: 139ms\n",
      "479:\tlearn: 0.0376601\ttotal: 3.18s\tremaining: 133ms\n",
      "480:\tlearn: 0.0375385\ttotal: 3.19s\tremaining: 126ms\n",
      "481:\tlearn: 0.0373801\ttotal: 3.2s\tremaining: 120ms\n",
      "482:\tlearn: 0.0371372\ttotal: 3.21s\tremaining: 113ms\n",
      "483:\tlearn: 0.0369560\ttotal: 3.21s\tremaining: 106ms\n",
      "484:\tlearn: 0.0368115\ttotal: 3.22s\tremaining: 99.6ms\n",
      "485:\tlearn: 0.0366527\ttotal: 3.23s\tremaining: 93ms\n",
      "486:\tlearn: 0.0364985\ttotal: 3.23s\tremaining: 86.3ms\n",
      "487:\tlearn: 0.0363734\ttotal: 3.24s\tremaining: 79.6ms\n",
      "488:\tlearn: 0.0361850\ttotal: 3.24s\tremaining: 73ms\n",
      "489:\tlearn: 0.0359623\ttotal: 3.25s\tremaining: 66.3ms\n",
      "490:\tlearn: 0.0357686\ttotal: 3.25s\tremaining: 59.6ms\n",
      "491:\tlearn: 0.0356378\ttotal: 3.26s\tremaining: 53ms\n",
      "492:\tlearn: 0.0352305\ttotal: 3.26s\tremaining: 46.3ms\n",
      "493:\tlearn: 0.0351131\ttotal: 3.27s\tremaining: 39.7ms\n",
      "494:\tlearn: 0.0349523\ttotal: 3.27s\tremaining: 33ms\n",
      "495:\tlearn: 0.0348092\ttotal: 3.27s\tremaining: 26.4ms\n",
      "496:\tlearn: 0.0347989\ttotal: 3.28s\tremaining: 19.8ms\n",
      "497:\tlearn: 0.0347119\ttotal: 3.28s\tremaining: 13.2ms\n",
      "498:\tlearn: 0.0346059\ttotal: 3.29s\tremaining: 6.59ms\n",
      "499:\tlearn: 0.0344383\ttotal: 3.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6821022\ttotal: 5.51ms\tremaining: 2.75s\n",
      "1:\tlearn: 0.6688852\ttotal: 10.2ms\tremaining: 2.55s\n",
      "2:\tlearn: 0.6552225\ttotal: 15.1ms\tremaining: 2.5s\n",
      "3:\tlearn: 0.6452622\ttotal: 19.9ms\tremaining: 2.46s\n",
      "4:\tlearn: 0.6353816\ttotal: 26.2ms\tremaining: 2.59s\n",
      "5:\tlearn: 0.6274518\ttotal: 31.4ms\tremaining: 2.58s\n",
      "6:\tlearn: 0.6196954\ttotal: 35ms\tremaining: 2.47s\n",
      "7:\tlearn: 0.6141336\ttotal: 39.9ms\tremaining: 2.45s\n",
      "8:\tlearn: 0.6086396\ttotal: 44.4ms\tremaining: 2.42s\n",
      "9:\tlearn: 0.6004363\ttotal: 48.5ms\tremaining: 2.38s\n",
      "10:\tlearn: 0.5927496\ttotal: 52.9ms\tremaining: 2.35s\n",
      "11:\tlearn: 0.5845742\ttotal: 57.2ms\tremaining: 2.32s\n",
      "12:\tlearn: 0.5755880\ttotal: 61.1ms\tremaining: 2.29s\n",
      "13:\tlearn: 0.5708838\ttotal: 65.2ms\tremaining: 2.26s\n",
      "14:\tlearn: 0.5646411\ttotal: 69.4ms\tremaining: 2.24s\n",
      "15:\tlearn: 0.5584175\ttotal: 73.6ms\tremaining: 2.23s\n",
      "16:\tlearn: 0.5526512\ttotal: 77.6ms\tremaining: 2.21s\n",
      "17:\tlearn: 0.5473923\ttotal: 87.5ms\tremaining: 2.34s\n",
      "18:\tlearn: 0.5406503\ttotal: 96.9ms\tremaining: 2.45s\n",
      "19:\tlearn: 0.5345236\ttotal: 106ms\tremaining: 2.55s\n",
      "20:\tlearn: 0.5294357\ttotal: 116ms\tremaining: 2.65s\n",
      "21:\tlearn: 0.5248898\ttotal: 126ms\tremaining: 2.73s\n",
      "22:\tlearn: 0.5195613\ttotal: 135ms\tremaining: 2.81s\n",
      "23:\tlearn: 0.5129026\ttotal: 145ms\tremaining: 2.88s\n",
      "24:\tlearn: 0.5087158\ttotal: 155ms\tremaining: 2.94s\n",
      "25:\tlearn: 0.5038581\ttotal: 162ms\tremaining: 2.96s\n",
      "26:\tlearn: 0.4997550\ttotal: 169ms\tremaining: 2.95s\n",
      "27:\tlearn: 0.4965028\ttotal: 175ms\tremaining: 2.95s\n",
      "28:\tlearn: 0.4911027\ttotal: 181ms\tremaining: 2.94s\n",
      "29:\tlearn: 0.4855059\ttotal: 187ms\tremaining: 2.93s\n",
      "30:\tlearn: 0.4774062\ttotal: 192ms\tremaining: 2.9s\n",
      "31:\tlearn: 0.4690729\ttotal: 197ms\tremaining: 2.88s\n",
      "32:\tlearn: 0.4651521\ttotal: 202ms\tremaining: 2.85s\n",
      "33:\tlearn: 0.4612475\ttotal: 206ms\tremaining: 2.83s\n",
      "34:\tlearn: 0.4571352\ttotal: 212ms\tremaining: 2.82s\n",
      "35:\tlearn: 0.4497850\ttotal: 219ms\tremaining: 2.82s\n",
      "36:\tlearn: 0.4472849\ttotal: 222ms\tremaining: 2.78s\n",
      "37:\tlearn: 0.4429172\ttotal: 226ms\tremaining: 2.75s\n",
      "38:\tlearn: 0.4403692\ttotal: 231ms\tremaining: 2.73s\n",
      "39:\tlearn: 0.4378736\ttotal: 235ms\tremaining: 2.7s\n",
      "40:\tlearn: 0.4335598\ttotal: 239ms\tremaining: 2.67s\n",
      "41:\tlearn: 0.4306282\ttotal: 243ms\tremaining: 2.65s\n",
      "42:\tlearn: 0.4273514\ttotal: 248ms\tremaining: 2.63s\n",
      "43:\tlearn: 0.4234193\ttotal: 252ms\tremaining: 2.61s\n",
      "44:\tlearn: 0.4210773\ttotal: 256ms\tremaining: 2.59s\n",
      "45:\tlearn: 0.4171718\ttotal: 260ms\tremaining: 2.57s\n",
      "46:\tlearn: 0.4122169\ttotal: 265ms\tremaining: 2.55s\n",
      "47:\tlearn: 0.4094473\ttotal: 269ms\tremaining: 2.53s\n",
      "48:\tlearn: 0.4073238\ttotal: 273ms\tremaining: 2.51s\n",
      "49:\tlearn: 0.4049448\ttotal: 277ms\tremaining: 2.5s\n",
      "50:\tlearn: 0.4024168\ttotal: 285ms\tremaining: 2.51s\n",
      "51:\tlearn: 0.3997399\ttotal: 295ms\tremaining: 2.54s\n",
      "52:\tlearn: 0.3970394\ttotal: 304ms\tremaining: 2.56s\n",
      "53:\tlearn: 0.3943619\ttotal: 314ms\tremaining: 2.59s\n",
      "54:\tlearn: 0.3924681\ttotal: 323ms\tremaining: 2.62s\n",
      "55:\tlearn: 0.3905180\ttotal: 333ms\tremaining: 2.64s\n",
      "56:\tlearn: 0.3887253\ttotal: 342ms\tremaining: 2.66s\n",
      "57:\tlearn: 0.3862825\ttotal: 352ms\tremaining: 2.68s\n",
      "58:\tlearn: 0.3835233\ttotal: 361ms\tremaining: 2.7s\n",
      "59:\tlearn: 0.3810350\ttotal: 367ms\tremaining: 2.69s\n",
      "60:\tlearn: 0.3784557\ttotal: 374ms\tremaining: 2.69s\n",
      "61:\tlearn: 0.3749241\ttotal: 380ms\tremaining: 2.68s\n",
      "62:\tlearn: 0.3716330\ttotal: 386ms\tremaining: 2.68s\n",
      "63:\tlearn: 0.3695503\ttotal: 392ms\tremaining: 2.67s\n",
      "64:\tlearn: 0.3674646\ttotal: 398ms\tremaining: 2.67s\n",
      "65:\tlearn: 0.3649907\ttotal: 403ms\tremaining: 2.65s\n",
      "66:\tlearn: 0.3626742\ttotal: 410ms\tremaining: 2.65s\n",
      "67:\tlearn: 0.3600588\ttotal: 416ms\tremaining: 2.64s\n",
      "68:\tlearn: 0.3580858\ttotal: 420ms\tremaining: 2.62s\n",
      "69:\tlearn: 0.3563326\ttotal: 424ms\tremaining: 2.6s\n",
      "70:\tlearn: 0.3537472\ttotal: 428ms\tremaining: 2.58s\n",
      "71:\tlearn: 0.3513166\ttotal: 432ms\tremaining: 2.57s\n",
      "72:\tlearn: 0.3497055\ttotal: 436ms\tremaining: 2.55s\n",
      "73:\tlearn: 0.3471009\ttotal: 441ms\tremaining: 2.54s\n",
      "74:\tlearn: 0.3418376\ttotal: 445ms\tremaining: 2.52s\n",
      "75:\tlearn: 0.3395124\ttotal: 454ms\tremaining: 2.54s\n",
      "76:\tlearn: 0.3371837\ttotal: 464ms\tremaining: 2.55s\n",
      "77:\tlearn: 0.3351826\ttotal: 474ms\tremaining: 2.56s\n",
      "78:\tlearn: 0.3329437\ttotal: 483ms\tremaining: 2.57s\n",
      "79:\tlearn: 0.3313075\ttotal: 493ms\tremaining: 2.59s\n",
      "80:\tlearn: 0.3297032\ttotal: 502ms\tremaining: 2.6s\n",
      "81:\tlearn: 0.3270897\ttotal: 512ms\tremaining: 2.61s\n",
      "82:\tlearn: 0.3247358\ttotal: 522ms\tremaining: 2.62s\n",
      "83:\tlearn: 0.3225978\ttotal: 531ms\tremaining: 2.63s\n",
      "84:\tlearn: 0.3199561\ttotal: 539ms\tremaining: 2.63s\n",
      "85:\tlearn: 0.3177222\ttotal: 545ms\tremaining: 2.63s\n",
      "86:\tlearn: 0.3155570\ttotal: 552ms\tremaining: 2.62s\n",
      "87:\tlearn: 0.3131580\ttotal: 558ms\tremaining: 2.61s\n",
      "88:\tlearn: 0.3110297\ttotal: 564ms\tremaining: 2.6s\n",
      "89:\tlearn: 0.3089318\ttotal: 569ms\tremaining: 2.59s\n",
      "90:\tlearn: 0.3063352\ttotal: 574ms\tremaining: 2.58s\n",
      "91:\tlearn: 0.2999563\ttotal: 579ms\tremaining: 2.56s\n",
      "92:\tlearn: 0.2969472\ttotal: 583ms\tremaining: 2.55s\n",
      "93:\tlearn: 0.2952253\ttotal: 588ms\tremaining: 2.54s\n",
      "94:\tlearn: 0.2932885\ttotal: 592ms\tremaining: 2.52s\n",
      "95:\tlearn: 0.2910679\ttotal: 596ms\tremaining: 2.51s\n",
      "96:\tlearn: 0.2890076\ttotal: 600ms\tremaining: 2.49s\n",
      "97:\tlearn: 0.2858038\ttotal: 604ms\tremaining: 2.48s\n",
      "98:\tlearn: 0.2840516\ttotal: 608ms\tremaining: 2.46s\n",
      "99:\tlearn: 0.2820017\ttotal: 613ms\tremaining: 2.45s\n",
      "100:\tlearn: 0.2800083\ttotal: 617ms\tremaining: 2.44s\n",
      "101:\tlearn: 0.2768137\ttotal: 627ms\tremaining: 2.45s\n",
      "102:\tlearn: 0.2750404\ttotal: 637ms\tremaining: 2.46s\n",
      "103:\tlearn: 0.2729796\ttotal: 647ms\tremaining: 2.46s\n",
      "104:\tlearn: 0.2709629\ttotal: 657ms\tremaining: 2.47s\n",
      "105:\tlearn: 0.2691393\ttotal: 667ms\tremaining: 2.48s\n",
      "106:\tlearn: 0.2674302\ttotal: 676ms\tremaining: 2.48s\n",
      "107:\tlearn: 0.2658662\ttotal: 686ms\tremaining: 2.49s\n",
      "108:\tlearn: 0.2641244\ttotal: 696ms\tremaining: 2.5s\n",
      "109:\tlearn: 0.2625122\ttotal: 705ms\tremaining: 2.5s\n",
      "110:\tlearn: 0.2606459\ttotal: 712ms\tremaining: 2.5s\n",
      "111:\tlearn: 0.2589828\ttotal: 718ms\tremaining: 2.49s\n",
      "112:\tlearn: 0.2573784\ttotal: 725ms\tremaining: 2.48s\n",
      "113:\tlearn: 0.2556535\ttotal: 731ms\tremaining: 2.47s\n",
      "114:\tlearn: 0.2539742\ttotal: 737ms\tremaining: 2.47s\n",
      "115:\tlearn: 0.2525551\ttotal: 741ms\tremaining: 2.45s\n",
      "116:\tlearn: 0.2493750\ttotal: 746ms\tremaining: 2.44s\n",
      "117:\tlearn: 0.2469908\ttotal: 751ms\tremaining: 2.43s\n",
      "118:\tlearn: 0.2455733\ttotal: 756ms\tremaining: 2.42s\n",
      "119:\tlearn: 0.2442598\ttotal: 760ms\tremaining: 2.41s\n",
      "120:\tlearn: 0.2423262\ttotal: 765ms\tremaining: 2.4s\n",
      "121:\tlearn: 0.2411265\ttotal: 770ms\tremaining: 2.38s\n",
      "122:\tlearn: 0.2396060\ttotal: 775ms\tremaining: 2.38s\n",
      "123:\tlearn: 0.2377140\ttotal: 779ms\tremaining: 2.36s\n",
      "124:\tlearn: 0.2360512\ttotal: 783ms\tremaining: 2.35s\n",
      "125:\tlearn: 0.2346076\ttotal: 787ms\tremaining: 2.34s\n",
      "126:\tlearn: 0.2333446\ttotal: 791ms\tremaining: 2.32s\n",
      "127:\tlearn: 0.2307836\ttotal: 801ms\tremaining: 2.33s\n",
      "128:\tlearn: 0.2294081\ttotal: 811ms\tremaining: 2.33s\n",
      "129:\tlearn: 0.2282127\ttotal: 820ms\tremaining: 2.33s\n",
      "130:\tlearn: 0.2271298\ttotal: 830ms\tremaining: 2.34s\n",
      "131:\tlearn: 0.2255828\ttotal: 840ms\tremaining: 2.34s\n",
      "132:\tlearn: 0.2240852\ttotal: 849ms\tremaining: 2.34s\n",
      "133:\tlearn: 0.2224070\ttotal: 859ms\tremaining: 2.35s\n",
      "134:\tlearn: 0.2210007\ttotal: 868ms\tremaining: 2.35s\n",
      "135:\tlearn: 0.2183531\ttotal: 879ms\tremaining: 2.35s\n",
      "136:\tlearn: 0.2171153\ttotal: 887ms\tremaining: 2.35s\n",
      "137:\tlearn: 0.2159487\ttotal: 894ms\tremaining: 2.35s\n",
      "138:\tlearn: 0.2149293\ttotal: 902ms\tremaining: 2.34s\n",
      "139:\tlearn: 0.2136979\ttotal: 909ms\tremaining: 2.34s\n",
      "140:\tlearn: 0.2123444\ttotal: 915ms\tremaining: 2.33s\n",
      "141:\tlearn: 0.2112454\ttotal: 923ms\tremaining: 2.33s\n",
      "142:\tlearn: 0.2100462\ttotal: 930ms\tremaining: 2.32s\n",
      "143:\tlearn: 0.2088017\ttotal: 935ms\tremaining: 2.31s\n",
      "144:\tlearn: 0.2069275\ttotal: 942ms\tremaining: 2.31s\n",
      "145:\tlearn: 0.2059134\ttotal: 946ms\tremaining: 2.29s\n",
      "146:\tlearn: 0.2038335\ttotal: 951ms\tremaining: 2.28s\n",
      "147:\tlearn: 0.2021497\ttotal: 955ms\tremaining: 2.27s\n",
      "148:\tlearn: 0.2008542\ttotal: 960ms\tremaining: 2.26s\n",
      "149:\tlearn: 0.1997895\ttotal: 964ms\tremaining: 2.25s\n",
      "150:\tlearn: 0.1986140\ttotal: 968ms\tremaining: 2.24s\n",
      "151:\tlearn: 0.1967425\ttotal: 972ms\tremaining: 2.23s\n",
      "152:\tlearn: 0.1956038\ttotal: 976ms\tremaining: 2.21s\n",
      "153:\tlearn: 0.1944018\ttotal: 981ms\tremaining: 2.2s\n",
      "154:\tlearn: 0.1928677\ttotal: 984ms\tremaining: 2.19s\n",
      "155:\tlearn: 0.1916939\ttotal: 994ms\tremaining: 2.19s\n",
      "156:\tlearn: 0.1900760\ttotal: 1s\tremaining: 2.19s\n",
      "157:\tlearn: 0.1890376\ttotal: 1.01s\tremaining: 2.19s\n",
      "158:\tlearn: 0.1879251\ttotal: 1.02s\tremaining: 2.19s\n",
      "159:\tlearn: 0.1858054\ttotal: 1.03s\tremaining: 2.2s\n",
      "160:\tlearn: 0.1848682\ttotal: 1.04s\tremaining: 2.2s\n",
      "161:\tlearn: 0.1838879\ttotal: 1.05s\tremaining: 2.2s\n",
      "162:\tlearn: 0.1828392\ttotal: 1.06s\tremaining: 2.2s\n",
      "163:\tlearn: 0.1819094\ttotal: 1.07s\tremaining: 2.2s\n",
      "164:\tlearn: 0.1810746\ttotal: 1.08s\tremaining: 2.19s\n",
      "165:\tlearn: 0.1802284\ttotal: 1.08s\tremaining: 2.18s\n",
      "166:\tlearn: 0.1779429\ttotal: 1.09s\tremaining: 2.18s\n",
      "167:\tlearn: 0.1770404\ttotal: 1.1s\tremaining: 2.17s\n",
      "168:\tlearn: 0.1760231\ttotal: 1.1s\tremaining: 2.16s\n",
      "169:\tlearn: 0.1750243\ttotal: 1.11s\tremaining: 2.15s\n",
      "170:\tlearn: 0.1738881\ttotal: 1.11s\tremaining: 2.14s\n",
      "171:\tlearn: 0.1719458\ttotal: 1.12s\tremaining: 2.13s\n",
      "172:\tlearn: 0.1709592\ttotal: 1.12s\tremaining: 2.12s\n",
      "173:\tlearn: 0.1700154\ttotal: 1.13s\tremaining: 2.11s\n",
      "174:\tlearn: 0.1690337\ttotal: 1.13s\tremaining: 2.1s\n",
      "175:\tlearn: 0.1681359\ttotal: 1.13s\tremaining: 2.08s\n",
      "176:\tlearn: 0.1673562\ttotal: 1.14s\tremaining: 2.07s\n",
      "177:\tlearn: 0.1664913\ttotal: 1.14s\tremaining: 2.06s\n",
      "178:\tlearn: 0.1655177\ttotal: 1.14s\tremaining: 2.05s\n",
      "179:\tlearn: 0.1639097\ttotal: 1.15s\tremaining: 2.04s\n",
      "180:\tlearn: 0.1629244\ttotal: 1.15s\tremaining: 2.03s\n",
      "181:\tlearn: 0.1621304\ttotal: 1.16s\tremaining: 2.02s\n",
      "182:\tlearn: 0.1613999\ttotal: 1.17s\tremaining: 2.02s\n",
      "183:\tlearn: 0.1602937\ttotal: 1.18s\tremaining: 2.02s\n",
      "184:\tlearn: 0.1594415\ttotal: 1.19s\tremaining: 2.02s\n",
      "185:\tlearn: 0.1586528\ttotal: 1.2s\tremaining: 2.02s\n",
      "186:\tlearn: 0.1569934\ttotal: 1.21s\tremaining: 2.02s\n",
      "187:\tlearn: 0.1561803\ttotal: 1.22s\tremaining: 2.02s\n",
      "188:\tlearn: 0.1553088\ttotal: 1.23s\tremaining: 2.02s\n",
      "189:\tlearn: 0.1544080\ttotal: 1.24s\tremaining: 2.02s\n",
      "190:\tlearn: 0.1536324\ttotal: 1.24s\tremaining: 2.01s\n",
      "191:\tlearn: 0.1524145\ttotal: 1.25s\tremaining: 2s\n",
      "192:\tlearn: 0.1515621\ttotal: 1.25s\tremaining: 2s\n",
      "193:\tlearn: 0.1504514\ttotal: 1.26s\tremaining: 1.99s\n",
      "194:\tlearn: 0.1495370\ttotal: 1.27s\tremaining: 1.99s\n",
      "195:\tlearn: 0.1486624\ttotal: 1.28s\tremaining: 1.98s\n",
      "196:\tlearn: 0.1478524\ttotal: 1.28s\tremaining: 1.97s\n",
      "197:\tlearn: 0.1469135\ttotal: 1.29s\tremaining: 1.97s\n",
      "198:\tlearn: 0.1459998\ttotal: 1.3s\tremaining: 1.96s\n",
      "199:\tlearn: 0.1454273\ttotal: 1.3s\tremaining: 1.96s\n",
      "200:\tlearn: 0.1445729\ttotal: 1.31s\tremaining: 1.95s\n",
      "201:\tlearn: 0.1437621\ttotal: 1.31s\tremaining: 1.94s\n",
      "202:\tlearn: 0.1430284\ttotal: 1.32s\tremaining: 1.93s\n",
      "203:\tlearn: 0.1420193\ttotal: 1.32s\tremaining: 1.92s\n",
      "204:\tlearn: 0.1412679\ttotal: 1.33s\tremaining: 1.92s\n",
      "205:\tlearn: 0.1405856\ttotal: 1.34s\tremaining: 1.92s\n",
      "206:\tlearn: 0.1399591\ttotal: 1.35s\tremaining: 1.92s\n",
      "207:\tlearn: 0.1393347\ttotal: 1.36s\tremaining: 1.91s\n",
      "208:\tlearn: 0.1384839\ttotal: 1.37s\tremaining: 1.9s\n",
      "209:\tlearn: 0.1372188\ttotal: 1.37s\tremaining: 1.9s\n",
      "210:\tlearn: 0.1358764\ttotal: 1.38s\tremaining: 1.89s\n",
      "211:\tlearn: 0.1351923\ttotal: 1.39s\tremaining: 1.88s\n",
      "212:\tlearn: 0.1338183\ttotal: 1.39s\tremaining: 1.87s\n",
      "213:\tlearn: 0.1331222\ttotal: 1.4s\tremaining: 1.86s\n",
      "214:\tlearn: 0.1323010\ttotal: 1.4s\tremaining: 1.85s\n",
      "215:\tlearn: 0.1316010\ttotal: 1.4s\tremaining: 1.85s\n",
      "216:\tlearn: 0.1309422\ttotal: 1.41s\tremaining: 1.84s\n",
      "217:\tlearn: 0.1302702\ttotal: 1.41s\tremaining: 1.83s\n",
      "218:\tlearn: 0.1295901\ttotal: 1.42s\tremaining: 1.82s\n",
      "219:\tlearn: 0.1289784\ttotal: 1.42s\tremaining: 1.81s\n",
      "220:\tlearn: 0.1280512\ttotal: 1.43s\tremaining: 1.8s\n",
      "221:\tlearn: 0.1273831\ttotal: 1.43s\tremaining: 1.79s\n",
      "222:\tlearn: 0.1267136\ttotal: 1.44s\tremaining: 1.78s\n",
      "223:\tlearn: 0.1261455\ttotal: 1.44s\tremaining: 1.77s\n",
      "224:\tlearn: 0.1255709\ttotal: 1.44s\tremaining: 1.76s\n",
      "225:\tlearn: 0.1247078\ttotal: 1.45s\tremaining: 1.75s\n",
      "226:\tlearn: 0.1240866\ttotal: 1.45s\tremaining: 1.75s\n",
      "227:\tlearn: 0.1233754\ttotal: 1.46s\tremaining: 1.74s\n",
      "228:\tlearn: 0.1228788\ttotal: 1.46s\tremaining: 1.73s\n",
      "229:\tlearn: 0.1222549\ttotal: 1.46s\tremaining: 1.72s\n",
      "230:\tlearn: 0.1216239\ttotal: 1.47s\tremaining: 1.71s\n",
      "231:\tlearn: 0.1213281\ttotal: 1.47s\tremaining: 1.7s\n",
      "232:\tlearn: 0.1207958\ttotal: 1.48s\tremaining: 1.69s\n",
      "233:\tlearn: 0.1201486\ttotal: 1.49s\tremaining: 1.69s\n",
      "234:\tlearn: 0.1196271\ttotal: 1.5s\tremaining: 1.69s\n",
      "235:\tlearn: 0.1189176\ttotal: 1.51s\tremaining: 1.69s\n",
      "236:\tlearn: 0.1183206\ttotal: 1.52s\tremaining: 1.68s\n",
      "237:\tlearn: 0.1177200\ttotal: 1.52s\tremaining: 1.68s\n",
      "238:\tlearn: 0.1170171\ttotal: 1.53s\tremaining: 1.68s\n",
      "239:\tlearn: 0.1158590\ttotal: 1.54s\tremaining: 1.67s\n",
      "240:\tlearn: 0.1150850\ttotal: 1.55s\tremaining: 1.67s\n",
      "241:\tlearn: 0.1145700\ttotal: 1.56s\tremaining: 1.67s\n",
      "242:\tlearn: 0.1140282\ttotal: 1.57s\tremaining: 1.66s\n",
      "243:\tlearn: 0.1133377\ttotal: 1.58s\tremaining: 1.66s\n",
      "244:\tlearn: 0.1125556\ttotal: 1.59s\tremaining: 1.65s\n",
      "245:\tlearn: 0.1120637\ttotal: 1.59s\tremaining: 1.64s\n",
      "246:\tlearn: 0.1114688\ttotal: 1.6s\tremaining: 1.64s\n",
      "247:\tlearn: 0.1108830\ttotal: 1.6s\tremaining: 1.63s\n",
      "248:\tlearn: 0.1103534\ttotal: 1.61s\tremaining: 1.62s\n",
      "249:\tlearn: 0.1098116\ttotal: 1.61s\tremaining: 1.61s\n",
      "250:\tlearn: 0.1092346\ttotal: 1.62s\tremaining: 1.6s\n",
      "251:\tlearn: 0.1086287\ttotal: 1.62s\tremaining: 1.59s\n",
      "252:\tlearn: 0.1080902\ttotal: 1.63s\tremaining: 1.59s\n",
      "253:\tlearn: 0.1075856\ttotal: 1.63s\tremaining: 1.58s\n",
      "254:\tlearn: 0.1071318\ttotal: 1.63s\tremaining: 1.57s\n",
      "255:\tlearn: 0.1065337\ttotal: 1.64s\tremaining: 1.56s\n",
      "256:\tlearn: 0.1059319\ttotal: 1.65s\tremaining: 1.55s\n",
      "257:\tlearn: 0.1052885\ttotal: 1.66s\tremaining: 1.55s\n",
      "258:\tlearn: 0.1047371\ttotal: 1.67s\tremaining: 1.55s\n",
      "259:\tlearn: 0.1042877\ttotal: 1.68s\tremaining: 1.55s\n",
      "260:\tlearn: 0.1038254\ttotal: 1.68s\tremaining: 1.54s\n",
      "261:\tlearn: 0.1032677\ttotal: 1.69s\tremaining: 1.54s\n",
      "262:\tlearn: 0.1024173\ttotal: 1.7s\tremaining: 1.53s\n",
      "263:\tlearn: 0.1019642\ttotal: 1.71s\tremaining: 1.53s\n",
      "264:\tlearn: 0.1015060\ttotal: 1.72s\tremaining: 1.53s\n",
      "265:\tlearn: 0.1010726\ttotal: 1.73s\tremaining: 1.52s\n",
      "266:\tlearn: 0.1004226\ttotal: 1.74s\tremaining: 1.52s\n",
      "267:\tlearn: 0.0998280\ttotal: 1.75s\tremaining: 1.51s\n",
      "268:\tlearn: 0.0993725\ttotal: 1.75s\tremaining: 1.5s\n",
      "269:\tlearn: 0.0988141\ttotal: 1.76s\tremaining: 1.5s\n",
      "270:\tlearn: 0.0980812\ttotal: 1.76s\tremaining: 1.49s\n",
      "271:\tlearn: 0.0975289\ttotal: 1.77s\tremaining: 1.48s\n",
      "272:\tlearn: 0.0970803\ttotal: 1.77s\tremaining: 1.48s\n",
      "273:\tlearn: 0.0964565\ttotal: 1.78s\tremaining: 1.47s\n",
      "274:\tlearn: 0.0959616\ttotal: 1.78s\tremaining: 1.46s\n",
      "275:\tlearn: 0.0954827\ttotal: 1.79s\tremaining: 1.45s\n",
      "276:\tlearn: 0.0950059\ttotal: 1.79s\tremaining: 1.44s\n",
      "277:\tlearn: 0.0945571\ttotal: 1.8s\tremaining: 1.44s\n",
      "278:\tlearn: 0.0940699\ttotal: 1.8s\tremaining: 1.43s\n",
      "279:\tlearn: 0.0935714\ttotal: 1.81s\tremaining: 1.42s\n",
      "280:\tlearn: 0.0931873\ttotal: 1.81s\tremaining: 1.41s\n",
      "281:\tlearn: 0.0927225\ttotal: 1.81s\tremaining: 1.4s\n",
      "282:\tlearn: 0.0921966\ttotal: 1.82s\tremaining: 1.4s\n",
      "283:\tlearn: 0.0916709\ttotal: 1.83s\tremaining: 1.4s\n",
      "284:\tlearn: 0.0908068\ttotal: 1.84s\tremaining: 1.39s\n",
      "285:\tlearn: 0.0903036\ttotal: 1.85s\tremaining: 1.39s\n",
      "286:\tlearn: 0.0897640\ttotal: 1.86s\tremaining: 1.38s\n",
      "287:\tlearn: 0.0893629\ttotal: 1.87s\tremaining: 1.38s\n",
      "288:\tlearn: 0.0889854\ttotal: 1.88s\tremaining: 1.38s\n",
      "289:\tlearn: 0.0885580\ttotal: 1.89s\tremaining: 1.37s\n",
      "290:\tlearn: 0.0881655\ttotal: 1.9s\tremaining: 1.36s\n",
      "291:\tlearn: 0.0873524\ttotal: 1.91s\tremaining: 1.36s\n",
      "292:\tlearn: 0.0869689\ttotal: 1.91s\tremaining: 1.35s\n",
      "293:\tlearn: 0.0864485\ttotal: 1.92s\tremaining: 1.34s\n",
      "294:\tlearn: 0.0860519\ttotal: 1.93s\tremaining: 1.34s\n",
      "295:\tlearn: 0.0856070\ttotal: 1.93s\tremaining: 1.33s\n",
      "296:\tlearn: 0.0851788\ttotal: 1.94s\tremaining: 1.32s\n",
      "297:\tlearn: 0.0847144\ttotal: 1.94s\tremaining: 1.31s\n",
      "298:\tlearn: 0.0843407\ttotal: 1.95s\tremaining: 1.31s\n",
      "299:\tlearn: 0.0839091\ttotal: 1.95s\tremaining: 1.3s\n",
      "300:\tlearn: 0.0835708\ttotal: 1.96s\tremaining: 1.29s\n",
      "301:\tlearn: 0.0828509\ttotal: 1.96s\tremaining: 1.28s\n",
      "302:\tlearn: 0.0824415\ttotal: 1.96s\tremaining: 1.28s\n",
      "303:\tlearn: 0.0820586\ttotal: 1.97s\tremaining: 1.27s\n",
      "304:\tlearn: 0.0816516\ttotal: 1.97s\tremaining: 1.26s\n",
      "305:\tlearn: 0.0812650\ttotal: 1.98s\tremaining: 1.25s\n",
      "306:\tlearn: 0.0807427\ttotal: 1.98s\tremaining: 1.25s\n",
      "307:\tlearn: 0.0803249\ttotal: 1.99s\tremaining: 1.24s\n",
      "308:\tlearn: 0.0799113\ttotal: 2s\tremaining: 1.24s\n",
      "309:\tlearn: 0.0796025\ttotal: 2.01s\tremaining: 1.23s\n",
      "310:\tlearn: 0.0791601\ttotal: 2.02s\tremaining: 1.23s\n",
      "311:\tlearn: 0.0786660\ttotal: 2.03s\tremaining: 1.22s\n",
      "312:\tlearn: 0.0783099\ttotal: 2.04s\tremaining: 1.22s\n",
      "313:\tlearn: 0.0772428\ttotal: 2.05s\tremaining: 1.21s\n",
      "314:\tlearn: 0.0767405\ttotal: 2.06s\tremaining: 1.21s\n",
      "315:\tlearn: 0.0764563\ttotal: 2.07s\tremaining: 1.2s\n",
      "316:\tlearn: 0.0760550\ttotal: 2.08s\tremaining: 1.2s\n",
      "317:\tlearn: 0.0756099\ttotal: 2.08s\tremaining: 1.19s\n",
      "318:\tlearn: 0.0753146\ttotal: 2.09s\tremaining: 1.18s\n",
      "319:\tlearn: 0.0748979\ttotal: 2.09s\tremaining: 1.18s\n",
      "320:\tlearn: 0.0745052\ttotal: 2.1s\tremaining: 1.17s\n",
      "321:\tlearn: 0.0742451\ttotal: 2.11s\tremaining: 1.16s\n",
      "322:\tlearn: 0.0738572\ttotal: 2.11s\tremaining: 1.16s\n",
      "323:\tlearn: 0.0732381\ttotal: 2.12s\tremaining: 1.15s\n",
      "324:\tlearn: 0.0729014\ttotal: 2.13s\tremaining: 1.14s\n",
      "325:\tlearn: 0.0725663\ttotal: 2.13s\tremaining: 1.14s\n",
      "326:\tlearn: 0.0722434\ttotal: 2.13s\tremaining: 1.13s\n",
      "327:\tlearn: 0.0720005\ttotal: 2.14s\tremaining: 1.12s\n",
      "328:\tlearn: 0.0716996\ttotal: 2.14s\tremaining: 1.11s\n",
      "329:\tlearn: 0.0712729\ttotal: 2.15s\tremaining: 1.11s\n",
      "330:\tlearn: 0.0707939\ttotal: 2.17s\tremaining: 1.1s\n",
      "331:\tlearn: 0.0704613\ttotal: 2.17s\tremaining: 1.1s\n",
      "332:\tlearn: 0.0701130\ttotal: 2.18s\tremaining: 1.09s\n",
      "333:\tlearn: 0.0699543\ttotal: 2.18s\tremaining: 1.08s\n",
      "334:\tlearn: 0.0695823\ttotal: 2.19s\tremaining: 1.08s\n",
      "335:\tlearn: 0.0693104\ttotal: 2.2s\tremaining: 1.07s\n",
      "336:\tlearn: 0.0689234\ttotal: 2.21s\tremaining: 1.07s\n",
      "337:\tlearn: 0.0685608\ttotal: 2.22s\tremaining: 1.06s\n",
      "338:\tlearn: 0.0682389\ttotal: 2.23s\tremaining: 1.06s\n",
      "339:\tlearn: 0.0679376\ttotal: 2.24s\tremaining: 1.05s\n",
      "340:\tlearn: 0.0676007\ttotal: 2.25s\tremaining: 1.05s\n",
      "341:\tlearn: 0.0672562\ttotal: 2.26s\tremaining: 1.04s\n",
      "342:\tlearn: 0.0669655\ttotal: 2.27s\tremaining: 1.04s\n",
      "343:\tlearn: 0.0666407\ttotal: 2.28s\tremaining: 1.03s\n",
      "344:\tlearn: 0.0662557\ttotal: 2.29s\tremaining: 1.03s\n",
      "345:\tlearn: 0.0659312\ttotal: 2.29s\tremaining: 1.02s\n",
      "346:\tlearn: 0.0656946\ttotal: 2.3s\tremaining: 1.01s\n",
      "347:\tlearn: 0.0653919\ttotal: 2.3s\tremaining: 1s\n",
      "348:\tlearn: 0.0651218\ttotal: 2.31s\tremaining: 998ms\n",
      "349:\tlearn: 0.0649637\ttotal: 2.31s\tremaining: 991ms\n",
      "350:\tlearn: 0.0647031\ttotal: 2.32s\tremaining: 984ms\n",
      "351:\tlearn: 0.0645570\ttotal: 2.32s\tremaining: 977ms\n",
      "352:\tlearn: 0.0643021\ttotal: 2.33s\tremaining: 969ms\n",
      "353:\tlearn: 0.0639429\ttotal: 2.33s\tremaining: 962ms\n",
      "354:\tlearn: 0.0634902\ttotal: 2.33s\tremaining: 954ms\n",
      "355:\tlearn: 0.0631464\ttotal: 2.34s\tremaining: 947ms\n",
      "356:\tlearn: 0.0626540\ttotal: 2.34s\tremaining: 939ms\n",
      "357:\tlearn: 0.0624249\ttotal: 2.35s\tremaining: 932ms\n",
      "358:\tlearn: 0.0620753\ttotal: 2.35s\tremaining: 924ms\n",
      "359:\tlearn: 0.0614624\ttotal: 2.36s\tremaining: 916ms\n",
      "360:\tlearn: 0.0610544\ttotal: 2.36s\tremaining: 909ms\n",
      "361:\tlearn: 0.0607445\ttotal: 2.37s\tremaining: 902ms\n",
      "362:\tlearn: 0.0604429\ttotal: 2.37s\tremaining: 895ms\n",
      "363:\tlearn: 0.0601927\ttotal: 2.38s\tremaining: 888ms\n",
      "364:\tlearn: 0.0599224\ttotal: 2.38s\tremaining: 881ms\n",
      "365:\tlearn: 0.0594315\ttotal: 2.39s\tremaining: 875ms\n",
      "366:\tlearn: 0.0591969\ttotal: 2.39s\tremaining: 868ms\n",
      "367:\tlearn: 0.0590911\ttotal: 2.4s\tremaining: 861ms\n",
      "368:\tlearn: 0.0588333\ttotal: 2.4s\tremaining: 854ms\n",
      "369:\tlearn: 0.0585453\ttotal: 2.41s\tremaining: 847ms\n",
      "370:\tlearn: 0.0582809\ttotal: 2.42s\tremaining: 840ms\n",
      "371:\tlearn: 0.0579791\ttotal: 2.42s\tremaining: 834ms\n",
      "372:\tlearn: 0.0577520\ttotal: 2.43s\tremaining: 827ms\n",
      "373:\tlearn: 0.0574330\ttotal: 2.43s\tremaining: 820ms\n",
      "374:\tlearn: 0.0571793\ttotal: 2.44s\tremaining: 813ms\n",
      "375:\tlearn: 0.0569338\ttotal: 2.45s\tremaining: 807ms\n",
      "376:\tlearn: 0.0567130\ttotal: 2.46s\tremaining: 802ms\n",
      "377:\tlearn: 0.0564605\ttotal: 2.47s\tremaining: 796ms\n",
      "378:\tlearn: 0.0562444\ttotal: 2.48s\tremaining: 791ms\n",
      "379:\tlearn: 0.0559871\ttotal: 2.49s\tremaining: 785ms\n",
      "380:\tlearn: 0.0557152\ttotal: 2.5s\tremaining: 780ms\n",
      "381:\tlearn: 0.0554520\ttotal: 2.51s\tremaining: 774ms\n",
      "382:\tlearn: 0.0551704\ttotal: 2.52s\tremaining: 769ms\n",
      "383:\tlearn: 0.0549022\ttotal: 2.52s\tremaining: 762ms\n",
      "384:\tlearn: 0.0545888\ttotal: 2.53s\tremaining: 755ms\n",
      "385:\tlearn: 0.0541945\ttotal: 2.53s\tremaining: 748ms\n",
      "386:\tlearn: 0.0539302\ttotal: 2.54s\tremaining: 740ms\n",
      "387:\tlearn: 0.0536048\ttotal: 2.54s\tremaining: 733ms\n",
      "388:\tlearn: 0.0533147\ttotal: 2.54s\tremaining: 726ms\n",
      "389:\tlearn: 0.0530170\ttotal: 2.55s\tremaining: 719ms\n",
      "390:\tlearn: 0.0527082\ttotal: 2.56s\tremaining: 713ms\n",
      "391:\tlearn: 0.0524943\ttotal: 2.57s\tremaining: 707ms\n",
      "392:\tlearn: 0.0522138\ttotal: 2.58s\tremaining: 701ms\n",
      "393:\tlearn: 0.0519843\ttotal: 2.58s\tremaining: 696ms\n",
      "394:\tlearn: 0.0517487\ttotal: 2.6s\tremaining: 690ms\n",
      "395:\tlearn: 0.0514909\ttotal: 2.6s\tremaining: 684ms\n",
      "396:\tlearn: 0.0512009\ttotal: 2.61s\tremaining: 678ms\n",
      "397:\tlearn: 0.0509732\ttotal: 2.62s\tremaining: 673ms\n",
      "398:\tlearn: 0.0507380\ttotal: 2.63s\tremaining: 667ms\n",
      "399:\tlearn: 0.0504591\ttotal: 2.64s\tremaining: 660ms\n",
      "400:\tlearn: 0.0502276\ttotal: 2.65s\tremaining: 653ms\n",
      "401:\tlearn: 0.0500017\ttotal: 2.65s\tremaining: 647ms\n",
      "402:\tlearn: 0.0497671\ttotal: 2.66s\tremaining: 640ms\n",
      "403:\tlearn: 0.0495356\ttotal: 2.67s\tremaining: 634ms\n",
      "404:\tlearn: 0.0493091\ttotal: 2.67s\tremaining: 627ms\n",
      "405:\tlearn: 0.0491098\ttotal: 2.68s\tremaining: 620ms\n",
      "406:\tlearn: 0.0489072\ttotal: 2.69s\tremaining: 614ms\n",
      "407:\tlearn: 0.0486770\ttotal: 2.69s\tremaining: 607ms\n",
      "408:\tlearn: 0.0484316\ttotal: 2.7s\tremaining: 600ms\n",
      "409:\tlearn: 0.0482155\ttotal: 2.7s\tremaining: 593ms\n",
      "410:\tlearn: 0.0481181\ttotal: 2.7s\tremaining: 586ms\n",
      "411:\tlearn: 0.0479185\ttotal: 2.71s\tremaining: 579ms\n",
      "412:\tlearn: 0.0477238\ttotal: 2.71s\tremaining: 572ms\n",
      "413:\tlearn: 0.0474826\ttotal: 2.72s\tremaining: 564ms\n",
      "414:\tlearn: 0.0473061\ttotal: 2.72s\tremaining: 557ms\n",
      "415:\tlearn: 0.0470516\ttotal: 2.73s\tremaining: 551ms\n",
      "416:\tlearn: 0.0468590\ttotal: 2.74s\tremaining: 546ms\n",
      "417:\tlearn: 0.0466366\ttotal: 2.75s\tremaining: 540ms\n",
      "418:\tlearn: 0.0464260\ttotal: 2.76s\tremaining: 534ms\n",
      "419:\tlearn: 0.0461933\ttotal: 2.77s\tremaining: 528ms\n",
      "420:\tlearn: 0.0459835\ttotal: 2.78s\tremaining: 522ms\n",
      "421:\tlearn: 0.0458065\ttotal: 2.79s\tremaining: 516ms\n",
      "422:\tlearn: 0.0456281\ttotal: 2.8s\tremaining: 510ms\n",
      "423:\tlearn: 0.0455096\ttotal: 2.81s\tremaining: 504ms\n",
      "424:\tlearn: 0.0453013\ttotal: 2.81s\tremaining: 497ms\n",
      "425:\tlearn: 0.0450485\ttotal: 2.82s\tremaining: 490ms\n",
      "426:\tlearn: 0.0447466\ttotal: 2.82s\tremaining: 483ms\n",
      "427:\tlearn: 0.0445101\ttotal: 2.83s\tremaining: 476ms\n",
      "428:\tlearn: 0.0443119\ttotal: 2.83s\tremaining: 469ms\n",
      "429:\tlearn: 0.0441497\ttotal: 2.84s\tremaining: 462ms\n",
      "430:\tlearn: 0.0439843\ttotal: 2.84s\tremaining: 455ms\n",
      "431:\tlearn: 0.0438551\ttotal: 2.85s\tremaining: 448ms\n",
      "432:\tlearn: 0.0436408\ttotal: 2.85s\tremaining: 441ms\n",
      "433:\tlearn: 0.0435088\ttotal: 2.86s\tremaining: 434ms\n",
      "434:\tlearn: 0.0433241\ttotal: 2.86s\tremaining: 427ms\n",
      "435:\tlearn: 0.0431010\ttotal: 2.86s\tremaining: 420ms\n",
      "436:\tlearn: 0.0429133\ttotal: 2.87s\tremaining: 414ms\n",
      "437:\tlearn: 0.0427403\ttotal: 2.88s\tremaining: 408ms\n",
      "438:\tlearn: 0.0425516\ttotal: 2.89s\tremaining: 402ms\n",
      "439:\tlearn: 0.0423657\ttotal: 2.9s\tremaining: 396ms\n",
      "440:\tlearn: 0.0421742\ttotal: 2.91s\tremaining: 390ms\n",
      "441:\tlearn: 0.0419955\ttotal: 2.92s\tremaining: 383ms\n",
      "442:\tlearn: 0.0417118\ttotal: 2.93s\tremaining: 377ms\n",
      "443:\tlearn: 0.0415283\ttotal: 2.94s\tremaining: 371ms\n",
      "444:\tlearn: 0.0413058\ttotal: 2.95s\tremaining: 365ms\n",
      "445:\tlearn: 0.0411390\ttotal: 2.96s\tremaining: 359ms\n",
      "446:\tlearn: 0.0409669\ttotal: 2.97s\tremaining: 352ms\n",
      "447:\tlearn: 0.0408076\ttotal: 2.97s\tremaining: 345ms\n",
      "448:\tlearn: 0.0406184\ttotal: 2.98s\tremaining: 338ms\n",
      "449:\tlearn: 0.0403828\ttotal: 2.99s\tremaining: 332ms\n",
      "450:\tlearn: 0.0401229\ttotal: 2.99s\tremaining: 325ms\n",
      "451:\tlearn: 0.0399262\ttotal: 3s\tremaining: 318ms\n",
      "452:\tlearn: 0.0397734\ttotal: 3s\tremaining: 311ms\n",
      "453:\tlearn: 0.0396676\ttotal: 3s\tremaining: 305ms\n",
      "454:\tlearn: 0.0394049\ttotal: 3.01s\tremaining: 298ms\n",
      "455:\tlearn: 0.0392563\ttotal: 3.01s\tremaining: 291ms\n",
      "456:\tlearn: 0.0391176\ttotal: 3.02s\tremaining: 284ms\n",
      "457:\tlearn: 0.0389958\ttotal: 3.02s\tremaining: 277ms\n",
      "458:\tlearn: 0.0388535\ttotal: 3.03s\tremaining: 271ms\n",
      "459:\tlearn: 0.0386703\ttotal: 3.03s\tremaining: 264ms\n",
      "460:\tlearn: 0.0383894\ttotal: 3.04s\tremaining: 257ms\n",
      "461:\tlearn: 0.0381879\ttotal: 3.04s\tremaining: 251ms\n",
      "462:\tlearn: 0.0380410\ttotal: 3.06s\tremaining: 244ms\n",
      "463:\tlearn: 0.0378821\ttotal: 3.06s\tremaining: 238ms\n",
      "464:\tlearn: 0.0377180\ttotal: 3.08s\tremaining: 231ms\n",
      "465:\tlearn: 0.0375517\ttotal: 3.08s\tremaining: 225ms\n",
      "466:\tlearn: 0.0372623\ttotal: 3.09s\tremaining: 219ms\n",
      "467:\tlearn: 0.0371079\ttotal: 3.1s\tremaining: 212ms\n",
      "468:\tlearn: 0.0369210\ttotal: 3.11s\tremaining: 206ms\n",
      "469:\tlearn: 0.0367286\ttotal: 3.12s\tremaining: 199ms\n",
      "470:\tlearn: 0.0365145\ttotal: 3.13s\tremaining: 193ms\n",
      "471:\tlearn: 0.0363245\ttotal: 3.14s\tremaining: 186ms\n",
      "472:\tlearn: 0.0361724\ttotal: 3.15s\tremaining: 180ms\n",
      "473:\tlearn: 0.0360281\ttotal: 3.15s\tremaining: 173ms\n",
      "474:\tlearn: 0.0357905\ttotal: 3.15s\tremaining: 166ms\n",
      "475:\tlearn: 0.0356139\ttotal: 3.16s\tremaining: 159ms\n",
      "476:\tlearn: 0.0354476\ttotal: 3.17s\tremaining: 153ms\n",
      "477:\tlearn: 0.0352955\ttotal: 3.17s\tremaining: 146ms\n",
      "478:\tlearn: 0.0351658\ttotal: 3.17s\tremaining: 139ms\n",
      "479:\tlearn: 0.0349908\ttotal: 3.18s\tremaining: 132ms\n",
      "480:\tlearn: 0.0348041\ttotal: 3.18s\tremaining: 126ms\n",
      "481:\tlearn: 0.0346325\ttotal: 3.19s\tremaining: 119ms\n",
      "482:\tlearn: 0.0344958\ttotal: 3.19s\tremaining: 112ms\n",
      "483:\tlearn: 0.0342781\ttotal: 3.2s\tremaining: 106ms\n",
      "484:\tlearn: 0.0341972\ttotal: 3.2s\tremaining: 99ms\n",
      "485:\tlearn: 0.0340813\ttotal: 3.21s\tremaining: 92.3ms\n",
      "486:\tlearn: 0.0339446\ttotal: 3.21s\tremaining: 85.7ms\n",
      "487:\tlearn: 0.0338048\ttotal: 3.21s\tremaining: 79ms\n",
      "488:\tlearn: 0.0336205\ttotal: 3.21s\tremaining: 72.3ms\n",
      "489:\tlearn: 0.0334930\ttotal: 3.22s\tremaining: 65.7ms\n",
      "490:\tlearn: 0.0333687\ttotal: 3.22s\tremaining: 59.1ms\n",
      "491:\tlearn: 0.0332305\ttotal: 3.23s\tremaining: 52.5ms\n",
      "492:\tlearn: 0.0331044\ttotal: 3.23s\tremaining: 45.9ms\n",
      "493:\tlearn: 0.0329687\ttotal: 3.24s\tremaining: 39.3ms\n",
      "494:\tlearn: 0.0328876\ttotal: 3.25s\tremaining: 32.8ms\n",
      "495:\tlearn: 0.0327332\ttotal: 3.26s\tremaining: 26.3ms\n",
      "496:\tlearn: 0.0326876\ttotal: 3.27s\tremaining: 19.7ms\n",
      "497:\tlearn: 0.0325768\ttotal: 3.27s\tremaining: 13.2ms\n",
      "498:\tlearn: 0.0324493\ttotal: 3.29s\tremaining: 6.58ms\n",
      "499:\tlearn: 0.0322534\ttotal: 3.29s\tremaining: 0us\n",
      "0:\tlearn: 0.6832004\ttotal: 6.88ms\tremaining: 3.43s\n",
      "1:\tlearn: 0.6716362\ttotal: 11.1ms\tremaining: 2.76s\n",
      "2:\tlearn: 0.6629258\ttotal: 15.3ms\tremaining: 2.54s\n",
      "3:\tlearn: 0.6527743\ttotal: 19.3ms\tremaining: 2.39s\n",
      "4:\tlearn: 0.6443530\ttotal: 24.4ms\tremaining: 2.41s\n",
      "5:\tlearn: 0.6379710\ttotal: 28.7ms\tremaining: 2.36s\n",
      "6:\tlearn: 0.6301405\ttotal: 33.2ms\tremaining: 2.34s\n",
      "7:\tlearn: 0.6143735\ttotal: 37.4ms\tremaining: 2.3s\n",
      "8:\tlearn: 0.6087442\ttotal: 41.3ms\tremaining: 2.25s\n",
      "9:\tlearn: 0.6021341\ttotal: 45.5ms\tremaining: 2.23s\n",
      "10:\tlearn: 0.5948369\ttotal: 49.5ms\tremaining: 2.2s\n",
      "11:\tlearn: 0.5868932\ttotal: 53.8ms\tremaining: 2.19s\n",
      "12:\tlearn: 0.5810643\ttotal: 58.1ms\tremaining: 2.17s\n",
      "13:\tlearn: 0.5745141\ttotal: 67.7ms\tremaining: 2.35s\n",
      "14:\tlearn: 0.5701485\ttotal: 77.3ms\tremaining: 2.5s\n",
      "15:\tlearn: 0.5649221\ttotal: 86.8ms\tremaining: 2.63s\n",
      "16:\tlearn: 0.5595327\ttotal: 97.2ms\tremaining: 2.76s\n",
      "17:\tlearn: 0.5541160\ttotal: 107ms\tremaining: 2.86s\n",
      "18:\tlearn: 0.5465269\ttotal: 116ms\tremaining: 2.95s\n",
      "19:\tlearn: 0.5388272\ttotal: 126ms\tremaining: 3.03s\n",
      "20:\tlearn: 0.5342048\ttotal: 136ms\tremaining: 3.1s\n",
      "21:\tlearn: 0.5296818\ttotal: 145ms\tremaining: 3.15s\n",
      "22:\tlearn: 0.5245737\ttotal: 153ms\tremaining: 3.17s\n",
      "23:\tlearn: 0.5196043\ttotal: 159ms\tremaining: 3.15s\n",
      "24:\tlearn: 0.5148416\ttotal: 165ms\tremaining: 3.14s\n",
      "25:\tlearn: 0.5113038\ttotal: 171ms\tremaining: 3.12s\n",
      "26:\tlearn: 0.5044591\ttotal: 178ms\tremaining: 3.11s\n",
      "27:\tlearn: 0.5000693\ttotal: 182ms\tremaining: 3.07s\n",
      "28:\tlearn: 0.4956081\ttotal: 188ms\tremaining: 3.05s\n",
      "29:\tlearn: 0.4921674\ttotal: 192ms\tremaining: 3s\n",
      "30:\tlearn: 0.4883919\ttotal: 196ms\tremaining: 2.96s\n",
      "31:\tlearn: 0.4829111\ttotal: 200ms\tremaining: 2.93s\n",
      "32:\tlearn: 0.4778933\ttotal: 205ms\tremaining: 2.9s\n",
      "33:\tlearn: 0.4708204\ttotal: 209ms\tremaining: 2.87s\n",
      "34:\tlearn: 0.4668706\ttotal: 214ms\tremaining: 2.84s\n",
      "35:\tlearn: 0.4628515\ttotal: 218ms\tremaining: 2.8s\n",
      "36:\tlearn: 0.4585866\ttotal: 222ms\tremaining: 2.78s\n",
      "37:\tlearn: 0.4544812\ttotal: 226ms\tremaining: 2.75s\n",
      "38:\tlearn: 0.4508116\ttotal: 230ms\tremaining: 2.72s\n",
      "39:\tlearn: 0.4480102\ttotal: 237ms\tremaining: 2.73s\n",
      "40:\tlearn: 0.4457855\ttotal: 247ms\tremaining: 2.76s\n",
      "41:\tlearn: 0.4429368\ttotal: 256ms\tremaining: 2.79s\n",
      "42:\tlearn: 0.4389196\ttotal: 266ms\tremaining: 2.83s\n",
      "43:\tlearn: 0.4362606\ttotal: 276ms\tremaining: 2.86s\n",
      "44:\tlearn: 0.4283650\ttotal: 285ms\tremaining: 2.88s\n",
      "45:\tlearn: 0.4235692\ttotal: 295ms\tremaining: 2.91s\n",
      "46:\tlearn: 0.4182275\ttotal: 305ms\tremaining: 2.94s\n",
      "47:\tlearn: 0.4151997\ttotal: 314ms\tremaining: 2.96s\n",
      "48:\tlearn: 0.4098212\ttotal: 321ms\tremaining: 2.96s\n",
      "49:\tlearn: 0.4023918\ttotal: 327ms\tremaining: 2.94s\n",
      "50:\tlearn: 0.3996020\ttotal: 333ms\tremaining: 2.93s\n",
      "51:\tlearn: 0.3947611\ttotal: 339ms\tremaining: 2.92s\n",
      "52:\tlearn: 0.3925825\ttotal: 346ms\tremaining: 2.91s\n",
      "53:\tlearn: 0.3892051\ttotal: 351ms\tremaining: 2.9s\n",
      "54:\tlearn: 0.3866289\ttotal: 356ms\tremaining: 2.88s\n",
      "55:\tlearn: 0.3841085\ttotal: 361ms\tremaining: 2.86s\n",
      "56:\tlearn: 0.3819281\ttotal: 366ms\tremaining: 2.85s\n",
      "57:\tlearn: 0.3797345\ttotal: 370ms\tremaining: 2.82s\n",
      "58:\tlearn: 0.3769309\ttotal: 374ms\tremaining: 2.8s\n",
      "59:\tlearn: 0.3735440\ttotal: 378ms\tremaining: 2.77s\n",
      "60:\tlearn: 0.3709017\ttotal: 382ms\tremaining: 2.75s\n",
      "61:\tlearn: 0.3684926\ttotal: 386ms\tremaining: 2.73s\n",
      "62:\tlearn: 0.3652271\ttotal: 391ms\tremaining: 2.71s\n",
      "63:\tlearn: 0.3632609\ttotal: 395ms\tremaining: 2.69s\n",
      "64:\tlearn: 0.3601287\ttotal: 400ms\tremaining: 2.68s\n",
      "65:\tlearn: 0.3573810\ttotal: 404ms\tremaining: 2.66s\n",
      "66:\tlearn: 0.3553062\ttotal: 412ms\tremaining: 2.66s\n",
      "67:\tlearn: 0.3531086\ttotal: 421ms\tremaining: 2.68s\n",
      "68:\tlearn: 0.3504183\ttotal: 431ms\tremaining: 2.69s\n",
      "69:\tlearn: 0.3483658\ttotal: 440ms\tremaining: 2.7s\n",
      "70:\tlearn: 0.3468297\ttotal: 450ms\tremaining: 2.72s\n",
      "71:\tlearn: 0.3439996\ttotal: 459ms\tremaining: 2.73s\n",
      "72:\tlearn: 0.3417043\ttotal: 469ms\tremaining: 2.74s\n",
      "73:\tlearn: 0.3384030\ttotal: 479ms\tremaining: 2.76s\n",
      "74:\tlearn: 0.3360138\ttotal: 489ms\tremaining: 2.77s\n",
      "75:\tlearn: 0.3320372\ttotal: 495ms\tremaining: 2.76s\n",
      "76:\tlearn: 0.3293589\ttotal: 502ms\tremaining: 2.75s\n",
      "77:\tlearn: 0.3271835\ttotal: 508ms\tremaining: 2.75s\n",
      "78:\tlearn: 0.3250676\ttotal: 514ms\tremaining: 2.74s\n",
      "79:\tlearn: 0.3230912\ttotal: 520ms\tremaining: 2.73s\n",
      "80:\tlearn: 0.3211875\ttotal: 524ms\tremaining: 2.71s\n",
      "81:\tlearn: 0.3188687\ttotal: 529ms\tremaining: 2.7s\n",
      "82:\tlearn: 0.3165552\ttotal: 534ms\tremaining: 2.68s\n",
      "83:\tlearn: 0.3141397\ttotal: 539ms\tremaining: 2.67s\n",
      "84:\tlearn: 0.3120504\ttotal: 543ms\tremaining: 2.65s\n",
      "85:\tlearn: 0.3100169\ttotal: 548ms\tremaining: 2.64s\n",
      "86:\tlearn: 0.3079549\ttotal: 552ms\tremaining: 2.62s\n",
      "87:\tlearn: 0.3057884\ttotal: 557ms\tremaining: 2.61s\n",
      "88:\tlearn: 0.3038633\ttotal: 562ms\tremaining: 2.59s\n",
      "89:\tlearn: 0.3022218\ttotal: 565ms\tremaining: 2.57s\n",
      "90:\tlearn: 0.2999043\ttotal: 569ms\tremaining: 2.56s\n",
      "91:\tlearn: 0.2974538\ttotal: 573ms\tremaining: 2.54s\n",
      "92:\tlearn: 0.2957454\ttotal: 583ms\tremaining: 2.55s\n",
      "93:\tlearn: 0.2916420\ttotal: 593ms\tremaining: 2.56s\n",
      "94:\tlearn: 0.2881755\ttotal: 603ms\tremaining: 2.57s\n",
      "95:\tlearn: 0.2860719\ttotal: 612ms\tremaining: 2.58s\n",
      "96:\tlearn: 0.2841459\ttotal: 622ms\tremaining: 2.58s\n",
      "97:\tlearn: 0.2823385\ttotal: 632ms\tremaining: 2.59s\n",
      "98:\tlearn: 0.2806975\ttotal: 642ms\tremaining: 2.6s\n",
      "99:\tlearn: 0.2788582\ttotal: 651ms\tremaining: 2.6s\n",
      "100:\tlearn: 0.2770978\ttotal: 661ms\tremaining: 2.61s\n",
      "101:\tlearn: 0.2751597\ttotal: 673ms\tremaining: 2.63s\n",
      "102:\tlearn: 0.2722160\ttotal: 679ms\tremaining: 2.62s\n",
      "103:\tlearn: 0.2709034\ttotal: 688ms\tremaining: 2.62s\n",
      "104:\tlearn: 0.2691152\ttotal: 694ms\tremaining: 2.61s\n",
      "105:\tlearn: 0.2673427\ttotal: 700ms\tremaining: 2.6s\n",
      "106:\tlearn: 0.2657308\ttotal: 705ms\tremaining: 2.59s\n",
      "107:\tlearn: 0.2629589\ttotal: 710ms\tremaining: 2.58s\n",
      "108:\tlearn: 0.2614073\ttotal: 715ms\tremaining: 2.56s\n",
      "109:\tlearn: 0.2587928\ttotal: 720ms\tremaining: 2.55s\n",
      "110:\tlearn: 0.2570867\ttotal: 724ms\tremaining: 2.54s\n",
      "111:\tlearn: 0.2555347\ttotal: 729ms\tremaining: 2.52s\n",
      "112:\tlearn: 0.2538101\ttotal: 734ms\tremaining: 2.51s\n",
      "113:\tlearn: 0.2511660\ttotal: 738ms\tremaining: 2.5s\n",
      "114:\tlearn: 0.2477087\ttotal: 741ms\tremaining: 2.48s\n",
      "115:\tlearn: 0.2447311\ttotal: 746ms\tremaining: 2.47s\n",
      "116:\tlearn: 0.2432006\ttotal: 755ms\tremaining: 2.47s\n",
      "117:\tlearn: 0.2416555\ttotal: 765ms\tremaining: 2.48s\n",
      "118:\tlearn: 0.2400045\ttotal: 775ms\tremaining: 2.48s\n",
      "119:\tlearn: 0.2386669\ttotal: 785ms\tremaining: 2.48s\n",
      "120:\tlearn: 0.2371660\ttotal: 794ms\tremaining: 2.49s\n",
      "121:\tlearn: 0.2358025\ttotal: 804ms\tremaining: 2.49s\n",
      "122:\tlearn: 0.2341892\ttotal: 813ms\tremaining: 2.49s\n",
      "123:\tlearn: 0.2325987\ttotal: 823ms\tremaining: 2.5s\n",
      "124:\tlearn: 0.2310665\ttotal: 833ms\tremaining: 2.5s\n",
      "125:\tlearn: 0.2284643\ttotal: 839ms\tremaining: 2.49s\n",
      "126:\tlearn: 0.2272276\ttotal: 845ms\tremaining: 2.48s\n",
      "127:\tlearn: 0.2260227\ttotal: 851ms\tremaining: 2.47s\n",
      "128:\tlearn: 0.2248610\ttotal: 858ms\tremaining: 2.47s\n",
      "129:\tlearn: 0.2234261\ttotal: 865ms\tremaining: 2.46s\n",
      "130:\tlearn: 0.2213642\ttotal: 870ms\tremaining: 2.45s\n",
      "131:\tlearn: 0.2199650\ttotal: 874ms\tremaining: 2.44s\n",
      "132:\tlearn: 0.2172987\ttotal: 879ms\tremaining: 2.42s\n",
      "133:\tlearn: 0.2160881\ttotal: 884ms\tremaining: 2.41s\n",
      "134:\tlearn: 0.2146581\ttotal: 888ms\tremaining: 2.4s\n",
      "135:\tlearn: 0.2132209\ttotal: 893ms\tremaining: 2.39s\n",
      "136:\tlearn: 0.2119489\ttotal: 897ms\tremaining: 2.38s\n",
      "137:\tlearn: 0.2105019\ttotal: 901ms\tremaining: 2.36s\n",
      "138:\tlearn: 0.2093209\ttotal: 906ms\tremaining: 2.35s\n",
      "139:\tlearn: 0.2066411\ttotal: 910ms\tremaining: 2.34s\n",
      "140:\tlearn: 0.2055300\ttotal: 915ms\tremaining: 2.33s\n",
      "141:\tlearn: 0.2041696\ttotal: 925ms\tremaining: 2.33s\n",
      "142:\tlearn: 0.2030459\ttotal: 934ms\tremaining: 2.33s\n",
      "143:\tlearn: 0.2020814\ttotal: 944ms\tremaining: 2.33s\n",
      "144:\tlearn: 0.2006244\ttotal: 954ms\tremaining: 2.33s\n",
      "145:\tlearn: 0.1986233\ttotal: 964ms\tremaining: 2.34s\n",
      "146:\tlearn: 0.1974440\ttotal: 974ms\tremaining: 2.34s\n",
      "147:\tlearn: 0.1961449\ttotal: 984ms\tremaining: 2.34s\n",
      "148:\tlearn: 0.1950377\ttotal: 994ms\tremaining: 2.34s\n",
      "149:\tlearn: 0.1939541\ttotal: 1s\tremaining: 2.34s\n",
      "150:\tlearn: 0.1924860\ttotal: 1.01s\tremaining: 2.34s\n",
      "151:\tlearn: 0.1914302\ttotal: 1.02s\tremaining: 2.33s\n",
      "152:\tlearn: 0.1903178\ttotal: 1.02s\tremaining: 2.32s\n",
      "153:\tlearn: 0.1891022\ttotal: 1.03s\tremaining: 2.31s\n",
      "154:\tlearn: 0.1869090\ttotal: 1.03s\tremaining: 2.3s\n",
      "155:\tlearn: 0.1855436\ttotal: 1.04s\tremaining: 2.29s\n",
      "156:\tlearn: 0.1845919\ttotal: 1.04s\tremaining: 2.28s\n",
      "157:\tlearn: 0.1833083\ttotal: 1.05s\tremaining: 2.27s\n",
      "158:\tlearn: 0.1821424\ttotal: 1.05s\tremaining: 2.26s\n",
      "159:\tlearn: 0.1812025\ttotal: 1.06s\tremaining: 2.25s\n",
      "160:\tlearn: 0.1802669\ttotal: 1.06s\tremaining: 2.24s\n",
      "161:\tlearn: 0.1792312\ttotal: 1.07s\tremaining: 2.23s\n",
      "162:\tlearn: 0.1782350\ttotal: 1.07s\tremaining: 2.22s\n",
      "163:\tlearn: 0.1771447\ttotal: 1.08s\tremaining: 2.21s\n",
      "164:\tlearn: 0.1759865\ttotal: 1.08s\tremaining: 2.19s\n",
      "165:\tlearn: 0.1750245\ttotal: 1.08s\tremaining: 2.18s\n",
      "166:\tlearn: 0.1740210\ttotal: 1.09s\tremaining: 2.17s\n",
      "167:\tlearn: 0.1732225\ttotal: 1.09s\tremaining: 2.16s\n",
      "168:\tlearn: 0.1722658\ttotal: 1.1s\tremaining: 2.15s\n",
      "169:\tlearn: 0.1712540\ttotal: 1.11s\tremaining: 2.16s\n",
      "170:\tlearn: 0.1703805\ttotal: 1.12s\tremaining: 2.16s\n",
      "171:\tlearn: 0.1693690\ttotal: 1.13s\tremaining: 2.16s\n",
      "172:\tlearn: 0.1685513\ttotal: 1.14s\tremaining: 2.15s\n",
      "173:\tlearn: 0.1678558\ttotal: 1.15s\tremaining: 2.15s\n",
      "174:\tlearn: 0.1669358\ttotal: 1.16s\tremaining: 2.15s\n",
      "175:\tlearn: 0.1658938\ttotal: 1.17s\tremaining: 2.15s\n",
      "176:\tlearn: 0.1644679\ttotal: 1.18s\tremaining: 2.15s\n",
      "177:\tlearn: 0.1635959\ttotal: 1.19s\tremaining: 2.15s\n",
      "178:\tlearn: 0.1630299\ttotal: 1.19s\tremaining: 2.14s\n",
      "179:\tlearn: 0.1621025\ttotal: 1.2s\tremaining: 2.13s\n",
      "180:\tlearn: 0.1615659\ttotal: 1.2s\tremaining: 2.12s\n",
      "181:\tlearn: 0.1604886\ttotal: 1.21s\tremaining: 2.12s\n",
      "182:\tlearn: 0.1596974\ttotal: 1.22s\tremaining: 2.11s\n",
      "183:\tlearn: 0.1589141\ttotal: 1.22s\tremaining: 2.1s\n",
      "184:\tlearn: 0.1579185\ttotal: 1.23s\tremaining: 2.09s\n",
      "185:\tlearn: 0.1569001\ttotal: 1.23s\tremaining: 2.08s\n",
      "186:\tlearn: 0.1561442\ttotal: 1.23s\tremaining: 2.06s\n",
      "187:\tlearn: 0.1554510\ttotal: 1.24s\tremaining: 2.05s\n",
      "188:\tlearn: 0.1541787\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.1531224\ttotal: 1.25s\tremaining: 2.03s\n",
      "190:\tlearn: 0.1518460\ttotal: 1.25s\tremaining: 2.02s\n",
      "191:\tlearn: 0.1510926\ttotal: 1.25s\tremaining: 2.01s\n",
      "192:\tlearn: 0.1501183\ttotal: 1.26s\tremaining: 2s\n",
      "193:\tlearn: 0.1493295\ttotal: 1.26s\tremaining: 1.99s\n",
      "194:\tlearn: 0.1484071\ttotal: 1.27s\tremaining: 1.98s\n",
      "195:\tlearn: 0.1475895\ttotal: 1.27s\tremaining: 1.97s\n",
      "196:\tlearn: 0.1467970\ttotal: 1.27s\tremaining: 1.96s\n",
      "197:\tlearn: 0.1460671\ttotal: 1.28s\tremaining: 1.95s\n",
      "198:\tlearn: 0.1452468\ttotal: 1.28s\tremaining: 1.94s\n",
      "199:\tlearn: 0.1446016\ttotal: 1.29s\tremaining: 1.94s\n",
      "200:\tlearn: 0.1439206\ttotal: 1.3s\tremaining: 1.94s\n",
      "201:\tlearn: 0.1430848\ttotal: 1.31s\tremaining: 1.94s\n",
      "202:\tlearn: 0.1423400\ttotal: 1.32s\tremaining: 1.93s\n",
      "203:\tlearn: 0.1417029\ttotal: 1.33s\tremaining: 1.93s\n",
      "204:\tlearn: 0.1409280\ttotal: 1.34s\tremaining: 1.93s\n",
      "205:\tlearn: 0.1403164\ttotal: 1.35s\tremaining: 1.93s\n",
      "206:\tlearn: 0.1396758\ttotal: 1.36s\tremaining: 1.93s\n",
      "207:\tlearn: 0.1389514\ttotal: 1.37s\tremaining: 1.92s\n",
      "208:\tlearn: 0.1377464\ttotal: 1.38s\tremaining: 1.92s\n",
      "209:\tlearn: 0.1369955\ttotal: 1.39s\tremaining: 1.92s\n",
      "210:\tlearn: 0.1362805\ttotal: 1.4s\tremaining: 1.92s\n",
      "211:\tlearn: 0.1354961\ttotal: 1.41s\tremaining: 1.91s\n",
      "212:\tlearn: 0.1347777\ttotal: 1.42s\tremaining: 1.91s\n",
      "213:\tlearn: 0.1340560\ttotal: 1.43s\tremaining: 1.91s\n",
      "214:\tlearn: 0.1332425\ttotal: 1.43s\tremaining: 1.9s\n",
      "215:\tlearn: 0.1323172\ttotal: 1.44s\tremaining: 1.89s\n",
      "216:\tlearn: 0.1315540\ttotal: 1.45s\tremaining: 1.88s\n",
      "217:\tlearn: 0.1310146\ttotal: 1.45s\tremaining: 1.87s\n",
      "218:\tlearn: 0.1302661\ttotal: 1.45s\tremaining: 1.86s\n",
      "219:\tlearn: 0.1298532\ttotal: 1.46s\tremaining: 1.85s\n",
      "220:\tlearn: 0.1291246\ttotal: 1.46s\tremaining: 1.84s\n",
      "221:\tlearn: 0.1284486\ttotal: 1.47s\tremaining: 1.83s\n",
      "222:\tlearn: 0.1277242\ttotal: 1.47s\tremaining: 1.83s\n",
      "223:\tlearn: 0.1270315\ttotal: 1.47s\tremaining: 1.82s\n",
      "224:\tlearn: 0.1264872\ttotal: 1.48s\tremaining: 1.81s\n",
      "225:\tlearn: 0.1257991\ttotal: 1.49s\tremaining: 1.8s\n",
      "226:\tlearn: 0.1250971\ttotal: 1.5s\tremaining: 1.8s\n",
      "227:\tlearn: 0.1243875\ttotal: 1.51s\tremaining: 1.8s\n",
      "228:\tlearn: 0.1237755\ttotal: 1.52s\tremaining: 1.79s\n",
      "229:\tlearn: 0.1231976\ttotal: 1.52s\tremaining: 1.79s\n",
      "230:\tlearn: 0.1225043\ttotal: 1.53s\tremaining: 1.79s\n",
      "231:\tlearn: 0.1218717\ttotal: 1.54s\tremaining: 1.78s\n",
      "232:\tlearn: 0.1202883\ttotal: 1.55s\tremaining: 1.78s\n",
      "233:\tlearn: 0.1196335\ttotal: 1.56s\tremaining: 1.78s\n",
      "234:\tlearn: 0.1191077\ttotal: 1.57s\tremaining: 1.77s\n",
      "235:\tlearn: 0.1185108\ttotal: 1.57s\tremaining: 1.76s\n",
      "236:\tlearn: 0.1180928\ttotal: 1.58s\tremaining: 1.75s\n",
      "237:\tlearn: 0.1175332\ttotal: 1.58s\tremaining: 1.74s\n",
      "238:\tlearn: 0.1168035\ttotal: 1.59s\tremaining: 1.73s\n",
      "239:\tlearn: 0.1161200\ttotal: 1.59s\tremaining: 1.72s\n",
      "240:\tlearn: 0.1156446\ttotal: 1.6s\tremaining: 1.72s\n",
      "241:\tlearn: 0.1150953\ttotal: 1.6s\tremaining: 1.71s\n",
      "242:\tlearn: 0.1146189\ttotal: 1.61s\tremaining: 1.7s\n",
      "243:\tlearn: 0.1140357\ttotal: 1.62s\tremaining: 1.7s\n",
      "244:\tlearn: 0.1134723\ttotal: 1.63s\tremaining: 1.7s\n",
      "245:\tlearn: 0.1128557\ttotal: 1.64s\tremaining: 1.69s\n",
      "246:\tlearn: 0.1122699\ttotal: 1.65s\tremaining: 1.69s\n",
      "247:\tlearn: 0.1116507\ttotal: 1.65s\tremaining: 1.68s\n",
      "248:\tlearn: 0.1111294\ttotal: 1.66s\tremaining: 1.67s\n",
      "249:\tlearn: 0.1106350\ttotal: 1.66s\tremaining: 1.66s\n",
      "250:\tlearn: 0.1101063\ttotal: 1.66s\tremaining: 1.65s\n",
      "251:\tlearn: 0.1095908\ttotal: 1.67s\tremaining: 1.64s\n",
      "252:\tlearn: 0.1091012\ttotal: 1.67s\tremaining: 1.63s\n",
      "253:\tlearn: 0.1081205\ttotal: 1.68s\tremaining: 1.63s\n",
      "254:\tlearn: 0.1075923\ttotal: 1.68s\tremaining: 1.62s\n",
      "255:\tlearn: 0.1067636\ttotal: 1.69s\tremaining: 1.61s\n",
      "256:\tlearn: 0.1061035\ttotal: 1.69s\tremaining: 1.6s\n",
      "257:\tlearn: 0.1055402\ttotal: 1.7s\tremaining: 1.59s\n",
      "258:\tlearn: 0.1050471\ttotal: 1.7s\tremaining: 1.58s\n",
      "259:\tlearn: 0.1045385\ttotal: 1.7s\tremaining: 1.57s\n",
      "260:\tlearn: 0.1034591\ttotal: 1.71s\tremaining: 1.56s\n",
      "261:\tlearn: 0.1028659\ttotal: 1.71s\tremaining: 1.55s\n",
      "262:\tlearn: 0.1022039\ttotal: 1.72s\tremaining: 1.55s\n",
      "263:\tlearn: 0.1012354\ttotal: 1.72s\tremaining: 1.54s\n",
      "264:\tlearn: 0.0999860\ttotal: 1.72s\tremaining: 1.53s\n",
      "265:\tlearn: 0.0992648\ttotal: 1.73s\tremaining: 1.52s\n",
      "266:\tlearn: 0.0988323\ttotal: 1.73s\tremaining: 1.51s\n",
      "267:\tlearn: 0.0983935\ttotal: 1.73s\tremaining: 1.5s\n",
      "268:\tlearn: 0.0975130\ttotal: 1.74s\tremaining: 1.49s\n",
      "269:\tlearn: 0.0969462\ttotal: 1.74s\tremaining: 1.49s\n",
      "270:\tlearn: 0.0964845\ttotal: 1.75s\tremaining: 1.48s\n",
      "271:\tlearn: 0.0960215\ttotal: 1.75s\tremaining: 1.47s\n",
      "272:\tlearn: 0.0952359\ttotal: 1.76s\tremaining: 1.46s\n",
      "273:\tlearn: 0.0947907\ttotal: 1.77s\tremaining: 1.46s\n",
      "274:\tlearn: 0.0942628\ttotal: 1.77s\tremaining: 1.45s\n",
      "275:\tlearn: 0.0937478\ttotal: 1.78s\tremaining: 1.44s\n",
      "276:\tlearn: 0.0932614\ttotal: 1.78s\tremaining: 1.44s\n",
      "277:\tlearn: 0.0923970\ttotal: 1.79s\tremaining: 1.43s\n",
      "278:\tlearn: 0.0919163\ttotal: 1.79s\tremaining: 1.42s\n",
      "279:\tlearn: 0.0914780\ttotal: 1.8s\tremaining: 1.41s\n",
      "280:\tlearn: 0.0910642\ttotal: 1.81s\tremaining: 1.41s\n",
      "281:\tlearn: 0.0904747\ttotal: 1.81s\tremaining: 1.4s\n",
      "282:\tlearn: 0.0898994\ttotal: 1.82s\tremaining: 1.4s\n",
      "283:\tlearn: 0.0894644\ttotal: 1.83s\tremaining: 1.39s\n",
      "284:\tlearn: 0.0888247\ttotal: 1.84s\tremaining: 1.39s\n",
      "285:\tlearn: 0.0883752\ttotal: 1.85s\tremaining: 1.39s\n",
      "286:\tlearn: 0.0878857\ttotal: 1.86s\tremaining: 1.38s\n",
      "287:\tlearn: 0.0874811\ttotal: 1.87s\tremaining: 1.38s\n",
      "288:\tlearn: 0.0871125\ttotal: 1.88s\tremaining: 1.37s\n",
      "289:\tlearn: 0.0866472\ttotal: 1.89s\tremaining: 1.37s\n",
      "290:\tlearn: 0.0860992\ttotal: 1.9s\tremaining: 1.36s\n",
      "291:\tlearn: 0.0855647\ttotal: 1.91s\tremaining: 1.36s\n",
      "292:\tlearn: 0.0850124\ttotal: 1.92s\tremaining: 1.35s\n",
      "293:\tlearn: 0.0845554\ttotal: 1.92s\tremaining: 1.35s\n",
      "294:\tlearn: 0.0841685\ttotal: 1.93s\tremaining: 1.34s\n",
      "295:\tlearn: 0.0838782\ttotal: 1.94s\tremaining: 1.33s\n",
      "296:\tlearn: 0.0834511\ttotal: 1.94s\tremaining: 1.33s\n",
      "297:\tlearn: 0.0828874\ttotal: 1.95s\tremaining: 1.32s\n",
      "298:\tlearn: 0.0825426\ttotal: 1.95s\tremaining: 1.31s\n",
      "299:\tlearn: 0.0821130\ttotal: 1.95s\tremaining: 1.3s\n",
      "300:\tlearn: 0.0816853\ttotal: 1.96s\tremaining: 1.29s\n",
      "301:\tlearn: 0.0813108\ttotal: 1.96s\tremaining: 1.29s\n",
      "302:\tlearn: 0.0809674\ttotal: 1.97s\tremaining: 1.28s\n",
      "303:\tlearn: 0.0806182\ttotal: 1.97s\tremaining: 1.27s\n",
      "304:\tlearn: 0.0803458\ttotal: 1.98s\tremaining: 1.26s\n",
      "305:\tlearn: 0.0799921\ttotal: 1.98s\tremaining: 1.26s\n",
      "306:\tlearn: 0.0796808\ttotal: 1.99s\tremaining: 1.25s\n",
      "307:\tlearn: 0.0793488\ttotal: 2s\tremaining: 1.25s\n",
      "308:\tlearn: 0.0789396\ttotal: 2.01s\tremaining: 1.24s\n",
      "309:\tlearn: 0.0785310\ttotal: 2.02s\tremaining: 1.24s\n",
      "310:\tlearn: 0.0781844\ttotal: 2.03s\tremaining: 1.23s\n",
      "311:\tlearn: 0.0777378\ttotal: 2.04s\tremaining: 1.23s\n",
      "312:\tlearn: 0.0772648\ttotal: 2.04s\tremaining: 1.22s\n",
      "313:\tlearn: 0.0769321\ttotal: 2.06s\tremaining: 1.22s\n",
      "314:\tlearn: 0.0764723\ttotal: 2.06s\tremaining: 1.21s\n",
      "315:\tlearn: 0.0760180\ttotal: 2.07s\tremaining: 1.21s\n",
      "316:\tlearn: 0.0756896\ttotal: 2.08s\tremaining: 1.2s\n",
      "317:\tlearn: 0.0752835\ttotal: 2.09s\tremaining: 1.19s\n",
      "318:\tlearn: 0.0748175\ttotal: 2.09s\tremaining: 1.19s\n",
      "319:\tlearn: 0.0744260\ttotal: 2.1s\tremaining: 1.18s\n",
      "320:\tlearn: 0.0740702\ttotal: 2.1s\tremaining: 1.17s\n",
      "321:\tlearn: 0.0737228\ttotal: 2.11s\tremaining: 1.17s\n",
      "322:\tlearn: 0.0733954\ttotal: 2.11s\tremaining: 1.16s\n",
      "323:\tlearn: 0.0730146\ttotal: 2.12s\tremaining: 1.15s\n",
      "324:\tlearn: 0.0726474\ttotal: 2.12s\tremaining: 1.14s\n",
      "325:\tlearn: 0.0724073\ttotal: 2.13s\tremaining: 1.14s\n",
      "326:\tlearn: 0.0720455\ttotal: 2.13s\tremaining: 1.13s\n",
      "327:\tlearn: 0.0716749\ttotal: 2.14s\tremaining: 1.12s\n",
      "328:\tlearn: 0.0712158\ttotal: 2.14s\tremaining: 1.11s\n",
      "329:\tlearn: 0.0709125\ttotal: 2.15s\tremaining: 1.1s\n",
      "330:\tlearn: 0.0705985\ttotal: 2.15s\tremaining: 1.1s\n",
      "331:\tlearn: 0.0701131\ttotal: 2.15s\tremaining: 1.09s\n",
      "332:\tlearn: 0.0697360\ttotal: 2.16s\tremaining: 1.08s\n",
      "333:\tlearn: 0.0692395\ttotal: 2.16s\tremaining: 1.07s\n",
      "334:\tlearn: 0.0689141\ttotal: 2.17s\tremaining: 1.07s\n",
      "335:\tlearn: 0.0686970\ttotal: 2.19s\tremaining: 1.07s\n",
      "336:\tlearn: 0.0683706\ttotal: 2.19s\tremaining: 1.06s\n",
      "337:\tlearn: 0.0680540\ttotal: 2.2s\tremaining: 1.06s\n",
      "338:\tlearn: 0.0677103\ttotal: 2.21s\tremaining: 1.05s\n",
      "339:\tlearn: 0.0674408\ttotal: 2.22s\tremaining: 1.05s\n",
      "340:\tlearn: 0.0671352\ttotal: 2.23s\tremaining: 1.04s\n",
      "341:\tlearn: 0.0669574\ttotal: 2.24s\tremaining: 1.04s\n",
      "342:\tlearn: 0.0664871\ttotal: 2.25s\tremaining: 1.03s\n",
      "343:\tlearn: 0.0662006\ttotal: 2.26s\tremaining: 1.02s\n",
      "344:\tlearn: 0.0658054\ttotal: 2.27s\tremaining: 1.02s\n",
      "345:\tlearn: 0.0655444\ttotal: 2.27s\tremaining: 1.01s\n",
      "346:\tlearn: 0.0651677\ttotal: 2.28s\tremaining: 1s\n",
      "347:\tlearn: 0.0647778\ttotal: 2.28s\tremaining: 998ms\n",
      "348:\tlearn: 0.0644788\ttotal: 2.29s\tremaining: 990ms\n",
      "349:\tlearn: 0.0642262\ttotal: 2.29s\tremaining: 983ms\n",
      "350:\tlearn: 0.0639389\ttotal: 2.3s\tremaining: 976ms\n",
      "351:\tlearn: 0.0637858\ttotal: 2.3s\tremaining: 968ms\n",
      "352:\tlearn: 0.0633042\ttotal: 2.31s\tremaining: 961ms\n",
      "353:\tlearn: 0.0631136\ttotal: 2.31s\tremaining: 954ms\n",
      "354:\tlearn: 0.0628788\ttotal: 2.32s\tremaining: 946ms\n",
      "355:\tlearn: 0.0625641\ttotal: 2.32s\tremaining: 939ms\n",
      "356:\tlearn: 0.0622797\ttotal: 2.33s\tremaining: 932ms\n",
      "357:\tlearn: 0.0619818\ttotal: 2.33s\tremaining: 924ms\n",
      "358:\tlearn: 0.0616968\ttotal: 2.34s\tremaining: 919ms\n",
      "359:\tlearn: 0.0613609\ttotal: 2.35s\tremaining: 914ms\n",
      "360:\tlearn: 0.0611035\ttotal: 2.36s\tremaining: 908ms\n",
      "361:\tlearn: 0.0608443\ttotal: 2.37s\tremaining: 903ms\n",
      "362:\tlearn: 0.0605858\ttotal: 2.38s\tremaining: 897ms\n",
      "363:\tlearn: 0.0603184\ttotal: 2.39s\tremaining: 892ms\n",
      "364:\tlearn: 0.0600351\ttotal: 2.4s\tremaining: 887ms\n",
      "365:\tlearn: 0.0596664\ttotal: 2.41s\tremaining: 881ms\n",
      "366:\tlearn: 0.0593738\ttotal: 2.42s\tremaining: 875ms\n",
      "367:\tlearn: 0.0590261\ttotal: 2.42s\tremaining: 869ms\n",
      "368:\tlearn: 0.0586732\ttotal: 2.43s\tremaining: 862ms\n",
      "369:\tlearn: 0.0584291\ttotal: 2.43s\tremaining: 855ms\n",
      "370:\tlearn: 0.0580877\ttotal: 2.44s\tremaining: 849ms\n",
      "371:\tlearn: 0.0578358\ttotal: 2.44s\tremaining: 842ms\n",
      "372:\tlearn: 0.0575734\ttotal: 2.45s\tremaining: 834ms\n",
      "373:\tlearn: 0.0573573\ttotal: 2.45s\tremaining: 827ms\n",
      "374:\tlearn: 0.0570732\ttotal: 2.46s\tremaining: 820ms\n",
      "375:\tlearn: 0.0566950\ttotal: 2.46s\tremaining: 813ms\n",
      "376:\tlearn: 0.0563890\ttotal: 2.47s\tremaining: 806ms\n",
      "377:\tlearn: 0.0561154\ttotal: 2.47s\tremaining: 798ms\n",
      "378:\tlearn: 0.0558857\ttotal: 2.48s\tremaining: 791ms\n",
      "379:\tlearn: 0.0555498\ttotal: 2.48s\tremaining: 784ms\n",
      "380:\tlearn: 0.0552865\ttotal: 2.49s\tremaining: 777ms\n",
      "381:\tlearn: 0.0550452\ttotal: 2.49s\tremaining: 770ms\n",
      "382:\tlearn: 0.0547275\ttotal: 2.5s\tremaining: 763ms\n",
      "383:\tlearn: 0.0543349\ttotal: 2.5s\tremaining: 756ms\n",
      "384:\tlearn: 0.0540870\ttotal: 2.51s\tremaining: 749ms\n",
      "385:\tlearn: 0.0537392\ttotal: 2.51s\tremaining: 742ms\n",
      "386:\tlearn: 0.0534775\ttotal: 2.52s\tremaining: 735ms\n",
      "387:\tlearn: 0.0532392\ttotal: 2.52s\tremaining: 728ms\n",
      "388:\tlearn: 0.0529775\ttotal: 2.53s\tremaining: 723ms\n",
      "389:\tlearn: 0.0526856\ttotal: 2.54s\tremaining: 717ms\n",
      "390:\tlearn: 0.0521881\ttotal: 2.55s\tremaining: 712ms\n",
      "391:\tlearn: 0.0519669\ttotal: 2.56s\tremaining: 706ms\n",
      "392:\tlearn: 0.0516720\ttotal: 2.57s\tremaining: 700ms\n",
      "393:\tlearn: 0.0513283\ttotal: 2.58s\tremaining: 695ms\n",
      "394:\tlearn: 0.0510446\ttotal: 2.59s\tremaining: 689ms\n",
      "395:\tlearn: 0.0507964\ttotal: 2.6s\tremaining: 683ms\n",
      "396:\tlearn: 0.0505022\ttotal: 2.61s\tremaining: 677ms\n",
      "397:\tlearn: 0.0503085\ttotal: 2.62s\tremaining: 671ms\n",
      "398:\tlearn: 0.0501055\ttotal: 2.62s\tremaining: 664ms\n",
      "399:\tlearn: 0.0497638\ttotal: 2.63s\tremaining: 657ms\n",
      "400:\tlearn: 0.0495803\ttotal: 2.63s\tremaining: 651ms\n",
      "401:\tlearn: 0.0493665\ttotal: 2.64s\tremaining: 644ms\n",
      "402:\tlearn: 0.0492300\ttotal: 2.65s\tremaining: 637ms\n",
      "403:\tlearn: 0.0489007\ttotal: 2.65s\tremaining: 630ms\n",
      "404:\tlearn: 0.0486551\ttotal: 2.65s\tremaining: 623ms\n",
      "405:\tlearn: 0.0484300\ttotal: 2.66s\tremaining: 616ms\n",
      "406:\tlearn: 0.0482048\ttotal: 2.66s\tremaining: 609ms\n",
      "407:\tlearn: 0.0479518\ttotal: 2.67s\tremaining: 602ms\n",
      "408:\tlearn: 0.0477324\ttotal: 2.67s\tremaining: 595ms\n",
      "409:\tlearn: 0.0475226\ttotal: 2.68s\tremaining: 588ms\n",
      "410:\tlearn: 0.0472470\ttotal: 2.68s\tremaining: 581ms\n",
      "411:\tlearn: 0.0470946\ttotal: 2.69s\tremaining: 574ms\n",
      "412:\tlearn: 0.0468704\ttotal: 2.69s\tremaining: 567ms\n",
      "413:\tlearn: 0.0466769\ttotal: 2.7s\tremaining: 561ms\n",
      "414:\tlearn: 0.0463719\ttotal: 2.71s\tremaining: 555ms\n",
      "415:\tlearn: 0.0462240\ttotal: 2.72s\tremaining: 549ms\n",
      "416:\tlearn: 0.0459959\ttotal: 2.73s\tremaining: 543ms\n",
      "417:\tlearn: 0.0457853\ttotal: 2.74s\tremaining: 537ms\n",
      "418:\tlearn: 0.0454531\ttotal: 2.75s\tremaining: 531ms\n",
      "419:\tlearn: 0.0451844\ttotal: 2.76s\tremaining: 525ms\n",
      "420:\tlearn: 0.0448438\ttotal: 2.77s\tremaining: 519ms\n",
      "421:\tlearn: 0.0446837\ttotal: 2.78s\tremaining: 513ms\n",
      "422:\tlearn: 0.0444411\ttotal: 2.79s\tremaining: 507ms\n",
      "423:\tlearn: 0.0441515\ttotal: 2.79s\tremaining: 501ms\n",
      "424:\tlearn: 0.0438902\ttotal: 2.8s\tremaining: 494ms\n",
      "425:\tlearn: 0.0436752\ttotal: 2.81s\tremaining: 487ms\n",
      "426:\tlearn: 0.0435259\ttotal: 2.81s\tremaining: 481ms\n",
      "427:\tlearn: 0.0433555\ttotal: 2.82s\tremaining: 474ms\n",
      "428:\tlearn: 0.0431580\ttotal: 2.82s\tremaining: 467ms\n",
      "429:\tlearn: 0.0429542\ttotal: 2.83s\tremaining: 460ms\n",
      "430:\tlearn: 0.0426647\ttotal: 2.83s\tremaining: 453ms\n",
      "431:\tlearn: 0.0424453\ttotal: 2.83s\tremaining: 446ms\n",
      "432:\tlearn: 0.0423080\ttotal: 2.84s\tremaining: 440ms\n",
      "433:\tlearn: 0.0419494\ttotal: 2.85s\tremaining: 433ms\n",
      "434:\tlearn: 0.0417954\ttotal: 2.85s\tremaining: 426ms\n",
      "435:\tlearn: 0.0415836\ttotal: 2.85s\tremaining: 419ms\n",
      "436:\tlearn: 0.0414702\ttotal: 2.86s\tremaining: 412ms\n",
      "437:\tlearn: 0.0412575\ttotal: 2.86s\tremaining: 405ms\n",
      "438:\tlearn: 0.0410888\ttotal: 2.87s\tremaining: 399ms\n",
      "439:\tlearn: 0.0409118\ttotal: 2.88s\tremaining: 393ms\n",
      "440:\tlearn: 0.0407682\ttotal: 2.89s\tremaining: 387ms\n",
      "441:\tlearn: 0.0405848\ttotal: 2.9s\tremaining: 381ms\n",
      "442:\tlearn: 0.0404279\ttotal: 2.91s\tremaining: 375ms\n",
      "443:\tlearn: 0.0402622\ttotal: 2.92s\tremaining: 368ms\n",
      "444:\tlearn: 0.0400481\ttotal: 2.93s\tremaining: 362ms\n",
      "445:\tlearn: 0.0398386\ttotal: 2.94s\tremaining: 356ms\n",
      "446:\tlearn: 0.0396742\ttotal: 2.95s\tremaining: 350ms\n",
      "447:\tlearn: 0.0394861\ttotal: 2.96s\tremaining: 343ms\n",
      "448:\tlearn: 0.0393045\ttotal: 2.96s\tremaining: 337ms\n",
      "449:\tlearn: 0.0391363\ttotal: 2.97s\tremaining: 330ms\n",
      "450:\tlearn: 0.0389667\ttotal: 2.98s\tremaining: 323ms\n",
      "451:\tlearn: 0.0387764\ttotal: 2.98s\tremaining: 317ms\n",
      "452:\tlearn: 0.0385473\ttotal: 2.99s\tremaining: 310ms\n",
      "453:\tlearn: 0.0383565\ttotal: 2.99s\tremaining: 303ms\n",
      "454:\tlearn: 0.0381975\ttotal: 3s\tremaining: 296ms\n",
      "455:\tlearn: 0.0379684\ttotal: 3s\tremaining: 289ms\n",
      "456:\tlearn: 0.0378399\ttotal: 3s\tremaining: 283ms\n",
      "457:\tlearn: 0.0376421\ttotal: 3.01s\tremaining: 276ms\n",
      "458:\tlearn: 0.0374439\ttotal: 3.01s\tremaining: 269ms\n",
      "459:\tlearn: 0.0372586\ttotal: 3.02s\tremaining: 262ms\n",
      "460:\tlearn: 0.0370812\ttotal: 3.02s\tremaining: 256ms\n",
      "461:\tlearn: 0.0369110\ttotal: 3.03s\tremaining: 249ms\n",
      "462:\tlearn: 0.0367515\ttotal: 3.03s\tremaining: 242ms\n",
      "463:\tlearn: 0.0365969\ttotal: 3.04s\tremaining: 236ms\n",
      "464:\tlearn: 0.0365022\ttotal: 3.04s\tremaining: 229ms\n",
      "465:\tlearn: 0.0363132\ttotal: 3.05s\tremaining: 223ms\n",
      "466:\tlearn: 0.0361335\ttotal: 3.06s\tremaining: 216ms\n",
      "467:\tlearn: 0.0360326\ttotal: 3.07s\tremaining: 210ms\n",
      "468:\tlearn: 0.0359006\ttotal: 3.08s\tremaining: 204ms\n",
      "469:\tlearn: 0.0357528\ttotal: 3.09s\tremaining: 197ms\n",
      "470:\tlearn: 0.0355236\ttotal: 3.1s\tremaining: 191ms\n",
      "471:\tlearn: 0.0353731\ttotal: 3.11s\tremaining: 184ms\n",
      "472:\tlearn: 0.0351931\ttotal: 3.12s\tremaining: 178ms\n",
      "473:\tlearn: 0.0349677\ttotal: 3.13s\tremaining: 172ms\n",
      "474:\tlearn: 0.0348330\ttotal: 3.13s\tremaining: 165ms\n",
      "475:\tlearn: 0.0347160\ttotal: 3.14s\tremaining: 158ms\n",
      "476:\tlearn: 0.0345284\ttotal: 3.15s\tremaining: 152ms\n",
      "477:\tlearn: 0.0343748\ttotal: 3.15s\tremaining: 145ms\n",
      "478:\tlearn: 0.0342016\ttotal: 3.16s\tremaining: 138ms\n",
      "479:\tlearn: 0.0340400\ttotal: 3.16s\tremaining: 132ms\n",
      "480:\tlearn: 0.0340304\ttotal: 3.17s\tremaining: 125ms\n",
      "481:\tlearn: 0.0338595\ttotal: 3.17s\tremaining: 119ms\n",
      "482:\tlearn: 0.0337628\ttotal: 3.18s\tremaining: 112ms\n",
      "483:\tlearn: 0.0336377\ttotal: 3.18s\tremaining: 105ms\n",
      "484:\tlearn: 0.0334880\ttotal: 3.19s\tremaining: 98.5ms\n",
      "485:\tlearn: 0.0333106\ttotal: 3.19s\tremaining: 91.9ms\n",
      "486:\tlearn: 0.0331687\ttotal: 3.19s\tremaining: 85.3ms\n",
      "487:\tlearn: 0.0330378\ttotal: 3.2s\tremaining: 78.7ms\n",
      "488:\tlearn: 0.0328837\ttotal: 3.21s\tremaining: 72.1ms\n",
      "489:\tlearn: 0.0327021\ttotal: 3.22s\tremaining: 65.7ms\n",
      "490:\tlearn: 0.0326286\ttotal: 3.23s\tremaining: 59.1ms\n",
      "491:\tlearn: 0.0325065\ttotal: 3.24s\tremaining: 52.6ms\n",
      "492:\tlearn: 0.0323378\ttotal: 3.25s\tremaining: 46.1ms\n",
      "493:\tlearn: 0.0321900\ttotal: 3.25s\tremaining: 39.5ms\n",
      "494:\tlearn: 0.0320239\ttotal: 3.27s\tremaining: 33ms\n",
      "495:\tlearn: 0.0318956\ttotal: 3.27s\tremaining: 26.4ms\n",
      "496:\tlearn: 0.0317574\ttotal: 3.29s\tremaining: 19.8ms\n",
      "497:\tlearn: 0.0317000\ttotal: 3.29s\tremaining: 13.2ms\n",
      "498:\tlearn: 0.0315440\ttotal: 3.3s\tremaining: 6.61ms\n",
      "499:\tlearn: 0.0314000\ttotal: 3.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6806784\ttotal: 5.05ms\tremaining: 2.52s\n",
      "1:\tlearn: 0.6714810\ttotal: 11.1ms\tremaining: 2.77s\n",
      "2:\tlearn: 0.6607656\ttotal: 15.7ms\tremaining: 2.6s\n",
      "3:\tlearn: 0.6530006\ttotal: 19.9ms\tremaining: 2.47s\n",
      "4:\tlearn: 0.6436467\ttotal: 24.6ms\tremaining: 2.44s\n",
      "5:\tlearn: 0.6349807\ttotal: 29.6ms\tremaining: 2.44s\n",
      "6:\tlearn: 0.6249167\ttotal: 35.5ms\tremaining: 2.5s\n",
      "7:\tlearn: 0.6174423\ttotal: 40.5ms\tremaining: 2.49s\n",
      "8:\tlearn: 0.6088822\ttotal: 45.5ms\tremaining: 2.48s\n",
      "9:\tlearn: 0.6012206\ttotal: 49.6ms\tremaining: 2.43s\n",
      "10:\tlearn: 0.5961709\ttotal: 53.8ms\tremaining: 2.39s\n",
      "11:\tlearn: 0.5909595\ttotal: 58.1ms\tremaining: 2.36s\n",
      "12:\tlearn: 0.5843527\ttotal: 62.4ms\tremaining: 2.34s\n",
      "13:\tlearn: 0.5786903\ttotal: 66.5ms\tremaining: 2.31s\n",
      "14:\tlearn: 0.5730930\ttotal: 70.8ms\tremaining: 2.29s\n",
      "15:\tlearn: 0.5627672\ttotal: 75ms\tremaining: 2.27s\n",
      "16:\tlearn: 0.5557380\ttotal: 78.9ms\tremaining: 2.24s\n",
      "17:\tlearn: 0.5483620\ttotal: 88.7ms\tremaining: 2.38s\n",
      "18:\tlearn: 0.5437408\ttotal: 98ms\tremaining: 2.48s\n",
      "19:\tlearn: 0.5369693\ttotal: 108ms\tremaining: 2.58s\n",
      "20:\tlearn: 0.5316391\ttotal: 117ms\tremaining: 2.67s\n",
      "21:\tlearn: 0.5260035\ttotal: 127ms\tremaining: 2.75s\n",
      "22:\tlearn: 0.5212617\ttotal: 136ms\tremaining: 2.82s\n",
      "23:\tlearn: 0.5141314\ttotal: 145ms\tremaining: 2.88s\n",
      "24:\tlearn: 0.5084225\ttotal: 155ms\tremaining: 2.95s\n",
      "25:\tlearn: 0.5041161\ttotal: 165ms\tremaining: 3s\n",
      "26:\tlearn: 0.4998431\ttotal: 172ms\tremaining: 3.02s\n",
      "27:\tlearn: 0.4962525\ttotal: 178ms\tremaining: 3s\n",
      "28:\tlearn: 0.4895570\ttotal: 184ms\tremaining: 2.98s\n",
      "29:\tlearn: 0.4851395\ttotal: 187ms\tremaining: 2.94s\n",
      "30:\tlearn: 0.4816286\ttotal: 192ms\tremaining: 2.91s\n",
      "31:\tlearn: 0.4773089\ttotal: 197ms\tremaining: 2.88s\n",
      "32:\tlearn: 0.4726507\ttotal: 203ms\tremaining: 2.88s\n",
      "33:\tlearn: 0.4673412\ttotal: 210ms\tremaining: 2.87s\n",
      "34:\tlearn: 0.4637554\ttotal: 215ms\tremaining: 2.86s\n",
      "35:\tlearn: 0.4592320\ttotal: 219ms\tremaining: 2.82s\n",
      "36:\tlearn: 0.4558125\ttotal: 223ms\tremaining: 2.79s\n",
      "37:\tlearn: 0.4527600\ttotal: 228ms\tremaining: 2.77s\n",
      "38:\tlearn: 0.4485214\ttotal: 232ms\tremaining: 2.74s\n",
      "39:\tlearn: 0.4428817\ttotal: 236ms\tremaining: 2.72s\n",
      "40:\tlearn: 0.4402147\ttotal: 240ms\tremaining: 2.69s\n",
      "41:\tlearn: 0.4370165\ttotal: 245ms\tremaining: 2.67s\n",
      "42:\tlearn: 0.4337168\ttotal: 254ms\tremaining: 2.7s\n",
      "43:\tlearn: 0.4301051\ttotal: 264ms\tremaining: 2.74s\n",
      "44:\tlearn: 0.4245779\ttotal: 274ms\tremaining: 2.77s\n",
      "45:\tlearn: 0.4218248\ttotal: 283ms\tremaining: 2.8s\n",
      "46:\tlearn: 0.4192483\ttotal: 293ms\tremaining: 2.83s\n",
      "47:\tlearn: 0.4147592\ttotal: 303ms\tremaining: 2.85s\n",
      "48:\tlearn: 0.4118216\ttotal: 312ms\tremaining: 2.87s\n",
      "49:\tlearn: 0.4092659\ttotal: 322ms\tremaining: 2.9s\n",
      "50:\tlearn: 0.4063153\ttotal: 331ms\tremaining: 2.91s\n",
      "51:\tlearn: 0.4038387\ttotal: 338ms\tremaining: 2.91s\n",
      "52:\tlearn: 0.4008570\ttotal: 344ms\tremaining: 2.9s\n",
      "53:\tlearn: 0.3963127\ttotal: 350ms\tremaining: 2.89s\n",
      "54:\tlearn: 0.3919170\ttotal: 357ms\tremaining: 2.89s\n",
      "55:\tlearn: 0.3883412\ttotal: 365ms\tremaining: 2.89s\n",
      "56:\tlearn: 0.3859565\ttotal: 370ms\tremaining: 2.88s\n",
      "57:\tlearn: 0.3823914\ttotal: 374ms\tremaining: 2.85s\n",
      "58:\tlearn: 0.3771826\ttotal: 378ms\tremaining: 2.83s\n",
      "59:\tlearn: 0.3741471\ttotal: 384ms\tremaining: 2.82s\n",
      "60:\tlearn: 0.3723708\ttotal: 389ms\tremaining: 2.8s\n",
      "61:\tlearn: 0.3695945\ttotal: 393ms\tremaining: 2.78s\n",
      "62:\tlearn: 0.3676110\ttotal: 398ms\tremaining: 2.76s\n",
      "63:\tlearn: 0.3655729\ttotal: 403ms\tremaining: 2.74s\n",
      "64:\tlearn: 0.3633835\ttotal: 407ms\tremaining: 2.73s\n",
      "65:\tlearn: 0.3617657\ttotal: 411ms\tremaining: 2.71s\n",
      "66:\tlearn: 0.3593773\ttotal: 416ms\tremaining: 2.69s\n",
      "67:\tlearn: 0.3564620\ttotal: 420ms\tremaining: 2.67s\n",
      "68:\tlearn: 0.3548702\ttotal: 425ms\tremaining: 2.65s\n",
      "69:\tlearn: 0.3524312\ttotal: 429ms\tremaining: 2.63s\n",
      "70:\tlearn: 0.3498974\ttotal: 433ms\tremaining: 2.62s\n",
      "71:\tlearn: 0.3475885\ttotal: 437ms\tremaining: 2.6s\n",
      "72:\tlearn: 0.3455365\ttotal: 442ms\tremaining: 2.58s\n",
      "73:\tlearn: 0.3429456\ttotal: 446ms\tremaining: 2.57s\n",
      "74:\tlearn: 0.3402321\ttotal: 457ms\tremaining: 2.59s\n",
      "75:\tlearn: 0.3376041\ttotal: 466ms\tremaining: 2.6s\n",
      "76:\tlearn: 0.3357298\ttotal: 476ms\tremaining: 2.62s\n",
      "77:\tlearn: 0.3338448\ttotal: 486ms\tremaining: 2.63s\n",
      "78:\tlearn: 0.3315672\ttotal: 496ms\tremaining: 2.64s\n",
      "79:\tlearn: 0.3289019\ttotal: 506ms\tremaining: 2.65s\n",
      "80:\tlearn: 0.3259077\ttotal: 516ms\tremaining: 2.67s\n",
      "81:\tlearn: 0.3243240\ttotal: 524ms\tremaining: 2.67s\n",
      "82:\tlearn: 0.3225137\ttotal: 531ms\tremaining: 2.67s\n",
      "83:\tlearn: 0.3184424\ttotal: 537ms\tremaining: 2.66s\n",
      "84:\tlearn: 0.3157155\ttotal: 546ms\tremaining: 2.67s\n",
      "85:\tlearn: 0.3112669\ttotal: 554ms\tremaining: 2.66s\n",
      "86:\tlearn: 0.3091015\ttotal: 558ms\tremaining: 2.65s\n",
      "87:\tlearn: 0.3072296\ttotal: 563ms\tremaining: 2.63s\n",
      "88:\tlearn: 0.3039306\ttotal: 568ms\tremaining: 2.62s\n",
      "89:\tlearn: 0.3020141\ttotal: 572ms\tremaining: 2.61s\n",
      "90:\tlearn: 0.2997433\ttotal: 577ms\tremaining: 2.59s\n",
      "91:\tlearn: 0.2980076\ttotal: 581ms\tremaining: 2.58s\n",
      "92:\tlearn: 0.2960585\ttotal: 585ms\tremaining: 2.56s\n",
      "93:\tlearn: 0.2940741\ttotal: 589ms\tremaining: 2.54s\n",
      "94:\tlearn: 0.2898104\ttotal: 594ms\tremaining: 2.53s\n",
      "95:\tlearn: 0.2879495\ttotal: 598ms\tremaining: 2.52s\n",
      "96:\tlearn: 0.2861143\ttotal: 602ms\tremaining: 2.5s\n",
      "97:\tlearn: 0.2843615\ttotal: 607ms\tremaining: 2.49s\n",
      "98:\tlearn: 0.2822218\ttotal: 611ms\tremaining: 2.47s\n",
      "99:\tlearn: 0.2807557\ttotal: 615ms\tremaining: 2.46s\n",
      "100:\tlearn: 0.2787941\ttotal: 620ms\tremaining: 2.45s\n",
      "101:\tlearn: 0.2765295\ttotal: 625ms\tremaining: 2.44s\n",
      "102:\tlearn: 0.2745783\ttotal: 635ms\tremaining: 2.45s\n",
      "103:\tlearn: 0.2726415\ttotal: 645ms\tremaining: 2.45s\n",
      "104:\tlearn: 0.2707714\ttotal: 655ms\tremaining: 2.46s\n",
      "105:\tlearn: 0.2691229\ttotal: 664ms\tremaining: 2.47s\n",
      "106:\tlearn: 0.2672943\ttotal: 675ms\tremaining: 2.48s\n",
      "107:\tlearn: 0.2657128\ttotal: 684ms\tremaining: 2.48s\n",
      "108:\tlearn: 0.2637548\ttotal: 694ms\tremaining: 2.49s\n",
      "109:\tlearn: 0.2616827\ttotal: 701ms\tremaining: 2.49s\n",
      "110:\tlearn: 0.2599764\ttotal: 707ms\tremaining: 2.48s\n",
      "111:\tlearn: 0.2568805\ttotal: 714ms\tremaining: 2.47s\n",
      "112:\tlearn: 0.2521721\ttotal: 720ms\tremaining: 2.47s\n",
      "113:\tlearn: 0.2501519\ttotal: 727ms\tremaining: 2.46s\n",
      "114:\tlearn: 0.2482374\ttotal: 733ms\tremaining: 2.45s\n",
      "115:\tlearn: 0.2454439\ttotal: 738ms\tremaining: 2.44s\n",
      "116:\tlearn: 0.2439246\ttotal: 742ms\tremaining: 2.43s\n",
      "117:\tlearn: 0.2422586\ttotal: 746ms\tremaining: 2.42s\n",
      "118:\tlearn: 0.2407260\ttotal: 751ms\tremaining: 2.4s\n",
      "119:\tlearn: 0.2395382\ttotal: 756ms\tremaining: 2.39s\n",
      "120:\tlearn: 0.2379998\ttotal: 760ms\tremaining: 2.38s\n",
      "121:\tlearn: 0.2362581\ttotal: 765ms\tremaining: 2.37s\n",
      "122:\tlearn: 0.2347301\ttotal: 769ms\tremaining: 2.36s\n",
      "123:\tlearn: 0.2332619\ttotal: 773ms\tremaining: 2.34s\n",
      "124:\tlearn: 0.2310085\ttotal: 778ms\tremaining: 2.33s\n",
      "125:\tlearn: 0.2290098\ttotal: 782ms\tremaining: 2.32s\n",
      "126:\tlearn: 0.2272653\ttotal: 792ms\tremaining: 2.33s\n",
      "127:\tlearn: 0.2258751\ttotal: 802ms\tremaining: 2.33s\n",
      "128:\tlearn: 0.2249252\ttotal: 812ms\tremaining: 2.33s\n",
      "129:\tlearn: 0.2236477\ttotal: 822ms\tremaining: 2.34s\n",
      "130:\tlearn: 0.2209260\ttotal: 832ms\tremaining: 2.34s\n",
      "131:\tlearn: 0.2197591\ttotal: 842ms\tremaining: 2.35s\n",
      "132:\tlearn: 0.2184481\ttotal: 852ms\tremaining: 2.35s\n",
      "133:\tlearn: 0.2172827\ttotal: 861ms\tremaining: 2.35s\n",
      "134:\tlearn: 0.2161233\ttotal: 871ms\tremaining: 2.36s\n",
      "135:\tlearn: 0.2148482\ttotal: 877ms\tremaining: 2.35s\n",
      "136:\tlearn: 0.2136937\ttotal: 882ms\tremaining: 2.34s\n",
      "137:\tlearn: 0.2122087\ttotal: 887ms\tremaining: 2.33s\n",
      "138:\tlearn: 0.2110980\ttotal: 893ms\tremaining: 2.32s\n",
      "139:\tlearn: 0.2094063\ttotal: 898ms\tremaining: 2.31s\n",
      "140:\tlearn: 0.2083438\ttotal: 903ms\tremaining: 2.3s\n",
      "141:\tlearn: 0.2069453\ttotal: 907ms\tremaining: 2.29s\n",
      "142:\tlearn: 0.2057225\ttotal: 912ms\tremaining: 2.27s\n",
      "143:\tlearn: 0.2041774\ttotal: 916ms\tremaining: 2.26s\n",
      "144:\tlearn: 0.2029915\ttotal: 921ms\tremaining: 2.25s\n",
      "145:\tlearn: 0.2016139\ttotal: 930ms\tremaining: 2.25s\n",
      "146:\tlearn: 0.2003576\ttotal: 940ms\tremaining: 2.26s\n",
      "147:\tlearn: 0.1988479\ttotal: 950ms\tremaining: 2.26s\n",
      "148:\tlearn: 0.1965819\ttotal: 960ms\tremaining: 2.26s\n",
      "149:\tlearn: 0.1952952\ttotal: 969ms\tremaining: 2.26s\n",
      "150:\tlearn: 0.1940043\ttotal: 979ms\tremaining: 2.26s\n",
      "151:\tlearn: 0.1929082\ttotal: 989ms\tremaining: 2.26s\n",
      "152:\tlearn: 0.1918393\ttotal: 998ms\tremaining: 2.26s\n",
      "153:\tlearn: 0.1904122\ttotal: 1.01s\tremaining: 2.26s\n",
      "154:\tlearn: 0.1889775\ttotal: 1.02s\tremaining: 2.26s\n",
      "155:\tlearn: 0.1879086\ttotal: 1.02s\tremaining: 2.26s\n",
      "156:\tlearn: 0.1867452\ttotal: 1.03s\tremaining: 2.25s\n",
      "157:\tlearn: 0.1854572\ttotal: 1.03s\tremaining: 2.24s\n",
      "158:\tlearn: 0.1842306\ttotal: 1.04s\tremaining: 2.23s\n",
      "159:\tlearn: 0.1832137\ttotal: 1.05s\tremaining: 2.23s\n",
      "160:\tlearn: 0.1822662\ttotal: 1.05s\tremaining: 2.22s\n",
      "161:\tlearn: 0.1814536\ttotal: 1.06s\tremaining: 2.21s\n",
      "162:\tlearn: 0.1801929\ttotal: 1.07s\tremaining: 2.2s\n",
      "163:\tlearn: 0.1783627\ttotal: 1.07s\tremaining: 2.2s\n",
      "164:\tlearn: 0.1773792\ttotal: 1.08s\tremaining: 2.19s\n",
      "165:\tlearn: 0.1763803\ttotal: 1.08s\tremaining: 2.18s\n",
      "166:\tlearn: 0.1744564\ttotal: 1.09s\tremaining: 2.17s\n",
      "167:\tlearn: 0.1734919\ttotal: 1.09s\tremaining: 2.16s\n",
      "168:\tlearn: 0.1728831\ttotal: 1.1s\tremaining: 2.15s\n",
      "169:\tlearn: 0.1720295\ttotal: 1.1s\tremaining: 2.14s\n",
      "170:\tlearn: 0.1711241\ttotal: 1.1s\tremaining: 2.13s\n",
      "171:\tlearn: 0.1700079\ttotal: 1.11s\tremaining: 2.12s\n",
      "172:\tlearn: 0.1691302\ttotal: 1.11s\tremaining: 2.1s\n",
      "173:\tlearn: 0.1682510\ttotal: 1.11s\tremaining: 2.09s\n",
      "174:\tlearn: 0.1673639\ttotal: 1.12s\tremaining: 2.08s\n",
      "175:\tlearn: 0.1664978\ttotal: 1.13s\tremaining: 2.07s\n",
      "176:\tlearn: 0.1656713\ttotal: 1.14s\tremaining: 2.07s\n",
      "177:\tlearn: 0.1644701\ttotal: 1.15s\tremaining: 2.07s\n",
      "178:\tlearn: 0.1635022\ttotal: 1.16s\tremaining: 2.07s\n",
      "179:\tlearn: 0.1628223\ttotal: 1.17s\tremaining: 2.07s\n",
      "180:\tlearn: 0.1619554\ttotal: 1.18s\tremaining: 2.07s\n",
      "181:\tlearn: 0.1610212\ttotal: 1.18s\tremaining: 2.07s\n",
      "182:\tlearn: 0.1599691\ttotal: 1.19s\tremaining: 2.07s\n",
      "183:\tlearn: 0.1588401\ttotal: 1.2s\tremaining: 2.07s\n",
      "184:\tlearn: 0.1581460\ttotal: 1.21s\tremaining: 2.06s\n",
      "185:\tlearn: 0.1566154\ttotal: 1.22s\tremaining: 2.06s\n",
      "186:\tlearn: 0.1558571\ttotal: 1.22s\tremaining: 2.05s\n",
      "187:\tlearn: 0.1550345\ttotal: 1.23s\tremaining: 2.04s\n",
      "188:\tlearn: 0.1534786\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.1527112\ttotal: 1.24s\tremaining: 2.03s\n",
      "190:\tlearn: 0.1519353\ttotal: 1.25s\tremaining: 2.02s\n",
      "191:\tlearn: 0.1511350\ttotal: 1.25s\tremaining: 2.01s\n",
      "192:\tlearn: 0.1500767\ttotal: 1.26s\tremaining: 2s\n",
      "193:\tlearn: 0.1490632\ttotal: 1.26s\tremaining: 1.99s\n",
      "194:\tlearn: 0.1480981\ttotal: 1.26s\tremaining: 1.98s\n",
      "195:\tlearn: 0.1473129\ttotal: 1.27s\tremaining: 1.97s\n",
      "196:\tlearn: 0.1465290\ttotal: 1.27s\tremaining: 1.96s\n",
      "197:\tlearn: 0.1456734\ttotal: 1.28s\tremaining: 1.95s\n",
      "198:\tlearn: 0.1450391\ttotal: 1.28s\tremaining: 1.94s\n",
      "199:\tlearn: 0.1442804\ttotal: 1.29s\tremaining: 1.93s\n",
      "200:\tlearn: 0.1435869\ttotal: 1.29s\tremaining: 1.92s\n",
      "201:\tlearn: 0.1427720\ttotal: 1.3s\tremaining: 1.92s\n",
      "202:\tlearn: 0.1421154\ttotal: 1.31s\tremaining: 1.92s\n",
      "203:\tlearn: 0.1413628\ttotal: 1.32s\tremaining: 1.92s\n",
      "204:\tlearn: 0.1395961\ttotal: 1.33s\tremaining: 1.92s\n",
      "205:\tlearn: 0.1389020\ttotal: 1.34s\tremaining: 1.91s\n",
      "206:\tlearn: 0.1381076\ttotal: 1.35s\tremaining: 1.91s\n",
      "207:\tlearn: 0.1373210\ttotal: 1.36s\tremaining: 1.91s\n",
      "208:\tlearn: 0.1365185\ttotal: 1.37s\tremaining: 1.91s\n",
      "209:\tlearn: 0.1357833\ttotal: 1.38s\tremaining: 1.91s\n",
      "210:\tlearn: 0.1350371\ttotal: 1.39s\tremaining: 1.9s\n",
      "211:\tlearn: 0.1343645\ttotal: 1.4s\tremaining: 1.9s\n",
      "212:\tlearn: 0.1335867\ttotal: 1.4s\tremaining: 1.89s\n",
      "213:\tlearn: 0.1329951\ttotal: 1.41s\tremaining: 1.88s\n",
      "214:\tlearn: 0.1321760\ttotal: 1.41s\tremaining: 1.87s\n",
      "215:\tlearn: 0.1314627\ttotal: 1.42s\tremaining: 1.86s\n",
      "216:\tlearn: 0.1310224\ttotal: 1.42s\tremaining: 1.86s\n",
      "217:\tlearn: 0.1300321\ttotal: 1.43s\tremaining: 1.85s\n",
      "218:\tlearn: 0.1289657\ttotal: 1.43s\tremaining: 1.84s\n",
      "219:\tlearn: 0.1281932\ttotal: 1.44s\tremaining: 1.83s\n",
      "220:\tlearn: 0.1270992\ttotal: 1.44s\tremaining: 1.82s\n",
      "221:\tlearn: 0.1264183\ttotal: 1.45s\tremaining: 1.81s\n",
      "222:\tlearn: 0.1258622\ttotal: 1.45s\tremaining: 1.8s\n",
      "223:\tlearn: 0.1251984\ttotal: 1.46s\tremaining: 1.79s\n",
      "224:\tlearn: 0.1245047\ttotal: 1.46s\tremaining: 1.78s\n",
      "225:\tlearn: 0.1239821\ttotal: 1.46s\tremaining: 1.77s\n",
      "226:\tlearn: 0.1231125\ttotal: 1.48s\tremaining: 1.78s\n",
      "227:\tlearn: 0.1224442\ttotal: 1.49s\tremaining: 1.77s\n",
      "228:\tlearn: 0.1217210\ttotal: 1.5s\tremaining: 1.77s\n",
      "229:\tlearn: 0.1208440\ttotal: 1.51s\tremaining: 1.77s\n",
      "230:\tlearn: 0.1202563\ttotal: 1.52s\tremaining: 1.76s\n",
      "231:\tlearn: 0.1195944\ttotal: 1.53s\tremaining: 1.76s\n",
      "232:\tlearn: 0.1189564\ttotal: 1.53s\tremaining: 1.76s\n",
      "233:\tlearn: 0.1182193\ttotal: 1.54s\tremaining: 1.76s\n",
      "234:\tlearn: 0.1176206\ttotal: 1.55s\tremaining: 1.75s\n",
      "235:\tlearn: 0.1169959\ttotal: 1.56s\tremaining: 1.75s\n",
      "236:\tlearn: 0.1165722\ttotal: 1.57s\tremaining: 1.74s\n",
      "237:\tlearn: 0.1159546\ttotal: 1.57s\tremaining: 1.73s\n",
      "238:\tlearn: 0.1152028\ttotal: 1.58s\tremaining: 1.72s\n",
      "239:\tlearn: 0.1144797\ttotal: 1.58s\tremaining: 1.72s\n",
      "240:\tlearn: 0.1139273\ttotal: 1.59s\tremaining: 1.71s\n",
      "241:\tlearn: 0.1133087\ttotal: 1.6s\tremaining: 1.7s\n",
      "242:\tlearn: 0.1126060\ttotal: 1.6s\tremaining: 1.7s\n",
      "243:\tlearn: 0.1118330\ttotal: 1.61s\tremaining: 1.69s\n",
      "244:\tlearn: 0.1113753\ttotal: 1.62s\tremaining: 1.68s\n",
      "245:\tlearn: 0.1108030\ttotal: 1.62s\tremaining: 1.68s\n",
      "246:\tlearn: 0.1102449\ttotal: 1.63s\tremaining: 1.67s\n",
      "247:\tlearn: 0.1095319\ttotal: 1.64s\tremaining: 1.66s\n",
      "248:\tlearn: 0.1089643\ttotal: 1.64s\tremaining: 1.65s\n",
      "249:\tlearn: 0.1083227\ttotal: 1.64s\tremaining: 1.64s\n",
      "250:\tlearn: 0.1071615\ttotal: 1.65s\tremaining: 1.64s\n",
      "251:\tlearn: 0.1066188\ttotal: 1.65s\tremaining: 1.63s\n",
      "252:\tlearn: 0.1060544\ttotal: 1.66s\tremaining: 1.62s\n",
      "253:\tlearn: 0.1055663\ttotal: 1.66s\tremaining: 1.61s\n",
      "254:\tlearn: 0.1050734\ttotal: 1.67s\tremaining: 1.6s\n",
      "255:\tlearn: 0.1045387\ttotal: 1.67s\tremaining: 1.59s\n",
      "256:\tlearn: 0.1038734\ttotal: 1.68s\tremaining: 1.58s\n",
      "257:\tlearn: 0.1033539\ttotal: 1.68s\tremaining: 1.58s\n",
      "258:\tlearn: 0.1028043\ttotal: 1.69s\tremaining: 1.57s\n",
      "259:\tlearn: 0.1023086\ttotal: 1.69s\tremaining: 1.56s\n",
      "260:\tlearn: 0.1017177\ttotal: 1.69s\tremaining: 1.55s\n",
      "261:\tlearn: 0.1012853\ttotal: 1.7s\tremaining: 1.54s\n",
      "262:\tlearn: 0.1002738\ttotal: 1.71s\tremaining: 1.54s\n",
      "263:\tlearn: 0.0997613\ttotal: 1.72s\tremaining: 1.53s\n",
      "264:\tlearn: 0.0993796\ttotal: 1.73s\tremaining: 1.53s\n",
      "265:\tlearn: 0.0987831\ttotal: 1.74s\tremaining: 1.53s\n",
      "266:\tlearn: 0.0982177\ttotal: 1.75s\tremaining: 1.53s\n",
      "267:\tlearn: 0.0976451\ttotal: 1.76s\tremaining: 1.52s\n",
      "268:\tlearn: 0.0969385\ttotal: 1.77s\tremaining: 1.52s\n",
      "269:\tlearn: 0.0964487\ttotal: 1.78s\tremaining: 1.51s\n",
      "270:\tlearn: 0.0955639\ttotal: 1.78s\tremaining: 1.51s\n",
      "271:\tlearn: 0.0950787\ttotal: 1.79s\tremaining: 1.5s\n",
      "272:\tlearn: 0.0941117\ttotal: 1.79s\tremaining: 1.49s\n",
      "273:\tlearn: 0.0936845\ttotal: 1.8s\tremaining: 1.49s\n",
      "274:\tlearn: 0.0932167\ttotal: 1.81s\tremaining: 1.48s\n",
      "275:\tlearn: 0.0927467\ttotal: 1.81s\tremaining: 1.47s\n",
      "276:\tlearn: 0.0923463\ttotal: 1.82s\tremaining: 1.46s\n",
      "277:\tlearn: 0.0919604\ttotal: 1.82s\tremaining: 1.46s\n",
      "278:\tlearn: 0.0916057\ttotal: 1.83s\tremaining: 1.45s\n",
      "279:\tlearn: 0.0910104\ttotal: 1.83s\tremaining: 1.44s\n",
      "280:\tlearn: 0.0905619\ttotal: 1.84s\tremaining: 1.43s\n",
      "281:\tlearn: 0.0900167\ttotal: 1.84s\tremaining: 1.42s\n",
      "282:\tlearn: 0.0896000\ttotal: 1.84s\tremaining: 1.42s\n",
      "283:\tlearn: 0.0891675\ttotal: 1.85s\tremaining: 1.41s\n",
      "284:\tlearn: 0.0887062\ttotal: 1.85s\tremaining: 1.4s\n",
      "285:\tlearn: 0.0883571\ttotal: 1.86s\tremaining: 1.39s\n",
      "286:\tlearn: 0.0879800\ttotal: 1.86s\tremaining: 1.38s\n",
      "287:\tlearn: 0.0876384\ttotal: 1.87s\tremaining: 1.38s\n",
      "288:\tlearn: 0.0870982\ttotal: 1.88s\tremaining: 1.37s\n",
      "289:\tlearn: 0.0866727\ttotal: 1.89s\tremaining: 1.37s\n",
      "290:\tlearn: 0.0863485\ttotal: 1.9s\tremaining: 1.37s\n",
      "291:\tlearn: 0.0859422\ttotal: 1.91s\tremaining: 1.36s\n",
      "292:\tlearn: 0.0854940\ttotal: 1.92s\tremaining: 1.36s\n",
      "293:\tlearn: 0.0851104\ttotal: 1.93s\tremaining: 1.35s\n",
      "294:\tlearn: 0.0847574\ttotal: 1.94s\tremaining: 1.35s\n",
      "295:\tlearn: 0.0842906\ttotal: 1.95s\tremaining: 1.34s\n",
      "296:\tlearn: 0.0837834\ttotal: 1.96s\tremaining: 1.34s\n",
      "297:\tlearn: 0.0835490\ttotal: 1.96s\tremaining: 1.33s\n",
      "298:\tlearn: 0.0830510\ttotal: 1.97s\tremaining: 1.32s\n",
      "299:\tlearn: 0.0825092\ttotal: 1.97s\tremaining: 1.32s\n",
      "300:\tlearn: 0.0820431\ttotal: 1.98s\tremaining: 1.31s\n",
      "301:\tlearn: 0.0816494\ttotal: 1.99s\tremaining: 1.3s\n",
      "302:\tlearn: 0.0812047\ttotal: 1.99s\tremaining: 1.3s\n",
      "303:\tlearn: 0.0809464\ttotal: 2s\tremaining: 1.29s\n",
      "304:\tlearn: 0.0806090\ttotal: 2s\tremaining: 1.28s\n",
      "305:\tlearn: 0.0802448\ttotal: 2.01s\tremaining: 1.27s\n",
      "306:\tlearn: 0.0796286\ttotal: 2.01s\tremaining: 1.26s\n",
      "307:\tlearn: 0.0790955\ttotal: 2.02s\tremaining: 1.26s\n",
      "308:\tlearn: 0.0786974\ttotal: 2.02s\tremaining: 1.25s\n",
      "309:\tlearn: 0.0782960\ttotal: 2.03s\tremaining: 1.24s\n",
      "310:\tlearn: 0.0779150\ttotal: 2.03s\tremaining: 1.23s\n",
      "311:\tlearn: 0.0774750\ttotal: 2.04s\tremaining: 1.23s\n",
      "312:\tlearn: 0.0771364\ttotal: 2.04s\tremaining: 1.22s\n",
      "313:\tlearn: 0.0767809\ttotal: 2.05s\tremaining: 1.22s\n",
      "314:\tlearn: 0.0764265\ttotal: 2.06s\tremaining: 1.21s\n",
      "315:\tlearn: 0.0760437\ttotal: 2.07s\tremaining: 1.21s\n",
      "316:\tlearn: 0.0755734\ttotal: 2.08s\tremaining: 1.2s\n",
      "317:\tlearn: 0.0752216\ttotal: 2.09s\tremaining: 1.2s\n",
      "318:\tlearn: 0.0749599\ttotal: 2.1s\tremaining: 1.19s\n",
      "319:\tlearn: 0.0745775\ttotal: 2.11s\tremaining: 1.19s\n",
      "320:\tlearn: 0.0741853\ttotal: 2.12s\tremaining: 1.18s\n",
      "321:\tlearn: 0.0739687\ttotal: 2.13s\tremaining: 1.18s\n",
      "322:\tlearn: 0.0735240\ttotal: 2.13s\tremaining: 1.17s\n",
      "323:\tlearn: 0.0730237\ttotal: 2.14s\tremaining: 1.16s\n",
      "324:\tlearn: 0.0726205\ttotal: 2.14s\tremaining: 1.15s\n",
      "325:\tlearn: 0.0722161\ttotal: 2.15s\tremaining: 1.15s\n",
      "326:\tlearn: 0.0719141\ttotal: 2.15s\tremaining: 1.14s\n",
      "327:\tlearn: 0.0717117\ttotal: 2.16s\tremaining: 1.13s\n",
      "328:\tlearn: 0.0714184\ttotal: 2.16s\tremaining: 1.12s\n",
      "329:\tlearn: 0.0710563\ttotal: 2.17s\tremaining: 1.12s\n",
      "330:\tlearn: 0.0706891\ttotal: 2.17s\tremaining: 1.11s\n",
      "331:\tlearn: 0.0703137\ttotal: 2.17s\tremaining: 1.1s\n",
      "332:\tlearn: 0.0700153\ttotal: 2.18s\tremaining: 1.09s\n",
      "333:\tlearn: 0.0696875\ttotal: 2.18s\tremaining: 1.08s\n",
      "334:\tlearn: 0.0693166\ttotal: 2.19s\tremaining: 1.08s\n",
      "335:\tlearn: 0.0690429\ttotal: 2.19s\tremaining: 1.07s\n",
      "336:\tlearn: 0.0686742\ttotal: 2.2s\tremaining: 1.06s\n",
      "337:\tlearn: 0.0683842\ttotal: 2.2s\tremaining: 1.05s\n",
      "338:\tlearn: 0.0680521\ttotal: 2.21s\tremaining: 1.05s\n",
      "339:\tlearn: 0.0677219\ttotal: 2.22s\tremaining: 1.04s\n",
      "340:\tlearn: 0.0673983\ttotal: 2.23s\tremaining: 1.04s\n",
      "341:\tlearn: 0.0670810\ttotal: 2.24s\tremaining: 1.03s\n",
      "342:\tlearn: 0.0667659\ttotal: 2.25s\tremaining: 1.03s\n",
      "343:\tlearn: 0.0664542\ttotal: 2.26s\tremaining: 1.02s\n",
      "344:\tlearn: 0.0661832\ttotal: 2.27s\tremaining: 1.02s\n",
      "345:\tlearn: 0.0656722\ttotal: 2.28s\tremaining: 1.01s\n",
      "346:\tlearn: 0.0652864\ttotal: 2.29s\tremaining: 1.01s\n",
      "347:\tlearn: 0.0650094\ttotal: 2.3s\tremaining: 1s\n",
      "348:\tlearn: 0.0646866\ttotal: 2.3s\tremaining: 997ms\n",
      "349:\tlearn: 0.0643386\ttotal: 2.31s\tremaining: 990ms\n",
      "350:\tlearn: 0.0639815\ttotal: 2.32s\tremaining: 983ms\n",
      "351:\tlearn: 0.0636996\ttotal: 2.32s\tremaining: 977ms\n",
      "352:\tlearn: 0.0634083\ttotal: 2.33s\tremaining: 970ms\n",
      "353:\tlearn: 0.0631583\ttotal: 2.33s\tremaining: 962ms\n",
      "354:\tlearn: 0.0628610\ttotal: 2.34s\tremaining: 955ms\n",
      "355:\tlearn: 0.0625516\ttotal: 2.34s\tremaining: 947ms\n",
      "356:\tlearn: 0.0623445\ttotal: 2.35s\tremaining: 941ms\n",
      "357:\tlearn: 0.0621457\ttotal: 2.35s\tremaining: 933ms\n",
      "358:\tlearn: 0.0618804\ttotal: 2.35s\tremaining: 925ms\n",
      "359:\tlearn: 0.0618507\ttotal: 2.36s\tremaining: 917ms\n",
      "360:\tlearn: 0.0615397\ttotal: 2.36s\tremaining: 909ms\n",
      "361:\tlearn: 0.0612234\ttotal: 2.36s\tremaining: 902ms\n",
      "362:\tlearn: 0.0609609\ttotal: 2.37s\tremaining: 894ms\n",
      "363:\tlearn: 0.0605243\ttotal: 2.37s\tremaining: 887ms\n",
      "364:\tlearn: 0.0602984\ttotal: 2.38s\tremaining: 881ms\n",
      "365:\tlearn: 0.0600366\ttotal: 2.39s\tremaining: 876ms\n",
      "366:\tlearn: 0.0597640\ttotal: 2.4s\tremaining: 871ms\n",
      "367:\tlearn: 0.0596051\ttotal: 2.41s\tremaining: 865ms\n",
      "368:\tlearn: 0.0593596\ttotal: 2.42s\tremaining: 860ms\n",
      "369:\tlearn: 0.0590774\ttotal: 2.43s\tremaining: 855ms\n",
      "370:\tlearn: 0.0588207\ttotal: 2.44s\tremaining: 849ms\n",
      "371:\tlearn: 0.0582948\ttotal: 2.45s\tremaining: 844ms\n",
      "372:\tlearn: 0.0580417\ttotal: 2.46s\tremaining: 838ms\n",
      "373:\tlearn: 0.0577835\ttotal: 2.47s\tremaining: 832ms\n",
      "374:\tlearn: 0.0574685\ttotal: 2.48s\tremaining: 825ms\n",
      "375:\tlearn: 0.0572108\ttotal: 2.48s\tremaining: 818ms\n",
      "376:\tlearn: 0.0569079\ttotal: 2.49s\tremaining: 812ms\n",
      "377:\tlearn: 0.0565734\ttotal: 2.49s\tremaining: 805ms\n",
      "378:\tlearn: 0.0563022\ttotal: 2.5s\tremaining: 798ms\n",
      "379:\tlearn: 0.0559855\ttotal: 2.5s\tremaining: 791ms\n",
      "380:\tlearn: 0.0556458\ttotal: 2.51s\tremaining: 783ms\n",
      "381:\tlearn: 0.0553952\ttotal: 2.51s\tremaining: 776ms\n",
      "382:\tlearn: 0.0551695\ttotal: 2.52s\tremaining: 769ms\n",
      "383:\tlearn: 0.0549461\ttotal: 2.52s\tremaining: 762ms\n",
      "384:\tlearn: 0.0547921\ttotal: 2.53s\tremaining: 755ms\n",
      "385:\tlearn: 0.0545744\ttotal: 2.53s\tremaining: 748ms\n",
      "386:\tlearn: 0.0541800\ttotal: 2.53s\tremaining: 740ms\n",
      "387:\tlearn: 0.0539612\ttotal: 2.54s\tremaining: 733ms\n",
      "388:\tlearn: 0.0537284\ttotal: 2.54s\tremaining: 726ms\n",
      "389:\tlearn: 0.0534407\ttotal: 2.55s\tremaining: 720ms\n",
      "390:\tlearn: 0.0531120\ttotal: 2.56s\tremaining: 715ms\n",
      "391:\tlearn: 0.0527764\ttotal: 2.57s\tremaining: 709ms\n",
      "392:\tlearn: 0.0525171\ttotal: 2.58s\tremaining: 703ms\n",
      "393:\tlearn: 0.0523114\ttotal: 2.59s\tremaining: 698ms\n",
      "394:\tlearn: 0.0520326\ttotal: 2.6s\tremaining: 692ms\n",
      "395:\tlearn: 0.0518451\ttotal: 2.61s\tremaining: 686ms\n",
      "396:\tlearn: 0.0516328\ttotal: 2.62s\tremaining: 681ms\n",
      "397:\tlearn: 0.0514355\ttotal: 2.63s\tremaining: 674ms\n",
      "398:\tlearn: 0.0511760\ttotal: 2.64s\tremaining: 668ms\n",
      "399:\tlearn: 0.0510054\ttotal: 2.64s\tremaining: 661ms\n",
      "400:\tlearn: 0.0507415\ttotal: 2.65s\tremaining: 654ms\n",
      "401:\tlearn: 0.0505435\ttotal: 2.66s\tremaining: 648ms\n",
      "402:\tlearn: 0.0503133\ttotal: 2.66s\tremaining: 641ms\n",
      "403:\tlearn: 0.0501007\ttotal: 2.67s\tremaining: 634ms\n",
      "404:\tlearn: 0.0497272\ttotal: 2.67s\tremaining: 627ms\n",
      "405:\tlearn: 0.0494978\ttotal: 2.68s\tremaining: 620ms\n",
      "406:\tlearn: 0.0489808\ttotal: 2.68s\tremaining: 613ms\n",
      "407:\tlearn: 0.0487165\ttotal: 2.69s\tremaining: 606ms\n",
      "408:\tlearn: 0.0484055\ttotal: 2.69s\tremaining: 598ms\n",
      "409:\tlearn: 0.0481489\ttotal: 2.69s\tremaining: 591ms\n",
      "410:\tlearn: 0.0478648\ttotal: 2.7s\tremaining: 584ms\n",
      "411:\tlearn: 0.0476555\ttotal: 2.7s\tremaining: 577ms\n",
      "412:\tlearn: 0.0474085\ttotal: 2.71s\tremaining: 570ms\n",
      "413:\tlearn: 0.0471814\ttotal: 2.71s\tremaining: 563ms\n",
      "414:\tlearn: 0.0470012\ttotal: 2.71s\tremaining: 556ms\n",
      "415:\tlearn: 0.0467994\ttotal: 2.72s\tremaining: 549ms\n",
      "416:\tlearn: 0.0467812\ttotal: 2.73s\tremaining: 543ms\n",
      "417:\tlearn: 0.0465806\ttotal: 2.74s\tremaining: 537ms\n",
      "418:\tlearn: 0.0463373\ttotal: 2.75s\tremaining: 531ms\n",
      "419:\tlearn: 0.0461599\ttotal: 2.76s\tremaining: 525ms\n",
      "420:\tlearn: 0.0459916\ttotal: 2.77s\tremaining: 519ms\n",
      "421:\tlearn: 0.0457800\ttotal: 2.78s\tremaining: 513ms\n",
      "422:\tlearn: 0.0455621\ttotal: 2.79s\tremaining: 507ms\n",
      "423:\tlearn: 0.0453319\ttotal: 2.8s\tremaining: 501ms\n",
      "424:\tlearn: 0.0450842\ttotal: 2.81s\tremaining: 495ms\n",
      "425:\tlearn: 0.0449376\ttotal: 2.81s\tremaining: 488ms\n",
      "426:\tlearn: 0.0447525\ttotal: 2.82s\tremaining: 482ms\n",
      "427:\tlearn: 0.0445830\ttotal: 2.82s\tremaining: 475ms\n",
      "428:\tlearn: 0.0442806\ttotal: 2.83s\tremaining: 468ms\n",
      "429:\tlearn: 0.0441239\ttotal: 2.83s\tremaining: 462ms\n",
      "430:\tlearn: 0.0439486\ttotal: 2.84s\tremaining: 455ms\n",
      "431:\tlearn: 0.0437494\ttotal: 2.85s\tremaining: 448ms\n",
      "432:\tlearn: 0.0435321\ttotal: 2.85s\tremaining: 441ms\n",
      "433:\tlearn: 0.0433162\ttotal: 2.85s\tremaining: 434ms\n",
      "434:\tlearn: 0.0431748\ttotal: 2.86s\tremaining: 428ms\n",
      "435:\tlearn: 0.0429290\ttotal: 2.87s\tremaining: 422ms\n",
      "436:\tlearn: 0.0428147\ttotal: 2.88s\tremaining: 416ms\n",
      "437:\tlearn: 0.0426094\ttotal: 2.89s\tremaining: 410ms\n",
      "438:\tlearn: 0.0424463\ttotal: 2.9s\tremaining: 404ms\n",
      "439:\tlearn: 0.0422143\ttotal: 2.91s\tremaining: 397ms\n",
      "440:\tlearn: 0.0419809\ttotal: 2.92s\tremaining: 390ms\n",
      "441:\tlearn: 0.0417809\ttotal: 2.92s\tremaining: 384ms\n",
      "442:\tlearn: 0.0416288\ttotal: 2.93s\tremaining: 377ms\n",
      "443:\tlearn: 0.0414735\ttotal: 2.94s\tremaining: 370ms\n",
      "444:\tlearn: 0.0412705\ttotal: 2.94s\tremaining: 363ms\n",
      "445:\tlearn: 0.0410930\ttotal: 2.94s\tremaining: 356ms\n",
      "446:\tlearn: 0.0409201\ttotal: 2.95s\tremaining: 350ms\n",
      "447:\tlearn: 0.0407274\ttotal: 2.95s\tremaining: 343ms\n",
      "448:\tlearn: 0.0405551\ttotal: 2.96s\tremaining: 336ms\n",
      "449:\tlearn: 0.0403552\ttotal: 2.96s\tremaining: 329ms\n",
      "450:\tlearn: 0.0401948\ttotal: 2.96s\tremaining: 322ms\n",
      "451:\tlearn: 0.0399874\ttotal: 2.97s\tremaining: 315ms\n",
      "452:\tlearn: 0.0398174\ttotal: 2.97s\tremaining: 309ms\n",
      "453:\tlearn: 0.0395024\ttotal: 2.98s\tremaining: 302ms\n",
      "454:\tlearn: 0.0393530\ttotal: 2.98s\tremaining: 295ms\n",
      "455:\tlearn: 0.0391885\ttotal: 2.99s\tremaining: 288ms\n",
      "456:\tlearn: 0.0390105\ttotal: 3s\tremaining: 282ms\n",
      "457:\tlearn: 0.0389151\ttotal: 3.01s\tremaining: 276ms\n",
      "458:\tlearn: 0.0387788\ttotal: 3.02s\tremaining: 269ms\n",
      "459:\tlearn: 0.0385837\ttotal: 3.02s\tremaining: 263ms\n",
      "460:\tlearn: 0.0384457\ttotal: 3.04s\tremaining: 257ms\n",
      "461:\tlearn: 0.0382901\ttotal: 3.04s\tremaining: 250ms\n",
      "462:\tlearn: 0.0381641\ttotal: 3.05s\tremaining: 244ms\n",
      "463:\tlearn: 0.0379588\ttotal: 3.06s\tremaining: 238ms\n",
      "464:\tlearn: 0.0377466\ttotal: 3.07s\tremaining: 231ms\n",
      "465:\tlearn: 0.0375953\ttotal: 3.08s\tremaining: 224ms\n",
      "466:\tlearn: 0.0373945\ttotal: 3.08s\tremaining: 218ms\n",
      "467:\tlearn: 0.0372118\ttotal: 3.08s\tremaining: 211ms\n",
      "468:\tlearn: 0.0370466\ttotal: 3.09s\tremaining: 204ms\n",
      "469:\tlearn: 0.0368967\ttotal: 3.09s\tremaining: 197ms\n",
      "470:\tlearn: 0.0367262\ttotal: 3.1s\tremaining: 191ms\n",
      "471:\tlearn: 0.0365615\ttotal: 3.1s\tremaining: 184ms\n",
      "472:\tlearn: 0.0364421\ttotal: 3.11s\tremaining: 177ms\n",
      "473:\tlearn: 0.0363404\ttotal: 3.11s\tremaining: 171ms\n",
      "474:\tlearn: 0.0361731\ttotal: 3.12s\tremaining: 164ms\n",
      "475:\tlearn: 0.0360428\ttotal: 3.12s\tremaining: 157ms\n",
      "476:\tlearn: 0.0358630\ttotal: 3.13s\tremaining: 151ms\n",
      "477:\tlearn: 0.0356820\ttotal: 3.13s\tremaining: 144ms\n",
      "478:\tlearn: 0.0355120\ttotal: 3.13s\tremaining: 137ms\n",
      "479:\tlearn: 0.0353543\ttotal: 3.15s\tremaining: 131ms\n",
      "480:\tlearn: 0.0351605\ttotal: 3.15s\tremaining: 125ms\n",
      "481:\tlearn: 0.0350296\ttotal: 3.17s\tremaining: 118ms\n",
      "482:\tlearn: 0.0349038\ttotal: 3.17s\tremaining: 112ms\n",
      "483:\tlearn: 0.0347693\ttotal: 3.19s\tremaining: 105ms\n",
      "484:\tlearn: 0.0346160\ttotal: 3.2s\tremaining: 98.9ms\n",
      "485:\tlearn: 0.0344591\ttotal: 3.21s\tremaining: 92.4ms\n",
      "486:\tlearn: 0.0343199\ttotal: 3.21s\tremaining: 85.8ms\n",
      "487:\tlearn: 0.0341902\ttotal: 3.22s\tremaining: 79.2ms\n",
      "488:\tlearn: 0.0340070\ttotal: 3.23s\tremaining: 72.6ms\n",
      "489:\tlearn: 0.0338468\ttotal: 3.24s\tremaining: 66.1ms\n",
      "490:\tlearn: 0.0336892\ttotal: 3.24s\tremaining: 59.4ms\n",
      "491:\tlearn: 0.0336396\ttotal: 3.25s\tremaining: 52.8ms\n",
      "492:\tlearn: 0.0334827\ttotal: 3.25s\tremaining: 46.2ms\n",
      "493:\tlearn: 0.0333527\ttotal: 3.25s\tremaining: 39.5ms\n",
      "494:\tlearn: 0.0331912\ttotal: 3.26s\tremaining: 32.9ms\n",
      "495:\tlearn: 0.0330044\ttotal: 3.26s\tremaining: 26.3ms\n",
      "496:\tlearn: 0.0328680\ttotal: 3.27s\tremaining: 19.7ms\n",
      "497:\tlearn: 0.0326941\ttotal: 3.27s\tremaining: 13.1ms\n",
      "498:\tlearn: 0.0326184\ttotal: 3.28s\tremaining: 6.57ms\n",
      "499:\tlearn: 0.0324563\ttotal: 3.28s\tremaining: 0us\n",
      "0:\tlearn: 0.6820659\ttotal: 4.41ms\tremaining: 2.2s\n",
      "1:\tlearn: 0.6691376\ttotal: 8.91ms\tremaining: 2.22s\n",
      "2:\tlearn: 0.6604783\ttotal: 13.4ms\tremaining: 2.21s\n",
      "3:\tlearn: 0.6499415\ttotal: 17.6ms\tremaining: 2.19s\n",
      "4:\tlearn: 0.6393861\ttotal: 21.7ms\tremaining: 2.15s\n",
      "5:\tlearn: 0.6263959\ttotal: 25.7ms\tremaining: 2.11s\n",
      "6:\tlearn: 0.6154947\ttotal: 30.3ms\tremaining: 2.14s\n",
      "7:\tlearn: 0.6053062\ttotal: 40.2ms\tremaining: 2.48s\n",
      "8:\tlearn: 0.5986184\ttotal: 49.7ms\tremaining: 2.71s\n",
      "9:\tlearn: 0.5927688\ttotal: 59.5ms\tremaining: 2.92s\n",
      "10:\tlearn: 0.5850873\ttotal: 69.3ms\tremaining: 3.08s\n",
      "11:\tlearn: 0.5793359\ttotal: 78.8ms\tremaining: 3.2s\n",
      "12:\tlearn: 0.5718078\ttotal: 88.1ms\tremaining: 3.3s\n",
      "13:\tlearn: 0.5669145\ttotal: 98.2ms\tremaining: 3.41s\n",
      "14:\tlearn: 0.5616825\ttotal: 108ms\tremaining: 3.49s\n",
      "15:\tlearn: 0.5573033\ttotal: 117ms\tremaining: 3.54s\n",
      "16:\tlearn: 0.5509595\ttotal: 125ms\tremaining: 3.56s\n",
      "17:\tlearn: 0.5442200\ttotal: 132ms\tremaining: 3.52s\n",
      "18:\tlearn: 0.5345831\ttotal: 138ms\tremaining: 3.49s\n",
      "19:\tlearn: 0.5296839\ttotal: 144ms\tremaining: 3.46s\n",
      "20:\tlearn: 0.5247689\ttotal: 151ms\tremaining: 3.44s\n",
      "21:\tlearn: 0.5199046\ttotal: 156ms\tremaining: 3.39s\n",
      "22:\tlearn: 0.5150427\ttotal: 160ms\tremaining: 3.33s\n",
      "23:\tlearn: 0.5112454\ttotal: 165ms\tremaining: 3.27s\n",
      "24:\tlearn: 0.5050690\ttotal: 170ms\tremaining: 3.22s\n",
      "25:\tlearn: 0.5021531\ttotal: 174ms\tremaining: 3.17s\n",
      "26:\tlearn: 0.4983207\ttotal: 178ms\tremaining: 3.13s\n",
      "27:\tlearn: 0.4938622\ttotal: 183ms\tremaining: 3.09s\n",
      "28:\tlearn: 0.4902402\ttotal: 188ms\tremaining: 3.05s\n",
      "29:\tlearn: 0.4847157\ttotal: 192ms\tremaining: 3.01s\n",
      "30:\tlearn: 0.4799323\ttotal: 196ms\tremaining: 2.97s\n",
      "31:\tlearn: 0.4764798\ttotal: 201ms\tremaining: 2.93s\n",
      "32:\tlearn: 0.4723322\ttotal: 205ms\tremaining: 2.9s\n",
      "33:\tlearn: 0.4653688\ttotal: 215ms\tremaining: 2.95s\n",
      "34:\tlearn: 0.4619387\ttotal: 225ms\tremaining: 2.98s\n",
      "35:\tlearn: 0.4577346\ttotal: 234ms\tremaining: 3.02s\n",
      "36:\tlearn: 0.4527142\ttotal: 244ms\tremaining: 3.05s\n",
      "37:\tlearn: 0.4479300\ttotal: 253ms\tremaining: 3.08s\n",
      "38:\tlearn: 0.4429975\ttotal: 263ms\tremaining: 3.11s\n",
      "39:\tlearn: 0.4403059\ttotal: 273ms\tremaining: 3.14s\n",
      "40:\tlearn: 0.4368863\ttotal: 283ms\tremaining: 3.17s\n",
      "41:\tlearn: 0.4327894\ttotal: 293ms\tremaining: 3.19s\n",
      "42:\tlearn: 0.4298787\ttotal: 301ms\tremaining: 3.2s\n",
      "43:\tlearn: 0.4276230\ttotal: 307ms\tremaining: 3.18s\n",
      "44:\tlearn: 0.4250674\ttotal: 313ms\tremaining: 3.16s\n",
      "45:\tlearn: 0.4224699\ttotal: 319ms\tremaining: 3.15s\n",
      "46:\tlearn: 0.4194669\ttotal: 325ms\tremaining: 3.13s\n",
      "47:\tlearn: 0.4169279\ttotal: 330ms\tremaining: 3.1s\n",
      "48:\tlearn: 0.4129869\ttotal: 334ms\tremaining: 3.08s\n",
      "49:\tlearn: 0.4095298\ttotal: 338ms\tremaining: 3.05s\n",
      "50:\tlearn: 0.4063744\ttotal: 343ms\tremaining: 3.02s\n",
      "51:\tlearn: 0.4038222\ttotal: 348ms\tremaining: 2.99s\n",
      "52:\tlearn: 0.4008168\ttotal: 352ms\tremaining: 2.97s\n",
      "53:\tlearn: 0.3979648\ttotal: 356ms\tremaining: 2.94s\n",
      "54:\tlearn: 0.3957147\ttotal: 360ms\tremaining: 2.91s\n",
      "55:\tlearn: 0.3916662\ttotal: 364ms\tremaining: 2.89s\n",
      "56:\tlearn: 0.3846143\ttotal: 368ms\tremaining: 2.86s\n",
      "57:\tlearn: 0.3811004\ttotal: 373ms\tremaining: 2.84s\n",
      "58:\tlearn: 0.3785504\ttotal: 383ms\tremaining: 2.86s\n",
      "59:\tlearn: 0.3760850\ttotal: 392ms\tremaining: 2.87s\n",
      "60:\tlearn: 0.3726512\ttotal: 402ms\tremaining: 2.89s\n",
      "61:\tlearn: 0.3685636\ttotal: 411ms\tremaining: 2.9s\n",
      "62:\tlearn: 0.3645894\ttotal: 421ms\tremaining: 2.92s\n",
      "63:\tlearn: 0.3620849\ttotal: 430ms\tremaining: 2.93s\n",
      "64:\tlearn: 0.3599822\ttotal: 440ms\tremaining: 2.94s\n",
      "65:\tlearn: 0.3577739\ttotal: 450ms\tremaining: 2.96s\n",
      "66:\tlearn: 0.3550238\ttotal: 457ms\tremaining: 2.96s\n",
      "67:\tlearn: 0.3532504\ttotal: 463ms\tremaining: 2.94s\n",
      "68:\tlearn: 0.3512889\ttotal: 470ms\tremaining: 2.94s\n",
      "69:\tlearn: 0.3497503\ttotal: 476ms\tremaining: 2.92s\n",
      "70:\tlearn: 0.3441109\ttotal: 482ms\tremaining: 2.91s\n",
      "71:\tlearn: 0.3419181\ttotal: 487ms\tremaining: 2.9s\n",
      "72:\tlearn: 0.3396233\ttotal: 492ms\tremaining: 2.88s\n",
      "73:\tlearn: 0.3375198\ttotal: 497ms\tremaining: 2.86s\n",
      "74:\tlearn: 0.3351974\ttotal: 501ms\tremaining: 2.84s\n",
      "75:\tlearn: 0.3326490\ttotal: 505ms\tremaining: 2.82s\n",
      "76:\tlearn: 0.3307116\ttotal: 510ms\tremaining: 2.8s\n",
      "77:\tlearn: 0.3282622\ttotal: 514ms\tremaining: 2.78s\n",
      "78:\tlearn: 0.3243964\ttotal: 519ms\tremaining: 2.76s\n",
      "79:\tlearn: 0.3212890\ttotal: 523ms\tremaining: 2.74s\n",
      "80:\tlearn: 0.3194044\ttotal: 527ms\tremaining: 2.73s\n",
      "81:\tlearn: 0.3173406\ttotal: 532ms\tremaining: 2.71s\n",
      "82:\tlearn: 0.3149350\ttotal: 536ms\tremaining: 2.69s\n",
      "83:\tlearn: 0.3123339\ttotal: 540ms\tremaining: 2.68s\n",
      "84:\tlearn: 0.3102873\ttotal: 544ms\tremaining: 2.66s\n",
      "85:\tlearn: 0.3083385\ttotal: 554ms\tremaining: 2.67s\n",
      "86:\tlearn: 0.3066569\ttotal: 564ms\tremaining: 2.67s\n",
      "87:\tlearn: 0.3046959\ttotal: 573ms\tremaining: 2.68s\n",
      "88:\tlearn: 0.3026564\ttotal: 583ms\tremaining: 2.69s\n",
      "89:\tlearn: 0.3002621\ttotal: 592ms\tremaining: 2.7s\n",
      "90:\tlearn: 0.2981632\ttotal: 601ms\tremaining: 2.7s\n",
      "91:\tlearn: 0.2963112\ttotal: 611ms\tremaining: 2.71s\n",
      "92:\tlearn: 0.2936032\ttotal: 621ms\tremaining: 2.72s\n",
      "93:\tlearn: 0.2915375\ttotal: 629ms\tremaining: 2.72s\n",
      "94:\tlearn: 0.2889445\ttotal: 636ms\tremaining: 2.71s\n",
      "95:\tlearn: 0.2872116\ttotal: 642ms\tremaining: 2.7s\n",
      "96:\tlearn: 0.2857617\ttotal: 648ms\tremaining: 2.69s\n",
      "97:\tlearn: 0.2837050\ttotal: 655ms\tremaining: 2.69s\n",
      "98:\tlearn: 0.2819935\ttotal: 661ms\tremaining: 2.68s\n",
      "99:\tlearn: 0.2801293\ttotal: 667ms\tremaining: 2.67s\n",
      "100:\tlearn: 0.2764798\ttotal: 674ms\tremaining: 2.66s\n",
      "101:\tlearn: 0.2750985\ttotal: 680ms\tremaining: 2.65s\n",
      "102:\tlearn: 0.2732119\ttotal: 686ms\tremaining: 2.64s\n",
      "103:\tlearn: 0.2716023\ttotal: 691ms\tremaining: 2.63s\n",
      "104:\tlearn: 0.2696037\ttotal: 696ms\tremaining: 2.62s\n",
      "105:\tlearn: 0.2673990\ttotal: 700ms\tremaining: 2.6s\n",
      "106:\tlearn: 0.2657732\ttotal: 705ms\tremaining: 2.59s\n",
      "107:\tlearn: 0.2639184\ttotal: 710ms\tremaining: 2.58s\n",
      "108:\tlearn: 0.2622009\ttotal: 714ms\tremaining: 2.56s\n",
      "109:\tlearn: 0.2609289\ttotal: 718ms\tremaining: 2.55s\n",
      "110:\tlearn: 0.2574322\ttotal: 723ms\tremaining: 2.53s\n",
      "111:\tlearn: 0.2556454\ttotal: 727ms\tremaining: 2.52s\n",
      "112:\tlearn: 0.2526131\ttotal: 732ms\tremaining: 2.51s\n",
      "113:\tlearn: 0.2511932\ttotal: 736ms\tremaining: 2.49s\n",
      "114:\tlearn: 0.2496494\ttotal: 746ms\tremaining: 2.5s\n",
      "115:\tlearn: 0.2480998\ttotal: 755ms\tremaining: 2.5s\n",
      "116:\tlearn: 0.2461280\ttotal: 765ms\tremaining: 2.5s\n",
      "117:\tlearn: 0.2445691\ttotal: 774ms\tremaining: 2.51s\n",
      "118:\tlearn: 0.2425550\ttotal: 784ms\tremaining: 2.51s\n",
      "119:\tlearn: 0.2408507\ttotal: 794ms\tremaining: 2.51s\n",
      "120:\tlearn: 0.2394570\ttotal: 803ms\tremaining: 2.52s\n",
      "121:\tlearn: 0.2380014\ttotal: 813ms\tremaining: 2.52s\n",
      "122:\tlearn: 0.2366080\ttotal: 823ms\tremaining: 2.52s\n",
      "123:\tlearn: 0.2337477\ttotal: 829ms\tremaining: 2.51s\n",
      "124:\tlearn: 0.2325509\ttotal: 836ms\tremaining: 2.51s\n",
      "125:\tlearn: 0.2311387\ttotal: 842ms\tremaining: 2.5s\n",
      "126:\tlearn: 0.2297943\ttotal: 848ms\tremaining: 2.49s\n",
      "127:\tlearn: 0.2283769\ttotal: 855ms\tremaining: 2.48s\n",
      "128:\tlearn: 0.2270671\ttotal: 859ms\tremaining: 2.47s\n",
      "129:\tlearn: 0.2244925\ttotal: 864ms\tremaining: 2.46s\n",
      "130:\tlearn: 0.2230566\ttotal: 869ms\tremaining: 2.45s\n",
      "131:\tlearn: 0.2216312\ttotal: 874ms\tremaining: 2.44s\n",
      "132:\tlearn: 0.2203384\ttotal: 878ms\tremaining: 2.42s\n",
      "133:\tlearn: 0.2192091\ttotal: 883ms\tremaining: 2.41s\n",
      "134:\tlearn: 0.2179480\ttotal: 888ms\tremaining: 2.4s\n",
      "135:\tlearn: 0.2169425\ttotal: 893ms\tremaining: 2.39s\n",
      "136:\tlearn: 0.2156517\ttotal: 897ms\tremaining: 2.38s\n",
      "137:\tlearn: 0.2140448\ttotal: 902ms\tremaining: 2.37s\n",
      "138:\tlearn: 0.2129337\ttotal: 907ms\tremaining: 2.35s\n",
      "139:\tlearn: 0.2104391\ttotal: 912ms\tremaining: 2.35s\n",
      "140:\tlearn: 0.2091782\ttotal: 922ms\tremaining: 2.35s\n",
      "141:\tlearn: 0.2081205\ttotal: 931ms\tremaining: 2.35s\n",
      "142:\tlearn: 0.2059047\ttotal: 941ms\tremaining: 2.35s\n",
      "143:\tlearn: 0.2047005\ttotal: 954ms\tremaining: 2.36s\n",
      "144:\tlearn: 0.2035281\ttotal: 963ms\tremaining: 2.36s\n",
      "145:\tlearn: 0.2021947\ttotal: 973ms\tremaining: 2.36s\n",
      "146:\tlearn: 0.2007788\ttotal: 983ms\tremaining: 2.36s\n",
      "147:\tlearn: 0.1996563\ttotal: 992ms\tremaining: 2.36s\n",
      "148:\tlearn: 0.1984940\ttotal: 998ms\tremaining: 2.35s\n",
      "149:\tlearn: 0.1971482\ttotal: 1s\tremaining: 2.34s\n",
      "150:\tlearn: 0.1961112\ttotal: 1.01s\tremaining: 2.33s\n",
      "151:\tlearn: 0.1950808\ttotal: 1.02s\tremaining: 2.33s\n",
      "152:\tlearn: 0.1940460\ttotal: 1.02s\tremaining: 2.32s\n",
      "153:\tlearn: 0.1925248\ttotal: 1.03s\tremaining: 2.31s\n",
      "154:\tlearn: 0.1915198\ttotal: 1.03s\tremaining: 2.3s\n",
      "155:\tlearn: 0.1900069\ttotal: 1.04s\tremaining: 2.29s\n",
      "156:\tlearn: 0.1882609\ttotal: 1.04s\tremaining: 2.27s\n",
      "157:\tlearn: 0.1873959\ttotal: 1.04s\tremaining: 2.26s\n",
      "158:\tlearn: 0.1855398\ttotal: 1.05s\tremaining: 2.25s\n",
      "159:\tlearn: 0.1844148\ttotal: 1.05s\tremaining: 2.24s\n",
      "160:\tlearn: 0.1825905\ttotal: 1.06s\tremaining: 2.23s\n",
      "161:\tlearn: 0.1817071\ttotal: 1.06s\tremaining: 2.22s\n",
      "162:\tlearn: 0.1807566\ttotal: 1.07s\tremaining: 2.21s\n",
      "163:\tlearn: 0.1797823\ttotal: 1.07s\tremaining: 2.19s\n",
      "164:\tlearn: 0.1779206\ttotal: 1.07s\tremaining: 2.18s\n",
      "165:\tlearn: 0.1768981\ttotal: 1.08s\tremaining: 2.17s\n",
      "166:\tlearn: 0.1760635\ttotal: 1.09s\tremaining: 2.17s\n",
      "167:\tlearn: 0.1751453\ttotal: 1.1s\tremaining: 2.17s\n",
      "168:\tlearn: 0.1739692\ttotal: 1.11s\tremaining: 2.17s\n",
      "169:\tlearn: 0.1729651\ttotal: 1.12s\tremaining: 2.17s\n",
      "170:\tlearn: 0.1720059\ttotal: 1.13s\tremaining: 2.17s\n",
      "171:\tlearn: 0.1711612\ttotal: 1.14s\tremaining: 2.17s\n",
      "172:\tlearn: 0.1699875\ttotal: 1.15s\tremaining: 2.17s\n",
      "173:\tlearn: 0.1688542\ttotal: 1.16s\tremaining: 2.17s\n",
      "174:\tlearn: 0.1680133\ttotal: 1.17s\tremaining: 2.16s\n",
      "175:\tlearn: 0.1672076\ttotal: 1.17s\tremaining: 2.15s\n",
      "176:\tlearn: 0.1661676\ttotal: 1.18s\tremaining: 2.15s\n",
      "177:\tlearn: 0.1651531\ttotal: 1.18s\tremaining: 2.13s\n",
      "178:\tlearn: 0.1641006\ttotal: 1.19s\tremaining: 2.13s\n",
      "179:\tlearn: 0.1632675\ttotal: 1.19s\tremaining: 2.12s\n",
      "180:\tlearn: 0.1624816\ttotal: 1.19s\tremaining: 2.1s\n",
      "181:\tlearn: 0.1615921\ttotal: 1.2s\tremaining: 2.09s\n",
      "182:\tlearn: 0.1604856\ttotal: 1.2s\tremaining: 2.08s\n",
      "183:\tlearn: 0.1588076\ttotal: 1.21s\tremaining: 2.07s\n",
      "184:\tlearn: 0.1578195\ttotal: 1.21s\tremaining: 2.06s\n",
      "185:\tlearn: 0.1570388\ttotal: 1.22s\tremaining: 2.05s\n",
      "186:\tlearn: 0.1561259\ttotal: 1.23s\tremaining: 2.05s\n",
      "187:\tlearn: 0.1553677\ttotal: 1.24s\tremaining: 2.05s\n",
      "188:\tlearn: 0.1544071\ttotal: 1.25s\tremaining: 2.05s\n",
      "189:\tlearn: 0.1532512\ttotal: 1.25s\tremaining: 2.05s\n",
      "190:\tlearn: 0.1523210\ttotal: 1.26s\tremaining: 2.05s\n",
      "191:\tlearn: 0.1514611\ttotal: 1.27s\tremaining: 2.04s\n",
      "192:\tlearn: 0.1506706\ttotal: 1.28s\tremaining: 2.04s\n",
      "193:\tlearn: 0.1501767\ttotal: 1.29s\tremaining: 2.04s\n",
      "194:\tlearn: 0.1493913\ttotal: 1.3s\tremaining: 2.04s\n",
      "195:\tlearn: 0.1483356\ttotal: 1.31s\tremaining: 2.03s\n",
      "196:\tlearn: 0.1477194\ttotal: 1.32s\tremaining: 2.03s\n",
      "197:\tlearn: 0.1469951\ttotal: 1.32s\tremaining: 2.02s\n",
      "198:\tlearn: 0.1461725\ttotal: 1.33s\tremaining: 2.01s\n",
      "199:\tlearn: 0.1454554\ttotal: 1.34s\tremaining: 2s\n",
      "200:\tlearn: 0.1448084\ttotal: 1.34s\tremaining: 1.99s\n",
      "201:\tlearn: 0.1441176\ttotal: 1.34s\tremaining: 1.99s\n",
      "202:\tlearn: 0.1432439\ttotal: 1.35s\tremaining: 1.98s\n",
      "203:\tlearn: 0.1424901\ttotal: 1.35s\tremaining: 1.97s\n",
      "204:\tlearn: 0.1418248\ttotal: 1.36s\tremaining: 1.96s\n",
      "205:\tlearn: 0.1412271\ttotal: 1.36s\tremaining: 1.95s\n",
      "206:\tlearn: 0.1404957\ttotal: 1.37s\tremaining: 1.94s\n",
      "207:\tlearn: 0.1396029\ttotal: 1.37s\tremaining: 1.93s\n",
      "208:\tlearn: 0.1381356\ttotal: 1.38s\tremaining: 1.92s\n",
      "209:\tlearn: 0.1364430\ttotal: 1.38s\tremaining: 1.91s\n",
      "210:\tlearn: 0.1357198\ttotal: 1.38s\tremaining: 1.9s\n",
      "211:\tlearn: 0.1348510\ttotal: 1.39s\tremaining: 1.89s\n",
      "212:\tlearn: 0.1341948\ttotal: 1.4s\tremaining: 1.89s\n",
      "213:\tlearn: 0.1334006\ttotal: 1.41s\tremaining: 1.88s\n",
      "214:\tlearn: 0.1330015\ttotal: 1.42s\tremaining: 1.88s\n",
      "215:\tlearn: 0.1317679\ttotal: 1.43s\tremaining: 1.88s\n",
      "216:\tlearn: 0.1309404\ttotal: 1.44s\tremaining: 1.88s\n",
      "217:\tlearn: 0.1302676\ttotal: 1.45s\tremaining: 1.87s\n",
      "218:\tlearn: 0.1296248\ttotal: 1.46s\tremaining: 1.87s\n",
      "219:\tlearn: 0.1290038\ttotal: 1.47s\tremaining: 1.87s\n",
      "220:\tlearn: 0.1283770\ttotal: 1.48s\tremaining: 1.86s\n",
      "221:\tlearn: 0.1277756\ttotal: 1.48s\tremaining: 1.86s\n",
      "222:\tlearn: 0.1265410\ttotal: 1.49s\tremaining: 1.85s\n",
      "223:\tlearn: 0.1256270\ttotal: 1.5s\tremaining: 1.84s\n",
      "224:\tlearn: 0.1250398\ttotal: 1.5s\tremaining: 1.83s\n",
      "225:\tlearn: 0.1246200\ttotal: 1.51s\tremaining: 1.83s\n",
      "226:\tlearn: 0.1239958\ttotal: 1.51s\tremaining: 1.82s\n",
      "227:\tlearn: 0.1233003\ttotal: 1.52s\tremaining: 1.81s\n",
      "228:\tlearn: 0.1227013\ttotal: 1.52s\tremaining: 1.8s\n",
      "229:\tlearn: 0.1224065\ttotal: 1.53s\tremaining: 1.79s\n",
      "230:\tlearn: 0.1218134\ttotal: 1.53s\tremaining: 1.78s\n",
      "231:\tlearn: 0.1211998\ttotal: 1.53s\tremaining: 1.77s\n",
      "232:\tlearn: 0.1204600\ttotal: 1.54s\tremaining: 1.76s\n",
      "233:\tlearn: 0.1198303\ttotal: 1.54s\tremaining: 1.75s\n",
      "234:\tlearn: 0.1190667\ttotal: 1.55s\tremaining: 1.75s\n",
      "235:\tlearn: 0.1184625\ttotal: 1.55s\tremaining: 1.74s\n",
      "236:\tlearn: 0.1180854\ttotal: 1.56s\tremaining: 1.73s\n",
      "237:\tlearn: 0.1173203\ttotal: 1.57s\tremaining: 1.72s\n",
      "238:\tlearn: 0.1167281\ttotal: 1.58s\tremaining: 1.72s\n",
      "239:\tlearn: 0.1160998\ttotal: 1.59s\tremaining: 1.72s\n",
      "240:\tlearn: 0.1154472\ttotal: 1.59s\tremaining: 1.71s\n",
      "241:\tlearn: 0.1147410\ttotal: 1.6s\tremaining: 1.71s\n",
      "242:\tlearn: 0.1141413\ttotal: 1.61s\tremaining: 1.71s\n",
      "243:\tlearn: 0.1138495\ttotal: 1.62s\tremaining: 1.7s\n",
      "244:\tlearn: 0.1134948\ttotal: 1.63s\tremaining: 1.7s\n",
      "245:\tlearn: 0.1127617\ttotal: 1.64s\tremaining: 1.7s\n",
      "246:\tlearn: 0.1122235\ttotal: 1.66s\tremaining: 1.7s\n",
      "247:\tlearn: 0.1116479\ttotal: 1.66s\tremaining: 1.69s\n",
      "248:\tlearn: 0.1111119\ttotal: 1.67s\tremaining: 1.68s\n",
      "249:\tlearn: 0.1105492\ttotal: 1.68s\tremaining: 1.68s\n",
      "250:\tlearn: 0.1100002\ttotal: 1.68s\tremaining: 1.67s\n",
      "251:\tlearn: 0.1092453\ttotal: 1.69s\tremaining: 1.66s\n",
      "252:\tlearn: 0.1086279\ttotal: 1.69s\tremaining: 1.65s\n",
      "253:\tlearn: 0.1075538\ttotal: 1.7s\tremaining: 1.64s\n",
      "254:\tlearn: 0.1071290\ttotal: 1.7s\tremaining: 1.63s\n",
      "255:\tlearn: 0.1065527\ttotal: 1.71s\tremaining: 1.63s\n",
      "256:\tlearn: 0.1059715\ttotal: 1.71s\tremaining: 1.62s\n",
      "257:\tlearn: 0.1054995\ttotal: 1.71s\tremaining: 1.61s\n",
      "258:\tlearn: 0.1050211\ttotal: 1.72s\tremaining: 1.6s\n",
      "259:\tlearn: 0.1042993\ttotal: 1.72s\tremaining: 1.59s\n",
      "260:\tlearn: 0.1037848\ttotal: 1.73s\tremaining: 1.58s\n",
      "261:\tlearn: 0.1030847\ttotal: 1.73s\tremaining: 1.57s\n",
      "262:\tlearn: 0.1023755\ttotal: 1.74s\tremaining: 1.57s\n",
      "263:\tlearn: 0.1018769\ttotal: 1.75s\tremaining: 1.56s\n",
      "264:\tlearn: 0.1011869\ttotal: 1.76s\tremaining: 1.56s\n",
      "265:\tlearn: 0.1009963\ttotal: 1.77s\tremaining: 1.56s\n",
      "266:\tlearn: 0.1005079\ttotal: 1.78s\tremaining: 1.55s\n",
      "267:\tlearn: 0.0999552\ttotal: 1.79s\tremaining: 1.55s\n",
      "268:\tlearn: 0.0993496\ttotal: 1.8s\tremaining: 1.54s\n",
      "269:\tlearn: 0.0989036\ttotal: 1.81s\tremaining: 1.54s\n",
      "270:\tlearn: 0.0982929\ttotal: 1.82s\tremaining: 1.54s\n",
      "271:\tlearn: 0.0977591\ttotal: 1.83s\tremaining: 1.53s\n",
      "272:\tlearn: 0.0973150\ttotal: 1.83s\tremaining: 1.52s\n",
      "273:\tlearn: 0.0968171\ttotal: 1.84s\tremaining: 1.52s\n",
      "274:\tlearn: 0.0962742\ttotal: 1.84s\tremaining: 1.51s\n",
      "275:\tlearn: 0.0960604\ttotal: 1.85s\tremaining: 1.5s\n",
      "276:\tlearn: 0.0955892\ttotal: 1.85s\tremaining: 1.49s\n",
      "277:\tlearn: 0.0950690\ttotal: 1.86s\tremaining: 1.48s\n",
      "278:\tlearn: 0.0944840\ttotal: 1.86s\tremaining: 1.48s\n",
      "279:\tlearn: 0.0939099\ttotal: 1.87s\tremaining: 1.47s\n",
      "280:\tlearn: 0.0934589\ttotal: 1.87s\tremaining: 1.46s\n",
      "281:\tlearn: 0.0930508\ttotal: 1.88s\tremaining: 1.45s\n",
      "282:\tlearn: 0.0926772\ttotal: 1.88s\tremaining: 1.44s\n",
      "283:\tlearn: 0.0917289\ttotal: 1.89s\tremaining: 1.44s\n",
      "284:\tlearn: 0.0913293\ttotal: 1.89s\tremaining: 1.43s\n",
      "285:\tlearn: 0.0906738\ttotal: 1.89s\tremaining: 1.42s\n",
      "286:\tlearn: 0.0902945\ttotal: 1.9s\tremaining: 1.41s\n",
      "287:\tlearn: 0.0900120\ttotal: 1.9s\tremaining: 1.4s\n",
      "288:\tlearn: 0.0895136\ttotal: 1.91s\tremaining: 1.39s\n",
      "289:\tlearn: 0.0894603\ttotal: 1.92s\tremaining: 1.39s\n",
      "290:\tlearn: 0.0890066\ttotal: 1.93s\tremaining: 1.38s\n",
      "291:\tlearn: 0.0886893\ttotal: 1.94s\tremaining: 1.38s\n",
      "292:\tlearn: 0.0883275\ttotal: 1.95s\tremaining: 1.37s\n",
      "293:\tlearn: 0.0879276\ttotal: 1.95s\tremaining: 1.37s\n",
      "294:\tlearn: 0.0874529\ttotal: 1.96s\tremaining: 1.36s\n",
      "295:\tlearn: 0.0869936\ttotal: 1.97s\tremaining: 1.36s\n",
      "296:\tlearn: 0.0864744\ttotal: 1.98s\tremaining: 1.35s\n",
      "297:\tlearn: 0.0861399\ttotal: 1.99s\tremaining: 1.35s\n",
      "298:\tlearn: 0.0855947\ttotal: 2s\tremaining: 1.34s\n",
      "299:\tlearn: 0.0851876\ttotal: 2s\tremaining: 1.34s\n",
      "300:\tlearn: 0.0847341\ttotal: 2.01s\tremaining: 1.33s\n",
      "301:\tlearn: 0.0844331\ttotal: 2.02s\tremaining: 1.32s\n",
      "302:\tlearn: 0.0838775\ttotal: 2.02s\tremaining: 1.31s\n",
      "303:\tlearn: 0.0837131\ttotal: 2.03s\tremaining: 1.31s\n",
      "304:\tlearn: 0.0833537\ttotal: 2.03s\tremaining: 1.3s\n",
      "305:\tlearn: 0.0829958\ttotal: 2.04s\tremaining: 1.29s\n",
      "306:\tlearn: 0.0822762\ttotal: 2.04s\tremaining: 1.28s\n",
      "307:\tlearn: 0.0819268\ttotal: 2.05s\tremaining: 1.28s\n",
      "308:\tlearn: 0.0815630\ttotal: 2.05s\tremaining: 1.27s\n",
      "309:\tlearn: 0.0811481\ttotal: 2.06s\tremaining: 1.26s\n",
      "310:\tlearn: 0.0806718\ttotal: 2.06s\tremaining: 1.25s\n",
      "311:\tlearn: 0.0802530\ttotal: 2.06s\tremaining: 1.24s\n",
      "312:\tlearn: 0.0799849\ttotal: 2.07s\tremaining: 1.24s\n",
      "313:\tlearn: 0.0796062\ttotal: 2.07s\tremaining: 1.23s\n",
      "314:\tlearn: 0.0791743\ttotal: 2.08s\tremaining: 1.22s\n",
      "315:\tlearn: 0.0788567\ttotal: 2.09s\tremaining: 1.22s\n",
      "316:\tlearn: 0.0784631\ttotal: 2.1s\tremaining: 1.21s\n",
      "317:\tlearn: 0.0779877\ttotal: 2.11s\tremaining: 1.21s\n",
      "318:\tlearn: 0.0775538\ttotal: 2.12s\tremaining: 1.2s\n",
      "319:\tlearn: 0.0771692\ttotal: 2.13s\tremaining: 1.2s\n",
      "320:\tlearn: 0.0768242\ttotal: 2.13s\tremaining: 1.19s\n",
      "321:\tlearn: 0.0764859\ttotal: 2.15s\tremaining: 1.19s\n",
      "322:\tlearn: 0.0761723\ttotal: 2.15s\tremaining: 1.18s\n",
      "323:\tlearn: 0.0758944\ttotal: 2.17s\tremaining: 1.18s\n",
      "324:\tlearn: 0.0755778\ttotal: 2.17s\tremaining: 1.17s\n",
      "325:\tlearn: 0.0752140\ttotal: 2.18s\tremaining: 1.16s\n",
      "326:\tlearn: 0.0751784\ttotal: 2.19s\tremaining: 1.16s\n",
      "327:\tlearn: 0.0748376\ttotal: 2.19s\tremaining: 1.15s\n",
      "328:\tlearn: 0.0744974\ttotal: 2.2s\tremaining: 1.14s\n",
      "329:\tlearn: 0.0738817\ttotal: 2.2s\tremaining: 1.13s\n",
      "330:\tlearn: 0.0735126\ttotal: 2.21s\tremaining: 1.13s\n",
      "331:\tlearn: 0.0730239\ttotal: 2.21s\tremaining: 1.12s\n",
      "332:\tlearn: 0.0727275\ttotal: 2.22s\tremaining: 1.11s\n",
      "333:\tlearn: 0.0724678\ttotal: 2.22s\tremaining: 1.1s\n",
      "334:\tlearn: 0.0720269\ttotal: 2.23s\tremaining: 1.1s\n",
      "335:\tlearn: 0.0717553\ttotal: 2.23s\tremaining: 1.09s\n",
      "336:\tlearn: 0.0713762\ttotal: 2.23s\tremaining: 1.08s\n",
      "337:\tlearn: 0.0710270\ttotal: 2.24s\tremaining: 1.07s\n",
      "338:\tlearn: 0.0706788\ttotal: 2.24s\tremaining: 1.06s\n",
      "339:\tlearn: 0.0705543\ttotal: 2.25s\tremaining: 1.06s\n",
      "340:\tlearn: 0.0702395\ttotal: 2.26s\tremaining: 1.05s\n",
      "341:\tlearn: 0.0699579\ttotal: 2.27s\tremaining: 1.05s\n",
      "342:\tlearn: 0.0697276\ttotal: 2.28s\tremaining: 1.04s\n",
      "343:\tlearn: 0.0694329\ttotal: 2.29s\tremaining: 1.04s\n",
      "344:\tlearn: 0.0690379\ttotal: 2.3s\tremaining: 1.03s\n",
      "345:\tlearn: 0.0686393\ttotal: 2.31s\tremaining: 1.03s\n",
      "346:\tlearn: 0.0682693\ttotal: 2.32s\tremaining: 1.02s\n",
      "347:\tlearn: 0.0679706\ttotal: 2.33s\tremaining: 1.02s\n",
      "348:\tlearn: 0.0676058\ttotal: 2.33s\tremaining: 1.01s\n",
      "349:\tlearn: 0.0673742\ttotal: 2.34s\tremaining: 1s\n",
      "350:\tlearn: 0.0669726\ttotal: 2.35s\tremaining: 997ms\n",
      "351:\tlearn: 0.0669415\ttotal: 2.35s\tremaining: 990ms\n",
      "352:\tlearn: 0.0666036\ttotal: 2.36s\tremaining: 982ms\n",
      "353:\tlearn: 0.0662578\ttotal: 2.36s\tremaining: 975ms\n",
      "354:\tlearn: 0.0660870\ttotal: 2.37s\tremaining: 967ms\n",
      "355:\tlearn: 0.0660283\ttotal: 2.37s\tremaining: 960ms\n",
      "356:\tlearn: 0.0656584\ttotal: 2.38s\tremaining: 952ms\n",
      "357:\tlearn: 0.0653265\ttotal: 2.38s\tremaining: 945ms\n",
      "358:\tlearn: 0.0648245\ttotal: 2.39s\tremaining: 937ms\n",
      "359:\tlearn: 0.0644085\ttotal: 2.39s\tremaining: 930ms\n",
      "360:\tlearn: 0.0640661\ttotal: 2.39s\tremaining: 922ms\n",
      "361:\tlearn: 0.0637395\ttotal: 2.4s\tremaining: 915ms\n",
      "362:\tlearn: 0.0634419\ttotal: 2.4s\tremaining: 907ms\n",
      "363:\tlearn: 0.0632011\ttotal: 2.41s\tremaining: 899ms\n",
      "364:\tlearn: 0.0629200\ttotal: 2.41s\tremaining: 891ms\n",
      "365:\tlearn: 0.0626162\ttotal: 2.42s\tremaining: 886ms\n",
      "366:\tlearn: 0.0623141\ttotal: 2.43s\tremaining: 881ms\n",
      "367:\tlearn: 0.0618881\ttotal: 2.44s\tremaining: 875ms\n",
      "368:\tlearn: 0.0615574\ttotal: 2.45s\tremaining: 870ms\n",
      "369:\tlearn: 0.0613084\ttotal: 2.46s\tremaining: 864ms\n",
      "370:\tlearn: 0.0609294\ttotal: 2.47s\tremaining: 858ms\n",
      "371:\tlearn: 0.0606585\ttotal: 2.48s\tremaining: 853ms\n",
      "372:\tlearn: 0.0603490\ttotal: 2.49s\tremaining: 847ms\n",
      "373:\tlearn: 0.0600543\ttotal: 2.5s\tremaining: 842ms\n",
      "374:\tlearn: 0.0598449\ttotal: 2.5s\tremaining: 835ms\n",
      "375:\tlearn: 0.0595543\ttotal: 2.51s\tremaining: 828ms\n",
      "376:\tlearn: 0.0592499\ttotal: 2.52s\tremaining: 821ms\n",
      "377:\tlearn: 0.0588986\ttotal: 2.52s\tremaining: 814ms\n",
      "378:\tlearn: 0.0585739\ttotal: 2.53s\tremaining: 808ms\n",
      "379:\tlearn: 0.0583410\ttotal: 2.53s\tremaining: 800ms\n",
      "380:\tlearn: 0.0580746\ttotal: 2.54s\tremaining: 793ms\n",
      "381:\tlearn: 0.0578113\ttotal: 2.54s\tremaining: 786ms\n",
      "382:\tlearn: 0.0575173\ttotal: 2.55s\tremaining: 778ms\n",
      "383:\tlearn: 0.0572342\ttotal: 2.55s\tremaining: 771ms\n",
      "384:\tlearn: 0.0569142\ttotal: 2.56s\tremaining: 764ms\n",
      "385:\tlearn: 0.0564499\ttotal: 2.56s\tremaining: 756ms\n",
      "386:\tlearn: 0.0561564\ttotal: 2.56s\tremaining: 749ms\n",
      "387:\tlearn: 0.0558598\ttotal: 2.57s\tremaining: 742ms\n",
      "388:\tlearn: 0.0556002\ttotal: 2.57s\tremaining: 734ms\n",
      "389:\tlearn: 0.0553311\ttotal: 2.58s\tremaining: 727ms\n",
      "390:\tlearn: 0.0546341\ttotal: 2.58s\tremaining: 720ms\n",
      "391:\tlearn: 0.0543506\ttotal: 2.59s\tremaining: 713ms\n",
      "392:\tlearn: 0.0541375\ttotal: 2.6s\tremaining: 707ms\n",
      "393:\tlearn: 0.0539324\ttotal: 2.6s\tremaining: 701ms\n",
      "394:\tlearn: 0.0535367\ttotal: 2.62s\tremaining: 695ms\n",
      "395:\tlearn: 0.0532204\ttotal: 2.63s\tremaining: 690ms\n",
      "396:\tlearn: 0.0530514\ttotal: 2.63s\tremaining: 684ms\n",
      "397:\tlearn: 0.0528068\ttotal: 2.64s\tremaining: 678ms\n",
      "398:\tlearn: 0.0525896\ttotal: 2.66s\tremaining: 673ms\n",
      "399:\tlearn: 0.0523777\ttotal: 2.66s\tremaining: 666ms\n",
      "400:\tlearn: 0.0521311\ttotal: 2.67s\tremaining: 659ms\n",
      "401:\tlearn: 0.0519148\ttotal: 2.67s\tremaining: 652ms\n",
      "402:\tlearn: 0.0515864\ttotal: 2.68s\tremaining: 644ms\n",
      "403:\tlearn: 0.0511439\ttotal: 2.68s\tremaining: 637ms\n",
      "404:\tlearn: 0.0508838\ttotal: 2.69s\tremaining: 630ms\n",
      "405:\tlearn: 0.0506716\ttotal: 2.69s\tremaining: 623ms\n",
      "406:\tlearn: 0.0504087\ttotal: 2.7s\tremaining: 616ms\n",
      "407:\tlearn: 0.0500978\ttotal: 2.7s\tremaining: 609ms\n",
      "408:\tlearn: 0.0498462\ttotal: 2.7s\tremaining: 602ms\n",
      "409:\tlearn: 0.0496519\ttotal: 2.71s\tremaining: 595ms\n",
      "410:\tlearn: 0.0494159\ttotal: 2.71s\tremaining: 588ms\n",
      "411:\tlearn: 0.0491828\ttotal: 2.72s\tremaining: 581ms\n",
      "412:\tlearn: 0.0489378\ttotal: 2.72s\tremaining: 573ms\n",
      "413:\tlearn: 0.0487266\ttotal: 2.73s\tremaining: 566ms\n",
      "414:\tlearn: 0.0484807\ttotal: 2.73s\tremaining: 559ms\n",
      "415:\tlearn: 0.0482688\ttotal: 2.74s\tremaining: 553ms\n",
      "416:\tlearn: 0.0480211\ttotal: 2.75s\tremaining: 547ms\n",
      "417:\tlearn: 0.0477815\ttotal: 2.76s\tremaining: 541ms\n",
      "418:\tlearn: 0.0474429\ttotal: 2.77s\tremaining: 535ms\n",
      "419:\tlearn: 0.0472230\ttotal: 2.78s\tremaining: 529ms\n",
      "420:\tlearn: 0.0470433\ttotal: 2.79s\tremaining: 523ms\n",
      "421:\tlearn: 0.0467700\ttotal: 2.8s\tremaining: 517ms\n",
      "422:\tlearn: 0.0465890\ttotal: 2.81s\tremaining: 511ms\n",
      "423:\tlearn: 0.0463728\ttotal: 2.81s\tremaining: 504ms\n",
      "424:\tlearn: 0.0461675\ttotal: 2.82s\tremaining: 497ms\n",
      "425:\tlearn: 0.0459918\ttotal: 2.83s\tremaining: 491ms\n",
      "426:\tlearn: 0.0457906\ttotal: 2.83s\tremaining: 484ms\n",
      "427:\tlearn: 0.0455987\ttotal: 2.84s\tremaining: 477ms\n",
      "428:\tlearn: 0.0454275\ttotal: 2.84s\tremaining: 470ms\n",
      "429:\tlearn: 0.0453038\ttotal: 2.85s\tremaining: 463ms\n",
      "430:\tlearn: 0.0450913\ttotal: 2.85s\tremaining: 456ms\n",
      "431:\tlearn: 0.0449888\ttotal: 2.85s\tremaining: 449ms\n",
      "432:\tlearn: 0.0447777\ttotal: 2.86s\tremaining: 443ms\n",
      "433:\tlearn: 0.0446682\ttotal: 2.87s\tremaining: 436ms\n",
      "434:\tlearn: 0.0444198\ttotal: 2.87s\tremaining: 429ms\n",
      "435:\tlearn: 0.0442229\ttotal: 2.87s\tremaining: 422ms\n",
      "436:\tlearn: 0.0440307\ttotal: 2.88s\tremaining: 415ms\n",
      "437:\tlearn: 0.0438329\ttotal: 2.88s\tremaining: 408ms\n",
      "438:\tlearn: 0.0436307\ttotal: 2.89s\tremaining: 401ms\n",
      "439:\tlearn: 0.0434509\ttotal: 2.89s\tremaining: 394ms\n",
      "440:\tlearn: 0.0432847\ttotal: 2.9s\tremaining: 388ms\n",
      "441:\tlearn: 0.0430259\ttotal: 2.9s\tremaining: 381ms\n",
      "442:\tlearn: 0.0428975\ttotal: 2.91s\tremaining: 375ms\n",
      "443:\tlearn: 0.0426285\ttotal: 2.92s\tremaining: 368ms\n",
      "444:\tlearn: 0.0423773\ttotal: 2.93s\tremaining: 362ms\n",
      "445:\tlearn: 0.0422028\ttotal: 2.94s\tremaining: 356ms\n",
      "446:\tlearn: 0.0420396\ttotal: 2.95s\tremaining: 350ms\n",
      "447:\tlearn: 0.0418506\ttotal: 2.96s\tremaining: 344ms\n",
      "448:\tlearn: 0.0416693\ttotal: 2.97s\tremaining: 337ms\n",
      "449:\tlearn: 0.0414682\ttotal: 2.98s\tremaining: 331ms\n",
      "450:\tlearn: 0.0413338\ttotal: 2.98s\tremaining: 324ms\n",
      "451:\tlearn: 0.0411402\ttotal: 2.99s\tremaining: 318ms\n",
      "452:\tlearn: 0.0409377\ttotal: 3s\tremaining: 311ms\n",
      "453:\tlearn: 0.0407311\ttotal: 3s\tremaining: 304ms\n",
      "454:\tlearn: 0.0406018\ttotal: 3.01s\tremaining: 298ms\n",
      "455:\tlearn: 0.0404458\ttotal: 3.02s\tremaining: 291ms\n",
      "456:\tlearn: 0.0402139\ttotal: 3.02s\tremaining: 284ms\n",
      "457:\tlearn: 0.0400754\ttotal: 3.03s\tremaining: 278ms\n",
      "458:\tlearn: 0.0398948\ttotal: 3.03s\tremaining: 271ms\n",
      "459:\tlearn: 0.0397653\ttotal: 3.04s\tremaining: 264ms\n",
      "460:\tlearn: 0.0395701\ttotal: 3.04s\tremaining: 257ms\n",
      "461:\tlearn: 0.0393552\ttotal: 3.04s\tremaining: 250ms\n",
      "462:\tlearn: 0.0391765\ttotal: 3.05s\tremaining: 244ms\n",
      "463:\tlearn: 0.0389958\ttotal: 3.05s\tremaining: 237ms\n",
      "464:\tlearn: 0.0388274\ttotal: 3.06s\tremaining: 230ms\n",
      "465:\tlearn: 0.0386423\ttotal: 3.06s\tremaining: 223ms\n",
      "466:\tlearn: 0.0384671\ttotal: 3.07s\tremaining: 217ms\n",
      "467:\tlearn: 0.0383227\ttotal: 3.08s\tremaining: 211ms\n",
      "468:\tlearn: 0.0380858\ttotal: 3.09s\tremaining: 204ms\n",
      "469:\tlearn: 0.0379372\ttotal: 3.1s\tremaining: 198ms\n",
      "470:\tlearn: 0.0377699\ttotal: 3.11s\tremaining: 191ms\n",
      "471:\tlearn: 0.0375613\ttotal: 3.12s\tremaining: 185ms\n",
      "472:\tlearn: 0.0374641\ttotal: 3.13s\tremaining: 179ms\n",
      "473:\tlearn: 0.0373099\ttotal: 3.14s\tremaining: 172ms\n",
      "474:\tlearn: 0.0371566\ttotal: 3.15s\tremaining: 166ms\n",
      "475:\tlearn: 0.0370114\ttotal: 3.15s\tremaining: 159ms\n",
      "476:\tlearn: 0.0369110\ttotal: 3.16s\tremaining: 152ms\n",
      "477:\tlearn: 0.0367446\ttotal: 3.17s\tremaining: 146ms\n",
      "478:\tlearn: 0.0366074\ttotal: 3.17s\tremaining: 139ms\n",
      "479:\tlearn: 0.0364387\ttotal: 3.18s\tremaining: 132ms\n",
      "480:\tlearn: 0.0363960\ttotal: 3.18s\tremaining: 126ms\n",
      "481:\tlearn: 0.0362045\ttotal: 3.19s\tremaining: 119ms\n",
      "482:\tlearn: 0.0360787\ttotal: 3.19s\tremaining: 112ms\n",
      "483:\tlearn: 0.0359319\ttotal: 3.2s\tremaining: 106ms\n",
      "484:\tlearn: 0.0358101\ttotal: 3.21s\tremaining: 99.1ms\n",
      "485:\tlearn: 0.0355853\ttotal: 3.21s\tremaining: 92.5ms\n",
      "486:\tlearn: 0.0354459\ttotal: 3.21s\tremaining: 85.8ms\n",
      "487:\tlearn: 0.0353549\ttotal: 3.22s\tremaining: 79.2ms\n",
      "488:\tlearn: 0.0352204\ttotal: 3.22s\tremaining: 72.5ms\n",
      "489:\tlearn: 0.0350796\ttotal: 3.23s\tremaining: 65.9ms\n",
      "490:\tlearn: 0.0348725\ttotal: 3.23s\tremaining: 59.3ms\n",
      "491:\tlearn: 0.0346869\ttotal: 3.24s\tremaining: 52.7ms\n",
      "492:\tlearn: 0.0345065\ttotal: 3.25s\tremaining: 46.2ms\n",
      "493:\tlearn: 0.0343066\ttotal: 3.26s\tremaining: 39.6ms\n",
      "494:\tlearn: 0.0342227\ttotal: 3.27s\tremaining: 33ms\n",
      "495:\tlearn: 0.0340042\ttotal: 3.28s\tremaining: 26.5ms\n",
      "496:\tlearn: 0.0338111\ttotal: 3.29s\tremaining: 19.9ms\n",
      "497:\tlearn: 0.0336878\ttotal: 3.3s\tremaining: 13.3ms\n",
      "498:\tlearn: 0.0334529\ttotal: 3.31s\tremaining: 6.63ms\n",
      "499:\tlearn: 0.0333447\ttotal: 3.31s\tremaining: 0us\n",
      "0:\tlearn: 0.6826357\ttotal: 6.3ms\tremaining: 3.14s\n",
      "1:\tlearn: 0.6681341\ttotal: 12.5ms\tremaining: 3.12s\n",
      "2:\tlearn: 0.6577064\ttotal: 19ms\tremaining: 3.15s\n",
      "3:\tlearn: 0.6488262\ttotal: 26.6ms\tremaining: 3.3s\n",
      "4:\tlearn: 0.6380804\ttotal: 31.6ms\tremaining: 3.13s\n",
      "5:\tlearn: 0.6278067\ttotal: 38ms\tremaining: 3.13s\n",
      "6:\tlearn: 0.6180406\ttotal: 43.7ms\tremaining: 3.08s\n",
      "7:\tlearn: 0.6104898\ttotal: 50.3ms\tremaining: 3.09s\n",
      "8:\tlearn: 0.6050968\ttotal: 56ms\tremaining: 3.06s\n",
      "9:\tlearn: 0.5959053\ttotal: 63.1ms\tremaining: 3.09s\n",
      "10:\tlearn: 0.5866726\ttotal: 69.2ms\tremaining: 3.08s\n",
      "11:\tlearn: 0.5814569\ttotal: 74.6ms\tremaining: 3.04s\n",
      "12:\tlearn: 0.5738037\ttotal: 79.8ms\tremaining: 2.99s\n",
      "13:\tlearn: 0.5687103\ttotal: 86.1ms\tremaining: 2.99s\n",
      "14:\tlearn: 0.5638448\ttotal: 91.8ms\tremaining: 2.97s\n",
      "15:\tlearn: 0.5552205\ttotal: 98.2ms\tremaining: 2.97s\n",
      "16:\tlearn: 0.5481480\ttotal: 104ms\tremaining: 2.96s\n",
      "17:\tlearn: 0.5404638\ttotal: 109ms\tremaining: 2.92s\n",
      "18:\tlearn: 0.5337726\ttotal: 114ms\tremaining: 2.89s\n",
      "19:\tlearn: 0.5282100\ttotal: 119ms\tremaining: 2.85s\n",
      "20:\tlearn: 0.5233682\ttotal: 123ms\tremaining: 2.81s\n",
      "21:\tlearn: 0.5196026\ttotal: 128ms\tremaining: 2.78s\n",
      "22:\tlearn: 0.5134021\ttotal: 132ms\tremaining: 2.75s\n",
      "23:\tlearn: 0.5081723\ttotal: 138ms\tremaining: 2.73s\n",
      "24:\tlearn: 0.5005715\ttotal: 142ms\tremaining: 2.7s\n",
      "25:\tlearn: 0.4971738\ttotal: 146ms\tremaining: 2.67s\n",
      "26:\tlearn: 0.4924579\ttotal: 151ms\tremaining: 2.64s\n",
      "27:\tlearn: 0.4872915\ttotal: 155ms\tremaining: 2.61s\n",
      "28:\tlearn: 0.4829069\ttotal: 160ms\tremaining: 2.59s\n",
      "29:\tlearn: 0.4808523\ttotal: 164ms\tremaining: 2.57s\n",
      "30:\tlearn: 0.4774242\ttotal: 168ms\tremaining: 2.54s\n",
      "31:\tlearn: 0.4716321\ttotal: 178ms\tremaining: 2.6s\n",
      "32:\tlearn: 0.4673339\ttotal: 188ms\tremaining: 2.65s\n",
      "33:\tlearn: 0.4642105\ttotal: 197ms\tremaining: 2.71s\n",
      "34:\tlearn: 0.4605045\ttotal: 207ms\tremaining: 2.75s\n",
      "35:\tlearn: 0.4562914\ttotal: 216ms\tremaining: 2.79s\n",
      "36:\tlearn: 0.4536129\ttotal: 226ms\tremaining: 2.83s\n",
      "37:\tlearn: 0.4495599\ttotal: 236ms\tremaining: 2.87s\n",
      "38:\tlearn: 0.4468046\ttotal: 245ms\tremaining: 2.9s\n",
      "39:\tlearn: 0.4431305\ttotal: 251ms\tremaining: 2.89s\n",
      "40:\tlearn: 0.4400659\ttotal: 257ms\tremaining: 2.88s\n",
      "41:\tlearn: 0.4366310\ttotal: 264ms\tremaining: 2.88s\n",
      "42:\tlearn: 0.4333460\ttotal: 270ms\tremaining: 2.87s\n",
      "43:\tlearn: 0.4300434\ttotal: 276ms\tremaining: 2.86s\n",
      "44:\tlearn: 0.4267281\ttotal: 282ms\tremaining: 2.85s\n",
      "45:\tlearn: 0.4238086\ttotal: 287ms\tremaining: 2.83s\n",
      "46:\tlearn: 0.4203400\ttotal: 291ms\tremaining: 2.81s\n",
      "47:\tlearn: 0.4176252\ttotal: 296ms\tremaining: 2.79s\n",
      "48:\tlearn: 0.4142468\ttotal: 301ms\tremaining: 2.77s\n",
      "49:\tlearn: 0.4095247\ttotal: 305ms\tremaining: 2.75s\n",
      "50:\tlearn: 0.4069144\ttotal: 310ms\tremaining: 2.73s\n",
      "51:\tlearn: 0.4039311\ttotal: 314ms\tremaining: 2.71s\n",
      "52:\tlearn: 0.4004769\ttotal: 318ms\tremaining: 2.68s\n",
      "53:\tlearn: 0.3983301\ttotal: 323ms\tremaining: 2.67s\n",
      "54:\tlearn: 0.3958790\ttotal: 327ms\tremaining: 2.64s\n",
      "55:\tlearn: 0.3924768\ttotal: 331ms\tremaining: 2.63s\n",
      "56:\tlearn: 0.3905178\ttotal: 336ms\tremaining: 2.61s\n",
      "57:\tlearn: 0.3873531\ttotal: 340ms\tremaining: 2.59s\n",
      "58:\tlearn: 0.3848220\ttotal: 350ms\tremaining: 2.61s\n",
      "59:\tlearn: 0.3824041\ttotal: 359ms\tremaining: 2.63s\n",
      "60:\tlearn: 0.3799667\ttotal: 369ms\tremaining: 2.65s\n",
      "61:\tlearn: 0.3780525\ttotal: 378ms\tremaining: 2.67s\n",
      "62:\tlearn: 0.3761294\ttotal: 388ms\tremaining: 2.69s\n",
      "63:\tlearn: 0.3733960\ttotal: 398ms\tremaining: 2.71s\n",
      "64:\tlearn: 0.3706768\ttotal: 407ms\tremaining: 2.73s\n",
      "65:\tlearn: 0.3678394\ttotal: 416ms\tremaining: 2.73s\n",
      "66:\tlearn: 0.3644717\ttotal: 421ms\tremaining: 2.72s\n",
      "67:\tlearn: 0.3624998\ttotal: 426ms\tremaining: 2.71s\n",
      "68:\tlearn: 0.3602622\ttotal: 431ms\tremaining: 2.69s\n",
      "69:\tlearn: 0.3568969\ttotal: 437ms\tremaining: 2.68s\n",
      "70:\tlearn: 0.3543242\ttotal: 441ms\tremaining: 2.66s\n",
      "71:\tlearn: 0.3507177\ttotal: 446ms\tremaining: 2.65s\n",
      "72:\tlearn: 0.3480983\ttotal: 450ms\tremaining: 2.63s\n",
      "73:\tlearn: 0.3453008\ttotal: 455ms\tremaining: 2.62s\n",
      "74:\tlearn: 0.3433263\ttotal: 459ms\tremaining: 2.6s\n",
      "75:\tlearn: 0.3400591\ttotal: 463ms\tremaining: 2.58s\n",
      "76:\tlearn: 0.3369203\ttotal: 468ms\tremaining: 2.57s\n",
      "77:\tlearn: 0.3352878\ttotal: 472ms\tremaining: 2.55s\n",
      "78:\tlearn: 0.3328301\ttotal: 476ms\tremaining: 2.54s\n",
      "79:\tlearn: 0.3303251\ttotal: 480ms\tremaining: 2.52s\n",
      "80:\tlearn: 0.3286696\ttotal: 485ms\tremaining: 2.51s\n",
      "81:\tlearn: 0.3259476\ttotal: 489ms\tremaining: 2.49s\n",
      "82:\tlearn: 0.3229666\ttotal: 494ms\tremaining: 2.48s\n",
      "83:\tlearn: 0.3212147\ttotal: 499ms\tremaining: 2.47s\n",
      "84:\tlearn: 0.3166541\ttotal: 508ms\tremaining: 2.48s\n",
      "85:\tlearn: 0.3142773\ttotal: 518ms\tremaining: 2.49s\n",
      "86:\tlearn: 0.3122053\ttotal: 528ms\tremaining: 2.5s\n",
      "87:\tlearn: 0.3101730\ttotal: 537ms\tremaining: 2.52s\n",
      "88:\tlearn: 0.3067954\ttotal: 547ms\tremaining: 2.53s\n",
      "89:\tlearn: 0.3042478\ttotal: 557ms\tremaining: 2.54s\n",
      "90:\tlearn: 0.3026957\ttotal: 566ms\tremaining: 2.54s\n",
      "91:\tlearn: 0.3005706\ttotal: 575ms\tremaining: 2.55s\n",
      "92:\tlearn: 0.2985269\ttotal: 581ms\tremaining: 2.54s\n",
      "93:\tlearn: 0.2964932\ttotal: 586ms\tremaining: 2.53s\n",
      "94:\tlearn: 0.2946450\ttotal: 591ms\tremaining: 2.52s\n",
      "95:\tlearn: 0.2929203\ttotal: 596ms\tremaining: 2.51s\n",
      "96:\tlearn: 0.2911035\ttotal: 600ms\tremaining: 2.49s\n",
      "97:\tlearn: 0.2887925\ttotal: 605ms\tremaining: 2.48s\n",
      "98:\tlearn: 0.2869294\ttotal: 609ms\tremaining: 2.47s\n",
      "99:\tlearn: 0.2830595\ttotal: 614ms\tremaining: 2.45s\n",
      "100:\tlearn: 0.2809204\ttotal: 618ms\tremaining: 2.44s\n",
      "101:\tlearn: 0.2791494\ttotal: 622ms\tremaining: 2.43s\n",
      "102:\tlearn: 0.2775055\ttotal: 626ms\tremaining: 2.41s\n",
      "103:\tlearn: 0.2753592\ttotal: 631ms\tremaining: 2.4s\n",
      "104:\tlearn: 0.2733759\ttotal: 635ms\tremaining: 2.39s\n",
      "105:\tlearn: 0.2716843\ttotal: 639ms\tremaining: 2.37s\n",
      "106:\tlearn: 0.2679687\ttotal: 649ms\tremaining: 2.38s\n",
      "107:\tlearn: 0.2663774\ttotal: 659ms\tremaining: 2.39s\n",
      "108:\tlearn: 0.2642103\ttotal: 668ms\tremaining: 2.4s\n",
      "109:\tlearn: 0.2624772\ttotal: 678ms\tremaining: 2.4s\n",
      "110:\tlearn: 0.2611253\ttotal: 687ms\tremaining: 2.41s\n",
      "111:\tlearn: 0.2596287\ttotal: 697ms\tremaining: 2.41s\n",
      "112:\tlearn: 0.2580172\ttotal: 706ms\tremaining: 2.42s\n",
      "113:\tlearn: 0.2544485\ttotal: 716ms\tremaining: 2.42s\n",
      "114:\tlearn: 0.2525613\ttotal: 726ms\tremaining: 2.43s\n",
      "115:\tlearn: 0.2509968\ttotal: 732ms\tremaining: 2.42s\n",
      "116:\tlearn: 0.2493651\ttotal: 741ms\tremaining: 2.42s\n",
      "117:\tlearn: 0.2478824\ttotal: 748ms\tremaining: 2.42s\n",
      "118:\tlearn: 0.2464181\ttotal: 755ms\tremaining: 2.42s\n",
      "119:\tlearn: 0.2448862\ttotal: 760ms\tremaining: 2.4s\n",
      "120:\tlearn: 0.2428293\ttotal: 765ms\tremaining: 2.39s\n",
      "121:\tlearn: 0.2415637\ttotal: 769ms\tremaining: 2.38s\n",
      "122:\tlearn: 0.2400207\ttotal: 774ms\tremaining: 2.37s\n",
      "123:\tlearn: 0.2384571\ttotal: 778ms\tremaining: 2.36s\n",
      "124:\tlearn: 0.2367545\ttotal: 782ms\tremaining: 2.35s\n",
      "125:\tlearn: 0.2354070\ttotal: 786ms\tremaining: 2.33s\n",
      "126:\tlearn: 0.2341947\ttotal: 791ms\tremaining: 2.32s\n",
      "127:\tlearn: 0.2326161\ttotal: 795ms\tremaining: 2.31s\n",
      "128:\tlearn: 0.2299659\ttotal: 799ms\tremaining: 2.3s\n",
      "129:\tlearn: 0.2288572\ttotal: 803ms\tremaining: 2.29s\n",
      "130:\tlearn: 0.2271005\ttotal: 808ms\tremaining: 2.27s\n",
      "131:\tlearn: 0.2244778\ttotal: 812ms\tremaining: 2.26s\n",
      "132:\tlearn: 0.2222588\ttotal: 818ms\tremaining: 2.26s\n",
      "133:\tlearn: 0.2207662\ttotal: 828ms\tremaining: 2.26s\n",
      "134:\tlearn: 0.2194088\ttotal: 837ms\tremaining: 2.26s\n",
      "135:\tlearn: 0.2180225\ttotal: 849ms\tremaining: 2.27s\n",
      "136:\tlearn: 0.2159797\ttotal: 858ms\tremaining: 2.27s\n",
      "137:\tlearn: 0.2146044\ttotal: 867ms\tremaining: 2.27s\n",
      "138:\tlearn: 0.2131591\ttotal: 877ms\tremaining: 2.28s\n",
      "139:\tlearn: 0.2121452\ttotal: 887ms\tremaining: 2.28s\n",
      "140:\tlearn: 0.2104058\ttotal: 896ms\tremaining: 2.28s\n",
      "141:\tlearn: 0.2092856\ttotal: 905ms\tremaining: 2.28s\n",
      "142:\tlearn: 0.2078559\ttotal: 916ms\tremaining: 2.29s\n",
      "143:\tlearn: 0.2061888\ttotal: 926ms\tremaining: 2.29s\n",
      "144:\tlearn: 0.2052484\ttotal: 935ms\tremaining: 2.29s\n",
      "145:\tlearn: 0.2037845\ttotal: 945ms\tremaining: 2.29s\n",
      "146:\tlearn: 0.2026262\ttotal: 954ms\tremaining: 2.29s\n",
      "147:\tlearn: 0.2004897\ttotal: 964ms\tremaining: 2.29s\n",
      "148:\tlearn: 0.1992570\ttotal: 973ms\tremaining: 2.29s\n",
      "149:\tlearn: 0.1981669\ttotal: 977ms\tremaining: 2.28s\n",
      "150:\tlearn: 0.1967057\ttotal: 981ms\tremaining: 2.27s\n",
      "151:\tlearn: 0.1956217\ttotal: 986ms\tremaining: 2.26s\n",
      "152:\tlearn: 0.1945658\ttotal: 990ms\tremaining: 2.24s\n",
      "153:\tlearn: 0.1934531\ttotal: 994ms\tremaining: 2.23s\n",
      "154:\tlearn: 0.1923345\ttotal: 998ms\tremaining: 2.22s\n",
      "155:\tlearn: 0.1908558\ttotal: 1s\tremaining: 2.21s\n",
      "156:\tlearn: 0.1896433\ttotal: 1.01s\tremaining: 2.2s\n",
      "157:\tlearn: 0.1877966\ttotal: 1.01s\tremaining: 2.19s\n",
      "158:\tlearn: 0.1866443\ttotal: 1.02s\tremaining: 2.19s\n",
      "159:\tlearn: 0.1856109\ttotal: 1.03s\tremaining: 2.19s\n",
      "160:\tlearn: 0.1846399\ttotal: 1.04s\tremaining: 2.19s\n",
      "161:\tlearn: 0.1834052\ttotal: 1.05s\tremaining: 2.19s\n",
      "162:\tlearn: 0.1821243\ttotal: 1.06s\tremaining: 2.19s\n",
      "163:\tlearn: 0.1811067\ttotal: 1.07s\tremaining: 2.19s\n",
      "164:\tlearn: 0.1801191\ttotal: 1.08s\tremaining: 2.19s\n",
      "165:\tlearn: 0.1780465\ttotal: 1.09s\tremaining: 2.19s\n",
      "166:\tlearn: 0.1770889\ttotal: 1.1s\tremaining: 2.19s\n",
      "167:\tlearn: 0.1756372\ttotal: 1.1s\tremaining: 2.18s\n",
      "168:\tlearn: 0.1738594\ttotal: 1.11s\tremaining: 2.17s\n",
      "169:\tlearn: 0.1728694\ttotal: 1.11s\tremaining: 2.16s\n",
      "170:\tlearn: 0.1718699\ttotal: 1.12s\tremaining: 2.15s\n",
      "171:\tlearn: 0.1707570\ttotal: 1.12s\tremaining: 2.14s\n",
      "172:\tlearn: 0.1691807\ttotal: 1.13s\tremaining: 2.13s\n",
      "173:\tlearn: 0.1682527\ttotal: 1.13s\tremaining: 2.12s\n",
      "174:\tlearn: 0.1672855\ttotal: 1.14s\tremaining: 2.11s\n",
      "175:\tlearn: 0.1663879\ttotal: 1.14s\tremaining: 2.1s\n",
      "176:\tlearn: 0.1654267\ttotal: 1.15s\tremaining: 2.09s\n",
      "177:\tlearn: 0.1645908\ttotal: 1.15s\tremaining: 2.08s\n",
      "178:\tlearn: 0.1637998\ttotal: 1.15s\tremaining: 2.07s\n",
      "179:\tlearn: 0.1629456\ttotal: 1.16s\tremaining: 2.06s\n",
      "180:\tlearn: 0.1620300\ttotal: 1.16s\tremaining: 2.05s\n",
      "181:\tlearn: 0.1614183\ttotal: 1.17s\tremaining: 2.04s\n",
      "182:\tlearn: 0.1607495\ttotal: 1.17s\tremaining: 2.02s\n",
      "183:\tlearn: 0.1597378\ttotal: 1.17s\tremaining: 2.02s\n",
      "184:\tlearn: 0.1586597\ttotal: 1.18s\tremaining: 2.01s\n",
      "185:\tlearn: 0.1578097\ttotal: 1.19s\tremaining: 2.01s\n",
      "186:\tlearn: 0.1571202\ttotal: 1.2s\tremaining: 2.01s\n",
      "187:\tlearn: 0.1562360\ttotal: 1.21s\tremaining: 2.01s\n",
      "188:\tlearn: 0.1553909\ttotal: 1.22s\tremaining: 2.01s\n",
      "189:\tlearn: 0.1544397\ttotal: 1.23s\tremaining: 2.01s\n",
      "190:\tlearn: 0.1536822\ttotal: 1.23s\tremaining: 2s\n",
      "191:\tlearn: 0.1529104\ttotal: 1.24s\tremaining: 1.99s\n",
      "192:\tlearn: 0.1520997\ttotal: 1.24s\tremaining: 1.98s\n",
      "193:\tlearn: 0.1511940\ttotal: 1.25s\tremaining: 1.97s\n",
      "194:\tlearn: 0.1506971\ttotal: 1.25s\tremaining: 1.96s\n",
      "195:\tlearn: 0.1490381\ttotal: 1.25s\tremaining: 1.95s\n",
      "196:\tlearn: 0.1481231\ttotal: 1.26s\tremaining: 1.94s\n",
      "197:\tlearn: 0.1474184\ttotal: 1.27s\tremaining: 1.93s\n",
      "198:\tlearn: 0.1463913\ttotal: 1.27s\tremaining: 1.92s\n",
      "199:\tlearn: 0.1451639\ttotal: 1.27s\tremaining: 1.91s\n",
      "200:\tlearn: 0.1435568\ttotal: 1.28s\tremaining: 1.91s\n",
      "201:\tlearn: 0.1426238\ttotal: 1.28s\tremaining: 1.9s\n",
      "202:\tlearn: 0.1417523\ttotal: 1.29s\tremaining: 1.89s\n",
      "203:\tlearn: 0.1408974\ttotal: 1.3s\tremaining: 1.88s\n",
      "204:\tlearn: 0.1402292\ttotal: 1.3s\tremaining: 1.87s\n",
      "205:\tlearn: 0.1389617\ttotal: 1.31s\tremaining: 1.86s\n",
      "206:\tlearn: 0.1381651\ttotal: 1.31s\tremaining: 1.86s\n",
      "207:\tlearn: 0.1375620\ttotal: 1.32s\tremaining: 1.85s\n",
      "208:\tlearn: 0.1368715\ttotal: 1.32s\tremaining: 1.84s\n",
      "209:\tlearn: 0.1360101\ttotal: 1.33s\tremaining: 1.83s\n",
      "210:\tlearn: 0.1349500\ttotal: 1.33s\tremaining: 1.83s\n",
      "211:\tlearn: 0.1342101\ttotal: 1.34s\tremaining: 1.82s\n",
      "212:\tlearn: 0.1335831\ttotal: 1.34s\tremaining: 1.81s\n",
      "213:\tlearn: 0.1329613\ttotal: 1.35s\tremaining: 1.8s\n",
      "214:\tlearn: 0.1322528\ttotal: 1.35s\tremaining: 1.79s\n",
      "215:\tlearn: 0.1315473\ttotal: 1.35s\tremaining: 1.78s\n",
      "216:\tlearn: 0.1307608\ttotal: 1.36s\tremaining: 1.77s\n",
      "217:\tlearn: 0.1295954\ttotal: 1.36s\tremaining: 1.76s\n",
      "218:\tlearn: 0.1289099\ttotal: 1.37s\tremaining: 1.76s\n",
      "219:\tlearn: 0.1281969\ttotal: 1.37s\tremaining: 1.75s\n",
      "220:\tlearn: 0.1275372\ttotal: 1.38s\tremaining: 1.74s\n",
      "221:\tlearn: 0.1269345\ttotal: 1.38s\tremaining: 1.73s\n",
      "222:\tlearn: 0.1263908\ttotal: 1.39s\tremaining: 1.72s\n",
      "223:\tlearn: 0.1256791\ttotal: 1.39s\tremaining: 1.72s\n",
      "224:\tlearn: 0.1250859\ttotal: 1.4s\tremaining: 1.71s\n",
      "225:\tlearn: 0.1246012\ttotal: 1.4s\tremaining: 1.7s\n",
      "226:\tlearn: 0.1238840\ttotal: 1.41s\tremaining: 1.69s\n",
      "227:\tlearn: 0.1233152\ttotal: 1.41s\tremaining: 1.68s\n",
      "228:\tlearn: 0.1225048\ttotal: 1.42s\tremaining: 1.68s\n",
      "229:\tlearn: 0.1218913\ttotal: 1.42s\tremaining: 1.67s\n",
      "230:\tlearn: 0.1213251\ttotal: 1.43s\tremaining: 1.66s\n",
      "231:\tlearn: 0.1205717\ttotal: 1.44s\tremaining: 1.66s\n",
      "232:\tlearn: 0.1201131\ttotal: 1.44s\tremaining: 1.65s\n",
      "233:\tlearn: 0.1193993\ttotal: 1.45s\tremaining: 1.65s\n",
      "234:\tlearn: 0.1188963\ttotal: 1.45s\tremaining: 1.64s\n",
      "235:\tlearn: 0.1183479\ttotal: 1.46s\tremaining: 1.63s\n",
      "236:\tlearn: 0.1176985\ttotal: 1.47s\tremaining: 1.63s\n",
      "237:\tlearn: 0.1169883\ttotal: 1.47s\tremaining: 1.62s\n",
      "238:\tlearn: 0.1159801\ttotal: 1.48s\tremaining: 1.61s\n",
      "239:\tlearn: 0.1154655\ttotal: 1.48s\tremaining: 1.61s\n",
      "240:\tlearn: 0.1148511\ttotal: 1.49s\tremaining: 1.6s\n",
      "241:\tlearn: 0.1141062\ttotal: 1.49s\tremaining: 1.59s\n",
      "242:\tlearn: 0.1135533\ttotal: 1.5s\tremaining: 1.58s\n",
      "243:\tlearn: 0.1130032\ttotal: 1.5s\tremaining: 1.57s\n",
      "244:\tlearn: 0.1122880\ttotal: 1.5s\tremaining: 1.56s\n",
      "245:\tlearn: 0.1115125\ttotal: 1.51s\tremaining: 1.56s\n",
      "246:\tlearn: 0.1108996\ttotal: 1.51s\tremaining: 1.55s\n",
      "247:\tlearn: 0.1103319\ttotal: 1.52s\tremaining: 1.54s\n",
      "248:\tlearn: 0.1096741\ttotal: 1.52s\tremaining: 1.54s\n",
      "249:\tlearn: 0.1089755\ttotal: 1.53s\tremaining: 1.53s\n",
      "250:\tlearn: 0.1084580\ttotal: 1.54s\tremaining: 1.53s\n",
      "251:\tlearn: 0.1076012\ttotal: 1.55s\tremaining: 1.53s\n",
      "252:\tlearn: 0.1069867\ttotal: 1.56s\tremaining: 1.53s\n",
      "253:\tlearn: 0.1061579\ttotal: 1.57s\tremaining: 1.52s\n",
      "254:\tlearn: 0.1055447\ttotal: 1.58s\tremaining: 1.52s\n",
      "255:\tlearn: 0.1047952\ttotal: 1.59s\tremaining: 1.52s\n",
      "256:\tlearn: 0.1033460\ttotal: 1.6s\tremaining: 1.51s\n",
      "257:\tlearn: 0.1027615\ttotal: 1.61s\tremaining: 1.51s\n",
      "258:\tlearn: 0.1022174\ttotal: 1.61s\tremaining: 1.5s\n",
      "259:\tlearn: 0.1017442\ttotal: 1.62s\tremaining: 1.5s\n",
      "260:\tlearn: 0.1011772\ttotal: 1.63s\tremaining: 1.49s\n",
      "261:\tlearn: 0.1006401\ttotal: 1.63s\tremaining: 1.48s\n",
      "262:\tlearn: 0.1001077\ttotal: 1.64s\tremaining: 1.48s\n",
      "263:\tlearn: 0.0994601\ttotal: 1.64s\tremaining: 1.47s\n",
      "264:\tlearn: 0.0986134\ttotal: 1.65s\tremaining: 1.46s\n",
      "265:\tlearn: 0.0980425\ttotal: 1.65s\tremaining: 1.45s\n",
      "266:\tlearn: 0.0975809\ttotal: 1.66s\tremaining: 1.44s\n",
      "267:\tlearn: 0.0970508\ttotal: 1.66s\tremaining: 1.44s\n",
      "268:\tlearn: 0.0966209\ttotal: 1.67s\tremaining: 1.43s\n",
      "269:\tlearn: 0.0958318\ttotal: 1.67s\tremaining: 1.42s\n",
      "270:\tlearn: 0.0952421\ttotal: 1.67s\tremaining: 1.41s\n",
      "271:\tlearn: 0.0946811\ttotal: 1.68s\tremaining: 1.41s\n",
      "272:\tlearn: 0.0942137\ttotal: 1.68s\tremaining: 1.4s\n",
      "273:\tlearn: 0.0937962\ttotal: 1.69s\tremaining: 1.39s\n",
      "274:\tlearn: 0.0933513\ttotal: 1.7s\tremaining: 1.39s\n",
      "275:\tlearn: 0.0929074\ttotal: 1.71s\tremaining: 1.39s\n",
      "276:\tlearn: 0.0923584\ttotal: 1.72s\tremaining: 1.38s\n",
      "277:\tlearn: 0.0919070\ttotal: 1.73s\tremaining: 1.38s\n",
      "278:\tlearn: 0.0910907\ttotal: 1.74s\tremaining: 1.38s\n",
      "279:\tlearn: 0.0906592\ttotal: 1.75s\tremaining: 1.37s\n",
      "280:\tlearn: 0.0902419\ttotal: 1.76s\tremaining: 1.37s\n",
      "281:\tlearn: 0.0899818\ttotal: 1.77s\tremaining: 1.36s\n",
      "282:\tlearn: 0.0895678\ttotal: 1.78s\tremaining: 1.36s\n",
      "283:\tlearn: 0.0893943\ttotal: 1.79s\tremaining: 1.36s\n",
      "284:\tlearn: 0.0889239\ttotal: 1.8s\tremaining: 1.36s\n",
      "285:\tlearn: 0.0884614\ttotal: 1.81s\tremaining: 1.35s\n",
      "286:\tlearn: 0.0880624\ttotal: 1.81s\tremaining: 1.34s\n",
      "287:\tlearn: 0.0876450\ttotal: 1.82s\tremaining: 1.34s\n",
      "288:\tlearn: 0.0872523\ttotal: 1.82s\tremaining: 1.33s\n",
      "289:\tlearn: 0.0867885\ttotal: 1.83s\tremaining: 1.32s\n",
      "290:\tlearn: 0.0863582\ttotal: 1.83s\tremaining: 1.32s\n",
      "291:\tlearn: 0.0859024\ttotal: 1.84s\tremaining: 1.31s\n",
      "292:\tlearn: 0.0855978\ttotal: 1.84s\tremaining: 1.3s\n",
      "293:\tlearn: 0.0850936\ttotal: 1.84s\tremaining: 1.29s\n",
      "294:\tlearn: 0.0847542\ttotal: 1.85s\tremaining: 1.28s\n",
      "295:\tlearn: 0.0843727\ttotal: 1.85s\tremaining: 1.28s\n",
      "296:\tlearn: 0.0837719\ttotal: 1.86s\tremaining: 1.27s\n",
      "297:\tlearn: 0.0833372\ttotal: 1.87s\tremaining: 1.27s\n",
      "298:\tlearn: 0.0829001\ttotal: 1.88s\tremaining: 1.27s\n",
      "299:\tlearn: 0.0825198\ttotal: 1.89s\tremaining: 1.26s\n",
      "300:\tlearn: 0.0821631\ttotal: 1.9s\tremaining: 1.26s\n",
      "301:\tlearn: 0.0817842\ttotal: 1.91s\tremaining: 1.25s\n",
      "302:\tlearn: 0.0813215\ttotal: 1.92s\tremaining: 1.25s\n",
      "303:\tlearn: 0.0809211\ttotal: 1.93s\tremaining: 1.25s\n",
      "304:\tlearn: 0.0803876\ttotal: 1.94s\tremaining: 1.24s\n",
      "305:\tlearn: 0.0799666\ttotal: 1.95s\tremaining: 1.24s\n",
      "306:\tlearn: 0.0795254\ttotal: 1.96s\tremaining: 1.23s\n",
      "307:\tlearn: 0.0791086\ttotal: 1.97s\tremaining: 1.23s\n",
      "308:\tlearn: 0.0787054\ttotal: 1.97s\tremaining: 1.22s\n",
      "309:\tlearn: 0.0783430\ttotal: 1.98s\tremaining: 1.21s\n",
      "310:\tlearn: 0.0780795\ttotal: 1.98s\tremaining: 1.21s\n",
      "311:\tlearn: 0.0776926\ttotal: 1.99s\tremaining: 1.2s\n",
      "312:\tlearn: 0.0774065\ttotal: 2s\tremaining: 1.19s\n",
      "313:\tlearn: 0.0770518\ttotal: 2s\tremaining: 1.19s\n",
      "314:\tlearn: 0.0767099\ttotal: 2.01s\tremaining: 1.18s\n",
      "315:\tlearn: 0.0761470\ttotal: 2.01s\tremaining: 1.17s\n",
      "316:\tlearn: 0.0757869\ttotal: 2.02s\tremaining: 1.16s\n",
      "317:\tlearn: 0.0754595\ttotal: 2.02s\tremaining: 1.16s\n",
      "318:\tlearn: 0.0752068\ttotal: 2.03s\tremaining: 1.15s\n",
      "319:\tlearn: 0.0748709\ttotal: 2.03s\tremaining: 1.14s\n",
      "320:\tlearn: 0.0744852\ttotal: 2.03s\tremaining: 1.13s\n",
      "321:\tlearn: 0.0741341\ttotal: 2.04s\tremaining: 1.13s\n",
      "322:\tlearn: 0.0738164\ttotal: 2.04s\tremaining: 1.12s\n",
      "323:\tlearn: 0.0733743\ttotal: 2.05s\tremaining: 1.11s\n",
      "324:\tlearn: 0.0730256\ttotal: 2.05s\tremaining: 1.1s\n",
      "325:\tlearn: 0.0727054\ttotal: 2.06s\tremaining: 1.1s\n",
      "326:\tlearn: 0.0723399\ttotal: 2.06s\tremaining: 1.09s\n",
      "327:\tlearn: 0.0720683\ttotal: 2.07s\tremaining: 1.09s\n",
      "328:\tlearn: 0.0717023\ttotal: 2.08s\tremaining: 1.08s\n",
      "329:\tlearn: 0.0714823\ttotal: 2.09s\tremaining: 1.08s\n",
      "330:\tlearn: 0.0711664\ttotal: 2.1s\tremaining: 1.07s\n",
      "331:\tlearn: 0.0708841\ttotal: 2.11s\tremaining: 1.07s\n",
      "332:\tlearn: 0.0705528\ttotal: 2.12s\tremaining: 1.06s\n",
      "333:\tlearn: 0.0702387\ttotal: 2.13s\tremaining: 1.06s\n",
      "334:\tlearn: 0.0699163\ttotal: 2.14s\tremaining: 1.05s\n",
      "335:\tlearn: 0.0695519\ttotal: 2.15s\tremaining: 1.05s\n",
      "336:\tlearn: 0.0691651\ttotal: 2.16s\tremaining: 1.04s\n",
      "337:\tlearn: 0.0687748\ttotal: 2.16s\tremaining: 1.04s\n",
      "338:\tlearn: 0.0684774\ttotal: 2.17s\tremaining: 1.03s\n",
      "339:\tlearn: 0.0679235\ttotal: 2.18s\tremaining: 1.02s\n",
      "340:\tlearn: 0.0676067\ttotal: 2.18s\tremaining: 1.02s\n",
      "341:\tlearn: 0.0672656\ttotal: 2.19s\tremaining: 1.01s\n",
      "342:\tlearn: 0.0667211\ttotal: 2.19s\tremaining: 1s\n",
      "343:\tlearn: 0.0663801\ttotal: 2.2s\tremaining: 996ms\n",
      "344:\tlearn: 0.0659162\ttotal: 2.2s\tremaining: 989ms\n",
      "345:\tlearn: 0.0655759\ttotal: 2.21s\tremaining: 982ms\n",
      "346:\tlearn: 0.0652951\ttotal: 2.21s\tremaining: 974ms\n",
      "347:\tlearn: 0.0650122\ttotal: 2.21s\tremaining: 967ms\n",
      "348:\tlearn: 0.0646066\ttotal: 2.22s\tremaining: 959ms\n",
      "349:\tlearn: 0.0643435\ttotal: 2.22s\tremaining: 952ms\n",
      "350:\tlearn: 0.0639983\ttotal: 2.23s\tremaining: 945ms\n",
      "351:\tlearn: 0.0637547\ttotal: 2.24s\tremaining: 940ms\n",
      "352:\tlearn: 0.0634413\ttotal: 2.25s\tremaining: 936ms\n",
      "353:\tlearn: 0.0631063\ttotal: 2.26s\tremaining: 931ms\n",
      "354:\tlearn: 0.0628881\ttotal: 2.27s\tremaining: 926ms\n",
      "355:\tlearn: 0.0626037\ttotal: 2.27s\tremaining: 921ms\n",
      "356:\tlearn: 0.0621500\ttotal: 2.29s\tremaining: 915ms\n",
      "357:\tlearn: 0.0617933\ttotal: 2.29s\tremaining: 910ms\n",
      "358:\tlearn: 0.0613239\ttotal: 2.3s\tremaining: 905ms\n",
      "359:\tlearn: 0.0610012\ttotal: 2.31s\tremaining: 899ms\n",
      "360:\tlearn: 0.0607693\ttotal: 2.32s\tremaining: 893ms\n",
      "361:\tlearn: 0.0604538\ttotal: 2.33s\tremaining: 886ms\n",
      "362:\tlearn: 0.0602534\ttotal: 2.33s\tremaining: 880ms\n",
      "363:\tlearn: 0.0598889\ttotal: 2.34s\tremaining: 874ms\n",
      "364:\tlearn: 0.0596495\ttotal: 2.34s\tremaining: 867ms\n",
      "365:\tlearn: 0.0593969\ttotal: 2.35s\tremaining: 860ms\n",
      "366:\tlearn: 0.0591211\ttotal: 2.35s\tremaining: 853ms\n",
      "367:\tlearn: 0.0588692\ttotal: 2.36s\tremaining: 846ms\n",
      "368:\tlearn: 0.0585884\ttotal: 2.36s\tremaining: 839ms\n",
      "369:\tlearn: 0.0581152\ttotal: 2.37s\tremaining: 832ms\n",
      "370:\tlearn: 0.0578574\ttotal: 2.37s\tremaining: 825ms\n",
      "371:\tlearn: 0.0576425\ttotal: 2.38s\tremaining: 818ms\n",
      "372:\tlearn: 0.0574970\ttotal: 2.38s\tremaining: 811ms\n",
      "373:\tlearn: 0.0573502\ttotal: 2.38s\tremaining: 804ms\n",
      "374:\tlearn: 0.0570820\ttotal: 2.39s\tremaining: 797ms\n",
      "375:\tlearn: 0.0568515\ttotal: 2.39s\tremaining: 790ms\n",
      "376:\tlearn: 0.0566023\ttotal: 2.4s\tremaining: 785ms\n",
      "377:\tlearn: 0.0563711\ttotal: 2.41s\tremaining: 779ms\n",
      "378:\tlearn: 0.0561805\ttotal: 2.42s\tremaining: 774ms\n",
      "379:\tlearn: 0.0558872\ttotal: 2.43s\tremaining: 769ms\n",
      "380:\tlearn: 0.0556141\ttotal: 2.44s\tremaining: 763ms\n",
      "381:\tlearn: 0.0553956\ttotal: 2.45s\tremaining: 758ms\n",
      "382:\tlearn: 0.0552093\ttotal: 2.46s\tremaining: 752ms\n",
      "383:\tlearn: 0.0549462\ttotal: 2.47s\tremaining: 747ms\n",
      "384:\tlearn: 0.0547142\ttotal: 2.48s\tremaining: 742ms\n",
      "385:\tlearn: 0.0545231\ttotal: 2.49s\tremaining: 736ms\n",
      "386:\tlearn: 0.0542727\ttotal: 2.5s\tremaining: 730ms\n",
      "387:\tlearn: 0.0540209\ttotal: 2.5s\tremaining: 723ms\n",
      "388:\tlearn: 0.0536523\ttotal: 2.51s\tremaining: 717ms\n",
      "389:\tlearn: 0.0534044\ttotal: 2.52s\tremaining: 710ms\n",
      "390:\tlearn: 0.0531525\ttotal: 2.52s\tremaining: 703ms\n",
      "391:\tlearn: 0.0528859\ttotal: 2.53s\tremaining: 696ms\n",
      "392:\tlearn: 0.0525405\ttotal: 2.53s\tremaining: 689ms\n",
      "393:\tlearn: 0.0523284\ttotal: 2.54s\tremaining: 682ms\n",
      "394:\tlearn: 0.0521126\ttotal: 2.54s\tremaining: 675ms\n",
      "395:\tlearn: 0.0518558\ttotal: 2.54s\tremaining: 668ms\n",
      "396:\tlearn: 0.0516449\ttotal: 2.55s\tremaining: 661ms\n",
      "397:\tlearn: 0.0513500\ttotal: 2.55s\tremaining: 655ms\n",
      "398:\tlearn: 0.0511031\ttotal: 2.56s\tremaining: 648ms\n",
      "399:\tlearn: 0.0508344\ttotal: 2.56s\tremaining: 641ms\n",
      "400:\tlearn: 0.0504122\ttotal: 2.57s\tremaining: 634ms\n",
      "401:\tlearn: 0.0502033\ttotal: 2.57s\tremaining: 627ms\n",
      "402:\tlearn: 0.0498907\ttotal: 2.58s\tremaining: 621ms\n",
      "403:\tlearn: 0.0496416\ttotal: 2.59s\tremaining: 616ms\n",
      "404:\tlearn: 0.0494469\ttotal: 2.6s\tremaining: 610ms\n",
      "405:\tlearn: 0.0493358\ttotal: 2.61s\tremaining: 604ms\n",
      "406:\tlearn: 0.0491126\ttotal: 2.62s\tremaining: 599ms\n",
      "407:\tlearn: 0.0489049\ttotal: 2.63s\tremaining: 593ms\n",
      "408:\tlearn: 0.0486535\ttotal: 2.64s\tremaining: 587ms\n",
      "409:\tlearn: 0.0484597\ttotal: 2.65s\tremaining: 581ms\n",
      "410:\tlearn: 0.0483212\ttotal: 2.66s\tremaining: 576ms\n",
      "411:\tlearn: 0.0479309\ttotal: 2.66s\tremaining: 569ms\n",
      "412:\tlearn: 0.0477198\ttotal: 2.67s\tremaining: 563ms\n",
      "413:\tlearn: 0.0474366\ttotal: 2.68s\tremaining: 556ms\n",
      "414:\tlearn: 0.0471942\ttotal: 2.68s\tremaining: 550ms\n",
      "415:\tlearn: 0.0470128\ttotal: 2.69s\tremaining: 543ms\n",
      "416:\tlearn: 0.0467753\ttotal: 2.69s\tremaining: 536ms\n",
      "417:\tlearn: 0.0464091\ttotal: 2.7s\tremaining: 529ms\n",
      "418:\tlearn: 0.0462453\ttotal: 2.7s\tremaining: 523ms\n",
      "419:\tlearn: 0.0461196\ttotal: 2.71s\tremaining: 516ms\n",
      "420:\tlearn: 0.0458800\ttotal: 2.71s\tremaining: 509ms\n",
      "421:\tlearn: 0.0457024\ttotal: 2.72s\tremaining: 502ms\n",
      "422:\tlearn: 0.0455244\ttotal: 2.72s\tremaining: 495ms\n",
      "423:\tlearn: 0.0452594\ttotal: 2.73s\tremaining: 489ms\n",
      "424:\tlearn: 0.0450940\ttotal: 2.73s\tremaining: 482ms\n",
      "425:\tlearn: 0.0448973\ttotal: 2.73s\tremaining: 475ms\n",
      "426:\tlearn: 0.0447235\ttotal: 2.74s\tremaining: 469ms\n",
      "427:\tlearn: 0.0444000\ttotal: 2.75s\tremaining: 463ms\n",
      "428:\tlearn: 0.0441984\ttotal: 2.76s\tremaining: 457ms\n",
      "429:\tlearn: 0.0439589\ttotal: 2.77s\tremaining: 452ms\n",
      "430:\tlearn: 0.0437586\ttotal: 2.78s\tremaining: 446ms\n",
      "431:\tlearn: 0.0435385\ttotal: 2.79s\tremaining: 440ms\n",
      "432:\tlearn: 0.0434125\ttotal: 2.8s\tremaining: 434ms\n",
      "433:\tlearn: 0.0432485\ttotal: 2.81s\tremaining: 428ms\n",
      "434:\tlearn: 0.0430163\ttotal: 2.82s\tremaining: 422ms\n",
      "435:\tlearn: 0.0428314\ttotal: 2.83s\tremaining: 415ms\n",
      "436:\tlearn: 0.0426701\ttotal: 2.83s\tremaining: 408ms\n",
      "437:\tlearn: 0.0424624\ttotal: 2.84s\tremaining: 402ms\n",
      "438:\tlearn: 0.0422534\ttotal: 2.84s\tremaining: 395ms\n",
      "439:\tlearn: 0.0420723\ttotal: 2.85s\tremaining: 388ms\n",
      "440:\tlearn: 0.0418802\ttotal: 2.85s\tremaining: 382ms\n",
      "441:\tlearn: 0.0417034\ttotal: 2.86s\tremaining: 375ms\n",
      "442:\tlearn: 0.0415319\ttotal: 2.86s\tremaining: 368ms\n",
      "443:\tlearn: 0.0413582\ttotal: 2.87s\tremaining: 361ms\n",
      "444:\tlearn: 0.0411585\ttotal: 2.87s\tremaining: 355ms\n",
      "445:\tlearn: 0.0409535\ttotal: 2.87s\tremaining: 348ms\n",
      "446:\tlearn: 0.0407756\ttotal: 2.88s\tremaining: 342ms\n",
      "447:\tlearn: 0.0405351\ttotal: 2.89s\tremaining: 336ms\n",
      "448:\tlearn: 0.0403948\ttotal: 2.9s\tremaining: 330ms\n",
      "449:\tlearn: 0.0402199\ttotal: 2.91s\tremaining: 324ms\n",
      "450:\tlearn: 0.0399971\ttotal: 2.92s\tremaining: 318ms\n",
      "451:\tlearn: 0.0397980\ttotal: 2.93s\tremaining: 311ms\n",
      "452:\tlearn: 0.0395961\ttotal: 2.94s\tremaining: 305ms\n",
      "453:\tlearn: 0.0394104\ttotal: 2.95s\tremaining: 299ms\n",
      "454:\tlearn: 0.0392304\ttotal: 2.96s\tremaining: 293ms\n",
      "455:\tlearn: 0.0390611\ttotal: 2.97s\tremaining: 286ms\n",
      "456:\tlearn: 0.0389895\ttotal: 2.98s\tremaining: 280ms\n",
      "457:\tlearn: 0.0388978\ttotal: 2.98s\tremaining: 274ms\n",
      "458:\tlearn: 0.0388136\ttotal: 2.99s\tremaining: 267ms\n",
      "459:\tlearn: 0.0385055\ttotal: 3s\tremaining: 261ms\n",
      "460:\tlearn: 0.0383100\ttotal: 3s\tremaining: 254ms\n",
      "461:\tlearn: 0.0380845\ttotal: 3s\tremaining: 247ms\n",
      "462:\tlearn: 0.0379271\ttotal: 3.01s\tremaining: 241ms\n",
      "463:\tlearn: 0.0377041\ttotal: 3.01s\tremaining: 234ms\n",
      "464:\tlearn: 0.0375248\ttotal: 3.02s\tremaining: 227ms\n",
      "465:\tlearn: 0.0373555\ttotal: 3.02s\tremaining: 221ms\n",
      "466:\tlearn: 0.0371804\ttotal: 3.03s\tremaining: 214ms\n",
      "467:\tlearn: 0.0370206\ttotal: 3.03s\tremaining: 207ms\n",
      "468:\tlearn: 0.0368470\ttotal: 3.04s\tremaining: 201ms\n",
      "469:\tlearn: 0.0367145\ttotal: 3.04s\tremaining: 194ms\n",
      "470:\tlearn: 0.0365754\ttotal: 3.04s\tremaining: 187ms\n",
      "471:\tlearn: 0.0364086\ttotal: 3.05s\tremaining: 181ms\n",
      "472:\tlearn: 0.0362027\ttotal: 3.06s\tremaining: 175ms\n",
      "473:\tlearn: 0.0360576\ttotal: 3.07s\tremaining: 168ms\n",
      "474:\tlearn: 0.0358721\ttotal: 3.08s\tremaining: 162ms\n",
      "475:\tlearn: 0.0357294\ttotal: 3.09s\tremaining: 156ms\n",
      "476:\tlearn: 0.0355127\ttotal: 3.1s\tremaining: 149ms\n",
      "477:\tlearn: 0.0353537\ttotal: 3.11s\tremaining: 143ms\n",
      "478:\tlearn: 0.0352259\ttotal: 3.12s\tremaining: 137ms\n",
      "479:\tlearn: 0.0350740\ttotal: 3.13s\tremaining: 130ms\n",
      "480:\tlearn: 0.0348744\ttotal: 3.13s\tremaining: 124ms\n",
      "481:\tlearn: 0.0347317\ttotal: 3.14s\tremaining: 117ms\n",
      "482:\tlearn: 0.0345581\ttotal: 3.15s\tremaining: 111ms\n",
      "483:\tlearn: 0.0343372\ttotal: 3.16s\tremaining: 104ms\n",
      "484:\tlearn: 0.0342102\ttotal: 3.16s\tremaining: 97.9ms\n",
      "485:\tlearn: 0.0340790\ttotal: 3.17s\tremaining: 91.3ms\n",
      "486:\tlearn: 0.0338765\ttotal: 3.18s\tremaining: 84.8ms\n",
      "487:\tlearn: 0.0336584\ttotal: 3.18s\tremaining: 78.2ms\n",
      "488:\tlearn: 0.0334928\ttotal: 3.19s\tremaining: 71.7ms\n",
      "489:\tlearn: 0.0333567\ttotal: 3.19s\tremaining: 65.1ms\n",
      "490:\tlearn: 0.0332606\ttotal: 3.19s\tremaining: 58.6ms\n",
      "491:\tlearn: 0.0331248\ttotal: 3.2s\tremaining: 52ms\n",
      "492:\tlearn: 0.0329382\ttotal: 3.2s\tremaining: 45.5ms\n",
      "493:\tlearn: 0.0328081\ttotal: 3.21s\tremaining: 39ms\n",
      "494:\tlearn: 0.0326699\ttotal: 3.21s\tremaining: 32.4ms\n",
      "495:\tlearn: 0.0325064\ttotal: 3.22s\tremaining: 25.9ms\n",
      "496:\tlearn: 0.0323760\ttotal: 3.22s\tremaining: 19.4ms\n",
      "497:\tlearn: 0.0322237\ttotal: 3.23s\tremaining: 13ms\n",
      "498:\tlearn: 0.0320296\ttotal: 3.24s\tremaining: 6.49ms\n",
      "499:\tlearn: 0.0318852\ttotal: 3.25s\tremaining: 0us\n",
      "0:\tlearn: 0.6878648\ttotal: 97.2ms\tremaining: 9.63s\n",
      "1:\tlearn: 0.6823808\ttotal: 238ms\tremaining: 11.7s\n",
      "2:\tlearn: 0.6775208\ttotal: 367ms\tremaining: 11.9s\n",
      "3:\tlearn: 0.6721228\ttotal: 442ms\tremaining: 10.6s\n",
      "4:\tlearn: 0.6670923\ttotal: 512ms\tremaining: 9.73s\n",
      "5:\tlearn: 0.6625727\ttotal: 659ms\tremaining: 10.3s\n",
      "6:\tlearn: 0.6567108\ttotal: 806ms\tremaining: 10.7s\n",
      "7:\tlearn: 0.6525579\ttotal: 925ms\tremaining: 10.6s\n",
      "8:\tlearn: 0.6491206\ttotal: 1.02s\tremaining: 10.3s\n",
      "9:\tlearn: 0.6450339\ttotal: 1.18s\tremaining: 10.6s\n",
      "10:\tlearn: 0.6397202\ttotal: 1.28s\tremaining: 10.3s\n",
      "11:\tlearn: 0.6355786\ttotal: 1.38s\tremaining: 10.1s\n",
      "12:\tlearn: 0.6306785\ttotal: 1.54s\tremaining: 10.3s\n",
      "13:\tlearn: 0.6251750\ttotal: 1.67s\tremaining: 10.2s\n",
      "14:\tlearn: 0.6208685\ttotal: 1.79s\tremaining: 10.1s\n",
      "15:\tlearn: 0.6158872\ttotal: 1.9s\tremaining: 9.98s\n",
      "16:\tlearn: 0.6120856\ttotal: 2.01s\tremaining: 9.83s\n",
      "17:\tlearn: 0.6075468\ttotal: 2.18s\tremaining: 9.95s\n",
      "18:\tlearn: 0.6028283\ttotal: 2.32s\tremaining: 9.91s\n",
      "19:\tlearn: 0.5984836\ttotal: 2.43s\tremaining: 9.72s\n",
      "20:\tlearn: 0.5943145\ttotal: 2.54s\tremaining: 9.58s\n",
      "21:\tlearn: 0.5902276\ttotal: 2.67s\tremaining: 9.47s\n",
      "22:\tlearn: 0.5856722\ttotal: 2.82s\tremaining: 9.45s\n",
      "23:\tlearn: 0.5820360\ttotal: 2.98s\tremaining: 9.42s\n",
      "24:\tlearn: 0.5782973\ttotal: 3.06s\tremaining: 9.18s\n",
      "25:\tlearn: 0.5739658\ttotal: 3.2s\tremaining: 9.11s\n",
      "26:\tlearn: 0.5688887\ttotal: 3.35s\tremaining: 9.06s\n",
      "27:\tlearn: 0.5648029\ttotal: 3.44s\tremaining: 8.85s\n",
      "28:\tlearn: 0.5607764\ttotal: 3.55s\tremaining: 8.7s\n",
      "29:\tlearn: 0.5567522\ttotal: 3.69s\tremaining: 8.61s\n",
      "30:\tlearn: 0.5526360\ttotal: 3.83s\tremaining: 8.52s\n",
      "31:\tlearn: 0.5487657\ttotal: 3.91s\tremaining: 8.3s\n",
      "32:\tlearn: 0.5441983\ttotal: 4.05s\tremaining: 8.23s\n",
      "33:\tlearn: 0.5403356\ttotal: 4.18s\tremaining: 8.12s\n",
      "34:\tlearn: 0.5373666\ttotal: 4.26s\tremaining: 7.92s\n",
      "35:\tlearn: 0.5328389\ttotal: 4.39s\tremaining: 7.81s\n",
      "36:\tlearn: 0.5292467\ttotal: 4.5s\tremaining: 7.66s\n",
      "37:\tlearn: 0.5262745\ttotal: 4.61s\tremaining: 7.51s\n",
      "38:\tlearn: 0.5230352\ttotal: 4.76s\tremaining: 7.45s\n",
      "39:\tlearn: 0.5193041\ttotal: 4.9s\tremaining: 7.35s\n",
      "40:\tlearn: 0.5158886\ttotal: 4.98s\tremaining: 7.17s\n",
      "41:\tlearn: 0.5118516\ttotal: 5.14s\tremaining: 7.09s\n",
      "42:\tlearn: 0.5086552\ttotal: 5.3s\tremaining: 7.03s\n",
      "43:\tlearn: 0.5048233\ttotal: 5.36s\tremaining: 6.83s\n",
      "44:\tlearn: 0.5020178\ttotal: 5.51s\tremaining: 6.74s\n",
      "45:\tlearn: 0.4988486\ttotal: 5.65s\tremaining: 6.63s\n",
      "46:\tlearn: 0.4961058\ttotal: 5.75s\tremaining: 6.48s\n",
      "47:\tlearn: 0.4932768\ttotal: 5.89s\tremaining: 6.38s\n",
      "48:\tlearn: 0.4903377\ttotal: 6.04s\tremaining: 6.29s\n",
      "49:\tlearn: 0.4872593\ttotal: 6.17s\tremaining: 6.17s\n",
      "50:\tlearn: 0.4836892\ttotal: 6.26s\tremaining: 6.01s\n",
      "51:\tlearn: 0.4809288\ttotal: 6.41s\tremaining: 5.92s\n",
      "52:\tlearn: 0.4775908\ttotal: 6.56s\tremaining: 5.82s\n",
      "53:\tlearn: 0.4741765\ttotal: 6.67s\tremaining: 5.68s\n",
      "54:\tlearn: 0.4713685\ttotal: 6.79s\tremaining: 5.55s\n",
      "55:\tlearn: 0.4686507\ttotal: 6.93s\tremaining: 5.45s\n",
      "56:\tlearn: 0.4661812\ttotal: 7.01s\tremaining: 5.29s\n",
      "57:\tlearn: 0.4633617\ttotal: 7.14s\tremaining: 5.17s\n",
      "58:\tlearn: 0.4604930\ttotal: 7.29s\tremaining: 5.07s\n",
      "59:\tlearn: 0.4576617\ttotal: 7.43s\tremaining: 4.95s\n",
      "60:\tlearn: 0.4550301\ttotal: 7.51s\tremaining: 4.8s\n",
      "61:\tlearn: 0.4526796\ttotal: 7.67s\tremaining: 4.7s\n",
      "62:\tlearn: 0.4498011\ttotal: 7.82s\tremaining: 4.59s\n",
      "63:\tlearn: 0.4455085\ttotal: 7.93s\tremaining: 4.46s\n",
      "64:\tlearn: 0.4427657\ttotal: 8.05s\tremaining: 4.33s\n",
      "65:\tlearn: 0.4393959\ttotal: 8.17s\tremaining: 4.21s\n",
      "66:\tlearn: 0.4367753\ttotal: 8.22s\tremaining: 4.05s\n",
      "67:\tlearn: 0.4340255\ttotal: 8.32s\tremaining: 3.92s\n",
      "68:\tlearn: 0.4313871\ttotal: 8.45s\tremaining: 3.8s\n",
      "69:\tlearn: 0.4288486\ttotal: 8.52s\tremaining: 3.65s\n",
      "70:\tlearn: 0.4246684\ttotal: 8.66s\tremaining: 3.54s\n",
      "71:\tlearn: 0.4223953\ttotal: 8.74s\tremaining: 3.4s\n",
      "72:\tlearn: 0.4200972\ttotal: 8.89s\tremaining: 3.29s\n",
      "73:\tlearn: 0.4174926\ttotal: 9.03s\tremaining: 3.17s\n",
      "74:\tlearn: 0.4152818\ttotal: 9.13s\tremaining: 3.04s\n",
      "75:\tlearn: 0.4123956\ttotal: 9.26s\tremaining: 2.92s\n",
      "76:\tlearn: 0.4106757\ttotal: 9.39s\tremaining: 2.8s\n",
      "77:\tlearn: 0.4082724\ttotal: 9.47s\tremaining: 2.67s\n",
      "78:\tlearn: 0.4052741\ttotal: 9.61s\tremaining: 2.55s\n",
      "79:\tlearn: 0.4030487\ttotal: 9.75s\tremaining: 2.44s\n",
      "80:\tlearn: 0.4012310\ttotal: 9.87s\tremaining: 2.31s\n",
      "81:\tlearn: 0.3984831\ttotal: 9.97s\tremaining: 2.19s\n",
      "82:\tlearn: 0.3955846\ttotal: 10.1s\tremaining: 2.07s\n",
      "83:\tlearn: 0.3924555\ttotal: 10.2s\tremaining: 1.94s\n",
      "84:\tlearn: 0.3906335\ttotal: 10.3s\tremaining: 1.82s\n",
      "85:\tlearn: 0.3880924\ttotal: 10.5s\tremaining: 1.71s\n",
      "86:\tlearn: 0.3861921\ttotal: 10.6s\tremaining: 1.58s\n",
      "87:\tlearn: 0.3835766\ttotal: 10.7s\tremaining: 1.46s\n",
      "88:\tlearn: 0.3817551\ttotal: 10.8s\tremaining: 1.34s\n",
      "89:\tlearn: 0.3793890\ttotal: 10.9s\tremaining: 1.22s\n",
      "90:\tlearn: 0.3773622\ttotal: 11.1s\tremaining: 1.09s\n",
      "91:\tlearn: 0.3749657\ttotal: 11.2s\tremaining: 973ms\n",
      "92:\tlearn: 0.3728075\ttotal: 11.3s\tremaining: 852ms\n",
      "93:\tlearn: 0.3701267\ttotal: 11.4s\tremaining: 728ms\n",
      "94:\tlearn: 0.3677073\ttotal: 11.5s\tremaining: 606ms\n",
      "95:\tlearn: 0.3653491\ttotal: 11.6s\tremaining: 485ms\n",
      "96:\tlearn: 0.3627942\ttotal: 11.8s\tremaining: 365ms\n",
      "97:\tlearn: 0.3607627\ttotal: 11.9s\tremaining: 243ms\n",
      "98:\tlearn: 0.3580673\ttotal: 12s\tremaining: 122ms\n",
      "99:\tlearn: 0.3552941\ttotal: 12.2s\tremaining: 0us\n",
      "0:\tlearn: 0.6876388\ttotal: 82.9ms\tremaining: 8.21s\n",
      "1:\tlearn: 0.6826559\ttotal: 189ms\tremaining: 9.26s\n",
      "2:\tlearn: 0.6769698\ttotal: 328ms\tremaining: 10.6s\n",
      "3:\tlearn: 0.6705937\ttotal: 417ms\tremaining: 10s\n",
      "4:\tlearn: 0.6654349\ttotal: 552ms\tremaining: 10.5s\n",
      "5:\tlearn: 0.6601499\ttotal: 674ms\tremaining: 10.6s\n",
      "6:\tlearn: 0.6539399\ttotal: 769ms\tremaining: 10.2s\n",
      "7:\tlearn: 0.6489388\ttotal: 883ms\tremaining: 10.2s\n",
      "8:\tlearn: 0.6433835\ttotal: 1.03s\tremaining: 10.5s\n",
      "9:\tlearn: 0.6397886\ttotal: 1.17s\tremaining: 10.5s\n",
      "10:\tlearn: 0.6352525\ttotal: 1.25s\tremaining: 10.1s\n",
      "11:\tlearn: 0.6308068\ttotal: 1.37s\tremaining: 10s\n",
      "12:\tlearn: 0.6263820\ttotal: 1.51s\tremaining: 10.1s\n",
      "13:\tlearn: 0.6214352\ttotal: 1.65s\tremaining: 10.1s\n",
      "14:\tlearn: 0.6172293\ttotal: 1.79s\tremaining: 10.2s\n",
      "15:\tlearn: 0.6130779\ttotal: 1.93s\tremaining: 10.1s\n",
      "16:\tlearn: 0.6086387\ttotal: 2.07s\tremaining: 10.1s\n",
      "17:\tlearn: 0.6039621\ttotal: 2.15s\tremaining: 9.77s\n",
      "18:\tlearn: 0.5998352\ttotal: 2.28s\tremaining: 9.73s\n",
      "19:\tlearn: 0.5955340\ttotal: 2.44s\tremaining: 9.75s\n",
      "20:\tlearn: 0.5913659\ttotal: 2.56s\tremaining: 9.62s\n",
      "21:\tlearn: 0.5875111\ttotal: 2.66s\tremaining: 9.44s\n",
      "22:\tlearn: 0.5835447\ttotal: 2.82s\tremaining: 9.43s\n",
      "23:\tlearn: 0.5796060\ttotal: 2.96s\tremaining: 9.39s\n",
      "24:\tlearn: 0.5746113\ttotal: 3.08s\tremaining: 9.24s\n",
      "25:\tlearn: 0.5700730\ttotal: 3.18s\tremaining: 9.06s\n",
      "26:\tlearn: 0.5648926\ttotal: 3.34s\tremaining: 9.03s\n",
      "27:\tlearn: 0.5604026\ttotal: 3.48s\tremaining: 8.95s\n",
      "28:\tlearn: 0.5554177\ttotal: 3.58s\tremaining: 8.78s\n",
      "29:\tlearn: 0.5510936\ttotal: 3.71s\tremaining: 8.66s\n",
      "30:\tlearn: 0.5466109\ttotal: 3.85s\tremaining: 8.57s\n",
      "31:\tlearn: 0.5421690\ttotal: 3.99s\tremaining: 8.48s\n",
      "32:\tlearn: 0.5391598\ttotal: 4.08s\tremaining: 8.28s\n",
      "33:\tlearn: 0.5349910\ttotal: 4.24s\tremaining: 8.23s\n",
      "34:\tlearn: 0.5305266\ttotal: 4.39s\tremaining: 8.15s\n",
      "35:\tlearn: 0.5266862\ttotal: 4.46s\tremaining: 7.93s\n",
      "36:\tlearn: 0.5226147\ttotal: 4.59s\tremaining: 7.81s\n",
      "37:\tlearn: 0.5181904\ttotal: 4.74s\tremaining: 7.74s\n",
      "38:\tlearn: 0.5154235\ttotal: 4.87s\tremaining: 7.61s\n",
      "39:\tlearn: 0.5117952\ttotal: 4.95s\tremaining: 7.42s\n",
      "40:\tlearn: 0.5081745\ttotal: 5.09s\tremaining: 7.33s\n",
      "41:\tlearn: 0.5050045\ttotal: 5.25s\tremaining: 7.25s\n",
      "42:\tlearn: 0.5003785\ttotal: 5.4s\tremaining: 7.16s\n",
      "43:\tlearn: 0.4969001\ttotal: 5.47s\tremaining: 6.96s\n",
      "44:\tlearn: 0.4943031\ttotal: 5.62s\tremaining: 6.87s\n",
      "45:\tlearn: 0.4901012\ttotal: 5.77s\tremaining: 6.77s\n",
      "46:\tlearn: 0.4852733\ttotal: 5.85s\tremaining: 6.59s\n",
      "47:\tlearn: 0.4818563\ttotal: 6.04s\tremaining: 6.55s\n",
      "48:\tlearn: 0.4779190\ttotal: 6.18s\tremaining: 6.43s\n",
      "49:\tlearn: 0.4746513\ttotal: 6.3s\tremaining: 6.3s\n",
      "50:\tlearn: 0.4709918\ttotal: 6.41s\tremaining: 6.16s\n",
      "51:\tlearn: 0.4681482\ttotal: 6.52s\tremaining: 6.02s\n",
      "52:\tlearn: 0.4652831\ttotal: 6.67s\tremaining: 5.91s\n",
      "53:\tlearn: 0.4621276\ttotal: 6.75s\tremaining: 5.75s\n",
      "54:\tlearn: 0.4591535\ttotal: 6.88s\tremaining: 5.63s\n",
      "55:\tlearn: 0.4562464\ttotal: 7.02s\tremaining: 5.51s\n",
      "56:\tlearn: 0.4542738\ttotal: 7.15s\tremaining: 5.39s\n",
      "57:\tlearn: 0.4513174\ttotal: 7.23s\tremaining: 5.23s\n",
      "58:\tlearn: 0.4479153\ttotal: 7.38s\tremaining: 5.13s\n",
      "59:\tlearn: 0.4454853\ttotal: 7.51s\tremaining: 5.01s\n",
      "60:\tlearn: 0.4435350\ttotal: 7.61s\tremaining: 4.87s\n",
      "61:\tlearn: 0.4409283\ttotal: 7.76s\tremaining: 4.76s\n",
      "62:\tlearn: 0.4382148\ttotal: 7.92s\tremaining: 4.65s\n",
      "63:\tlearn: 0.4356799\ttotal: 8.05s\tremaining: 4.53s\n",
      "64:\tlearn: 0.4330434\ttotal: 8.14s\tremaining: 4.38s\n",
      "65:\tlearn: 0.4300693\ttotal: 8.29s\tremaining: 4.27s\n",
      "66:\tlearn: 0.4278022\ttotal: 8.44s\tremaining: 4.16s\n",
      "67:\tlearn: 0.4257623\ttotal: 8.52s\tremaining: 4.01s\n",
      "68:\tlearn: 0.4219344\ttotal: 8.66s\tremaining: 3.89s\n",
      "69:\tlearn: 0.4195720\ttotal: 8.81s\tremaining: 3.78s\n",
      "70:\tlearn: 0.4169224\ttotal: 8.92s\tremaining: 3.64s\n",
      "71:\tlearn: 0.4142704\ttotal: 9.02s\tremaining: 3.51s\n",
      "72:\tlearn: 0.4116644\ttotal: 9.18s\tremaining: 3.39s\n",
      "73:\tlearn: 0.4093031\ttotal: 9.31s\tremaining: 3.27s\n",
      "74:\tlearn: 0.4073161\ttotal: 9.4s\tremaining: 3.13s\n",
      "75:\tlearn: 0.4045038\ttotal: 9.55s\tremaining: 3.01s\n",
      "76:\tlearn: 0.4017227\ttotal: 9.68s\tremaining: 2.89s\n",
      "77:\tlearn: 0.3986167\ttotal: 9.76s\tremaining: 2.75s\n",
      "78:\tlearn: 0.3965363\ttotal: 9.93s\tremaining: 2.64s\n",
      "79:\tlearn: 0.3939628\ttotal: 10.1s\tremaining: 2.52s\n",
      "80:\tlearn: 0.3916488\ttotal: 10.2s\tremaining: 2.38s\n",
      "81:\tlearn: 0.3890511\ttotal: 10.3s\tremaining: 2.26s\n",
      "82:\tlearn: 0.3869206\ttotal: 10.4s\tremaining: 2.14s\n",
      "83:\tlearn: 0.3847878\ttotal: 10.5s\tremaining: 2s\n",
      "84:\tlearn: 0.3832207\ttotal: 10.7s\tremaining: 1.88s\n",
      "85:\tlearn: 0.3804493\ttotal: 10.8s\tremaining: 1.76s\n",
      "86:\tlearn: 0.3786765\ttotal: 10.9s\tremaining: 1.63s\n",
      "87:\tlearn: 0.3770164\ttotal: 11s\tremaining: 1.5s\n",
      "88:\tlearn: 0.3746592\ttotal: 11.2s\tremaining: 1.38s\n",
      "89:\tlearn: 0.3727089\ttotal: 11.2s\tremaining: 1.25s\n",
      "90:\tlearn: 0.3710788\ttotal: 11.4s\tremaining: 1.13s\n",
      "91:\tlearn: 0.3687135\ttotal: 11.5s\tremaining: 1s\n",
      "92:\tlearn: 0.3666700\ttotal: 11.6s\tremaining: 873ms\n",
      "93:\tlearn: 0.3639902\ttotal: 11.7s\tremaining: 749ms\n",
      "94:\tlearn: 0.3619491\ttotal: 11.9s\tremaining: 626ms\n",
      "95:\tlearn: 0.3597051\ttotal: 12s\tremaining: 501ms\n",
      "96:\tlearn: 0.3575311\ttotal: 12.1s\tremaining: 375ms\n",
      "97:\tlearn: 0.3552247\ttotal: 12.3s\tremaining: 250ms\n",
      "98:\tlearn: 0.3528618\ttotal: 12.4s\tremaining: 125ms\n",
      "99:\tlearn: 0.3504893\ttotal: 12.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6875813\ttotal: 145ms\tremaining: 14.3s\n",
      "1:\tlearn: 0.6806767\ttotal: 227ms\tremaining: 11.1s\n",
      "2:\tlearn: 0.6756111\ttotal: 354ms\tremaining: 11.4s\n",
      "3:\tlearn: 0.6712687\ttotal: 497ms\tremaining: 11.9s\n",
      "4:\tlearn: 0.6662445\ttotal: 570ms\tremaining: 10.8s\n",
      "5:\tlearn: 0.6612640\ttotal: 718ms\tremaining: 11.2s\n",
      "6:\tlearn: 0.6554586\ttotal: 865ms\tremaining: 11.5s\n",
      "7:\tlearn: 0.6503143\ttotal: 970ms\tremaining: 11.2s\n",
      "8:\tlearn: 0.6463631\ttotal: 1.07s\tremaining: 10.8s\n",
      "9:\tlearn: 0.6424097\ttotal: 1.22s\tremaining: 11s\n",
      "10:\tlearn: 0.6373452\ttotal: 1.37s\tremaining: 11.1s\n",
      "11:\tlearn: 0.6333177\ttotal: 1.51s\tremaining: 11.1s\n",
      "12:\tlearn: 0.6292114\ttotal: 1.6s\tremaining: 10.7s\n",
      "13:\tlearn: 0.6251300\ttotal: 1.75s\tremaining: 10.8s\n",
      "14:\tlearn: 0.6202499\ttotal: 1.89s\tremaining: 10.7s\n",
      "15:\tlearn: 0.6144461\ttotal: 1.97s\tremaining: 10.3s\n",
      "16:\tlearn: 0.6103818\ttotal: 2.11s\tremaining: 10.3s\n",
      "17:\tlearn: 0.6050028\ttotal: 2.24s\tremaining: 10.2s\n",
      "18:\tlearn: 0.6001433\ttotal: 2.32s\tremaining: 9.88s\n",
      "19:\tlearn: 0.5960851\ttotal: 2.48s\tremaining: 9.9s\n",
      "20:\tlearn: 0.5906195\ttotal: 2.63s\tremaining: 9.88s\n",
      "21:\tlearn: 0.5862354\ttotal: 2.77s\tremaining: 9.83s\n",
      "22:\tlearn: 0.5820099\ttotal: 2.85s\tremaining: 9.56s\n",
      "23:\tlearn: 0.5780292\ttotal: 3s\tremaining: 9.51s\n",
      "24:\tlearn: 0.5737764\ttotal: 3.14s\tremaining: 9.42s\n",
      "25:\tlearn: 0.5691631\ttotal: 3.27s\tremaining: 9.29s\n",
      "26:\tlearn: 0.5643484\ttotal: 3.38s\tremaining: 9.14s\n",
      "27:\tlearn: 0.5609686\ttotal: 3.52s\tremaining: 9.06s\n",
      "28:\tlearn: 0.5566397\ttotal: 3.64s\tremaining: 8.91s\n",
      "29:\tlearn: 0.5526202\ttotal: 3.72s\tremaining: 8.67s\n",
      "30:\tlearn: 0.5481377\ttotal: 3.9s\tremaining: 8.69s\n",
      "31:\tlearn: 0.5444713\ttotal: 4.03s\tremaining: 8.56s\n",
      "32:\tlearn: 0.5411643\ttotal: 4.14s\tremaining: 8.4s\n",
      "33:\tlearn: 0.5372625\ttotal: 4.18s\tremaining: 8.12s\n",
      "34:\tlearn: 0.5334663\ttotal: 4.23s\tremaining: 7.85s\n",
      "35:\tlearn: 0.5290699\ttotal: 4.31s\tremaining: 7.67s\n",
      "36:\tlearn: 0.5244294\ttotal: 4.46s\tremaining: 7.59s\n",
      "37:\tlearn: 0.5207614\ttotal: 4.54s\tremaining: 7.42s\n",
      "38:\tlearn: 0.5180070\ttotal: 4.68s\tremaining: 7.32s\n",
      "39:\tlearn: 0.5141853\ttotal: 4.84s\tremaining: 7.26s\n",
      "40:\tlearn: 0.5100589\ttotal: 4.98s\tremaining: 7.17s\n",
      "41:\tlearn: 0.5069633\ttotal: 5.07s\tremaining: 7s\n",
      "42:\tlearn: 0.5025655\ttotal: 5.22s\tremaining: 6.92s\n",
      "43:\tlearn: 0.4982977\ttotal: 5.36s\tremaining: 6.82s\n",
      "44:\tlearn: 0.4940293\ttotal: 5.44s\tremaining: 6.65s\n",
      "45:\tlearn: 0.4907633\ttotal: 5.57s\tremaining: 6.54s\n",
      "46:\tlearn: 0.4872575\ttotal: 5.7s\tremaining: 6.43s\n",
      "47:\tlearn: 0.4842297\ttotal: 5.78s\tremaining: 6.26s\n",
      "48:\tlearn: 0.4807138\ttotal: 5.9s\tremaining: 6.14s\n",
      "49:\tlearn: 0.4778439\ttotal: 6.04s\tremaining: 6.04s\n",
      "50:\tlearn: 0.4740592\ttotal: 6.13s\tremaining: 5.88s\n",
      "51:\tlearn: 0.4706612\ttotal: 6.27s\tremaining: 5.79s\n",
      "52:\tlearn: 0.4676770\ttotal: 6.41s\tremaining: 5.68s\n",
      "53:\tlearn: 0.4643911\ttotal: 6.48s\tremaining: 5.52s\n",
      "54:\tlearn: 0.4616366\ttotal: 6.62s\tremaining: 5.42s\n",
      "55:\tlearn: 0.4590405\ttotal: 6.76s\tremaining: 5.31s\n",
      "56:\tlearn: 0.4561644\ttotal: 6.86s\tremaining: 5.17s\n",
      "57:\tlearn: 0.4531848\ttotal: 6.98s\tremaining: 5.06s\n",
      "58:\tlearn: 0.4497784\ttotal: 7.1s\tremaining: 4.93s\n",
      "59:\tlearn: 0.4465926\ttotal: 7.18s\tremaining: 4.79s\n",
      "60:\tlearn: 0.4439858\ttotal: 7.3s\tremaining: 4.67s\n",
      "61:\tlearn: 0.4412855\ttotal: 7.44s\tremaining: 4.56s\n",
      "62:\tlearn: 0.4384437\ttotal: 7.52s\tremaining: 4.42s\n",
      "63:\tlearn: 0.4351543\ttotal: 7.67s\tremaining: 4.31s\n",
      "64:\tlearn: 0.4327536\ttotal: 7.82s\tremaining: 4.21s\n",
      "65:\tlearn: 0.4296901\ttotal: 7.88s\tremaining: 4.06s\n",
      "66:\tlearn: 0.4260483\ttotal: 8.02s\tremaining: 3.95s\n",
      "67:\tlearn: 0.4234784\ttotal: 8.16s\tremaining: 3.84s\n",
      "68:\tlearn: 0.4195793\ttotal: 8.25s\tremaining: 3.71s\n",
      "69:\tlearn: 0.4170005\ttotal: 8.39s\tremaining: 3.59s\n",
      "70:\tlearn: 0.4144414\ttotal: 8.55s\tremaining: 3.49s\n",
      "71:\tlearn: 0.4120841\ttotal: 8.62s\tremaining: 3.35s\n",
      "72:\tlearn: 0.4093612\ttotal: 8.74s\tremaining: 3.23s\n",
      "73:\tlearn: 0.4068223\ttotal: 8.89s\tremaining: 3.12s\n",
      "74:\tlearn: 0.4047626\ttotal: 8.96s\tremaining: 2.99s\n",
      "75:\tlearn: 0.4023674\ttotal: 9.1s\tremaining: 2.87s\n",
      "76:\tlearn: 0.4004262\ttotal: 9.25s\tremaining: 2.76s\n",
      "77:\tlearn: 0.3985838\ttotal: 9.36s\tremaining: 2.64s\n",
      "78:\tlearn: 0.3966244\ttotal: 9.47s\tremaining: 2.52s\n",
      "79:\tlearn: 0.3936198\ttotal: 9.54s\tremaining: 2.38s\n",
      "80:\tlearn: 0.3911917\ttotal: 9.66s\tremaining: 2.27s\n",
      "81:\tlearn: 0.3884982\ttotal: 9.8s\tremaining: 2.15s\n",
      "82:\tlearn: 0.3858564\ttotal: 9.95s\tremaining: 2.04s\n",
      "83:\tlearn: 0.3838965\ttotal: 10s\tremaining: 1.91s\n",
      "84:\tlearn: 0.3819811\ttotal: 10.2s\tremaining: 1.79s\n",
      "85:\tlearn: 0.3798621\ttotal: 10.3s\tremaining: 1.68s\n",
      "86:\tlearn: 0.3775258\ttotal: 10.4s\tremaining: 1.55s\n",
      "87:\tlearn: 0.3755780\ttotal: 10.5s\tremaining: 1.43s\n",
      "88:\tlearn: 0.3739106\ttotal: 10.7s\tremaining: 1.32s\n",
      "89:\tlearn: 0.3707171\ttotal: 10.8s\tremaining: 1.19s\n",
      "90:\tlearn: 0.3687115\ttotal: 10.9s\tremaining: 1.07s\n",
      "91:\tlearn: 0.3667227\ttotal: 11s\tremaining: 957ms\n",
      "92:\tlearn: 0.3648085\ttotal: 11.1s\tremaining: 838ms\n",
      "93:\tlearn: 0.3626991\ttotal: 11.2s\tremaining: 717ms\n",
      "94:\tlearn: 0.3605276\ttotal: 11.4s\tremaining: 598ms\n",
      "95:\tlearn: 0.3585663\ttotal: 11.5s\tremaining: 479ms\n",
      "96:\tlearn: 0.3563709\ttotal: 11.6s\tremaining: 358ms\n",
      "97:\tlearn: 0.3547434\ttotal: 11.7s\tremaining: 239ms\n",
      "98:\tlearn: 0.3525491\ttotal: 11.9s\tremaining: 120ms\n",
      "99:\tlearn: 0.3498288\ttotal: 11.9s\tremaining: 0us\n",
      "0:\tlearn: 0.6879323\ttotal: 141ms\tremaining: 14s\n",
      "1:\tlearn: 0.6818039\ttotal: 219ms\tremaining: 10.7s\n",
      "2:\tlearn: 0.6757430\ttotal: 369ms\tremaining: 11.9s\n",
      "3:\tlearn: 0.6708506\ttotal: 506ms\tremaining: 12.2s\n",
      "4:\tlearn: 0.6659760\ttotal: 605ms\tremaining: 11.5s\n",
      "5:\tlearn: 0.6610673\ttotal: 733ms\tremaining: 11.5s\n",
      "6:\tlearn: 0.6560176\ttotal: 868ms\tremaining: 11.5s\n",
      "7:\tlearn: 0.6505745\ttotal: 960ms\tremaining: 11s\n",
      "8:\tlearn: 0.6461859\ttotal: 1.07s\tremaining: 10.8s\n",
      "9:\tlearn: 0.6427350\ttotal: 1.22s\tremaining: 11s\n",
      "10:\tlearn: 0.6375574\ttotal: 1.34s\tremaining: 10.9s\n",
      "11:\tlearn: 0.6329234\ttotal: 1.43s\tremaining: 10.5s\n",
      "12:\tlearn: 0.6283170\ttotal: 1.58s\tremaining: 10.6s\n",
      "13:\tlearn: 0.6225651\ttotal: 1.65s\tremaining: 10.2s\n",
      "14:\tlearn: 0.6181907\ttotal: 1.78s\tremaining: 10.1s\n",
      "15:\tlearn: 0.6136442\ttotal: 1.91s\tremaining: 10s\n",
      "16:\tlearn: 0.6081453\ttotal: 2s\tremaining: 9.77s\n",
      "17:\tlearn: 0.6034355\ttotal: 2.21s\tremaining: 10s\n",
      "18:\tlearn: 0.5987441\ttotal: 2.35s\tremaining: 10s\n",
      "19:\tlearn: 0.5930052\ttotal: 2.47s\tremaining: 9.87s\n",
      "20:\tlearn: 0.5894419\ttotal: 2.54s\tremaining: 9.57s\n",
      "21:\tlearn: 0.5853556\ttotal: 2.6s\tremaining: 9.22s\n",
      "22:\tlearn: 0.5811011\ttotal: 2.71s\tremaining: 9.07s\n",
      "23:\tlearn: 0.5773847\ttotal: 2.84s\tremaining: 8.99s\n",
      "24:\tlearn: 0.5734819\ttotal: 2.92s\tremaining: 8.75s\n",
      "25:\tlearn: 0.5699384\ttotal: 3.08s\tremaining: 8.78s\n",
      "26:\tlearn: 0.5648582\ttotal: 3.23s\tremaining: 8.75s\n",
      "27:\tlearn: 0.5604698\ttotal: 3.3s\tremaining: 8.49s\n",
      "28:\tlearn: 0.5562241\ttotal: 3.44s\tremaining: 8.43s\n",
      "29:\tlearn: 0.5519789\ttotal: 3.58s\tremaining: 8.36s\n",
      "30:\tlearn: 0.5472586\ttotal: 3.68s\tremaining: 8.19s\n",
      "31:\tlearn: 0.5431729\ttotal: 3.8s\tremaining: 8.08s\n",
      "32:\tlearn: 0.5405018\ttotal: 3.93s\tremaining: 7.99s\n",
      "33:\tlearn: 0.5372244\ttotal: 4.02s\tremaining: 7.8s\n",
      "34:\tlearn: 0.5338932\ttotal: 4.15s\tremaining: 7.7s\n",
      "35:\tlearn: 0.5294678\ttotal: 4.3s\tremaining: 7.65s\n",
      "36:\tlearn: 0.5255340\ttotal: 4.45s\tremaining: 7.58s\n",
      "37:\tlearn: 0.5217312\ttotal: 4.53s\tremaining: 7.39s\n",
      "38:\tlearn: 0.5178036\ttotal: 4.67s\tremaining: 7.31s\n",
      "39:\tlearn: 0.5145488\ttotal: 4.81s\tremaining: 7.22s\n",
      "40:\tlearn: 0.5104813\ttotal: 4.95s\tremaining: 7.12s\n",
      "41:\tlearn: 0.5069177\ttotal: 5.05s\tremaining: 6.97s\n",
      "42:\tlearn: 0.5036458\ttotal: 5.21s\tremaining: 6.91s\n",
      "43:\tlearn: 0.5004452\ttotal: 5.35s\tremaining: 6.81s\n",
      "44:\tlearn: 0.4977962\ttotal: 5.46s\tremaining: 6.67s\n",
      "45:\tlearn: 0.4934868\ttotal: 5.58s\tremaining: 6.55s\n",
      "46:\tlearn: 0.4901520\ttotal: 5.72s\tremaining: 6.45s\n",
      "47:\tlearn: 0.4869297\ttotal: 5.86s\tremaining: 6.35s\n",
      "48:\tlearn: 0.4836944\ttotal: 5.94s\tremaining: 6.18s\n",
      "49:\tlearn: 0.4798222\ttotal: 6.08s\tremaining: 6.08s\n",
      "50:\tlearn: 0.4768506\ttotal: 6.22s\tremaining: 5.98s\n",
      "51:\tlearn: 0.4734909\ttotal: 6.31s\tremaining: 5.82s\n",
      "52:\tlearn: 0.4705973\ttotal: 6.45s\tremaining: 5.71s\n",
      "53:\tlearn: 0.4652018\ttotal: 6.6s\tremaining: 5.62s\n",
      "54:\tlearn: 0.4628446\ttotal: 6.72s\tremaining: 5.5s\n",
      "55:\tlearn: 0.4605648\ttotal: 6.82s\tremaining: 5.36s\n",
      "56:\tlearn: 0.4585549\ttotal: 6.96s\tremaining: 5.25s\n",
      "57:\tlearn: 0.4557339\ttotal: 7.11s\tremaining: 5.15s\n",
      "58:\tlearn: 0.4527377\ttotal: 7.22s\tremaining: 5.01s\n",
      "59:\tlearn: 0.4495286\ttotal: 7.33s\tremaining: 4.89s\n",
      "60:\tlearn: 0.4468578\ttotal: 7.46s\tremaining: 4.77s\n",
      "61:\tlearn: 0.4441675\ttotal: 7.56s\tremaining: 4.63s\n",
      "62:\tlearn: 0.4404353\ttotal: 7.68s\tremaining: 4.51s\n",
      "63:\tlearn: 0.4381084\ttotal: 7.84s\tremaining: 4.41s\n",
      "64:\tlearn: 0.4349920\ttotal: 7.94s\tremaining: 4.28s\n",
      "65:\tlearn: 0.4321876\ttotal: 8.04s\tremaining: 4.14s\n",
      "66:\tlearn: 0.4298041\ttotal: 8.2s\tremaining: 4.04s\n",
      "67:\tlearn: 0.4269694\ttotal: 8.34s\tremaining: 3.92s\n",
      "68:\tlearn: 0.4232349\ttotal: 8.46s\tremaining: 3.8s\n",
      "69:\tlearn: 0.4207745\ttotal: 8.57s\tremaining: 3.67s\n",
      "70:\tlearn: 0.4175072\ttotal: 8.72s\tremaining: 3.56s\n",
      "71:\tlearn: 0.4154569\ttotal: 8.79s\tremaining: 3.42s\n",
      "72:\tlearn: 0.4132432\ttotal: 8.92s\tremaining: 3.3s\n",
      "73:\tlearn: 0.4111784\ttotal: 9.07s\tremaining: 3.19s\n",
      "74:\tlearn: 0.4089984\ttotal: 9.19s\tremaining: 3.06s\n",
      "75:\tlearn: 0.4066940\ttotal: 9.29s\tremaining: 2.93s\n",
      "76:\tlearn: 0.4048091\ttotal: 9.38s\tremaining: 2.8s\n",
      "77:\tlearn: 0.4017308\ttotal: 9.49s\tremaining: 2.68s\n",
      "78:\tlearn: 0.3996255\ttotal: 9.64s\tremaining: 2.56s\n",
      "79:\tlearn: 0.3970751\ttotal: 9.75s\tremaining: 2.44s\n",
      "80:\tlearn: 0.3942086\ttotal: 9.85s\tremaining: 2.31s\n",
      "81:\tlearn: 0.3920342\ttotal: 10s\tremaining: 2.2s\n",
      "82:\tlearn: 0.3891761\ttotal: 10.1s\tremaining: 2.08s\n",
      "83:\tlearn: 0.3874722\ttotal: 10.2s\tremaining: 1.95s\n",
      "84:\tlearn: 0.3850751\ttotal: 10.4s\tremaining: 1.83s\n",
      "85:\tlearn: 0.3821750\ttotal: 10.5s\tremaining: 1.71s\n",
      "86:\tlearn: 0.3799985\ttotal: 10.6s\tremaining: 1.58s\n",
      "87:\tlearn: 0.3776242\ttotal: 10.7s\tremaining: 1.46s\n",
      "88:\tlearn: 0.3757302\ttotal: 10.9s\tremaining: 1.35s\n",
      "89:\tlearn: 0.3739161\ttotal: 11.1s\tremaining: 1.23s\n",
      "90:\tlearn: 0.3723732\ttotal: 11.1s\tremaining: 1.1s\n",
      "91:\tlearn: 0.3702728\ttotal: 11.3s\tremaining: 981ms\n",
      "92:\tlearn: 0.3683471\ttotal: 11.4s\tremaining: 861ms\n",
      "93:\tlearn: 0.3662583\ttotal: 11.6s\tremaining: 739ms\n",
      "94:\tlearn: 0.3637023\ttotal: 11.7s\tremaining: 614ms\n",
      "95:\tlearn: 0.3618812\ttotal: 11.8s\tremaining: 492ms\n",
      "96:\tlearn: 0.3592437\ttotal: 12s\tremaining: 370ms\n",
      "97:\tlearn: 0.3572046\ttotal: 12.1s\tremaining: 247ms\n",
      "98:\tlearn: 0.3550651\ttotal: 12.2s\tremaining: 123ms\n",
      "99:\tlearn: 0.3526281\ttotal: 12.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6874528\ttotal: 72.4ms\tremaining: 7.16s\n",
      "1:\tlearn: 0.6818994\ttotal: 145ms\tremaining: 7.12s\n",
      "2:\tlearn: 0.6770405\ttotal: 206ms\tremaining: 6.64s\n",
      "3:\tlearn: 0.6718075\ttotal: 262ms\tremaining: 6.29s\n",
      "4:\tlearn: 0.6646899\ttotal: 339ms\tremaining: 6.43s\n",
      "5:\tlearn: 0.6601561\ttotal: 493ms\tremaining: 7.73s\n",
      "6:\tlearn: 0.6544245\ttotal: 556ms\tremaining: 7.39s\n",
      "7:\tlearn: 0.6497036\ttotal: 633ms\tremaining: 7.28s\n",
      "8:\tlearn: 0.6449147\ttotal: 721ms\tremaining: 7.29s\n",
      "9:\tlearn: 0.6398269\ttotal: 860ms\tremaining: 7.74s\n",
      "10:\tlearn: 0.6360660\ttotal: 980ms\tremaining: 7.93s\n",
      "11:\tlearn: 0.6310729\ttotal: 1.12s\tremaining: 8.19s\n",
      "12:\tlearn: 0.6273230\ttotal: 1.22s\tremaining: 8.13s\n",
      "13:\tlearn: 0.6221317\ttotal: 1.34s\tremaining: 8.24s\n",
      "14:\tlearn: 0.6178287\ttotal: 1.48s\tremaining: 8.39s\n",
      "15:\tlearn: 0.6137191\ttotal: 1.59s\tremaining: 8.37s\n",
      "16:\tlearn: 0.6090662\ttotal: 1.68s\tremaining: 8.23s\n",
      "17:\tlearn: 0.6052047\ttotal: 1.83s\tremaining: 8.34s\n",
      "18:\tlearn: 0.5997419\ttotal: 1.91s\tremaining: 8.15s\n",
      "19:\tlearn: 0.5946088\ttotal: 2.06s\tremaining: 8.22s\n",
      "20:\tlearn: 0.5904417\ttotal: 2.21s\tremaining: 8.29s\n",
      "21:\tlearn: 0.5866278\ttotal: 2.31s\tremaining: 8.17s\n",
      "22:\tlearn: 0.5818394\ttotal: 2.42s\tremaining: 8.1s\n",
      "23:\tlearn: 0.5783451\ttotal: 2.58s\tremaining: 8.16s\n",
      "24:\tlearn: 0.5739695\ttotal: 2.74s\tremaining: 8.22s\n",
      "25:\tlearn: 0.5708649\ttotal: 2.82s\tremaining: 8.04s\n",
      "26:\tlearn: 0.5661556\ttotal: 2.96s\tremaining: 8s\n",
      "27:\tlearn: 0.5619575\ttotal: 3.11s\tremaining: 8s\n",
      "28:\tlearn: 0.5578482\ttotal: 3.19s\tremaining: 7.8s\n",
      "29:\tlearn: 0.5533677\ttotal: 3.31s\tremaining: 7.72s\n",
      "30:\tlearn: 0.5489876\ttotal: 3.46s\tremaining: 7.7s\n",
      "31:\tlearn: 0.5449228\ttotal: 3.54s\tremaining: 7.51s\n",
      "32:\tlearn: 0.5413589\ttotal: 3.67s\tremaining: 7.45s\n",
      "33:\tlearn: 0.5375106\ttotal: 3.81s\tremaining: 7.39s\n",
      "34:\tlearn: 0.5341396\ttotal: 3.92s\tremaining: 7.27s\n",
      "35:\tlearn: 0.5296209\ttotal: 4.03s\tremaining: 7.17s\n",
      "36:\tlearn: 0.5256048\ttotal: 4.17s\tremaining: 7.1s\n",
      "37:\tlearn: 0.5211830\ttotal: 4.3s\tremaining: 7.02s\n",
      "38:\tlearn: 0.5179219\ttotal: 4.36s\tremaining: 6.82s\n",
      "39:\tlearn: 0.5149669\ttotal: 4.52s\tremaining: 6.78s\n",
      "40:\tlearn: 0.5111011\ttotal: 4.59s\tremaining: 6.6s\n",
      "41:\tlearn: 0.5077427\ttotal: 4.71s\tremaining: 6.51s\n",
      "42:\tlearn: 0.5024094\ttotal: 4.8s\tremaining: 6.36s\n",
      "43:\tlearn: 0.4994785\ttotal: 4.93s\tremaining: 6.27s\n",
      "44:\tlearn: 0.4964076\ttotal: 5.07s\tremaining: 6.2s\n",
      "45:\tlearn: 0.4928159\ttotal: 5.22s\tremaining: 6.13s\n",
      "46:\tlearn: 0.4886039\ttotal: 5.3s\tremaining: 5.97s\n",
      "47:\tlearn: 0.4856870\ttotal: 5.46s\tremaining: 5.91s\n",
      "48:\tlearn: 0.4825247\ttotal: 5.6s\tremaining: 5.83s\n",
      "49:\tlearn: 0.4787070\ttotal: 5.68s\tremaining: 5.68s\n",
      "50:\tlearn: 0.4748067\ttotal: 5.81s\tremaining: 5.58s\n",
      "51:\tlearn: 0.4717825\ttotal: 5.96s\tremaining: 5.5s\n",
      "52:\tlearn: 0.4684245\ttotal: 6.1s\tremaining: 5.41s\n",
      "53:\tlearn: 0.4645723\ttotal: 6.18s\tremaining: 5.26s\n",
      "54:\tlearn: 0.4624686\ttotal: 6.33s\tremaining: 5.18s\n",
      "55:\tlearn: 0.4600864\ttotal: 6.4s\tremaining: 5.03s\n",
      "56:\tlearn: 0.4576673\ttotal: 6.54s\tremaining: 4.93s\n",
      "57:\tlearn: 0.4541401\ttotal: 6.68s\tremaining: 4.84s\n",
      "58:\tlearn: 0.4515427\ttotal: 6.8s\tremaining: 4.73s\n",
      "59:\tlearn: 0.4482400\ttotal: 6.97s\tremaining: 4.64s\n",
      "60:\tlearn: 0.4455730\ttotal: 7.05s\tremaining: 4.51s\n",
      "61:\tlearn: 0.4423527\ttotal: 7.19s\tremaining: 4.41s\n",
      "62:\tlearn: 0.4396154\ttotal: 7.32s\tremaining: 4.3s\n",
      "63:\tlearn: 0.4364793\ttotal: 7.41s\tremaining: 4.17s\n",
      "64:\tlearn: 0.4341838\ttotal: 7.55s\tremaining: 4.06s\n",
      "65:\tlearn: 0.4318860\ttotal: 7.68s\tremaining: 3.96s\n",
      "66:\tlearn: 0.4292024\ttotal: 7.78s\tremaining: 3.83s\n",
      "67:\tlearn: 0.4265779\ttotal: 7.91s\tremaining: 3.72s\n",
      "68:\tlearn: 0.4223350\ttotal: 8.05s\tremaining: 3.62s\n",
      "69:\tlearn: 0.4187592\ttotal: 8.12s\tremaining: 3.48s\n",
      "70:\tlearn: 0.4158011\ttotal: 8.26s\tremaining: 3.37s\n",
      "71:\tlearn: 0.4135549\ttotal: 8.41s\tremaining: 3.27s\n",
      "72:\tlearn: 0.4112302\ttotal: 8.54s\tremaining: 3.16s\n",
      "73:\tlearn: 0.4092076\ttotal: 8.64s\tremaining: 3.03s\n",
      "74:\tlearn: 0.4069622\ttotal: 8.8s\tremaining: 2.93s\n",
      "75:\tlearn: 0.4043011\ttotal: 8.88s\tremaining: 2.81s\n",
      "76:\tlearn: 0.4020757\ttotal: 9.03s\tremaining: 2.7s\n",
      "77:\tlearn: 0.3995899\ttotal: 9.17s\tremaining: 2.59s\n",
      "78:\tlearn: 0.3976261\ttotal: 9.27s\tremaining: 2.46s\n",
      "79:\tlearn: 0.3952475\ttotal: 9.4s\tremaining: 2.35s\n",
      "80:\tlearn: 0.3932858\ttotal: 9.54s\tremaining: 2.24s\n",
      "81:\tlearn: 0.3911874\ttotal: 9.68s\tremaining: 2.13s\n",
      "82:\tlearn: 0.3879272\ttotal: 9.79s\tremaining: 2.01s\n",
      "83:\tlearn: 0.3864490\ttotal: 9.91s\tremaining: 1.89s\n",
      "84:\tlearn: 0.3844978\ttotal: 10s\tremaining: 1.77s\n",
      "85:\tlearn: 0.3819770\ttotal: 10.1s\tremaining: 1.65s\n",
      "86:\tlearn: 0.3794217\ttotal: 10.2s\tremaining: 1.53s\n",
      "87:\tlearn: 0.3773341\ttotal: 10.4s\tremaining: 1.42s\n",
      "88:\tlearn: 0.3756313\ttotal: 10.5s\tremaining: 1.29s\n",
      "89:\tlearn: 0.3732470\ttotal: 10.7s\tremaining: 1.18s\n",
      "90:\tlearn: 0.3709284\ttotal: 10.8s\tremaining: 1.06s\n",
      "91:\tlearn: 0.3682666\ttotal: 10.9s\tremaining: 944ms\n",
      "92:\tlearn: 0.3664983\ttotal: 11s\tremaining: 826ms\n",
      "93:\tlearn: 0.3646908\ttotal: 11.1s\tremaining: 707ms\n",
      "94:\tlearn: 0.3628732\ttotal: 11.2s\tremaining: 588ms\n",
      "95:\tlearn: 0.3601209\ttotal: 11.3s\tremaining: 471ms\n",
      "96:\tlearn: 0.3573356\ttotal: 11.5s\tremaining: 354ms\n",
      "97:\tlearn: 0.3549926\ttotal: 11.6s\tremaining: 237ms\n",
      "98:\tlearn: 0.3526397\ttotal: 11.7s\tremaining: 118ms\n",
      "99:\tlearn: 0.3509398\ttotal: 11.9s\tremaining: 0us\n",
      "0:\tlearn: 0.6886249\ttotal: 109ms\tremaining: 10.8s\n",
      "1:\tlearn: 0.6826894\ttotal: 228ms\tremaining: 11.2s\n",
      "2:\tlearn: 0.6770939\ttotal: 364ms\tremaining: 11.8s\n",
      "3:\tlearn: 0.6723519\ttotal: 490ms\tremaining: 11.8s\n",
      "4:\tlearn: 0.6674106\ttotal: 597ms\tremaining: 11.3s\n",
      "5:\tlearn: 0.6631844\ttotal: 724ms\tremaining: 11.3s\n",
      "6:\tlearn: 0.6572370\ttotal: 856ms\tremaining: 11.4s\n",
      "7:\tlearn: 0.6524885\ttotal: 973ms\tremaining: 11.2s\n",
      "8:\tlearn: 0.6470425\ttotal: 1.08s\tremaining: 11s\n",
      "9:\tlearn: 0.6424197\ttotal: 1.25s\tremaining: 11.2s\n",
      "10:\tlearn: 0.6379714\ttotal: 1.4s\tremaining: 11.3s\n",
      "11:\tlearn: 0.6339886\ttotal: 1.58s\tremaining: 11.6s\n",
      "12:\tlearn: 0.6277726\ttotal: 1.77s\tremaining: 11.8s\n",
      "13:\tlearn: 0.6222964\ttotal: 1.85s\tremaining: 11.4s\n",
      "14:\tlearn: 0.6170424\ttotal: 2.01s\tremaining: 11.4s\n",
      "15:\tlearn: 0.6123677\ttotal: 2.08s\tremaining: 10.9s\n",
      "16:\tlearn: 0.6081734\ttotal: 2.22s\tremaining: 10.8s\n",
      "17:\tlearn: 0.6032773\ttotal: 2.36s\tremaining: 10.8s\n",
      "18:\tlearn: 0.5988090\ttotal: 2.44s\tremaining: 10.4s\n",
      "19:\tlearn: 0.5944575\ttotal: 2.58s\tremaining: 10.3s\n",
      "20:\tlearn: 0.5905670\ttotal: 2.71s\tremaining: 10.2s\n",
      "21:\tlearn: 0.5865593\ttotal: 2.8s\tremaining: 9.93s\n",
      "22:\tlearn: 0.5827962\ttotal: 2.92s\tremaining: 9.78s\n",
      "23:\tlearn: 0.5785771\ttotal: 3.07s\tremaining: 9.72s\n",
      "24:\tlearn: 0.5743262\ttotal: 3.17s\tremaining: 9.52s\n",
      "25:\tlearn: 0.5696925\ttotal: 3.29s\tremaining: 9.36s\n",
      "26:\tlearn: 0.5655304\ttotal: 3.42s\tremaining: 9.24s\n",
      "27:\tlearn: 0.5612240\ttotal: 3.56s\tremaining: 9.15s\n",
      "28:\tlearn: 0.5571160\ttotal: 3.67s\tremaining: 8.98s\n",
      "29:\tlearn: 0.5531588\ttotal: 3.79s\tremaining: 8.84s\n",
      "30:\tlearn: 0.5493467\ttotal: 3.92s\tremaining: 8.73s\n",
      "31:\tlearn: 0.5455633\ttotal: 4.08s\tremaining: 8.67s\n",
      "32:\tlearn: 0.5422173\ttotal: 4.32s\tremaining: 8.77s\n",
      "33:\tlearn: 0.5382966\ttotal: 4.46s\tremaining: 8.65s\n",
      "34:\tlearn: 0.5346755\ttotal: 4.54s\tremaining: 8.44s\n",
      "35:\tlearn: 0.5315902\ttotal: 4.7s\tremaining: 8.36s\n",
      "36:\tlearn: 0.5271706\ttotal: 4.85s\tremaining: 8.25s\n",
      "37:\tlearn: 0.5233358\ttotal: 4.92s\tremaining: 8.03s\n",
      "38:\tlearn: 0.5206622\ttotal: 5.06s\tremaining: 7.91s\n",
      "39:\tlearn: 0.5171090\ttotal: 5.2s\tremaining: 7.8s\n",
      "40:\tlearn: 0.5134390\ttotal: 5.31s\tremaining: 7.64s\n",
      "41:\tlearn: 0.5101776\ttotal: 5.43s\tremaining: 7.5s\n",
      "42:\tlearn: 0.5063400\ttotal: 5.55s\tremaining: 7.36s\n",
      "43:\tlearn: 0.5007695\ttotal: 5.62s\tremaining: 7.16s\n",
      "44:\tlearn: 0.4977957\ttotal: 5.74s\tremaining: 7.02s\n",
      "45:\tlearn: 0.4942338\ttotal: 5.88s\tremaining: 6.91s\n",
      "46:\tlearn: 0.4908717\ttotal: 5.96s\tremaining: 6.72s\n",
      "47:\tlearn: 0.4875860\ttotal: 6.11s\tremaining: 6.62s\n",
      "48:\tlearn: 0.4846504\ttotal: 6.26s\tremaining: 6.51s\n",
      "49:\tlearn: 0.4812706\ttotal: 6.36s\tremaining: 6.36s\n",
      "50:\tlearn: 0.4780129\ttotal: 6.48s\tremaining: 6.23s\n",
      "51:\tlearn: 0.4748243\ttotal: 6.59s\tremaining: 6.08s\n",
      "52:\tlearn: 0.4718649\ttotal: 6.69s\tremaining: 5.93s\n",
      "53:\tlearn: 0.4684628\ttotal: 6.83s\tremaining: 5.82s\n",
      "54:\tlearn: 0.4654874\ttotal: 6.9s\tremaining: 5.64s\n",
      "55:\tlearn: 0.4622548\ttotal: 7.04s\tremaining: 5.53s\n",
      "56:\tlearn: 0.4599044\ttotal: 7.18s\tremaining: 5.42s\n",
      "57:\tlearn: 0.4577737\ttotal: 7.26s\tremaining: 5.26s\n",
      "58:\tlearn: 0.4549441\ttotal: 7.42s\tremaining: 5.16s\n",
      "59:\tlearn: 0.4521624\ttotal: 7.56s\tremaining: 5.04s\n",
      "60:\tlearn: 0.4486128\ttotal: 7.63s\tremaining: 4.88s\n",
      "61:\tlearn: 0.4459060\ttotal: 7.79s\tremaining: 4.77s\n",
      "62:\tlearn: 0.4429575\ttotal: 7.93s\tremaining: 4.66s\n",
      "63:\tlearn: 0.4408224\ttotal: 8.04s\tremaining: 4.52s\n",
      "64:\tlearn: 0.4382412\ttotal: 8.15s\tremaining: 4.39s\n",
      "65:\tlearn: 0.4353833\ttotal: 8.29s\tremaining: 4.27s\n",
      "66:\tlearn: 0.4328341\ttotal: 8.42s\tremaining: 4.15s\n",
      "67:\tlearn: 0.4299410\ttotal: 8.51s\tremaining: 4s\n",
      "68:\tlearn: 0.4269789\ttotal: 8.65s\tremaining: 3.89s\n",
      "69:\tlearn: 0.4241311\ttotal: 8.78s\tremaining: 3.76s\n",
      "70:\tlearn: 0.4217759\ttotal: 8.86s\tremaining: 3.62s\n",
      "71:\tlearn: 0.4190962\ttotal: 9.03s\tremaining: 3.51s\n",
      "72:\tlearn: 0.4158575\ttotal: 9.17s\tremaining: 3.39s\n",
      "73:\tlearn: 0.4136385\ttotal: 9.29s\tremaining: 3.26s\n",
      "74:\tlearn: 0.4116318\ttotal: 9.35s\tremaining: 3.12s\n",
      "75:\tlearn: 0.4090843\ttotal: 9.5s\tremaining: 3s\n",
      "76:\tlearn: 0.4062847\ttotal: 9.6s\tremaining: 2.87s\n",
      "77:\tlearn: 0.4032401\ttotal: 9.71s\tremaining: 2.74s\n",
      "78:\tlearn: 0.4010075\ttotal: 9.87s\tremaining: 2.62s\n",
      "79:\tlearn: 0.3979392\ttotal: 10s\tremaining: 2.5s\n",
      "80:\tlearn: 0.3958068\ttotal: 10.1s\tremaining: 2.38s\n",
      "81:\tlearn: 0.3936544\ttotal: 10.2s\tremaining: 2.25s\n",
      "82:\tlearn: 0.3910792\ttotal: 10.4s\tremaining: 2.13s\n",
      "83:\tlearn: 0.3894300\ttotal: 10.5s\tremaining: 2.01s\n",
      "84:\tlearn: 0.3870564\ttotal: 10.6s\tremaining: 1.88s\n",
      "85:\tlearn: 0.3848034\ttotal: 10.8s\tremaining: 1.75s\n",
      "86:\tlearn: 0.3825745\ttotal: 10.9s\tremaining: 1.63s\n",
      "87:\tlearn: 0.3802204\ttotal: 11s\tremaining: 1.5s\n",
      "88:\tlearn: 0.3778351\ttotal: 11.1s\tremaining: 1.38s\n",
      "89:\tlearn: 0.3755250\ttotal: 11.3s\tremaining: 1.25s\n",
      "90:\tlearn: 0.3736865\ttotal: 11.4s\tremaining: 1.13s\n",
      "91:\tlearn: 0.3708377\ttotal: 11.5s\tremaining: 1s\n",
      "92:\tlearn: 0.3682162\ttotal: 11.7s\tremaining: 878ms\n",
      "93:\tlearn: 0.3654836\ttotal: 11.8s\tremaining: 750ms\n",
      "94:\tlearn: 0.3629706\ttotal: 11.9s\tremaining: 625ms\n",
      "95:\tlearn: 0.3604008\ttotal: 12s\tremaining: 501ms\n",
      "96:\tlearn: 0.3586303\ttotal: 12.1s\tremaining: 376ms\n",
      "97:\tlearn: 0.3565910\ttotal: 12.2s\tremaining: 250ms\n",
      "98:\tlearn: 0.3540430\ttotal: 12.4s\tremaining: 125ms\n",
      "99:\tlearn: 0.3520634\ttotal: 12.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6882959\ttotal: 94.1ms\tremaining: 9.32s\n",
      "1:\tlearn: 0.6823105\ttotal: 224ms\tremaining: 11s\n",
      "2:\tlearn: 0.6773788\ttotal: 352ms\tremaining: 11.4s\n",
      "3:\tlearn: 0.6726835\ttotal: 430ms\tremaining: 10.3s\n",
      "4:\tlearn: 0.6665072\ttotal: 562ms\tremaining: 10.7s\n",
      "5:\tlearn: 0.6621900\ttotal: 684ms\tremaining: 10.7s\n",
      "6:\tlearn: 0.6560267\ttotal: 768ms\tremaining: 10.2s\n",
      "7:\tlearn: 0.6509346\ttotal: 909ms\tremaining: 10.4s\n",
      "8:\tlearn: 0.6449926\ttotal: 1.05s\tremaining: 10.6s\n",
      "9:\tlearn: 0.6408627\ttotal: 1.13s\tremaining: 10.2s\n",
      "10:\tlearn: 0.6359471\ttotal: 1.27s\tremaining: 10.3s\n",
      "11:\tlearn: 0.6308574\ttotal: 1.42s\tremaining: 10.4s\n",
      "12:\tlearn: 0.6265602\ttotal: 1.55s\tremaining: 10.4s\n",
      "13:\tlearn: 0.6220286\ttotal: 1.65s\tremaining: 10.1s\n",
      "14:\tlearn: 0.6179132\ttotal: 1.81s\tremaining: 10.2s\n",
      "15:\tlearn: 0.6129993\ttotal: 1.91s\tremaining: 10s\n",
      "16:\tlearn: 0.6088503\ttotal: 2.01s\tremaining: 9.81s\n",
      "17:\tlearn: 0.6050828\ttotal: 2.15s\tremaining: 9.79s\n",
      "18:\tlearn: 0.6003788\ttotal: 2.3s\tremaining: 9.81s\n",
      "19:\tlearn: 0.5963897\ttotal: 2.38s\tremaining: 9.52s\n",
      "20:\tlearn: 0.5924532\ttotal: 2.53s\tremaining: 9.51s\n",
      "21:\tlearn: 0.5881017\ttotal: 2.66s\tremaining: 9.45s\n",
      "22:\tlearn: 0.5842807\ttotal: 2.75s\tremaining: 9.22s\n",
      "23:\tlearn: 0.5801894\ttotal: 2.89s\tremaining: 9.15s\n",
      "24:\tlearn: 0.5767936\ttotal: 3.03s\tremaining: 9.09s\n",
      "25:\tlearn: 0.5720946\ttotal: 3.09s\tremaining: 8.81s\n",
      "26:\tlearn: 0.5684301\ttotal: 3.24s\tremaining: 8.76s\n",
      "27:\tlearn: 0.5651430\ttotal: 3.38s\tremaining: 8.68s\n",
      "28:\tlearn: 0.5593778\ttotal: 3.47s\tremaining: 8.49s\n",
      "29:\tlearn: 0.5550515\ttotal: 3.6s\tremaining: 8.4s\n",
      "30:\tlearn: 0.5506429\ttotal: 3.74s\tremaining: 8.32s\n",
      "31:\tlearn: 0.5457017\ttotal: 3.82s\tremaining: 8.12s\n",
      "32:\tlearn: 0.5425450\ttotal: 3.97s\tremaining: 8.05s\n",
      "33:\tlearn: 0.5390839\ttotal: 4.12s\tremaining: 7.99s\n",
      "34:\tlearn: 0.5356647\ttotal: 4.23s\tremaining: 7.85s\n",
      "35:\tlearn: 0.5327150\ttotal: 4.34s\tremaining: 7.71s\n",
      "36:\tlearn: 0.5285028\ttotal: 4.41s\tremaining: 7.51s\n",
      "37:\tlearn: 0.5244674\ttotal: 4.53s\tremaining: 7.39s\n",
      "38:\tlearn: 0.5219813\ttotal: 4.68s\tremaining: 7.32s\n",
      "39:\tlearn: 0.5187399\ttotal: 4.84s\tremaining: 7.25s\n",
      "40:\tlearn: 0.5153439\ttotal: 4.98s\tremaining: 7.16s\n",
      "41:\tlearn: 0.5120576\ttotal: 5.06s\tremaining: 6.99s\n",
      "42:\tlearn: 0.5085881\ttotal: 5.23s\tremaining: 6.93s\n",
      "43:\tlearn: 0.5061015\ttotal: 5.37s\tremaining: 6.84s\n",
      "44:\tlearn: 0.5025627\ttotal: 5.49s\tremaining: 6.71s\n",
      "45:\tlearn: 0.4991083\ttotal: 5.62s\tremaining: 6.6s\n",
      "46:\tlearn: 0.4961178\ttotal: 5.71s\tremaining: 6.44s\n",
      "47:\tlearn: 0.4928989\ttotal: 5.87s\tremaining: 6.35s\n",
      "48:\tlearn: 0.4890603\ttotal: 5.96s\tremaining: 6.2s\n",
      "49:\tlearn: 0.4863273\ttotal: 6.04s\tremaining: 6.04s\n",
      "50:\tlearn: 0.4830438\ttotal: 6.19s\tremaining: 5.95s\n",
      "51:\tlearn: 0.4801148\ttotal: 6.27s\tremaining: 5.79s\n",
      "52:\tlearn: 0.4774722\ttotal: 6.38s\tremaining: 5.66s\n",
      "53:\tlearn: 0.4749024\ttotal: 6.54s\tremaining: 5.58s\n",
      "54:\tlearn: 0.4723577\ttotal: 6.71s\tremaining: 5.49s\n",
      "55:\tlearn: 0.4689171\ttotal: 6.8s\tremaining: 5.35s\n",
      "56:\tlearn: 0.4665243\ttotal: 6.92s\tremaining: 5.22s\n",
      "57:\tlearn: 0.4628273\ttotal: 7.06s\tremaining: 5.11s\n",
      "58:\tlearn: 0.4606178\ttotal: 7.14s\tremaining: 4.96s\n",
      "59:\tlearn: 0.4578103\ttotal: 7.28s\tremaining: 4.85s\n",
      "60:\tlearn: 0.4542061\ttotal: 7.43s\tremaining: 4.75s\n",
      "61:\tlearn: 0.4516084\ttotal: 7.57s\tremaining: 4.64s\n",
      "62:\tlearn: 0.4486752\ttotal: 7.71s\tremaining: 4.53s\n",
      "63:\tlearn: 0.4457030\ttotal: 7.8s\tremaining: 4.39s\n",
      "64:\tlearn: 0.4424764\ttotal: 7.96s\tremaining: 4.28s\n",
      "65:\tlearn: 0.4390318\ttotal: 8.1s\tremaining: 4.17s\n",
      "66:\tlearn: 0.4361128\ttotal: 8.18s\tremaining: 4.03s\n",
      "67:\tlearn: 0.4329777\ttotal: 8.32s\tremaining: 3.91s\n",
      "68:\tlearn: 0.4293493\ttotal: 8.46s\tremaining: 3.8s\n",
      "69:\tlearn: 0.4262742\ttotal: 8.54s\tremaining: 3.66s\n",
      "70:\tlearn: 0.4230108\ttotal: 8.69s\tremaining: 3.55s\n",
      "71:\tlearn: 0.4204456\ttotal: 8.84s\tremaining: 3.44s\n",
      "72:\tlearn: 0.4175130\ttotal: 8.95s\tremaining: 3.31s\n",
      "73:\tlearn: 0.4150189\ttotal: 9.04s\tremaining: 3.18s\n",
      "74:\tlearn: 0.4127339\ttotal: 9.11s\tremaining: 3.04s\n",
      "75:\tlearn: 0.4088859\ttotal: 9.25s\tremaining: 2.92s\n",
      "76:\tlearn: 0.4064106\ttotal: 9.4s\tremaining: 2.81s\n",
      "77:\tlearn: 0.4042338\ttotal: 9.48s\tremaining: 2.67s\n",
      "78:\tlearn: 0.4022136\ttotal: 9.61s\tremaining: 2.55s\n",
      "79:\tlearn: 0.3999006\ttotal: 9.77s\tremaining: 2.44s\n",
      "80:\tlearn: 0.3982344\ttotal: 9.91s\tremaining: 2.33s\n",
      "81:\tlearn: 0.3951198\ttotal: 9.99s\tremaining: 2.19s\n",
      "82:\tlearn: 0.3924535\ttotal: 10.1s\tremaining: 2.08s\n",
      "83:\tlearn: 0.3903903\ttotal: 10.3s\tremaining: 1.96s\n",
      "84:\tlearn: 0.3879903\ttotal: 10.4s\tremaining: 1.83s\n",
      "85:\tlearn: 0.3854110\ttotal: 10.5s\tremaining: 1.71s\n",
      "86:\tlearn: 0.3829107\ttotal: 10.7s\tremaining: 1.59s\n",
      "87:\tlearn: 0.3797923\ttotal: 10.8s\tremaining: 1.47s\n",
      "88:\tlearn: 0.3775479\ttotal: 10.9s\tremaining: 1.35s\n",
      "89:\tlearn: 0.3755177\ttotal: 11s\tremaining: 1.22s\n",
      "90:\tlearn: 0.3736879\ttotal: 11.2s\tremaining: 1.1s\n",
      "91:\tlearn: 0.3706108\ttotal: 11.3s\tremaining: 984ms\n",
      "92:\tlearn: 0.3687052\ttotal: 11.4s\tremaining: 858ms\n",
      "93:\tlearn: 0.3666338\ttotal: 11.5s\tremaining: 737ms\n",
      "94:\tlearn: 0.3638162\ttotal: 11.6s\tremaining: 613ms\n",
      "95:\tlearn: 0.3612587\ttotal: 11.8s\tremaining: 490ms\n",
      "96:\tlearn: 0.3585763\ttotal: 11.9s\tremaining: 368ms\n",
      "97:\tlearn: 0.3564586\ttotal: 12.1s\tremaining: 246ms\n",
      "98:\tlearn: 0.3545428\ttotal: 12.2s\tremaining: 123ms\n",
      "99:\tlearn: 0.3521559\ttotal: 12.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6884057\ttotal: 148ms\tremaining: 14.6s\n",
      "1:\tlearn: 0.6822769\ttotal: 226ms\tremaining: 11.1s\n",
      "2:\tlearn: 0.6773531\ttotal: 369ms\tremaining: 11.9s\n",
      "3:\tlearn: 0.6717442\ttotal: 516ms\tremaining: 12.4s\n",
      "4:\tlearn: 0.6653732\ttotal: 612ms\tremaining: 11.6s\n",
      "5:\tlearn: 0.6600504\ttotal: 734ms\tremaining: 11.5s\n",
      "6:\tlearn: 0.6561682\ttotal: 869ms\tremaining: 11.5s\n",
      "7:\tlearn: 0.6512741\ttotal: 948ms\tremaining: 10.9s\n",
      "8:\tlearn: 0.6473055\ttotal: 1.06s\tremaining: 10.8s\n",
      "9:\tlearn: 0.6438282\ttotal: 1.21s\tremaining: 10.9s\n",
      "10:\tlearn: 0.6391416\ttotal: 1.28s\tremaining: 10.3s\n",
      "11:\tlearn: 0.6345433\ttotal: 1.42s\tremaining: 10.4s\n",
      "12:\tlearn: 0.6296864\ttotal: 1.57s\tremaining: 10.5s\n",
      "13:\tlearn: 0.6244673\ttotal: 1.69s\tremaining: 10.4s\n",
      "14:\tlearn: 0.6190141\ttotal: 1.79s\tremaining: 10.1s\n",
      "15:\tlearn: 0.6143028\ttotal: 1.93s\tremaining: 10.2s\n",
      "16:\tlearn: 0.6101450\ttotal: 2.01s\tremaining: 9.81s\n",
      "17:\tlearn: 0.6058151\ttotal: 2.12s\tremaining: 9.64s\n",
      "18:\tlearn: 0.6011739\ttotal: 2.27s\tremaining: 9.68s\n",
      "19:\tlearn: 0.5969558\ttotal: 2.42s\tremaining: 9.67s\n",
      "20:\tlearn: 0.5926009\ttotal: 2.5s\tremaining: 9.39s\n",
      "21:\tlearn: 0.5887770\ttotal: 2.64s\tremaining: 9.37s\n",
      "22:\tlearn: 0.5839049\ttotal: 2.79s\tremaining: 9.35s\n",
      "23:\tlearn: 0.5802563\ttotal: 2.86s\tremaining: 9.07s\n",
      "24:\tlearn: 0.5758703\ttotal: 3s\tremaining: 9.01s\n",
      "25:\tlearn: 0.5727867\ttotal: 3.13s\tremaining: 8.9s\n",
      "26:\tlearn: 0.5686971\ttotal: 3.21s\tremaining: 8.67s\n",
      "27:\tlearn: 0.5648489\ttotal: 3.33s\tremaining: 8.56s\n",
      "28:\tlearn: 0.5610080\ttotal: 3.49s\tremaining: 8.55s\n",
      "29:\tlearn: 0.5566780\ttotal: 3.63s\tremaining: 8.48s\n",
      "30:\tlearn: 0.5522084\ttotal: 3.72s\tremaining: 8.28s\n",
      "31:\tlearn: 0.5488288\ttotal: 3.86s\tremaining: 8.2s\n",
      "32:\tlearn: 0.5452422\ttotal: 3.99s\tremaining: 8.11s\n",
      "33:\tlearn: 0.5417092\ttotal: 4.07s\tremaining: 7.91s\n",
      "34:\tlearn: 0.5386839\ttotal: 4.22s\tremaining: 7.84s\n",
      "35:\tlearn: 0.5340976\ttotal: 4.36s\tremaining: 7.75s\n",
      "36:\tlearn: 0.5295306\ttotal: 4.46s\tremaining: 7.59s\n",
      "37:\tlearn: 0.5247937\ttotal: 4.66s\tremaining: 7.6s\n",
      "38:\tlearn: 0.5215672\ttotal: 4.8s\tremaining: 7.51s\n",
      "39:\tlearn: 0.5181069\ttotal: 4.93s\tremaining: 7.39s\n",
      "40:\tlearn: 0.5147668\ttotal: 5.08s\tremaining: 7.31s\n",
      "41:\tlearn: 0.5112846\ttotal: 5.21s\tremaining: 7.19s\n",
      "42:\tlearn: 0.5067831\ttotal: 5.29s\tremaining: 7.02s\n",
      "43:\tlearn: 0.5040549\ttotal: 5.45s\tremaining: 6.93s\n",
      "44:\tlearn: 0.5010293\ttotal: 5.59s\tremaining: 6.84s\n",
      "45:\tlearn: 0.4973002\ttotal: 5.7s\tremaining: 6.7s\n",
      "46:\tlearn: 0.4939079\ttotal: 5.81s\tremaining: 6.55s\n",
      "47:\tlearn: 0.4909074\ttotal: 5.96s\tremaining: 6.45s\n",
      "48:\tlearn: 0.4880007\ttotal: 6.08s\tremaining: 6.33s\n",
      "49:\tlearn: 0.4851102\ttotal: 6.17s\tremaining: 6.17s\n",
      "50:\tlearn: 0.4818435\ttotal: 6.33s\tremaining: 6.08s\n",
      "51:\tlearn: 0.4790761\ttotal: 6.47s\tremaining: 5.97s\n",
      "52:\tlearn: 0.4759132\ttotal: 6.55s\tremaining: 5.81s\n",
      "53:\tlearn: 0.4729268\ttotal: 6.7s\tremaining: 5.71s\n",
      "54:\tlearn: 0.4708729\ttotal: 6.86s\tremaining: 5.61s\n",
      "55:\tlearn: 0.4672546\ttotal: 6.99s\tremaining: 5.49s\n",
      "56:\tlearn: 0.4642559\ttotal: 7.08s\tremaining: 5.34s\n",
      "57:\tlearn: 0.4619318\ttotal: 7.22s\tremaining: 5.23s\n",
      "58:\tlearn: 0.4578439\ttotal: 7.37s\tremaining: 5.12s\n",
      "59:\tlearn: 0.4545032\ttotal: 7.47s\tremaining: 4.98s\n",
      "60:\tlearn: 0.4511226\ttotal: 7.6s\tremaining: 4.86s\n",
      "61:\tlearn: 0.4477411\ttotal: 7.72s\tremaining: 4.73s\n",
      "62:\tlearn: 0.4445478\ttotal: 7.83s\tremaining: 4.6s\n",
      "63:\tlearn: 0.4416380\ttotal: 7.93s\tremaining: 4.46s\n",
      "64:\tlearn: 0.4394933\ttotal: 8.09s\tremaining: 4.36s\n",
      "65:\tlearn: 0.4372109\ttotal: 8.23s\tremaining: 4.24s\n",
      "66:\tlearn: 0.4336404\ttotal: 8.35s\tremaining: 4.11s\n",
      "67:\tlearn: 0.4304628\ttotal: 8.46s\tremaining: 3.98s\n",
      "68:\tlearn: 0.4258958\ttotal: 8.61s\tremaining: 3.87s\n",
      "69:\tlearn: 0.4229904\ttotal: 8.73s\tremaining: 3.74s\n",
      "70:\tlearn: 0.4197847\ttotal: 8.84s\tremaining: 3.61s\n",
      "71:\tlearn: 0.4174153\ttotal: 8.99s\tremaining: 3.5s\n",
      "72:\tlearn: 0.4153965\ttotal: 9.12s\tremaining: 3.37s\n",
      "73:\tlearn: 0.4130962\ttotal: 9.22s\tremaining: 3.24s\n",
      "74:\tlearn: 0.4113210\ttotal: 9.36s\tremaining: 3.12s\n",
      "75:\tlearn: 0.4078417\ttotal: 9.51s\tremaining: 3s\n",
      "76:\tlearn: 0.4055967\ttotal: 9.6s\tremaining: 2.87s\n",
      "77:\tlearn: 0.4035801\ttotal: 9.72s\tremaining: 2.74s\n",
      "78:\tlearn: 0.4014691\ttotal: 9.88s\tremaining: 2.63s\n",
      "79:\tlearn: 0.3990399\ttotal: 10s\tremaining: 2.5s\n",
      "80:\tlearn: 0.3970689\ttotal: 10.1s\tremaining: 2.37s\n",
      "81:\tlearn: 0.3944764\ttotal: 10.2s\tremaining: 2.25s\n",
      "82:\tlearn: 0.3914582\ttotal: 10.4s\tremaining: 2.13s\n",
      "83:\tlearn: 0.3885435\ttotal: 10.5s\tremaining: 2s\n",
      "84:\tlearn: 0.3863894\ttotal: 10.6s\tremaining: 1.87s\n",
      "85:\tlearn: 0.3842831\ttotal: 10.8s\tremaining: 1.75s\n",
      "86:\tlearn: 0.3820615\ttotal: 10.9s\tremaining: 1.63s\n",
      "87:\tlearn: 0.3798863\ttotal: 11s\tremaining: 1.5s\n",
      "88:\tlearn: 0.3778150\ttotal: 11.1s\tremaining: 1.37s\n",
      "89:\tlearn: 0.3757034\ttotal: 11.3s\tremaining: 1.25s\n",
      "90:\tlearn: 0.3740462\ttotal: 11.4s\tremaining: 1.13s\n",
      "91:\tlearn: 0.3720076\ttotal: 11.5s\tremaining: 1s\n",
      "92:\tlearn: 0.3701397\ttotal: 11.6s\tremaining: 876ms\n",
      "93:\tlearn: 0.3684544\ttotal: 11.8s\tremaining: 752ms\n",
      "94:\tlearn: 0.3657578\ttotal: 11.9s\tremaining: 625ms\n",
      "95:\tlearn: 0.3634176\ttotal: 12s\tremaining: 499ms\n",
      "96:\tlearn: 0.3611595\ttotal: 12.1s\tremaining: 375ms\n",
      "97:\tlearn: 0.3593241\ttotal: 12.3s\tremaining: 250ms\n",
      "98:\tlearn: 0.3571375\ttotal: 12.3s\tremaining: 125ms\n",
      "99:\tlearn: 0.3551487\ttotal: 12.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6880797\ttotal: 79.9ms\tremaining: 7.91s\n",
      "1:\tlearn: 0.6818682\ttotal: 231ms\tremaining: 11.3s\n",
      "2:\tlearn: 0.6774803\ttotal: 356ms\tremaining: 11.5s\n",
      "3:\tlearn: 0.6721748\ttotal: 461ms\tremaining: 11.1s\n",
      "4:\tlearn: 0.6673980\ttotal: 605ms\tremaining: 11.5s\n",
      "5:\tlearn: 0.6625343\ttotal: 702ms\tremaining: 11s\n",
      "6:\tlearn: 0.6563251\ttotal: 810ms\tremaining: 10.8s\n",
      "7:\tlearn: 0.6510307\ttotal: 957ms\tremaining: 11s\n",
      "8:\tlearn: 0.6470408\ttotal: 1.11s\tremaining: 11.2s\n",
      "9:\tlearn: 0.6431452\ttotal: 1.18s\tremaining: 10.6s\n",
      "10:\tlearn: 0.6380327\ttotal: 1.32s\tremaining: 10.7s\n",
      "11:\tlearn: 0.6344196\ttotal: 1.47s\tremaining: 10.8s\n",
      "12:\tlearn: 0.6286606\ttotal: 1.55s\tremaining: 10.4s\n",
      "13:\tlearn: 0.6244889\ttotal: 1.65s\tremaining: 10.2s\n",
      "14:\tlearn: 0.6192625\ttotal: 1.79s\tremaining: 10.2s\n",
      "15:\tlearn: 0.6150284\ttotal: 1.93s\tremaining: 10.1s\n",
      "16:\tlearn: 0.6093483\ttotal: 2.04s\tremaining: 9.94s\n",
      "17:\tlearn: 0.6042472\ttotal: 2.16s\tremaining: 9.84s\n",
      "18:\tlearn: 0.5993382\ttotal: 2.38s\tremaining: 10.1s\n",
      "19:\tlearn: 0.5949045\ttotal: 2.52s\tremaining: 10.1s\n",
      "20:\tlearn: 0.5909451\ttotal: 2.6s\tremaining: 9.79s\n",
      "21:\tlearn: 0.5869726\ttotal: 2.72s\tremaining: 9.63s\n",
      "22:\tlearn: 0.5825518\ttotal: 2.85s\tremaining: 9.55s\n",
      "23:\tlearn: 0.5777493\ttotal: 3s\tremaining: 9.51s\n",
      "24:\tlearn: 0.5734624\ttotal: 3.12s\tremaining: 9.37s\n",
      "25:\tlearn: 0.5699557\ttotal: 3.23s\tremaining: 9.18s\n",
      "26:\tlearn: 0.5660033\ttotal: 3.37s\tremaining: 9.12s\n",
      "27:\tlearn: 0.5618131\ttotal: 3.52s\tremaining: 9.05s\n",
      "28:\tlearn: 0.5583875\ttotal: 3.6s\tremaining: 8.81s\n",
      "29:\tlearn: 0.5536714\ttotal: 3.75s\tremaining: 8.74s\n",
      "30:\tlearn: 0.5493207\ttotal: 3.9s\tremaining: 8.69s\n",
      "31:\tlearn: 0.5453186\ttotal: 3.99s\tremaining: 8.48s\n",
      "32:\tlearn: 0.5422829\ttotal: 4.11s\tremaining: 8.34s\n",
      "33:\tlearn: 0.5387647\ttotal: 4.25s\tremaining: 8.24s\n",
      "34:\tlearn: 0.5352597\ttotal: 4.33s\tremaining: 8.03s\n",
      "35:\tlearn: 0.5313355\ttotal: 4.47s\tremaining: 7.95s\n",
      "36:\tlearn: 0.5273234\ttotal: 4.62s\tremaining: 7.86s\n",
      "37:\tlearn: 0.5235536\ttotal: 4.7s\tremaining: 7.67s\n",
      "38:\tlearn: 0.5204068\ttotal: 4.84s\tremaining: 7.57s\n",
      "39:\tlearn: 0.5162947\ttotal: 4.98s\tremaining: 7.47s\n",
      "40:\tlearn: 0.5121150\ttotal: 5.08s\tremaining: 7.31s\n",
      "41:\tlearn: 0.5081280\ttotal: 5.22s\tremaining: 7.21s\n",
      "42:\tlearn: 0.5042239\ttotal: 5.38s\tremaining: 7.13s\n",
      "43:\tlearn: 0.4999299\ttotal: 5.46s\tremaining: 6.95s\n",
      "44:\tlearn: 0.4969930\ttotal: 5.58s\tremaining: 6.83s\n",
      "45:\tlearn: 0.4932357\ttotal: 5.67s\tremaining: 6.65s\n",
      "46:\tlearn: 0.4896350\ttotal: 5.79s\tremaining: 6.53s\n",
      "47:\tlearn: 0.4867808\ttotal: 5.95s\tremaining: 6.44s\n",
      "48:\tlearn: 0.4837033\ttotal: 6.07s\tremaining: 6.31s\n",
      "49:\tlearn: 0.4808860\ttotal: 6.17s\tremaining: 6.17s\n",
      "50:\tlearn: 0.4769601\ttotal: 6.29s\tremaining: 6.05s\n",
      "51:\tlearn: 0.4744352\ttotal: 6.43s\tremaining: 5.94s\n",
      "52:\tlearn: 0.4711509\ttotal: 6.59s\tremaining: 5.84s\n",
      "53:\tlearn: 0.4676879\ttotal: 6.74s\tremaining: 5.74s\n",
      "54:\tlearn: 0.4654209\ttotal: 6.83s\tremaining: 5.59s\n",
      "55:\tlearn: 0.4628090\ttotal: 6.96s\tremaining: 5.47s\n",
      "56:\tlearn: 0.4600492\ttotal: 7.1s\tremaining: 5.36s\n",
      "57:\tlearn: 0.4572453\ttotal: 7.21s\tremaining: 5.22s\n",
      "58:\tlearn: 0.4531456\ttotal: 7.33s\tremaining: 5.09s\n",
      "59:\tlearn: 0.4507613\ttotal: 7.46s\tremaining: 4.97s\n",
      "60:\tlearn: 0.4478803\ttotal: 7.58s\tremaining: 4.85s\n",
      "61:\tlearn: 0.4455204\ttotal: 7.71s\tremaining: 4.72s\n",
      "62:\tlearn: 0.4426280\ttotal: 7.85s\tremaining: 4.61s\n",
      "63:\tlearn: 0.4402023\ttotal: 7.99s\tremaining: 4.49s\n",
      "64:\tlearn: 0.4372548\ttotal: 8.22s\tremaining: 4.43s\n",
      "65:\tlearn: 0.4343537\ttotal: 8.38s\tremaining: 4.32s\n",
      "66:\tlearn: 0.4323813\ttotal: 8.51s\tremaining: 4.19s\n",
      "67:\tlearn: 0.4291276\ttotal: 8.6s\tremaining: 4.05s\n",
      "68:\tlearn: 0.4252907\ttotal: 8.76s\tremaining: 3.94s\n",
      "69:\tlearn: 0.4221023\ttotal: 8.9s\tremaining: 3.82s\n",
      "70:\tlearn: 0.4190855\ttotal: 9.08s\tremaining: 3.71s\n",
      "71:\tlearn: 0.4168767\ttotal: 9.23s\tremaining: 3.59s\n",
      "72:\tlearn: 0.4144791\ttotal: 9.32s\tremaining: 3.45s\n",
      "73:\tlearn: 0.4120573\ttotal: 9.48s\tremaining: 3.33s\n",
      "74:\tlearn: 0.4098654\ttotal: 9.63s\tremaining: 3.21s\n",
      "75:\tlearn: 0.4069486\ttotal: 9.78s\tremaining: 3.09s\n",
      "76:\tlearn: 0.4039800\ttotal: 9.93s\tremaining: 2.97s\n",
      "77:\tlearn: 0.4014774\ttotal: 10s\tremaining: 2.82s\n",
      "78:\tlearn: 0.3995951\ttotal: 10.1s\tremaining: 2.69s\n",
      "79:\tlearn: 0.3964382\ttotal: 10.3s\tremaining: 2.58s\n",
      "80:\tlearn: 0.3942731\ttotal: 10.5s\tremaining: 2.46s\n",
      "81:\tlearn: 0.3920769\ttotal: 10.7s\tremaining: 2.34s\n",
      "82:\tlearn: 0.3896094\ttotal: 10.7s\tremaining: 2.2s\n",
      "83:\tlearn: 0.3874489\ttotal: 10.9s\tremaining: 2.07s\n",
      "84:\tlearn: 0.3850470\ttotal: 11s\tremaining: 1.94s\n",
      "85:\tlearn: 0.3828388\ttotal: 11.1s\tremaining: 1.8s\n",
      "86:\tlearn: 0.3811710\ttotal: 11.2s\tremaining: 1.67s\n",
      "87:\tlearn: 0.3792353\ttotal: 11.3s\tremaining: 1.55s\n",
      "88:\tlearn: 0.3764106\ttotal: 11.5s\tremaining: 1.42s\n",
      "89:\tlearn: 0.3737977\ttotal: 11.6s\tremaining: 1.29s\n",
      "90:\tlearn: 0.3721205\ttotal: 11.8s\tremaining: 1.16s\n",
      "91:\tlearn: 0.3697973\ttotal: 11.9s\tremaining: 1.03s\n",
      "92:\tlearn: 0.3677149\ttotal: 12s\tremaining: 902ms\n",
      "93:\tlearn: 0.3646969\ttotal: 12.1s\tremaining: 770ms\n",
      "94:\tlearn: 0.3626401\ttotal: 12.2s\tremaining: 641ms\n",
      "95:\tlearn: 0.3603681\ttotal: 12.3s\tremaining: 514ms\n",
      "96:\tlearn: 0.3583270\ttotal: 12.5s\tremaining: 386ms\n",
      "97:\tlearn: 0.3563038\ttotal: 12.6s\tremaining: 258ms\n",
      "98:\tlearn: 0.3534306\ttotal: 12.9s\tremaining: 130ms\n",
      "99:\tlearn: 0.3506185\ttotal: 13s\tremaining: 0us\n",
      "0:\tlearn: 0.6878735\ttotal: 72.1ms\tremaining: 7.14s\n",
      "1:\tlearn: 0.6825029\ttotal: 212ms\tremaining: 10.4s\n",
      "2:\tlearn: 0.6778482\ttotal: 287ms\tremaining: 9.28s\n",
      "3:\tlearn: 0.6720200\ttotal: 443ms\tremaining: 10.6s\n",
      "4:\tlearn: 0.6674327\ttotal: 583ms\tremaining: 11.1s\n",
      "5:\tlearn: 0.6628529\ttotal: 658ms\tremaining: 10.3s\n",
      "6:\tlearn: 0.6561532\ttotal: 789ms\tremaining: 10.5s\n",
      "7:\tlearn: 0.6514322\ttotal: 942ms\tremaining: 10.8s\n",
      "8:\tlearn: 0.6463813\ttotal: 1.09s\tremaining: 11s\n",
      "9:\tlearn: 0.6432097\ttotal: 1.17s\tremaining: 10.5s\n",
      "10:\tlearn: 0.6381103\ttotal: 1.32s\tremaining: 10.6s\n",
      "11:\tlearn: 0.6339496\ttotal: 1.39s\tremaining: 10.2s\n",
      "12:\tlearn: 0.6293647\ttotal: 1.5s\tremaining: 10.1s\n",
      "13:\tlearn: 0.6237713\ttotal: 1.65s\tremaining: 10.2s\n",
      "14:\tlearn: 0.6186793\ttotal: 1.73s\tremaining: 9.8s\n",
      "15:\tlearn: 0.6149232\ttotal: 1.86s\tremaining: 9.77s\n",
      "16:\tlearn: 0.6102152\ttotal: 2.01s\tremaining: 9.83s\n",
      "17:\tlearn: 0.6051483\ttotal: 2.16s\tremaining: 9.84s\n",
      "18:\tlearn: 0.6020813\ttotal: 2.24s\tremaining: 9.54s\n",
      "19:\tlearn: 0.5976101\ttotal: 2.39s\tremaining: 9.58s\n",
      "20:\tlearn: 0.5935722\ttotal: 2.55s\tremaining: 9.59s\n",
      "21:\tlearn: 0.5891544\ttotal: 2.66s\tremaining: 9.45s\n",
      "22:\tlearn: 0.5845655\ttotal: 2.77s\tremaining: 9.28s\n",
      "23:\tlearn: 0.5802769\ttotal: 2.91s\tremaining: 9.22s\n",
      "24:\tlearn: 0.5763891\ttotal: 2.99s\tremaining: 8.96s\n",
      "25:\tlearn: 0.5721761\ttotal: 3.12s\tremaining: 8.89s\n",
      "26:\tlearn: 0.5670587\ttotal: 3.27s\tremaining: 8.85s\n",
      "27:\tlearn: 0.5637897\ttotal: 3.39s\tremaining: 8.71s\n",
      "28:\tlearn: 0.5596563\ttotal: 3.5s\tremaining: 8.58s\n",
      "29:\tlearn: 0.5551703\ttotal: 3.63s\tremaining: 8.48s\n",
      "30:\tlearn: 0.5512518\ttotal: 3.71s\tremaining: 8.27s\n",
      "31:\tlearn: 0.5481070\ttotal: 3.83s\tremaining: 8.14s\n",
      "32:\tlearn: 0.5438003\ttotal: 3.91s\tremaining: 7.94s\n",
      "33:\tlearn: 0.5402521\ttotal: 4.03s\tremaining: 7.82s\n",
      "34:\tlearn: 0.5360666\ttotal: 4.17s\tremaining: 7.75s\n",
      "35:\tlearn: 0.5326195\ttotal: 4.32s\tremaining: 7.68s\n",
      "36:\tlearn: 0.5291217\ttotal: 4.44s\tremaining: 7.57s\n",
      "37:\tlearn: 0.5251356\ttotal: 4.56s\tremaining: 7.43s\n",
      "38:\tlearn: 0.5210290\ttotal: 4.69s\tremaining: 7.33s\n",
      "39:\tlearn: 0.5176493\ttotal: 4.83s\tremaining: 7.24s\n",
      "40:\tlearn: 0.5141605\ttotal: 4.92s\tremaining: 7.08s\n",
      "41:\tlearn: 0.5101016\ttotal: 5.07s\tremaining: 7s\n",
      "42:\tlearn: 0.5055789\ttotal: 5.2s\tremaining: 6.89s\n",
      "43:\tlearn: 0.5013686\ttotal: 5.28s\tremaining: 6.72s\n",
      "44:\tlearn: 0.4982077\ttotal: 5.42s\tremaining: 6.63s\n",
      "45:\tlearn: 0.4943311\ttotal: 5.57s\tremaining: 6.54s\n",
      "46:\tlearn: 0.4906946\ttotal: 5.69s\tremaining: 6.41s\n",
      "47:\tlearn: 0.4873112\ttotal: 5.79s\tremaining: 6.28s\n",
      "48:\tlearn: 0.4841844\ttotal: 5.93s\tremaining: 6.17s\n",
      "49:\tlearn: 0.4814546\ttotal: 6.08s\tremaining: 6.08s\n",
      "50:\tlearn: 0.4771604\ttotal: 6.2s\tremaining: 5.96s\n",
      "51:\tlearn: 0.4736133\ttotal: 6.31s\tremaining: 5.83s\n",
      "52:\tlearn: 0.4704937\ttotal: 6.47s\tremaining: 5.73s\n",
      "53:\tlearn: 0.4671269\ttotal: 6.6s\tremaining: 5.63s\n",
      "54:\tlearn: 0.4644365\ttotal: 6.72s\tremaining: 5.5s\n",
      "55:\tlearn: 0.4615255\ttotal: 6.84s\tremaining: 5.37s\n",
      "56:\tlearn: 0.4592796\ttotal: 6.97s\tremaining: 5.26s\n",
      "57:\tlearn: 0.4552680\ttotal: 7.11s\tremaining: 5.15s\n",
      "58:\tlearn: 0.4521531\ttotal: 7.21s\tremaining: 5.01s\n",
      "59:\tlearn: 0.4490882\ttotal: 7.37s\tremaining: 4.91s\n",
      "60:\tlearn: 0.4462347\ttotal: 7.5s\tremaining: 4.8s\n",
      "61:\tlearn: 0.4434560\ttotal: 7.66s\tremaining: 4.7s\n",
      "62:\tlearn: 0.4398623\ttotal: 7.84s\tremaining: 4.61s\n",
      "63:\tlearn: 0.4373506\ttotal: 7.92s\tremaining: 4.46s\n",
      "64:\tlearn: 0.4348645\ttotal: 8.12s\tremaining: 4.37s\n",
      "65:\tlearn: 0.4319528\ttotal: 8.25s\tremaining: 4.25s\n",
      "66:\tlearn: 0.4297474\ttotal: 8.39s\tremaining: 4.13s\n",
      "67:\tlearn: 0.4267113\ttotal: 8.54s\tremaining: 4.02s\n",
      "68:\tlearn: 0.4236621\ttotal: 8.67s\tremaining: 3.9s\n",
      "69:\tlearn: 0.4215090\ttotal: 8.77s\tremaining: 3.76s\n",
      "70:\tlearn: 0.4176604\ttotal: 8.92s\tremaining: 3.64s\n",
      "71:\tlearn: 0.4140094\ttotal: 9.04s\tremaining: 3.52s\n",
      "72:\tlearn: 0.4112109\ttotal: 9.14s\tremaining: 3.38s\n",
      "73:\tlearn: 0.4094304\ttotal: 9.29s\tremaining: 3.26s\n",
      "74:\tlearn: 0.4074491\ttotal: 9.38s\tremaining: 3.13s\n",
      "75:\tlearn: 0.4044707\ttotal: 9.49s\tremaining: 3s\n",
      "76:\tlearn: 0.4020343\ttotal: 9.64s\tremaining: 2.88s\n",
      "77:\tlearn: 0.3997835\ttotal: 9.71s\tremaining: 2.74s\n",
      "78:\tlearn: 0.3976705\ttotal: 9.87s\tremaining: 2.62s\n",
      "79:\tlearn: 0.3946811\ttotal: 10s\tremaining: 2.51s\n",
      "80:\tlearn: 0.3924898\ttotal: 10.2s\tremaining: 2.38s\n",
      "81:\tlearn: 0.3901042\ttotal: 10.3s\tremaining: 2.26s\n",
      "82:\tlearn: 0.3875307\ttotal: 10.4s\tremaining: 2.14s\n",
      "83:\tlearn: 0.3857940\ttotal: 10.5s\tremaining: 2s\n",
      "84:\tlearn: 0.3839994\ttotal: 10.6s\tremaining: 1.88s\n",
      "85:\tlearn: 0.3817190\ttotal: 10.8s\tremaining: 1.76s\n",
      "86:\tlearn: 0.3795333\ttotal: 10.9s\tremaining: 1.63s\n",
      "87:\tlearn: 0.3772854\ttotal: 11s\tremaining: 1.5s\n",
      "88:\tlearn: 0.3749801\ttotal: 11.2s\tremaining: 1.38s\n",
      "89:\tlearn: 0.3728068\ttotal: 11.3s\tremaining: 1.26s\n",
      "90:\tlearn: 0.3713005\ttotal: 11.4s\tremaining: 1.13s\n",
      "91:\tlearn: 0.3693416\ttotal: 11.5s\tremaining: 1s\n",
      "92:\tlearn: 0.3672156\ttotal: 11.7s\tremaining: 879ms\n",
      "93:\tlearn: 0.3643604\ttotal: 11.8s\tremaining: 751ms\n",
      "94:\tlearn: 0.3623726\ttotal: 11.9s\tremaining: 626ms\n",
      "95:\tlearn: 0.3598873\ttotal: 12s\tremaining: 502ms\n",
      "96:\tlearn: 0.3582068\ttotal: 12.2s\tremaining: 377ms\n",
      "97:\tlearn: 0.3561873\ttotal: 12.3s\tremaining: 250ms\n",
      "98:\tlearn: 0.3538391\ttotal: 12.4s\tremaining: 125ms\n",
      "99:\tlearn: 0.3519529\ttotal: 12.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6608068\ttotal: 3.31ms\tremaining: 327ms\n",
      "1:\tlearn: 0.6320222\ttotal: 6.75ms\tremaining: 331ms\n",
      "2:\tlearn: 0.6067147\ttotal: 9.93ms\tremaining: 321ms\n",
      "3:\tlearn: 0.5861865\ttotal: 12.7ms\tremaining: 305ms\n",
      "4:\tlearn: 0.5645105\ttotal: 16.3ms\tremaining: 309ms\n",
      "5:\tlearn: 0.5467279\ttotal: 19.3ms\tremaining: 303ms\n",
      "6:\tlearn: 0.5271783\ttotal: 22.4ms\tremaining: 298ms\n",
      "7:\tlearn: 0.5063034\ttotal: 25.4ms\tremaining: 292ms\n",
      "8:\tlearn: 0.4785326\ttotal: 28.3ms\tremaining: 286ms\n",
      "9:\tlearn: 0.4638592\ttotal: 31.2ms\tremaining: 281ms\n",
      "10:\tlearn: 0.4444502\ttotal: 34ms\tremaining: 275ms\n",
      "11:\tlearn: 0.4287031\ttotal: 36.9ms\tremaining: 271ms\n",
      "12:\tlearn: 0.4112053\ttotal: 42.2ms\tremaining: 283ms\n",
      "13:\tlearn: 0.3986353\ttotal: 47.5ms\tremaining: 292ms\n",
      "14:\tlearn: 0.3878131\ttotal: 52.9ms\tremaining: 300ms\n",
      "15:\tlearn: 0.3704585\ttotal: 58.1ms\tremaining: 305ms\n",
      "16:\tlearn: 0.3609618\ttotal: 63.1ms\tremaining: 308ms\n",
      "17:\tlearn: 0.3499443\ttotal: 68.4ms\tremaining: 312ms\n",
      "18:\tlearn: 0.3405166\ttotal: 73.4ms\tremaining: 313ms\n",
      "19:\tlearn: 0.3311994\ttotal: 78.5ms\tremaining: 314ms\n",
      "20:\tlearn: 0.3210013\ttotal: 83.9ms\tremaining: 316ms\n",
      "21:\tlearn: 0.3133189\ttotal: 88.8ms\tremaining: 315ms\n",
      "22:\tlearn: 0.3034235\ttotal: 94.1ms\tremaining: 315ms\n",
      "23:\tlearn: 0.2930079\ttotal: 99ms\tremaining: 314ms\n",
      "24:\tlearn: 0.2838173\ttotal: 104ms\tremaining: 313ms\n",
      "25:\tlearn: 0.2761828\ttotal: 110ms\tremaining: 312ms\n",
      "26:\tlearn: 0.2681282\ttotal: 115ms\tremaining: 310ms\n",
      "27:\tlearn: 0.2612511\ttotal: 120ms\tremaining: 308ms\n",
      "28:\tlearn: 0.2549008\ttotal: 125ms\tremaining: 306ms\n",
      "29:\tlearn: 0.2493033\ttotal: 129ms\tremaining: 300ms\n",
      "30:\tlearn: 0.2427661\ttotal: 133ms\tremaining: 296ms\n",
      "31:\tlearn: 0.2378534\ttotal: 136ms\tremaining: 290ms\n",
      "32:\tlearn: 0.2320773\ttotal: 140ms\tremaining: 285ms\n",
      "33:\tlearn: 0.2226464\ttotal: 144ms\tremaining: 280ms\n",
      "34:\tlearn: 0.2161842\ttotal: 147ms\tremaining: 273ms\n",
      "35:\tlearn: 0.2118557\ttotal: 150ms\tremaining: 267ms\n",
      "36:\tlearn: 0.2083174\ttotal: 153ms\tremaining: 261ms\n",
      "37:\tlearn: 0.2043554\ttotal: 157ms\tremaining: 256ms\n",
      "38:\tlearn: 0.2006541\ttotal: 160ms\tremaining: 250ms\n",
      "39:\tlearn: 0.1947033\ttotal: 163ms\tremaining: 244ms\n",
      "40:\tlearn: 0.1909889\ttotal: 166ms\tremaining: 239ms\n",
      "41:\tlearn: 0.1880000\ttotal: 169ms\tremaining: 233ms\n",
      "42:\tlearn: 0.1849775\ttotal: 173ms\tremaining: 229ms\n",
      "43:\tlearn: 0.1806002\ttotal: 176ms\tremaining: 224ms\n",
      "44:\tlearn: 0.1754647\ttotal: 178ms\tremaining: 217ms\n",
      "45:\tlearn: 0.1694933\ttotal: 180ms\tremaining: 211ms\n",
      "46:\tlearn: 0.1660482\ttotal: 182ms\tremaining: 205ms\n",
      "47:\tlearn: 0.1646973\ttotal: 184ms\tremaining: 199ms\n",
      "48:\tlearn: 0.1615820\ttotal: 187ms\tremaining: 195ms\n",
      "49:\tlearn: 0.1583964\ttotal: 190ms\tremaining: 190ms\n",
      "50:\tlearn: 0.1551968\ttotal: 193ms\tremaining: 185ms\n",
      "51:\tlearn: 0.1516481\ttotal: 196ms\tremaining: 181ms\n",
      "52:\tlearn: 0.1492539\ttotal: 198ms\tremaining: 176ms\n",
      "53:\tlearn: 0.1462464\ttotal: 204ms\tremaining: 173ms\n",
      "54:\tlearn: 0.1433067\ttotal: 209ms\tremaining: 171ms\n",
      "55:\tlearn: 0.1403644\ttotal: 214ms\tremaining: 168ms\n",
      "56:\tlearn: 0.1377123\ttotal: 219ms\tremaining: 165ms\n",
      "57:\tlearn: 0.1345185\ttotal: 224ms\tremaining: 162ms\n",
      "58:\tlearn: 0.1311732\ttotal: 229ms\tremaining: 159ms\n",
      "59:\tlearn: 0.1276447\ttotal: 235ms\tremaining: 156ms\n",
      "60:\tlearn: 0.1254088\ttotal: 240ms\tremaining: 153ms\n",
      "61:\tlearn: 0.1236195\ttotal: 245ms\tremaining: 150ms\n",
      "62:\tlearn: 0.1212234\ttotal: 251ms\tremaining: 147ms\n",
      "63:\tlearn: 0.1188190\ttotal: 256ms\tremaining: 144ms\n",
      "64:\tlearn: 0.1166137\ttotal: 261ms\tremaining: 140ms\n",
      "65:\tlearn: 0.1145558\ttotal: 266ms\tremaining: 137ms\n",
      "66:\tlearn: 0.1121515\ttotal: 271ms\tremaining: 134ms\n",
      "67:\tlearn: 0.1099939\ttotal: 276ms\tremaining: 130ms\n",
      "68:\tlearn: 0.1058108\ttotal: 282ms\tremaining: 127ms\n",
      "69:\tlearn: 0.1037820\ttotal: 286ms\tremaining: 123ms\n",
      "70:\tlearn: 0.1024696\ttotal: 290ms\tremaining: 118ms\n",
      "71:\tlearn: 0.1007542\ttotal: 294ms\tremaining: 114ms\n",
      "72:\tlearn: 0.0982844\ttotal: 297ms\tremaining: 110ms\n",
      "73:\tlearn: 0.0961965\ttotal: 301ms\tremaining: 106ms\n",
      "74:\tlearn: 0.0943496\ttotal: 305ms\tremaining: 102ms\n",
      "75:\tlearn: 0.0926548\ttotal: 309ms\tremaining: 97.4ms\n",
      "76:\tlearn: 0.0907737\ttotal: 312ms\tremaining: 93.1ms\n",
      "77:\tlearn: 0.0892924\ttotal: 315ms\tremaining: 88.8ms\n",
      "78:\tlearn: 0.0878858\ttotal: 318ms\tremaining: 84.5ms\n",
      "79:\tlearn: 0.0864768\ttotal: 321ms\tremaining: 80.3ms\n",
      "80:\tlearn: 0.0851126\ttotal: 324ms\tremaining: 76ms\n",
      "81:\tlearn: 0.0833539\ttotal: 327ms\tremaining: 71.8ms\n",
      "82:\tlearn: 0.0822437\ttotal: 330ms\tremaining: 67.6ms\n",
      "83:\tlearn: 0.0810132\ttotal: 333ms\tremaining: 63.4ms\n",
      "84:\tlearn: 0.0798489\ttotal: 336ms\tremaining: 59.3ms\n",
      "85:\tlearn: 0.0785188\ttotal: 339ms\tremaining: 55.2ms\n",
      "86:\tlearn: 0.0775274\ttotal: 342ms\tremaining: 51.1ms\n",
      "87:\tlearn: 0.0769785\ttotal: 345ms\tremaining: 47ms\n",
      "88:\tlearn: 0.0758908\ttotal: 348ms\tremaining: 43ms\n",
      "89:\tlearn: 0.0745358\ttotal: 351ms\tremaining: 39ms\n",
      "90:\tlearn: 0.0737629\ttotal: 353ms\tremaining: 34.9ms\n",
      "91:\tlearn: 0.0727782\ttotal: 356ms\tremaining: 30.9ms\n",
      "92:\tlearn: 0.0715564\ttotal: 358ms\tremaining: 27ms\n",
      "93:\tlearn: 0.0702906\ttotal: 361ms\tremaining: 23.1ms\n",
      "94:\tlearn: 0.0691486\ttotal: 365ms\tremaining: 19.2ms\n",
      "95:\tlearn: 0.0682401\ttotal: 367ms\tremaining: 15.3ms\n",
      "96:\tlearn: 0.0677423\ttotal: 373ms\tremaining: 11.5ms\n",
      "97:\tlearn: 0.0665195\ttotal: 378ms\tremaining: 7.71ms\n",
      "98:\tlearn: 0.0655649\ttotal: 383ms\tremaining: 3.87ms\n",
      "99:\tlearn: 0.0647745\ttotal: 388ms\tremaining: 0us\n",
      "0:\tlearn: 0.6612732\ttotal: 2.98ms\tremaining: 296ms\n",
      "1:\tlearn: 0.6332328\ttotal: 5.73ms\tremaining: 281ms\n",
      "2:\tlearn: 0.6047212\ttotal: 8.73ms\tremaining: 282ms\n",
      "3:\tlearn: 0.5862979\ttotal: 11.5ms\tremaining: 276ms\n",
      "4:\tlearn: 0.5673984\ttotal: 14.5ms\tremaining: 275ms\n",
      "5:\tlearn: 0.5423351\ttotal: 17.2ms\tremaining: 269ms\n",
      "6:\tlearn: 0.5260458\ttotal: 19.9ms\tremaining: 264ms\n",
      "7:\tlearn: 0.5077571\ttotal: 22.8ms\tremaining: 263ms\n",
      "8:\tlearn: 0.4795993\ttotal: 25.7ms\tremaining: 260ms\n",
      "9:\tlearn: 0.4625934\ttotal: 28.6ms\tremaining: 257ms\n",
      "10:\tlearn: 0.4462838\ttotal: 31.3ms\tremaining: 253ms\n",
      "11:\tlearn: 0.4309581\ttotal: 34.2ms\tremaining: 251ms\n",
      "12:\tlearn: 0.4133478\ttotal: 36.9ms\tremaining: 247ms\n",
      "13:\tlearn: 0.3997383\ttotal: 42.2ms\tremaining: 259ms\n",
      "14:\tlearn: 0.3879904\ttotal: 47.4ms\tremaining: 268ms\n",
      "15:\tlearn: 0.3746951\ttotal: 52.4ms\tremaining: 275ms\n",
      "16:\tlearn: 0.3591345\ttotal: 57.4ms\tremaining: 280ms\n",
      "17:\tlearn: 0.3443749\ttotal: 62.5ms\tremaining: 285ms\n",
      "18:\tlearn: 0.3302664\ttotal: 67.9ms\tremaining: 289ms\n",
      "19:\tlearn: 0.3196470\ttotal: 72.9ms\tremaining: 292ms\n",
      "20:\tlearn: 0.3130902\ttotal: 78.1ms\tremaining: 294ms\n",
      "21:\tlearn: 0.3022048\ttotal: 83.3ms\tremaining: 295ms\n",
      "22:\tlearn: 0.2934854\ttotal: 88.4ms\tremaining: 296ms\n",
      "23:\tlearn: 0.2853173\ttotal: 93.4ms\tremaining: 296ms\n",
      "24:\tlearn: 0.2763206\ttotal: 98.9ms\tremaining: 297ms\n",
      "25:\tlearn: 0.2694986\ttotal: 104ms\tremaining: 296ms\n",
      "26:\tlearn: 0.2614607\ttotal: 109ms\tremaining: 295ms\n",
      "27:\tlearn: 0.2556833\ttotal: 114ms\tremaining: 293ms\n",
      "28:\tlearn: 0.2504572\ttotal: 119ms\tremaining: 292ms\n",
      "29:\tlearn: 0.2438589\ttotal: 124ms\tremaining: 290ms\n",
      "30:\tlearn: 0.2361584\ttotal: 128ms\tremaining: 285ms\n",
      "31:\tlearn: 0.2301872\ttotal: 132ms\tremaining: 279ms\n",
      "32:\tlearn: 0.2198967\ttotal: 135ms\tremaining: 275ms\n",
      "33:\tlearn: 0.2161338\ttotal: 139ms\tremaining: 270ms\n",
      "34:\tlearn: 0.2084516\ttotal: 143ms\tremaining: 265ms\n",
      "35:\tlearn: 0.2040095\ttotal: 146ms\tremaining: 260ms\n",
      "36:\tlearn: 0.1984960\ttotal: 150ms\tremaining: 256ms\n",
      "37:\tlearn: 0.1943904\ttotal: 154ms\tremaining: 251ms\n",
      "38:\tlearn: 0.1886610\ttotal: 157ms\tremaining: 246ms\n",
      "39:\tlearn: 0.1847379\ttotal: 160ms\tremaining: 241ms\n",
      "40:\tlearn: 0.1804199\ttotal: 164ms\tremaining: 235ms\n",
      "41:\tlearn: 0.1763352\ttotal: 166ms\tremaining: 230ms\n",
      "42:\tlearn: 0.1738696\ttotal: 170ms\tremaining: 225ms\n",
      "43:\tlearn: 0.1707819\ttotal: 173ms\tremaining: 220ms\n",
      "44:\tlearn: 0.1677413\ttotal: 175ms\tremaining: 214ms\n",
      "45:\tlearn: 0.1650442\ttotal: 177ms\tremaining: 208ms\n",
      "46:\tlearn: 0.1622398\ttotal: 179ms\tremaining: 202ms\n",
      "47:\tlearn: 0.1587857\ttotal: 181ms\tremaining: 196ms\n",
      "48:\tlearn: 0.1558379\ttotal: 183ms\tremaining: 191ms\n",
      "49:\tlearn: 0.1541243\ttotal: 187ms\tremaining: 187ms\n",
      "50:\tlearn: 0.1515609\ttotal: 190ms\tremaining: 182ms\n",
      "51:\tlearn: 0.1486760\ttotal: 193ms\tremaining: 178ms\n",
      "52:\tlearn: 0.1455614\ttotal: 196ms\tremaining: 174ms\n",
      "53:\tlearn: 0.1405833\ttotal: 198ms\tremaining: 169ms\n",
      "54:\tlearn: 0.1379458\ttotal: 204ms\tremaining: 167ms\n",
      "55:\tlearn: 0.1351033\ttotal: 209ms\tremaining: 164ms\n",
      "56:\tlearn: 0.1323832\ttotal: 214ms\tremaining: 162ms\n",
      "57:\tlearn: 0.1299240\ttotal: 220ms\tremaining: 159ms\n",
      "58:\tlearn: 0.1252988\ttotal: 225ms\tremaining: 156ms\n",
      "59:\tlearn: 0.1229376\ttotal: 230ms\tremaining: 154ms\n",
      "60:\tlearn: 0.1215430\ttotal: 236ms\tremaining: 151ms\n",
      "61:\tlearn: 0.1199700\ttotal: 241ms\tremaining: 148ms\n",
      "62:\tlearn: 0.1178884\ttotal: 246ms\tremaining: 144ms\n",
      "63:\tlearn: 0.1156398\ttotal: 251ms\tremaining: 141ms\n",
      "64:\tlearn: 0.1133314\ttotal: 256ms\tremaining: 138ms\n",
      "65:\tlearn: 0.1105953\ttotal: 262ms\tremaining: 135ms\n",
      "66:\tlearn: 0.1086467\ttotal: 267ms\tremaining: 131ms\n",
      "67:\tlearn: 0.1062038\ttotal: 272ms\tremaining: 128ms\n",
      "68:\tlearn: 0.1041286\ttotal: 277ms\tremaining: 124ms\n",
      "69:\tlearn: 0.1018915\ttotal: 282ms\tremaining: 121ms\n",
      "70:\tlearn: 0.1007339\ttotal: 287ms\tremaining: 117ms\n",
      "71:\tlearn: 0.0990699\ttotal: 291ms\tremaining: 113ms\n",
      "72:\tlearn: 0.0974423\ttotal: 295ms\tremaining: 109ms\n",
      "73:\tlearn: 0.0946959\ttotal: 298ms\tremaining: 105ms\n",
      "74:\tlearn: 0.0926609\ttotal: 302ms\tremaining: 101ms\n",
      "75:\tlearn: 0.0903638\ttotal: 306ms\tremaining: 96.6ms\n",
      "76:\tlearn: 0.0881457\ttotal: 310ms\tremaining: 92.5ms\n",
      "77:\tlearn: 0.0869767\ttotal: 313ms\tremaining: 88.4ms\n",
      "78:\tlearn: 0.0854221\ttotal: 317ms\tremaining: 84.3ms\n",
      "79:\tlearn: 0.0837310\ttotal: 320ms\tremaining: 80ms\n",
      "80:\tlearn: 0.0826677\ttotal: 323ms\tremaining: 75.8ms\n",
      "81:\tlearn: 0.0810908\ttotal: 326ms\tremaining: 71.7ms\n",
      "82:\tlearn: 0.0797037\ttotal: 329ms\tremaining: 67.4ms\n",
      "83:\tlearn: 0.0783332\ttotal: 332ms\tremaining: 63.3ms\n",
      "84:\tlearn: 0.0772572\ttotal: 335ms\tremaining: 59.1ms\n",
      "85:\tlearn: 0.0759428\ttotal: 338ms\tremaining: 55.1ms\n",
      "86:\tlearn: 0.0746476\ttotal: 341ms\tremaining: 51ms\n",
      "87:\tlearn: 0.0734939\ttotal: 345ms\tremaining: 47ms\n",
      "88:\tlearn: 0.0728527\ttotal: 348ms\tremaining: 43ms\n",
      "89:\tlearn: 0.0718072\ttotal: 351ms\tremaining: 38.9ms\n",
      "90:\tlearn: 0.0711641\ttotal: 353ms\tremaining: 35ms\n",
      "91:\tlearn: 0.0700812\ttotal: 356ms\tremaining: 31ms\n",
      "92:\tlearn: 0.0694446\ttotal: 359ms\tremaining: 27ms\n",
      "93:\tlearn: 0.0689536\ttotal: 363ms\tremaining: 23.2ms\n",
      "94:\tlearn: 0.0682390\ttotal: 366ms\tremaining: 19.2ms\n",
      "95:\tlearn: 0.0671957\ttotal: 368ms\tremaining: 15.4ms\n",
      "96:\tlearn: 0.0660382\ttotal: 374ms\tremaining: 11.6ms\n",
      "97:\tlearn: 0.0648283\ttotal: 379ms\tremaining: 7.73ms\n",
      "98:\tlearn: 0.0639782\ttotal: 384ms\tremaining: 3.88ms\n",
      "99:\tlearn: 0.0636176\ttotal: 390ms\tremaining: 0us\n",
      "0:\tlearn: 0.6602262\ttotal: 3.45ms\tremaining: 341ms\n",
      "1:\tlearn: 0.6311558\ttotal: 6.71ms\tremaining: 329ms\n",
      "2:\tlearn: 0.6013192\ttotal: 9.64ms\tremaining: 312ms\n",
      "3:\tlearn: 0.5776892\ttotal: 12.6ms\tremaining: 302ms\n",
      "4:\tlearn: 0.5495185\ttotal: 15.5ms\tremaining: 294ms\n",
      "5:\tlearn: 0.5273491\ttotal: 18.3ms\tremaining: 287ms\n",
      "6:\tlearn: 0.5095508\ttotal: 21.1ms\tremaining: 281ms\n",
      "7:\tlearn: 0.4911508\ttotal: 24ms\tremaining: 276ms\n",
      "8:\tlearn: 0.4751217\ttotal: 26.9ms\tremaining: 272ms\n",
      "9:\tlearn: 0.4594326\ttotal: 29.7ms\tremaining: 268ms\n",
      "10:\tlearn: 0.4410160\ttotal: 32.6ms\tremaining: 264ms\n",
      "11:\tlearn: 0.4229793\ttotal: 35.6ms\tremaining: 261ms\n",
      "12:\tlearn: 0.4104149\ttotal: 38.8ms\tremaining: 260ms\n",
      "13:\tlearn: 0.3963225\ttotal: 41.6ms\tremaining: 256ms\n",
      "14:\tlearn: 0.3821370\ttotal: 44.6ms\tremaining: 253ms\n",
      "15:\tlearn: 0.3731507\ttotal: 47.5ms\tremaining: 249ms\n",
      "16:\tlearn: 0.3610002\ttotal: 50.6ms\tremaining: 247ms\n",
      "17:\tlearn: 0.3513426\ttotal: 55.9ms\tremaining: 255ms\n",
      "18:\tlearn: 0.3398367\ttotal: 61.1ms\tremaining: 260ms\n",
      "19:\tlearn: 0.3305645\ttotal: 66.6ms\tremaining: 267ms\n",
      "20:\tlearn: 0.3193758\ttotal: 71.7ms\tremaining: 270ms\n",
      "21:\tlearn: 0.3140658\ttotal: 77.1ms\tremaining: 273ms\n",
      "22:\tlearn: 0.3044175\ttotal: 82.3ms\tremaining: 276ms\n",
      "23:\tlearn: 0.2935308\ttotal: 87.6ms\tremaining: 277ms\n",
      "24:\tlearn: 0.2859808\ttotal: 92.7ms\tremaining: 278ms\n",
      "25:\tlearn: 0.2786702\ttotal: 97.8ms\tremaining: 278ms\n",
      "26:\tlearn: 0.2700475\ttotal: 103ms\tremaining: 278ms\n",
      "27:\tlearn: 0.2636706\ttotal: 108ms\tremaining: 279ms\n",
      "28:\tlearn: 0.2579352\ttotal: 113ms\tremaining: 278ms\n",
      "29:\tlearn: 0.2509239\ttotal: 119ms\tremaining: 277ms\n",
      "30:\tlearn: 0.2422766\ttotal: 123ms\tremaining: 274ms\n",
      "31:\tlearn: 0.2361608\ttotal: 127ms\tremaining: 270ms\n",
      "32:\tlearn: 0.2307721\ttotal: 131ms\tremaining: 265ms\n",
      "33:\tlearn: 0.2256758\ttotal: 134ms\tremaining: 261ms\n",
      "34:\tlearn: 0.2211958\ttotal: 138ms\tremaining: 256ms\n",
      "35:\tlearn: 0.2173224\ttotal: 142ms\tremaining: 252ms\n",
      "36:\tlearn: 0.2133847\ttotal: 146ms\tremaining: 248ms\n",
      "37:\tlearn: 0.2085537\ttotal: 150ms\tremaining: 244ms\n",
      "38:\tlearn: 0.2033011\ttotal: 153ms\tremaining: 239ms\n",
      "39:\tlearn: 0.1988699\ttotal: 156ms\tremaining: 234ms\n",
      "40:\tlearn: 0.1937164\ttotal: 159ms\tremaining: 229ms\n",
      "41:\tlearn: 0.1893512\ttotal: 162ms\tremaining: 224ms\n",
      "42:\tlearn: 0.1872776\ttotal: 165ms\tremaining: 219ms\n",
      "43:\tlearn: 0.1835255\ttotal: 168ms\tremaining: 214ms\n",
      "44:\tlearn: 0.1804511\ttotal: 171ms\tremaining: 209ms\n",
      "45:\tlearn: 0.1769372\ttotal: 174ms\tremaining: 204ms\n",
      "46:\tlearn: 0.1744359\ttotal: 177ms\tremaining: 200ms\n",
      "47:\tlearn: 0.1709784\ttotal: 180ms\tremaining: 195ms\n",
      "48:\tlearn: 0.1674393\ttotal: 183ms\tremaining: 190ms\n",
      "49:\tlearn: 0.1647469\ttotal: 185ms\tremaining: 185ms\n",
      "50:\tlearn: 0.1604718\ttotal: 188ms\tremaining: 180ms\n",
      "51:\tlearn: 0.1574805\ttotal: 190ms\tremaining: 175ms\n",
      "52:\tlearn: 0.1538161\ttotal: 191ms\tremaining: 170ms\n",
      "53:\tlearn: 0.1500180\ttotal: 193ms\tremaining: 164ms\n",
      "54:\tlearn: 0.1467047\ttotal: 196ms\tremaining: 160ms\n",
      "55:\tlearn: 0.1451307\ttotal: 199ms\tremaining: 157ms\n",
      "56:\tlearn: 0.1399996\ttotal: 203ms\tremaining: 153ms\n",
      "57:\tlearn: 0.1366496\ttotal: 208ms\tremaining: 151ms\n",
      "58:\tlearn: 0.1339607\ttotal: 213ms\tremaining: 148ms\n",
      "59:\tlearn: 0.1313209\ttotal: 218ms\tremaining: 145ms\n",
      "60:\tlearn: 0.1284429\ttotal: 223ms\tremaining: 143ms\n",
      "61:\tlearn: 0.1248946\ttotal: 229ms\tremaining: 140ms\n",
      "62:\tlearn: 0.1227117\ttotal: 234ms\tremaining: 137ms\n",
      "63:\tlearn: 0.1198955\ttotal: 239ms\tremaining: 135ms\n",
      "64:\tlearn: 0.1182445\ttotal: 244ms\tremaining: 132ms\n",
      "65:\tlearn: 0.1158094\ttotal: 249ms\tremaining: 129ms\n",
      "66:\tlearn: 0.1129689\ttotal: 255ms\tremaining: 125ms\n",
      "67:\tlearn: 0.1111027\ttotal: 260ms\tremaining: 122ms\n",
      "68:\tlearn: 0.1092616\ttotal: 265ms\tremaining: 119ms\n",
      "69:\tlearn: 0.1075589\ttotal: 270ms\tremaining: 116ms\n",
      "70:\tlearn: 0.1055205\ttotal: 276ms\tremaining: 113ms\n",
      "71:\tlearn: 0.1040327\ttotal: 281ms\tremaining: 109ms\n",
      "72:\tlearn: 0.1022146\ttotal: 286ms\tremaining: 106ms\n",
      "73:\tlearn: 0.1010357\ttotal: 291ms\tremaining: 102ms\n",
      "74:\tlearn: 0.0987676\ttotal: 295ms\tremaining: 98.3ms\n",
      "75:\tlearn: 0.0958786\ttotal: 299ms\tremaining: 94.4ms\n",
      "76:\tlearn: 0.0937630\ttotal: 303ms\tremaining: 90.5ms\n",
      "77:\tlearn: 0.0923837\ttotal: 307ms\tremaining: 86.5ms\n",
      "78:\tlearn: 0.0908560\ttotal: 311ms\tremaining: 82.6ms\n",
      "79:\tlearn: 0.0890457\ttotal: 314ms\tremaining: 78.6ms\n",
      "80:\tlearn: 0.0874968\ttotal: 318ms\tremaining: 74.6ms\n",
      "81:\tlearn: 0.0857231\ttotal: 321ms\tremaining: 70.6ms\n",
      "82:\tlearn: 0.0844313\ttotal: 324ms\tremaining: 66.5ms\n",
      "83:\tlearn: 0.0831074\ttotal: 327ms\tremaining: 62.4ms\n",
      "84:\tlearn: 0.0818701\ttotal: 331ms\tremaining: 58.4ms\n",
      "85:\tlearn: 0.0804711\ttotal: 334ms\tremaining: 54.3ms\n",
      "86:\tlearn: 0.0798909\ttotal: 337ms\tremaining: 50.3ms\n",
      "87:\tlearn: 0.0785396\ttotal: 340ms\tremaining: 46.4ms\n",
      "88:\tlearn: 0.0768489\ttotal: 343ms\tremaining: 42.4ms\n",
      "89:\tlearn: 0.0754630\ttotal: 347ms\tremaining: 38.5ms\n",
      "90:\tlearn: 0.0739872\ttotal: 350ms\tremaining: 34.6ms\n",
      "91:\tlearn: 0.0725858\ttotal: 353ms\tremaining: 30.7ms\n",
      "92:\tlearn: 0.0705291\ttotal: 356ms\tremaining: 26.8ms\n",
      "93:\tlearn: 0.0691637\ttotal: 359ms\tremaining: 22.9ms\n",
      "94:\tlearn: 0.0677045\ttotal: 361ms\tremaining: 19ms\n",
      "95:\tlearn: 0.0658073\ttotal: 363ms\tremaining: 15.1ms\n",
      "96:\tlearn: 0.0648158\ttotal: 366ms\tremaining: 11.3ms\n",
      "97:\tlearn: 0.0639332\ttotal: 368ms\tremaining: 7.51ms\n",
      "98:\tlearn: 0.0629536\ttotal: 372ms\tremaining: 3.75ms\n",
      "99:\tlearn: 0.0624706\ttotal: 377ms\tremaining: 0us\n",
      "0:\tlearn: 0.6599093\ttotal: 6ms\tremaining: 594ms\n",
      "1:\tlearn: 0.6284991\ttotal: 10.9ms\tremaining: 533ms\n",
      "2:\tlearn: 0.6050162\ttotal: 14.5ms\tremaining: 470ms\n",
      "3:\tlearn: 0.5710825\ttotal: 18.3ms\tremaining: 440ms\n",
      "4:\tlearn: 0.5493189\ttotal: 22.2ms\tremaining: 422ms\n",
      "5:\tlearn: 0.5327275\ttotal: 25.9ms\tremaining: 406ms\n",
      "6:\tlearn: 0.5125023\ttotal: 29.6ms\tremaining: 393ms\n",
      "7:\tlearn: 0.4963396\ttotal: 33.5ms\tremaining: 385ms\n",
      "8:\tlearn: 0.4796005\ttotal: 37.1ms\tremaining: 375ms\n",
      "9:\tlearn: 0.4573769\ttotal: 40.2ms\tremaining: 362ms\n",
      "10:\tlearn: 0.4303893\ttotal: 43.4ms\tremaining: 351ms\n",
      "11:\tlearn: 0.4131730\ttotal: 46.4ms\tremaining: 340ms\n",
      "12:\tlearn: 0.4010610\ttotal: 49.3ms\tremaining: 330ms\n",
      "13:\tlearn: 0.3898391\ttotal: 52.3ms\tremaining: 321ms\n",
      "14:\tlearn: 0.3743176\ttotal: 55.4ms\tremaining: 314ms\n",
      "15:\tlearn: 0.3615416\ttotal: 58.5ms\tremaining: 307ms\n",
      "16:\tlearn: 0.3506328\ttotal: 61.5ms\tremaining: 301ms\n",
      "17:\tlearn: 0.3403063\ttotal: 64.6ms\tremaining: 294ms\n",
      "18:\tlearn: 0.3297160\ttotal: 67.7ms\tremaining: 289ms\n",
      "19:\tlearn: 0.3209228\ttotal: 70.7ms\tremaining: 283ms\n",
      "20:\tlearn: 0.3110661\ttotal: 73.5ms\tremaining: 277ms\n",
      "21:\tlearn: 0.3040660\ttotal: 76.7ms\tremaining: 272ms\n",
      "22:\tlearn: 0.2953537\ttotal: 79.8ms\tremaining: 267ms\n",
      "23:\tlearn: 0.2837860\ttotal: 82.8ms\tremaining: 262ms\n",
      "24:\tlearn: 0.2751688\ttotal: 85.7ms\tremaining: 257ms\n",
      "25:\tlearn: 0.2667139\ttotal: 88.5ms\tremaining: 252ms\n",
      "26:\tlearn: 0.2599454\ttotal: 91.3ms\tremaining: 247ms\n",
      "27:\tlearn: 0.2528542\ttotal: 94.1ms\tremaining: 242ms\n",
      "28:\tlearn: 0.2446138\ttotal: 96.8ms\tremaining: 237ms\n",
      "29:\tlearn: 0.2407237\ttotal: 102ms\tremaining: 238ms\n",
      "30:\tlearn: 0.2346537\ttotal: 107ms\tremaining: 239ms\n",
      "31:\tlearn: 0.2290125\ttotal: 113ms\tremaining: 239ms\n",
      "32:\tlearn: 0.2222846\ttotal: 118ms\tremaining: 239ms\n",
      "33:\tlearn: 0.2182842\ttotal: 123ms\tremaining: 238ms\n",
      "34:\tlearn: 0.2125159\ttotal: 128ms\tremaining: 238ms\n",
      "35:\tlearn: 0.2078020\ttotal: 133ms\tremaining: 237ms\n",
      "36:\tlearn: 0.2031475\ttotal: 139ms\tremaining: 236ms\n",
      "37:\tlearn: 0.1984372\ttotal: 144ms\tremaining: 234ms\n",
      "38:\tlearn: 0.1937886\ttotal: 149ms\tremaining: 233ms\n",
      "39:\tlearn: 0.1890262\ttotal: 154ms\tremaining: 231ms\n",
      "40:\tlearn: 0.1834515\ttotal: 159ms\tremaining: 229ms\n",
      "41:\tlearn: 0.1811337\ttotal: 164ms\tremaining: 227ms\n",
      "42:\tlearn: 0.1784322\ttotal: 169ms\tremaining: 225ms\n",
      "43:\tlearn: 0.1739690\ttotal: 172ms\tremaining: 219ms\n",
      "44:\tlearn: 0.1695514\ttotal: 176ms\tremaining: 215ms\n",
      "45:\tlearn: 0.1658889\ttotal: 180ms\tremaining: 211ms\n",
      "46:\tlearn: 0.1620221\ttotal: 187ms\tremaining: 211ms\n",
      "47:\tlearn: 0.1586221\ttotal: 191ms\tremaining: 207ms\n",
      "48:\tlearn: 0.1537042\ttotal: 195ms\tremaining: 203ms\n",
      "49:\tlearn: 0.1510637\ttotal: 198ms\tremaining: 198ms\n",
      "50:\tlearn: 0.1477521\ttotal: 201ms\tremaining: 193ms\n",
      "51:\tlearn: 0.1441172\ttotal: 204ms\tremaining: 189ms\n",
      "52:\tlearn: 0.1409477\ttotal: 207ms\tremaining: 184ms\n",
      "53:\tlearn: 0.1365787\ttotal: 210ms\tremaining: 179ms\n",
      "54:\tlearn: 0.1336744\ttotal: 213ms\tremaining: 175ms\n",
      "55:\tlearn: 0.1310721\ttotal: 216ms\tremaining: 170ms\n",
      "56:\tlearn: 0.1280609\ttotal: 219ms\tremaining: 165ms\n",
      "57:\tlearn: 0.1255550\ttotal: 222ms\tremaining: 161ms\n",
      "58:\tlearn: 0.1225497\ttotal: 226ms\tremaining: 157ms\n",
      "59:\tlearn: 0.1185758\ttotal: 229ms\tremaining: 152ms\n",
      "60:\tlearn: 0.1163621\ttotal: 231ms\tremaining: 148ms\n",
      "61:\tlearn: 0.1138708\ttotal: 234ms\tremaining: 144ms\n",
      "62:\tlearn: 0.1114758\ttotal: 237ms\tremaining: 139ms\n",
      "63:\tlearn: 0.1096995\ttotal: 240ms\tremaining: 135ms\n",
      "64:\tlearn: 0.1073592\ttotal: 243ms\tremaining: 131ms\n",
      "65:\tlearn: 0.1053000\ttotal: 246ms\tremaining: 127ms\n",
      "66:\tlearn: 0.1039913\ttotal: 249ms\tremaining: 123ms\n",
      "67:\tlearn: 0.1028204\ttotal: 252ms\tremaining: 119ms\n",
      "68:\tlearn: 0.1007429\ttotal: 255ms\tremaining: 114ms\n",
      "69:\tlearn: 0.0993066\ttotal: 260ms\tremaining: 111ms\n",
      "70:\tlearn: 0.0981577\ttotal: 265ms\tremaining: 108ms\n",
      "71:\tlearn: 0.0961758\ttotal: 270ms\tremaining: 105ms\n",
      "72:\tlearn: 0.0942177\ttotal: 276ms\tremaining: 102ms\n",
      "73:\tlearn: 0.0934035\ttotal: 281ms\tremaining: 98.7ms\n",
      "74:\tlearn: 0.0909091\ttotal: 286ms\tremaining: 95.3ms\n",
      "75:\tlearn: 0.0896749\ttotal: 291ms\tremaining: 91.9ms\n",
      "76:\tlearn: 0.0884050\ttotal: 296ms\tremaining: 88.4ms\n",
      "77:\tlearn: 0.0870399\ttotal: 301ms\tremaining: 85ms\n",
      "78:\tlearn: 0.0855160\ttotal: 306ms\tremaining: 81.4ms\n",
      "79:\tlearn: 0.0841047\ttotal: 312ms\tremaining: 77.9ms\n",
      "80:\tlearn: 0.0815315\ttotal: 317ms\tremaining: 74.3ms\n",
      "81:\tlearn: 0.0800460\ttotal: 322ms\tremaining: 70.7ms\n",
      "82:\tlearn: 0.0791345\ttotal: 327ms\tremaining: 67ms\n",
      "83:\tlearn: 0.0782018\ttotal: 332ms\tremaining: 63.3ms\n",
      "84:\tlearn: 0.0752787\ttotal: 338ms\tremaining: 59.6ms\n",
      "85:\tlearn: 0.0743085\ttotal: 343ms\tremaining: 55.9ms\n",
      "86:\tlearn: 0.0729882\ttotal: 348ms\tremaining: 52ms\n",
      "87:\tlearn: 0.0714272\ttotal: 352ms\tremaining: 48ms\n",
      "88:\tlearn: 0.0703599\ttotal: 355ms\tremaining: 43.9ms\n",
      "89:\tlearn: 0.0690422\ttotal: 359ms\tremaining: 39.9ms\n",
      "90:\tlearn: 0.0679709\ttotal: 363ms\tremaining: 35.9ms\n",
      "91:\tlearn: 0.0671290\ttotal: 385ms\tremaining: 33.4ms\n",
      "92:\tlearn: 0.0659202\ttotal: 390ms\tremaining: 29.4ms\n",
      "93:\tlearn: 0.0649820\ttotal: 393ms\tremaining: 25.1ms\n",
      "94:\tlearn: 0.0639701\ttotal: 396ms\tremaining: 20.9ms\n",
      "95:\tlearn: 0.0628452\ttotal: 398ms\tremaining: 16.6ms\n",
      "96:\tlearn: 0.0617748\ttotal: 401ms\tremaining: 12.4ms\n",
      "97:\tlearn: 0.0598703\ttotal: 402ms\tremaining: 8.21ms\n",
      "98:\tlearn: 0.0588431\ttotal: 404ms\tremaining: 4.08ms\n",
      "99:\tlearn: 0.0580432\ttotal: 406ms\tremaining: 0us\n",
      "0:\tlearn: 0.6588770\ttotal: 4.18ms\tremaining: 414ms\n",
      "1:\tlearn: 0.6308577\ttotal: 8.12ms\tremaining: 398ms\n",
      "2:\tlearn: 0.6014125\ttotal: 12.1ms\tremaining: 392ms\n",
      "3:\tlearn: 0.5775566\ttotal: 15.9ms\tremaining: 381ms\n",
      "4:\tlearn: 0.5481980\ttotal: 19.8ms\tremaining: 376ms\n",
      "5:\tlearn: 0.5234604\ttotal: 23.6ms\tremaining: 370ms\n",
      "6:\tlearn: 0.5091391\ttotal: 27.7ms\tremaining: 368ms\n",
      "7:\tlearn: 0.4920835\ttotal: 31.3ms\tremaining: 359ms\n",
      "8:\tlearn: 0.4625589\ttotal: 35.2ms\tremaining: 356ms\n",
      "9:\tlearn: 0.4484004\ttotal: 38.1ms\tremaining: 343ms\n",
      "10:\tlearn: 0.4328244\ttotal: 41.1ms\tremaining: 333ms\n",
      "11:\tlearn: 0.4182463\ttotal: 44.1ms\tremaining: 323ms\n",
      "12:\tlearn: 0.4025304\ttotal: 47.2ms\tremaining: 316ms\n",
      "13:\tlearn: 0.3913518\ttotal: 50.2ms\tremaining: 309ms\n",
      "14:\tlearn: 0.3804377\ttotal: 53.3ms\tremaining: 302ms\n",
      "15:\tlearn: 0.3695224\ttotal: 56.3ms\tremaining: 295ms\n",
      "16:\tlearn: 0.3597083\ttotal: 59.4ms\tremaining: 290ms\n",
      "17:\tlearn: 0.3533674\ttotal: 62.5ms\tremaining: 285ms\n",
      "18:\tlearn: 0.3419000\ttotal: 65.7ms\tremaining: 280ms\n",
      "19:\tlearn: 0.3335127\ttotal: 68.5ms\tremaining: 274ms\n",
      "20:\tlearn: 0.3225983\ttotal: 71.5ms\tremaining: 269ms\n",
      "21:\tlearn: 0.3146646\ttotal: 74.4ms\tremaining: 264ms\n",
      "22:\tlearn: 0.3060724\ttotal: 77ms\tremaining: 258ms\n",
      "23:\tlearn: 0.2979084\ttotal: 80ms\tremaining: 253ms\n",
      "24:\tlearn: 0.2887468\ttotal: 82.7ms\tremaining: 248ms\n",
      "25:\tlearn: 0.2804887\ttotal: 85.6ms\tremaining: 244ms\n",
      "26:\tlearn: 0.2695923\ttotal: 88.6ms\tremaining: 239ms\n",
      "27:\tlearn: 0.2609111\ttotal: 91.3ms\tremaining: 235ms\n",
      "28:\tlearn: 0.2530266\ttotal: 94.2ms\tremaining: 231ms\n",
      "29:\tlearn: 0.2404906\ttotal: 99.8ms\tremaining: 233ms\n",
      "30:\tlearn: 0.2348537\ttotal: 105ms\tremaining: 234ms\n",
      "31:\tlearn: 0.2291454\ttotal: 110ms\tremaining: 234ms\n",
      "32:\tlearn: 0.2231584\ttotal: 115ms\tremaining: 234ms\n",
      "33:\tlearn: 0.2185045\ttotal: 121ms\tremaining: 234ms\n",
      "34:\tlearn: 0.2121785\ttotal: 126ms\tremaining: 234ms\n",
      "35:\tlearn: 0.2072065\ttotal: 131ms\tremaining: 233ms\n",
      "36:\tlearn: 0.2022332\ttotal: 136ms\tremaining: 232ms\n",
      "37:\tlearn: 0.1959252\ttotal: 141ms\tremaining: 231ms\n",
      "38:\tlearn: 0.1915284\ttotal: 146ms\tremaining: 229ms\n",
      "39:\tlearn: 0.1863827\ttotal: 152ms\tremaining: 227ms\n",
      "40:\tlearn: 0.1818882\ttotal: 157ms\tremaining: 225ms\n",
      "41:\tlearn: 0.1754308\ttotal: 162ms\tremaining: 224ms\n",
      "42:\tlearn: 0.1706979\ttotal: 167ms\tremaining: 221ms\n",
      "43:\tlearn: 0.1668052\ttotal: 172ms\tremaining: 219ms\n",
      "44:\tlearn: 0.1628436\ttotal: 176ms\tremaining: 216ms\n",
      "45:\tlearn: 0.1593229\ttotal: 181ms\tremaining: 212ms\n",
      "46:\tlearn: 0.1570304\ttotal: 184ms\tremaining: 208ms\n",
      "47:\tlearn: 0.1537611\ttotal: 188ms\tremaining: 204ms\n",
      "48:\tlearn: 0.1514629\ttotal: 193ms\tremaining: 200ms\n",
      "49:\tlearn: 0.1490802\ttotal: 196ms\tremaining: 196ms\n",
      "50:\tlearn: 0.1459947\ttotal: 200ms\tremaining: 192ms\n",
      "51:\tlearn: 0.1431969\ttotal: 203ms\tremaining: 188ms\n",
      "52:\tlearn: 0.1400274\ttotal: 206ms\tremaining: 183ms\n",
      "53:\tlearn: 0.1369643\ttotal: 209ms\tremaining: 178ms\n",
      "54:\tlearn: 0.1349378\ttotal: 212ms\tremaining: 173ms\n",
      "55:\tlearn: 0.1337525\ttotal: 215ms\tremaining: 169ms\n",
      "56:\tlearn: 0.1315413\ttotal: 218ms\tremaining: 165ms\n",
      "57:\tlearn: 0.1291495\ttotal: 221ms\tremaining: 160ms\n",
      "58:\tlearn: 0.1269225\ttotal: 225ms\tremaining: 156ms\n",
      "59:\tlearn: 0.1244544\ttotal: 228ms\tremaining: 152ms\n",
      "60:\tlearn: 0.1221399\ttotal: 231ms\tremaining: 148ms\n",
      "61:\tlearn: 0.1198163\ttotal: 234ms\tremaining: 144ms\n",
      "62:\tlearn: 0.1178262\ttotal: 238ms\tremaining: 140ms\n",
      "63:\tlearn: 0.1156957\ttotal: 241ms\tremaining: 136ms\n",
      "64:\tlearn: 0.1139639\ttotal: 245ms\tremaining: 132ms\n",
      "65:\tlearn: 0.1118289\ttotal: 248ms\tremaining: 128ms\n",
      "66:\tlearn: 0.1093357\ttotal: 250ms\tremaining: 123ms\n",
      "67:\tlearn: 0.1070415\ttotal: 253ms\tremaining: 119ms\n",
      "68:\tlearn: 0.1050847\ttotal: 256ms\tremaining: 115ms\n",
      "69:\tlearn: 0.1028363\ttotal: 259ms\tremaining: 111ms\n",
      "70:\tlearn: 0.1002058\ttotal: 264ms\tremaining: 108ms\n",
      "71:\tlearn: 0.0983383\ttotal: 270ms\tremaining: 105ms\n",
      "72:\tlearn: 0.0956830\ttotal: 276ms\tremaining: 102ms\n",
      "73:\tlearn: 0.0939467\ttotal: 281ms\tremaining: 98.7ms\n",
      "74:\tlearn: 0.0924688\ttotal: 286ms\tremaining: 95.3ms\n",
      "75:\tlearn: 0.0912234\ttotal: 291ms\tremaining: 92ms\n",
      "76:\tlearn: 0.0902325\ttotal: 297ms\tremaining: 88.6ms\n",
      "77:\tlearn: 0.0883901\ttotal: 302ms\tremaining: 85.1ms\n",
      "78:\tlearn: 0.0856064\ttotal: 307ms\tremaining: 81.6ms\n",
      "79:\tlearn: 0.0835124\ttotal: 312ms\tremaining: 78.1ms\n",
      "80:\tlearn: 0.0818366\ttotal: 318ms\tremaining: 74.5ms\n",
      "81:\tlearn: 0.0801599\ttotal: 323ms\tremaining: 70.9ms\n",
      "82:\tlearn: 0.0793211\ttotal: 328ms\tremaining: 67.2ms\n",
      "83:\tlearn: 0.0776081\ttotal: 333ms\tremaining: 63.5ms\n",
      "84:\tlearn: 0.0762914\ttotal: 339ms\tremaining: 59.7ms\n",
      "85:\tlearn: 0.0753352\ttotal: 344ms\tremaining: 56ms\n",
      "86:\tlearn: 0.0740337\ttotal: 348ms\tremaining: 52ms\n",
      "87:\tlearn: 0.0730017\ttotal: 353ms\tremaining: 48.1ms\n",
      "88:\tlearn: 0.0721947\ttotal: 357ms\tremaining: 44.1ms\n",
      "89:\tlearn: 0.0707807\ttotal: 360ms\tremaining: 40ms\n",
      "90:\tlearn: 0.0697561\ttotal: 364ms\tremaining: 36ms\n",
      "91:\tlearn: 0.0686683\ttotal: 369ms\tremaining: 32.1ms\n",
      "92:\tlearn: 0.0671990\ttotal: 372ms\tremaining: 28ms\n",
      "93:\tlearn: 0.0661239\ttotal: 376ms\tremaining: 24ms\n",
      "94:\tlearn: 0.0650320\ttotal: 379ms\tremaining: 19.9ms\n",
      "95:\tlearn: 0.0638235\ttotal: 382ms\tremaining: 15.9ms\n",
      "96:\tlearn: 0.0627096\ttotal: 385ms\tremaining: 11.9ms\n",
      "97:\tlearn: 0.0622560\ttotal: 388ms\tremaining: 7.91ms\n",
      "98:\tlearn: 0.0609858\ttotal: 391ms\tremaining: 3.95ms\n",
      "99:\tlearn: 0.0600247\ttotal: 393ms\tremaining: 0us\n",
      "0:\tlearn: 0.6572759\ttotal: 3.98ms\tremaining: 394ms\n",
      "1:\tlearn: 0.6347926\ttotal: 7.68ms\tremaining: 376ms\n",
      "2:\tlearn: 0.6024672\ttotal: 11.6ms\tremaining: 375ms\n",
      "3:\tlearn: 0.5844324\ttotal: 15.4ms\tremaining: 369ms\n",
      "4:\tlearn: 0.5686910\ttotal: 19.1ms\tremaining: 363ms\n",
      "5:\tlearn: 0.5442444\ttotal: 23ms\tremaining: 361ms\n",
      "6:\tlearn: 0.5276920\ttotal: 26.6ms\tremaining: 354ms\n",
      "7:\tlearn: 0.5006692\ttotal: 30.6ms\tremaining: 352ms\n",
      "8:\tlearn: 0.4794708\ttotal: 34.4ms\tremaining: 347ms\n",
      "9:\tlearn: 0.4602261\ttotal: 38.2ms\tremaining: 344ms\n",
      "10:\tlearn: 0.4414774\ttotal: 42ms\tremaining: 340ms\n",
      "11:\tlearn: 0.4277950\ttotal: 45ms\tremaining: 330ms\n",
      "12:\tlearn: 0.4097276\ttotal: 48.1ms\tremaining: 322ms\n",
      "13:\tlearn: 0.3967164\ttotal: 51.2ms\tremaining: 314ms\n",
      "14:\tlearn: 0.3791227\ttotal: 54.1ms\tremaining: 307ms\n",
      "15:\tlearn: 0.3684446\ttotal: 57.1ms\tremaining: 300ms\n",
      "16:\tlearn: 0.3565722\ttotal: 60.3ms\tremaining: 294ms\n",
      "17:\tlearn: 0.3450190\ttotal: 63.3ms\tremaining: 289ms\n",
      "18:\tlearn: 0.3325891\ttotal: 66.3ms\tremaining: 283ms\n",
      "19:\tlearn: 0.3227990\ttotal: 69.5ms\tremaining: 278ms\n",
      "20:\tlearn: 0.3139078\ttotal: 72.3ms\tremaining: 272ms\n",
      "21:\tlearn: 0.3062740\ttotal: 75.2ms\tremaining: 267ms\n",
      "22:\tlearn: 0.2980046\ttotal: 78.4ms\tremaining: 262ms\n",
      "23:\tlearn: 0.2910173\ttotal: 80.9ms\tremaining: 256ms\n",
      "24:\tlearn: 0.2834831\ttotal: 83.9ms\tremaining: 252ms\n",
      "25:\tlearn: 0.2776146\ttotal: 86.9ms\tremaining: 247ms\n",
      "26:\tlearn: 0.2683864\ttotal: 89.9ms\tremaining: 243ms\n",
      "27:\tlearn: 0.2594798\ttotal: 92.8ms\tremaining: 239ms\n",
      "28:\tlearn: 0.2539465\ttotal: 95.6ms\tremaining: 234ms\n",
      "29:\tlearn: 0.2463460\ttotal: 98.7ms\tremaining: 230ms\n",
      "30:\tlearn: 0.2393069\ttotal: 104ms\tremaining: 231ms\n",
      "31:\tlearn: 0.2302237\ttotal: 109ms\tremaining: 232ms\n",
      "32:\tlearn: 0.2203253\ttotal: 114ms\tremaining: 232ms\n",
      "33:\tlearn: 0.2116820\ttotal: 119ms\tremaining: 232ms\n",
      "34:\tlearn: 0.2055475\ttotal: 124ms\tremaining: 231ms\n",
      "35:\tlearn: 0.2026112\ttotal: 130ms\tremaining: 230ms\n",
      "36:\tlearn: 0.1941285\ttotal: 135ms\tremaining: 230ms\n",
      "37:\tlearn: 0.1904033\ttotal: 140ms\tremaining: 229ms\n",
      "38:\tlearn: 0.1873918\ttotal: 145ms\tremaining: 227ms\n",
      "39:\tlearn: 0.1830976\ttotal: 151ms\tremaining: 226ms\n",
      "40:\tlearn: 0.1791518\ttotal: 156ms\tremaining: 224ms\n",
      "41:\tlearn: 0.1752893\ttotal: 161ms\tremaining: 222ms\n",
      "42:\tlearn: 0.1711416\ttotal: 166ms\tremaining: 220ms\n",
      "43:\tlearn: 0.1655127\ttotal: 172ms\tremaining: 218ms\n",
      "44:\tlearn: 0.1614459\ttotal: 177ms\tremaining: 216ms\n",
      "45:\tlearn: 0.1570879\ttotal: 181ms\tremaining: 212ms\n",
      "46:\tlearn: 0.1553146\ttotal: 185ms\tremaining: 208ms\n",
      "47:\tlearn: 0.1521986\ttotal: 189ms\tremaining: 205ms\n",
      "48:\tlearn: 0.1487047\ttotal: 193ms\tremaining: 201ms\n",
      "49:\tlearn: 0.1463166\ttotal: 197ms\tremaining: 197ms\n",
      "50:\tlearn: 0.1432561\ttotal: 200ms\tremaining: 192ms\n",
      "51:\tlearn: 0.1392187\ttotal: 204ms\tremaining: 188ms\n",
      "52:\tlearn: 0.1358131\ttotal: 207ms\tremaining: 183ms\n",
      "53:\tlearn: 0.1326567\ttotal: 210ms\tremaining: 179ms\n",
      "54:\tlearn: 0.1277417\ttotal: 213ms\tremaining: 174ms\n",
      "55:\tlearn: 0.1252271\ttotal: 216ms\tremaining: 170ms\n",
      "56:\tlearn: 0.1234224\ttotal: 219ms\tremaining: 165ms\n",
      "57:\tlearn: 0.1211810\ttotal: 222ms\tremaining: 161ms\n",
      "58:\tlearn: 0.1187021\ttotal: 225ms\tremaining: 157ms\n",
      "59:\tlearn: 0.1165020\ttotal: 228ms\tremaining: 152ms\n",
      "60:\tlearn: 0.1139773\ttotal: 232ms\tremaining: 148ms\n",
      "61:\tlearn: 0.1116801\ttotal: 234ms\tremaining: 144ms\n",
      "62:\tlearn: 0.1092167\ttotal: 237ms\tremaining: 139ms\n",
      "63:\tlearn: 0.1069969\ttotal: 240ms\tremaining: 135ms\n",
      "64:\tlearn: 0.1051519\ttotal: 243ms\tremaining: 131ms\n",
      "65:\tlearn: 0.1030753\ttotal: 246ms\tremaining: 127ms\n",
      "66:\tlearn: 0.1012144\ttotal: 249ms\tremaining: 122ms\n",
      "67:\tlearn: 0.0992978\ttotal: 252ms\tremaining: 118ms\n",
      "68:\tlearn: 0.0976500\ttotal: 255ms\tremaining: 114ms\n",
      "69:\tlearn: 0.0963928\ttotal: 258ms\tremaining: 111ms\n",
      "70:\tlearn: 0.0944123\ttotal: 263ms\tremaining: 108ms\n",
      "71:\tlearn: 0.0925313\ttotal: 269ms\tremaining: 104ms\n",
      "72:\tlearn: 0.0910996\ttotal: 274ms\tremaining: 101ms\n",
      "73:\tlearn: 0.0898167\ttotal: 279ms\tremaining: 98ms\n",
      "74:\tlearn: 0.0874663\ttotal: 284ms\tremaining: 94.7ms\n",
      "75:\tlearn: 0.0860303\ttotal: 289ms\tremaining: 91.4ms\n",
      "76:\tlearn: 0.0846604\ttotal: 295ms\tremaining: 88ms\n",
      "77:\tlearn: 0.0832458\ttotal: 300ms\tremaining: 84.5ms\n",
      "78:\tlearn: 0.0812632\ttotal: 305ms\tremaining: 81ms\n",
      "79:\tlearn: 0.0794144\ttotal: 310ms\tremaining: 77.5ms\n",
      "80:\tlearn: 0.0782108\ttotal: 315ms\tremaining: 73.9ms\n",
      "81:\tlearn: 0.0769445\ttotal: 320ms\tremaining: 70.3ms\n",
      "82:\tlearn: 0.0758726\ttotal: 326ms\tremaining: 66.7ms\n",
      "83:\tlearn: 0.0737969\ttotal: 331ms\tremaining: 63ms\n",
      "84:\tlearn: 0.0717491\ttotal: 336ms\tremaining: 59.2ms\n",
      "85:\tlearn: 0.0704822\ttotal: 341ms\tremaining: 55.4ms\n",
      "86:\tlearn: 0.0693141\ttotal: 346ms\tremaining: 51.8ms\n",
      "87:\tlearn: 0.0679846\ttotal: 351ms\tremaining: 47.8ms\n",
      "88:\tlearn: 0.0668801\ttotal: 355ms\tremaining: 43.9ms\n",
      "89:\tlearn: 0.0659233\ttotal: 359ms\tremaining: 39.9ms\n",
      "90:\tlearn: 0.0648720\ttotal: 362ms\tremaining: 35.8ms\n",
      "91:\tlearn: 0.0638132\ttotal: 366ms\tremaining: 31.8ms\n",
      "92:\tlearn: 0.0632650\ttotal: 370ms\tremaining: 27.8ms\n",
      "93:\tlearn: 0.0622195\ttotal: 373ms\tremaining: 23.8ms\n",
      "94:\tlearn: 0.0609976\ttotal: 376ms\tremaining: 19.8ms\n",
      "95:\tlearn: 0.0599348\ttotal: 379ms\tremaining: 15.8ms\n",
      "96:\tlearn: 0.0590621\ttotal: 382ms\tremaining: 11.8ms\n",
      "97:\tlearn: 0.0581688\ttotal: 385ms\tremaining: 7.86ms\n",
      "98:\tlearn: 0.0574902\ttotal: 388ms\tremaining: 3.92ms\n",
      "99:\tlearn: 0.0567123\ttotal: 391ms\tremaining: 0us\n",
      "0:\tlearn: 0.6629937\ttotal: 3.54ms\tremaining: 351ms\n",
      "1:\tlearn: 0.6424147\ttotal: 6.97ms\tremaining: 342ms\n",
      "2:\tlearn: 0.6100783\ttotal: 10ms\tremaining: 323ms\n",
      "3:\tlearn: 0.5903226\ttotal: 13.1ms\tremaining: 314ms\n",
      "4:\tlearn: 0.5725645\ttotal: 15.9ms\tremaining: 301ms\n",
      "5:\tlearn: 0.5495567\ttotal: 18.9ms\tremaining: 296ms\n",
      "6:\tlearn: 0.5243685\ttotal: 22.2ms\tremaining: 296ms\n",
      "7:\tlearn: 0.4990894\ttotal: 25.3ms\tremaining: 291ms\n",
      "8:\tlearn: 0.4789480\ttotal: 28.4ms\tremaining: 287ms\n",
      "9:\tlearn: 0.4607603\ttotal: 31.3ms\tremaining: 282ms\n",
      "10:\tlearn: 0.4441251\ttotal: 34.7ms\tremaining: 281ms\n",
      "11:\tlearn: 0.4265547\ttotal: 37.8ms\tremaining: 277ms\n",
      "12:\tlearn: 0.4111228\ttotal: 40.7ms\tremaining: 272ms\n",
      "13:\tlearn: 0.4021091\ttotal: 43.7ms\tremaining: 269ms\n",
      "14:\tlearn: 0.3915084\ttotal: 46.8ms\tremaining: 265ms\n",
      "15:\tlearn: 0.3832740\ttotal: 50.1ms\tremaining: 263ms\n",
      "16:\tlearn: 0.3718466\ttotal: 53.1ms\tremaining: 259ms\n",
      "17:\tlearn: 0.3614857\ttotal: 55.9ms\tremaining: 255ms\n",
      "18:\tlearn: 0.3519300\ttotal: 58.9ms\tremaining: 251ms\n",
      "19:\tlearn: 0.3416437\ttotal: 61.6ms\tremaining: 246ms\n",
      "20:\tlearn: 0.3323914\ttotal: 64.5ms\tremaining: 243ms\n",
      "21:\tlearn: 0.3251796\ttotal: 68.1ms\tremaining: 241ms\n",
      "22:\tlearn: 0.3132003\ttotal: 71.1ms\tremaining: 238ms\n",
      "23:\tlearn: 0.3030549\ttotal: 74.8ms\tremaining: 237ms\n",
      "24:\tlearn: 0.2961249\ttotal: 78.1ms\tremaining: 234ms\n",
      "25:\tlearn: 0.2862619\ttotal: 81.1ms\tremaining: 231ms\n",
      "26:\tlearn: 0.2796449\ttotal: 86.6ms\tremaining: 234ms\n",
      "27:\tlearn: 0.2730789\ttotal: 91.7ms\tremaining: 236ms\n",
      "28:\tlearn: 0.2635626\ttotal: 96.9ms\tremaining: 237ms\n",
      "29:\tlearn: 0.2576341\ttotal: 102ms\tremaining: 239ms\n",
      "30:\tlearn: 0.2512018\ttotal: 107ms\tremaining: 239ms\n",
      "31:\tlearn: 0.2443345\ttotal: 113ms\tremaining: 240ms\n",
      "32:\tlearn: 0.2394511\ttotal: 118ms\tremaining: 239ms\n",
      "33:\tlearn: 0.2329843\ttotal: 123ms\tremaining: 239ms\n",
      "34:\tlearn: 0.2291028\ttotal: 128ms\tremaining: 238ms\n",
      "35:\tlearn: 0.2235104\ttotal: 133ms\tremaining: 237ms\n",
      "36:\tlearn: 0.2179300\ttotal: 139ms\tremaining: 236ms\n",
      "37:\tlearn: 0.2129513\ttotal: 144ms\tremaining: 234ms\n",
      "38:\tlearn: 0.2082215\ttotal: 149ms\tremaining: 232ms\n",
      "39:\tlearn: 0.2041533\ttotal: 154ms\tremaining: 231ms\n",
      "40:\tlearn: 0.1998752\ttotal: 159ms\tremaining: 229ms\n",
      "41:\tlearn: 0.1953502\ttotal: 164ms\tremaining: 227ms\n",
      "42:\tlearn: 0.1904272\ttotal: 169ms\tremaining: 224ms\n",
      "43:\tlearn: 0.1849335\ttotal: 174ms\tremaining: 221ms\n",
      "44:\tlearn: 0.1805855\ttotal: 178ms\tremaining: 217ms\n",
      "45:\tlearn: 0.1760443\ttotal: 182ms\tremaining: 213ms\n",
      "46:\tlearn: 0.1728149\ttotal: 185ms\tremaining: 209ms\n",
      "47:\tlearn: 0.1699655\ttotal: 189ms\tremaining: 205ms\n",
      "48:\tlearn: 0.1667010\ttotal: 192ms\tremaining: 200ms\n",
      "49:\tlearn: 0.1637802\ttotal: 195ms\tremaining: 195ms\n",
      "50:\tlearn: 0.1597769\ttotal: 199ms\tremaining: 191ms\n",
      "51:\tlearn: 0.1565696\ttotal: 202ms\tremaining: 186ms\n",
      "52:\tlearn: 0.1534620\ttotal: 205ms\tremaining: 182ms\n",
      "53:\tlearn: 0.1502170\ttotal: 208ms\tremaining: 177ms\n",
      "54:\tlearn: 0.1472108\ttotal: 211ms\tremaining: 173ms\n",
      "55:\tlearn: 0.1448795\ttotal: 214ms\tremaining: 168ms\n",
      "56:\tlearn: 0.1426263\ttotal: 217ms\tremaining: 164ms\n",
      "57:\tlearn: 0.1388790\ttotal: 219ms\tremaining: 159ms\n",
      "58:\tlearn: 0.1376675\ttotal: 220ms\tremaining: 153ms\n",
      "59:\tlearn: 0.1356825\ttotal: 222ms\tremaining: 148ms\n",
      "60:\tlearn: 0.1329292\ttotal: 225ms\tremaining: 144ms\n",
      "61:\tlearn: 0.1311297\ttotal: 228ms\tremaining: 140ms\n",
      "62:\tlearn: 0.1285047\ttotal: 231ms\tremaining: 135ms\n",
      "63:\tlearn: 0.1257235\ttotal: 234ms\tremaining: 132ms\n",
      "64:\tlearn: 0.1230077\ttotal: 237ms\tremaining: 128ms\n",
      "65:\tlearn: 0.1206889\ttotal: 240ms\tremaining: 124ms\n",
      "66:\tlearn: 0.1196580\ttotal: 245ms\tremaining: 121ms\n",
      "67:\tlearn: 0.1178576\ttotal: 251ms\tremaining: 118ms\n",
      "68:\tlearn: 0.1161330\ttotal: 256ms\tremaining: 115ms\n",
      "69:\tlearn: 0.1137788\ttotal: 261ms\tremaining: 112ms\n",
      "70:\tlearn: 0.1122042\ttotal: 266ms\tremaining: 109ms\n",
      "71:\tlearn: 0.1092209\ttotal: 271ms\tremaining: 106ms\n",
      "72:\tlearn: 0.1070284\ttotal: 276ms\tremaining: 102ms\n",
      "73:\tlearn: 0.1054380\ttotal: 282ms\tremaining: 99ms\n",
      "74:\tlearn: 0.1035145\ttotal: 287ms\tremaining: 95.7ms\n",
      "75:\tlearn: 0.1018948\ttotal: 292ms\tremaining: 92.2ms\n",
      "76:\tlearn: 0.1001524\ttotal: 297ms\tremaining: 88.7ms\n",
      "77:\tlearn: 0.0979204\ttotal: 302ms\tremaining: 85.3ms\n",
      "78:\tlearn: 0.0968167\ttotal: 308ms\tremaining: 81.8ms\n",
      "79:\tlearn: 0.0949266\ttotal: 313ms\tremaining: 78.2ms\n",
      "80:\tlearn: 0.0934956\ttotal: 318ms\tremaining: 74.6ms\n",
      "81:\tlearn: 0.0915793\ttotal: 323ms\tremaining: 70.9ms\n",
      "82:\tlearn: 0.0901915\ttotal: 329ms\tremaining: 67.3ms\n",
      "83:\tlearn: 0.0890149\ttotal: 332ms\tremaining: 63.3ms\n",
      "84:\tlearn: 0.0874082\ttotal: 336ms\tremaining: 59.3ms\n",
      "85:\tlearn: 0.0857535\ttotal: 340ms\tremaining: 55.4ms\n",
      "86:\tlearn: 0.0846912\ttotal: 344ms\tremaining: 51.4ms\n",
      "87:\tlearn: 0.0833286\ttotal: 349ms\tremaining: 47.7ms\n",
      "88:\tlearn: 0.0819141\ttotal: 353ms\tremaining: 43.6ms\n",
      "89:\tlearn: 0.0808097\ttotal: 357ms\tremaining: 39.6ms\n",
      "90:\tlearn: 0.0798609\ttotal: 360ms\tremaining: 35.6ms\n",
      "91:\tlearn: 0.0787576\ttotal: 363ms\tremaining: 31.6ms\n",
      "92:\tlearn: 0.0772849\ttotal: 366ms\tremaining: 27.5ms\n",
      "93:\tlearn: 0.0763108\ttotal: 369ms\tremaining: 23.6ms\n",
      "94:\tlearn: 0.0752791\ttotal: 373ms\tremaining: 19.6ms\n",
      "95:\tlearn: 0.0735211\ttotal: 376ms\tremaining: 15.7ms\n",
      "96:\tlearn: 0.0723779\ttotal: 379ms\tremaining: 11.7ms\n",
      "97:\tlearn: 0.0715319\ttotal: 382ms\tremaining: 7.79ms\n",
      "98:\tlearn: 0.0711755\ttotal: 384ms\tremaining: 3.88ms\n",
      "99:\tlearn: 0.0700487\ttotal: 387ms\tremaining: 0us\n",
      "0:\tlearn: 0.6597589\ttotal: 3.46ms\tremaining: 343ms\n",
      "1:\tlearn: 0.6397939\ttotal: 6.37ms\tremaining: 312ms\n",
      "2:\tlearn: 0.6065900\ttotal: 9.33ms\tremaining: 302ms\n",
      "3:\tlearn: 0.5924821\ttotal: 12.2ms\tremaining: 293ms\n",
      "4:\tlearn: 0.5698998\ttotal: 15ms\tremaining: 285ms\n",
      "5:\tlearn: 0.5465960\ttotal: 18ms\tremaining: 281ms\n",
      "6:\tlearn: 0.5203595\ttotal: 20.8ms\tremaining: 277ms\n",
      "7:\tlearn: 0.5024988\ttotal: 23.8ms\tremaining: 274ms\n",
      "8:\tlearn: 0.4842550\ttotal: 26.7ms\tremaining: 270ms\n",
      "9:\tlearn: 0.4606724\ttotal: 29.6ms\tremaining: 267ms\n",
      "10:\tlearn: 0.4363374\ttotal: 32.4ms\tremaining: 263ms\n",
      "11:\tlearn: 0.4212520\ttotal: 35.4ms\tremaining: 259ms\n",
      "12:\tlearn: 0.4076761\ttotal: 38.3ms\tremaining: 256ms\n",
      "13:\tlearn: 0.3952534\ttotal: 41ms\tremaining: 252ms\n",
      "14:\tlearn: 0.3825305\ttotal: 44ms\tremaining: 249ms\n",
      "15:\tlearn: 0.3702996\ttotal: 46.8ms\tremaining: 246ms\n",
      "16:\tlearn: 0.3592269\ttotal: 49.9ms\tremaining: 243ms\n",
      "17:\tlearn: 0.3471463\ttotal: 52.6ms\tremaining: 239ms\n",
      "18:\tlearn: 0.3374867\ttotal: 55.3ms\tremaining: 236ms\n",
      "19:\tlearn: 0.3279261\ttotal: 60.8ms\tremaining: 243ms\n",
      "20:\tlearn: 0.3201819\ttotal: 65.9ms\tremaining: 248ms\n",
      "21:\tlearn: 0.3101666\ttotal: 71.2ms\tremaining: 253ms\n",
      "22:\tlearn: 0.3005326\ttotal: 76.4ms\tremaining: 256ms\n",
      "23:\tlearn: 0.2926053\ttotal: 81.7ms\tremaining: 259ms\n",
      "24:\tlearn: 0.2845316\ttotal: 86.9ms\tremaining: 261ms\n",
      "25:\tlearn: 0.2748540\ttotal: 92.2ms\tremaining: 262ms\n",
      "26:\tlearn: 0.2671610\ttotal: 97.3ms\tremaining: 263ms\n",
      "27:\tlearn: 0.2578678\ttotal: 103ms\tremaining: 264ms\n",
      "28:\tlearn: 0.2519199\ttotal: 108ms\tremaining: 264ms\n",
      "29:\tlearn: 0.2454736\ttotal: 113ms\tremaining: 263ms\n",
      "30:\tlearn: 0.2394976\ttotal: 118ms\tremaining: 263ms\n",
      "31:\tlearn: 0.2340766\ttotal: 123ms\tremaining: 262ms\n",
      "32:\tlearn: 0.2250101\ttotal: 129ms\tremaining: 261ms\n",
      "33:\tlearn: 0.2213034\ttotal: 132ms\tremaining: 256ms\n",
      "34:\tlearn: 0.2139050\ttotal: 135ms\tremaining: 251ms\n",
      "35:\tlearn: 0.2099053\ttotal: 138ms\tremaining: 246ms\n",
      "36:\tlearn: 0.2039804\ttotal: 141ms\tremaining: 241ms\n",
      "37:\tlearn: 0.1997235\ttotal: 145ms\tremaining: 236ms\n",
      "38:\tlearn: 0.1955485\ttotal: 148ms\tremaining: 231ms\n",
      "39:\tlearn: 0.1908362\ttotal: 151ms\tremaining: 226ms\n",
      "40:\tlearn: 0.1864483\ttotal: 153ms\tremaining: 221ms\n",
      "41:\tlearn: 0.1823507\ttotal: 156ms\tremaining: 216ms\n",
      "42:\tlearn: 0.1753994\ttotal: 160ms\tremaining: 212ms\n",
      "43:\tlearn: 0.1719714\ttotal: 163ms\tremaining: 207ms\n",
      "44:\tlearn: 0.1679167\ttotal: 166ms\tremaining: 203ms\n",
      "45:\tlearn: 0.1649525\ttotal: 168ms\tremaining: 197ms\n",
      "46:\tlearn: 0.1617115\ttotal: 170ms\tremaining: 191ms\n",
      "47:\tlearn: 0.1585960\ttotal: 171ms\tremaining: 186ms\n",
      "48:\tlearn: 0.1563348\ttotal: 174ms\tremaining: 181ms\n",
      "49:\tlearn: 0.1498183\ttotal: 177ms\tremaining: 177ms\n",
      "50:\tlearn: 0.1471591\ttotal: 180ms\tremaining: 172ms\n",
      "51:\tlearn: 0.1429249\ttotal: 183ms\tremaining: 168ms\n",
      "52:\tlearn: 0.1399811\ttotal: 185ms\tremaining: 164ms\n",
      "53:\tlearn: 0.1376941\ttotal: 188ms\tremaining: 160ms\n",
      "54:\tlearn: 0.1353518\ttotal: 193ms\tremaining: 158ms\n",
      "55:\tlearn: 0.1323427\ttotal: 198ms\tremaining: 156ms\n",
      "56:\tlearn: 0.1300970\ttotal: 204ms\tremaining: 154ms\n",
      "57:\tlearn: 0.1278460\ttotal: 209ms\tremaining: 151ms\n",
      "58:\tlearn: 0.1258448\ttotal: 214ms\tremaining: 149ms\n",
      "59:\tlearn: 0.1227786\ttotal: 219ms\tremaining: 146ms\n",
      "60:\tlearn: 0.1207930\ttotal: 224ms\tremaining: 143ms\n",
      "61:\tlearn: 0.1173150\ttotal: 229ms\tremaining: 141ms\n",
      "62:\tlearn: 0.1149736\ttotal: 235ms\tremaining: 138ms\n",
      "63:\tlearn: 0.1121575\ttotal: 240ms\tremaining: 135ms\n",
      "64:\tlearn: 0.1097149\ttotal: 245ms\tremaining: 132ms\n",
      "65:\tlearn: 0.1073910\ttotal: 250ms\tremaining: 129ms\n",
      "66:\tlearn: 0.1047873\ttotal: 255ms\tremaining: 126ms\n",
      "67:\tlearn: 0.1029321\ttotal: 260ms\tremaining: 122ms\n",
      "68:\tlearn: 0.1009369\ttotal: 265ms\tremaining: 119ms\n",
      "69:\tlearn: 0.0988604\ttotal: 271ms\tremaining: 116ms\n",
      "70:\tlearn: 0.0974227\ttotal: 276ms\tremaining: 113ms\n",
      "71:\tlearn: 0.0956768\ttotal: 279ms\tremaining: 109ms\n",
      "72:\tlearn: 0.0940357\ttotal: 283ms\tremaining: 105ms\n",
      "73:\tlearn: 0.0922076\ttotal: 287ms\tremaining: 101ms\n",
      "74:\tlearn: 0.0913670\ttotal: 291ms\tremaining: 96.9ms\n",
      "75:\tlearn: 0.0896125\ttotal: 294ms\tremaining: 93ms\n",
      "76:\tlearn: 0.0875964\ttotal: 298ms\tremaining: 89.1ms\n",
      "77:\tlearn: 0.0857116\ttotal: 302ms\tremaining: 85.2ms\n",
      "78:\tlearn: 0.0849114\ttotal: 306ms\tremaining: 81.3ms\n",
      "79:\tlearn: 0.0825721\ttotal: 309ms\tremaining: 77.2ms\n",
      "80:\tlearn: 0.0812142\ttotal: 312ms\tremaining: 73.2ms\n",
      "81:\tlearn: 0.0798992\ttotal: 315ms\tremaining: 69.2ms\n",
      "82:\tlearn: 0.0783879\ttotal: 318ms\tremaining: 65.1ms\n",
      "83:\tlearn: 0.0764429\ttotal: 321ms\tremaining: 61.2ms\n",
      "84:\tlearn: 0.0750632\ttotal: 324ms\tremaining: 57.2ms\n",
      "85:\tlearn: 0.0739054\ttotal: 327ms\tremaining: 53.3ms\n",
      "86:\tlearn: 0.0727266\ttotal: 331ms\tremaining: 49.4ms\n",
      "87:\tlearn: 0.0712545\ttotal: 334ms\tremaining: 45.5ms\n",
      "88:\tlearn: 0.0703205\ttotal: 337ms\tremaining: 41.7ms\n",
      "89:\tlearn: 0.0685016\ttotal: 340ms\tremaining: 37.8ms\n",
      "90:\tlearn: 0.0679819\ttotal: 343ms\tremaining: 33.9ms\n",
      "91:\tlearn: 0.0667734\ttotal: 346ms\tremaining: 30.1ms\n",
      "92:\tlearn: 0.0653463\ttotal: 349ms\tremaining: 26.2ms\n",
      "93:\tlearn: 0.0639943\ttotal: 354ms\tremaining: 22.6ms\n",
      "94:\tlearn: 0.0629605\ttotal: 359ms\tremaining: 18.9ms\n",
      "95:\tlearn: 0.0616938\ttotal: 365ms\tremaining: 15.2ms\n",
      "96:\tlearn: 0.0607338\ttotal: 370ms\tremaining: 11.4ms\n",
      "97:\tlearn: 0.0595736\ttotal: 375ms\tremaining: 7.65ms\n",
      "98:\tlearn: 0.0586764\ttotal: 380ms\tremaining: 3.84ms\n",
      "99:\tlearn: 0.0570738\ttotal: 386ms\tremaining: 0us\n",
      "0:\tlearn: 0.6593594\ttotal: 3.44ms\tremaining: 341ms\n",
      "1:\tlearn: 0.6296984\ttotal: 6.57ms\tremaining: 322ms\n",
      "2:\tlearn: 0.6021864\ttotal: 9.72ms\tremaining: 314ms\n",
      "3:\tlearn: 0.5765701\ttotal: 12.9ms\tremaining: 309ms\n",
      "4:\tlearn: 0.5542417\ttotal: 16ms\tremaining: 305ms\n",
      "5:\tlearn: 0.5361777\ttotal: 18.9ms\tremaining: 297ms\n",
      "6:\tlearn: 0.5218690\ttotal: 21.9ms\tremaining: 291ms\n",
      "7:\tlearn: 0.5022137\ttotal: 25.2ms\tremaining: 289ms\n",
      "8:\tlearn: 0.4794931\ttotal: 28.2ms\tremaining: 286ms\n",
      "9:\tlearn: 0.4571445\ttotal: 31.3ms\tremaining: 281ms\n",
      "10:\tlearn: 0.4409949\ttotal: 34.3ms\tremaining: 277ms\n",
      "11:\tlearn: 0.4282337\ttotal: 37.4ms\tremaining: 274ms\n",
      "12:\tlearn: 0.4117557\ttotal: 40.3ms\tremaining: 270ms\n",
      "13:\tlearn: 0.3990564\ttotal: 43.3ms\tremaining: 266ms\n",
      "14:\tlearn: 0.3842740\ttotal: 46.5ms\tremaining: 263ms\n",
      "15:\tlearn: 0.3686615\ttotal: 49.3ms\tremaining: 259ms\n",
      "16:\tlearn: 0.3545073\ttotal: 52.3ms\tremaining: 255ms\n",
      "17:\tlearn: 0.3450156\ttotal: 55.3ms\tremaining: 252ms\n",
      "18:\tlearn: 0.3330271\ttotal: 57.9ms\tremaining: 247ms\n",
      "19:\tlearn: 0.3228139\ttotal: 60.7ms\tremaining: 243ms\n",
      "20:\tlearn: 0.3139787\ttotal: 63.5ms\tremaining: 239ms\n",
      "21:\tlearn: 0.3052622\ttotal: 66.4ms\tremaining: 236ms\n",
      "22:\tlearn: 0.2961176\ttotal: 71.9ms\tremaining: 241ms\n",
      "23:\tlearn: 0.2889917\ttotal: 76.9ms\tremaining: 244ms\n",
      "24:\tlearn: 0.2819530\ttotal: 82.2ms\tremaining: 247ms\n",
      "25:\tlearn: 0.2710698\ttotal: 87.4ms\tremaining: 249ms\n",
      "26:\tlearn: 0.2647707\ttotal: 92.6ms\tremaining: 250ms\n",
      "27:\tlearn: 0.2575577\ttotal: 98.1ms\tremaining: 252ms\n",
      "28:\tlearn: 0.2499451\ttotal: 103ms\tremaining: 253ms\n",
      "29:\tlearn: 0.2431797\ttotal: 108ms\tremaining: 253ms\n",
      "30:\tlearn: 0.2376644\ttotal: 114ms\tremaining: 253ms\n",
      "31:\tlearn: 0.2315410\ttotal: 119ms\tremaining: 252ms\n",
      "32:\tlearn: 0.2260522\ttotal: 124ms\tremaining: 251ms\n",
      "33:\tlearn: 0.2208706\ttotal: 129ms\tremaining: 250ms\n",
      "34:\tlearn: 0.2141827\ttotal: 134ms\tremaining: 249ms\n",
      "35:\tlearn: 0.2088310\ttotal: 139ms\tremaining: 248ms\n",
      "36:\tlearn: 0.2041992\ttotal: 145ms\tremaining: 246ms\n",
      "37:\tlearn: 0.1996258\ttotal: 150ms\tremaining: 244ms\n",
      "38:\tlearn: 0.1931260\ttotal: 155ms\tremaining: 243ms\n",
      "39:\tlearn: 0.1877172\ttotal: 159ms\tremaining: 238ms\n",
      "40:\tlearn: 0.1833133\ttotal: 163ms\tremaining: 234ms\n",
      "41:\tlearn: 0.1813899\ttotal: 167ms\tremaining: 230ms\n",
      "42:\tlearn: 0.1780205\ttotal: 171ms\tremaining: 226ms\n",
      "43:\tlearn: 0.1723907\ttotal: 176ms\tremaining: 225ms\n",
      "44:\tlearn: 0.1695516\ttotal: 179ms\tremaining: 219ms\n",
      "45:\tlearn: 0.1653684\ttotal: 182ms\tremaining: 214ms\n",
      "46:\tlearn: 0.1629577\ttotal: 186ms\tremaining: 209ms\n",
      "47:\tlearn: 0.1615965\ttotal: 188ms\tremaining: 204ms\n",
      "48:\tlearn: 0.1586562\ttotal: 190ms\tremaining: 198ms\n",
      "49:\tlearn: 0.1557279\ttotal: 193ms\tremaining: 193ms\n",
      "50:\tlearn: 0.1525891\ttotal: 196ms\tremaining: 188ms\n",
      "51:\tlearn: 0.1490151\ttotal: 199ms\tremaining: 184ms\n",
      "52:\tlearn: 0.1463398\ttotal: 203ms\tremaining: 180ms\n",
      "53:\tlearn: 0.1440958\ttotal: 206ms\tremaining: 175ms\n",
      "54:\tlearn: 0.1406420\ttotal: 209ms\tremaining: 171ms\n",
      "55:\tlearn: 0.1381173\ttotal: 211ms\tremaining: 166ms\n",
      "56:\tlearn: 0.1354814\ttotal: 214ms\tremaining: 161ms\n",
      "57:\tlearn: 0.1335276\ttotal: 216ms\tremaining: 157ms\n",
      "58:\tlearn: 0.1312139\ttotal: 219ms\tremaining: 152ms\n",
      "59:\tlearn: 0.1284923\ttotal: 223ms\tremaining: 148ms\n",
      "60:\tlearn: 0.1253679\ttotal: 225ms\tremaining: 144ms\n",
      "61:\tlearn: 0.1226791\ttotal: 228ms\tremaining: 140ms\n",
      "62:\tlearn: 0.1204992\ttotal: 231ms\tremaining: 136ms\n",
      "63:\tlearn: 0.1188104\ttotal: 234ms\tremaining: 132ms\n",
      "64:\tlearn: 0.1162906\ttotal: 237ms\tremaining: 128ms\n",
      "65:\tlearn: 0.1147137\ttotal: 242ms\tremaining: 125ms\n",
      "66:\tlearn: 0.1121544\ttotal: 247ms\tremaining: 122ms\n",
      "67:\tlearn: 0.1101424\ttotal: 253ms\tremaining: 119ms\n",
      "68:\tlearn: 0.1084891\ttotal: 258ms\tremaining: 116ms\n",
      "69:\tlearn: 0.1060764\ttotal: 263ms\tremaining: 113ms\n",
      "70:\tlearn: 0.1045033\ttotal: 268ms\tremaining: 110ms\n",
      "71:\tlearn: 0.1022964\ttotal: 273ms\tremaining: 106ms\n",
      "72:\tlearn: 0.1004265\ttotal: 278ms\tremaining: 103ms\n",
      "73:\tlearn: 0.0983142\ttotal: 284ms\tremaining: 99.7ms\n",
      "74:\tlearn: 0.0969659\ttotal: 289ms\tremaining: 96.3ms\n",
      "75:\tlearn: 0.0957436\ttotal: 294ms\tremaining: 92.8ms\n",
      "76:\tlearn: 0.0944878\ttotal: 299ms\tremaining: 89.4ms\n",
      "77:\tlearn: 0.0922420\ttotal: 305ms\tremaining: 85.9ms\n",
      "78:\tlearn: 0.0905124\ttotal: 310ms\tremaining: 82.4ms\n",
      "79:\tlearn: 0.0889016\ttotal: 315ms\tremaining: 78.8ms\n",
      "80:\tlearn: 0.0872140\ttotal: 320ms\tremaining: 75.1ms\n",
      "81:\tlearn: 0.0858561\ttotal: 325ms\tremaining: 71.4ms\n",
      "82:\tlearn: 0.0848094\ttotal: 329ms\tremaining: 67.3ms\n",
      "83:\tlearn: 0.0832059\ttotal: 332ms\tremaining: 63.3ms\n",
      "84:\tlearn: 0.0816480\ttotal: 336ms\tremaining: 59.3ms\n",
      "85:\tlearn: 0.0808751\ttotal: 340ms\tremaining: 55.3ms\n",
      "86:\tlearn: 0.0796063\ttotal: 344ms\tremaining: 51.4ms\n",
      "87:\tlearn: 0.0784198\ttotal: 347ms\tremaining: 47.4ms\n",
      "88:\tlearn: 0.0771926\ttotal: 351ms\tremaining: 43.4ms\n",
      "89:\tlearn: 0.0763779\ttotal: 355ms\tremaining: 39.4ms\n",
      "90:\tlearn: 0.0751313\ttotal: 359ms\tremaining: 35.5ms\n",
      "91:\tlearn: 0.0737355\ttotal: 362ms\tremaining: 31.5ms\n",
      "92:\tlearn: 0.0719631\ttotal: 365ms\tremaining: 27.5ms\n",
      "93:\tlearn: 0.0709822\ttotal: 367ms\tremaining: 23.4ms\n",
      "94:\tlearn: 0.0697941\ttotal: 369ms\tremaining: 19.4ms\n",
      "95:\tlearn: 0.0691769\ttotal: 372ms\tremaining: 15.5ms\n",
      "96:\tlearn: 0.0681337\ttotal: 375ms\tremaining: 11.6ms\n",
      "97:\tlearn: 0.0676291\ttotal: 378ms\tremaining: 7.71ms\n",
      "98:\tlearn: 0.0667373\ttotal: 381ms\tremaining: 3.85ms\n",
      "99:\tlearn: 0.0656094\ttotal: 384ms\tremaining: 0us\n",
      "0:\tlearn: 0.6596832\ttotal: 3.61ms\tremaining: 358ms\n",
      "1:\tlearn: 0.6304489\ttotal: 7.31ms\tremaining: 358ms\n",
      "2:\tlearn: 0.5995056\ttotal: 10.3ms\tremaining: 333ms\n",
      "3:\tlearn: 0.5768044\ttotal: 13.4ms\tremaining: 323ms\n",
      "4:\tlearn: 0.5520286\ttotal: 16.4ms\tremaining: 312ms\n",
      "5:\tlearn: 0.5294294\ttotal: 19.3ms\tremaining: 302ms\n",
      "6:\tlearn: 0.5046084\ttotal: 22.3ms\tremaining: 296ms\n",
      "7:\tlearn: 0.4927039\ttotal: 25.3ms\tremaining: 291ms\n",
      "8:\tlearn: 0.4710432\ttotal: 28.7ms\tremaining: 290ms\n",
      "9:\tlearn: 0.4565088\ttotal: 31.8ms\tremaining: 286ms\n",
      "10:\tlearn: 0.4403106\ttotal: 34.8ms\tremaining: 281ms\n",
      "11:\tlearn: 0.4263815\ttotal: 38ms\tremaining: 279ms\n",
      "12:\tlearn: 0.4133465\ttotal: 41.1ms\tremaining: 275ms\n",
      "13:\tlearn: 0.3982009\ttotal: 44.2ms\tremaining: 271ms\n",
      "14:\tlearn: 0.3873266\ttotal: 47ms\tremaining: 266ms\n",
      "15:\tlearn: 0.3742269\ttotal: 49.8ms\tremaining: 262ms\n",
      "16:\tlearn: 0.3636628\ttotal: 52.8ms\tremaining: 258ms\n",
      "17:\tlearn: 0.3557181\ttotal: 55.7ms\tremaining: 254ms\n",
      "18:\tlearn: 0.3436020\ttotal: 58.4ms\tremaining: 249ms\n",
      "19:\tlearn: 0.3340578\ttotal: 61.4ms\tremaining: 246ms\n",
      "20:\tlearn: 0.3240127\ttotal: 64.1ms\tremaining: 241ms\n",
      "21:\tlearn: 0.3142150\ttotal: 67.2ms\tremaining: 238ms\n",
      "22:\tlearn: 0.3043019\ttotal: 72.3ms\tremaining: 242ms\n",
      "23:\tlearn: 0.2950780\ttotal: 77.4ms\tremaining: 245ms\n",
      "24:\tlearn: 0.2878904\ttotal: 82.7ms\tremaining: 248ms\n",
      "25:\tlearn: 0.2797290\ttotal: 87.9ms\tremaining: 250ms\n",
      "26:\tlearn: 0.2739726\ttotal: 92.9ms\tremaining: 251ms\n",
      "27:\tlearn: 0.2654612\ttotal: 98.2ms\tremaining: 253ms\n",
      "28:\tlearn: 0.2588093\ttotal: 103ms\tremaining: 253ms\n",
      "29:\tlearn: 0.2522812\ttotal: 108ms\tremaining: 253ms\n",
      "30:\tlearn: 0.2425739\ttotal: 114ms\tremaining: 253ms\n",
      "31:\tlearn: 0.2373519\ttotal: 119ms\tremaining: 252ms\n",
      "32:\tlearn: 0.2323476\ttotal: 124ms\tremaining: 252ms\n",
      "33:\tlearn: 0.2282922\ttotal: 129ms\tremaining: 251ms\n",
      "34:\tlearn: 0.2235686\ttotal: 134ms\tremaining: 250ms\n",
      "35:\tlearn: 0.2179774\ttotal: 140ms\tremaining: 248ms\n",
      "36:\tlearn: 0.2128349\ttotal: 145ms\tremaining: 247ms\n",
      "37:\tlearn: 0.2084778\ttotal: 150ms\tremaining: 244ms\n",
      "38:\tlearn: 0.2016530\ttotal: 155ms\tremaining: 243ms\n",
      "39:\tlearn: 0.1947633\ttotal: 159ms\tremaining: 239ms\n",
      "40:\tlearn: 0.1905281\ttotal: 163ms\tremaining: 235ms\n",
      "41:\tlearn: 0.1864501\ttotal: 167ms\tremaining: 230ms\n",
      "42:\tlearn: 0.1838576\ttotal: 171ms\tremaining: 226ms\n",
      "43:\tlearn: 0.1806598\ttotal: 176ms\tremaining: 224ms\n",
      "44:\tlearn: 0.1759692\ttotal: 180ms\tremaining: 219ms\n",
      "45:\tlearn: 0.1728076\ttotal: 182ms\tremaining: 214ms\n",
      "46:\tlearn: 0.1687382\ttotal: 186ms\tremaining: 209ms\n",
      "47:\tlearn: 0.1635279\ttotal: 190ms\tremaining: 206ms\n",
      "48:\tlearn: 0.1604742\ttotal: 193ms\tremaining: 201ms\n",
      "49:\tlearn: 0.1549863\ttotal: 196ms\tremaining: 196ms\n",
      "50:\tlearn: 0.1524453\ttotal: 199ms\tremaining: 191ms\n",
      "51:\tlearn: 0.1481527\ttotal: 201ms\tremaining: 186ms\n",
      "52:\tlearn: 0.1434827\ttotal: 205ms\tremaining: 181ms\n",
      "53:\tlearn: 0.1409021\ttotal: 208ms\tremaining: 177ms\n",
      "54:\tlearn: 0.1383678\ttotal: 211ms\tremaining: 173ms\n",
      "55:\tlearn: 0.1364888\ttotal: 215ms\tremaining: 169ms\n",
      "56:\tlearn: 0.1339449\ttotal: 218ms\tremaining: 164ms\n",
      "57:\tlearn: 0.1314032\ttotal: 221ms\tremaining: 160ms\n",
      "58:\tlearn: 0.1280072\ttotal: 224ms\tremaining: 156ms\n",
      "59:\tlearn: 0.1255149\ttotal: 227ms\tremaining: 151ms\n",
      "60:\tlearn: 0.1244233\ttotal: 230ms\tremaining: 147ms\n",
      "61:\tlearn: 0.1213949\ttotal: 235ms\tremaining: 144ms\n",
      "62:\tlearn: 0.1189938\ttotal: 240ms\tremaining: 141ms\n",
      "63:\tlearn: 0.1166660\ttotal: 246ms\tremaining: 138ms\n",
      "64:\tlearn: 0.1151028\ttotal: 251ms\tremaining: 135ms\n",
      "65:\tlearn: 0.1133722\ttotal: 256ms\tremaining: 132ms\n",
      "66:\tlearn: 0.1099683\ttotal: 261ms\tremaining: 129ms\n",
      "67:\tlearn: 0.1080093\ttotal: 267ms\tremaining: 125ms\n",
      "68:\tlearn: 0.1068448\ttotal: 272ms\tremaining: 122ms\n",
      "69:\tlearn: 0.1028690\ttotal: 277ms\tremaining: 119ms\n",
      "70:\tlearn: 0.1011546\ttotal: 282ms\tremaining: 115ms\n",
      "71:\tlearn: 0.0993478\ttotal: 288ms\tremaining: 112ms\n",
      "72:\tlearn: 0.0973013\ttotal: 293ms\tremaining: 108ms\n",
      "73:\tlearn: 0.0957227\ttotal: 298ms\tremaining: 105ms\n",
      "74:\tlearn: 0.0941266\ttotal: 303ms\tremaining: 101ms\n",
      "75:\tlearn: 0.0927844\ttotal: 308ms\tremaining: 97.3ms\n",
      "76:\tlearn: 0.0907377\ttotal: 313ms\tremaining: 93.6ms\n",
      "77:\tlearn: 0.0893037\ttotal: 319ms\tremaining: 90ms\n",
      "78:\tlearn: 0.0877473\ttotal: 323ms\tremaining: 85.8ms\n",
      "79:\tlearn: 0.0865747\ttotal: 327ms\tremaining: 81.7ms\n",
      "80:\tlearn: 0.0854706\ttotal: 330ms\tremaining: 77.5ms\n",
      "81:\tlearn: 0.0839127\ttotal: 334ms\tremaining: 73.4ms\n",
      "82:\tlearn: 0.0824625\ttotal: 338ms\tremaining: 69.2ms\n",
      "83:\tlearn: 0.0810555\ttotal: 342ms\tremaining: 65.1ms\n",
      "84:\tlearn: 0.0784247\ttotal: 345ms\tremaining: 61ms\n",
      "85:\tlearn: 0.0775672\ttotal: 349ms\tremaining: 56.8ms\n",
      "86:\tlearn: 0.0761441\ttotal: 353ms\tremaining: 52.8ms\n",
      "87:\tlearn: 0.0754494\ttotal: 357ms\tremaining: 48.7ms\n",
      "88:\tlearn: 0.0744085\ttotal: 361ms\tremaining: 44.6ms\n",
      "89:\tlearn: 0.0735576\ttotal: 364ms\tremaining: 40.5ms\n",
      "90:\tlearn: 0.0724321\ttotal: 368ms\tremaining: 36.4ms\n",
      "91:\tlearn: 0.0711409\ttotal: 371ms\tremaining: 32.2ms\n",
      "92:\tlearn: 0.0691815\ttotal: 374ms\tremaining: 28.1ms\n",
      "93:\tlearn: 0.0683653\ttotal: 376ms\tremaining: 24ms\n",
      "94:\tlearn: 0.0673228\ttotal: 379ms\tremaining: 20ms\n",
      "95:\tlearn: 0.0667448\ttotal: 382ms\tremaining: 15.9ms\n",
      "96:\tlearn: 0.0657205\ttotal: 385ms\tremaining: 11.9ms\n",
      "97:\tlearn: 0.0646109\ttotal: 388ms\tremaining: 7.91ms\n",
      "98:\tlearn: 0.0636765\ttotal: 390ms\tremaining: 3.94ms\n",
      "99:\tlearn: 0.0623212\ttotal: 393ms\tremaining: 0us\n",
      "0:\tlearn: 0.6889968\ttotal: 25.6ms\tremaining: 2.54s\n",
      "1:\tlearn: 0.6847591\ttotal: 87.1ms\tremaining: 4.27s\n",
      "2:\tlearn: 0.6809759\ttotal: 147ms\tremaining: 4.77s\n",
      "3:\tlearn: 0.6769466\ttotal: 175ms\tremaining: 4.2s\n",
      "4:\tlearn: 0.6737146\ttotal: 198ms\tremaining: 3.77s\n",
      "5:\tlearn: 0.6692587\ttotal: 274ms\tremaining: 4.29s\n",
      "6:\tlearn: 0.6655373\ttotal: 328ms\tremaining: 4.35s\n",
      "7:\tlearn: 0.6612093\ttotal: 356ms\tremaining: 4.1s\n",
      "8:\tlearn: 0.6573385\ttotal: 380ms\tremaining: 3.84s\n",
      "9:\tlearn: 0.6540954\ttotal: 410ms\tremaining: 3.69s\n",
      "10:\tlearn: 0.6510249\ttotal: 490ms\tremaining: 3.96s\n",
      "11:\tlearn: 0.6470738\ttotal: 523ms\tremaining: 3.83s\n",
      "12:\tlearn: 0.6438962\ttotal: 548ms\tremaining: 3.67s\n",
      "13:\tlearn: 0.6405876\ttotal: 570ms\tremaining: 3.5s\n",
      "14:\tlearn: 0.6376621\ttotal: 650ms\tremaining: 3.68s\n",
      "15:\tlearn: 0.6340023\ttotal: 697ms\tremaining: 3.66s\n",
      "16:\tlearn: 0.6305414\ttotal: 722ms\tremaining: 3.52s\n",
      "17:\tlearn: 0.6267394\ttotal: 762ms\tremaining: 3.47s\n",
      "18:\tlearn: 0.6223023\ttotal: 841ms\tremaining: 3.58s\n",
      "19:\tlearn: 0.6190705\ttotal: 866ms\tremaining: 3.46s\n",
      "20:\tlearn: 0.6160378\ttotal: 892ms\tremaining: 3.36s\n",
      "21:\tlearn: 0.6132354\ttotal: 973ms\tremaining: 3.45s\n",
      "22:\tlearn: 0.6097428\ttotal: 1.01s\tremaining: 3.4s\n",
      "23:\tlearn: 0.6070757\ttotal: 1.04s\tremaining: 3.3s\n",
      "24:\tlearn: 0.6038761\ttotal: 1.07s\tremaining: 3.2s\n",
      "25:\tlearn: 0.6009525\ttotal: 1.09s\tremaining: 3.1s\n",
      "26:\tlearn: 0.5980147\ttotal: 1.14s\tremaining: 3.08s\n",
      "27:\tlearn: 0.5951496\ttotal: 1.21s\tremaining: 3.11s\n",
      "28:\tlearn: 0.5925432\ttotal: 1.24s\tremaining: 3.04s\n",
      "29:\tlearn: 0.5899745\ttotal: 1.27s\tremaining: 2.96s\n",
      "30:\tlearn: 0.5872840\ttotal: 1.33s\tremaining: 2.95s\n",
      "31:\tlearn: 0.5847673\ttotal: 1.39s\tremaining: 2.96s\n",
      "32:\tlearn: 0.5809587\ttotal: 1.43s\tremaining: 2.9s\n",
      "33:\tlearn: 0.5790470\ttotal: 1.45s\tremaining: 2.81s\n",
      "34:\tlearn: 0.5765904\ttotal: 1.51s\tremaining: 2.81s\n",
      "35:\tlearn: 0.5739913\ttotal: 1.57s\tremaining: 2.79s\n",
      "36:\tlearn: 0.5718163\ttotal: 1.6s\tremaining: 2.73s\n",
      "37:\tlearn: 0.5694052\ttotal: 1.62s\tremaining: 2.65s\n",
      "38:\tlearn: 0.5665356\ttotal: 1.65s\tremaining: 2.58s\n",
      "39:\tlearn: 0.5639045\ttotal: 1.73s\tremaining: 2.6s\n",
      "40:\tlearn: 0.5612032\ttotal: 1.77s\tremaining: 2.54s\n",
      "41:\tlearn: 0.5590194\ttotal: 1.79s\tremaining: 2.48s\n",
      "42:\tlearn: 0.5569178\ttotal: 1.82s\tremaining: 2.41s\n",
      "43:\tlearn: 0.5545454\ttotal: 1.87s\tremaining: 2.38s\n",
      "44:\tlearn: 0.5517683\ttotal: 1.93s\tremaining: 2.35s\n",
      "45:\tlearn: 0.5495420\ttotal: 1.96s\tremaining: 2.3s\n",
      "46:\tlearn: 0.5469068\ttotal: 1.98s\tremaining: 2.23s\n",
      "47:\tlearn: 0.5445867\ttotal: 2.05s\tremaining: 2.22s\n",
      "48:\tlearn: 0.5421801\ttotal: 2.1s\tremaining: 2.19s\n",
      "49:\tlearn: 0.5397533\ttotal: 2.13s\tremaining: 2.13s\n",
      "50:\tlearn: 0.5374670\ttotal: 2.16s\tremaining: 2.07s\n",
      "51:\tlearn: 0.5345379\ttotal: 2.22s\tremaining: 2.05s\n",
      "52:\tlearn: 0.5322926\ttotal: 2.28s\tremaining: 2.02s\n",
      "53:\tlearn: 0.5297660\ttotal: 2.31s\tremaining: 1.97s\n",
      "54:\tlearn: 0.5264769\ttotal: 2.34s\tremaining: 1.91s\n",
      "55:\tlearn: 0.5243549\ttotal: 2.4s\tremaining: 1.89s\n",
      "56:\tlearn: 0.5217813\ttotal: 2.46s\tremaining: 1.85s\n",
      "57:\tlearn: 0.5195115\ttotal: 2.49s\tremaining: 1.8s\n",
      "58:\tlearn: 0.5170812\ttotal: 2.51s\tremaining: 1.75s\n",
      "59:\tlearn: 0.5150184\ttotal: 2.56s\tremaining: 1.71s\n",
      "60:\tlearn: 0.5121842\ttotal: 2.63s\tremaining: 1.68s\n",
      "61:\tlearn: 0.5099309\ttotal: 2.66s\tremaining: 1.63s\n",
      "62:\tlearn: 0.5076987\ttotal: 2.69s\tremaining: 1.58s\n",
      "63:\tlearn: 0.5051454\ttotal: 2.74s\tremaining: 1.54s\n",
      "64:\tlearn: 0.5028402\ttotal: 2.81s\tremaining: 1.51s\n",
      "65:\tlearn: 0.5008650\ttotal: 2.84s\tremaining: 1.46s\n",
      "66:\tlearn: 0.4988209\ttotal: 2.87s\tremaining: 1.41s\n",
      "67:\tlearn: 0.4968716\ttotal: 2.92s\tremaining: 1.37s\n",
      "68:\tlearn: 0.4948776\ttotal: 2.98s\tremaining: 1.34s\n",
      "69:\tlearn: 0.4930206\ttotal: 3.02s\tremaining: 1.29s\n",
      "70:\tlearn: 0.4907564\ttotal: 3.04s\tremaining: 1.24s\n",
      "71:\tlearn: 0.4890693\ttotal: 3.09s\tremaining: 1.2s\n",
      "72:\tlearn: 0.4864022\ttotal: 3.16s\tremaining: 1.17s\n",
      "73:\tlearn: 0.4845512\ttotal: 3.19s\tremaining: 1.12s\n",
      "74:\tlearn: 0.4827674\ttotal: 3.22s\tremaining: 1.07s\n",
      "75:\tlearn: 0.4802008\ttotal: 3.24s\tremaining: 1.02s\n",
      "76:\tlearn: 0.4781048\ttotal: 3.32s\tremaining: 993ms\n",
      "77:\tlearn: 0.4762034\ttotal: 3.35s\tremaining: 946ms\n",
      "78:\tlearn: 0.4739269\ttotal: 3.38s\tremaining: 898ms\n",
      "79:\tlearn: 0.4701708\ttotal: 3.43s\tremaining: 857ms\n",
      "80:\tlearn: 0.4683194\ttotal: 3.49s\tremaining: 819ms\n",
      "81:\tlearn: 0.4666058\ttotal: 3.53s\tremaining: 774ms\n",
      "82:\tlearn: 0.4645525\ttotal: 3.55s\tremaining: 727ms\n",
      "83:\tlearn: 0.4626703\ttotal: 3.6s\tremaining: 686ms\n",
      "84:\tlearn: 0.4601044\ttotal: 3.67s\tremaining: 647ms\n",
      "85:\tlearn: 0.4578036\ttotal: 3.69s\tremaining: 601ms\n",
      "86:\tlearn: 0.4558673\ttotal: 3.72s\tremaining: 555ms\n",
      "87:\tlearn: 0.4544152\ttotal: 3.74s\tremaining: 510ms\n",
      "88:\tlearn: 0.4522075\ttotal: 3.82s\tremaining: 472ms\n",
      "89:\tlearn: 0.4497639\ttotal: 3.86s\tremaining: 429ms\n",
      "90:\tlearn: 0.4482559\ttotal: 3.89s\tremaining: 385ms\n",
      "91:\tlearn: 0.4460398\ttotal: 3.91s\tremaining: 340ms\n",
      "92:\tlearn: 0.4442950\ttotal: 3.99s\tremaining: 301ms\n",
      "93:\tlearn: 0.4424215\ttotal: 4.04s\tremaining: 258ms\n",
      "94:\tlearn: 0.4408433\ttotal: 4.06s\tremaining: 214ms\n",
      "95:\tlearn: 0.4390252\ttotal: 4.09s\tremaining: 170ms\n",
      "96:\tlearn: 0.4367806\ttotal: 4.15s\tremaining: 128ms\n",
      "97:\tlearn: 0.4348600\ttotal: 4.23s\tremaining: 86.4ms\n",
      "98:\tlearn: 0.4329803\ttotal: 4.27s\tremaining: 43.1ms\n",
      "99:\tlearn: 0.4312335\ttotal: 4.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6895540\ttotal: 25ms\tremaining: 2.47s\n",
      "1:\tlearn: 0.6856500\ttotal: 104ms\tremaining: 5.09s\n",
      "2:\tlearn: 0.6820555\ttotal: 139ms\tremaining: 4.49s\n",
      "3:\tlearn: 0.6786481\ttotal: 163ms\tremaining: 3.92s\n",
      "4:\tlearn: 0.6752253\ttotal: 228ms\tremaining: 4.34s\n",
      "5:\tlearn: 0.6717789\ttotal: 287ms\tremaining: 4.5s\n",
      "6:\tlearn: 0.6675025\ttotal: 315ms\tremaining: 4.18s\n",
      "7:\tlearn: 0.6631971\ttotal: 338ms\tremaining: 3.89s\n",
      "8:\tlearn: 0.6596705\ttotal: 385ms\tremaining: 3.89s\n",
      "9:\tlearn: 0.6566984\ttotal: 456ms\tremaining: 4.11s\n",
      "10:\tlearn: 0.6534811\ttotal: 487ms\tremaining: 3.94s\n",
      "11:\tlearn: 0.6497779\ttotal: 512ms\tremaining: 3.75s\n",
      "12:\tlearn: 0.6471131\ttotal: 536ms\tremaining: 3.59s\n",
      "13:\tlearn: 0.6439093\ttotal: 615ms\tremaining: 3.77s\n",
      "14:\tlearn: 0.6403324\ttotal: 660ms\tremaining: 3.74s\n",
      "15:\tlearn: 0.6365076\ttotal: 687ms\tremaining: 3.6s\n",
      "16:\tlearn: 0.6324554\ttotal: 708ms\tremaining: 3.46s\n",
      "17:\tlearn: 0.6282454\ttotal: 788ms\tremaining: 3.59s\n",
      "18:\tlearn: 0.6247530\ttotal: 830ms\tremaining: 3.54s\n",
      "19:\tlearn: 0.6215673\ttotal: 856ms\tremaining: 3.42s\n",
      "20:\tlearn: 0.6176330\ttotal: 879ms\tremaining: 3.31s\n",
      "21:\tlearn: 0.6144930\ttotal: 961ms\tremaining: 3.41s\n",
      "22:\tlearn: 0.6118085\ttotal: 1.01s\tremaining: 3.37s\n",
      "23:\tlearn: 0.6084048\ttotal: 1.03s\tremaining: 3.28s\n",
      "24:\tlearn: 0.6051313\ttotal: 1.06s\tremaining: 3.18s\n",
      "25:\tlearn: 0.6023897\ttotal: 1.14s\tremaining: 3.25s\n",
      "26:\tlearn: 0.5993693\ttotal: 1.19s\tremaining: 3.21s\n",
      "27:\tlearn: 0.5965705\ttotal: 1.21s\tremaining: 3.12s\n",
      "28:\tlearn: 0.5939002\ttotal: 1.24s\tremaining: 3.02s\n",
      "29:\tlearn: 0.5909376\ttotal: 1.29s\tremaining: 3s\n",
      "30:\tlearn: 0.5883056\ttotal: 1.35s\tremaining: 3.01s\n",
      "31:\tlearn: 0.5849328\ttotal: 1.38s\tremaining: 2.93s\n",
      "32:\tlearn: 0.5820925\ttotal: 1.4s\tremaining: 2.85s\n",
      "33:\tlearn: 0.5797411\ttotal: 1.45s\tremaining: 2.81s\n",
      "34:\tlearn: 0.5767662\ttotal: 1.52s\tremaining: 2.83s\n",
      "35:\tlearn: 0.5744482\ttotal: 1.56s\tremaining: 2.77s\n",
      "36:\tlearn: 0.5715473\ttotal: 1.58s\tremaining: 2.69s\n",
      "37:\tlearn: 0.5690444\ttotal: 1.64s\tremaining: 2.68s\n",
      "38:\tlearn: 0.5669425\ttotal: 1.71s\tremaining: 2.67s\n",
      "39:\tlearn: 0.5649402\ttotal: 1.74s\tremaining: 2.61s\n",
      "40:\tlearn: 0.5618893\ttotal: 1.76s\tremaining: 2.54s\n",
      "41:\tlearn: 0.5589176\ttotal: 1.84s\tremaining: 2.54s\n",
      "42:\tlearn: 0.5566138\ttotal: 1.89s\tremaining: 2.51s\n",
      "43:\tlearn: 0.5534750\ttotal: 1.92s\tremaining: 2.44s\n",
      "44:\tlearn: 0.5509526\ttotal: 1.94s\tremaining: 2.38s\n",
      "45:\tlearn: 0.5484627\ttotal: 2s\tremaining: 2.34s\n",
      "46:\tlearn: 0.5454307\ttotal: 2.06s\tremaining: 2.33s\n",
      "47:\tlearn: 0.5428324\ttotal: 2.09s\tremaining: 2.27s\n",
      "48:\tlearn: 0.5408329\ttotal: 2.12s\tremaining: 2.2s\n",
      "49:\tlearn: 0.5388994\ttotal: 2.17s\tremaining: 2.17s\n",
      "50:\tlearn: 0.5367235\ttotal: 2.23s\tremaining: 2.15s\n",
      "51:\tlearn: 0.5339098\ttotal: 2.27s\tremaining: 2.1s\n",
      "52:\tlearn: 0.5317299\ttotal: 2.29s\tremaining: 2.03s\n",
      "53:\tlearn: 0.5287875\ttotal: 2.35s\tremaining: 2s\n",
      "54:\tlearn: 0.5251328\ttotal: 2.42s\tremaining: 1.98s\n",
      "55:\tlearn: 0.5229709\ttotal: 2.45s\tremaining: 1.92s\n",
      "56:\tlearn: 0.5209791\ttotal: 2.47s\tremaining: 1.86s\n",
      "57:\tlearn: 0.5185482\ttotal: 2.52s\tremaining: 1.82s\n",
      "58:\tlearn: 0.5157193\ttotal: 2.58s\tremaining: 1.79s\n",
      "59:\tlearn: 0.5137156\ttotal: 2.62s\tremaining: 1.74s\n",
      "60:\tlearn: 0.5106837\ttotal: 2.64s\tremaining: 1.69s\n",
      "61:\tlearn: 0.5087148\ttotal: 2.67s\tremaining: 1.64s\n",
      "62:\tlearn: 0.5070257\ttotal: 2.7s\tremaining: 1.59s\n",
      "63:\tlearn: 0.5043892\ttotal: 2.78s\tremaining: 1.56s\n",
      "64:\tlearn: 0.5016637\ttotal: 2.82s\tremaining: 1.52s\n",
      "65:\tlearn: 0.4989830\ttotal: 2.85s\tremaining: 1.47s\n",
      "66:\tlearn: 0.4970038\ttotal: 2.87s\tremaining: 1.42s\n",
      "67:\tlearn: 0.4949021\ttotal: 2.95s\tremaining: 1.39s\n",
      "68:\tlearn: 0.4926372\ttotal: 2.99s\tremaining: 1.34s\n",
      "69:\tlearn: 0.4908095\ttotal: 3.02s\tremaining: 1.29s\n",
      "70:\tlearn: 0.4886215\ttotal: 3.04s\tremaining: 1.24s\n",
      "71:\tlearn: 0.4861517\ttotal: 3.11s\tremaining: 1.21s\n",
      "72:\tlearn: 0.4837269\ttotal: 3.16s\tremaining: 1.17s\n",
      "73:\tlearn: 0.4810980\ttotal: 3.19s\tremaining: 1.12s\n",
      "74:\tlearn: 0.4787040\ttotal: 3.22s\tremaining: 1.07s\n",
      "75:\tlearn: 0.4765828\ttotal: 3.27s\tremaining: 1.03s\n",
      "76:\tlearn: 0.4748030\ttotal: 3.33s\tremaining: 996ms\n",
      "77:\tlearn: 0.4727495\ttotal: 3.37s\tremaining: 949ms\n",
      "78:\tlearn: 0.4703338\ttotal: 3.39s\tremaining: 901ms\n",
      "79:\tlearn: 0.4684182\ttotal: 3.45s\tremaining: 863ms\n",
      "80:\tlearn: 0.4666233\ttotal: 3.51s\tremaining: 824ms\n",
      "81:\tlearn: 0.4646626\ttotal: 3.54s\tremaining: 778ms\n",
      "82:\tlearn: 0.4629757\ttotal: 3.56s\tremaining: 730ms\n",
      "83:\tlearn: 0.4607547\ttotal: 3.62s\tremaining: 689ms\n",
      "84:\tlearn: 0.4586519\ttotal: 3.68s\tremaining: 650ms\n",
      "85:\tlearn: 0.4569021\ttotal: 3.72s\tremaining: 605ms\n",
      "86:\tlearn: 0.4551957\ttotal: 3.74s\tremaining: 559ms\n",
      "87:\tlearn: 0.4530061\ttotal: 3.77s\tremaining: 514ms\n",
      "88:\tlearn: 0.4513560\ttotal: 3.85s\tremaining: 475ms\n",
      "89:\tlearn: 0.4495492\ttotal: 3.88s\tremaining: 432ms\n",
      "90:\tlearn: 0.4479849\ttotal: 3.91s\tremaining: 387ms\n",
      "91:\tlearn: 0.4458203\ttotal: 3.93s\tremaining: 342ms\n",
      "92:\tlearn: 0.4443168\ttotal: 4.01s\tremaining: 302ms\n",
      "93:\tlearn: 0.4428786\ttotal: 4.05s\tremaining: 259ms\n",
      "94:\tlearn: 0.4412849\ttotal: 4.08s\tremaining: 215ms\n",
      "95:\tlearn: 0.4396548\ttotal: 4.11s\tremaining: 171ms\n",
      "96:\tlearn: 0.4374226\ttotal: 4.16s\tremaining: 129ms\n",
      "97:\tlearn: 0.4352453\ttotal: 4.22s\tremaining: 86.2ms\n",
      "98:\tlearn: 0.4334845\ttotal: 4.25s\tremaining: 43ms\n",
      "99:\tlearn: 0.4316886\ttotal: 4.28s\tremaining: 0us\n",
      "0:\tlearn: 0.6894731\ttotal: 26.1ms\tremaining: 2.58s\n",
      "1:\tlearn: 0.6850994\ttotal: 48.9ms\tremaining: 2.4s\n",
      "2:\tlearn: 0.6814156\ttotal: 106ms\tremaining: 3.42s\n",
      "3:\tlearn: 0.6781406\ttotal: 160ms\tremaining: 3.83s\n",
      "4:\tlearn: 0.6749461\ttotal: 192ms\tremaining: 3.65s\n",
      "5:\tlearn: 0.6704019\ttotal: 222ms\tremaining: 3.47s\n",
      "6:\tlearn: 0.6666642\ttotal: 248ms\tremaining: 3.29s\n",
      "7:\tlearn: 0.6627464\ttotal: 328ms\tremaining: 3.77s\n",
      "8:\tlearn: 0.6590606\ttotal: 360ms\tremaining: 3.64s\n",
      "9:\tlearn: 0.6555589\ttotal: 382ms\tremaining: 3.44s\n",
      "10:\tlearn: 0.6523718\ttotal: 429ms\tremaining: 3.47s\n",
      "11:\tlearn: 0.6476046\ttotal: 497ms\tremaining: 3.64s\n",
      "12:\tlearn: 0.6443363\ttotal: 529ms\tremaining: 3.54s\n",
      "13:\tlearn: 0.6406680\ttotal: 554ms\tremaining: 3.4s\n",
      "14:\tlearn: 0.6370316\ttotal: 578ms\tremaining: 3.27s\n",
      "15:\tlearn: 0.6340791\ttotal: 660ms\tremaining: 3.46s\n",
      "16:\tlearn: 0.6303513\ttotal: 688ms\tremaining: 3.36s\n",
      "17:\tlearn: 0.6266291\ttotal: 711ms\tremaining: 3.24s\n",
      "18:\tlearn: 0.6231026\ttotal: 734ms\tremaining: 3.13s\n",
      "19:\tlearn: 0.6200309\ttotal: 812ms\tremaining: 3.25s\n",
      "20:\tlearn: 0.6172066\ttotal: 847ms\tremaining: 3.19s\n",
      "21:\tlearn: 0.6136742\ttotal: 874ms\tremaining: 3.1s\n",
      "22:\tlearn: 0.6113445\ttotal: 897ms\tremaining: 3s\n",
      "23:\tlearn: 0.6076140\ttotal: 975ms\tremaining: 3.09s\n",
      "24:\tlearn: 0.6040780\ttotal: 1.02s\tremaining: 3.06s\n",
      "25:\tlearn: 0.6007289\ttotal: 1.05s\tremaining: 2.98s\n",
      "26:\tlearn: 0.5976054\ttotal: 1.07s\tremaining: 2.89s\n",
      "27:\tlearn: 0.5948941\ttotal: 1.15s\tremaining: 2.95s\n",
      "28:\tlearn: 0.5924155\ttotal: 1.2s\tremaining: 2.94s\n",
      "29:\tlearn: 0.5887963\ttotal: 1.23s\tremaining: 2.86s\n",
      "30:\tlearn: 0.5859349\ttotal: 1.25s\tremaining: 2.78s\n",
      "31:\tlearn: 0.5824697\ttotal: 1.33s\tremaining: 2.83s\n",
      "32:\tlearn: 0.5796985\ttotal: 1.38s\tremaining: 2.79s\n",
      "33:\tlearn: 0.5764571\ttotal: 1.4s\tremaining: 2.72s\n",
      "34:\tlearn: 0.5736240\ttotal: 1.43s\tremaining: 2.65s\n",
      "35:\tlearn: 0.5708399\ttotal: 1.47s\tremaining: 2.61s\n",
      "36:\tlearn: 0.5684805\ttotal: 1.52s\tremaining: 2.59s\n",
      "37:\tlearn: 0.5659519\ttotal: 1.55s\tremaining: 2.53s\n",
      "38:\tlearn: 0.5628604\ttotal: 1.57s\tremaining: 2.46s\n",
      "39:\tlearn: 0.5607414\ttotal: 1.66s\tremaining: 2.48s\n",
      "40:\tlearn: 0.5568535\ttotal: 1.7s\tremaining: 2.45s\n",
      "41:\tlearn: 0.5542929\ttotal: 1.73s\tremaining: 2.39s\n",
      "42:\tlearn: 0.5515793\ttotal: 1.75s\tremaining: 2.32s\n",
      "43:\tlearn: 0.5488298\ttotal: 1.83s\tremaining: 2.33s\n",
      "44:\tlearn: 0.5464788\ttotal: 1.88s\tremaining: 2.3s\n",
      "45:\tlearn: 0.5441840\ttotal: 1.91s\tremaining: 2.24s\n",
      "46:\tlearn: 0.5414058\ttotal: 1.93s\tremaining: 2.18s\n",
      "47:\tlearn: 0.5382198\ttotal: 2.01s\tremaining: 2.18s\n",
      "48:\tlearn: 0.5356205\ttotal: 2.06s\tremaining: 2.14s\n",
      "49:\tlearn: 0.5333478\ttotal: 2.08s\tremaining: 2.08s\n",
      "50:\tlearn: 0.5314704\ttotal: 2.11s\tremaining: 2.02s\n",
      "51:\tlearn: 0.5292532\ttotal: 2.19s\tremaining: 2.02s\n",
      "52:\tlearn: 0.5269257\ttotal: 2.23s\tremaining: 1.98s\n",
      "53:\tlearn: 0.5241124\ttotal: 2.26s\tremaining: 1.92s\n",
      "54:\tlearn: 0.5218373\ttotal: 2.28s\tremaining: 1.87s\n",
      "55:\tlearn: 0.5193270\ttotal: 2.36s\tremaining: 1.85s\n",
      "56:\tlearn: 0.5169995\ttotal: 2.41s\tremaining: 1.82s\n",
      "57:\tlearn: 0.5145771\ttotal: 2.44s\tremaining: 1.76s\n",
      "58:\tlearn: 0.5117487\ttotal: 2.46s\tremaining: 1.71s\n",
      "59:\tlearn: 0.5099546\ttotal: 2.51s\tremaining: 1.67s\n",
      "60:\tlearn: 0.5078107\ttotal: 2.57s\tremaining: 1.64s\n",
      "61:\tlearn: 0.5055796\ttotal: 2.6s\tremaining: 1.59s\n",
      "62:\tlearn: 0.5038216\ttotal: 2.62s\tremaining: 1.54s\n",
      "63:\tlearn: 0.5013061\ttotal: 2.67s\tremaining: 1.5s\n",
      "64:\tlearn: 0.4982958\ttotal: 2.75s\tremaining: 1.48s\n",
      "65:\tlearn: 0.4960018\ttotal: 2.78s\tremaining: 1.43s\n",
      "66:\tlearn: 0.4934542\ttotal: 2.81s\tremaining: 1.38s\n",
      "67:\tlearn: 0.4915318\ttotal: 2.83s\tremaining: 1.33s\n",
      "68:\tlearn: 0.4889438\ttotal: 2.85s\tremaining: 1.28s\n",
      "69:\tlearn: 0.4865882\ttotal: 2.93s\tremaining: 1.26s\n",
      "70:\tlearn: 0.4843946\ttotal: 2.97s\tremaining: 1.21s\n",
      "71:\tlearn: 0.4823080\ttotal: 3s\tremaining: 1.17s\n",
      "72:\tlearn: 0.4802887\ttotal: 3.02s\tremaining: 1.12s\n",
      "73:\tlearn: 0.4780208\ttotal: 3.1s\tremaining: 1.09s\n",
      "74:\tlearn: 0.4761373\ttotal: 3.15s\tremaining: 1.05s\n",
      "75:\tlearn: 0.4739734\ttotal: 3.18s\tremaining: 1s\n",
      "76:\tlearn: 0.4721428\ttotal: 3.2s\tremaining: 957ms\n",
      "77:\tlearn: 0.4701227\ttotal: 3.28s\tremaining: 926ms\n",
      "78:\tlearn: 0.4675409\ttotal: 3.32s\tremaining: 884ms\n",
      "79:\tlearn: 0.4649609\ttotal: 3.35s\tremaining: 838ms\n",
      "80:\tlearn: 0.4624267\ttotal: 3.38s\tremaining: 792ms\n",
      "81:\tlearn: 0.4607940\ttotal: 3.44s\tremaining: 754ms\n",
      "82:\tlearn: 0.4584396\ttotal: 3.49s\tremaining: 715ms\n",
      "83:\tlearn: 0.4563553\ttotal: 3.52s\tremaining: 671ms\n",
      "84:\tlearn: 0.4543870\ttotal: 3.55s\tremaining: 626ms\n",
      "85:\tlearn: 0.4508592\ttotal: 3.57s\tremaining: 581ms\n",
      "86:\tlearn: 0.4492905\ttotal: 3.65s\tremaining: 545ms\n",
      "87:\tlearn: 0.4473081\ttotal: 3.68s\tremaining: 502ms\n",
      "88:\tlearn: 0.4452537\ttotal: 3.7s\tremaining: 458ms\n",
      "89:\tlearn: 0.4426046\ttotal: 3.77s\tremaining: 418ms\n",
      "90:\tlearn: 0.4407256\ttotal: 3.83s\tremaining: 378ms\n",
      "91:\tlearn: 0.4385610\ttotal: 3.86s\tremaining: 336ms\n",
      "92:\tlearn: 0.4366019\ttotal: 3.88s\tremaining: 292ms\n",
      "93:\tlearn: 0.4347853\ttotal: 3.95s\tremaining: 252ms\n",
      "94:\tlearn: 0.4332589\ttotal: 4s\tremaining: 211ms\n",
      "95:\tlearn: 0.4312432\ttotal: 4.03s\tremaining: 168ms\n",
      "96:\tlearn: 0.4295224\ttotal: 4.09s\tremaining: 127ms\n",
      "97:\tlearn: 0.4279797\ttotal: 4.15s\tremaining: 84.6ms\n",
      "98:\tlearn: 0.4265597\ttotal: 4.17s\tremaining: 42.2ms\n",
      "99:\tlearn: 0.4247191\ttotal: 4.2s\tremaining: 0us\n",
      "0:\tlearn: 0.6883921\ttotal: 38.2ms\tremaining: 3.78s\n",
      "1:\tlearn: 0.6838724\ttotal: 64ms\tremaining: 3.14s\n",
      "2:\tlearn: 0.6796687\ttotal: 87.2ms\tremaining: 2.82s\n",
      "3:\tlearn: 0.6764791\ttotal: 169ms\tremaining: 4.05s\n",
      "4:\tlearn: 0.6729080\ttotal: 216ms\tremaining: 4.11s\n",
      "5:\tlearn: 0.6683693\ttotal: 245ms\tremaining: 3.83s\n",
      "6:\tlearn: 0.6647285\ttotal: 271ms\tremaining: 3.6s\n",
      "7:\tlearn: 0.6614633\ttotal: 353ms\tremaining: 4.06s\n",
      "8:\tlearn: 0.6574365\ttotal: 395ms\tremaining: 3.99s\n",
      "9:\tlearn: 0.6544322\ttotal: 418ms\tremaining: 3.76s\n",
      "10:\tlearn: 0.6511561\ttotal: 446ms\tremaining: 3.61s\n",
      "11:\tlearn: 0.6476865\ttotal: 469ms\tremaining: 3.44s\n",
      "12:\tlearn: 0.6442234\ttotal: 537ms\tremaining: 3.59s\n",
      "13:\tlearn: 0.6404145\ttotal: 599ms\tremaining: 3.68s\n",
      "14:\tlearn: 0.6361703\ttotal: 626ms\tremaining: 3.55s\n",
      "15:\tlearn: 0.6321714\ttotal: 649ms\tremaining: 3.41s\n",
      "16:\tlearn: 0.6288816\ttotal: 723ms\tremaining: 3.53s\n",
      "17:\tlearn: 0.6254437\ttotal: 767ms\tremaining: 3.49s\n",
      "18:\tlearn: 0.6224302\ttotal: 791ms\tremaining: 3.37s\n",
      "19:\tlearn: 0.6184681\ttotal: 865ms\tremaining: 3.46s\n",
      "20:\tlearn: 0.6153850\ttotal: 917ms\tremaining: 3.45s\n",
      "21:\tlearn: 0.6120405\ttotal: 949ms\tremaining: 3.36s\n",
      "22:\tlearn: 0.6089748\ttotal: 971ms\tremaining: 3.25s\n",
      "23:\tlearn: 0.6059780\ttotal: 1.02s\tremaining: 3.24s\n",
      "24:\tlearn: 0.6028254\ttotal: 1.09s\tremaining: 3.26s\n",
      "25:\tlearn: 0.5993327\ttotal: 1.12s\tremaining: 3.19s\n",
      "26:\tlearn: 0.5953370\ttotal: 1.15s\tremaining: 3.1s\n",
      "27:\tlearn: 0.5919137\ttotal: 1.21s\tremaining: 3.11s\n",
      "28:\tlearn: 0.5897295\ttotal: 1.26s\tremaining: 3.1s\n",
      "29:\tlearn: 0.5869223\ttotal: 1.29s\tremaining: 3.02s\n",
      "30:\tlearn: 0.5837966\ttotal: 1.32s\tremaining: 2.93s\n",
      "31:\tlearn: 0.5808654\ttotal: 1.34s\tremaining: 2.85s\n",
      "32:\tlearn: 0.5776955\ttotal: 1.42s\tremaining: 2.88s\n",
      "33:\tlearn: 0.5749061\ttotal: 1.46s\tremaining: 2.83s\n",
      "34:\tlearn: 0.5724275\ttotal: 1.48s\tremaining: 2.75s\n",
      "35:\tlearn: 0.5701031\ttotal: 1.5s\tremaining: 2.68s\n",
      "36:\tlearn: 0.5675872\ttotal: 1.59s\tremaining: 2.71s\n",
      "37:\tlearn: 0.5645238\ttotal: 1.62s\tremaining: 2.64s\n",
      "38:\tlearn: 0.5622825\ttotal: 1.64s\tremaining: 2.57s\n",
      "39:\tlearn: 0.5600549\ttotal: 1.67s\tremaining: 2.5s\n",
      "40:\tlearn: 0.5569206\ttotal: 1.74s\tremaining: 2.51s\n",
      "41:\tlearn: 0.5538234\ttotal: 1.79s\tremaining: 2.47s\n",
      "42:\tlearn: 0.5516601\ttotal: 1.82s\tremaining: 2.41s\n",
      "43:\tlearn: 0.5485413\ttotal: 1.84s\tremaining: 2.34s\n",
      "44:\tlearn: 0.5456447\ttotal: 1.92s\tremaining: 2.35s\n",
      "45:\tlearn: 0.5433586\ttotal: 1.97s\tremaining: 2.31s\n",
      "46:\tlearn: 0.5402725\ttotal: 2s\tremaining: 2.25s\n",
      "47:\tlearn: 0.5379724\ttotal: 2.02s\tremaining: 2.19s\n",
      "48:\tlearn: 0.5362164\ttotal: 2.09s\tremaining: 2.18s\n",
      "49:\tlearn: 0.5339507\ttotal: 2.14s\tremaining: 2.14s\n",
      "50:\tlearn: 0.5312856\ttotal: 2.17s\tremaining: 2.08s\n",
      "51:\tlearn: 0.5288280\ttotal: 2.19s\tremaining: 2.02s\n",
      "52:\tlearn: 0.5258660\ttotal: 2.25s\tremaining: 2s\n",
      "53:\tlearn: 0.5230281\ttotal: 2.31s\tremaining: 1.97s\n",
      "54:\tlearn: 0.5205519\ttotal: 2.34s\tremaining: 1.92s\n",
      "55:\tlearn: 0.5181735\ttotal: 2.37s\tremaining: 1.86s\n",
      "56:\tlearn: 0.5160401\ttotal: 2.39s\tremaining: 1.8s\n",
      "57:\tlearn: 0.5140105\ttotal: 2.46s\tremaining: 1.78s\n",
      "58:\tlearn: 0.5117764\ttotal: 2.5s\tremaining: 1.74s\n",
      "59:\tlearn: 0.5095440\ttotal: 2.53s\tremaining: 1.69s\n",
      "60:\tlearn: 0.5074076\ttotal: 2.55s\tremaining: 1.63s\n",
      "61:\tlearn: 0.5048625\ttotal: 2.6s\tremaining: 1.59s\n",
      "62:\tlearn: 0.5026631\ttotal: 2.66s\tremaining: 1.56s\n",
      "63:\tlearn: 0.5006979\ttotal: 2.69s\tremaining: 1.51s\n",
      "64:\tlearn: 0.4988175\ttotal: 2.72s\tremaining: 1.46s\n",
      "65:\tlearn: 0.4968535\ttotal: 2.77s\tremaining: 1.42s\n",
      "66:\tlearn: 0.4947447\ttotal: 2.83s\tremaining: 1.4s\n",
      "67:\tlearn: 0.4930283\ttotal: 2.87s\tremaining: 1.35s\n",
      "68:\tlearn: 0.4907715\ttotal: 2.89s\tremaining: 1.3s\n",
      "69:\tlearn: 0.4891404\ttotal: 2.91s\tremaining: 1.25s\n",
      "70:\tlearn: 0.4869001\ttotal: 2.99s\tremaining: 1.22s\n",
      "71:\tlearn: 0.4854513\ttotal: 3.04s\tremaining: 1.18s\n",
      "72:\tlearn: 0.4839646\ttotal: 3.06s\tremaining: 1.13s\n",
      "73:\tlearn: 0.4821795\ttotal: 3.09s\tremaining: 1.08s\n",
      "74:\tlearn: 0.4802476\ttotal: 3.11s\tremaining: 1.04s\n",
      "75:\tlearn: 0.4780266\ttotal: 3.14s\tremaining: 992ms\n",
      "76:\tlearn: 0.4757826\ttotal: 3.21s\tremaining: 960ms\n",
      "77:\tlearn: 0.4736300\ttotal: 3.25s\tremaining: 918ms\n",
      "78:\tlearn: 0.4710972\ttotal: 3.28s\tremaining: 872ms\n",
      "79:\tlearn: 0.4689371\ttotal: 3.3s\tremaining: 826ms\n",
      "80:\tlearn: 0.4668968\ttotal: 3.38s\tremaining: 794ms\n",
      "81:\tlearn: 0.4643312\ttotal: 3.43s\tremaining: 752ms\n",
      "82:\tlearn: 0.4620746\ttotal: 3.45s\tremaining: 707ms\n",
      "83:\tlearn: 0.4596384\ttotal: 3.48s\tremaining: 662ms\n",
      "84:\tlearn: 0.4572194\ttotal: 3.56s\tremaining: 628ms\n",
      "85:\tlearn: 0.4552490\ttotal: 3.61s\tremaining: 587ms\n",
      "86:\tlearn: 0.4533152\ttotal: 3.63s\tremaining: 543ms\n",
      "87:\tlearn: 0.4508537\ttotal: 3.66s\tremaining: 499ms\n",
      "88:\tlearn: 0.4493167\ttotal: 3.74s\tremaining: 462ms\n",
      "89:\tlearn: 0.4471499\ttotal: 3.78s\tremaining: 420ms\n",
      "90:\tlearn: 0.4451384\ttotal: 3.81s\tremaining: 376ms\n",
      "91:\tlearn: 0.4434331\ttotal: 3.83s\tremaining: 333ms\n",
      "92:\tlearn: 0.4418936\ttotal: 3.89s\tremaining: 293ms\n",
      "93:\tlearn: 0.4400352\ttotal: 3.94s\tremaining: 251ms\n",
      "94:\tlearn: 0.4381680\ttotal: 3.96s\tremaining: 208ms\n",
      "95:\tlearn: 0.4361023\ttotal: 3.98s\tremaining: 166ms\n",
      "96:\tlearn: 0.4338749\ttotal: 4.06s\tremaining: 126ms\n",
      "97:\tlearn: 0.4316667\ttotal: 4.11s\tremaining: 83.8ms\n",
      "98:\tlearn: 0.4302576\ttotal: 4.13s\tremaining: 41.7ms\n",
      "99:\tlearn: 0.4286468\ttotal: 4.15s\tremaining: 0us\n",
      "0:\tlearn: 0.6885608\ttotal: 26.1ms\tremaining: 2.58s\n",
      "1:\tlearn: 0.6841200\ttotal: 101ms\tremaining: 4.93s\n",
      "2:\tlearn: 0.6805493\ttotal: 152ms\tremaining: 4.92s\n",
      "3:\tlearn: 0.6767451\ttotal: 182ms\tremaining: 4.36s\n",
      "4:\tlearn: 0.6738010\ttotal: 208ms\tremaining: 3.96s\n",
      "5:\tlearn: 0.6702620\ttotal: 290ms\tremaining: 4.54s\n",
      "6:\tlearn: 0.6668193\ttotal: 341ms\tremaining: 4.53s\n",
      "7:\tlearn: 0.6629883\ttotal: 369ms\tremaining: 4.25s\n",
      "8:\tlearn: 0.6596708\ttotal: 393ms\tremaining: 3.98s\n",
      "9:\tlearn: 0.6559987\ttotal: 474ms\tremaining: 4.27s\n",
      "10:\tlearn: 0.6527755\ttotal: 515ms\tremaining: 4.17s\n",
      "11:\tlearn: 0.6491620\ttotal: 540ms\tremaining: 3.96s\n",
      "12:\tlearn: 0.6454156\ttotal: 565ms\tremaining: 3.78s\n",
      "13:\tlearn: 0.6424615\ttotal: 644ms\tremaining: 3.96s\n",
      "14:\tlearn: 0.6388236\ttotal: 690ms\tremaining: 3.91s\n",
      "15:\tlearn: 0.6352227\ttotal: 730ms\tremaining: 3.83s\n",
      "16:\tlearn: 0.6318775\ttotal: 777ms\tremaining: 3.79s\n",
      "17:\tlearn: 0.6280146\ttotal: 843ms\tremaining: 3.84s\n",
      "18:\tlearn: 0.6243212\ttotal: 876ms\tremaining: 3.74s\n",
      "19:\tlearn: 0.6212334\ttotal: 902ms\tremaining: 3.61s\n",
      "20:\tlearn: 0.6178206\ttotal: 930ms\tremaining: 3.5s\n",
      "21:\tlearn: 0.6146915\ttotal: 1.01s\tremaining: 3.57s\n",
      "22:\tlearn: 0.6120934\ttotal: 1.04s\tremaining: 3.5s\n",
      "23:\tlearn: 0.6089885\ttotal: 1.07s\tremaining: 3.4s\n",
      "24:\tlearn: 0.6057620\ttotal: 1.1s\tremaining: 3.29s\n",
      "25:\tlearn: 0.6032604\ttotal: 1.17s\tremaining: 3.33s\n",
      "26:\tlearn: 0.5990610\ttotal: 1.22s\tremaining: 3.29s\n",
      "27:\tlearn: 0.5964878\ttotal: 1.25s\tremaining: 3.2s\n",
      "28:\tlearn: 0.5931145\ttotal: 1.27s\tremaining: 3.11s\n",
      "29:\tlearn: 0.5898933\ttotal: 1.32s\tremaining: 3.08s\n",
      "30:\tlearn: 0.5869746\ttotal: 1.39s\tremaining: 3.08s\n",
      "31:\tlearn: 0.5843790\ttotal: 1.42s\tremaining: 3.01s\n",
      "32:\tlearn: 0.5810593\ttotal: 1.44s\tremaining: 2.93s\n",
      "33:\tlearn: 0.5775430\ttotal: 1.49s\tremaining: 2.9s\n",
      "34:\tlearn: 0.5745912\ttotal: 1.56s\tremaining: 2.9s\n",
      "35:\tlearn: 0.5724749\ttotal: 1.6s\tremaining: 2.84s\n",
      "36:\tlearn: 0.5701721\ttotal: 1.62s\tremaining: 2.76s\n",
      "37:\tlearn: 0.5679258\ttotal: 1.67s\tremaining: 2.72s\n",
      "38:\tlearn: 0.5648373\ttotal: 1.74s\tremaining: 2.72s\n",
      "39:\tlearn: 0.5625745\ttotal: 1.77s\tremaining: 2.65s\n",
      "40:\tlearn: 0.5594646\ttotal: 1.79s\tremaining: 2.58s\n",
      "41:\tlearn: 0.5564696\ttotal: 1.81s\tremaining: 2.51s\n",
      "42:\tlearn: 0.5531976\ttotal: 1.89s\tremaining: 2.51s\n",
      "43:\tlearn: 0.5505278\ttotal: 1.94s\tremaining: 2.46s\n",
      "44:\tlearn: 0.5481667\ttotal: 1.96s\tremaining: 2.4s\n",
      "45:\tlearn: 0.5454638\ttotal: 1.99s\tremaining: 2.33s\n",
      "46:\tlearn: 0.5431002\ttotal: 2.06s\tremaining: 2.32s\n",
      "47:\tlearn: 0.5408974\ttotal: 2.11s\tremaining: 2.29s\n",
      "48:\tlearn: 0.5386248\ttotal: 2.14s\tremaining: 2.23s\n",
      "49:\tlearn: 0.5363456\ttotal: 2.17s\tremaining: 2.17s\n",
      "50:\tlearn: 0.5342024\ttotal: 2.19s\tremaining: 2.1s\n",
      "51:\tlearn: 0.5319003\ttotal: 2.27s\tremaining: 2.1s\n",
      "52:\tlearn: 0.5296091\ttotal: 2.31s\tremaining: 2.05s\n",
      "53:\tlearn: 0.5267748\ttotal: 2.34s\tremaining: 2s\n",
      "54:\tlearn: 0.5245794\ttotal: 2.37s\tremaining: 1.94s\n",
      "55:\tlearn: 0.5220170\ttotal: 2.4s\tremaining: 1.89s\n",
      "56:\tlearn: 0.5199745\ttotal: 2.48s\tremaining: 1.87s\n",
      "57:\tlearn: 0.5178028\ttotal: 2.51s\tremaining: 1.82s\n",
      "58:\tlearn: 0.5152117\ttotal: 2.54s\tremaining: 1.76s\n",
      "59:\tlearn: 0.5118795\ttotal: 2.6s\tremaining: 1.73s\n",
      "60:\tlearn: 0.5092850\ttotal: 2.66s\tremaining: 1.7s\n",
      "61:\tlearn: 0.5070117\ttotal: 2.69s\tremaining: 1.65s\n",
      "62:\tlearn: 0.5049830\ttotal: 2.72s\tremaining: 1.59s\n",
      "63:\tlearn: 0.5028031\ttotal: 2.78s\tremaining: 1.56s\n",
      "64:\tlearn: 0.5005341\ttotal: 2.84s\tremaining: 1.53s\n",
      "65:\tlearn: 0.4986551\ttotal: 2.87s\tremaining: 1.48s\n",
      "66:\tlearn: 0.4967314\ttotal: 2.89s\tremaining: 1.43s\n",
      "67:\tlearn: 0.4950581\ttotal: 2.96s\tremaining: 1.39s\n",
      "68:\tlearn: 0.4928057\ttotal: 3.01s\tremaining: 1.35s\n",
      "69:\tlearn: 0.4908316\ttotal: 3.04s\tremaining: 1.3s\n",
      "70:\tlearn: 0.4886256\ttotal: 3.07s\tremaining: 1.25s\n",
      "71:\tlearn: 0.4864327\ttotal: 3.12s\tremaining: 1.21s\n",
      "72:\tlearn: 0.4841018\ttotal: 3.19s\tremaining: 1.18s\n",
      "73:\tlearn: 0.4825261\ttotal: 3.22s\tremaining: 1.13s\n",
      "74:\tlearn: 0.4805426\ttotal: 3.24s\tremaining: 1.08s\n",
      "75:\tlearn: 0.4787504\ttotal: 3.26s\tremaining: 1.03s\n",
      "76:\tlearn: 0.4765745\ttotal: 3.35s\tremaining: 999ms\n",
      "77:\tlearn: 0.4748320\ttotal: 3.37s\tremaining: 952ms\n",
      "78:\tlearn: 0.4721507\ttotal: 3.4s\tremaining: 903ms\n",
      "79:\tlearn: 0.4698103\ttotal: 3.45s\tremaining: 862ms\n",
      "80:\tlearn: 0.4680525\ttotal: 3.52s\tremaining: 826ms\n",
      "81:\tlearn: 0.4667264\ttotal: 3.55s\tremaining: 780ms\n",
      "82:\tlearn: 0.4647961\ttotal: 3.58s\tremaining: 732ms\n",
      "83:\tlearn: 0.4634405\ttotal: 3.64s\tremaining: 693ms\n",
      "84:\tlearn: 0.4614843\ttotal: 3.69s\tremaining: 652ms\n",
      "85:\tlearn: 0.4591378\ttotal: 3.73s\tremaining: 607ms\n",
      "86:\tlearn: 0.4564322\ttotal: 3.75s\tremaining: 560ms\n",
      "87:\tlearn: 0.4541401\ttotal: 3.8s\tremaining: 518ms\n",
      "88:\tlearn: 0.4522299\ttotal: 3.87s\tremaining: 478ms\n",
      "89:\tlearn: 0.4508095\ttotal: 3.9s\tremaining: 433ms\n",
      "90:\tlearn: 0.4486488\ttotal: 3.92s\tremaining: 388ms\n",
      "91:\tlearn: 0.4464858\ttotal: 3.95s\tremaining: 344ms\n",
      "92:\tlearn: 0.4442126\ttotal: 4.03s\tremaining: 304ms\n",
      "93:\tlearn: 0.4424190\ttotal: 4.06s\tremaining: 259ms\n",
      "94:\tlearn: 0.4405479\ttotal: 4.09s\tremaining: 215ms\n",
      "95:\tlearn: 0.4391380\ttotal: 4.12s\tremaining: 172ms\n",
      "96:\tlearn: 0.4372156\ttotal: 4.2s\tremaining: 130ms\n",
      "97:\tlearn: 0.4357485\ttotal: 4.24s\tremaining: 86.6ms\n",
      "98:\tlearn: 0.4341912\ttotal: 4.27s\tremaining: 43.1ms\n",
      "99:\tlearn: 0.4324652\ttotal: 4.29s\tremaining: 0us\n",
      "0:\tlearn: 0.6892596\ttotal: 39.3ms\tremaining: 3.89s\n",
      "1:\tlearn: 0.6851154\ttotal: 65.2ms\tremaining: 3.19s\n",
      "2:\tlearn: 0.6804812\ttotal: 88.6ms\tremaining: 2.86s\n",
      "3:\tlearn: 0.6769337\ttotal: 168ms\tremaining: 4.03s\n",
      "4:\tlearn: 0.6734362\ttotal: 206ms\tremaining: 3.91s\n",
      "5:\tlearn: 0.6696512\ttotal: 230ms\tremaining: 3.6s\n",
      "6:\tlearn: 0.6665006\ttotal: 310ms\tremaining: 4.12s\n",
      "7:\tlearn: 0.6621612\ttotal: 352ms\tremaining: 4.04s\n",
      "8:\tlearn: 0.6584935\ttotal: 377ms\tremaining: 3.81s\n",
      "9:\tlearn: 0.6549732\ttotal: 399ms\tremaining: 3.59s\n",
      "10:\tlearn: 0.6517196\ttotal: 475ms\tremaining: 3.84s\n",
      "11:\tlearn: 0.6481843\ttotal: 504ms\tremaining: 3.69s\n",
      "12:\tlearn: 0.6448786\ttotal: 527ms\tremaining: 3.52s\n",
      "13:\tlearn: 0.6415722\ttotal: 590ms\tremaining: 3.63s\n",
      "14:\tlearn: 0.6375930\ttotal: 651ms\tremaining: 3.69s\n",
      "15:\tlearn: 0.6343131\ttotal: 681ms\tremaining: 3.57s\n",
      "16:\tlearn: 0.6308415\ttotal: 703ms\tremaining: 3.43s\n",
      "17:\tlearn: 0.6272499\ttotal: 780ms\tremaining: 3.55s\n",
      "18:\tlearn: 0.6240359\ttotal: 832ms\tremaining: 3.55s\n",
      "19:\tlearn: 0.6206419\ttotal: 859ms\tremaining: 3.44s\n",
      "20:\tlearn: 0.6175506\ttotal: 882ms\tremaining: 3.32s\n",
      "21:\tlearn: 0.6146056\ttotal: 945ms\tremaining: 3.35s\n",
      "22:\tlearn: 0.6113696\ttotal: 999ms\tremaining: 3.35s\n",
      "23:\tlearn: 0.6079906\ttotal: 1.03s\tremaining: 3.26s\n",
      "24:\tlearn: 0.6043934\ttotal: 1.05s\tremaining: 3.16s\n",
      "25:\tlearn: 0.6015684\ttotal: 1.08s\tremaining: 3.07s\n",
      "26:\tlearn: 0.5984543\ttotal: 1.16s\tremaining: 3.13s\n",
      "27:\tlearn: 0.5950231\ttotal: 1.19s\tremaining: 3.07s\n",
      "28:\tlearn: 0.5919065\ttotal: 1.22s\tremaining: 2.98s\n",
      "29:\tlearn: 0.5892495\ttotal: 1.24s\tremaining: 2.9s\n",
      "30:\tlearn: 0.5866163\ttotal: 1.32s\tremaining: 2.95s\n",
      "31:\tlearn: 0.5842663\ttotal: 1.37s\tremaining: 2.9s\n",
      "32:\tlearn: 0.5816582\ttotal: 1.39s\tremaining: 2.83s\n",
      "33:\tlearn: 0.5785947\ttotal: 1.42s\tremaining: 2.75s\n",
      "34:\tlearn: 0.5759527\ttotal: 1.48s\tremaining: 2.74s\n",
      "35:\tlearn: 0.5733612\ttotal: 1.53s\tremaining: 2.73s\n",
      "36:\tlearn: 0.5714153\ttotal: 1.56s\tremaining: 2.66s\n",
      "37:\tlearn: 0.5688769\ttotal: 1.58s\tremaining: 2.59s\n",
      "38:\tlearn: 0.5664551\ttotal: 1.63s\tremaining: 2.55s\n",
      "39:\tlearn: 0.5639544\ttotal: 1.7s\tremaining: 2.55s\n",
      "40:\tlearn: 0.5609141\ttotal: 1.74s\tremaining: 2.5s\n",
      "41:\tlearn: 0.5591065\ttotal: 1.76s\tremaining: 2.43s\n",
      "42:\tlearn: 0.5570276\ttotal: 1.8s\tremaining: 2.39s\n",
      "43:\tlearn: 0.5537200\ttotal: 1.87s\tremaining: 2.38s\n",
      "44:\tlearn: 0.5514030\ttotal: 1.91s\tremaining: 2.33s\n",
      "45:\tlearn: 0.5491790\ttotal: 1.93s\tremaining: 2.27s\n",
      "46:\tlearn: 0.5464641\ttotal: 1.99s\tremaining: 2.24s\n",
      "47:\tlearn: 0.5431590\ttotal: 2.06s\tremaining: 2.23s\n",
      "48:\tlearn: 0.5411249\ttotal: 2.09s\tremaining: 2.17s\n",
      "49:\tlearn: 0.5390211\ttotal: 2.11s\tremaining: 2.11s\n",
      "50:\tlearn: 0.5363740\ttotal: 2.14s\tremaining: 2.05s\n",
      "51:\tlearn: 0.5343316\ttotal: 2.22s\tremaining: 2.05s\n",
      "52:\tlearn: 0.5319178\ttotal: 2.25s\tremaining: 1.99s\n",
      "53:\tlearn: 0.5294506\ttotal: 2.27s\tremaining: 1.94s\n",
      "54:\tlearn: 0.5270105\ttotal: 2.35s\tremaining: 1.92s\n",
      "55:\tlearn: 0.5242863\ttotal: 2.4s\tremaining: 1.89s\n",
      "56:\tlearn: 0.5218157\ttotal: 2.43s\tremaining: 1.83s\n",
      "57:\tlearn: 0.5193341\ttotal: 2.46s\tremaining: 1.78s\n",
      "58:\tlearn: 0.5169880\ttotal: 2.54s\tremaining: 1.76s\n",
      "59:\tlearn: 0.5148956\ttotal: 2.58s\tremaining: 1.72s\n",
      "60:\tlearn: 0.5124486\ttotal: 2.61s\tremaining: 1.67s\n",
      "61:\tlearn: 0.5106274\ttotal: 2.63s\tremaining: 1.61s\n",
      "62:\tlearn: 0.5082648\ttotal: 2.71s\tremaining: 1.59s\n",
      "63:\tlearn: 0.5054614\ttotal: 2.75s\tremaining: 1.55s\n",
      "64:\tlearn: 0.5029318\ttotal: 2.78s\tremaining: 1.5s\n",
      "65:\tlearn: 0.5008369\ttotal: 2.81s\tremaining: 1.45s\n",
      "66:\tlearn: 0.4983918\ttotal: 2.89s\tremaining: 1.42s\n",
      "67:\tlearn: 0.4971815\ttotal: 2.93s\tremaining: 1.38s\n",
      "68:\tlearn: 0.4950435\ttotal: 2.96s\tremaining: 1.33s\n",
      "69:\tlearn: 0.4931928\ttotal: 2.98s\tremaining: 1.28s\n",
      "70:\tlearn: 0.4912237\ttotal: 3.05s\tremaining: 1.24s\n",
      "71:\tlearn: 0.4896946\ttotal: 3.11s\tremaining: 1.21s\n",
      "72:\tlearn: 0.4881438\ttotal: 3.13s\tremaining: 1.16s\n",
      "73:\tlearn: 0.4865558\ttotal: 3.16s\tremaining: 1.11s\n",
      "74:\tlearn: 0.4842390\ttotal: 3.21s\tremaining: 1.07s\n",
      "75:\tlearn: 0.4817969\ttotal: 3.28s\tremaining: 1.03s\n",
      "76:\tlearn: 0.4797701\ttotal: 3.31s\tremaining: 988ms\n",
      "77:\tlearn: 0.4773142\ttotal: 3.33s\tremaining: 939ms\n",
      "78:\tlearn: 0.4746340\ttotal: 3.38s\tremaining: 898ms\n",
      "79:\tlearn: 0.4725705\ttotal: 3.44s\tremaining: 861ms\n",
      "80:\tlearn: 0.4703611\ttotal: 3.47s\tremaining: 814ms\n",
      "81:\tlearn: 0.4678161\ttotal: 3.49s\tremaining: 767ms\n",
      "82:\tlearn: 0.4661021\ttotal: 3.56s\tremaining: 729ms\n",
      "83:\tlearn: 0.4640433\ttotal: 3.61s\tremaining: 688ms\n",
      "84:\tlearn: 0.4612675\ttotal: 3.64s\tremaining: 642ms\n",
      "85:\tlearn: 0.4588937\ttotal: 3.66s\tremaining: 596ms\n",
      "86:\tlearn: 0.4570036\ttotal: 3.68s\tremaining: 550ms\n",
      "87:\tlearn: 0.4550582\ttotal: 3.76s\tremaining: 513ms\n",
      "88:\tlearn: 0.4532717\ttotal: 3.79s\tremaining: 469ms\n",
      "89:\tlearn: 0.4505485\ttotal: 3.82s\tremaining: 424ms\n",
      "90:\tlearn: 0.4488601\ttotal: 3.84s\tremaining: 380ms\n",
      "91:\tlearn: 0.4471877\ttotal: 3.92s\tremaining: 341ms\n",
      "92:\tlearn: 0.4452934\ttotal: 3.96s\tremaining: 298ms\n",
      "93:\tlearn: 0.4435056\ttotal: 3.98s\tremaining: 254ms\n",
      "94:\tlearn: 0.4420103\ttotal: 4s\tremaining: 211ms\n",
      "95:\tlearn: 0.4405760\ttotal: 4.08s\tremaining: 170ms\n",
      "96:\tlearn: 0.4380913\ttotal: 4.13s\tremaining: 128ms\n",
      "97:\tlearn: 0.4361545\ttotal: 4.16s\tremaining: 84.8ms\n",
      "98:\tlearn: 0.4348082\ttotal: 4.18s\tremaining: 42.2ms\n",
      "99:\tlearn: 0.4333349\ttotal: 4.26s\tremaining: 0us\n",
      "0:\tlearn: 0.6888653\ttotal: 25.8ms\tremaining: 2.56s\n",
      "1:\tlearn: 0.6841732\ttotal: 53.4ms\tremaining: 2.62s\n",
      "2:\tlearn: 0.6803015\ttotal: 137ms\tremaining: 4.43s\n",
      "3:\tlearn: 0.6771083\ttotal: 166ms\tremaining: 3.99s\n",
      "4:\tlearn: 0.6735027\ttotal: 192ms\tremaining: 3.65s\n",
      "5:\tlearn: 0.6684052\ttotal: 232ms\tremaining: 3.64s\n",
      "6:\tlearn: 0.6642342\ttotal: 299ms\tremaining: 3.97s\n",
      "7:\tlearn: 0.6601538\ttotal: 330ms\tremaining: 3.79s\n",
      "8:\tlearn: 0.6571324\ttotal: 354ms\tremaining: 3.58s\n",
      "9:\tlearn: 0.6540067\ttotal: 381ms\tremaining: 3.43s\n",
      "10:\tlearn: 0.6505197\ttotal: 461ms\tremaining: 3.73s\n",
      "11:\tlearn: 0.6465880\ttotal: 490ms\tremaining: 3.59s\n",
      "12:\tlearn: 0.6430133\ttotal: 514ms\tremaining: 3.44s\n",
      "13:\tlearn: 0.6402020\ttotal: 575ms\tremaining: 3.53s\n",
      "14:\tlearn: 0.6370513\ttotal: 635ms\tremaining: 3.6s\n",
      "15:\tlearn: 0.6336235\ttotal: 667ms\tremaining: 3.5s\n",
      "16:\tlearn: 0.6300322\ttotal: 689ms\tremaining: 3.36s\n",
      "17:\tlearn: 0.6270962\ttotal: 739ms\tremaining: 3.37s\n",
      "18:\tlearn: 0.6242186\ttotal: 805ms\tremaining: 3.43s\n",
      "19:\tlearn: 0.6210675\ttotal: 841ms\tremaining: 3.36s\n",
      "20:\tlearn: 0.6175246\ttotal: 868ms\tremaining: 3.26s\n",
      "21:\tlearn: 0.6145508\ttotal: 951ms\tremaining: 3.37s\n",
      "22:\tlearn: 0.6118519\ttotal: 998ms\tremaining: 3.34s\n",
      "23:\tlearn: 0.6083843\ttotal: 1.03s\tremaining: 3.25s\n",
      "24:\tlearn: 0.6059304\ttotal: 1.05s\tremaining: 3.15s\n",
      "25:\tlearn: 0.6026176\ttotal: 1.1s\tremaining: 3.13s\n",
      "26:\tlearn: 0.5991022\ttotal: 1.16s\tremaining: 3.14s\n",
      "27:\tlearn: 0.5963282\ttotal: 1.19s\tremaining: 3.06s\n",
      "28:\tlearn: 0.5930859\ttotal: 1.22s\tremaining: 2.97s\n",
      "29:\tlearn: 0.5901123\ttotal: 1.24s\tremaining: 2.89s\n",
      "30:\tlearn: 0.5869105\ttotal: 1.3s\tremaining: 2.89s\n",
      "31:\tlearn: 0.5843365\ttotal: 1.35s\tremaining: 2.87s\n",
      "32:\tlearn: 0.5817305\ttotal: 1.39s\tremaining: 2.82s\n",
      "33:\tlearn: 0.5791108\ttotal: 1.41s\tremaining: 2.74s\n",
      "34:\tlearn: 0.5767247\ttotal: 1.49s\tremaining: 2.77s\n",
      "35:\tlearn: 0.5742702\ttotal: 1.54s\tremaining: 2.73s\n",
      "36:\tlearn: 0.5717009\ttotal: 1.56s\tremaining: 2.66s\n",
      "37:\tlearn: 0.5692918\ttotal: 1.58s\tremaining: 2.59s\n",
      "38:\tlearn: 0.5668699\ttotal: 1.66s\tremaining: 2.6s\n",
      "39:\tlearn: 0.5646593\ttotal: 1.71s\tremaining: 2.57s\n",
      "40:\tlearn: 0.5617347\ttotal: 1.74s\tremaining: 2.5s\n",
      "41:\tlearn: 0.5592245\ttotal: 1.76s\tremaining: 2.44s\n",
      "42:\tlearn: 0.5567499\ttotal: 1.84s\tremaining: 2.44s\n",
      "43:\tlearn: 0.5540146\ttotal: 1.88s\tremaining: 2.4s\n",
      "44:\tlearn: 0.5515205\ttotal: 1.91s\tremaining: 2.34s\n",
      "45:\tlearn: 0.5493342\ttotal: 1.94s\tremaining: 2.27s\n",
      "46:\tlearn: 0.5463677\ttotal: 2s\tremaining: 2.25s\n",
      "47:\tlearn: 0.5439280\ttotal: 2.06s\tremaining: 2.23s\n",
      "48:\tlearn: 0.5416743\ttotal: 2.09s\tremaining: 2.17s\n",
      "49:\tlearn: 0.5389602\ttotal: 2.11s\tremaining: 2.11s\n",
      "50:\tlearn: 0.5366307\ttotal: 2.13s\tremaining: 2.05s\n",
      "51:\tlearn: 0.5343570\ttotal: 2.22s\tremaining: 2.05s\n",
      "52:\tlearn: 0.5320709\ttotal: 2.25s\tremaining: 2s\n",
      "53:\tlearn: 0.5291013\ttotal: 2.28s\tremaining: 1.94s\n",
      "54:\tlearn: 0.5270698\ttotal: 2.3s\tremaining: 1.88s\n",
      "55:\tlearn: 0.5243289\ttotal: 2.38s\tremaining: 1.87s\n",
      "56:\tlearn: 0.5214432\ttotal: 2.42s\tremaining: 1.83s\n",
      "57:\tlearn: 0.5194202\ttotal: 2.45s\tremaining: 1.78s\n",
      "58:\tlearn: 0.5174570\ttotal: 2.48s\tremaining: 1.72s\n",
      "59:\tlearn: 0.5149145\ttotal: 2.55s\tremaining: 1.7s\n",
      "60:\tlearn: 0.5127041\ttotal: 2.58s\tremaining: 1.65s\n",
      "61:\tlearn: 0.5103438\ttotal: 2.6s\tremaining: 1.6s\n",
      "62:\tlearn: 0.5084255\ttotal: 2.63s\tremaining: 1.54s\n",
      "63:\tlearn: 0.5060435\ttotal: 2.71s\tremaining: 1.52s\n",
      "64:\tlearn: 0.5037536\ttotal: 2.75s\tremaining: 1.48s\n",
      "65:\tlearn: 0.5019216\ttotal: 2.78s\tremaining: 1.43s\n",
      "66:\tlearn: 0.4997312\ttotal: 2.8s\tremaining: 1.38s\n",
      "67:\tlearn: 0.4981562\ttotal: 2.88s\tremaining: 1.35s\n",
      "68:\tlearn: 0.4962751\ttotal: 2.93s\tremaining: 1.32s\n",
      "69:\tlearn: 0.4935660\ttotal: 2.96s\tremaining: 1.27s\n",
      "70:\tlearn: 0.4913992\ttotal: 2.99s\tremaining: 1.22s\n",
      "71:\tlearn: 0.4892336\ttotal: 3.04s\tremaining: 1.18s\n",
      "72:\tlearn: 0.4877842\ttotal: 3.1s\tremaining: 1.15s\n",
      "73:\tlearn: 0.4852667\ttotal: 3.13s\tremaining: 1.1s\n",
      "74:\tlearn: 0.4831683\ttotal: 3.15s\tremaining: 1.05s\n",
      "75:\tlearn: 0.4810714\ttotal: 3.21s\tremaining: 1.01s\n",
      "76:\tlearn: 0.4790509\ttotal: 3.27s\tremaining: 978ms\n",
      "77:\tlearn: 0.4769362\ttotal: 3.31s\tremaining: 932ms\n",
      "78:\tlearn: 0.4750242\ttotal: 3.33s\tremaining: 885ms\n",
      "79:\tlearn: 0.4728756\ttotal: 3.39s\tremaining: 848ms\n",
      "80:\tlearn: 0.4711034\ttotal: 3.45s\tremaining: 810ms\n",
      "81:\tlearn: 0.4694194\ttotal: 3.48s\tremaining: 764ms\n",
      "82:\tlearn: 0.4679346\ttotal: 3.5s\tremaining: 718ms\n",
      "83:\tlearn: 0.4657765\ttotal: 3.55s\tremaining: 677ms\n",
      "84:\tlearn: 0.4640086\ttotal: 3.63s\tremaining: 641ms\n",
      "85:\tlearn: 0.4622752\ttotal: 3.66s\tremaining: 595ms\n",
      "86:\tlearn: 0.4606367\ttotal: 3.68s\tremaining: 550ms\n",
      "87:\tlearn: 0.4584174\ttotal: 3.7s\tremaining: 505ms\n",
      "88:\tlearn: 0.4566658\ttotal: 3.78s\tremaining: 468ms\n",
      "89:\tlearn: 0.4536926\ttotal: 3.81s\tremaining: 424ms\n",
      "90:\tlearn: 0.4512560\ttotal: 3.84s\tremaining: 380ms\n",
      "91:\tlearn: 0.4486966\ttotal: 3.86s\tremaining: 336ms\n",
      "92:\tlearn: 0.4463252\ttotal: 3.94s\tremaining: 297ms\n",
      "93:\tlearn: 0.4443204\ttotal: 3.99s\tremaining: 255ms\n",
      "94:\tlearn: 0.4427341\ttotal: 4.02s\tremaining: 212ms\n",
      "95:\tlearn: 0.4412798\ttotal: 4.04s\tremaining: 168ms\n",
      "96:\tlearn: 0.4395197\ttotal: 4.12s\tremaining: 127ms\n",
      "97:\tlearn: 0.4380269\ttotal: 4.17s\tremaining: 85.1ms\n",
      "98:\tlearn: 0.4366213\ttotal: 4.2s\tremaining: 42.4ms\n",
      "99:\tlearn: 0.4348962\ttotal: 4.22s\tremaining: 0us\n",
      "0:\tlearn: 0.6897797\ttotal: 37.8ms\tremaining: 3.75s\n",
      "1:\tlearn: 0.6856483\ttotal: 61.2ms\tremaining: 3s\n",
      "2:\tlearn: 0.6809385\ttotal: 112ms\tremaining: 3.62s\n",
      "3:\tlearn: 0.6778443\ttotal: 181ms\tremaining: 4.35s\n",
      "4:\tlearn: 0.6736521\ttotal: 216ms\tremaining: 4.11s\n",
      "5:\tlearn: 0.6702420\ttotal: 240ms\tremaining: 3.76s\n",
      "6:\tlearn: 0.6666290\ttotal: 305ms\tremaining: 4.05s\n",
      "7:\tlearn: 0.6625392\ttotal: 370ms\tremaining: 4.26s\n",
      "8:\tlearn: 0.6589189\ttotal: 407ms\tremaining: 4.11s\n",
      "9:\tlearn: 0.6555555\ttotal: 432ms\tremaining: 3.89s\n",
      "10:\tlearn: 0.6515846\ttotal: 514ms\tremaining: 4.16s\n",
      "11:\tlearn: 0.6479499\ttotal: 558ms\tremaining: 4.09s\n",
      "12:\tlearn: 0.6447972\ttotal: 585ms\tremaining: 3.92s\n",
      "13:\tlearn: 0.6411885\ttotal: 608ms\tremaining: 3.73s\n",
      "14:\tlearn: 0.6379042\ttotal: 673ms\tremaining: 3.81s\n",
      "15:\tlearn: 0.6340169\ttotal: 727ms\tremaining: 3.82s\n",
      "16:\tlearn: 0.6305800\ttotal: 755ms\tremaining: 3.69s\n",
      "17:\tlearn: 0.6268373\ttotal: 778ms\tremaining: 3.54s\n",
      "18:\tlearn: 0.6236779\ttotal: 860ms\tremaining: 3.67s\n",
      "19:\tlearn: 0.6201513\ttotal: 904ms\tremaining: 3.62s\n",
      "20:\tlearn: 0.6166538\ttotal: 930ms\tremaining: 3.5s\n",
      "21:\tlearn: 0.6131341\ttotal: 953ms\tremaining: 3.38s\n",
      "22:\tlearn: 0.6101580\ttotal: 1.02s\tremaining: 3.43s\n",
      "23:\tlearn: 0.6069443\ttotal: 1.08s\tremaining: 3.42s\n",
      "24:\tlearn: 0.6030062\ttotal: 1.11s\tremaining: 3.33s\n",
      "25:\tlearn: 0.6005984\ttotal: 1.13s\tremaining: 3.22s\n",
      "26:\tlearn: 0.5967923\ttotal: 1.18s\tremaining: 3.19s\n",
      "27:\tlearn: 0.5941411\ttotal: 1.24s\tremaining: 3.19s\n",
      "28:\tlearn: 0.5909275\ttotal: 1.27s\tremaining: 3.12s\n",
      "29:\tlearn: 0.5873801\ttotal: 1.3s\tremaining: 3.04s\n",
      "30:\tlearn: 0.5845936\ttotal: 1.35s\tremaining: 3.02s\n",
      "31:\tlearn: 0.5823767\ttotal: 1.41s\tremaining: 3.01s\n",
      "32:\tlearn: 0.5795945\ttotal: 1.44s\tremaining: 2.93s\n",
      "33:\tlearn: 0.5767840\ttotal: 1.49s\tremaining: 2.89s\n",
      "34:\tlearn: 0.5747087\ttotal: 1.56s\tremaining: 2.9s\n",
      "35:\tlearn: 0.5716039\ttotal: 1.59s\tremaining: 2.82s\n",
      "36:\tlearn: 0.5691745\ttotal: 1.61s\tremaining: 2.74s\n",
      "37:\tlearn: 0.5669148\ttotal: 1.68s\tremaining: 2.73s\n",
      "38:\tlearn: 0.5646794\ttotal: 1.73s\tremaining: 2.71s\n",
      "39:\tlearn: 0.5615053\ttotal: 1.76s\tremaining: 2.64s\n",
      "40:\tlearn: 0.5587207\ttotal: 1.78s\tremaining: 2.57s\n",
      "41:\tlearn: 0.5564778\ttotal: 1.85s\tremaining: 2.56s\n",
      "42:\tlearn: 0.5540215\ttotal: 1.91s\tremaining: 2.53s\n",
      "43:\tlearn: 0.5513785\ttotal: 1.94s\tremaining: 2.46s\n",
      "44:\tlearn: 0.5489041\ttotal: 1.96s\tremaining: 2.4s\n",
      "45:\tlearn: 0.5461031\ttotal: 2.05s\tremaining: 2.4s\n",
      "46:\tlearn: 0.5433688\ttotal: 2.09s\tremaining: 2.36s\n",
      "47:\tlearn: 0.5404458\ttotal: 2.12s\tremaining: 2.3s\n",
      "48:\tlearn: 0.5383723\ttotal: 2.14s\tremaining: 2.23s\n",
      "49:\tlearn: 0.5359917\ttotal: 2.21s\tremaining: 2.21s\n",
      "50:\tlearn: 0.5335342\ttotal: 2.26s\tremaining: 2.17s\n",
      "51:\tlearn: 0.5316251\ttotal: 2.29s\tremaining: 2.11s\n",
      "52:\tlearn: 0.5294951\ttotal: 2.31s\tremaining: 2.05s\n",
      "53:\tlearn: 0.5264626\ttotal: 2.36s\tremaining: 2.01s\n",
      "54:\tlearn: 0.5241092\ttotal: 2.43s\tremaining: 1.98s\n",
      "55:\tlearn: 0.5214026\ttotal: 2.46s\tremaining: 1.93s\n",
      "56:\tlearn: 0.5192830\ttotal: 2.48s\tremaining: 1.87s\n",
      "57:\tlearn: 0.5170774\ttotal: 2.52s\tremaining: 1.82s\n",
      "58:\tlearn: 0.5141540\ttotal: 2.59s\tremaining: 1.8s\n",
      "59:\tlearn: 0.5111907\ttotal: 2.63s\tremaining: 1.75s\n",
      "60:\tlearn: 0.5087576\ttotal: 2.66s\tremaining: 1.7s\n",
      "61:\tlearn: 0.5070891\ttotal: 2.68s\tremaining: 1.64s\n",
      "62:\tlearn: 0.5050833\ttotal: 2.76s\tremaining: 1.62s\n",
      "63:\tlearn: 0.5028092\ttotal: 2.8s\tremaining: 1.57s\n",
      "64:\tlearn: 0.5008725\ttotal: 2.83s\tremaining: 1.52s\n",
      "65:\tlearn: 0.4988787\ttotal: 2.86s\tremaining: 1.47s\n",
      "66:\tlearn: 0.4963435\ttotal: 2.88s\tremaining: 1.42s\n",
      "67:\tlearn: 0.4948318\ttotal: 2.91s\tremaining: 1.37s\n",
      "68:\tlearn: 0.4929044\ttotal: 2.98s\tremaining: 1.34s\n",
      "69:\tlearn: 0.4911299\ttotal: 3.02s\tremaining: 1.29s\n",
      "70:\tlearn: 0.4893870\ttotal: 3.05s\tremaining: 1.24s\n",
      "71:\tlearn: 0.4872443\ttotal: 3.08s\tremaining: 1.2s\n",
      "72:\tlearn: 0.4855217\ttotal: 3.16s\tremaining: 1.17s\n",
      "73:\tlearn: 0.4835304\ttotal: 3.19s\tremaining: 1.12s\n",
      "74:\tlearn: 0.4811923\ttotal: 3.22s\tremaining: 1.07s\n",
      "75:\tlearn: 0.4792326\ttotal: 3.25s\tremaining: 1.02s\n",
      "76:\tlearn: 0.4771563\ttotal: 3.29s\tremaining: 983ms\n",
      "77:\tlearn: 0.4754647\ttotal: 3.35s\tremaining: 946ms\n",
      "78:\tlearn: 0.4731719\ttotal: 3.39s\tremaining: 901ms\n",
      "79:\tlearn: 0.4709785\ttotal: 3.41s\tremaining: 852ms\n",
      "80:\tlearn: 0.4689558\ttotal: 3.44s\tremaining: 807ms\n",
      "81:\tlearn: 0.4671469\ttotal: 3.52s\tremaining: 772ms\n",
      "82:\tlearn: 0.4644575\ttotal: 3.54s\tremaining: 726ms\n",
      "83:\tlearn: 0.4618205\ttotal: 3.57s\tremaining: 680ms\n",
      "84:\tlearn: 0.4597547\ttotal: 3.65s\tremaining: 644ms\n",
      "85:\tlearn: 0.4575962\ttotal: 3.69s\tremaining: 601ms\n",
      "86:\tlearn: 0.4553647\ttotal: 3.72s\tremaining: 556ms\n",
      "87:\tlearn: 0.4531672\ttotal: 3.74s\tremaining: 510ms\n",
      "88:\tlearn: 0.4509852\ttotal: 3.8s\tremaining: 470ms\n",
      "89:\tlearn: 0.4482173\ttotal: 3.87s\tremaining: 429ms\n",
      "90:\tlearn: 0.4466942\ttotal: 3.9s\tremaining: 385ms\n",
      "91:\tlearn: 0.4450384\ttotal: 3.92s\tremaining: 341ms\n",
      "92:\tlearn: 0.4428285\ttotal: 3.98s\tremaining: 299ms\n",
      "93:\tlearn: 0.4410117\ttotal: 4.04s\tremaining: 258ms\n",
      "94:\tlearn: 0.4393049\ttotal: 4.07s\tremaining: 214ms\n",
      "95:\tlearn: 0.4375977\ttotal: 4.09s\tremaining: 171ms\n",
      "96:\tlearn: 0.4351458\ttotal: 4.16s\tremaining: 129ms\n",
      "97:\tlearn: 0.4332954\ttotal: 4.22s\tremaining: 86.2ms\n",
      "98:\tlearn: 0.4319818\ttotal: 4.25s\tremaining: 42.9ms\n",
      "99:\tlearn: 0.4301245\ttotal: 4.27s\tremaining: 0us\n",
      "0:\tlearn: 0.6889955\ttotal: 30.1ms\tremaining: 2.98s\n",
      "1:\tlearn: 0.6848158\ttotal: 53.8ms\tremaining: 2.63s\n",
      "2:\tlearn: 0.6811863\ttotal: 136ms\tremaining: 4.4s\n",
      "3:\tlearn: 0.6777220\ttotal: 170ms\tremaining: 4.09s\n",
      "4:\tlearn: 0.6747689\ttotal: 194ms\tremaining: 3.69s\n",
      "5:\tlearn: 0.6706616\ttotal: 248ms\tremaining: 3.89s\n",
      "6:\tlearn: 0.6666585\ttotal: 299ms\tremaining: 3.97s\n",
      "7:\tlearn: 0.6617785\ttotal: 328ms\tremaining: 3.77s\n",
      "8:\tlearn: 0.6583420\ttotal: 351ms\tremaining: 3.55s\n",
      "9:\tlearn: 0.6541164\ttotal: 421ms\tremaining: 3.79s\n",
      "10:\tlearn: 0.6505463\ttotal: 483ms\tremaining: 3.91s\n",
      "11:\tlearn: 0.6469301\ttotal: 508ms\tremaining: 3.72s\n",
      "12:\tlearn: 0.6431857\ttotal: 530ms\tremaining: 3.55s\n",
      "13:\tlearn: 0.6401040\ttotal: 609ms\tremaining: 3.74s\n",
      "14:\tlearn: 0.6357839\ttotal: 657ms\tremaining: 3.73s\n",
      "15:\tlearn: 0.6317980\ttotal: 691ms\tremaining: 3.63s\n",
      "16:\tlearn: 0.6282143\ttotal: 712ms\tremaining: 3.47s\n",
      "17:\tlearn: 0.6245338\ttotal: 790ms\tremaining: 3.6s\n",
      "18:\tlearn: 0.6217998\ttotal: 834ms\tremaining: 3.56s\n",
      "19:\tlearn: 0.6178620\ttotal: 862ms\tremaining: 3.45s\n",
      "20:\tlearn: 0.6145141\ttotal: 885ms\tremaining: 3.33s\n",
      "21:\tlearn: 0.6112632\ttotal: 944ms\tremaining: 3.35s\n",
      "22:\tlearn: 0.6080953\ttotal: 992ms\tremaining: 3.32s\n",
      "23:\tlearn: 0.6042536\ttotal: 1.02s\tremaining: 3.22s\n",
      "24:\tlearn: 0.6006693\ttotal: 1.04s\tremaining: 3.12s\n",
      "25:\tlearn: 0.5971143\ttotal: 1.12s\tremaining: 3.19s\n",
      "26:\tlearn: 0.5940627\ttotal: 1.17s\tremaining: 3.16s\n",
      "27:\tlearn: 0.5911041\ttotal: 1.19s\tremaining: 3.07s\n",
      "28:\tlearn: 0.5880408\ttotal: 1.22s\tremaining: 2.98s\n",
      "29:\tlearn: 0.5854583\ttotal: 1.29s\tremaining: 3.02s\n",
      "30:\tlearn: 0.5826039\ttotal: 1.34s\tremaining: 2.98s\n",
      "31:\tlearn: 0.5798976\ttotal: 1.36s\tremaining: 2.9s\n",
      "32:\tlearn: 0.5773191\ttotal: 1.39s\tremaining: 2.82s\n",
      "33:\tlearn: 0.5744322\ttotal: 1.45s\tremaining: 2.82s\n",
      "34:\tlearn: 0.5716086\ttotal: 1.51s\tremaining: 2.8s\n",
      "35:\tlearn: 0.5681637\ttotal: 1.54s\tremaining: 2.73s\n",
      "36:\tlearn: 0.5653858\ttotal: 1.56s\tremaining: 2.66s\n",
      "37:\tlearn: 0.5628461\ttotal: 1.64s\tremaining: 2.67s\n",
      "38:\tlearn: 0.5594489\ttotal: 1.67s\tremaining: 2.62s\n",
      "39:\tlearn: 0.5569409\ttotal: 1.7s\tremaining: 2.55s\n",
      "40:\tlearn: 0.5539025\ttotal: 1.72s\tremaining: 2.48s\n",
      "41:\tlearn: 0.5516148\ttotal: 1.8s\tremaining: 2.49s\n",
      "42:\tlearn: 0.5485890\ttotal: 1.83s\tremaining: 2.43s\n",
      "43:\tlearn: 0.5458996\ttotal: 1.85s\tremaining: 2.36s\n",
      "44:\tlearn: 0.5427661\ttotal: 1.92s\tremaining: 2.35s\n",
      "45:\tlearn: 0.5407105\ttotal: 1.98s\tremaining: 2.32s\n",
      "46:\tlearn: 0.5385253\ttotal: 2.01s\tremaining: 2.27s\n",
      "47:\tlearn: 0.5360689\ttotal: 2.03s\tremaining: 2.2s\n",
      "48:\tlearn: 0.5342295\ttotal: 2.11s\tremaining: 2.19s\n",
      "49:\tlearn: 0.5314544\ttotal: 2.15s\tremaining: 2.15s\n",
      "50:\tlearn: 0.5294446\ttotal: 2.18s\tremaining: 2.1s\n",
      "51:\tlearn: 0.5271898\ttotal: 2.21s\tremaining: 2.04s\n",
      "52:\tlearn: 0.5245079\ttotal: 2.26s\tremaining: 2s\n",
      "53:\tlearn: 0.5216018\ttotal: 2.32s\tremaining: 1.98s\n",
      "54:\tlearn: 0.5187384\ttotal: 2.36s\tremaining: 1.93s\n",
      "55:\tlearn: 0.5165275\ttotal: 2.38s\tremaining: 1.87s\n",
      "56:\tlearn: 0.5143543\ttotal: 2.41s\tremaining: 1.82s\n",
      "57:\tlearn: 0.5120950\ttotal: 2.49s\tremaining: 1.8s\n",
      "58:\tlearn: 0.5094883\ttotal: 2.52s\tremaining: 1.75s\n",
      "59:\tlearn: 0.5071389\ttotal: 2.54s\tremaining: 1.69s\n",
      "60:\tlearn: 0.5041557\ttotal: 2.6s\tremaining: 1.67s\n",
      "61:\tlearn: 0.5013377\ttotal: 2.66s\tremaining: 1.63s\n",
      "62:\tlearn: 0.4993502\ttotal: 2.69s\tremaining: 1.58s\n",
      "63:\tlearn: 0.4967697\ttotal: 2.71s\tremaining: 1.52s\n",
      "64:\tlearn: 0.4943596\ttotal: 2.77s\tremaining: 1.49s\n",
      "65:\tlearn: 0.4919691\ttotal: 2.83s\tremaining: 1.46s\n",
      "66:\tlearn: 0.4899295\ttotal: 2.86s\tremaining: 1.41s\n",
      "67:\tlearn: 0.4879427\ttotal: 2.89s\tremaining: 1.36s\n",
      "68:\tlearn: 0.4852903\ttotal: 2.91s\tremaining: 1.31s\n",
      "69:\tlearn: 0.4830466\ttotal: 2.94s\tremaining: 1.26s\n",
      "70:\tlearn: 0.4811498\ttotal: 2.98s\tremaining: 1.22s\n",
      "71:\tlearn: 0.4793071\ttotal: 3.05s\tremaining: 1.19s\n",
      "72:\tlearn: 0.4772483\ttotal: 3.08s\tremaining: 1.14s\n",
      "73:\tlearn: 0.4756469\ttotal: 3.1s\tremaining: 1.09s\n",
      "74:\tlearn: 0.4734978\ttotal: 3.15s\tremaining: 1.05s\n",
      "75:\tlearn: 0.4712611\ttotal: 3.22s\tremaining: 1.02s\n",
      "76:\tlearn: 0.4691070\ttotal: 3.25s\tremaining: 970ms\n",
      "77:\tlearn: 0.4671062\ttotal: 3.27s\tremaining: 922ms\n",
      "78:\tlearn: 0.4647151\ttotal: 3.29s\tremaining: 876ms\n",
      "79:\tlearn: 0.4627400\ttotal: 3.37s\tremaining: 842ms\n",
      "80:\tlearn: 0.4604210\ttotal: 3.42s\tremaining: 801ms\n",
      "81:\tlearn: 0.4577854\ttotal: 3.44s\tremaining: 756ms\n",
      "82:\tlearn: 0.4559072\ttotal: 3.47s\tremaining: 710ms\n",
      "83:\tlearn: 0.4541258\ttotal: 3.55s\tremaining: 676ms\n",
      "84:\tlearn: 0.4518017\ttotal: 3.59s\tremaining: 634ms\n",
      "85:\tlearn: 0.4497190\ttotal: 3.62s\tremaining: 589ms\n",
      "86:\tlearn: 0.4477231\ttotal: 3.64s\tremaining: 545ms\n",
      "87:\tlearn: 0.4458297\ttotal: 3.69s\tremaining: 504ms\n",
      "88:\tlearn: 0.4438111\ttotal: 3.76s\tremaining: 465ms\n",
      "89:\tlearn: 0.4421003\ttotal: 3.79s\tremaining: 421ms\n",
      "90:\tlearn: 0.4404096\ttotal: 3.81s\tremaining: 377ms\n",
      "91:\tlearn: 0.4381910\ttotal: 3.86s\tremaining: 336ms\n",
      "92:\tlearn: 0.4362388\ttotal: 3.93s\tremaining: 296ms\n",
      "93:\tlearn: 0.4341865\ttotal: 3.96s\tremaining: 253ms\n",
      "94:\tlearn: 0.4327345\ttotal: 3.98s\tremaining: 210ms\n",
      "95:\tlearn: 0.4308779\ttotal: 4.02s\tremaining: 168ms\n",
      "96:\tlearn: 0.4285959\ttotal: 4.09s\tremaining: 127ms\n",
      "97:\tlearn: 0.4266427\ttotal: 4.12s\tremaining: 84.1ms\n",
      "98:\tlearn: 0.4253084\ttotal: 4.14s\tremaining: 41.9ms\n",
      "99:\tlearn: 0.4238265\ttotal: 4.2s\tremaining: 0us\n",
      "0:\tlearn: 0.6894767\ttotal: 45.9ms\tremaining: 4.54s\n",
      "1:\tlearn: 0.6851752\ttotal: 76.5ms\tremaining: 3.75s\n",
      "2:\tlearn: 0.6816689\ttotal: 101ms\tremaining: 3.27s\n",
      "3:\tlearn: 0.6776853\ttotal: 154ms\tremaining: 3.7s\n",
      "4:\tlearn: 0.6740380\ttotal: 214ms\tremaining: 4.06s\n",
      "5:\tlearn: 0.6697781\ttotal: 257ms\tremaining: 4.03s\n",
      "6:\tlearn: 0.6666757\ttotal: 278ms\tremaining: 3.69s\n",
      "7:\tlearn: 0.6628664\ttotal: 328ms\tremaining: 3.77s\n",
      "8:\tlearn: 0.6590905\ttotal: 382ms\tremaining: 3.86s\n",
      "9:\tlearn: 0.6555120\ttotal: 408ms\tremaining: 3.67s\n",
      "10:\tlearn: 0.6515109\ttotal: 431ms\tremaining: 3.49s\n",
      "11:\tlearn: 0.6478605\ttotal: 491ms\tremaining: 3.6s\n",
      "12:\tlearn: 0.6440182\ttotal: 552ms\tremaining: 3.7s\n",
      "13:\tlearn: 0.6409221\ttotal: 584ms\tremaining: 3.58s\n",
      "14:\tlearn: 0.6372417\ttotal: 607ms\tremaining: 3.44s\n",
      "15:\tlearn: 0.6332768\ttotal: 629ms\tremaining: 3.3s\n",
      "16:\tlearn: 0.6292472\ttotal: 709ms\tremaining: 3.46s\n",
      "17:\tlearn: 0.6258332\ttotal: 748ms\tremaining: 3.41s\n",
      "18:\tlearn: 0.6234155\ttotal: 777ms\tremaining: 3.31s\n",
      "19:\tlearn: 0.6205912\ttotal: 802ms\tremaining: 3.21s\n",
      "20:\tlearn: 0.6174311\ttotal: 865ms\tremaining: 3.25s\n",
      "21:\tlearn: 0.6138769\ttotal: 915ms\tremaining: 3.24s\n",
      "22:\tlearn: 0.6107774\ttotal: 943ms\tremaining: 3.15s\n",
      "23:\tlearn: 0.6074831\ttotal: 966ms\tremaining: 3.06s\n",
      "24:\tlearn: 0.6037795\ttotal: 1.04s\tremaining: 3.14s\n",
      "25:\tlearn: 0.6011654\ttotal: 1.1s\tremaining: 3.13s\n",
      "26:\tlearn: 0.5981966\ttotal: 1.12s\tremaining: 3.04s\n",
      "27:\tlearn: 0.5954091\ttotal: 1.15s\tremaining: 2.95s\n",
      "28:\tlearn: 0.5923996\ttotal: 1.19s\tremaining: 2.92s\n",
      "29:\tlearn: 0.5900556\ttotal: 1.25s\tremaining: 2.93s\n",
      "30:\tlearn: 0.5875564\ttotal: 1.29s\tremaining: 2.87s\n",
      "31:\tlearn: 0.5845103\ttotal: 1.31s\tremaining: 2.79s\n",
      "32:\tlearn: 0.5803902\ttotal: 1.35s\tremaining: 2.74s\n",
      "33:\tlearn: 0.5777515\ttotal: 1.43s\tremaining: 2.77s\n",
      "34:\tlearn: 0.5750206\ttotal: 1.47s\tremaining: 2.72s\n",
      "35:\tlearn: 0.5724399\ttotal: 1.49s\tremaining: 2.65s\n",
      "36:\tlearn: 0.5699571\ttotal: 1.54s\tremaining: 2.62s\n",
      "37:\tlearn: 0.5671368\ttotal: 1.61s\tremaining: 2.63s\n",
      "38:\tlearn: 0.5645662\ttotal: 1.65s\tremaining: 2.58s\n",
      "39:\tlearn: 0.5618168\ttotal: 1.67s\tremaining: 2.51s\n",
      "40:\tlearn: 0.5589922\ttotal: 1.7s\tremaining: 2.44s\n",
      "41:\tlearn: 0.5566602\ttotal: 1.72s\tremaining: 2.38s\n",
      "42:\tlearn: 0.5540165\ttotal: 1.8s\tremaining: 2.38s\n",
      "43:\tlearn: 0.5510868\ttotal: 1.83s\tremaining: 2.34s\n",
      "44:\tlearn: 0.5487908\ttotal: 1.86s\tremaining: 2.28s\n",
      "45:\tlearn: 0.5464595\ttotal: 1.89s\tremaining: 2.21s\n",
      "46:\tlearn: 0.5436791\ttotal: 1.99s\tremaining: 2.24s\n",
      "47:\tlearn: 0.5413445\ttotal: 2.03s\tremaining: 2.2s\n",
      "48:\tlearn: 0.5384277\ttotal: 2.06s\tremaining: 2.15s\n",
      "49:\tlearn: 0.5358839\ttotal: 2.08s\tremaining: 2.08s\n",
      "50:\tlearn: 0.5335769\ttotal: 2.15s\tremaining: 2.06s\n",
      "51:\tlearn: 0.5316912\ttotal: 2.21s\tremaining: 2.04s\n",
      "52:\tlearn: 0.5290522\ttotal: 2.24s\tremaining: 1.99s\n",
      "53:\tlearn: 0.5264702\ttotal: 2.27s\tremaining: 1.93s\n",
      "54:\tlearn: 0.5235934\ttotal: 2.29s\tremaining: 1.87s\n",
      "55:\tlearn: 0.5209207\ttotal: 2.36s\tremaining: 1.86s\n",
      "56:\tlearn: 0.5188266\ttotal: 2.39s\tremaining: 1.8s\n",
      "57:\tlearn: 0.5167104\ttotal: 2.42s\tremaining: 1.75s\n",
      "58:\tlearn: 0.5137770\ttotal: 2.48s\tremaining: 1.72s\n",
      "59:\tlearn: 0.5114079\ttotal: 2.53s\tremaining: 1.69s\n",
      "60:\tlearn: 0.5079190\ttotal: 2.56s\tremaining: 1.64s\n",
      "61:\tlearn: 0.5056916\ttotal: 2.59s\tremaining: 1.59s\n",
      "62:\tlearn: 0.5042241\ttotal: 2.64s\tremaining: 1.55s\n",
      "63:\tlearn: 0.5017081\ttotal: 2.71s\tremaining: 1.52s\n",
      "64:\tlearn: 0.4989932\ttotal: 2.74s\tremaining: 1.47s\n",
      "65:\tlearn: 0.4970784\ttotal: 2.76s\tremaining: 1.42s\n",
      "66:\tlearn: 0.4947626\ttotal: 2.79s\tremaining: 1.37s\n",
      "67:\tlearn: 0.4933300\ttotal: 2.86s\tremaining: 1.35s\n",
      "68:\tlearn: 0.4910254\ttotal: 2.89s\tremaining: 1.3s\n",
      "69:\tlearn: 0.4892283\ttotal: 2.92s\tremaining: 1.25s\n",
      "70:\tlearn: 0.4868549\ttotal: 2.99s\tremaining: 1.22s\n",
      "71:\tlearn: 0.4851936\ttotal: 3.04s\tremaining: 1.18s\n",
      "72:\tlearn: 0.4831051\ttotal: 3.07s\tremaining: 1.14s\n",
      "73:\tlearn: 0.4813920\ttotal: 3.09s\tremaining: 1.09s\n",
      "74:\tlearn: 0.4790770\ttotal: 3.14s\tremaining: 1.05s\n",
      "75:\tlearn: 0.4764137\ttotal: 3.21s\tremaining: 1.01s\n",
      "76:\tlearn: 0.4744892\ttotal: 3.24s\tremaining: 968ms\n",
      "77:\tlearn: 0.4726643\ttotal: 3.26s\tremaining: 921ms\n",
      "78:\tlearn: 0.4708951\ttotal: 3.31s\tremaining: 880ms\n",
      "79:\tlearn: 0.4685864\ttotal: 3.38s\tremaining: 845ms\n",
      "80:\tlearn: 0.4671618\ttotal: 3.41s\tremaining: 800ms\n",
      "81:\tlearn: 0.4643108\ttotal: 3.44s\tremaining: 754ms\n",
      "82:\tlearn: 0.4618485\ttotal: 3.47s\tremaining: 710ms\n",
      "83:\tlearn: 0.4592153\ttotal: 3.55s\tremaining: 676ms\n",
      "84:\tlearn: 0.4574083\ttotal: 3.58s\tremaining: 633ms\n",
      "85:\tlearn: 0.4554803\ttotal: 3.61s\tremaining: 588ms\n",
      "86:\tlearn: 0.4541277\ttotal: 3.63s\tremaining: 543ms\n",
      "87:\tlearn: 0.4517777\ttotal: 3.68s\tremaining: 502ms\n",
      "88:\tlearn: 0.4498535\ttotal: 3.74s\tremaining: 462ms\n",
      "89:\tlearn: 0.4479273\ttotal: 3.78s\tremaining: 420ms\n",
      "90:\tlearn: 0.4456975\ttotal: 3.8s\tremaining: 376ms\n",
      "91:\tlearn: 0.4439950\ttotal: 3.88s\tremaining: 337ms\n",
      "92:\tlearn: 0.4426080\ttotal: 3.92s\tremaining: 295ms\n",
      "93:\tlearn: 0.4410710\ttotal: 3.94s\tremaining: 252ms\n",
      "94:\tlearn: 0.4395738\ttotal: 3.99s\tremaining: 210ms\n",
      "95:\tlearn: 0.4380918\ttotal: 4.06s\tremaining: 169ms\n",
      "96:\tlearn: 0.4364211\ttotal: 4.1s\tremaining: 127ms\n",
      "97:\tlearn: 0.4347538\ttotal: 4.12s\tremaining: 84.1ms\n",
      "98:\tlearn: 0.4329386\ttotal: 4.14s\tremaining: 41.9ms\n",
      "99:\tlearn: 0.4313877\ttotal: 4.23s\tremaining: 0us\n",
      "0:\tlearn: 0.6821250\ttotal: 4.44ms\tremaining: 2.21s\n",
      "1:\tlearn: 0.6720012\ttotal: 8.81ms\tremaining: 2.19s\n",
      "2:\tlearn: 0.6601896\ttotal: 13.1ms\tremaining: 2.17s\n",
      "3:\tlearn: 0.6526460\ttotal: 17.7ms\tremaining: 2.19s\n",
      "4:\tlearn: 0.6422093\ttotal: 21.8ms\tremaining: 2.15s\n",
      "5:\tlearn: 0.6354636\ttotal: 26.1ms\tremaining: 2.15s\n",
      "6:\tlearn: 0.6258923\ttotal: 30.2ms\tremaining: 2.13s\n",
      "7:\tlearn: 0.6185681\ttotal: 34.3ms\tremaining: 2.11s\n",
      "8:\tlearn: 0.6097660\ttotal: 38.4ms\tremaining: 2.09s\n",
      "9:\tlearn: 0.6038651\ttotal: 42.7ms\tremaining: 2.09s\n",
      "10:\tlearn: 0.5983804\ttotal: 47.9ms\tremaining: 2.13s\n",
      "11:\tlearn: 0.5920023\ttotal: 57.4ms\tremaining: 2.33s\n",
      "12:\tlearn: 0.5825396\ttotal: 67.1ms\tremaining: 2.51s\n",
      "13:\tlearn: 0.5720743\ttotal: 76.8ms\tremaining: 2.67s\n",
      "14:\tlearn: 0.5660930\ttotal: 86.5ms\tremaining: 2.79s\n",
      "15:\tlearn: 0.5597207\ttotal: 96.1ms\tremaining: 2.91s\n",
      "16:\tlearn: 0.5535314\ttotal: 106ms\tremaining: 3s\n",
      "17:\tlearn: 0.5488789\ttotal: 115ms\tremaining: 3.08s\n",
      "18:\tlearn: 0.5429698\ttotal: 125ms\tremaining: 3.15s\n",
      "19:\tlearn: 0.5382927\ttotal: 134ms\tremaining: 3.22s\n",
      "20:\tlearn: 0.5343060\ttotal: 140ms\tremaining: 3.2s\n",
      "21:\tlearn: 0.5244747\ttotal: 146ms\tremaining: 3.18s\n",
      "22:\tlearn: 0.5196451\ttotal: 153ms\tremaining: 3.16s\n",
      "23:\tlearn: 0.5148111\ttotal: 157ms\tremaining: 3.11s\n",
      "24:\tlearn: 0.5115233\ttotal: 161ms\tremaining: 3.06s\n",
      "25:\tlearn: 0.5060995\ttotal: 166ms\tremaining: 3.03s\n",
      "26:\tlearn: 0.5036300\ttotal: 171ms\tremaining: 2.99s\n",
      "27:\tlearn: 0.4984324\ttotal: 175ms\tremaining: 2.96s\n",
      "28:\tlearn: 0.4923145\ttotal: 180ms\tremaining: 2.93s\n",
      "29:\tlearn: 0.4874771\ttotal: 186ms\tremaining: 2.91s\n",
      "30:\tlearn: 0.4796162\ttotal: 190ms\tremaining: 2.88s\n",
      "31:\tlearn: 0.4746014\ttotal: 194ms\tremaining: 2.84s\n",
      "32:\tlearn: 0.4694283\ttotal: 199ms\tremaining: 2.81s\n",
      "33:\tlearn: 0.4644142\ttotal: 203ms\tremaining: 2.79s\n",
      "34:\tlearn: 0.4600974\ttotal: 208ms\tremaining: 2.76s\n",
      "35:\tlearn: 0.4563048\ttotal: 212ms\tremaining: 2.73s\n",
      "36:\tlearn: 0.4542492\ttotal: 222ms\tremaining: 2.78s\n",
      "37:\tlearn: 0.4494481\ttotal: 232ms\tremaining: 2.82s\n",
      "38:\tlearn: 0.4455142\ttotal: 242ms\tremaining: 2.86s\n",
      "39:\tlearn: 0.4431316\ttotal: 251ms\tremaining: 2.89s\n",
      "40:\tlearn: 0.4404494\ttotal: 261ms\tremaining: 2.92s\n",
      "41:\tlearn: 0.4369891\ttotal: 271ms\tremaining: 2.95s\n",
      "42:\tlearn: 0.4335935\ttotal: 280ms\tremaining: 2.98s\n",
      "43:\tlearn: 0.4314028\ttotal: 290ms\tremaining: 3s\n",
      "44:\tlearn: 0.4264811\ttotal: 299ms\tremaining: 3.02s\n",
      "45:\tlearn: 0.4215123\ttotal: 306ms\tremaining: 3.02s\n",
      "46:\tlearn: 0.4182443\ttotal: 312ms\tremaining: 3.01s\n",
      "47:\tlearn: 0.4121087\ttotal: 318ms\tremaining: 3s\n",
      "48:\tlearn: 0.4089305\ttotal: 324ms\tremaining: 2.99s\n",
      "49:\tlearn: 0.4056939\ttotal: 331ms\tremaining: 2.98s\n",
      "50:\tlearn: 0.4034018\ttotal: 335ms\tremaining: 2.95s\n",
      "51:\tlearn: 0.3994042\ttotal: 340ms\tremaining: 2.93s\n",
      "52:\tlearn: 0.3968880\ttotal: 345ms\tremaining: 2.91s\n",
      "53:\tlearn: 0.3932802\ttotal: 350ms\tremaining: 2.89s\n",
      "54:\tlearn: 0.3914707\ttotal: 354ms\tremaining: 2.87s\n",
      "55:\tlearn: 0.3848628\ttotal: 359ms\tremaining: 2.85s\n",
      "56:\tlearn: 0.3827081\ttotal: 363ms\tremaining: 2.82s\n",
      "57:\tlearn: 0.3755688\ttotal: 368ms\tremaining: 2.81s\n",
      "58:\tlearn: 0.3728232\ttotal: 372ms\tremaining: 2.78s\n",
      "59:\tlearn: 0.3692811\ttotal: 376ms\tremaining: 2.76s\n",
      "60:\tlearn: 0.3669630\ttotal: 380ms\tremaining: 2.74s\n",
      "61:\tlearn: 0.3647731\ttotal: 389ms\tremaining: 2.75s\n",
      "62:\tlearn: 0.3622115\ttotal: 399ms\tremaining: 2.76s\n",
      "63:\tlearn: 0.3603002\ttotal: 408ms\tremaining: 2.78s\n",
      "64:\tlearn: 0.3555405\ttotal: 418ms\tremaining: 2.8s\n",
      "65:\tlearn: 0.3524519\ttotal: 428ms\tremaining: 2.81s\n",
      "66:\tlearn: 0.3500214\ttotal: 438ms\tremaining: 2.83s\n",
      "67:\tlearn: 0.3480451\ttotal: 448ms\tremaining: 2.85s\n",
      "68:\tlearn: 0.3457807\ttotal: 458ms\tremaining: 2.86s\n",
      "69:\tlearn: 0.3439585\ttotal: 467ms\tremaining: 2.87s\n",
      "70:\tlearn: 0.3423764\ttotal: 477ms\tremaining: 2.88s\n",
      "71:\tlearn: 0.3410605\ttotal: 483ms\tremaining: 2.87s\n",
      "72:\tlearn: 0.3391431\ttotal: 489ms\tremaining: 2.86s\n",
      "73:\tlearn: 0.3360879\ttotal: 495ms\tremaining: 2.85s\n",
      "74:\tlearn: 0.3342617\ttotal: 501ms\tremaining: 2.84s\n",
      "75:\tlearn: 0.3322071\ttotal: 507ms\tremaining: 2.83s\n",
      "76:\tlearn: 0.3304331\ttotal: 512ms\tremaining: 2.81s\n",
      "77:\tlearn: 0.3281420\ttotal: 516ms\tremaining: 2.79s\n",
      "78:\tlearn: 0.3260217\ttotal: 521ms\tremaining: 2.78s\n",
      "79:\tlearn: 0.3219494\ttotal: 529ms\tremaining: 2.78s\n",
      "80:\tlearn: 0.3199730\ttotal: 533ms\tremaining: 2.76s\n",
      "81:\tlearn: 0.3179633\ttotal: 538ms\tremaining: 2.74s\n",
      "82:\tlearn: 0.3160145\ttotal: 542ms\tremaining: 2.72s\n",
      "83:\tlearn: 0.3113844\ttotal: 546ms\tremaining: 2.71s\n",
      "84:\tlearn: 0.3095475\ttotal: 551ms\tremaining: 2.69s\n",
      "85:\tlearn: 0.3063979\ttotal: 555ms\tremaining: 2.67s\n",
      "86:\tlearn: 0.3037483\ttotal: 560ms\tremaining: 2.66s\n",
      "87:\tlearn: 0.3015079\ttotal: 565ms\tremaining: 2.65s\n",
      "88:\tlearn: 0.2997563\ttotal: 570ms\tremaining: 2.63s\n",
      "89:\tlearn: 0.2956580\ttotal: 575ms\tremaining: 2.62s\n",
      "90:\tlearn: 0.2914651\ttotal: 585ms\tremaining: 2.63s\n",
      "91:\tlearn: 0.2895854\ttotal: 594ms\tremaining: 2.63s\n",
      "92:\tlearn: 0.2872200\ttotal: 604ms\tremaining: 2.64s\n",
      "93:\tlearn: 0.2852033\ttotal: 614ms\tremaining: 2.65s\n",
      "94:\tlearn: 0.2832405\ttotal: 624ms\tremaining: 2.66s\n",
      "95:\tlearn: 0.2815151\ttotal: 633ms\tremaining: 2.66s\n",
      "96:\tlearn: 0.2796167\ttotal: 643ms\tremaining: 2.67s\n",
      "97:\tlearn: 0.2778136\ttotal: 653ms\tremaining: 2.68s\n",
      "98:\tlearn: 0.2760151\ttotal: 662ms\tremaining: 2.68s\n",
      "99:\tlearn: 0.2741585\ttotal: 669ms\tremaining: 2.67s\n",
      "100:\tlearn: 0.2723830\ttotal: 675ms\tremaining: 2.67s\n",
      "101:\tlearn: 0.2703748\ttotal: 681ms\tremaining: 2.66s\n",
      "102:\tlearn: 0.2687181\ttotal: 687ms\tremaining: 2.65s\n",
      "103:\tlearn: 0.2668200\ttotal: 694ms\tremaining: 2.64s\n",
      "104:\tlearn: 0.2651970\ttotal: 698ms\tremaining: 2.63s\n",
      "105:\tlearn: 0.2634627\ttotal: 703ms\tremaining: 2.61s\n",
      "106:\tlearn: 0.2618602\ttotal: 708ms\tremaining: 2.6s\n",
      "107:\tlearn: 0.2603196\ttotal: 715ms\tremaining: 2.59s\n",
      "108:\tlearn: 0.2582571\ttotal: 719ms\tremaining: 2.58s\n",
      "109:\tlearn: 0.2563760\ttotal: 724ms\tremaining: 2.57s\n",
      "110:\tlearn: 0.2546069\ttotal: 728ms\tremaining: 2.55s\n",
      "111:\tlearn: 0.2531179\ttotal: 733ms\tremaining: 2.54s\n",
      "112:\tlearn: 0.2516654\ttotal: 737ms\tremaining: 2.52s\n",
      "113:\tlearn: 0.2503356\ttotal: 741ms\tremaining: 2.51s\n",
      "114:\tlearn: 0.2484755\ttotal: 745ms\tremaining: 2.49s\n",
      "115:\tlearn: 0.2467667\ttotal: 755ms\tremaining: 2.5s\n",
      "116:\tlearn: 0.2454082\ttotal: 764ms\tremaining: 2.5s\n",
      "117:\tlearn: 0.2441847\ttotal: 774ms\tremaining: 2.5s\n",
      "118:\tlearn: 0.2424935\ttotal: 784ms\tremaining: 2.51s\n",
      "119:\tlearn: 0.2412163\ttotal: 793ms\tremaining: 2.51s\n",
      "120:\tlearn: 0.2386140\ttotal: 802ms\tremaining: 2.51s\n",
      "121:\tlearn: 0.2372427\ttotal: 812ms\tremaining: 2.52s\n",
      "122:\tlearn: 0.2355050\ttotal: 821ms\tremaining: 2.52s\n",
      "123:\tlearn: 0.2341196\ttotal: 831ms\tremaining: 2.52s\n",
      "124:\tlearn: 0.2328694\ttotal: 841ms\tremaining: 2.52s\n",
      "125:\tlearn: 0.2298601\ttotal: 848ms\tremaining: 2.52s\n",
      "126:\tlearn: 0.2286088\ttotal: 854ms\tremaining: 2.51s\n",
      "127:\tlearn: 0.2271901\ttotal: 860ms\tremaining: 2.5s\n",
      "128:\tlearn: 0.2259380\ttotal: 866ms\tremaining: 2.49s\n",
      "129:\tlearn: 0.2246781\ttotal: 873ms\tremaining: 2.48s\n",
      "130:\tlearn: 0.2236553\ttotal: 878ms\tremaining: 2.47s\n",
      "131:\tlearn: 0.2217685\ttotal: 882ms\tremaining: 2.46s\n",
      "132:\tlearn: 0.2195038\ttotal: 888ms\tremaining: 2.45s\n",
      "133:\tlearn: 0.2182740\ttotal: 892ms\tremaining: 2.44s\n",
      "134:\tlearn: 0.2166611\ttotal: 896ms\tremaining: 2.42s\n",
      "135:\tlearn: 0.2153072\ttotal: 899ms\tremaining: 2.4s\n",
      "136:\tlearn: 0.2127500\ttotal: 902ms\tremaining: 2.39s\n",
      "137:\tlearn: 0.2102817\ttotal: 906ms\tremaining: 2.38s\n",
      "138:\tlearn: 0.2080816\ttotal: 910ms\tremaining: 2.36s\n",
      "139:\tlearn: 0.2064933\ttotal: 915ms\tremaining: 2.35s\n",
      "140:\tlearn: 0.2054417\ttotal: 919ms\tremaining: 2.34s\n",
      "141:\tlearn: 0.2042553\ttotal: 929ms\tremaining: 2.34s\n",
      "142:\tlearn: 0.2029005\ttotal: 939ms\tremaining: 2.34s\n",
      "143:\tlearn: 0.2015966\ttotal: 948ms\tremaining: 2.34s\n",
      "144:\tlearn: 0.2003976\ttotal: 958ms\tremaining: 2.34s\n",
      "145:\tlearn: 0.1988637\ttotal: 967ms\tremaining: 2.34s\n",
      "146:\tlearn: 0.1976303\ttotal: 977ms\tremaining: 2.35s\n",
      "147:\tlearn: 0.1963246\ttotal: 986ms\tremaining: 2.35s\n",
      "148:\tlearn: 0.1951680\ttotal: 996ms\tremaining: 2.35s\n",
      "149:\tlearn: 0.1941021\ttotal: 1s\tremaining: 2.34s\n",
      "150:\tlearn: 0.1929510\ttotal: 1.01s\tremaining: 2.33s\n",
      "151:\tlearn: 0.1919176\ttotal: 1.01s\tremaining: 2.33s\n",
      "152:\tlearn: 0.1907954\ttotal: 1.02s\tremaining: 2.32s\n",
      "153:\tlearn: 0.1899034\ttotal: 1.03s\tremaining: 2.31s\n",
      "154:\tlearn: 0.1888116\ttotal: 1.03s\tremaining: 2.3s\n",
      "155:\tlearn: 0.1876351\ttotal: 1.04s\tremaining: 2.29s\n",
      "156:\tlearn: 0.1865534\ttotal: 1.04s\tremaining: 2.28s\n",
      "157:\tlearn: 0.1852037\ttotal: 1.05s\tremaining: 2.27s\n",
      "158:\tlearn: 0.1841659\ttotal: 1.05s\tremaining: 2.26s\n",
      "159:\tlearn: 0.1831110\ttotal: 1.06s\tremaining: 2.25s\n",
      "160:\tlearn: 0.1821366\ttotal: 1.06s\tremaining: 2.24s\n",
      "161:\tlearn: 0.1811538\ttotal: 1.07s\tremaining: 2.23s\n",
      "162:\tlearn: 0.1800325\ttotal: 1.07s\tremaining: 2.21s\n",
      "163:\tlearn: 0.1788964\ttotal: 1.07s\tremaining: 2.2s\n",
      "164:\tlearn: 0.1778331\ttotal: 1.08s\tremaining: 2.19s\n",
      "165:\tlearn: 0.1767863\ttotal: 1.08s\tremaining: 2.18s\n",
      "166:\tlearn: 0.1755279\ttotal: 1.09s\tremaining: 2.17s\n",
      "167:\tlearn: 0.1738569\ttotal: 1.09s\tremaining: 2.16s\n",
      "168:\tlearn: 0.1727298\ttotal: 1.1s\tremaining: 2.16s\n",
      "169:\tlearn: 0.1705645\ttotal: 1.11s\tremaining: 2.16s\n",
      "170:\tlearn: 0.1692744\ttotal: 1.12s\tremaining: 2.16s\n",
      "171:\tlearn: 0.1683734\ttotal: 1.13s\tremaining: 2.16s\n",
      "172:\tlearn: 0.1674781\ttotal: 1.14s\tremaining: 2.16s\n",
      "173:\tlearn: 0.1664119\ttotal: 1.15s\tremaining: 2.16s\n",
      "174:\tlearn: 0.1656037\ttotal: 1.16s\tremaining: 2.16s\n",
      "175:\tlearn: 0.1647428\ttotal: 1.17s\tremaining: 2.15s\n",
      "176:\tlearn: 0.1638821\ttotal: 1.18s\tremaining: 2.15s\n",
      "177:\tlearn: 0.1624577\ttotal: 1.19s\tremaining: 2.14s\n",
      "178:\tlearn: 0.1615995\ttotal: 1.19s\tremaining: 2.14s\n",
      "179:\tlearn: 0.1606949\ttotal: 1.2s\tremaining: 2.13s\n",
      "180:\tlearn: 0.1596620\ttotal: 1.2s\tremaining: 2.12s\n",
      "181:\tlearn: 0.1585491\ttotal: 1.21s\tremaining: 2.11s\n",
      "182:\tlearn: 0.1576740\ttotal: 1.21s\tremaining: 2.1s\n",
      "183:\tlearn: 0.1568479\ttotal: 1.22s\tremaining: 2.09s\n",
      "184:\tlearn: 0.1558731\ttotal: 1.22s\tremaining: 2.08s\n",
      "185:\tlearn: 0.1543798\ttotal: 1.23s\tremaining: 2.07s\n",
      "186:\tlearn: 0.1537530\ttotal: 1.23s\tremaining: 2.06s\n",
      "187:\tlearn: 0.1523217\ttotal: 1.24s\tremaining: 2.05s\n",
      "188:\tlearn: 0.1514389\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.1506118\ttotal: 1.25s\tremaining: 2.03s\n",
      "190:\tlearn: 0.1498950\ttotal: 1.25s\tremaining: 2.02s\n",
      "191:\tlearn: 0.1493559\ttotal: 1.25s\tremaining: 2.01s\n",
      "192:\tlearn: 0.1485705\ttotal: 1.26s\tremaining: 2s\n",
      "193:\tlearn: 0.1475732\ttotal: 1.27s\tremaining: 2s\n",
      "194:\tlearn: 0.1467078\ttotal: 1.28s\tremaining: 2s\n",
      "195:\tlearn: 0.1457007\ttotal: 1.29s\tremaining: 2s\n",
      "196:\tlearn: 0.1449883\ttotal: 1.3s\tremaining: 2s\n",
      "197:\tlearn: 0.1441486\ttotal: 1.31s\tremaining: 1.99s\n",
      "198:\tlearn: 0.1431445\ttotal: 1.32s\tremaining: 1.99s\n",
      "199:\tlearn: 0.1422178\ttotal: 1.33s\tremaining: 1.99s\n",
      "200:\tlearn: 0.1415816\ttotal: 1.34s\tremaining: 1.99s\n",
      "201:\tlearn: 0.1407599\ttotal: 1.35s\tremaining: 1.99s\n",
      "202:\tlearn: 0.1400276\ttotal: 1.35s\tremaining: 1.98s\n",
      "203:\tlearn: 0.1392599\ttotal: 1.36s\tremaining: 1.97s\n",
      "204:\tlearn: 0.1386105\ttotal: 1.36s\tremaining: 1.97s\n",
      "205:\tlearn: 0.1378310\ttotal: 1.37s\tremaining: 1.96s\n",
      "206:\tlearn: 0.1370732\ttotal: 1.38s\tremaining: 1.95s\n",
      "207:\tlearn: 0.1362646\ttotal: 1.38s\tremaining: 1.94s\n",
      "208:\tlearn: 0.1355562\ttotal: 1.39s\tremaining: 1.93s\n",
      "209:\tlearn: 0.1346887\ttotal: 1.39s\tremaining: 1.92s\n",
      "210:\tlearn: 0.1337154\ttotal: 1.4s\tremaining: 1.91s\n",
      "211:\tlearn: 0.1334143\ttotal: 1.4s\tremaining: 1.9s\n",
      "212:\tlearn: 0.1325858\ttotal: 1.41s\tremaining: 1.9s\n",
      "213:\tlearn: 0.1319061\ttotal: 1.41s\tremaining: 1.89s\n",
      "214:\tlearn: 0.1307297\ttotal: 1.42s\tremaining: 1.88s\n",
      "215:\tlearn: 0.1301786\ttotal: 1.42s\tremaining: 1.87s\n",
      "216:\tlearn: 0.1288467\ttotal: 1.42s\tremaining: 1.86s\n",
      "217:\tlearn: 0.1276838\ttotal: 1.43s\tremaining: 1.85s\n",
      "218:\tlearn: 0.1271222\ttotal: 1.44s\tremaining: 1.85s\n",
      "219:\tlearn: 0.1264557\ttotal: 1.45s\tremaining: 1.84s\n",
      "220:\tlearn: 0.1257675\ttotal: 1.46s\tremaining: 1.84s\n",
      "221:\tlearn: 0.1251017\ttotal: 1.47s\tremaining: 1.84s\n",
      "222:\tlearn: 0.1245079\ttotal: 1.48s\tremaining: 1.83s\n",
      "223:\tlearn: 0.1238561\ttotal: 1.49s\tremaining: 1.83s\n",
      "224:\tlearn: 0.1234031\ttotal: 1.5s\tremaining: 1.83s\n",
      "225:\tlearn: 0.1221781\ttotal: 1.51s\tremaining: 1.83s\n",
      "226:\tlearn: 0.1215634\ttotal: 1.52s\tremaining: 1.82s\n",
      "227:\tlearn: 0.1208798\ttotal: 1.52s\tremaining: 1.82s\n",
      "228:\tlearn: 0.1197317\ttotal: 1.53s\tremaining: 1.81s\n",
      "229:\tlearn: 0.1191714\ttotal: 1.54s\tremaining: 1.8s\n",
      "230:\tlearn: 0.1180679\ttotal: 1.54s\tremaining: 1.8s\n",
      "231:\tlearn: 0.1170345\ttotal: 1.55s\tremaining: 1.79s\n",
      "232:\tlearn: 0.1165812\ttotal: 1.55s\tremaining: 1.78s\n",
      "233:\tlearn: 0.1159035\ttotal: 1.56s\tremaining: 1.77s\n",
      "234:\tlearn: 0.1152854\ttotal: 1.56s\tremaining: 1.76s\n",
      "235:\tlearn: 0.1147081\ttotal: 1.57s\tremaining: 1.75s\n",
      "236:\tlearn: 0.1141581\ttotal: 1.57s\tremaining: 1.75s\n",
      "237:\tlearn: 0.1133421\ttotal: 1.58s\tremaining: 1.74s\n",
      "238:\tlearn: 0.1128497\ttotal: 1.58s\tremaining: 1.73s\n",
      "239:\tlearn: 0.1123343\ttotal: 1.59s\tremaining: 1.72s\n",
      "240:\tlearn: 0.1115960\ttotal: 1.59s\tremaining: 1.71s\n",
      "241:\tlearn: 0.1110548\ttotal: 1.6s\tremaining: 1.7s\n",
      "242:\tlearn: 0.1105580\ttotal: 1.6s\tremaining: 1.69s\n",
      "243:\tlearn: 0.1098593\ttotal: 1.61s\tremaining: 1.69s\n",
      "244:\tlearn: 0.1094134\ttotal: 1.61s\tremaining: 1.68s\n",
      "245:\tlearn: 0.1088021\ttotal: 1.61s\tremaining: 1.67s\n",
      "246:\tlearn: 0.1080824\ttotal: 1.62s\tremaining: 1.66s\n",
      "247:\tlearn: 0.1072499\ttotal: 1.62s\tremaining: 1.65s\n",
      "248:\tlearn: 0.1066193\ttotal: 1.63s\tremaining: 1.64s\n",
      "249:\tlearn: 0.1060056\ttotal: 1.63s\tremaining: 1.63s\n",
      "250:\tlearn: 0.1055083\ttotal: 1.63s\tremaining: 1.62s\n",
      "251:\tlearn: 0.1048965\ttotal: 1.64s\tremaining: 1.62s\n",
      "252:\tlearn: 0.1043816\ttotal: 1.65s\tremaining: 1.61s\n",
      "253:\tlearn: 0.1039103\ttotal: 1.66s\tremaining: 1.61s\n",
      "254:\tlearn: 0.1033500\ttotal: 1.67s\tremaining: 1.61s\n",
      "255:\tlearn: 0.1028786\ttotal: 1.68s\tremaining: 1.6s\n",
      "256:\tlearn: 0.1022154\ttotal: 1.69s\tremaining: 1.6s\n",
      "257:\tlearn: 0.1016294\ttotal: 1.7s\tremaining: 1.6s\n",
      "258:\tlearn: 0.1011855\ttotal: 1.71s\tremaining: 1.59s\n",
      "259:\tlearn: 0.1005956\ttotal: 1.72s\tremaining: 1.59s\n",
      "260:\tlearn: 0.1001926\ttotal: 1.73s\tremaining: 1.58s\n",
      "261:\tlearn: 0.0994403\ttotal: 1.74s\tremaining: 1.58s\n",
      "262:\tlearn: 0.0988808\ttotal: 1.74s\tremaining: 1.57s\n",
      "263:\tlearn: 0.0981169\ttotal: 1.75s\tremaining: 1.56s\n",
      "264:\tlearn: 0.0976272\ttotal: 1.75s\tremaining: 1.56s\n",
      "265:\tlearn: 0.0970197\ttotal: 1.76s\tremaining: 1.55s\n",
      "266:\tlearn: 0.0964304\ttotal: 1.76s\tremaining: 1.54s\n",
      "267:\tlearn: 0.0960379\ttotal: 1.77s\tremaining: 1.53s\n",
      "268:\tlearn: 0.0955600\ttotal: 1.77s\tremaining: 1.52s\n",
      "269:\tlearn: 0.0953235\ttotal: 1.78s\tremaining: 1.51s\n",
      "270:\tlearn: 0.0948207\ttotal: 1.78s\tremaining: 1.51s\n",
      "271:\tlearn: 0.0943082\ttotal: 1.79s\tremaining: 1.5s\n",
      "272:\tlearn: 0.0937893\ttotal: 1.79s\tremaining: 1.49s\n",
      "273:\tlearn: 0.0933015\ttotal: 1.79s\tremaining: 1.48s\n",
      "274:\tlearn: 0.0928726\ttotal: 1.8s\tremaining: 1.47s\n",
      "275:\tlearn: 0.0923110\ttotal: 1.8s\tremaining: 1.46s\n",
      "276:\tlearn: 0.0919211\ttotal: 1.81s\tremaining: 1.46s\n",
      "277:\tlearn: 0.0915034\ttotal: 1.82s\tremaining: 1.46s\n",
      "278:\tlearn: 0.0911409\ttotal: 1.83s\tremaining: 1.45s\n",
      "279:\tlearn: 0.0902983\ttotal: 1.84s\tremaining: 1.45s\n",
      "280:\tlearn: 0.0898877\ttotal: 1.85s\tremaining: 1.44s\n",
      "281:\tlearn: 0.0894489\ttotal: 1.86s\tremaining: 1.44s\n",
      "282:\tlearn: 0.0883208\ttotal: 1.87s\tremaining: 1.43s\n",
      "283:\tlearn: 0.0878950\ttotal: 1.88s\tremaining: 1.43s\n",
      "284:\tlearn: 0.0873440\ttotal: 1.89s\tremaining: 1.43s\n",
      "285:\tlearn: 0.0866931\ttotal: 1.9s\tremaining: 1.42s\n",
      "286:\tlearn: 0.0862723\ttotal: 1.9s\tremaining: 1.41s\n",
      "287:\tlearn: 0.0858147\ttotal: 1.91s\tremaining: 1.41s\n",
      "288:\tlearn: 0.0853265\ttotal: 1.92s\tremaining: 1.4s\n",
      "289:\tlearn: 0.0849305\ttotal: 1.92s\tremaining: 1.39s\n",
      "290:\tlearn: 0.0845220\ttotal: 1.93s\tremaining: 1.38s\n",
      "291:\tlearn: 0.0841360\ttotal: 1.93s\tremaining: 1.38s\n",
      "292:\tlearn: 0.0836392\ttotal: 1.94s\tremaining: 1.37s\n",
      "293:\tlearn: 0.0832275\ttotal: 1.94s\tremaining: 1.36s\n",
      "294:\tlearn: 0.0828532\ttotal: 1.94s\tremaining: 1.35s\n",
      "295:\tlearn: 0.0824233\ttotal: 1.95s\tremaining: 1.34s\n",
      "296:\tlearn: 0.0821089\ttotal: 1.95s\tremaining: 1.33s\n",
      "297:\tlearn: 0.0814550\ttotal: 1.96s\tremaining: 1.33s\n",
      "298:\tlearn: 0.0811029\ttotal: 1.96s\tremaining: 1.32s\n",
      "299:\tlearn: 0.0806297\ttotal: 1.97s\tremaining: 1.31s\n",
      "300:\tlearn: 0.0803031\ttotal: 1.97s\tremaining: 1.3s\n",
      "301:\tlearn: 0.0797431\ttotal: 1.98s\tremaining: 1.29s\n",
      "302:\tlearn: 0.0793540\ttotal: 1.98s\tremaining: 1.29s\n",
      "303:\tlearn: 0.0790634\ttotal: 1.99s\tremaining: 1.28s\n",
      "304:\tlearn: 0.0790139\ttotal: 2s\tremaining: 1.28s\n",
      "305:\tlearn: 0.0786911\ttotal: 2.01s\tremaining: 1.27s\n",
      "306:\tlearn: 0.0781536\ttotal: 2.02s\tremaining: 1.27s\n",
      "307:\tlearn: 0.0777984\ttotal: 2.03s\tremaining: 1.26s\n",
      "308:\tlearn: 0.0774450\ttotal: 2.04s\tremaining: 1.26s\n",
      "309:\tlearn: 0.0770388\ttotal: 2.05s\tremaining: 1.25s\n",
      "310:\tlearn: 0.0766961\ttotal: 2.06s\tremaining: 1.25s\n",
      "311:\tlearn: 0.0763008\ttotal: 2.06s\tremaining: 1.24s\n",
      "312:\tlearn: 0.0759444\ttotal: 2.07s\tremaining: 1.24s\n",
      "313:\tlearn: 0.0758975\ttotal: 2.08s\tremaining: 1.23s\n",
      "314:\tlearn: 0.0754939\ttotal: 2.08s\tremaining: 1.22s\n",
      "315:\tlearn: 0.0750351\ttotal: 2.09s\tremaining: 1.22s\n",
      "316:\tlearn: 0.0747027\ttotal: 2.1s\tremaining: 1.21s\n",
      "317:\tlearn: 0.0743909\ttotal: 2.1s\tremaining: 1.2s\n",
      "318:\tlearn: 0.0738546\ttotal: 2.1s\tremaining: 1.19s\n",
      "319:\tlearn: 0.0735322\ttotal: 2.11s\tremaining: 1.19s\n",
      "320:\tlearn: 0.0731865\ttotal: 2.12s\tremaining: 1.18s\n",
      "321:\tlearn: 0.0728317\ttotal: 2.12s\tremaining: 1.17s\n",
      "322:\tlearn: 0.0724777\ttotal: 2.12s\tremaining: 1.16s\n",
      "323:\tlearn: 0.0721009\ttotal: 2.13s\tremaining: 1.16s\n",
      "324:\tlearn: 0.0717823\ttotal: 2.13s\tremaining: 1.15s\n",
      "325:\tlearn: 0.0713644\ttotal: 2.14s\tremaining: 1.14s\n",
      "326:\tlearn: 0.0709706\ttotal: 2.14s\tremaining: 1.13s\n",
      "327:\tlearn: 0.0705551\ttotal: 2.15s\tremaining: 1.13s\n",
      "328:\tlearn: 0.0701388\ttotal: 2.15s\tremaining: 1.12s\n",
      "329:\tlearn: 0.0697193\ttotal: 2.16s\tremaining: 1.11s\n",
      "330:\tlearn: 0.0693999\ttotal: 2.17s\tremaining: 1.11s\n",
      "331:\tlearn: 0.0689865\ttotal: 2.18s\tremaining: 1.1s\n",
      "332:\tlearn: 0.0686071\ttotal: 2.19s\tremaining: 1.1s\n",
      "333:\tlearn: 0.0683138\ttotal: 2.2s\tremaining: 1.09s\n",
      "334:\tlearn: 0.0680100\ttotal: 2.21s\tremaining: 1.09s\n",
      "335:\tlearn: 0.0677122\ttotal: 2.22s\tremaining: 1.08s\n",
      "336:\tlearn: 0.0674541\ttotal: 2.23s\tremaining: 1.08s\n",
      "337:\tlearn: 0.0671002\ttotal: 2.23s\tremaining: 1.07s\n",
      "338:\tlearn: 0.0667387\ttotal: 2.24s\tremaining: 1.06s\n",
      "339:\tlearn: 0.0664226\ttotal: 2.25s\tremaining: 1.06s\n",
      "340:\tlearn: 0.0660886\ttotal: 2.25s\tremaining: 1.05s\n",
      "341:\tlearn: 0.0657156\ttotal: 2.26s\tremaining: 1.04s\n",
      "342:\tlearn: 0.0653899\ttotal: 2.26s\tremaining: 1.03s\n",
      "343:\tlearn: 0.0651257\ttotal: 2.27s\tremaining: 1.03s\n",
      "344:\tlearn: 0.0646754\ttotal: 2.27s\tremaining: 1.02s\n",
      "345:\tlearn: 0.0644310\ttotal: 2.28s\tremaining: 1.01s\n",
      "346:\tlearn: 0.0641260\ttotal: 2.28s\tremaining: 1.01s\n",
      "347:\tlearn: 0.0638521\ttotal: 2.29s\tremaining: 999ms\n",
      "348:\tlearn: 0.0636082\ttotal: 2.29s\tremaining: 991ms\n",
      "349:\tlearn: 0.0632791\ttotal: 2.29s\tremaining: 984ms\n",
      "350:\tlearn: 0.0630004\ttotal: 2.3s\tremaining: 976ms\n",
      "351:\tlearn: 0.0627193\ttotal: 2.3s\tremaining: 969ms\n",
      "352:\tlearn: 0.0624682\ttotal: 2.31s\tremaining: 961ms\n",
      "353:\tlearn: 0.0622176\ttotal: 2.31s\tremaining: 953ms\n",
      "354:\tlearn: 0.0619074\ttotal: 2.32s\tremaining: 946ms\n",
      "355:\tlearn: 0.0614379\ttotal: 2.33s\tremaining: 941ms\n",
      "356:\tlearn: 0.0611487\ttotal: 2.33s\tremaining: 936ms\n",
      "357:\tlearn: 0.0609256\ttotal: 2.35s\tremaining: 930ms\n",
      "358:\tlearn: 0.0607230\ttotal: 2.35s\tremaining: 925ms\n",
      "359:\tlearn: 0.0603169\ttotal: 2.36s\tremaining: 920ms\n",
      "360:\tlearn: 0.0600546\ttotal: 2.37s\tremaining: 914ms\n",
      "361:\tlearn: 0.0598164\ttotal: 2.38s\tremaining: 909ms\n",
      "362:\tlearn: 0.0594438\ttotal: 2.39s\tremaining: 904ms\n",
      "363:\tlearn: 0.0592012\ttotal: 2.4s\tremaining: 897ms\n",
      "364:\tlearn: 0.0588406\ttotal: 2.41s\tremaining: 891ms\n",
      "365:\tlearn: 0.0585824\ttotal: 2.41s\tremaining: 884ms\n",
      "366:\tlearn: 0.0583042\ttotal: 2.42s\tremaining: 877ms\n",
      "367:\tlearn: 0.0580656\ttotal: 2.43s\tremaining: 870ms\n",
      "368:\tlearn: 0.0578785\ttotal: 2.43s\tremaining: 863ms\n",
      "369:\tlearn: 0.0576157\ttotal: 2.44s\tremaining: 856ms\n",
      "370:\tlearn: 0.0573688\ttotal: 2.44s\tremaining: 849ms\n",
      "371:\tlearn: 0.0571220\ttotal: 2.45s\tremaining: 842ms\n",
      "372:\tlearn: 0.0568793\ttotal: 2.45s\tremaining: 835ms\n",
      "373:\tlearn: 0.0568548\ttotal: 2.45s\tremaining: 827ms\n",
      "374:\tlearn: 0.0566042\ttotal: 2.46s\tremaining: 820ms\n",
      "375:\tlearn: 0.0563098\ttotal: 2.46s\tremaining: 812ms\n",
      "376:\tlearn: 0.0560565\ttotal: 2.47s\tremaining: 805ms\n",
      "377:\tlearn: 0.0559024\ttotal: 2.47s\tremaining: 798ms\n",
      "378:\tlearn: 0.0556844\ttotal: 2.48s\tremaining: 791ms\n",
      "379:\tlearn: 0.0554155\ttotal: 2.48s\tremaining: 783ms\n",
      "380:\tlearn: 0.0552595\ttotal: 2.49s\tremaining: 778ms\n",
      "381:\tlearn: 0.0550446\ttotal: 2.5s\tremaining: 772ms\n",
      "382:\tlearn: 0.0545861\ttotal: 2.51s\tremaining: 767ms\n",
      "383:\tlearn: 0.0542995\ttotal: 2.52s\tremaining: 761ms\n",
      "384:\tlearn: 0.0540170\ttotal: 2.53s\tremaining: 755ms\n",
      "385:\tlearn: 0.0538185\ttotal: 2.54s\tremaining: 750ms\n",
      "386:\tlearn: 0.0535913\ttotal: 2.55s\tremaining: 744ms\n",
      "387:\tlearn: 0.0533221\ttotal: 2.56s\tremaining: 739ms\n",
      "388:\tlearn: 0.0531038\ttotal: 2.56s\tremaining: 732ms\n",
      "389:\tlearn: 0.0528531\ttotal: 2.57s\tremaining: 725ms\n",
      "390:\tlearn: 0.0526406\ttotal: 2.57s\tremaining: 717ms\n",
      "391:\tlearn: 0.0522665\ttotal: 2.58s\tremaining: 710ms\n",
      "392:\tlearn: 0.0520298\ttotal: 2.58s\tremaining: 703ms\n",
      "393:\tlearn: 0.0518612\ttotal: 2.59s\tremaining: 696ms\n",
      "394:\tlearn: 0.0516113\ttotal: 2.59s\tremaining: 689ms\n",
      "395:\tlearn: 0.0513642\ttotal: 2.6s\tremaining: 682ms\n",
      "396:\tlearn: 0.0510743\ttotal: 2.6s\tremaining: 675ms\n",
      "397:\tlearn: 0.0508033\ttotal: 2.6s\tremaining: 668ms\n",
      "398:\tlearn: 0.0505773\ttotal: 2.61s\tremaining: 661ms\n",
      "399:\tlearn: 0.0504517\ttotal: 2.61s\tremaining: 653ms\n",
      "400:\tlearn: 0.0502052\ttotal: 2.62s\tremaining: 646ms\n",
      "401:\tlearn: 0.0499883\ttotal: 2.62s\tremaining: 639ms\n",
      "402:\tlearn: 0.0497770\ttotal: 2.63s\tremaining: 634ms\n",
      "403:\tlearn: 0.0495016\ttotal: 2.64s\tremaining: 628ms\n",
      "404:\tlearn: 0.0492715\ttotal: 2.65s\tremaining: 622ms\n",
      "405:\tlearn: 0.0491097\ttotal: 2.66s\tremaining: 616ms\n",
      "406:\tlearn: 0.0488503\ttotal: 2.67s\tremaining: 610ms\n",
      "407:\tlearn: 0.0486386\ttotal: 2.68s\tremaining: 604ms\n",
      "408:\tlearn: 0.0484142\ttotal: 2.69s\tremaining: 599ms\n",
      "409:\tlearn: 0.0481895\ttotal: 2.7s\tremaining: 593ms\n",
      "410:\tlearn: 0.0479332\ttotal: 2.71s\tremaining: 587ms\n",
      "411:\tlearn: 0.0477665\ttotal: 2.72s\tremaining: 581ms\n",
      "412:\tlearn: 0.0475130\ttotal: 2.73s\tremaining: 574ms\n",
      "413:\tlearn: 0.0473336\ttotal: 2.73s\tremaining: 568ms\n",
      "414:\tlearn: 0.0471480\ttotal: 2.74s\tremaining: 561ms\n",
      "415:\tlearn: 0.0469074\ttotal: 2.74s\tremaining: 554ms\n",
      "416:\tlearn: 0.0466732\ttotal: 2.75s\tremaining: 547ms\n",
      "417:\tlearn: 0.0465007\ttotal: 2.75s\tremaining: 540ms\n",
      "418:\tlearn: 0.0462900\ttotal: 2.76s\tremaining: 533ms\n",
      "419:\tlearn: 0.0460488\ttotal: 2.76s\tremaining: 526ms\n",
      "420:\tlearn: 0.0458240\ttotal: 2.77s\tremaining: 519ms\n",
      "421:\tlearn: 0.0456041\ttotal: 2.77s\tremaining: 512ms\n",
      "422:\tlearn: 0.0454544\ttotal: 2.78s\tremaining: 505ms\n",
      "423:\tlearn: 0.0453484\ttotal: 2.78s\tremaining: 498ms\n",
      "424:\tlearn: 0.0450798\ttotal: 2.78s\tremaining: 491ms\n",
      "425:\tlearn: 0.0448133\ttotal: 2.79s\tremaining: 485ms\n",
      "426:\tlearn: 0.0446353\ttotal: 2.79s\tremaining: 478ms\n",
      "427:\tlearn: 0.0443984\ttotal: 2.8s\tremaining: 471ms\n",
      "428:\tlearn: 0.0441979\ttotal: 2.8s\tremaining: 464ms\n",
      "429:\tlearn: 0.0439743\ttotal: 2.81s\tremaining: 457ms\n",
      "430:\tlearn: 0.0437816\ttotal: 2.81s\tremaining: 450ms\n",
      "431:\tlearn: 0.0435703\ttotal: 2.81s\tremaining: 443ms\n",
      "432:\tlearn: 0.0433676\ttotal: 2.82s\tremaining: 436ms\n",
      "433:\tlearn: 0.0431054\ttotal: 2.82s\tremaining: 429ms\n",
      "434:\tlearn: 0.0428922\ttotal: 2.83s\tremaining: 423ms\n",
      "435:\tlearn: 0.0426648\ttotal: 2.83s\tremaining: 416ms\n",
      "436:\tlearn: 0.0424086\ttotal: 2.84s\tremaining: 410ms\n",
      "437:\tlearn: 0.0421665\ttotal: 2.85s\tremaining: 404ms\n",
      "438:\tlearn: 0.0420046\ttotal: 2.86s\tremaining: 398ms\n",
      "439:\tlearn: 0.0417314\ttotal: 2.87s\tremaining: 392ms\n",
      "440:\tlearn: 0.0415463\ttotal: 2.88s\tremaining: 386ms\n",
      "441:\tlearn: 0.0413697\ttotal: 2.89s\tremaining: 379ms\n",
      "442:\tlearn: 0.0411146\ttotal: 2.9s\tremaining: 373ms\n",
      "443:\tlearn: 0.0409854\ttotal: 2.91s\tremaining: 367ms\n",
      "444:\tlearn: 0.0407031\ttotal: 2.92s\tremaining: 361ms\n",
      "445:\tlearn: 0.0405048\ttotal: 2.92s\tremaining: 354ms\n",
      "446:\tlearn: 0.0403372\ttotal: 2.93s\tremaining: 348ms\n",
      "447:\tlearn: 0.0401745\ttotal: 2.94s\tremaining: 341ms\n",
      "448:\tlearn: 0.0399891\ttotal: 2.94s\tremaining: 334ms\n",
      "449:\tlearn: 0.0398321\ttotal: 2.94s\tremaining: 327ms\n",
      "450:\tlearn: 0.0395968\ttotal: 2.95s\tremaining: 321ms\n",
      "451:\tlearn: 0.0394391\ttotal: 2.96s\tremaining: 314ms\n",
      "452:\tlearn: 0.0392618\ttotal: 2.96s\tremaining: 307ms\n",
      "453:\tlearn: 0.0390760\ttotal: 2.96s\tremaining: 300ms\n",
      "454:\tlearn: 0.0388338\ttotal: 2.97s\tremaining: 294ms\n",
      "455:\tlearn: 0.0387043\ttotal: 2.97s\tremaining: 287ms\n",
      "456:\tlearn: 0.0385055\ttotal: 2.98s\tremaining: 280ms\n",
      "457:\tlearn: 0.0383142\ttotal: 2.98s\tremaining: 273ms\n",
      "458:\tlearn: 0.0381693\ttotal: 2.99s\tremaining: 267ms\n",
      "459:\tlearn: 0.0379720\ttotal: 2.99s\tremaining: 260ms\n",
      "460:\tlearn: 0.0378033\ttotal: 3s\tremaining: 254ms\n",
      "461:\tlearn: 0.0376148\ttotal: 3.01s\tremaining: 248ms\n",
      "462:\tlearn: 0.0374074\ttotal: 3.02s\tremaining: 241ms\n",
      "463:\tlearn: 0.0372000\ttotal: 3.03s\tremaining: 235ms\n",
      "464:\tlearn: 0.0370134\ttotal: 3.04s\tremaining: 229ms\n",
      "465:\tlearn: 0.0368290\ttotal: 3.05s\tremaining: 222ms\n",
      "466:\tlearn: 0.0366652\ttotal: 3.06s\tremaining: 216ms\n",
      "467:\tlearn: 0.0363988\ttotal: 3.07s\tremaining: 210ms\n",
      "468:\tlearn: 0.0361250\ttotal: 3.08s\tremaining: 203ms\n",
      "469:\tlearn: 0.0359376\ttotal: 3.09s\tremaining: 197ms\n",
      "470:\tlearn: 0.0357689\ttotal: 3.09s\tremaining: 191ms\n",
      "471:\tlearn: 0.0356258\ttotal: 3.1s\tremaining: 184ms\n",
      "472:\tlearn: 0.0354616\ttotal: 3.11s\tremaining: 177ms\n",
      "473:\tlearn: 0.0352982\ttotal: 3.11s\tremaining: 171ms\n",
      "474:\tlearn: 0.0351465\ttotal: 3.12s\tremaining: 164ms\n",
      "475:\tlearn: 0.0349476\ttotal: 3.13s\tremaining: 158ms\n",
      "476:\tlearn: 0.0347149\ttotal: 3.13s\tremaining: 151ms\n",
      "477:\tlearn: 0.0345745\ttotal: 3.14s\tremaining: 144ms\n",
      "478:\tlearn: 0.0344370\ttotal: 3.14s\tremaining: 138ms\n",
      "479:\tlearn: 0.0343112\ttotal: 3.15s\tremaining: 131ms\n",
      "480:\tlearn: 0.0342140\ttotal: 3.15s\tremaining: 124ms\n",
      "481:\tlearn: 0.0340652\ttotal: 3.15s\tremaining: 118ms\n",
      "482:\tlearn: 0.0338874\ttotal: 3.16s\tremaining: 111ms\n",
      "483:\tlearn: 0.0337251\ttotal: 3.16s\tremaining: 105ms\n",
      "484:\tlearn: 0.0335989\ttotal: 3.17s\tremaining: 98ms\n",
      "485:\tlearn: 0.0334518\ttotal: 3.17s\tremaining: 91.4ms\n",
      "486:\tlearn: 0.0333422\ttotal: 3.18s\tremaining: 84.8ms\n",
      "487:\tlearn: 0.0331807\ttotal: 3.18s\tremaining: 78.2ms\n",
      "488:\tlearn: 0.0330297\ttotal: 3.19s\tremaining: 71.7ms\n",
      "489:\tlearn: 0.0329188\ttotal: 3.19s\tremaining: 65.1ms\n",
      "490:\tlearn: 0.0327951\ttotal: 3.19s\tremaining: 58.6ms\n",
      "491:\tlearn: 0.0326558\ttotal: 3.21s\tremaining: 52.1ms\n",
      "492:\tlearn: 0.0325207\ttotal: 3.21s\tremaining: 45.6ms\n",
      "493:\tlearn: 0.0323729\ttotal: 3.22s\tremaining: 39.2ms\n",
      "494:\tlearn: 0.0322651\ttotal: 3.23s\tremaining: 32.7ms\n",
      "495:\tlearn: 0.0321671\ttotal: 3.24s\tremaining: 26.2ms\n",
      "496:\tlearn: 0.0319897\ttotal: 3.25s\tremaining: 19.6ms\n",
      "497:\tlearn: 0.0318610\ttotal: 3.26s\tremaining: 13.1ms\n",
      "498:\tlearn: 0.0317246\ttotal: 3.27s\tremaining: 6.56ms\n",
      "499:\tlearn: 0.0315348\ttotal: 3.28s\tremaining: 0us\n",
      "0:\tlearn: 0.6804790\ttotal: 4.67ms\tremaining: 2.33s\n",
      "1:\tlearn: 0.6696726\ttotal: 9.33ms\tremaining: 2.32s\n",
      "2:\tlearn: 0.6589276\ttotal: 13.6ms\tremaining: 2.26s\n",
      "3:\tlearn: 0.6461868\ttotal: 17.9ms\tremaining: 2.21s\n",
      "4:\tlearn: 0.6369796\ttotal: 22.2ms\tremaining: 2.2s\n",
      "5:\tlearn: 0.6298920\ttotal: 26.4ms\tremaining: 2.17s\n",
      "6:\tlearn: 0.6222694\ttotal: 30.6ms\tremaining: 2.15s\n",
      "7:\tlearn: 0.6135167\ttotal: 34.6ms\tremaining: 2.13s\n",
      "8:\tlearn: 0.6056303\ttotal: 38.9ms\tremaining: 2.12s\n",
      "9:\tlearn: 0.5997151\ttotal: 43.2ms\tremaining: 2.12s\n",
      "10:\tlearn: 0.5924225\ttotal: 47.6ms\tremaining: 2.12s\n",
      "11:\tlearn: 0.5866128\ttotal: 51.9ms\tremaining: 2.11s\n",
      "12:\tlearn: 0.5795638\ttotal: 61.6ms\tremaining: 2.31s\n",
      "13:\tlearn: 0.5751160\ttotal: 71ms\tremaining: 2.46s\n",
      "14:\tlearn: 0.5658151\ttotal: 80.5ms\tremaining: 2.6s\n",
      "15:\tlearn: 0.5551403\ttotal: 91.5ms\tremaining: 2.77s\n",
      "16:\tlearn: 0.5496398\ttotal: 101ms\tremaining: 2.88s\n",
      "17:\tlearn: 0.5459360\ttotal: 111ms\tremaining: 2.98s\n",
      "18:\tlearn: 0.5394096\ttotal: 122ms\tremaining: 3.09s\n",
      "19:\tlearn: 0.5347667\ttotal: 132ms\tremaining: 3.17s\n",
      "20:\tlearn: 0.5305082\ttotal: 142ms\tremaining: 3.24s\n",
      "21:\tlearn: 0.5254299\ttotal: 154ms\tremaining: 3.34s\n",
      "22:\tlearn: 0.5199492\ttotal: 164ms\tremaining: 3.4s\n",
      "23:\tlearn: 0.5151061\ttotal: 173ms\tremaining: 3.43s\n",
      "24:\tlearn: 0.5113010\ttotal: 182ms\tremaining: 3.46s\n",
      "25:\tlearn: 0.5041991\ttotal: 192ms\tremaining: 3.49s\n",
      "26:\tlearn: 0.4992222\ttotal: 201ms\tremaining: 3.52s\n",
      "27:\tlearn: 0.4960968\ttotal: 208ms\tremaining: 3.5s\n",
      "28:\tlearn: 0.4913938\ttotal: 212ms\tremaining: 3.44s\n",
      "29:\tlearn: 0.4869974\ttotal: 216ms\tremaining: 3.38s\n",
      "30:\tlearn: 0.4820385\ttotal: 219ms\tremaining: 3.32s\n",
      "31:\tlearn: 0.4796077\ttotal: 223ms\tremaining: 3.26s\n",
      "32:\tlearn: 0.4761648\ttotal: 226ms\tremaining: 3.2s\n",
      "33:\tlearn: 0.4721503\ttotal: 230ms\tremaining: 3.15s\n",
      "34:\tlearn: 0.4680195\ttotal: 234ms\tremaining: 3.11s\n",
      "35:\tlearn: 0.4639310\ttotal: 243ms\tremaining: 3.14s\n",
      "36:\tlearn: 0.4612681\ttotal: 253ms\tremaining: 3.16s\n",
      "37:\tlearn: 0.4570335\ttotal: 262ms\tremaining: 3.19s\n",
      "38:\tlearn: 0.4528479\ttotal: 272ms\tremaining: 3.21s\n",
      "39:\tlearn: 0.4488474\ttotal: 281ms\tremaining: 3.23s\n",
      "40:\tlearn: 0.4463596\ttotal: 290ms\tremaining: 3.25s\n",
      "41:\tlearn: 0.4433980\ttotal: 299ms\tremaining: 3.27s\n",
      "42:\tlearn: 0.4399732\ttotal: 309ms\tremaining: 3.28s\n",
      "43:\tlearn: 0.4355484\ttotal: 318ms\tremaining: 3.3s\n",
      "44:\tlearn: 0.4316271\ttotal: 323ms\tremaining: 3.26s\n",
      "45:\tlearn: 0.4282767\ttotal: 327ms\tremaining: 3.23s\n",
      "46:\tlearn: 0.4240969\ttotal: 332ms\tremaining: 3.2s\n",
      "47:\tlearn: 0.4185613\ttotal: 335ms\tremaining: 3.16s\n",
      "48:\tlearn: 0.4162185\ttotal: 339ms\tremaining: 3.12s\n",
      "49:\tlearn: 0.4130472\ttotal: 343ms\tremaining: 3.09s\n",
      "50:\tlearn: 0.4096063\ttotal: 347ms\tremaining: 3.05s\n",
      "51:\tlearn: 0.4067882\ttotal: 350ms\tremaining: 3.01s\n",
      "52:\tlearn: 0.4044297\ttotal: 354ms\tremaining: 2.99s\n",
      "53:\tlearn: 0.3969454\ttotal: 358ms\tremaining: 2.95s\n",
      "54:\tlearn: 0.3946725\ttotal: 361ms\tremaining: 2.92s\n",
      "55:\tlearn: 0.3918548\ttotal: 365ms\tremaining: 2.89s\n",
      "56:\tlearn: 0.3894116\ttotal: 369ms\tremaining: 2.86s\n",
      "57:\tlearn: 0.3860399\ttotal: 372ms\tremaining: 2.84s\n",
      "58:\tlearn: 0.3822501\ttotal: 377ms\tremaining: 2.81s\n",
      "59:\tlearn: 0.3794600\ttotal: 387ms\tremaining: 2.83s\n",
      "60:\tlearn: 0.3765060\ttotal: 396ms\tremaining: 2.85s\n",
      "61:\tlearn: 0.3726313\ttotal: 405ms\tremaining: 2.86s\n",
      "62:\tlearn: 0.3700073\ttotal: 415ms\tremaining: 2.88s\n",
      "63:\tlearn: 0.3666656\ttotal: 424ms\tremaining: 2.89s\n",
      "64:\tlearn: 0.3641870\ttotal: 433ms\tremaining: 2.9s\n",
      "65:\tlearn: 0.3609680\ttotal: 443ms\tremaining: 2.91s\n",
      "66:\tlearn: 0.3581188\ttotal: 452ms\tremaining: 2.92s\n",
      "67:\tlearn: 0.3552192\ttotal: 462ms\tremaining: 2.93s\n",
      "68:\tlearn: 0.3527620\ttotal: 471ms\tremaining: 2.94s\n",
      "69:\tlearn: 0.3510691\ttotal: 481ms\tremaining: 2.95s\n",
      "70:\tlearn: 0.3482808\ttotal: 487ms\tremaining: 2.94s\n",
      "71:\tlearn: 0.3458245\ttotal: 493ms\tremaining: 2.93s\n",
      "72:\tlearn: 0.3440015\ttotal: 499ms\tremaining: 2.92s\n",
      "73:\tlearn: 0.3402892\ttotal: 505ms\tremaining: 2.91s\n",
      "74:\tlearn: 0.3377321\ttotal: 511ms\tremaining: 2.9s\n",
      "75:\tlearn: 0.3353708\ttotal: 516ms\tremaining: 2.88s\n",
      "76:\tlearn: 0.3331489\ttotal: 521ms\tremaining: 2.86s\n",
      "77:\tlearn: 0.3310661\ttotal: 526ms\tremaining: 2.85s\n",
      "78:\tlearn: 0.3285551\ttotal: 532ms\tremaining: 2.83s\n",
      "79:\tlearn: 0.3259429\ttotal: 538ms\tremaining: 2.82s\n",
      "80:\tlearn: 0.3216560\ttotal: 542ms\tremaining: 2.8s\n",
      "81:\tlearn: 0.3197726\ttotal: 546ms\tremaining: 2.78s\n",
      "82:\tlearn: 0.3176158\ttotal: 550ms\tremaining: 2.77s\n",
      "83:\tlearn: 0.3139774\ttotal: 555ms\tremaining: 2.75s\n",
      "84:\tlearn: 0.3118733\ttotal: 559ms\tremaining: 2.73s\n",
      "85:\tlearn: 0.3092521\ttotal: 563ms\tremaining: 2.71s\n",
      "86:\tlearn: 0.3051963\ttotal: 573ms\tremaining: 2.72s\n",
      "87:\tlearn: 0.3030901\ttotal: 583ms\tremaining: 2.73s\n",
      "88:\tlearn: 0.3008626\ttotal: 592ms\tremaining: 2.73s\n",
      "89:\tlearn: 0.2987908\ttotal: 602ms\tremaining: 2.74s\n",
      "90:\tlearn: 0.2971756\ttotal: 611ms\tremaining: 2.75s\n",
      "91:\tlearn: 0.2949573\ttotal: 620ms\tremaining: 2.75s\n",
      "92:\tlearn: 0.2925164\ttotal: 631ms\tremaining: 2.76s\n",
      "93:\tlearn: 0.2908575\ttotal: 640ms\tremaining: 2.76s\n",
      "94:\tlearn: 0.2882826\ttotal: 650ms\tremaining: 2.77s\n",
      "95:\tlearn: 0.2861059\ttotal: 657ms\tremaining: 2.76s\n",
      "96:\tlearn: 0.2841777\ttotal: 663ms\tremaining: 2.75s\n",
      "97:\tlearn: 0.2822736\ttotal: 669ms\tremaining: 2.75s\n",
      "98:\tlearn: 0.2804937\ttotal: 676ms\tremaining: 2.74s\n",
      "99:\tlearn: 0.2773803\ttotal: 682ms\tremaining: 2.73s\n",
      "100:\tlearn: 0.2752253\ttotal: 686ms\tremaining: 2.71s\n",
      "101:\tlearn: 0.2736928\ttotal: 691ms\tremaining: 2.7s\n",
      "102:\tlearn: 0.2720052\ttotal: 696ms\tremaining: 2.68s\n",
      "103:\tlearn: 0.2700153\ttotal: 701ms\tremaining: 2.67s\n",
      "104:\tlearn: 0.2682358\ttotal: 705ms\tremaining: 2.65s\n",
      "105:\tlearn: 0.2664008\ttotal: 710ms\tremaining: 2.64s\n",
      "106:\tlearn: 0.2631578\ttotal: 715ms\tremaining: 2.63s\n",
      "107:\tlearn: 0.2607556\ttotal: 719ms\tremaining: 2.61s\n",
      "108:\tlearn: 0.2585978\ttotal: 723ms\tremaining: 2.59s\n",
      "109:\tlearn: 0.2564806\ttotal: 727ms\tremaining: 2.58s\n",
      "110:\tlearn: 0.2550835\ttotal: 730ms\tremaining: 2.56s\n",
      "111:\tlearn: 0.2533755\ttotal: 734ms\tremaining: 2.54s\n",
      "112:\tlearn: 0.2503353\ttotal: 741ms\tremaining: 2.54s\n",
      "113:\tlearn: 0.2487927\ttotal: 751ms\tremaining: 2.54s\n",
      "114:\tlearn: 0.2471960\ttotal: 761ms\tremaining: 2.55s\n",
      "115:\tlearn: 0.2458112\ttotal: 771ms\tremaining: 2.55s\n",
      "116:\tlearn: 0.2442936\ttotal: 781ms\tremaining: 2.56s\n",
      "117:\tlearn: 0.2425430\ttotal: 790ms\tremaining: 2.56s\n",
      "118:\tlearn: 0.2396537\ttotal: 800ms\tremaining: 2.56s\n",
      "119:\tlearn: 0.2383531\ttotal: 810ms\tremaining: 2.56s\n",
      "120:\tlearn: 0.2368486\ttotal: 820ms\tremaining: 2.57s\n",
      "121:\tlearn: 0.2349205\ttotal: 829ms\tremaining: 2.57s\n",
      "122:\tlearn: 0.2335096\ttotal: 835ms\tremaining: 2.56s\n",
      "123:\tlearn: 0.2319029\ttotal: 841ms\tremaining: 2.55s\n",
      "124:\tlearn: 0.2306346\ttotal: 847ms\tremaining: 2.54s\n",
      "125:\tlearn: 0.2288980\ttotal: 854ms\tremaining: 2.53s\n",
      "126:\tlearn: 0.2263751\ttotal: 859ms\tremaining: 2.52s\n",
      "127:\tlearn: 0.2246162\ttotal: 863ms\tremaining: 2.51s\n",
      "128:\tlearn: 0.2233371\ttotal: 868ms\tremaining: 2.5s\n",
      "129:\tlearn: 0.2219251\ttotal: 873ms\tremaining: 2.48s\n",
      "130:\tlearn: 0.2205467\ttotal: 877ms\tremaining: 2.47s\n",
      "131:\tlearn: 0.2191858\ttotal: 882ms\tremaining: 2.46s\n",
      "132:\tlearn: 0.2178162\ttotal: 886ms\tremaining: 2.44s\n",
      "133:\tlearn: 0.2163484\ttotal: 891ms\tremaining: 2.43s\n",
      "134:\tlearn: 0.2151883\ttotal: 895ms\tremaining: 2.42s\n",
      "135:\tlearn: 0.2138842\ttotal: 899ms\tremaining: 2.41s\n",
      "136:\tlearn: 0.2117545\ttotal: 903ms\tremaining: 2.39s\n",
      "137:\tlearn: 0.2105324\ttotal: 909ms\tremaining: 2.38s\n",
      "138:\tlearn: 0.2093830\ttotal: 919ms\tremaining: 2.38s\n",
      "139:\tlearn: 0.2080815\ttotal: 928ms\tremaining: 2.39s\n",
      "140:\tlearn: 0.2070158\ttotal: 938ms\tremaining: 2.39s\n",
      "141:\tlearn: 0.2054743\ttotal: 948ms\tremaining: 2.39s\n",
      "142:\tlearn: 0.2042493\ttotal: 958ms\tremaining: 2.39s\n",
      "143:\tlearn: 0.2031641\ttotal: 967ms\tremaining: 2.39s\n",
      "144:\tlearn: 0.2021478\ttotal: 977ms\tremaining: 2.39s\n",
      "145:\tlearn: 0.2003041\ttotal: 987ms\tremaining: 2.39s\n",
      "146:\tlearn: 0.1990476\ttotal: 996ms\tremaining: 2.39s\n",
      "147:\tlearn: 0.1980510\ttotal: 1s\tremaining: 2.38s\n",
      "148:\tlearn: 0.1968287\ttotal: 1.01s\tremaining: 2.37s\n",
      "149:\tlearn: 0.1956048\ttotal: 1.02s\tremaining: 2.38s\n",
      "150:\tlearn: 0.1944381\ttotal: 1.03s\tremaining: 2.38s\n",
      "151:\tlearn: 0.1932690\ttotal: 1.03s\tremaining: 2.37s\n",
      "152:\tlearn: 0.1920777\ttotal: 1.04s\tremaining: 2.36s\n",
      "153:\tlearn: 0.1908159\ttotal: 1.05s\tremaining: 2.35s\n",
      "154:\tlearn: 0.1898391\ttotal: 1.05s\tremaining: 2.34s\n",
      "155:\tlearn: 0.1888426\ttotal: 1.05s\tremaining: 2.33s\n",
      "156:\tlearn: 0.1877225\ttotal: 1.06s\tremaining: 2.31s\n",
      "157:\tlearn: 0.1867324\ttotal: 1.06s\tremaining: 2.3s\n",
      "158:\tlearn: 0.1855192\ttotal: 1.07s\tremaining: 2.29s\n",
      "159:\tlearn: 0.1845990\ttotal: 1.07s\tremaining: 2.28s\n",
      "160:\tlearn: 0.1835099\ttotal: 1.08s\tremaining: 2.27s\n",
      "161:\tlearn: 0.1825747\ttotal: 1.08s\tremaining: 2.26s\n",
      "162:\tlearn: 0.1805501\ttotal: 1.09s\tremaining: 2.25s\n",
      "163:\tlearn: 0.1796943\ttotal: 1.09s\tremaining: 2.23s\n",
      "164:\tlearn: 0.1784439\ttotal: 1.09s\tremaining: 2.22s\n",
      "165:\tlearn: 0.1774545\ttotal: 1.1s\tremaining: 2.21s\n",
      "166:\tlearn: 0.1762491\ttotal: 1.1s\tremaining: 2.19s\n",
      "167:\tlearn: 0.1735595\ttotal: 1.1s\tremaining: 2.18s\n",
      "168:\tlearn: 0.1724992\ttotal: 1.11s\tremaining: 2.18s\n",
      "169:\tlearn: 0.1713350\ttotal: 1.12s\tremaining: 2.18s\n",
      "170:\tlearn: 0.1703880\ttotal: 1.13s\tremaining: 2.17s\n",
      "171:\tlearn: 0.1690048\ttotal: 1.14s\tremaining: 2.17s\n",
      "172:\tlearn: 0.1679468\ttotal: 1.15s\tremaining: 2.17s\n",
      "173:\tlearn: 0.1669512\ttotal: 1.16s\tremaining: 2.17s\n",
      "174:\tlearn: 0.1660792\ttotal: 1.17s\tremaining: 2.17s\n",
      "175:\tlearn: 0.1651298\ttotal: 1.18s\tremaining: 2.17s\n",
      "176:\tlearn: 0.1642744\ttotal: 1.19s\tremaining: 2.17s\n",
      "177:\tlearn: 0.1635337\ttotal: 1.2s\tremaining: 2.17s\n",
      "178:\tlearn: 0.1628216\ttotal: 1.2s\tremaining: 2.16s\n",
      "179:\tlearn: 0.1619100\ttotal: 1.21s\tremaining: 2.15s\n",
      "180:\tlearn: 0.1602922\ttotal: 1.22s\tremaining: 2.15s\n",
      "181:\tlearn: 0.1595215\ttotal: 1.22s\tremaining: 2.14s\n",
      "182:\tlearn: 0.1586849\ttotal: 1.23s\tremaining: 2.13s\n",
      "183:\tlearn: 0.1575736\ttotal: 1.23s\tremaining: 2.12s\n",
      "184:\tlearn: 0.1569019\ttotal: 1.24s\tremaining: 2.11s\n",
      "185:\tlearn: 0.1555642\ttotal: 1.24s\tremaining: 2.1s\n",
      "186:\tlearn: 0.1546250\ttotal: 1.25s\tremaining: 2.09s\n",
      "187:\tlearn: 0.1537777\ttotal: 1.25s\tremaining: 2.08s\n",
      "188:\tlearn: 0.1530463\ttotal: 1.26s\tremaining: 2.07s\n",
      "189:\tlearn: 0.1522022\ttotal: 1.26s\tremaining: 2.06s\n",
      "190:\tlearn: 0.1512517\ttotal: 1.27s\tremaining: 2.05s\n",
      "191:\tlearn: 0.1505504\ttotal: 1.27s\tremaining: 2.04s\n",
      "192:\tlearn: 0.1496321\ttotal: 1.27s\tremaining: 2.03s\n",
      "193:\tlearn: 0.1488003\ttotal: 1.28s\tremaining: 2.02s\n",
      "194:\tlearn: 0.1480365\ttotal: 1.29s\tremaining: 2.02s\n",
      "195:\tlearn: 0.1472596\ttotal: 1.3s\tremaining: 2.02s\n",
      "196:\tlearn: 0.1455545\ttotal: 1.31s\tremaining: 2.01s\n",
      "197:\tlearn: 0.1443484\ttotal: 1.32s\tremaining: 2.01s\n",
      "198:\tlearn: 0.1437290\ttotal: 1.33s\tremaining: 2.01s\n",
      "199:\tlearn: 0.1432587\ttotal: 1.34s\tremaining: 2.01s\n",
      "200:\tlearn: 0.1424746\ttotal: 1.35s\tremaining: 2s\n",
      "201:\tlearn: 0.1415644\ttotal: 1.36s\tremaining: 2s\n",
      "202:\tlearn: 0.1408281\ttotal: 1.37s\tremaining: 2s\n",
      "203:\tlearn: 0.1398233\ttotal: 1.38s\tremaining: 2s\n",
      "204:\tlearn: 0.1390035\ttotal: 1.38s\tremaining: 1.99s\n",
      "205:\tlearn: 0.1383609\ttotal: 1.39s\tremaining: 1.98s\n",
      "206:\tlearn: 0.1375843\ttotal: 1.39s\tremaining: 1.97s\n",
      "207:\tlearn: 0.1365868\ttotal: 1.4s\tremaining: 1.97s\n",
      "208:\tlearn: 0.1352807\ttotal: 1.4s\tremaining: 1.96s\n",
      "209:\tlearn: 0.1345635\ttotal: 1.41s\tremaining: 1.95s\n",
      "210:\tlearn: 0.1337882\ttotal: 1.41s\tremaining: 1.94s\n",
      "211:\tlearn: 0.1328845\ttotal: 1.42s\tremaining: 1.93s\n",
      "212:\tlearn: 0.1321791\ttotal: 1.42s\tremaining: 1.92s\n",
      "213:\tlearn: 0.1312917\ttotal: 1.43s\tremaining: 1.91s\n",
      "214:\tlearn: 0.1305866\ttotal: 1.43s\tremaining: 1.9s\n",
      "215:\tlearn: 0.1297703\ttotal: 1.44s\tremaining: 1.89s\n",
      "216:\tlearn: 0.1290739\ttotal: 1.44s\tremaining: 1.88s\n",
      "217:\tlearn: 0.1284109\ttotal: 1.45s\tremaining: 1.87s\n",
      "218:\tlearn: 0.1276324\ttotal: 1.45s\tremaining: 1.86s\n",
      "219:\tlearn: 0.1270893\ttotal: 1.45s\tremaining: 1.85s\n",
      "220:\tlearn: 0.1263436\ttotal: 1.46s\tremaining: 1.84s\n",
      "221:\tlearn: 0.1259580\ttotal: 1.46s\tremaining: 1.83s\n",
      "222:\tlearn: 0.1250350\ttotal: 1.48s\tremaining: 1.83s\n",
      "223:\tlearn: 0.1244485\ttotal: 1.49s\tremaining: 1.83s\n",
      "224:\tlearn: 0.1238483\ttotal: 1.5s\tremaining: 1.83s\n",
      "225:\tlearn: 0.1231486\ttotal: 1.5s\tremaining: 1.82s\n",
      "226:\tlearn: 0.1224842\ttotal: 1.52s\tremaining: 1.82s\n",
      "227:\tlearn: 0.1218708\ttotal: 1.52s\tremaining: 1.82s\n",
      "228:\tlearn: 0.1212626\ttotal: 1.53s\tremaining: 1.81s\n",
      "229:\tlearn: 0.1206459\ttotal: 1.54s\tremaining: 1.8s\n",
      "230:\tlearn: 0.1198984\ttotal: 1.54s\tremaining: 1.8s\n",
      "231:\tlearn: 0.1193336\ttotal: 1.55s\tremaining: 1.79s\n",
      "232:\tlearn: 0.1187241\ttotal: 1.55s\tremaining: 1.78s\n",
      "233:\tlearn: 0.1180643\ttotal: 1.56s\tremaining: 1.77s\n",
      "234:\tlearn: 0.1174532\ttotal: 1.56s\tremaining: 1.76s\n",
      "235:\tlearn: 0.1169586\ttotal: 1.57s\tremaining: 1.75s\n",
      "236:\tlearn: 0.1165340\ttotal: 1.57s\tremaining: 1.74s\n",
      "237:\tlearn: 0.1152071\ttotal: 1.57s\tremaining: 1.73s\n",
      "238:\tlearn: 0.1141147\ttotal: 1.58s\tremaining: 1.73s\n",
      "239:\tlearn: 0.1135589\ttotal: 1.58s\tremaining: 1.72s\n",
      "240:\tlearn: 0.1129194\ttotal: 1.59s\tremaining: 1.71s\n",
      "241:\tlearn: 0.1123953\ttotal: 1.59s\tremaining: 1.7s\n",
      "242:\tlearn: 0.1117521\ttotal: 1.6s\tremaining: 1.69s\n",
      "243:\tlearn: 0.1112139\ttotal: 1.6s\tremaining: 1.68s\n",
      "244:\tlearn: 0.1104574\ttotal: 1.61s\tremaining: 1.68s\n",
      "245:\tlearn: 0.1097971\ttotal: 1.62s\tremaining: 1.67s\n",
      "246:\tlearn: 0.1093128\ttotal: 1.63s\tremaining: 1.67s\n",
      "247:\tlearn: 0.1088321\ttotal: 1.64s\tremaining: 1.67s\n",
      "248:\tlearn: 0.1083125\ttotal: 1.65s\tremaining: 1.66s\n",
      "249:\tlearn: 0.1077122\ttotal: 1.66s\tremaining: 1.66s\n",
      "250:\tlearn: 0.1067087\ttotal: 1.67s\tremaining: 1.66s\n",
      "251:\tlearn: 0.1061349\ttotal: 1.68s\tremaining: 1.65s\n",
      "252:\tlearn: 0.1055606\ttotal: 1.68s\tremaining: 1.64s\n",
      "253:\tlearn: 0.1050436\ttotal: 1.69s\tremaining: 1.64s\n",
      "254:\tlearn: 0.1044417\ttotal: 1.7s\tremaining: 1.63s\n",
      "255:\tlearn: 0.1037615\ttotal: 1.7s\tremaining: 1.62s\n",
      "256:\tlearn: 0.1030110\ttotal: 1.71s\tremaining: 1.61s\n",
      "257:\tlearn: 0.1022346\ttotal: 1.71s\tremaining: 1.6s\n",
      "258:\tlearn: 0.1016867\ttotal: 1.72s\tremaining: 1.6s\n",
      "259:\tlearn: 0.1011804\ttotal: 1.72s\tremaining: 1.59s\n",
      "260:\tlearn: 0.1006505\ttotal: 1.73s\tremaining: 1.58s\n",
      "261:\tlearn: 0.1000315\ttotal: 1.73s\tremaining: 1.57s\n",
      "262:\tlearn: 0.0994503\ttotal: 1.73s\tremaining: 1.56s\n",
      "263:\tlearn: 0.0989998\ttotal: 1.74s\tremaining: 1.55s\n",
      "264:\tlearn: 0.0985028\ttotal: 1.74s\tremaining: 1.54s\n",
      "265:\tlearn: 0.0979570\ttotal: 1.75s\tremaining: 1.54s\n",
      "266:\tlearn: 0.0973773\ttotal: 1.75s\tremaining: 1.53s\n",
      "267:\tlearn: 0.0968172\ttotal: 1.75s\tremaining: 1.52s\n",
      "268:\tlearn: 0.0963479\ttotal: 1.76s\tremaining: 1.51s\n",
      "269:\tlearn: 0.0956570\ttotal: 1.77s\tremaining: 1.51s\n",
      "270:\tlearn: 0.0952038\ttotal: 1.78s\tremaining: 1.51s\n",
      "271:\tlearn: 0.0946145\ttotal: 1.79s\tremaining: 1.5s\n",
      "272:\tlearn: 0.0939697\ttotal: 1.8s\tremaining: 1.5s\n",
      "273:\tlearn: 0.0935236\ttotal: 1.81s\tremaining: 1.49s\n",
      "274:\tlearn: 0.0930686\ttotal: 1.82s\tremaining: 1.49s\n",
      "275:\tlearn: 0.0925329\ttotal: 1.83s\tremaining: 1.49s\n",
      "276:\tlearn: 0.0920710\ttotal: 1.84s\tremaining: 1.48s\n",
      "277:\tlearn: 0.0916594\ttotal: 1.84s\tremaining: 1.47s\n",
      "278:\tlearn: 0.0910824\ttotal: 1.85s\tremaining: 1.46s\n",
      "279:\tlearn: 0.0906698\ttotal: 1.85s\tremaining: 1.46s\n",
      "280:\tlearn: 0.0899385\ttotal: 1.86s\tremaining: 1.45s\n",
      "281:\tlearn: 0.0894524\ttotal: 1.86s\tremaining: 1.44s\n",
      "282:\tlearn: 0.0890624\ttotal: 1.87s\tremaining: 1.43s\n",
      "283:\tlearn: 0.0885967\ttotal: 1.87s\tremaining: 1.42s\n",
      "284:\tlearn: 0.0881182\ttotal: 1.88s\tremaining: 1.42s\n",
      "285:\tlearn: 0.0875465\ttotal: 1.88s\tremaining: 1.41s\n",
      "286:\tlearn: 0.0871735\ttotal: 1.88s\tremaining: 1.4s\n",
      "287:\tlearn: 0.0867914\ttotal: 1.89s\tremaining: 1.39s\n",
      "288:\tlearn: 0.0864170\ttotal: 1.89s\tremaining: 1.38s\n",
      "289:\tlearn: 0.0860356\ttotal: 1.9s\tremaining: 1.37s\n",
      "290:\tlearn: 0.0855748\ttotal: 1.91s\tremaining: 1.37s\n",
      "291:\tlearn: 0.0851045\ttotal: 1.92s\tremaining: 1.36s\n",
      "292:\tlearn: 0.0848235\ttotal: 1.93s\tremaining: 1.36s\n",
      "293:\tlearn: 0.0844126\ttotal: 1.94s\tremaining: 1.36s\n",
      "294:\tlearn: 0.0839939\ttotal: 1.95s\tremaining: 1.35s\n",
      "295:\tlearn: 0.0836044\ttotal: 1.96s\tremaining: 1.35s\n",
      "296:\tlearn: 0.0831062\ttotal: 1.97s\tremaining: 1.34s\n",
      "297:\tlearn: 0.0826600\ttotal: 1.98s\tremaining: 1.34s\n",
      "298:\tlearn: 0.0821570\ttotal: 1.98s\tremaining: 1.33s\n",
      "299:\tlearn: 0.0817952\ttotal: 1.99s\tremaining: 1.32s\n",
      "300:\tlearn: 0.0814618\ttotal: 2s\tremaining: 1.32s\n",
      "301:\tlearn: 0.0811500\ttotal: 2s\tremaining: 1.31s\n",
      "302:\tlearn: 0.0808253\ttotal: 2.01s\tremaining: 1.31s\n",
      "303:\tlearn: 0.0804951\ttotal: 2.01s\tremaining: 1.3s\n",
      "304:\tlearn: 0.0800633\ttotal: 2.02s\tremaining: 1.29s\n",
      "305:\tlearn: 0.0796308\ttotal: 2.02s\tremaining: 1.28s\n",
      "306:\tlearn: 0.0792462\ttotal: 2.03s\tremaining: 1.27s\n",
      "307:\tlearn: 0.0790111\ttotal: 2.03s\tremaining: 1.27s\n",
      "308:\tlearn: 0.0787222\ttotal: 2.04s\tremaining: 1.26s\n",
      "309:\tlearn: 0.0783906\ttotal: 2.04s\tremaining: 1.25s\n",
      "310:\tlearn: 0.0780397\ttotal: 2.04s\tremaining: 1.24s\n",
      "311:\tlearn: 0.0775440\ttotal: 2.05s\tremaining: 1.23s\n",
      "312:\tlearn: 0.0772021\ttotal: 2.05s\tremaining: 1.23s\n",
      "313:\tlearn: 0.0769564\ttotal: 2.06s\tremaining: 1.22s\n",
      "314:\tlearn: 0.0765796\ttotal: 2.06s\tremaining: 1.21s\n",
      "315:\tlearn: 0.0762671\ttotal: 2.07s\tremaining: 1.2s\n",
      "316:\tlearn: 0.0757989\ttotal: 2.08s\tremaining: 1.2s\n",
      "317:\tlearn: 0.0753697\ttotal: 2.09s\tremaining: 1.19s\n",
      "318:\tlearn: 0.0749584\ttotal: 2.1s\tremaining: 1.19s\n",
      "319:\tlearn: 0.0745908\ttotal: 2.1s\tremaining: 1.18s\n",
      "320:\tlearn: 0.0743022\ttotal: 2.12s\tremaining: 1.18s\n",
      "321:\tlearn: 0.0740658\ttotal: 2.12s\tremaining: 1.17s\n",
      "322:\tlearn: 0.0735196\ttotal: 2.13s\tremaining: 1.17s\n",
      "323:\tlearn: 0.0731907\ttotal: 2.14s\tremaining: 1.16s\n",
      "324:\tlearn: 0.0729150\ttotal: 2.15s\tremaining: 1.16s\n",
      "325:\tlearn: 0.0725685\ttotal: 2.16s\tremaining: 1.15s\n",
      "326:\tlearn: 0.0722145\ttotal: 2.17s\tremaining: 1.15s\n",
      "327:\tlearn: 0.0717926\ttotal: 2.17s\tremaining: 1.14s\n",
      "328:\tlearn: 0.0713821\ttotal: 2.17s\tremaining: 1.13s\n",
      "329:\tlearn: 0.0710200\ttotal: 2.18s\tremaining: 1.12s\n",
      "330:\tlearn: 0.0707169\ttotal: 2.18s\tremaining: 1.11s\n",
      "331:\tlearn: 0.0704401\ttotal: 2.19s\tremaining: 1.11s\n",
      "332:\tlearn: 0.0701114\ttotal: 2.19s\tremaining: 1.1s\n",
      "333:\tlearn: 0.0696595\ttotal: 2.2s\tremaining: 1.09s\n",
      "334:\tlearn: 0.0693235\ttotal: 2.2s\tremaining: 1.08s\n",
      "335:\tlearn: 0.0690214\ttotal: 2.21s\tremaining: 1.08s\n",
      "336:\tlearn: 0.0687359\ttotal: 2.21s\tremaining: 1.07s\n",
      "337:\tlearn: 0.0683910\ttotal: 2.22s\tremaining: 1.06s\n",
      "338:\tlearn: 0.0678916\ttotal: 2.22s\tremaining: 1.05s\n",
      "339:\tlearn: 0.0678519\ttotal: 2.22s\tremaining: 1.05s\n",
      "340:\tlearn: 0.0675610\ttotal: 2.23s\tremaining: 1.04s\n",
      "341:\tlearn: 0.0671957\ttotal: 2.23s\tremaining: 1.03s\n",
      "342:\tlearn: 0.0669287\ttotal: 2.24s\tremaining: 1.02s\n",
      "343:\tlearn: 0.0665518\ttotal: 2.25s\tremaining: 1.02s\n",
      "344:\tlearn: 0.0659979\ttotal: 2.26s\tremaining: 1.01s\n",
      "345:\tlearn: 0.0656116\ttotal: 2.27s\tremaining: 1.01s\n",
      "346:\tlearn: 0.0653255\ttotal: 2.27s\tremaining: 1s\n",
      "347:\tlearn: 0.0649764\ttotal: 2.29s\tremaining: 998ms\n",
      "348:\tlearn: 0.0646021\ttotal: 2.29s\tremaining: 993ms\n",
      "349:\tlearn: 0.0643294\ttotal: 2.3s\tremaining: 988ms\n",
      "350:\tlearn: 0.0640098\ttotal: 2.31s\tremaining: 982ms\n",
      "351:\tlearn: 0.0636887\ttotal: 2.32s\tremaining: 977ms\n",
      "352:\tlearn: 0.0632567\ttotal: 2.33s\tremaining: 970ms\n",
      "353:\tlearn: 0.0630105\ttotal: 2.34s\tremaining: 963ms\n",
      "354:\tlearn: 0.0627518\ttotal: 2.34s\tremaining: 957ms\n",
      "355:\tlearn: 0.0624341\ttotal: 2.35s\tremaining: 950ms\n",
      "356:\tlearn: 0.0621516\ttotal: 2.35s\tremaining: 943ms\n",
      "357:\tlearn: 0.0618928\ttotal: 2.36s\tremaining: 936ms\n",
      "358:\tlearn: 0.0616254\ttotal: 2.36s\tremaining: 929ms\n",
      "359:\tlearn: 0.0614002\ttotal: 2.37s\tremaining: 922ms\n",
      "360:\tlearn: 0.0611518\ttotal: 2.37s\tremaining: 914ms\n",
      "361:\tlearn: 0.0608557\ttotal: 2.38s\tremaining: 907ms\n",
      "362:\tlearn: 0.0607209\ttotal: 2.38s\tremaining: 900ms\n",
      "363:\tlearn: 0.0604004\ttotal: 2.39s\tremaining: 892ms\n",
      "364:\tlearn: 0.0600734\ttotal: 2.39s\tremaining: 885ms\n",
      "365:\tlearn: 0.0597811\ttotal: 2.4s\tremaining: 878ms\n",
      "366:\tlearn: 0.0597555\ttotal: 2.4s\tremaining: 870ms\n",
      "367:\tlearn: 0.0595080\ttotal: 2.4s\tremaining: 863ms\n",
      "368:\tlearn: 0.0592396\ttotal: 2.41s\tremaining: 855ms\n",
      "369:\tlearn: 0.0590366\ttotal: 2.42s\tremaining: 850ms\n",
      "370:\tlearn: 0.0587774\ttotal: 2.43s\tremaining: 845ms\n",
      "371:\tlearn: 0.0584895\ttotal: 2.44s\tremaining: 839ms\n",
      "372:\tlearn: 0.0582774\ttotal: 2.45s\tremaining: 834ms\n",
      "373:\tlearn: 0.0580283\ttotal: 2.46s\tremaining: 828ms\n",
      "374:\tlearn: 0.0577605\ttotal: 2.47s\tremaining: 823ms\n",
      "375:\tlearn: 0.0574432\ttotal: 2.48s\tremaining: 817ms\n",
      "376:\tlearn: 0.0571322\ttotal: 2.49s\tremaining: 811ms\n",
      "377:\tlearn: 0.0568935\ttotal: 2.5s\tremaining: 806ms\n",
      "378:\tlearn: 0.0566239\ttotal: 2.5s\tremaining: 799ms\n",
      "379:\tlearn: 0.0563744\ttotal: 2.51s\tremaining: 792ms\n",
      "380:\tlearn: 0.0561097\ttotal: 2.52s\tremaining: 786ms\n",
      "381:\tlearn: 0.0558770\ttotal: 2.52s\tremaining: 779ms\n",
      "382:\tlearn: 0.0556058\ttotal: 2.53s\tremaining: 772ms\n",
      "383:\tlearn: 0.0551227\ttotal: 2.53s\tremaining: 765ms\n",
      "384:\tlearn: 0.0549356\ttotal: 2.54s\tremaining: 758ms\n",
      "385:\tlearn: 0.0546384\ttotal: 2.54s\tremaining: 751ms\n",
      "386:\tlearn: 0.0544233\ttotal: 2.55s\tremaining: 744ms\n",
      "387:\tlearn: 0.0541942\ttotal: 2.55s\tremaining: 737ms\n",
      "388:\tlearn: 0.0539577\ttotal: 2.56s\tremaining: 729ms\n",
      "389:\tlearn: 0.0537544\ttotal: 2.56s\tremaining: 722ms\n",
      "390:\tlearn: 0.0534890\ttotal: 2.56s\tremaining: 715ms\n",
      "391:\tlearn: 0.0532651\ttotal: 2.57s\tremaining: 708ms\n",
      "392:\tlearn: 0.0529096\ttotal: 2.57s\tremaining: 701ms\n",
      "393:\tlearn: 0.0526789\ttotal: 2.58s\tremaining: 694ms\n",
      "394:\tlearn: 0.0523962\ttotal: 2.59s\tremaining: 689ms\n",
      "395:\tlearn: 0.0520325\ttotal: 2.6s\tremaining: 683ms\n",
      "396:\tlearn: 0.0517460\ttotal: 2.61s\tremaining: 677ms\n",
      "397:\tlearn: 0.0514711\ttotal: 2.62s\tremaining: 671ms\n",
      "398:\tlearn: 0.0512804\ttotal: 2.63s\tremaining: 666ms\n",
      "399:\tlearn: 0.0510092\ttotal: 2.64s\tremaining: 660ms\n",
      "400:\tlearn: 0.0504798\ttotal: 2.65s\tremaining: 654ms\n",
      "401:\tlearn: 0.0502705\ttotal: 2.66s\tremaining: 648ms\n",
      "402:\tlearn: 0.0500464\ttotal: 2.67s\tremaining: 642ms\n",
      "403:\tlearn: 0.0498370\ttotal: 2.67s\tremaining: 635ms\n",
      "404:\tlearn: 0.0496458\ttotal: 2.68s\tremaining: 629ms\n",
      "405:\tlearn: 0.0494381\ttotal: 2.69s\tremaining: 622ms\n",
      "406:\tlearn: 0.0491689\ttotal: 2.69s\tremaining: 615ms\n",
      "407:\tlearn: 0.0489674\ttotal: 2.7s\tremaining: 608ms\n",
      "408:\tlearn: 0.0487607\ttotal: 2.7s\tremaining: 601ms\n",
      "409:\tlearn: 0.0484996\ttotal: 2.71s\tremaining: 594ms\n",
      "410:\tlearn: 0.0481951\ttotal: 2.71s\tremaining: 587ms\n",
      "411:\tlearn: 0.0479895\ttotal: 2.72s\tremaining: 581ms\n",
      "412:\tlearn: 0.0478193\ttotal: 2.72s\tremaining: 574ms\n",
      "413:\tlearn: 0.0475986\ttotal: 2.73s\tremaining: 566ms\n",
      "414:\tlearn: 0.0474101\ttotal: 2.73s\tremaining: 559ms\n",
      "415:\tlearn: 0.0472187\ttotal: 2.73s\tremaining: 552ms\n",
      "416:\tlearn: 0.0470088\ttotal: 2.74s\tremaining: 545ms\n",
      "417:\tlearn: 0.0468252\ttotal: 2.74s\tremaining: 538ms\n",
      "418:\tlearn: 0.0466749\ttotal: 2.74s\tremaining: 530ms\n",
      "419:\tlearn: 0.0464994\ttotal: 2.75s\tremaining: 523ms\n",
      "420:\tlearn: 0.0462724\ttotal: 2.75s\tremaining: 516ms\n",
      "421:\tlearn: 0.0460277\ttotal: 2.78s\tremaining: 513ms\n",
      "422:\tlearn: 0.0458310\ttotal: 2.79s\tremaining: 509ms\n",
      "423:\tlearn: 0.0455889\ttotal: 2.8s\tremaining: 502ms\n",
      "424:\tlearn: 0.0454170\ttotal: 2.81s\tremaining: 495ms\n",
      "425:\tlearn: 0.0452208\ttotal: 2.81s\tremaining: 488ms\n",
      "426:\tlearn: 0.0449945\ttotal: 2.82s\tremaining: 482ms\n",
      "427:\tlearn: 0.0447452\ttotal: 2.82s\tremaining: 475ms\n",
      "428:\tlearn: 0.0445823\ttotal: 2.83s\tremaining: 468ms\n",
      "429:\tlearn: 0.0443795\ttotal: 2.83s\tremaining: 461ms\n",
      "430:\tlearn: 0.0442039\ttotal: 2.84s\tremaining: 454ms\n",
      "431:\tlearn: 0.0440504\ttotal: 2.84s\tremaining: 447ms\n",
      "432:\tlearn: 0.0438238\ttotal: 2.85s\tremaining: 441ms\n",
      "433:\tlearn: 0.0436323\ttotal: 2.85s\tremaining: 434ms\n",
      "434:\tlearn: 0.0434546\ttotal: 2.86s\tremaining: 427ms\n",
      "435:\tlearn: 0.0431939\ttotal: 2.86s\tremaining: 420ms\n",
      "436:\tlearn: 0.0429946\ttotal: 2.87s\tremaining: 413ms\n",
      "437:\tlearn: 0.0427711\ttotal: 2.87s\tremaining: 407ms\n",
      "438:\tlearn: 0.0425643\ttotal: 2.88s\tremaining: 400ms\n",
      "439:\tlearn: 0.0424289\ttotal: 2.9s\tremaining: 395ms\n",
      "440:\tlearn: 0.0422186\ttotal: 2.91s\tremaining: 389ms\n",
      "441:\tlearn: 0.0420485\ttotal: 2.92s\tremaining: 383ms\n",
      "442:\tlearn: 0.0418917\ttotal: 2.93s\tremaining: 377ms\n",
      "443:\tlearn: 0.0416974\ttotal: 2.94s\tremaining: 371ms\n",
      "444:\tlearn: 0.0414261\ttotal: 2.94s\tremaining: 364ms\n",
      "445:\tlearn: 0.0412458\ttotal: 2.95s\tremaining: 358ms\n",
      "446:\tlearn: 0.0410735\ttotal: 2.96s\tremaining: 351ms\n",
      "447:\tlearn: 0.0409126\ttotal: 2.96s\tremaining: 344ms\n",
      "448:\tlearn: 0.0407267\ttotal: 2.97s\tremaining: 338ms\n",
      "449:\tlearn: 0.0404255\ttotal: 2.98s\tremaining: 332ms\n",
      "450:\tlearn: 0.0402976\ttotal: 2.99s\tremaining: 325ms\n",
      "451:\tlearn: 0.0400792\ttotal: 3s\tremaining: 318ms\n",
      "452:\tlearn: 0.0398900\ttotal: 3s\tremaining: 312ms\n",
      "453:\tlearn: 0.0397560\ttotal: 3.01s\tremaining: 305ms\n",
      "454:\tlearn: 0.0395553\ttotal: 3.02s\tremaining: 298ms\n",
      "455:\tlearn: 0.0393714\ttotal: 3.02s\tremaining: 291ms\n",
      "456:\tlearn: 0.0392239\ttotal: 3.03s\tremaining: 285ms\n",
      "457:\tlearn: 0.0389876\ttotal: 3.03s\tremaining: 278ms\n",
      "458:\tlearn: 0.0388146\ttotal: 3.04s\tremaining: 271ms\n",
      "459:\tlearn: 0.0385532\ttotal: 3.04s\tremaining: 265ms\n",
      "460:\tlearn: 0.0383493\ttotal: 3.05s\tremaining: 258ms\n",
      "461:\tlearn: 0.0382126\ttotal: 3.05s\tremaining: 251ms\n",
      "462:\tlearn: 0.0379709\ttotal: 3.06s\tremaining: 245ms\n",
      "463:\tlearn: 0.0378195\ttotal: 3.06s\tremaining: 238ms\n",
      "464:\tlearn: 0.0376355\ttotal: 3.07s\tremaining: 231ms\n",
      "465:\tlearn: 0.0374922\ttotal: 3.07s\tremaining: 224ms\n",
      "466:\tlearn: 0.0373570\ttotal: 3.08s\tremaining: 217ms\n",
      "467:\tlearn: 0.0372212\ttotal: 3.08s\tremaining: 211ms\n",
      "468:\tlearn: 0.0370824\ttotal: 3.09s\tremaining: 204ms\n",
      "469:\tlearn: 0.0369060\ttotal: 3.09s\tremaining: 197ms\n",
      "470:\tlearn: 0.0367461\ttotal: 3.1s\tremaining: 191ms\n",
      "471:\tlearn: 0.0365701\ttotal: 3.1s\tremaining: 184ms\n",
      "472:\tlearn: 0.0364671\ttotal: 3.11s\tremaining: 177ms\n",
      "473:\tlearn: 0.0363061\ttotal: 3.11s\tremaining: 171ms\n",
      "474:\tlearn: 0.0361955\ttotal: 3.12s\tremaining: 164ms\n",
      "475:\tlearn: 0.0360038\ttotal: 3.12s\tremaining: 157ms\n",
      "476:\tlearn: 0.0358284\ttotal: 3.13s\tremaining: 151ms\n",
      "477:\tlearn: 0.0356687\ttotal: 3.13s\tremaining: 144ms\n",
      "478:\tlearn: 0.0354988\ttotal: 3.14s\tremaining: 138ms\n",
      "479:\tlearn: 0.0353423\ttotal: 3.14s\tremaining: 131ms\n",
      "480:\tlearn: 0.0351947\ttotal: 3.15s\tremaining: 124ms\n",
      "481:\tlearn: 0.0350713\ttotal: 3.15s\tremaining: 118ms\n",
      "482:\tlearn: 0.0348448\ttotal: 3.16s\tremaining: 111ms\n",
      "483:\tlearn: 0.0347018\ttotal: 3.16s\tremaining: 105ms\n",
      "484:\tlearn: 0.0345547\ttotal: 3.17s\tremaining: 98ms\n",
      "485:\tlearn: 0.0344756\ttotal: 3.17s\tremaining: 91.4ms\n",
      "486:\tlearn: 0.0343493\ttotal: 3.18s\tremaining: 84.8ms\n",
      "487:\tlearn: 0.0342224\ttotal: 3.18s\tremaining: 78.2ms\n",
      "488:\tlearn: 0.0340761\ttotal: 3.19s\tremaining: 71.7ms\n",
      "489:\tlearn: 0.0339431\ttotal: 3.19s\tremaining: 65.2ms\n",
      "490:\tlearn: 0.0337877\ttotal: 3.2s\tremaining: 58.6ms\n",
      "491:\tlearn: 0.0336626\ttotal: 3.2s\tremaining: 52.1ms\n",
      "492:\tlearn: 0.0335360\ttotal: 3.21s\tremaining: 45.6ms\n",
      "493:\tlearn: 0.0333308\ttotal: 3.22s\tremaining: 39.1ms\n",
      "494:\tlearn: 0.0331108\ttotal: 3.23s\tremaining: 32.7ms\n",
      "495:\tlearn: 0.0329660\ttotal: 3.24s\tremaining: 26.2ms\n",
      "496:\tlearn: 0.0328265\ttotal: 3.25s\tremaining: 19.6ms\n",
      "497:\tlearn: 0.0326852\ttotal: 3.26s\tremaining: 13.1ms\n",
      "498:\tlearn: 0.0325050\ttotal: 3.27s\tremaining: 6.56ms\n",
      "499:\tlearn: 0.0323494\ttotal: 3.28s\tremaining: 0us\n",
      "0:\tlearn: 0.6809729\ttotal: 4.37ms\tremaining: 2.18s\n",
      "1:\tlearn: 0.6702979\ttotal: 8.44ms\tremaining: 2.1s\n",
      "2:\tlearn: 0.6573967\ttotal: 12.7ms\tremaining: 2.11s\n",
      "3:\tlearn: 0.6463352\ttotal: 17.1ms\tremaining: 2.13s\n",
      "4:\tlearn: 0.6381409\ttotal: 21.5ms\tremaining: 2.13s\n",
      "5:\tlearn: 0.6301095\ttotal: 25.7ms\tremaining: 2.12s\n",
      "6:\tlearn: 0.6206219\ttotal: 29.9ms\tremaining: 2.1s\n",
      "7:\tlearn: 0.6136743\ttotal: 33.8ms\tremaining: 2.08s\n",
      "8:\tlearn: 0.6056937\ttotal: 38.2ms\tremaining: 2.08s\n",
      "9:\tlearn: 0.5983097\ttotal: 42.6ms\tremaining: 2.09s\n",
      "10:\tlearn: 0.5894031\ttotal: 52.4ms\tremaining: 2.33s\n",
      "11:\tlearn: 0.5822491\ttotal: 62ms\tremaining: 2.52s\n",
      "12:\tlearn: 0.5763168\ttotal: 71.6ms\tremaining: 2.68s\n",
      "13:\tlearn: 0.5703274\ttotal: 81.5ms\tremaining: 2.83s\n",
      "14:\tlearn: 0.5633798\ttotal: 91.1ms\tremaining: 2.94s\n",
      "15:\tlearn: 0.5582867\ttotal: 101ms\tremaining: 3.04s\n",
      "16:\tlearn: 0.5468863\ttotal: 110ms\tremaining: 3.13s\n",
      "17:\tlearn: 0.5411425\ttotal: 120ms\tremaining: 3.21s\n",
      "18:\tlearn: 0.5302100\ttotal: 129ms\tremaining: 3.27s\n",
      "19:\tlearn: 0.5205121\ttotal: 137ms\tremaining: 3.29s\n",
      "20:\tlearn: 0.5115271\ttotal: 144ms\tremaining: 3.27s\n",
      "21:\tlearn: 0.5058176\ttotal: 150ms\tremaining: 3.25s\n",
      "22:\tlearn: 0.5012441\ttotal: 156ms\tremaining: 3.23s\n",
      "23:\tlearn: 0.4977269\ttotal: 162ms\tremaining: 3.21s\n",
      "24:\tlearn: 0.4936421\ttotal: 167ms\tremaining: 3.18s\n",
      "25:\tlearn: 0.4876194\ttotal: 172ms\tremaining: 3.13s\n",
      "26:\tlearn: 0.4840754\ttotal: 176ms\tremaining: 3.09s\n",
      "27:\tlearn: 0.4798224\ttotal: 182ms\tremaining: 3.06s\n",
      "28:\tlearn: 0.4757412\ttotal: 187ms\tremaining: 3.03s\n",
      "29:\tlearn: 0.4720126\ttotal: 190ms\tremaining: 2.98s\n",
      "30:\tlearn: 0.4681627\ttotal: 195ms\tremaining: 2.95s\n",
      "31:\tlearn: 0.4651745\ttotal: 200ms\tremaining: 2.92s\n",
      "32:\tlearn: 0.4618554\ttotal: 203ms\tremaining: 2.88s\n",
      "33:\tlearn: 0.4582731\ttotal: 208ms\tremaining: 2.85s\n",
      "34:\tlearn: 0.4548061\ttotal: 212ms\tremaining: 2.81s\n",
      "35:\tlearn: 0.4503304\ttotal: 216ms\tremaining: 2.79s\n",
      "36:\tlearn: 0.4476313\ttotal: 220ms\tremaining: 2.75s\n",
      "37:\tlearn: 0.4448047\ttotal: 224ms\tremaining: 2.73s\n",
      "38:\tlearn: 0.4409216\ttotal: 229ms\tremaining: 2.7s\n",
      "39:\tlearn: 0.4365288\ttotal: 233ms\tremaining: 2.68s\n",
      "40:\tlearn: 0.4309914\ttotal: 243ms\tremaining: 2.71s\n",
      "41:\tlearn: 0.4279969\ttotal: 252ms\tremaining: 2.75s\n",
      "42:\tlearn: 0.4252838\ttotal: 262ms\tremaining: 2.78s\n",
      "43:\tlearn: 0.4224747\ttotal: 272ms\tremaining: 2.81s\n",
      "44:\tlearn: 0.4190950\ttotal: 281ms\tremaining: 2.85s\n",
      "45:\tlearn: 0.4163155\ttotal: 291ms\tremaining: 2.87s\n",
      "46:\tlearn: 0.4127494\ttotal: 300ms\tremaining: 2.9s\n",
      "47:\tlearn: 0.4094189\ttotal: 310ms\tremaining: 2.92s\n",
      "48:\tlearn: 0.4068038\ttotal: 320ms\tremaining: 2.94s\n",
      "49:\tlearn: 0.4038196\ttotal: 328ms\tremaining: 2.95s\n",
      "50:\tlearn: 0.4006692\ttotal: 334ms\tremaining: 2.94s\n",
      "51:\tlearn: 0.3980255\ttotal: 340ms\tremaining: 2.93s\n",
      "52:\tlearn: 0.3941874\ttotal: 346ms\tremaining: 2.92s\n",
      "53:\tlearn: 0.3909262\ttotal: 352ms\tremaining: 2.91s\n",
      "54:\tlearn: 0.3886990\ttotal: 358ms\tremaining: 2.89s\n",
      "55:\tlearn: 0.3851624\ttotal: 364ms\tremaining: 2.88s\n",
      "56:\tlearn: 0.3821341\ttotal: 370ms\tremaining: 2.88s\n",
      "57:\tlearn: 0.3746426\ttotal: 376ms\tremaining: 2.86s\n",
      "58:\tlearn: 0.3724174\ttotal: 380ms\tremaining: 2.84s\n",
      "59:\tlearn: 0.3699431\ttotal: 385ms\tremaining: 2.82s\n",
      "60:\tlearn: 0.3674015\ttotal: 389ms\tremaining: 2.8s\n",
      "61:\tlearn: 0.3651473\ttotal: 393ms\tremaining: 2.77s\n",
      "62:\tlearn: 0.3622020\ttotal: 397ms\tremaining: 2.75s\n",
      "63:\tlearn: 0.3597381\ttotal: 401ms\tremaining: 2.73s\n",
      "64:\tlearn: 0.3578554\ttotal: 406ms\tremaining: 2.71s\n",
      "65:\tlearn: 0.3563310\ttotal: 409ms\tremaining: 2.69s\n",
      "66:\tlearn: 0.3542091\ttotal: 419ms\tremaining: 2.71s\n",
      "67:\tlearn: 0.3522373\ttotal: 428ms\tremaining: 2.72s\n",
      "68:\tlearn: 0.3496416\ttotal: 438ms\tremaining: 2.74s\n",
      "69:\tlearn: 0.3477579\ttotal: 448ms\tremaining: 2.75s\n",
      "70:\tlearn: 0.3439867\ttotal: 457ms\tremaining: 2.76s\n",
      "71:\tlearn: 0.3399087\ttotal: 467ms\tremaining: 2.77s\n",
      "72:\tlearn: 0.3355340\ttotal: 476ms\tremaining: 2.79s\n",
      "73:\tlearn: 0.3327634\ttotal: 486ms\tremaining: 2.8s\n",
      "74:\tlearn: 0.3301106\ttotal: 496ms\tremaining: 2.81s\n",
      "75:\tlearn: 0.3282471\ttotal: 503ms\tremaining: 2.8s\n",
      "76:\tlearn: 0.3256759\ttotal: 509ms\tremaining: 2.79s\n",
      "77:\tlearn: 0.3231375\ttotal: 515ms\tremaining: 2.79s\n",
      "78:\tlearn: 0.3205243\ttotal: 521ms\tremaining: 2.78s\n",
      "79:\tlearn: 0.3185703\ttotal: 526ms\tremaining: 2.76s\n",
      "80:\tlearn: 0.3164220\ttotal: 531ms\tremaining: 2.74s\n",
      "81:\tlearn: 0.3142957\ttotal: 535ms\tremaining: 2.73s\n",
      "82:\tlearn: 0.3122261\ttotal: 541ms\tremaining: 2.72s\n",
      "83:\tlearn: 0.3099521\ttotal: 546ms\tremaining: 2.7s\n",
      "84:\tlearn: 0.3077133\ttotal: 552ms\tremaining: 2.7s\n",
      "85:\tlearn: 0.3057525\ttotal: 557ms\tremaining: 2.68s\n",
      "86:\tlearn: 0.3035020\ttotal: 560ms\tremaining: 2.66s\n",
      "87:\tlearn: 0.3008006\ttotal: 565ms\tremaining: 2.64s\n",
      "88:\tlearn: 0.2969892\ttotal: 569ms\tremaining: 2.63s\n",
      "89:\tlearn: 0.2946066\ttotal: 574ms\tremaining: 2.61s\n",
      "90:\tlearn: 0.2926925\ttotal: 583ms\tremaining: 2.62s\n",
      "91:\tlearn: 0.2904489\ttotal: 592ms\tremaining: 2.63s\n",
      "92:\tlearn: 0.2886208\ttotal: 602ms\tremaining: 2.63s\n",
      "93:\tlearn: 0.2863475\ttotal: 612ms\tremaining: 2.64s\n",
      "94:\tlearn: 0.2840989\ttotal: 621ms\tremaining: 2.65s\n",
      "95:\tlearn: 0.2819585\ttotal: 631ms\tremaining: 2.66s\n",
      "96:\tlearn: 0.2800642\ttotal: 641ms\tremaining: 2.66s\n",
      "97:\tlearn: 0.2781796\ttotal: 651ms\tremaining: 2.67s\n",
      "98:\tlearn: 0.2762962\ttotal: 661ms\tremaining: 2.68s\n",
      "99:\tlearn: 0.2744772\ttotal: 670ms\tremaining: 2.68s\n",
      "100:\tlearn: 0.2720755\ttotal: 677ms\tremaining: 2.68s\n",
      "101:\tlearn: 0.2702905\ttotal: 684ms\tremaining: 2.67s\n",
      "102:\tlearn: 0.2676470\ttotal: 690ms\tremaining: 2.66s\n",
      "103:\tlearn: 0.2661174\ttotal: 695ms\tremaining: 2.65s\n",
      "104:\tlearn: 0.2645220\ttotal: 700ms\tremaining: 2.63s\n",
      "105:\tlearn: 0.2629103\ttotal: 704ms\tremaining: 2.62s\n",
      "106:\tlearn: 0.2610163\ttotal: 709ms\tremaining: 2.6s\n",
      "107:\tlearn: 0.2588356\ttotal: 714ms\tremaining: 2.59s\n",
      "108:\tlearn: 0.2575019\ttotal: 718ms\tremaining: 2.58s\n",
      "109:\tlearn: 0.2541051\ttotal: 723ms\tremaining: 2.56s\n",
      "110:\tlearn: 0.2524134\ttotal: 727ms\tremaining: 2.55s\n",
      "111:\tlearn: 0.2507133\ttotal: 732ms\tremaining: 2.53s\n",
      "112:\tlearn: 0.2492553\ttotal: 736ms\tremaining: 2.52s\n",
      "113:\tlearn: 0.2477490\ttotal: 740ms\tremaining: 2.51s\n",
      "114:\tlearn: 0.2456352\ttotal: 743ms\tremaining: 2.49s\n",
      "115:\tlearn: 0.2441860\ttotal: 747ms\tremaining: 2.47s\n",
      "116:\tlearn: 0.2428583\ttotal: 749ms\tremaining: 2.45s\n",
      "117:\tlearn: 0.2407917\ttotal: 759ms\tremaining: 2.46s\n",
      "118:\tlearn: 0.2393886\ttotal: 769ms\tremaining: 2.46s\n",
      "119:\tlearn: 0.2376141\ttotal: 778ms\tremaining: 2.46s\n",
      "120:\tlearn: 0.2361423\ttotal: 788ms\tremaining: 2.47s\n",
      "121:\tlearn: 0.2346981\ttotal: 797ms\tremaining: 2.47s\n",
      "122:\tlearn: 0.2333616\ttotal: 807ms\tremaining: 2.47s\n",
      "123:\tlearn: 0.2307295\ttotal: 817ms\tremaining: 2.48s\n",
      "124:\tlearn: 0.2293943\ttotal: 826ms\tremaining: 2.48s\n",
      "125:\tlearn: 0.2278560\ttotal: 834ms\tremaining: 2.48s\n",
      "126:\tlearn: 0.2265598\ttotal: 841ms\tremaining: 2.47s\n",
      "127:\tlearn: 0.2250109\ttotal: 845ms\tremaining: 2.46s\n",
      "128:\tlearn: 0.2233508\ttotal: 849ms\tremaining: 2.44s\n",
      "129:\tlearn: 0.2220377\ttotal: 856ms\tremaining: 2.44s\n",
      "130:\tlearn: 0.2203757\ttotal: 860ms\tremaining: 2.42s\n",
      "131:\tlearn: 0.2189350\ttotal: 865ms\tremaining: 2.41s\n",
      "132:\tlearn: 0.2178036\ttotal: 869ms\tremaining: 2.4s\n",
      "133:\tlearn: 0.2163892\ttotal: 874ms\tremaining: 2.39s\n",
      "134:\tlearn: 0.2152841\ttotal: 878ms\tremaining: 2.37s\n",
      "135:\tlearn: 0.2141895\ttotal: 883ms\tremaining: 2.36s\n",
      "136:\tlearn: 0.2129249\ttotal: 887ms\tremaining: 2.35s\n",
      "137:\tlearn: 0.2113683\ttotal: 897ms\tremaining: 2.35s\n",
      "138:\tlearn: 0.2101371\ttotal: 906ms\tremaining: 2.35s\n",
      "139:\tlearn: 0.2087446\ttotal: 916ms\tremaining: 2.35s\n",
      "140:\tlearn: 0.2076802\ttotal: 926ms\tremaining: 2.36s\n",
      "141:\tlearn: 0.2064334\ttotal: 935ms\tremaining: 2.36s\n",
      "142:\tlearn: 0.2052013\ttotal: 945ms\tremaining: 2.36s\n",
      "143:\tlearn: 0.2039282\ttotal: 955ms\tremaining: 2.36s\n",
      "144:\tlearn: 0.2029020\ttotal: 964ms\tremaining: 2.36s\n",
      "145:\tlearn: 0.2015771\ttotal: 974ms\tremaining: 2.36s\n",
      "146:\tlearn: 0.2004420\ttotal: 980ms\tremaining: 2.35s\n",
      "147:\tlearn: 0.1981611\ttotal: 987ms\tremaining: 2.35s\n",
      "148:\tlearn: 0.1958343\ttotal: 993ms\tremaining: 2.34s\n",
      "149:\tlearn: 0.1947528\ttotal: 999ms\tremaining: 2.33s\n",
      "150:\tlearn: 0.1936994\ttotal: 1s\tremaining: 2.32s\n",
      "151:\tlearn: 0.1912482\ttotal: 1.01s\tremaining: 2.31s\n",
      "152:\tlearn: 0.1901584\ttotal: 1.01s\tremaining: 2.3s\n",
      "153:\tlearn: 0.1888659\ttotal: 1.02s\tremaining: 2.29s\n",
      "154:\tlearn: 0.1876958\ttotal: 1.02s\tremaining: 2.28s\n",
      "155:\tlearn: 0.1866019\ttotal: 1.03s\tremaining: 2.27s\n",
      "156:\tlearn: 0.1847758\ttotal: 1.03s\tremaining: 2.25s\n",
      "157:\tlearn: 0.1830157\ttotal: 1.04s\tremaining: 2.24s\n",
      "158:\tlearn: 0.1818099\ttotal: 1.04s\tremaining: 2.23s\n",
      "159:\tlearn: 0.1807157\ttotal: 1.04s\tremaining: 2.22s\n",
      "160:\tlearn: 0.1796119\ttotal: 1.05s\tremaining: 2.21s\n",
      "161:\tlearn: 0.1778421\ttotal: 1.05s\tremaining: 2.2s\n",
      "162:\tlearn: 0.1768641\ttotal: 1.06s\tremaining: 2.19s\n",
      "163:\tlearn: 0.1760179\ttotal: 1.07s\tremaining: 2.19s\n",
      "164:\tlearn: 0.1751052\ttotal: 1.08s\tremaining: 2.19s\n",
      "165:\tlearn: 0.1740802\ttotal: 1.09s\tremaining: 2.19s\n",
      "166:\tlearn: 0.1731041\ttotal: 1.1s\tremaining: 2.19s\n",
      "167:\tlearn: 0.1722439\ttotal: 1.11s\tremaining: 2.19s\n",
      "168:\tlearn: 0.1715874\ttotal: 1.12s\tremaining: 2.19s\n",
      "169:\tlearn: 0.1707105\ttotal: 1.13s\tremaining: 2.19s\n",
      "170:\tlearn: 0.1694772\ttotal: 1.14s\tremaining: 2.19s\n",
      "171:\tlearn: 0.1686475\ttotal: 1.14s\tremaining: 2.18s\n",
      "172:\tlearn: 0.1677475\ttotal: 1.15s\tremaining: 2.17s\n",
      "173:\tlearn: 0.1662953\ttotal: 1.16s\tremaining: 2.17s\n",
      "174:\tlearn: 0.1652557\ttotal: 1.17s\tremaining: 2.16s\n",
      "175:\tlearn: 0.1645359\ttotal: 1.17s\tremaining: 2.16s\n",
      "176:\tlearn: 0.1636389\ttotal: 1.18s\tremaining: 2.15s\n",
      "177:\tlearn: 0.1625545\ttotal: 1.18s\tremaining: 2.14s\n",
      "178:\tlearn: 0.1615765\ttotal: 1.19s\tremaining: 2.13s\n",
      "179:\tlearn: 0.1605005\ttotal: 1.2s\tremaining: 2.13s\n",
      "180:\tlearn: 0.1596247\ttotal: 1.2s\tremaining: 2.12s\n",
      "181:\tlearn: 0.1587616\ttotal: 1.21s\tremaining: 2.11s\n",
      "182:\tlearn: 0.1579554\ttotal: 1.21s\tremaining: 2.1s\n",
      "183:\tlearn: 0.1565796\ttotal: 1.22s\tremaining: 2.09s\n",
      "184:\tlearn: 0.1556805\ttotal: 1.22s\tremaining: 2.08s\n",
      "185:\tlearn: 0.1548392\ttotal: 1.23s\tremaining: 2.07s\n",
      "186:\tlearn: 0.1540061\ttotal: 1.23s\tremaining: 2.06s\n",
      "187:\tlearn: 0.1532600\ttotal: 1.24s\tremaining: 2.05s\n",
      "188:\tlearn: 0.1524446\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.1517082\ttotal: 1.24s\tremaining: 2.03s\n",
      "190:\tlearn: 0.1504629\ttotal: 1.25s\tremaining: 2.02s\n",
      "191:\tlearn: 0.1497255\ttotal: 1.26s\tremaining: 2.02s\n",
      "192:\tlearn: 0.1489529\ttotal: 1.27s\tremaining: 2.02s\n",
      "193:\tlearn: 0.1482162\ttotal: 1.28s\tremaining: 2.01s\n",
      "194:\tlearn: 0.1474632\ttotal: 1.29s\tremaining: 2.01s\n",
      "195:\tlearn: 0.1462088\ttotal: 1.3s\tremaining: 2.01s\n",
      "196:\tlearn: 0.1447845\ttotal: 1.31s\tremaining: 2.01s\n",
      "197:\tlearn: 0.1441916\ttotal: 1.32s\tremaining: 2.01s\n",
      "198:\tlearn: 0.1434694\ttotal: 1.33s\tremaining: 2.01s\n",
      "199:\tlearn: 0.1426773\ttotal: 1.34s\tremaining: 2.01s\n",
      "200:\tlearn: 0.1417948\ttotal: 1.34s\tremaining: 2s\n",
      "201:\tlearn: 0.1409317\ttotal: 1.35s\tremaining: 1.99s\n",
      "202:\tlearn: 0.1391791\ttotal: 1.36s\tremaining: 1.98s\n",
      "203:\tlearn: 0.1383833\ttotal: 1.36s\tremaining: 1.98s\n",
      "204:\tlearn: 0.1376708\ttotal: 1.37s\tremaining: 1.97s\n",
      "205:\tlearn: 0.1368678\ttotal: 1.37s\tremaining: 1.96s\n",
      "206:\tlearn: 0.1362434\ttotal: 1.38s\tremaining: 1.95s\n",
      "207:\tlearn: 0.1355422\ttotal: 1.38s\tremaining: 1.94s\n",
      "208:\tlearn: 0.1348762\ttotal: 1.39s\tremaining: 1.93s\n",
      "209:\tlearn: 0.1342472\ttotal: 1.39s\tremaining: 1.92s\n",
      "210:\tlearn: 0.1336936\ttotal: 1.4s\tremaining: 1.91s\n",
      "211:\tlearn: 0.1330236\ttotal: 1.4s\tremaining: 1.9s\n",
      "212:\tlearn: 0.1323202\ttotal: 1.4s\tremaining: 1.89s\n",
      "213:\tlearn: 0.1317883\ttotal: 1.41s\tremaining: 1.88s\n",
      "214:\tlearn: 0.1311416\ttotal: 1.41s\tremaining: 1.87s\n",
      "215:\tlearn: 0.1305627\ttotal: 1.42s\tremaining: 1.86s\n",
      "216:\tlearn: 0.1298929\ttotal: 1.42s\tremaining: 1.85s\n",
      "217:\tlearn: 0.1292326\ttotal: 1.43s\tremaining: 1.85s\n",
      "218:\tlearn: 0.1285128\ttotal: 1.44s\tremaining: 1.85s\n",
      "219:\tlearn: 0.1278318\ttotal: 1.45s\tremaining: 1.84s\n",
      "220:\tlearn: 0.1265077\ttotal: 1.46s\tremaining: 1.84s\n",
      "221:\tlearn: 0.1257782\ttotal: 1.47s\tremaining: 1.84s\n",
      "222:\tlearn: 0.1251201\ttotal: 1.48s\tremaining: 1.84s\n",
      "223:\tlearn: 0.1244123\ttotal: 1.49s\tremaining: 1.83s\n",
      "224:\tlearn: 0.1239809\ttotal: 1.5s\tremaining: 1.83s\n",
      "225:\tlearn: 0.1233895\ttotal: 1.51s\tremaining: 1.83s\n",
      "226:\tlearn: 0.1226179\ttotal: 1.52s\tremaining: 1.82s\n",
      "227:\tlearn: 0.1220171\ttotal: 1.52s\tremaining: 1.82s\n",
      "228:\tlearn: 0.1211673\ttotal: 1.53s\tremaining: 1.81s\n",
      "229:\tlearn: 0.1206527\ttotal: 1.53s\tremaining: 1.8s\n",
      "230:\tlearn: 0.1192804\ttotal: 1.54s\tremaining: 1.79s\n",
      "231:\tlearn: 0.1184691\ttotal: 1.54s\tremaining: 1.78s\n",
      "232:\tlearn: 0.1178606\ttotal: 1.55s\tremaining: 1.78s\n",
      "233:\tlearn: 0.1172046\ttotal: 1.55s\tremaining: 1.77s\n",
      "234:\tlearn: 0.1166616\ttotal: 1.56s\tremaining: 1.76s\n",
      "235:\tlearn: 0.1161242\ttotal: 1.56s\tremaining: 1.75s\n",
      "236:\tlearn: 0.1155202\ttotal: 1.57s\tremaining: 1.74s\n",
      "237:\tlearn: 0.1149355\ttotal: 1.57s\tremaining: 1.73s\n",
      "238:\tlearn: 0.1142496\ttotal: 1.58s\tremaining: 1.72s\n",
      "239:\tlearn: 0.1136799\ttotal: 1.58s\tremaining: 1.72s\n",
      "240:\tlearn: 0.1130669\ttotal: 1.59s\tremaining: 1.71s\n",
      "241:\tlearn: 0.1125623\ttotal: 1.59s\tremaining: 1.7s\n",
      "242:\tlearn: 0.1120810\ttotal: 1.6s\tremaining: 1.7s\n",
      "243:\tlearn: 0.1114595\ttotal: 1.61s\tremaining: 1.69s\n",
      "244:\tlearn: 0.1109451\ttotal: 1.62s\tremaining: 1.69s\n",
      "245:\tlearn: 0.1100450\ttotal: 1.63s\tremaining: 1.68s\n",
      "246:\tlearn: 0.1094856\ttotal: 1.64s\tremaining: 1.68s\n",
      "247:\tlearn: 0.1090107\ttotal: 1.65s\tremaining: 1.68s\n",
      "248:\tlearn: 0.1085088\ttotal: 1.66s\tremaining: 1.67s\n",
      "249:\tlearn: 0.1080495\ttotal: 1.67s\tremaining: 1.67s\n",
      "250:\tlearn: 0.1074758\ttotal: 1.68s\tremaining: 1.67s\n",
      "251:\tlearn: 0.1069362\ttotal: 1.69s\tremaining: 1.66s\n",
      "252:\tlearn: 0.1061056\ttotal: 1.7s\tremaining: 1.65s\n",
      "253:\tlearn: 0.1056209\ttotal: 1.7s\tremaining: 1.65s\n",
      "254:\tlearn: 0.1052579\ttotal: 1.71s\tremaining: 1.64s\n",
      "255:\tlearn: 0.1047303\ttotal: 1.71s\tremaining: 1.63s\n",
      "256:\tlearn: 0.1042158\ttotal: 1.72s\tremaining: 1.63s\n",
      "257:\tlearn: 0.1030932\ttotal: 1.72s\tremaining: 1.62s\n",
      "258:\tlearn: 0.1025976\ttotal: 1.73s\tremaining: 1.61s\n",
      "259:\tlearn: 0.1020545\ttotal: 1.73s\tremaining: 1.6s\n",
      "260:\tlearn: 0.1015597\ttotal: 1.74s\tremaining: 1.59s\n",
      "261:\tlearn: 0.1010780\ttotal: 1.74s\tremaining: 1.58s\n",
      "262:\tlearn: 0.1005907\ttotal: 1.75s\tremaining: 1.57s\n",
      "263:\tlearn: 0.1001338\ttotal: 1.75s\tremaining: 1.57s\n",
      "264:\tlearn: 0.0996997\ttotal: 1.76s\tremaining: 1.56s\n",
      "265:\tlearn: 0.0992360\ttotal: 1.76s\tremaining: 1.55s\n",
      "266:\tlearn: 0.0987624\ttotal: 1.76s\tremaining: 1.54s\n",
      "267:\tlearn: 0.0982130\ttotal: 1.77s\tremaining: 1.54s\n",
      "268:\tlearn: 0.0978345\ttotal: 1.78s\tremaining: 1.53s\n",
      "269:\tlearn: 0.0972901\ttotal: 1.79s\tremaining: 1.53s\n",
      "270:\tlearn: 0.0967983\ttotal: 1.8s\tremaining: 1.52s\n",
      "271:\tlearn: 0.0965242\ttotal: 1.81s\tremaining: 1.52s\n",
      "272:\tlearn: 0.0961000\ttotal: 1.82s\tremaining: 1.52s\n",
      "273:\tlearn: 0.0955908\ttotal: 1.83s\tremaining: 1.51s\n",
      "274:\tlearn: 0.0951474\ttotal: 1.84s\tremaining: 1.51s\n",
      "275:\tlearn: 0.0945782\ttotal: 1.85s\tremaining: 1.5s\n",
      "276:\tlearn: 0.0940818\ttotal: 1.86s\tremaining: 1.5s\n",
      "277:\tlearn: 0.0933650\ttotal: 1.87s\tremaining: 1.49s\n",
      "278:\tlearn: 0.0928092\ttotal: 1.87s\tremaining: 1.48s\n",
      "279:\tlearn: 0.0923629\ttotal: 1.88s\tremaining: 1.48s\n",
      "280:\tlearn: 0.0915228\ttotal: 1.89s\tremaining: 1.47s\n",
      "281:\tlearn: 0.0911896\ttotal: 1.89s\tremaining: 1.46s\n",
      "282:\tlearn: 0.0907145\ttotal: 1.9s\tremaining: 1.45s\n",
      "283:\tlearn: 0.0902772\ttotal: 1.9s\tremaining: 1.45s\n",
      "284:\tlearn: 0.0897820\ttotal: 1.91s\tremaining: 1.44s\n",
      "285:\tlearn: 0.0894184\ttotal: 1.91s\tremaining: 1.43s\n",
      "286:\tlearn: 0.0889760\ttotal: 1.91s\tremaining: 1.42s\n",
      "287:\tlearn: 0.0885734\ttotal: 1.92s\tremaining: 1.41s\n",
      "288:\tlearn: 0.0879240\ttotal: 1.92s\tremaining: 1.4s\n",
      "289:\tlearn: 0.0874476\ttotal: 1.93s\tremaining: 1.4s\n",
      "290:\tlearn: 0.0868825\ttotal: 1.93s\tremaining: 1.39s\n",
      "291:\tlearn: 0.0864376\ttotal: 1.94s\tremaining: 1.38s\n",
      "292:\tlearn: 0.0860818\ttotal: 1.95s\tremaining: 1.38s\n",
      "293:\tlearn: 0.0856940\ttotal: 1.96s\tremaining: 1.37s\n",
      "294:\tlearn: 0.0853618\ttotal: 1.97s\tremaining: 1.37s\n",
      "295:\tlearn: 0.0849304\ttotal: 1.98s\tremaining: 1.36s\n",
      "296:\tlearn: 0.0845171\ttotal: 1.99s\tremaining: 1.36s\n",
      "297:\tlearn: 0.0841180\ttotal: 2s\tremaining: 1.35s\n",
      "298:\tlearn: 0.0837394\ttotal: 2s\tremaining: 1.35s\n",
      "299:\tlearn: 0.0832478\ttotal: 2.01s\tremaining: 1.34s\n",
      "300:\tlearn: 0.0826861\ttotal: 2.02s\tremaining: 1.34s\n",
      "301:\tlearn: 0.0823743\ttotal: 2.03s\tremaining: 1.33s\n",
      "302:\tlearn: 0.0819903\ttotal: 2.04s\tremaining: 1.32s\n",
      "303:\tlearn: 0.0814932\ttotal: 2.04s\tremaining: 1.32s\n",
      "304:\tlearn: 0.0810232\ttotal: 2.05s\tremaining: 1.31s\n",
      "305:\tlearn: 0.0806298\ttotal: 2.05s\tremaining: 1.3s\n",
      "306:\tlearn: 0.0803900\ttotal: 2.06s\tremaining: 1.29s\n",
      "307:\tlearn: 0.0799845\ttotal: 2.06s\tremaining: 1.28s\n",
      "308:\tlearn: 0.0797934\ttotal: 2.07s\tremaining: 1.28s\n",
      "309:\tlearn: 0.0794488\ttotal: 2.07s\tremaining: 1.27s\n",
      "310:\tlearn: 0.0790525\ttotal: 2.08s\tremaining: 1.26s\n",
      "311:\tlearn: 0.0785216\ttotal: 2.08s\tremaining: 1.25s\n",
      "312:\tlearn: 0.0780686\ttotal: 2.08s\tremaining: 1.25s\n",
      "313:\tlearn: 0.0776348\ttotal: 2.09s\tremaining: 1.24s\n",
      "314:\tlearn: 0.0772851\ttotal: 2.09s\tremaining: 1.23s\n",
      "315:\tlearn: 0.0769220\ttotal: 2.1s\tremaining: 1.22s\n",
      "316:\tlearn: 0.0766875\ttotal: 2.1s\tremaining: 1.21s\n",
      "317:\tlearn: 0.0763438\ttotal: 2.11s\tremaining: 1.21s\n",
      "318:\tlearn: 0.0757148\ttotal: 2.12s\tremaining: 1.2s\n",
      "319:\tlearn: 0.0752202\ttotal: 2.13s\tremaining: 1.2s\n",
      "320:\tlearn: 0.0747898\ttotal: 2.14s\tremaining: 1.19s\n",
      "321:\tlearn: 0.0743299\ttotal: 2.15s\tremaining: 1.19s\n",
      "322:\tlearn: 0.0741233\ttotal: 2.16s\tremaining: 1.18s\n",
      "323:\tlearn: 0.0738189\ttotal: 2.17s\tremaining: 1.18s\n",
      "324:\tlearn: 0.0733925\ttotal: 2.18s\tremaining: 1.17s\n",
      "325:\tlearn: 0.0730732\ttotal: 2.19s\tremaining: 1.17s\n",
      "326:\tlearn: 0.0727306\ttotal: 2.19s\tremaining: 1.16s\n",
      "327:\tlearn: 0.0724291\ttotal: 2.2s\tremaining: 1.15s\n",
      "328:\tlearn: 0.0721068\ttotal: 2.21s\tremaining: 1.15s\n",
      "329:\tlearn: 0.0717240\ttotal: 2.21s\tremaining: 1.14s\n",
      "330:\tlearn: 0.0714345\ttotal: 2.22s\tremaining: 1.13s\n",
      "331:\tlearn: 0.0711750\ttotal: 2.22s\tremaining: 1.13s\n",
      "332:\tlearn: 0.0709077\ttotal: 2.23s\tremaining: 1.12s\n",
      "333:\tlearn: 0.0705694\ttotal: 2.23s\tremaining: 1.11s\n",
      "334:\tlearn: 0.0703101\ttotal: 2.24s\tremaining: 1.1s\n",
      "335:\tlearn: 0.0700512\ttotal: 2.24s\tremaining: 1.09s\n",
      "336:\tlearn: 0.0697187\ttotal: 2.25s\tremaining: 1.09s\n",
      "337:\tlearn: 0.0691294\ttotal: 2.25s\tremaining: 1.08s\n",
      "338:\tlearn: 0.0687842\ttotal: 2.26s\tremaining: 1.07s\n",
      "339:\tlearn: 0.0685929\ttotal: 2.26s\tremaining: 1.06s\n",
      "340:\tlearn: 0.0683045\ttotal: 2.27s\tremaining: 1.06s\n",
      "341:\tlearn: 0.0680188\ttotal: 2.27s\tremaining: 1.05s\n",
      "342:\tlearn: 0.0676966\ttotal: 2.27s\tremaining: 1.04s\n",
      "343:\tlearn: 0.0674102\ttotal: 2.28s\tremaining: 1.03s\n",
      "344:\tlearn: 0.0671230\ttotal: 2.28s\tremaining: 1.02s\n",
      "345:\tlearn: 0.0667556\ttotal: 2.29s\tremaining: 1.02s\n",
      "346:\tlearn: 0.0663098\ttotal: 2.3s\tremaining: 1.01s\n",
      "347:\tlearn: 0.0660065\ttotal: 2.31s\tremaining: 1.01s\n",
      "348:\tlearn: 0.0656474\ttotal: 2.32s\tremaining: 1s\n",
      "349:\tlearn: 0.0655160\ttotal: 2.33s\tremaining: 999ms\n",
      "350:\tlearn: 0.0650527\ttotal: 2.34s\tremaining: 993ms\n",
      "351:\tlearn: 0.0646694\ttotal: 2.35s\tremaining: 988ms\n",
      "352:\tlearn: 0.0640953\ttotal: 2.36s\tremaining: 982ms\n",
      "353:\tlearn: 0.0637870\ttotal: 2.36s\tremaining: 975ms\n",
      "354:\tlearn: 0.0635451\ttotal: 2.37s\tremaining: 968ms\n",
      "355:\tlearn: 0.0632621\ttotal: 2.38s\tremaining: 961ms\n",
      "356:\tlearn: 0.0628715\ttotal: 2.38s\tremaining: 954ms\n",
      "357:\tlearn: 0.0626359\ttotal: 2.39s\tremaining: 947ms\n",
      "358:\tlearn: 0.0620656\ttotal: 2.39s\tremaining: 939ms\n",
      "359:\tlearn: 0.0617968\ttotal: 2.4s\tremaining: 932ms\n",
      "360:\tlearn: 0.0615137\ttotal: 2.4s\tremaining: 925ms\n",
      "361:\tlearn: 0.0612075\ttotal: 2.41s\tremaining: 918ms\n",
      "362:\tlearn: 0.0609259\ttotal: 2.41s\tremaining: 911ms\n",
      "363:\tlearn: 0.0605012\ttotal: 2.42s\tremaining: 903ms\n",
      "364:\tlearn: 0.0602054\ttotal: 2.42s\tremaining: 896ms\n",
      "365:\tlearn: 0.0599048\ttotal: 2.43s\tremaining: 889ms\n",
      "366:\tlearn: 0.0595701\ttotal: 2.43s\tremaining: 881ms\n",
      "367:\tlearn: 0.0593223\ttotal: 2.44s\tremaining: 874ms\n",
      "368:\tlearn: 0.0590820\ttotal: 2.44s\tremaining: 867ms\n",
      "369:\tlearn: 0.0587700\ttotal: 2.44s\tremaining: 859ms\n",
      "370:\tlearn: 0.0585212\ttotal: 2.45s\tremaining: 852ms\n",
      "371:\tlearn: 0.0582821\ttotal: 2.45s\tremaining: 844ms\n",
      "372:\tlearn: 0.0581150\ttotal: 2.46s\tremaining: 838ms\n",
      "373:\tlearn: 0.0578827\ttotal: 2.46s\tremaining: 830ms\n",
      "374:\tlearn: 0.0575449\ttotal: 2.47s\tremaining: 824ms\n",
      "375:\tlearn: 0.0572706\ttotal: 2.48s\tremaining: 819ms\n",
      "376:\tlearn: 0.0570205\ttotal: 2.49s\tremaining: 813ms\n",
      "377:\tlearn: 0.0567883\ttotal: 2.5s\tremaining: 808ms\n",
      "378:\tlearn: 0.0565093\ttotal: 2.51s\tremaining: 802ms\n",
      "379:\tlearn: 0.0563259\ttotal: 2.52s\tremaining: 797ms\n",
      "380:\tlearn: 0.0559413\ttotal: 2.53s\tremaining: 791ms\n",
      "381:\tlearn: 0.0557595\ttotal: 2.54s\tremaining: 785ms\n",
      "382:\tlearn: 0.0555519\ttotal: 2.55s\tremaining: 779ms\n",
      "383:\tlearn: 0.0553388\ttotal: 2.55s\tremaining: 772ms\n",
      "384:\tlearn: 0.0550514\ttotal: 2.56s\tremaining: 765ms\n",
      "385:\tlearn: 0.0548137\ttotal: 2.57s\tremaining: 758ms\n",
      "386:\tlearn: 0.0546652\ttotal: 2.57s\tremaining: 751ms\n",
      "387:\tlearn: 0.0543213\ttotal: 2.58s\tremaining: 745ms\n",
      "388:\tlearn: 0.0541597\ttotal: 2.58s\tremaining: 737ms\n",
      "389:\tlearn: 0.0539613\ttotal: 2.59s\tremaining: 730ms\n",
      "390:\tlearn: 0.0537054\ttotal: 2.59s\tremaining: 723ms\n",
      "391:\tlearn: 0.0536830\ttotal: 2.6s\tremaining: 716ms\n",
      "392:\tlearn: 0.0535487\ttotal: 2.6s\tremaining: 709ms\n",
      "393:\tlearn: 0.0533603\ttotal: 2.61s\tremaining: 702ms\n",
      "394:\tlearn: 0.0529293\ttotal: 2.61s\tremaining: 694ms\n",
      "395:\tlearn: 0.0526098\ttotal: 2.62s\tremaining: 687ms\n",
      "396:\tlearn: 0.0523487\ttotal: 2.62s\tremaining: 680ms\n",
      "397:\tlearn: 0.0521047\ttotal: 2.62s\tremaining: 673ms\n",
      "398:\tlearn: 0.0518540\ttotal: 2.63s\tremaining: 666ms\n",
      "399:\tlearn: 0.0515882\ttotal: 2.63s\tremaining: 658ms\n",
      "400:\tlearn: 0.0513501\ttotal: 2.64s\tremaining: 651ms\n",
      "401:\tlearn: 0.0511213\ttotal: 2.64s\tremaining: 644ms\n",
      "402:\tlearn: 0.0508459\ttotal: 2.65s\tremaining: 637ms\n",
      "403:\tlearn: 0.0506528\ttotal: 2.65s\tremaining: 629ms\n",
      "404:\tlearn: 0.0506348\ttotal: 2.65s\tremaining: 622ms\n",
      "405:\tlearn: 0.0504282\ttotal: 2.66s\tremaining: 615ms\n",
      "406:\tlearn: 0.0502364\ttotal: 2.66s\tremaining: 608ms\n",
      "407:\tlearn: 0.0500191\ttotal: 2.67s\tremaining: 602ms\n",
      "408:\tlearn: 0.0499013\ttotal: 2.68s\tremaining: 596ms\n",
      "409:\tlearn: 0.0496981\ttotal: 2.69s\tremaining: 591ms\n",
      "410:\tlearn: 0.0494831\ttotal: 2.7s\tremaining: 585ms\n",
      "411:\tlearn: 0.0493578\ttotal: 2.71s\tremaining: 579ms\n",
      "412:\tlearn: 0.0492349\ttotal: 2.72s\tremaining: 573ms\n",
      "413:\tlearn: 0.0489832\ttotal: 2.73s\tremaining: 567ms\n",
      "414:\tlearn: 0.0487290\ttotal: 2.74s\tremaining: 561ms\n",
      "415:\tlearn: 0.0485004\ttotal: 2.75s\tremaining: 555ms\n",
      "416:\tlearn: 0.0482506\ttotal: 2.75s\tremaining: 548ms\n",
      "417:\tlearn: 0.0481048\ttotal: 2.76s\tremaining: 542ms\n",
      "418:\tlearn: 0.0478562\ttotal: 2.77s\tremaining: 535ms\n",
      "419:\tlearn: 0.0476569\ttotal: 2.77s\tremaining: 528ms\n",
      "420:\tlearn: 0.0474682\ttotal: 2.78s\tremaining: 522ms\n",
      "421:\tlearn: 0.0472117\ttotal: 2.78s\tremaining: 515ms\n",
      "422:\tlearn: 0.0471044\ttotal: 2.79s\tremaining: 508ms\n",
      "423:\tlearn: 0.0469119\ttotal: 2.79s\tremaining: 501ms\n",
      "424:\tlearn: 0.0467079\ttotal: 2.8s\tremaining: 494ms\n",
      "425:\tlearn: 0.0464424\ttotal: 2.8s\tremaining: 487ms\n",
      "426:\tlearn: 0.0462896\ttotal: 2.81s\tremaining: 480ms\n",
      "427:\tlearn: 0.0460774\ttotal: 2.81s\tremaining: 473ms\n",
      "428:\tlearn: 0.0459024\ttotal: 2.82s\tremaining: 466ms\n",
      "429:\tlearn: 0.0456902\ttotal: 2.82s\tremaining: 459ms\n",
      "430:\tlearn: 0.0455012\ttotal: 2.83s\tremaining: 452ms\n",
      "431:\tlearn: 0.0451920\ttotal: 2.83s\tremaining: 445ms\n",
      "432:\tlearn: 0.0449946\ttotal: 2.84s\tremaining: 439ms\n",
      "433:\tlearn: 0.0448080\ttotal: 2.85s\tremaining: 433ms\n",
      "434:\tlearn: 0.0446861\ttotal: 2.86s\tremaining: 427ms\n",
      "435:\tlearn: 0.0444837\ttotal: 2.87s\tremaining: 421ms\n",
      "436:\tlearn: 0.0443210\ttotal: 2.88s\tremaining: 415ms\n",
      "437:\tlearn: 0.0441375\ttotal: 2.88s\tremaining: 408ms\n",
      "438:\tlearn: 0.0439208\ttotal: 2.9s\tremaining: 402ms\n",
      "439:\tlearn: 0.0437431\ttotal: 2.9s\tremaining: 396ms\n",
      "440:\tlearn: 0.0435233\ttotal: 2.92s\tremaining: 390ms\n",
      "441:\tlearn: 0.0432027\ttotal: 2.92s\tremaining: 384ms\n",
      "442:\tlearn: 0.0430226\ttotal: 2.93s\tremaining: 377ms\n",
      "443:\tlearn: 0.0428535\ttotal: 2.94s\tremaining: 371ms\n",
      "444:\tlearn: 0.0426653\ttotal: 2.94s\tremaining: 364ms\n",
      "445:\tlearn: 0.0424740\ttotal: 2.95s\tremaining: 357ms\n",
      "446:\tlearn: 0.0422135\ttotal: 2.96s\tremaining: 351ms\n",
      "447:\tlearn: 0.0421001\ttotal: 2.96s\tremaining: 344ms\n",
      "448:\tlearn: 0.0419152\ttotal: 2.97s\tremaining: 337ms\n",
      "449:\tlearn: 0.0417261\ttotal: 2.97s\tremaining: 330ms\n",
      "450:\tlearn: 0.0415320\ttotal: 2.98s\tremaining: 324ms\n",
      "451:\tlearn: 0.0413372\ttotal: 2.98s\tremaining: 317ms\n",
      "452:\tlearn: 0.0411595\ttotal: 2.99s\tremaining: 310ms\n",
      "453:\tlearn: 0.0409495\ttotal: 2.99s\tremaining: 303ms\n",
      "454:\tlearn: 0.0407436\ttotal: 3s\tremaining: 296ms\n",
      "455:\tlearn: 0.0405701\ttotal: 3s\tremaining: 290ms\n",
      "456:\tlearn: 0.0404662\ttotal: 3.02s\tremaining: 284ms\n",
      "457:\tlearn: 0.0402606\ttotal: 3.02s\tremaining: 277ms\n",
      "458:\tlearn: 0.0400319\ttotal: 3.04s\tremaining: 271ms\n",
      "459:\tlearn: 0.0398393\ttotal: 3.04s\tremaining: 265ms\n",
      "460:\tlearn: 0.0396897\ttotal: 3.05s\tremaining: 258ms\n",
      "461:\tlearn: 0.0394947\ttotal: 3.06s\tremaining: 252ms\n",
      "462:\tlearn: 0.0392674\ttotal: 3.07s\tremaining: 246ms\n",
      "463:\tlearn: 0.0391234\ttotal: 3.08s\tremaining: 239ms\n",
      "464:\tlearn: 0.0388719\ttotal: 3.09s\tremaining: 233ms\n",
      "465:\tlearn: 0.0386941\ttotal: 3.11s\tremaining: 227ms\n",
      "466:\tlearn: 0.0386058\ttotal: 3.11s\tremaining: 220ms\n",
      "467:\tlearn: 0.0384034\ttotal: 3.12s\tremaining: 213ms\n",
      "468:\tlearn: 0.0382518\ttotal: 3.12s\tremaining: 206ms\n",
      "469:\tlearn: 0.0380047\ttotal: 3.13s\tremaining: 200ms\n",
      "470:\tlearn: 0.0378639\ttotal: 3.13s\tremaining: 193ms\n",
      "471:\tlearn: 0.0377126\ttotal: 3.14s\tremaining: 186ms\n",
      "472:\tlearn: 0.0375603\ttotal: 3.14s\tremaining: 179ms\n",
      "473:\tlearn: 0.0373983\ttotal: 3.15s\tremaining: 173ms\n",
      "474:\tlearn: 0.0372583\ttotal: 3.15s\tremaining: 166ms\n",
      "475:\tlearn: 0.0370862\ttotal: 3.16s\tremaining: 159ms\n",
      "476:\tlearn: 0.0368907\ttotal: 3.16s\tremaining: 152ms\n",
      "477:\tlearn: 0.0367418\ttotal: 3.16s\tremaining: 146ms\n",
      "478:\tlearn: 0.0365708\ttotal: 3.17s\tremaining: 139ms\n",
      "479:\tlearn: 0.0364084\ttotal: 3.17s\tremaining: 132ms\n",
      "480:\tlearn: 0.0362381\ttotal: 3.18s\tremaining: 126ms\n",
      "481:\tlearn: 0.0360650\ttotal: 3.19s\tremaining: 119ms\n",
      "482:\tlearn: 0.0359004\ttotal: 3.2s\tremaining: 113ms\n",
      "483:\tlearn: 0.0357980\ttotal: 3.21s\tremaining: 106ms\n",
      "484:\tlearn: 0.0355323\ttotal: 3.22s\tremaining: 99.5ms\n",
      "485:\tlearn: 0.0353471\ttotal: 3.23s\tremaining: 92.9ms\n",
      "486:\tlearn: 0.0351778\ttotal: 3.24s\tremaining: 86.4ms\n",
      "487:\tlearn: 0.0350065\ttotal: 3.25s\tremaining: 79.8ms\n",
      "488:\tlearn: 0.0348646\ttotal: 3.26s\tremaining: 73.3ms\n",
      "489:\tlearn: 0.0346266\ttotal: 3.26s\tremaining: 66.6ms\n",
      "490:\tlearn: 0.0344693\ttotal: 3.27s\tremaining: 59.9ms\n",
      "491:\tlearn: 0.0342762\ttotal: 3.27s\tremaining: 53.3ms\n",
      "492:\tlearn: 0.0341416\ttotal: 3.28s\tremaining: 46.6ms\n",
      "493:\tlearn: 0.0339939\ttotal: 3.29s\tremaining: 39.9ms\n",
      "494:\tlearn: 0.0338635\ttotal: 3.29s\tremaining: 33.3ms\n",
      "495:\tlearn: 0.0337196\ttotal: 3.3s\tremaining: 26.6ms\n",
      "496:\tlearn: 0.0335567\ttotal: 3.3s\tremaining: 19.9ms\n",
      "497:\tlearn: 0.0332454\ttotal: 3.31s\tremaining: 13.3ms\n",
      "498:\tlearn: 0.0331261\ttotal: 3.31s\tremaining: 6.64ms\n",
      "499:\tlearn: 0.0329607\ttotal: 3.32s\tremaining: 0us\n",
      "0:\tlearn: 0.6811201\ttotal: 7.06ms\tremaining: 3.52s\n",
      "1:\tlearn: 0.6713832\ttotal: 13ms\tremaining: 3.24s\n",
      "2:\tlearn: 0.6622277\ttotal: 19.4ms\tremaining: 3.21s\n",
      "3:\tlearn: 0.6520369\ttotal: 25.7ms\tremaining: 3.18s\n",
      "4:\tlearn: 0.6430112\ttotal: 32ms\tremaining: 3.16s\n",
      "5:\tlearn: 0.6325407\ttotal: 36.8ms\tremaining: 3.03s\n",
      "6:\tlearn: 0.6244835\ttotal: 41.2ms\tremaining: 2.9s\n",
      "7:\tlearn: 0.6150857\ttotal: 45.7ms\tremaining: 2.81s\n",
      "8:\tlearn: 0.6071622\ttotal: 50.1ms\tremaining: 2.73s\n",
      "9:\tlearn: 0.5967798\ttotal: 54.7ms\tremaining: 2.68s\n",
      "10:\tlearn: 0.5896808\ttotal: 59.4ms\tremaining: 2.64s\n",
      "11:\tlearn: 0.5816335\ttotal: 63.7ms\tremaining: 2.59s\n",
      "12:\tlearn: 0.5712504\ttotal: 68ms\tremaining: 2.55s\n",
      "13:\tlearn: 0.5654295\ttotal: 72.1ms\tremaining: 2.5s\n",
      "14:\tlearn: 0.5600151\ttotal: 76.6ms\tremaining: 2.48s\n",
      "15:\tlearn: 0.5541586\ttotal: 81ms\tremaining: 2.45s\n",
      "16:\tlearn: 0.5491025\ttotal: 85ms\tremaining: 2.42s\n",
      "17:\tlearn: 0.5449118\ttotal: 89.4ms\tremaining: 2.39s\n",
      "18:\tlearn: 0.5385930\ttotal: 99.2ms\tremaining: 2.51s\n",
      "19:\tlearn: 0.5348561\ttotal: 109ms\tremaining: 2.61s\n",
      "20:\tlearn: 0.5293826\ttotal: 118ms\tremaining: 2.69s\n",
      "21:\tlearn: 0.5206543\ttotal: 128ms\tremaining: 2.78s\n",
      "22:\tlearn: 0.5155504\ttotal: 138ms\tremaining: 2.86s\n",
      "23:\tlearn: 0.5098199\ttotal: 148ms\tremaining: 2.93s\n",
      "24:\tlearn: 0.5064872\ttotal: 157ms\tremaining: 2.99s\n",
      "25:\tlearn: 0.4986240\ttotal: 166ms\tremaining: 3.02s\n",
      "26:\tlearn: 0.4952922\ttotal: 172ms\tremaining: 3.01s\n",
      "27:\tlearn: 0.4909607\ttotal: 177ms\tremaining: 2.98s\n",
      "28:\tlearn: 0.4870094\ttotal: 182ms\tremaining: 2.95s\n",
      "29:\tlearn: 0.4828195\ttotal: 185ms\tremaining: 2.9s\n",
      "30:\tlearn: 0.4781792\ttotal: 188ms\tremaining: 2.85s\n",
      "31:\tlearn: 0.4692177\ttotal: 193ms\tremaining: 2.82s\n",
      "32:\tlearn: 0.4645894\ttotal: 197ms\tremaining: 2.79s\n",
      "33:\tlearn: 0.4612949\ttotal: 207ms\tremaining: 2.83s\n",
      "34:\tlearn: 0.4580439\ttotal: 217ms\tremaining: 2.88s\n",
      "35:\tlearn: 0.4534810\ttotal: 226ms\tremaining: 2.92s\n",
      "36:\tlearn: 0.4495429\ttotal: 236ms\tremaining: 2.95s\n",
      "37:\tlearn: 0.4453472\ttotal: 246ms\tremaining: 2.99s\n",
      "38:\tlearn: 0.4408292\ttotal: 256ms\tremaining: 3.02s\n",
      "39:\tlearn: 0.4381080\ttotal: 265ms\tremaining: 3.05s\n",
      "40:\tlearn: 0.4333348\ttotal: 276ms\tremaining: 3.08s\n",
      "41:\tlearn: 0.4274801\ttotal: 285ms\tremaining: 3.11s\n",
      "42:\tlearn: 0.4235389\ttotal: 292ms\tremaining: 3.1s\n",
      "43:\tlearn: 0.4194729\ttotal: 298ms\tremaining: 3.08s\n",
      "44:\tlearn: 0.4161149\ttotal: 304ms\tremaining: 3.07s\n",
      "45:\tlearn: 0.4118629\ttotal: 310ms\tremaining: 3.06s\n",
      "46:\tlearn: 0.4081979\ttotal: 316ms\tremaining: 3.05s\n",
      "47:\tlearn: 0.4038318\ttotal: 321ms\tremaining: 3.02s\n",
      "48:\tlearn: 0.4010081\ttotal: 325ms\tremaining: 2.99s\n",
      "49:\tlearn: 0.3982128\ttotal: 329ms\tremaining: 2.96s\n",
      "50:\tlearn: 0.3955022\ttotal: 334ms\tremaining: 2.94s\n",
      "51:\tlearn: 0.3931051\ttotal: 339ms\tremaining: 2.92s\n",
      "52:\tlearn: 0.3907713\ttotal: 343ms\tremaining: 2.9s\n",
      "53:\tlearn: 0.3850932\ttotal: 348ms\tremaining: 2.88s\n",
      "54:\tlearn: 0.3796052\ttotal: 355ms\tremaining: 2.87s\n",
      "55:\tlearn: 0.3772832\ttotal: 360ms\tremaining: 2.85s\n",
      "56:\tlearn: 0.3742189\ttotal: 364ms\tremaining: 2.83s\n",
      "57:\tlearn: 0.3716636\ttotal: 368ms\tremaining: 2.81s\n",
      "58:\tlearn: 0.3692588\ttotal: 378ms\tremaining: 2.82s\n",
      "59:\tlearn: 0.3671926\ttotal: 387ms\tremaining: 2.84s\n",
      "60:\tlearn: 0.3647715\ttotal: 397ms\tremaining: 2.86s\n",
      "61:\tlearn: 0.3625360\ttotal: 407ms\tremaining: 2.87s\n",
      "62:\tlearn: 0.3603441\ttotal: 416ms\tremaining: 2.89s\n",
      "63:\tlearn: 0.3585956\ttotal: 426ms\tremaining: 2.9s\n",
      "64:\tlearn: 0.3567162\ttotal: 436ms\tremaining: 2.92s\n",
      "65:\tlearn: 0.3548789\ttotal: 445ms\tremaining: 2.93s\n",
      "66:\tlearn: 0.3523979\ttotal: 455ms\tremaining: 2.94s\n",
      "67:\tlearn: 0.3495051\ttotal: 461ms\tremaining: 2.93s\n",
      "68:\tlearn: 0.3482289\ttotal: 467ms\tremaining: 2.92s\n",
      "69:\tlearn: 0.3453490\ttotal: 473ms\tremaining: 2.91s\n",
      "70:\tlearn: 0.3426739\ttotal: 480ms\tremaining: 2.9s\n",
      "71:\tlearn: 0.3405385\ttotal: 486ms\tremaining: 2.89s\n",
      "72:\tlearn: 0.3369268\ttotal: 492ms\tremaining: 2.88s\n",
      "73:\tlearn: 0.3342602\ttotal: 497ms\tremaining: 2.86s\n",
      "74:\tlearn: 0.3307723\ttotal: 502ms\tremaining: 2.84s\n",
      "75:\tlearn: 0.3279766\ttotal: 506ms\tremaining: 2.82s\n",
      "76:\tlearn: 0.3265488\ttotal: 511ms\tremaining: 2.8s\n",
      "77:\tlearn: 0.3240499\ttotal: 515ms\tremaining: 2.78s\n",
      "78:\tlearn: 0.3198745\ttotal: 519ms\tremaining: 2.77s\n",
      "79:\tlearn: 0.3175052\ttotal: 524ms\tremaining: 2.75s\n",
      "80:\tlearn: 0.3157443\ttotal: 528ms\tremaining: 2.73s\n",
      "81:\tlearn: 0.3135263\ttotal: 532ms\tremaining: 2.71s\n",
      "82:\tlearn: 0.3095610\ttotal: 536ms\tremaining: 2.69s\n",
      "83:\tlearn: 0.3071970\ttotal: 549ms\tremaining: 2.72s\n",
      "84:\tlearn: 0.3059020\ttotal: 559ms\tremaining: 2.73s\n",
      "85:\tlearn: 0.3036809\ttotal: 569ms\tremaining: 2.74s\n",
      "86:\tlearn: 0.3013597\ttotal: 579ms\tremaining: 2.75s\n",
      "87:\tlearn: 0.2993487\ttotal: 588ms\tremaining: 2.75s\n",
      "88:\tlearn: 0.2967267\ttotal: 598ms\tremaining: 2.76s\n",
      "89:\tlearn: 0.2947317\ttotal: 608ms\tremaining: 2.77s\n",
      "90:\tlearn: 0.2923787\ttotal: 617ms\tremaining: 2.77s\n",
      "91:\tlearn: 0.2905086\ttotal: 627ms\tremaining: 2.78s\n",
      "92:\tlearn: 0.2886989\ttotal: 636ms\tremaining: 2.79s\n",
      "93:\tlearn: 0.2867589\ttotal: 643ms\tremaining: 2.77s\n",
      "94:\tlearn: 0.2851400\ttotal: 649ms\tremaining: 2.77s\n",
      "95:\tlearn: 0.2834238\ttotal: 653ms\tremaining: 2.75s\n",
      "96:\tlearn: 0.2814011\ttotal: 658ms\tremaining: 2.73s\n",
      "97:\tlearn: 0.2774734\ttotal: 663ms\tremaining: 2.72s\n",
      "98:\tlearn: 0.2744494\ttotal: 668ms\tremaining: 2.7s\n",
      "99:\tlearn: 0.2724838\ttotal: 672ms\tremaining: 2.69s\n",
      "100:\tlearn: 0.2709969\ttotal: 677ms\tremaining: 2.67s\n",
      "101:\tlearn: 0.2688198\ttotal: 682ms\tremaining: 2.66s\n",
      "102:\tlearn: 0.2669954\ttotal: 686ms\tremaining: 2.64s\n",
      "103:\tlearn: 0.2650403\ttotal: 690ms\tremaining: 2.63s\n",
      "104:\tlearn: 0.2633643\ttotal: 694ms\tremaining: 2.61s\n",
      "105:\tlearn: 0.2618312\ttotal: 699ms\tremaining: 2.6s\n",
      "106:\tlearn: 0.2597976\ttotal: 703ms\tremaining: 2.58s\n",
      "107:\tlearn: 0.2581946\ttotal: 707ms\tremaining: 2.57s\n",
      "108:\tlearn: 0.2564486\ttotal: 711ms\tremaining: 2.55s\n",
      "109:\tlearn: 0.2549064\ttotal: 721ms\tremaining: 2.56s\n",
      "110:\tlearn: 0.2532310\ttotal: 730ms\tremaining: 2.56s\n",
      "111:\tlearn: 0.2518484\ttotal: 740ms\tremaining: 2.56s\n",
      "112:\tlearn: 0.2504419\ttotal: 749ms\tremaining: 2.57s\n",
      "113:\tlearn: 0.2487786\ttotal: 759ms\tremaining: 2.57s\n",
      "114:\tlearn: 0.2474607\ttotal: 769ms\tremaining: 2.57s\n",
      "115:\tlearn: 0.2453615\ttotal: 779ms\tremaining: 2.58s\n",
      "116:\tlearn: 0.2435489\ttotal: 789ms\tremaining: 2.58s\n",
      "117:\tlearn: 0.2392030\ttotal: 795ms\tremaining: 2.57s\n",
      "118:\tlearn: 0.2375835\ttotal: 802ms\tremaining: 2.57s\n",
      "119:\tlearn: 0.2361151\ttotal: 808ms\tremaining: 2.56s\n",
      "120:\tlearn: 0.2347431\ttotal: 814ms\tremaining: 2.55s\n",
      "121:\tlearn: 0.2324253\ttotal: 820ms\tremaining: 2.54s\n",
      "122:\tlearn: 0.2310552\ttotal: 827ms\tremaining: 2.53s\n",
      "123:\tlearn: 0.2282231\ttotal: 833ms\tremaining: 2.52s\n",
      "124:\tlearn: 0.2270410\ttotal: 839ms\tremaining: 2.52s\n",
      "125:\tlearn: 0.2255874\ttotal: 845ms\tremaining: 2.51s\n",
      "126:\tlearn: 0.2241905\ttotal: 852ms\tremaining: 2.5s\n",
      "127:\tlearn: 0.2231918\ttotal: 856ms\tremaining: 2.49s\n",
      "128:\tlearn: 0.2219539\ttotal: 861ms\tremaining: 2.48s\n",
      "129:\tlearn: 0.2207910\ttotal: 866ms\tremaining: 2.46s\n",
      "130:\tlearn: 0.2191598\ttotal: 870ms\tremaining: 2.45s\n",
      "131:\tlearn: 0.2181941\ttotal: 875ms\tremaining: 2.44s\n",
      "132:\tlearn: 0.2159410\ttotal: 880ms\tremaining: 2.43s\n",
      "133:\tlearn: 0.2147440\ttotal: 884ms\tremaining: 2.42s\n",
      "134:\tlearn: 0.2136319\ttotal: 888ms\tremaining: 2.4s\n",
      "135:\tlearn: 0.2125459\ttotal: 891ms\tremaining: 2.38s\n",
      "136:\tlearn: 0.2113518\ttotal: 894ms\tremaining: 2.37s\n",
      "137:\tlearn: 0.2095983\ttotal: 899ms\tremaining: 2.36s\n",
      "138:\tlearn: 0.2084730\ttotal: 903ms\tremaining: 2.35s\n",
      "139:\tlearn: 0.2068894\ttotal: 913ms\tremaining: 2.35s\n",
      "140:\tlearn: 0.2047859\ttotal: 923ms\tremaining: 2.35s\n",
      "141:\tlearn: 0.2035444\ttotal: 932ms\tremaining: 2.35s\n",
      "142:\tlearn: 0.2020733\ttotal: 942ms\tremaining: 2.35s\n",
      "143:\tlearn: 0.1995997\ttotal: 951ms\tremaining: 2.35s\n",
      "144:\tlearn: 0.1983808\ttotal: 962ms\tremaining: 2.35s\n",
      "145:\tlearn: 0.1974312\ttotal: 971ms\tremaining: 2.35s\n",
      "146:\tlearn: 0.1952550\ttotal: 981ms\tremaining: 2.35s\n",
      "147:\tlearn: 0.1938641\ttotal: 989ms\tremaining: 2.35s\n",
      "148:\tlearn: 0.1928131\ttotal: 995ms\tremaining: 2.34s\n",
      "149:\tlearn: 0.1918044\ttotal: 1s\tremaining: 2.34s\n",
      "150:\tlearn: 0.1904618\ttotal: 1.01s\tremaining: 2.33s\n",
      "151:\tlearn: 0.1895211\ttotal: 1.01s\tremaining: 2.32s\n",
      "152:\tlearn: 0.1883280\ttotal: 1.02s\tremaining: 2.31s\n",
      "153:\tlearn: 0.1872977\ttotal: 1.02s\tremaining: 2.3s\n",
      "154:\tlearn: 0.1862376\ttotal: 1.03s\tremaining: 2.29s\n",
      "155:\tlearn: 0.1850021\ttotal: 1.03s\tremaining: 2.28s\n",
      "156:\tlearn: 0.1841921\ttotal: 1.04s\tremaining: 2.27s\n",
      "157:\tlearn: 0.1830631\ttotal: 1.04s\tremaining: 2.26s\n",
      "158:\tlearn: 0.1821488\ttotal: 1.05s\tremaining: 2.25s\n",
      "159:\tlearn: 0.1811315\ttotal: 1.05s\tremaining: 2.23s\n",
      "160:\tlearn: 0.1801646\ttotal: 1.05s\tremaining: 2.22s\n",
      "161:\tlearn: 0.1793033\ttotal: 1.06s\tremaining: 2.21s\n",
      "162:\tlearn: 0.1783185\ttotal: 1.07s\tremaining: 2.2s\n",
      "163:\tlearn: 0.1774355\ttotal: 1.07s\tremaining: 2.19s\n",
      "164:\tlearn: 0.1761865\ttotal: 1.07s\tremaining: 2.18s\n",
      "165:\tlearn: 0.1751566\ttotal: 1.08s\tremaining: 2.17s\n",
      "166:\tlearn: 0.1738039\ttotal: 1.09s\tremaining: 2.17s\n",
      "167:\tlearn: 0.1729206\ttotal: 1.1s\tremaining: 2.17s\n",
      "168:\tlearn: 0.1716162\ttotal: 1.11s\tremaining: 2.17s\n",
      "169:\tlearn: 0.1708334\ttotal: 1.12s\tremaining: 2.17s\n",
      "170:\tlearn: 0.1697385\ttotal: 1.13s\tremaining: 2.17s\n",
      "171:\tlearn: 0.1677038\ttotal: 1.14s\tremaining: 2.17s\n",
      "172:\tlearn: 0.1666044\ttotal: 1.15s\tremaining: 2.16s\n",
      "173:\tlearn: 0.1657126\ttotal: 1.16s\tremaining: 2.16s\n",
      "174:\tlearn: 0.1646237\ttotal: 1.16s\tremaining: 2.16s\n",
      "175:\tlearn: 0.1637745\ttotal: 1.17s\tremaining: 2.16s\n",
      "176:\tlearn: 0.1624820\ttotal: 1.18s\tremaining: 2.15s\n",
      "177:\tlearn: 0.1609823\ttotal: 1.18s\tremaining: 2.14s\n",
      "178:\tlearn: 0.1601663\ttotal: 1.19s\tremaining: 2.13s\n",
      "179:\tlearn: 0.1586659\ttotal: 1.2s\tremaining: 2.13s\n",
      "180:\tlearn: 0.1576705\ttotal: 1.2s\tremaining: 2.12s\n",
      "181:\tlearn: 0.1568357\ttotal: 1.21s\tremaining: 2.1s\n",
      "182:\tlearn: 0.1559921\ttotal: 1.21s\tremaining: 2.1s\n",
      "183:\tlearn: 0.1551480\ttotal: 1.21s\tremaining: 2.09s\n",
      "184:\tlearn: 0.1543005\ttotal: 1.22s\tremaining: 2.08s\n",
      "185:\tlearn: 0.1536039\ttotal: 1.22s\tremaining: 2.07s\n",
      "186:\tlearn: 0.1528017\ttotal: 1.23s\tremaining: 2.06s\n",
      "187:\tlearn: 0.1516763\ttotal: 1.23s\tremaining: 2.05s\n",
      "188:\tlearn: 0.1508598\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.1501540\ttotal: 1.24s\tremaining: 2.03s\n",
      "190:\tlearn: 0.1494518\ttotal: 1.25s\tremaining: 2.03s\n",
      "191:\tlearn: 0.1485810\ttotal: 1.26s\tremaining: 2.03s\n",
      "192:\tlearn: 0.1476269\ttotal: 1.27s\tremaining: 2.03s\n",
      "193:\tlearn: 0.1469419\ttotal: 1.28s\tremaining: 2.03s\n",
      "194:\tlearn: 0.1461824\ttotal: 1.29s\tremaining: 2.02s\n",
      "195:\tlearn: 0.1454879\ttotal: 1.3s\tremaining: 2.02s\n",
      "196:\tlearn: 0.1441229\ttotal: 1.31s\tremaining: 2.02s\n",
      "197:\tlearn: 0.1429618\ttotal: 1.32s\tremaining: 2.02s\n",
      "198:\tlearn: 0.1423085\ttotal: 1.33s\tremaining: 2.02s\n",
      "199:\tlearn: 0.1414509\ttotal: 1.34s\tremaining: 2.01s\n",
      "200:\tlearn: 0.1406136\ttotal: 1.35s\tremaining: 2s\n",
      "201:\tlearn: 0.1398893\ttotal: 1.35s\tremaining: 2s\n",
      "202:\tlearn: 0.1390829\ttotal: 1.36s\tremaining: 1.99s\n",
      "203:\tlearn: 0.1382389\ttotal: 1.36s\tremaining: 1.98s\n",
      "204:\tlearn: 0.1376039\ttotal: 1.37s\tremaining: 1.97s\n",
      "205:\tlearn: 0.1367948\ttotal: 1.37s\tremaining: 1.96s\n",
      "206:\tlearn: 0.1359438\ttotal: 1.38s\tremaining: 1.95s\n",
      "207:\tlearn: 0.1345306\ttotal: 1.38s\tremaining: 1.94s\n",
      "208:\tlearn: 0.1338455\ttotal: 1.39s\tremaining: 1.93s\n",
      "209:\tlearn: 0.1330986\ttotal: 1.39s\tremaining: 1.92s\n",
      "210:\tlearn: 0.1325634\ttotal: 1.39s\tremaining: 1.91s\n",
      "211:\tlearn: 0.1318621\ttotal: 1.4s\tremaining: 1.9s\n",
      "212:\tlearn: 0.1313795\ttotal: 1.4s\tremaining: 1.89s\n",
      "213:\tlearn: 0.1307593\ttotal: 1.41s\tremaining: 1.88s\n",
      "214:\tlearn: 0.1299872\ttotal: 1.41s\tremaining: 1.87s\n",
      "215:\tlearn: 0.1292683\ttotal: 1.42s\tremaining: 1.86s\n",
      "216:\tlearn: 0.1287458\ttotal: 1.43s\tremaining: 1.86s\n",
      "217:\tlearn: 0.1280623\ttotal: 1.44s\tremaining: 1.86s\n",
      "218:\tlearn: 0.1273973\ttotal: 1.45s\tremaining: 1.85s\n",
      "219:\tlearn: 0.1264406\ttotal: 1.46s\tremaining: 1.86s\n",
      "220:\tlearn: 0.1257073\ttotal: 1.47s\tremaining: 1.85s\n",
      "221:\tlearn: 0.1250677\ttotal: 1.48s\tremaining: 1.85s\n",
      "222:\tlearn: 0.1244472\ttotal: 1.49s\tremaining: 1.85s\n",
      "223:\tlearn: 0.1238845\ttotal: 1.5s\tremaining: 1.85s\n",
      "224:\tlearn: 0.1232122\ttotal: 1.51s\tremaining: 1.85s\n",
      "225:\tlearn: 0.1225769\ttotal: 1.52s\tremaining: 1.85s\n",
      "226:\tlearn: 0.1219753\ttotal: 1.53s\tremaining: 1.84s\n",
      "227:\tlearn: 0.1214035\ttotal: 1.54s\tremaining: 1.84s\n",
      "228:\tlearn: 0.1207800\ttotal: 1.55s\tremaining: 1.83s\n",
      "229:\tlearn: 0.1202014\ttotal: 1.56s\tremaining: 1.83s\n",
      "230:\tlearn: 0.1195039\ttotal: 1.57s\tremaining: 1.83s\n",
      "231:\tlearn: 0.1187051\ttotal: 1.58s\tremaining: 1.82s\n",
      "232:\tlearn: 0.1177615\ttotal: 1.58s\tremaining: 1.82s\n",
      "233:\tlearn: 0.1172784\ttotal: 1.59s\tremaining: 1.81s\n",
      "234:\tlearn: 0.1167530\ttotal: 1.59s\tremaining: 1.8s\n",
      "235:\tlearn: 0.1161393\ttotal: 1.6s\tremaining: 1.79s\n",
      "236:\tlearn: 0.1154308\ttotal: 1.6s\tremaining: 1.78s\n",
      "237:\tlearn: 0.1149151\ttotal: 1.61s\tremaining: 1.77s\n",
      "238:\tlearn: 0.1142528\ttotal: 1.61s\tremaining: 1.76s\n",
      "239:\tlearn: 0.1136134\ttotal: 1.62s\tremaining: 1.75s\n",
      "240:\tlearn: 0.1130201\ttotal: 1.62s\tremaining: 1.74s\n",
      "241:\tlearn: 0.1123928\ttotal: 1.63s\tremaining: 1.74s\n",
      "242:\tlearn: 0.1117243\ttotal: 1.63s\tremaining: 1.73s\n",
      "243:\tlearn: 0.1111246\ttotal: 1.64s\tremaining: 1.72s\n",
      "244:\tlearn: 0.1105389\ttotal: 1.64s\tremaining: 1.71s\n",
      "245:\tlearn: 0.1100056\ttotal: 1.65s\tremaining: 1.7s\n",
      "246:\tlearn: 0.1095683\ttotal: 1.66s\tremaining: 1.7s\n",
      "247:\tlearn: 0.1091071\ttotal: 1.67s\tremaining: 1.69s\n",
      "248:\tlearn: 0.1086750\ttotal: 1.68s\tremaining: 1.69s\n",
      "249:\tlearn: 0.1081665\ttotal: 1.69s\tremaining: 1.69s\n",
      "250:\tlearn: 0.1073172\ttotal: 1.7s\tremaining: 1.68s\n",
      "251:\tlearn: 0.1068902\ttotal: 1.71s\tremaining: 1.68s\n",
      "252:\tlearn: 0.1061405\ttotal: 1.71s\tremaining: 1.67s\n",
      "253:\tlearn: 0.1055138\ttotal: 1.72s\tremaining: 1.67s\n",
      "254:\tlearn: 0.1049910\ttotal: 1.73s\tremaining: 1.66s\n",
      "255:\tlearn: 0.1045281\ttotal: 1.73s\tremaining: 1.65s\n",
      "256:\tlearn: 0.1039609\ttotal: 1.74s\tremaining: 1.64s\n",
      "257:\tlearn: 0.1034417\ttotal: 1.74s\tremaining: 1.63s\n",
      "258:\tlearn: 0.1028325\ttotal: 1.75s\tremaining: 1.62s\n",
      "259:\tlearn: 0.1022806\ttotal: 1.75s\tremaining: 1.61s\n",
      "260:\tlearn: 0.1016863\ttotal: 1.75s\tremaining: 1.61s\n",
      "261:\tlearn: 0.1012678\ttotal: 1.76s\tremaining: 1.6s\n",
      "262:\tlearn: 0.1008156\ttotal: 1.76s\tremaining: 1.59s\n",
      "263:\tlearn: 0.1003482\ttotal: 1.77s\tremaining: 1.58s\n",
      "264:\tlearn: 0.0996177\ttotal: 1.77s\tremaining: 1.57s\n",
      "265:\tlearn: 0.0990703\ttotal: 1.77s\tremaining: 1.56s\n",
      "266:\tlearn: 0.0986278\ttotal: 1.78s\tremaining: 1.55s\n",
      "267:\tlearn: 0.0981581\ttotal: 1.78s\tremaining: 1.54s\n",
      "268:\tlearn: 0.0975566\ttotal: 1.79s\tremaining: 1.53s\n",
      "269:\tlearn: 0.0971392\ttotal: 1.79s\tremaining: 1.52s\n",
      "270:\tlearn: 0.0966805\ttotal: 1.8s\tremaining: 1.52s\n",
      "271:\tlearn: 0.0962104\ttotal: 1.81s\tremaining: 1.52s\n",
      "272:\tlearn: 0.0956161\ttotal: 1.82s\tremaining: 1.51s\n",
      "273:\tlearn: 0.0950575\ttotal: 1.83s\tremaining: 1.51s\n",
      "274:\tlearn: 0.0941609\ttotal: 1.84s\tremaining: 1.5s\n",
      "275:\tlearn: 0.0937032\ttotal: 1.85s\tremaining: 1.5s\n",
      "276:\tlearn: 0.0931338\ttotal: 1.86s\tremaining: 1.5s\n",
      "277:\tlearn: 0.0925151\ttotal: 1.87s\tremaining: 1.49s\n",
      "278:\tlearn: 0.0920367\ttotal: 1.88s\tremaining: 1.49s\n",
      "279:\tlearn: 0.0913803\ttotal: 1.88s\tremaining: 1.48s\n",
      "280:\tlearn: 0.0908279\ttotal: 1.88s\tremaining: 1.47s\n",
      "281:\tlearn: 0.0900992\ttotal: 1.89s\tremaining: 1.46s\n",
      "282:\tlearn: 0.0896612\ttotal: 1.89s\tremaining: 1.45s\n",
      "283:\tlearn: 0.0893769\ttotal: 1.9s\tremaining: 1.44s\n",
      "284:\tlearn: 0.0890054\ttotal: 1.9s\tremaining: 1.44s\n",
      "285:\tlearn: 0.0886645\ttotal: 1.91s\tremaining: 1.43s\n",
      "286:\tlearn: 0.0882305\ttotal: 1.91s\tremaining: 1.42s\n",
      "287:\tlearn: 0.0877963\ttotal: 1.92s\tremaining: 1.41s\n",
      "288:\tlearn: 0.0873433\ttotal: 1.92s\tremaining: 1.4s\n",
      "289:\tlearn: 0.0868949\ttotal: 1.93s\tremaining: 1.39s\n",
      "290:\tlearn: 0.0865565\ttotal: 1.93s\tremaining: 1.39s\n",
      "291:\tlearn: 0.0860988\ttotal: 1.93s\tremaining: 1.38s\n",
      "292:\tlearn: 0.0856541\ttotal: 1.94s\tremaining: 1.37s\n",
      "293:\tlearn: 0.0852696\ttotal: 1.94s\tremaining: 1.36s\n",
      "294:\tlearn: 0.0848135\ttotal: 1.95s\tremaining: 1.35s\n",
      "295:\tlearn: 0.0842681\ttotal: 1.96s\tremaining: 1.35s\n",
      "296:\tlearn: 0.0839083\ttotal: 1.97s\tremaining: 1.34s\n",
      "297:\tlearn: 0.0835673\ttotal: 1.98s\tremaining: 1.34s\n",
      "298:\tlearn: 0.0830881\ttotal: 1.99s\tremaining: 1.33s\n",
      "299:\tlearn: 0.0826974\ttotal: 2s\tremaining: 1.33s\n",
      "300:\tlearn: 0.0823427\ttotal: 2s\tremaining: 1.33s\n",
      "301:\tlearn: 0.0818062\ttotal: 2.02s\tremaining: 1.32s\n",
      "302:\tlearn: 0.0813260\ttotal: 2.02s\tremaining: 1.32s\n",
      "303:\tlearn: 0.0809495\ttotal: 2.04s\tremaining: 1.31s\n",
      "304:\tlearn: 0.0806258\ttotal: 2.04s\tremaining: 1.31s\n",
      "305:\tlearn: 0.0801838\ttotal: 2.05s\tremaining: 1.3s\n",
      "306:\tlearn: 0.0795060\ttotal: 2.06s\tremaining: 1.29s\n",
      "307:\tlearn: 0.0790913\ttotal: 2.06s\tremaining: 1.29s\n",
      "308:\tlearn: 0.0787479\ttotal: 2.07s\tremaining: 1.28s\n",
      "309:\tlearn: 0.0783417\ttotal: 2.08s\tremaining: 1.27s\n",
      "310:\tlearn: 0.0780371\ttotal: 2.08s\tremaining: 1.26s\n",
      "311:\tlearn: 0.0776262\ttotal: 2.09s\tremaining: 1.26s\n",
      "312:\tlearn: 0.0772299\ttotal: 2.09s\tremaining: 1.25s\n",
      "313:\tlearn: 0.0767583\ttotal: 2.1s\tremaining: 1.24s\n",
      "314:\tlearn: 0.0760729\ttotal: 2.1s\tremaining: 1.23s\n",
      "315:\tlearn: 0.0757245\ttotal: 2.1s\tremaining: 1.23s\n",
      "316:\tlearn: 0.0752360\ttotal: 2.11s\tremaining: 1.22s\n",
      "317:\tlearn: 0.0748519\ttotal: 2.12s\tremaining: 1.21s\n",
      "318:\tlearn: 0.0745222\ttotal: 2.12s\tremaining: 1.2s\n",
      "319:\tlearn: 0.0742150\ttotal: 2.12s\tremaining: 1.19s\n",
      "320:\tlearn: 0.0738143\ttotal: 2.13s\tremaining: 1.19s\n",
      "321:\tlearn: 0.0732787\ttotal: 2.13s\tremaining: 1.18s\n",
      "322:\tlearn: 0.0727431\ttotal: 2.14s\tremaining: 1.17s\n",
      "323:\tlearn: 0.0723679\ttotal: 2.14s\tremaining: 1.16s\n",
      "324:\tlearn: 0.0720173\ttotal: 2.15s\tremaining: 1.16s\n",
      "325:\tlearn: 0.0717597\ttotal: 2.16s\tremaining: 1.15s\n",
      "326:\tlearn: 0.0713921\ttotal: 2.17s\tremaining: 1.15s\n",
      "327:\tlearn: 0.0711533\ttotal: 2.18s\tremaining: 1.14s\n",
      "328:\tlearn: 0.0707799\ttotal: 2.19s\tremaining: 1.14s\n",
      "329:\tlearn: 0.0703504\ttotal: 2.2s\tremaining: 1.13s\n",
      "330:\tlearn: 0.0700262\ttotal: 2.21s\tremaining: 1.13s\n",
      "331:\tlearn: 0.0697271\ttotal: 2.22s\tremaining: 1.12s\n",
      "332:\tlearn: 0.0694285\ttotal: 2.23s\tremaining: 1.12s\n",
      "333:\tlearn: 0.0690587\ttotal: 2.24s\tremaining: 1.11s\n",
      "334:\tlearn: 0.0687723\ttotal: 2.24s\tremaining: 1.1s\n",
      "335:\tlearn: 0.0682793\ttotal: 2.25s\tremaining: 1.1s\n",
      "336:\tlearn: 0.0678975\ttotal: 2.26s\tremaining: 1.09s\n",
      "337:\tlearn: 0.0675519\ttotal: 2.26s\tremaining: 1.08s\n",
      "338:\tlearn: 0.0673276\ttotal: 2.27s\tremaining: 1.08s\n",
      "339:\tlearn: 0.0670771\ttotal: 2.27s\tremaining: 1.07s\n",
      "340:\tlearn: 0.0668671\ttotal: 2.28s\tremaining: 1.06s\n",
      "341:\tlearn: 0.0664355\ttotal: 2.28s\tremaining: 1.05s\n",
      "342:\tlearn: 0.0661674\ttotal: 2.29s\tremaining: 1.05s\n",
      "343:\tlearn: 0.0657927\ttotal: 2.29s\tremaining: 1.04s\n",
      "344:\tlearn: 0.0654707\ttotal: 2.29s\tremaining: 1.03s\n",
      "345:\tlearn: 0.0651788\ttotal: 2.3s\tremaining: 1.02s\n",
      "346:\tlearn: 0.0648265\ttotal: 2.3s\tremaining: 1.01s\n",
      "347:\tlearn: 0.0645540\ttotal: 2.31s\tremaining: 1.01s\n",
      "348:\tlearn: 0.0642225\ttotal: 2.32s\tremaining: 1s\n",
      "349:\tlearn: 0.0639594\ttotal: 2.33s\tremaining: 997ms\n",
      "350:\tlearn: 0.0637254\ttotal: 2.34s\tremaining: 992ms\n",
      "351:\tlearn: 0.0634268\ttotal: 2.35s\tremaining: 986ms\n",
      "352:\tlearn: 0.0631265\ttotal: 2.35s\tremaining: 981ms\n",
      "353:\tlearn: 0.0628820\ttotal: 2.36s\tremaining: 975ms\n",
      "354:\tlearn: 0.0625795\ttotal: 2.37s\tremaining: 970ms\n",
      "355:\tlearn: 0.0623814\ttotal: 2.38s\tremaining: 964ms\n",
      "356:\tlearn: 0.0621039\ttotal: 2.39s\tremaining: 959ms\n",
      "357:\tlearn: 0.0617454\ttotal: 2.4s\tremaining: 952ms\n",
      "358:\tlearn: 0.0614380\ttotal: 2.4s\tremaining: 945ms\n",
      "359:\tlearn: 0.0610700\ttotal: 2.41s\tremaining: 938ms\n",
      "360:\tlearn: 0.0608306\ttotal: 2.42s\tremaining: 931ms\n",
      "361:\tlearn: 0.0604792\ttotal: 2.42s\tremaining: 924ms\n",
      "362:\tlearn: 0.0602683\ttotal: 2.43s\tremaining: 917ms\n",
      "363:\tlearn: 0.0600120\ttotal: 2.44s\tremaining: 910ms\n",
      "364:\tlearn: 0.0596865\ttotal: 2.44s\tremaining: 903ms\n",
      "365:\tlearn: 0.0593778\ttotal: 2.44s\tremaining: 895ms\n",
      "366:\tlearn: 0.0591741\ttotal: 2.45s\tremaining: 888ms\n",
      "367:\tlearn: 0.0588372\ttotal: 2.45s\tremaining: 880ms\n",
      "368:\tlearn: 0.0585157\ttotal: 2.46s\tremaining: 873ms\n",
      "369:\tlearn: 0.0582233\ttotal: 2.46s\tremaining: 865ms\n",
      "370:\tlearn: 0.0579809\ttotal: 2.47s\tremaining: 858ms\n",
      "371:\tlearn: 0.0576890\ttotal: 2.47s\tremaining: 850ms\n",
      "372:\tlearn: 0.0574330\ttotal: 2.47s\tremaining: 843ms\n",
      "373:\tlearn: 0.0571288\ttotal: 2.48s\tremaining: 837ms\n",
      "374:\tlearn: 0.0568460\ttotal: 2.49s\tremaining: 831ms\n",
      "375:\tlearn: 0.0565690\ttotal: 2.5s\tremaining: 826ms\n",
      "376:\tlearn: 0.0562805\ttotal: 2.51s\tremaining: 820ms\n",
      "377:\tlearn: 0.0559648\ttotal: 2.52s\tremaining: 814ms\n",
      "378:\tlearn: 0.0556512\ttotal: 2.53s\tremaining: 809ms\n",
      "379:\tlearn: 0.0553957\ttotal: 2.54s\tremaining: 803ms\n",
      "380:\tlearn: 0.0550500\ttotal: 2.55s\tremaining: 797ms\n",
      "381:\tlearn: 0.0547920\ttotal: 2.56s\tremaining: 790ms\n",
      "382:\tlearn: 0.0545406\ttotal: 2.56s\tremaining: 783ms\n",
      "383:\tlearn: 0.0542573\ttotal: 2.57s\tremaining: 776ms\n",
      "384:\tlearn: 0.0540826\ttotal: 2.57s\tremaining: 768ms\n",
      "385:\tlearn: 0.0538745\ttotal: 2.58s\tremaining: 761ms\n",
      "386:\tlearn: 0.0536214\ttotal: 2.58s\tremaining: 754ms\n",
      "387:\tlearn: 0.0533410\ttotal: 2.59s\tremaining: 747ms\n",
      "388:\tlearn: 0.0530550\ttotal: 2.59s\tremaining: 739ms\n",
      "389:\tlearn: 0.0527023\ttotal: 2.6s\tremaining: 732ms\n",
      "390:\tlearn: 0.0524227\ttotal: 2.6s\tremaining: 725ms\n",
      "391:\tlearn: 0.0521524\ttotal: 2.6s\tremaining: 717ms\n",
      "392:\tlearn: 0.0518509\ttotal: 2.61s\tremaining: 710ms\n",
      "393:\tlearn: 0.0516471\ttotal: 2.61s\tremaining: 703ms\n",
      "394:\tlearn: 0.0513635\ttotal: 2.62s\tremaining: 696ms\n",
      "395:\tlearn: 0.0511249\ttotal: 2.63s\tremaining: 690ms\n",
      "396:\tlearn: 0.0509208\ttotal: 2.64s\tremaining: 684ms\n",
      "397:\tlearn: 0.0506904\ttotal: 2.65s\tremaining: 678ms\n",
      "398:\tlearn: 0.0504251\ttotal: 2.65s\tremaining: 672ms\n",
      "399:\tlearn: 0.0501856\ttotal: 2.67s\tremaining: 666ms\n",
      "400:\tlearn: 0.0499664\ttotal: 2.67s\tremaining: 660ms\n",
      "401:\tlearn: 0.0497622\ttotal: 2.68s\tremaining: 654ms\n",
      "402:\tlearn: 0.0495158\ttotal: 2.69s\tremaining: 649ms\n",
      "403:\tlearn: 0.0492354\ttotal: 2.7s\tremaining: 642ms\n",
      "404:\tlearn: 0.0488561\ttotal: 2.71s\tremaining: 636ms\n",
      "405:\tlearn: 0.0486622\ttotal: 2.71s\tremaining: 629ms\n",
      "406:\tlearn: 0.0484820\ttotal: 2.72s\tremaining: 622ms\n",
      "407:\tlearn: 0.0482485\ttotal: 2.73s\tremaining: 615ms\n",
      "408:\tlearn: 0.0479877\ttotal: 2.73s\tremaining: 608ms\n",
      "409:\tlearn: 0.0477688\ttotal: 2.74s\tremaining: 601ms\n",
      "410:\tlearn: 0.0475620\ttotal: 2.74s\tremaining: 594ms\n",
      "411:\tlearn: 0.0472574\ttotal: 2.75s\tremaining: 587ms\n",
      "412:\tlearn: 0.0470397\ttotal: 2.75s\tremaining: 580ms\n",
      "413:\tlearn: 0.0466726\ttotal: 2.76s\tremaining: 573ms\n",
      "414:\tlearn: 0.0464257\ttotal: 2.76s\tremaining: 565ms\n",
      "415:\tlearn: 0.0462786\ttotal: 2.76s\tremaining: 558ms\n",
      "416:\tlearn: 0.0459992\ttotal: 2.77s\tremaining: 551ms\n",
      "417:\tlearn: 0.0456737\ttotal: 2.77s\tremaining: 544ms\n",
      "418:\tlearn: 0.0454675\ttotal: 2.78s\tremaining: 537ms\n",
      "419:\tlearn: 0.0450062\ttotal: 2.78s\tremaining: 530ms\n",
      "420:\tlearn: 0.0449046\ttotal: 2.79s\tremaining: 523ms\n",
      "421:\tlearn: 0.0445524\ttotal: 2.79s\tremaining: 517ms\n",
      "422:\tlearn: 0.0443747\ttotal: 2.81s\tremaining: 511ms\n",
      "423:\tlearn: 0.0441654\ttotal: 2.81s\tremaining: 505ms\n",
      "424:\tlearn: 0.0439463\ttotal: 2.83s\tremaining: 499ms\n",
      "425:\tlearn: 0.0436498\ttotal: 2.83s\tremaining: 492ms\n",
      "426:\tlearn: 0.0434568\ttotal: 2.84s\tremaining: 486ms\n",
      "427:\tlearn: 0.0432005\ttotal: 2.85s\tremaining: 480ms\n",
      "428:\tlearn: 0.0430117\ttotal: 2.86s\tremaining: 474ms\n",
      "429:\tlearn: 0.0428336\ttotal: 2.87s\tremaining: 468ms\n",
      "430:\tlearn: 0.0426762\ttotal: 2.88s\tremaining: 461ms\n",
      "431:\tlearn: 0.0424628\ttotal: 2.89s\tremaining: 455ms\n",
      "432:\tlearn: 0.0421202\ttotal: 2.9s\tremaining: 448ms\n",
      "433:\tlearn: 0.0419393\ttotal: 2.9s\tremaining: 441ms\n",
      "434:\tlearn: 0.0417893\ttotal: 2.91s\tremaining: 434ms\n",
      "435:\tlearn: 0.0416764\ttotal: 2.91s\tremaining: 428ms\n",
      "436:\tlearn: 0.0415057\ttotal: 2.92s\tremaining: 421ms\n",
      "437:\tlearn: 0.0413226\ttotal: 2.92s\tremaining: 414ms\n",
      "438:\tlearn: 0.0411942\ttotal: 2.93s\tremaining: 407ms\n",
      "439:\tlearn: 0.0410427\ttotal: 2.93s\tremaining: 400ms\n",
      "440:\tlearn: 0.0408434\ttotal: 2.94s\tremaining: 393ms\n",
      "441:\tlearn: 0.0406585\ttotal: 2.94s\tremaining: 386ms\n",
      "442:\tlearn: 0.0404179\ttotal: 2.94s\tremaining: 379ms\n",
      "443:\tlearn: 0.0401669\ttotal: 2.95s\tremaining: 372ms\n",
      "444:\tlearn: 0.0400229\ttotal: 2.95s\tremaining: 365ms\n",
      "445:\tlearn: 0.0398620\ttotal: 2.96s\tremaining: 358ms\n",
      "446:\tlearn: 0.0396869\ttotal: 2.96s\tremaining: 351ms\n",
      "447:\tlearn: 0.0395421\ttotal: 2.96s\tremaining: 344ms\n",
      "448:\tlearn: 0.0393015\ttotal: 2.97s\tremaining: 338ms\n",
      "449:\tlearn: 0.0391613\ttotal: 2.98s\tremaining: 332ms\n",
      "450:\tlearn: 0.0390396\ttotal: 2.99s\tremaining: 325ms\n",
      "451:\tlearn: 0.0388371\ttotal: 3s\tremaining: 319ms\n",
      "452:\tlearn: 0.0386791\ttotal: 3.01s\tremaining: 313ms\n",
      "453:\tlearn: 0.0384972\ttotal: 3.02s\tremaining: 306ms\n",
      "454:\tlearn: 0.0382890\ttotal: 3.03s\tremaining: 300ms\n",
      "455:\tlearn: 0.0381678\ttotal: 3.04s\tremaining: 294ms\n",
      "456:\tlearn: 0.0379587\ttotal: 3.05s\tremaining: 287ms\n",
      "457:\tlearn: 0.0377991\ttotal: 3.06s\tremaining: 280ms\n",
      "458:\tlearn: 0.0376137\ttotal: 3.06s\tremaining: 274ms\n",
      "459:\tlearn: 0.0374635\ttotal: 3.07s\tremaining: 267ms\n",
      "460:\tlearn: 0.0373250\ttotal: 3.08s\tremaining: 260ms\n",
      "461:\tlearn: 0.0371610\ttotal: 3.08s\tremaining: 253ms\n",
      "462:\tlearn: 0.0369412\ttotal: 3.08s\tremaining: 247ms\n",
      "463:\tlearn: 0.0368006\ttotal: 3.09s\tremaining: 240ms\n",
      "464:\tlearn: 0.0366041\ttotal: 3.09s\tremaining: 233ms\n",
      "465:\tlearn: 0.0364523\ttotal: 3.1s\tremaining: 226ms\n",
      "466:\tlearn: 0.0363260\ttotal: 3.1s\tremaining: 219ms\n",
      "467:\tlearn: 0.0361827\ttotal: 3.11s\tremaining: 213ms\n",
      "468:\tlearn: 0.0360118\ttotal: 3.11s\tremaining: 206ms\n",
      "469:\tlearn: 0.0357971\ttotal: 3.12s\tremaining: 199ms\n",
      "470:\tlearn: 0.0356472\ttotal: 3.12s\tremaining: 192ms\n",
      "471:\tlearn: 0.0354326\ttotal: 3.12s\tremaining: 185ms\n",
      "472:\tlearn: 0.0353205\ttotal: 3.13s\tremaining: 179ms\n",
      "473:\tlearn: 0.0351999\ttotal: 3.14s\tremaining: 172ms\n",
      "474:\tlearn: 0.0350763\ttotal: 3.15s\tremaining: 166ms\n",
      "475:\tlearn: 0.0349516\ttotal: 3.16s\tremaining: 160ms\n",
      "476:\tlearn: 0.0348122\ttotal: 3.17s\tremaining: 153ms\n",
      "477:\tlearn: 0.0346857\ttotal: 3.18s\tremaining: 146ms\n",
      "478:\tlearn: 0.0345343\ttotal: 3.19s\tremaining: 140ms\n",
      "479:\tlearn: 0.0343919\ttotal: 3.2s\tremaining: 133ms\n",
      "480:\tlearn: 0.0342313\ttotal: 3.21s\tremaining: 127ms\n",
      "481:\tlearn: 0.0340947\ttotal: 3.22s\tremaining: 120ms\n",
      "482:\tlearn: 0.0339420\ttotal: 3.23s\tremaining: 114ms\n",
      "483:\tlearn: 0.0338452\ttotal: 3.23s\tremaining: 107ms\n",
      "484:\tlearn: 0.0336700\ttotal: 3.24s\tremaining: 100ms\n",
      "485:\tlearn: 0.0335118\ttotal: 3.25s\tremaining: 93.5ms\n",
      "486:\tlearn: 0.0333493\ttotal: 3.25s\tremaining: 86.8ms\n",
      "487:\tlearn: 0.0332060\ttotal: 3.26s\tremaining: 80.1ms\n",
      "488:\tlearn: 0.0331185\ttotal: 3.26s\tremaining: 73.4ms\n",
      "489:\tlearn: 0.0329785\ttotal: 3.27s\tremaining: 66.7ms\n",
      "490:\tlearn: 0.0328531\ttotal: 3.27s\tremaining: 60ms\n",
      "491:\tlearn: 0.0327086\ttotal: 3.27s\tremaining: 53.3ms\n",
      "492:\tlearn: 0.0324472\ttotal: 3.28s\tremaining: 46.6ms\n",
      "493:\tlearn: 0.0322942\ttotal: 3.29s\tremaining: 39.9ms\n",
      "494:\tlearn: 0.0321605\ttotal: 3.29s\tremaining: 33.2ms\n",
      "495:\tlearn: 0.0319965\ttotal: 3.29s\tremaining: 26.6ms\n",
      "496:\tlearn: 0.0317365\ttotal: 3.3s\tremaining: 19.9ms\n",
      "497:\tlearn: 0.0316319\ttotal: 3.3s\tremaining: 13.3ms\n",
      "498:\tlearn: 0.0314448\ttotal: 3.31s\tremaining: 6.63ms\n",
      "499:\tlearn: 0.0312916\ttotal: 3.31s\tremaining: 0us\n",
      "0:\tlearn: 0.6809174\ttotal: 5.26ms\tremaining: 2.63s\n",
      "1:\tlearn: 0.6686759\ttotal: 9.79ms\tremaining: 2.44s\n",
      "2:\tlearn: 0.6568023\ttotal: 14.6ms\tremaining: 2.42s\n",
      "3:\tlearn: 0.6465113\ttotal: 19.3ms\tremaining: 2.39s\n",
      "4:\tlearn: 0.6375501\ttotal: 24.1ms\tremaining: 2.38s\n",
      "5:\tlearn: 0.6265755\ttotal: 28.7ms\tremaining: 2.36s\n",
      "6:\tlearn: 0.6133231\ttotal: 33.2ms\tremaining: 2.34s\n",
      "7:\tlearn: 0.6054503\ttotal: 37.7ms\tremaining: 2.32s\n",
      "8:\tlearn: 0.5978515\ttotal: 42ms\tremaining: 2.29s\n",
      "9:\tlearn: 0.5903478\ttotal: 46.3ms\tremaining: 2.27s\n",
      "10:\tlearn: 0.5837090\ttotal: 50.7ms\tremaining: 2.25s\n",
      "11:\tlearn: 0.5760912\ttotal: 54.9ms\tremaining: 2.23s\n",
      "12:\tlearn: 0.5693529\ttotal: 59.3ms\tremaining: 2.22s\n",
      "13:\tlearn: 0.5634280\ttotal: 63.5ms\tremaining: 2.21s\n",
      "14:\tlearn: 0.5575718\ttotal: 68ms\tremaining: 2.2s\n",
      "15:\tlearn: 0.5523249\ttotal: 72.2ms\tremaining: 2.19s\n",
      "16:\tlearn: 0.5447018\ttotal: 76.7ms\tremaining: 2.18s\n",
      "17:\tlearn: 0.5362835\ttotal: 81ms\tremaining: 2.17s\n",
      "18:\tlearn: 0.5308729\ttotal: 85.7ms\tremaining: 2.17s\n",
      "19:\tlearn: 0.5278653\ttotal: 91.1ms\tremaining: 2.19s\n",
      "20:\tlearn: 0.5229962\ttotal: 95.9ms\tremaining: 2.19s\n",
      "21:\tlearn: 0.5186282\ttotal: 101ms\tremaining: 2.2s\n",
      "22:\tlearn: 0.5103441\ttotal: 111ms\tremaining: 2.3s\n",
      "23:\tlearn: 0.5062196\ttotal: 120ms\tremaining: 2.38s\n",
      "24:\tlearn: 0.5014121\ttotal: 130ms\tremaining: 2.46s\n",
      "25:\tlearn: 0.4937998\ttotal: 139ms\tremaining: 2.54s\n",
      "26:\tlearn: 0.4898580\ttotal: 149ms\tremaining: 2.61s\n",
      "27:\tlearn: 0.4855677\ttotal: 159ms\tremaining: 2.67s\n",
      "28:\tlearn: 0.4814392\ttotal: 168ms\tremaining: 2.73s\n",
      "29:\tlearn: 0.4781217\ttotal: 178ms\tremaining: 2.78s\n",
      "30:\tlearn: 0.4733484\ttotal: 190ms\tremaining: 2.88s\n",
      "31:\tlearn: 0.4678627\ttotal: 199ms\tremaining: 2.9s\n",
      "32:\tlearn: 0.4638537\ttotal: 207ms\tremaining: 2.92s\n",
      "33:\tlearn: 0.4591090\ttotal: 210ms\tremaining: 2.88s\n",
      "34:\tlearn: 0.4560859\ttotal: 213ms\tremaining: 2.83s\n",
      "35:\tlearn: 0.4485270\ttotal: 219ms\tremaining: 2.82s\n",
      "36:\tlearn: 0.4453821\ttotal: 223ms\tremaining: 2.79s\n",
      "37:\tlearn: 0.4420272\ttotal: 228ms\tremaining: 2.77s\n",
      "38:\tlearn: 0.4384577\ttotal: 232ms\tremaining: 2.74s\n",
      "39:\tlearn: 0.4349720\ttotal: 236ms\tremaining: 2.72s\n",
      "40:\tlearn: 0.4327605\ttotal: 240ms\tremaining: 2.69s\n",
      "41:\tlearn: 0.4295341\ttotal: 245ms\tremaining: 2.67s\n",
      "42:\tlearn: 0.4262916\ttotal: 249ms\tremaining: 2.65s\n",
      "43:\tlearn: 0.4222790\ttotal: 254ms\tremaining: 2.63s\n",
      "44:\tlearn: 0.4202079\ttotal: 258ms\tremaining: 2.61s\n",
      "45:\tlearn: 0.4172682\ttotal: 262ms\tremaining: 2.59s\n",
      "46:\tlearn: 0.4156065\ttotal: 266ms\tremaining: 2.57s\n",
      "47:\tlearn: 0.4110824\ttotal: 271ms\tremaining: 2.55s\n",
      "48:\tlearn: 0.4089576\ttotal: 281ms\tremaining: 2.58s\n",
      "49:\tlearn: 0.4065052\ttotal: 290ms\tremaining: 2.61s\n",
      "50:\tlearn: 0.4026585\ttotal: 300ms\tremaining: 2.64s\n",
      "51:\tlearn: 0.3991914\ttotal: 309ms\tremaining: 2.66s\n",
      "52:\tlearn: 0.3960707\ttotal: 319ms\tremaining: 2.69s\n",
      "53:\tlearn: 0.3934766\ttotal: 329ms\tremaining: 2.71s\n",
      "54:\tlearn: 0.3907657\ttotal: 338ms\tremaining: 2.74s\n",
      "55:\tlearn: 0.3876469\ttotal: 349ms\tremaining: 2.77s\n",
      "56:\tlearn: 0.3849220\ttotal: 355ms\tremaining: 2.76s\n",
      "57:\tlearn: 0.3827350\ttotal: 362ms\tremaining: 2.75s\n",
      "58:\tlearn: 0.3803499\ttotal: 370ms\tremaining: 2.77s\n",
      "59:\tlearn: 0.3762182\ttotal: 376ms\tremaining: 2.75s\n",
      "60:\tlearn: 0.3745351\ttotal: 380ms\tremaining: 2.73s\n",
      "61:\tlearn: 0.3689431\ttotal: 384ms\tremaining: 2.71s\n",
      "62:\tlearn: 0.3647106\ttotal: 389ms\tremaining: 2.69s\n",
      "63:\tlearn: 0.3628102\ttotal: 393ms\tremaining: 2.68s\n",
      "64:\tlearn: 0.3595976\ttotal: 398ms\tremaining: 2.66s\n",
      "65:\tlearn: 0.3573331\ttotal: 402ms\tremaining: 2.65s\n",
      "66:\tlearn: 0.3556349\ttotal: 408ms\tremaining: 2.63s\n",
      "67:\tlearn: 0.3528934\ttotal: 411ms\tremaining: 2.61s\n",
      "68:\tlearn: 0.3505738\ttotal: 416ms\tremaining: 2.6s\n",
      "69:\tlearn: 0.3481646\ttotal: 420ms\tremaining: 2.58s\n",
      "70:\tlearn: 0.3449542\ttotal: 424ms\tremaining: 2.56s\n",
      "71:\tlearn: 0.3426382\ttotal: 428ms\tremaining: 2.55s\n",
      "72:\tlearn: 0.3397307\ttotal: 432ms\tremaining: 2.53s\n",
      "73:\tlearn: 0.3375325\ttotal: 442ms\tremaining: 2.54s\n",
      "74:\tlearn: 0.3348178\ttotal: 452ms\tremaining: 2.56s\n",
      "75:\tlearn: 0.3317205\ttotal: 461ms\tremaining: 2.57s\n",
      "76:\tlearn: 0.3287057\ttotal: 471ms\tremaining: 2.59s\n",
      "77:\tlearn: 0.3263633\ttotal: 480ms\tremaining: 2.6s\n",
      "78:\tlearn: 0.3243329\ttotal: 490ms\tremaining: 2.61s\n",
      "79:\tlearn: 0.3223997\ttotal: 500ms\tremaining: 2.62s\n",
      "80:\tlearn: 0.3201111\ttotal: 509ms\tremaining: 2.63s\n",
      "81:\tlearn: 0.3182778\ttotal: 519ms\tremaining: 2.65s\n",
      "82:\tlearn: 0.3163161\ttotal: 526ms\tremaining: 2.64s\n",
      "83:\tlearn: 0.3143642\ttotal: 532ms\tremaining: 2.63s\n",
      "84:\tlearn: 0.3124466\ttotal: 538ms\tremaining: 2.63s\n",
      "85:\tlearn: 0.3100965\ttotal: 547ms\tremaining: 2.63s\n",
      "86:\tlearn: 0.3080403\ttotal: 553ms\tremaining: 2.63s\n",
      "87:\tlearn: 0.3020234\ttotal: 558ms\tremaining: 2.61s\n",
      "88:\tlearn: 0.2999546\ttotal: 563ms\tremaining: 2.6s\n",
      "89:\tlearn: 0.2979418\ttotal: 567ms\tremaining: 2.58s\n",
      "90:\tlearn: 0.2948499\ttotal: 571ms\tremaining: 2.57s\n",
      "91:\tlearn: 0.2929584\ttotal: 576ms\tremaining: 2.55s\n",
      "92:\tlearn: 0.2910919\ttotal: 580ms\tremaining: 2.54s\n",
      "93:\tlearn: 0.2891602\ttotal: 584ms\tremaining: 2.52s\n",
      "94:\tlearn: 0.2872661\ttotal: 588ms\tremaining: 2.51s\n",
      "95:\tlearn: 0.2853606\ttotal: 593ms\tremaining: 2.49s\n",
      "96:\tlearn: 0.2832349\ttotal: 597ms\tremaining: 2.48s\n",
      "97:\tlearn: 0.2810509\ttotal: 601ms\tremaining: 2.47s\n",
      "98:\tlearn: 0.2790145\ttotal: 606ms\tremaining: 2.45s\n",
      "99:\tlearn: 0.2772412\ttotal: 610ms\tremaining: 2.44s\n",
      "100:\tlearn: 0.2756117\ttotal: 615ms\tremaining: 2.43s\n",
      "101:\tlearn: 0.2737845\ttotal: 619ms\tremaining: 2.42s\n",
      "102:\tlearn: 0.2719122\ttotal: 624ms\tremaining: 2.4s\n",
      "103:\tlearn: 0.2700625\ttotal: 628ms\tremaining: 2.39s\n",
      "104:\tlearn: 0.2686047\ttotal: 632ms\tremaining: 2.38s\n",
      "105:\tlearn: 0.2666229\ttotal: 639ms\tremaining: 2.38s\n",
      "106:\tlearn: 0.2651634\ttotal: 649ms\tremaining: 2.38s\n",
      "107:\tlearn: 0.2628945\ttotal: 658ms\tremaining: 2.39s\n",
      "108:\tlearn: 0.2613227\ttotal: 668ms\tremaining: 2.4s\n",
      "109:\tlearn: 0.2596322\ttotal: 678ms\tremaining: 2.4s\n",
      "110:\tlearn: 0.2584185\ttotal: 687ms\tremaining: 2.41s\n",
      "111:\tlearn: 0.2554678\ttotal: 697ms\tremaining: 2.42s\n",
      "112:\tlearn: 0.2537556\ttotal: 707ms\tremaining: 2.42s\n",
      "113:\tlearn: 0.2522438\ttotal: 716ms\tremaining: 2.42s\n",
      "114:\tlearn: 0.2506602\ttotal: 726ms\tremaining: 2.43s\n",
      "115:\tlearn: 0.2490528\ttotal: 734ms\tremaining: 2.43s\n",
      "116:\tlearn: 0.2475985\ttotal: 741ms\tremaining: 2.42s\n",
      "117:\tlearn: 0.2454581\ttotal: 748ms\tremaining: 2.42s\n",
      "118:\tlearn: 0.2427125\ttotal: 753ms\tremaining: 2.41s\n",
      "119:\tlearn: 0.2410392\ttotal: 757ms\tremaining: 2.4s\n",
      "120:\tlearn: 0.2396523\ttotal: 761ms\tremaining: 2.38s\n",
      "121:\tlearn: 0.2382723\ttotal: 766ms\tremaining: 2.37s\n",
      "122:\tlearn: 0.2365651\ttotal: 771ms\tremaining: 2.36s\n",
      "123:\tlearn: 0.2350364\ttotal: 775ms\tremaining: 2.35s\n",
      "124:\tlearn: 0.2338564\ttotal: 779ms\tremaining: 2.34s\n",
      "125:\tlearn: 0.2325474\ttotal: 784ms\tremaining: 2.33s\n",
      "126:\tlearn: 0.2312505\ttotal: 788ms\tremaining: 2.31s\n",
      "127:\tlearn: 0.2299134\ttotal: 793ms\tremaining: 2.3s\n",
      "128:\tlearn: 0.2271672\ttotal: 797ms\tremaining: 2.29s\n",
      "129:\tlearn: 0.2255267\ttotal: 802ms\tremaining: 2.28s\n",
      "130:\tlearn: 0.2238206\ttotal: 806ms\tremaining: 2.27s\n",
      "131:\tlearn: 0.2225080\ttotal: 816ms\tremaining: 2.27s\n",
      "132:\tlearn: 0.2208551\ttotal: 826ms\tremaining: 2.28s\n",
      "133:\tlearn: 0.2196851\ttotal: 835ms\tremaining: 2.28s\n",
      "134:\tlearn: 0.2169019\ttotal: 845ms\tremaining: 2.28s\n",
      "135:\tlearn: 0.2140424\ttotal: 855ms\tremaining: 2.29s\n",
      "136:\tlearn: 0.2128756\ttotal: 864ms\tremaining: 2.29s\n",
      "137:\tlearn: 0.2117032\ttotal: 874ms\tremaining: 2.29s\n",
      "138:\tlearn: 0.2101549\ttotal: 884ms\tremaining: 2.29s\n",
      "139:\tlearn: 0.2087662\ttotal: 892ms\tremaining: 2.29s\n",
      "140:\tlearn: 0.2075561\ttotal: 899ms\tremaining: 2.29s\n",
      "141:\tlearn: 0.2060666\ttotal: 907ms\tremaining: 2.29s\n",
      "142:\tlearn: 0.2047810\ttotal: 914ms\tremaining: 2.28s\n",
      "143:\tlearn: 0.2037491\ttotal: 920ms\tremaining: 2.27s\n",
      "144:\tlearn: 0.2026917\ttotal: 926ms\tremaining: 2.27s\n",
      "145:\tlearn: 0.2015534\ttotal: 931ms\tremaining: 2.26s\n",
      "146:\tlearn: 0.2002780\ttotal: 935ms\tremaining: 2.24s\n",
      "147:\tlearn: 0.1989846\ttotal: 939ms\tremaining: 2.23s\n",
      "148:\tlearn: 0.1978451\ttotal: 944ms\tremaining: 2.22s\n",
      "149:\tlearn: 0.1964184\ttotal: 948ms\tremaining: 2.21s\n",
      "150:\tlearn: 0.1942054\ttotal: 953ms\tremaining: 2.2s\n",
      "151:\tlearn: 0.1927997\ttotal: 957ms\tremaining: 2.19s\n",
      "152:\tlearn: 0.1914227\ttotal: 961ms\tremaining: 2.18s\n",
      "153:\tlearn: 0.1903376\ttotal: 966ms\tremaining: 2.17s\n",
      "154:\tlearn: 0.1896012\ttotal: 970ms\tremaining: 2.16s\n",
      "155:\tlearn: 0.1885151\ttotal: 974ms\tremaining: 2.15s\n",
      "156:\tlearn: 0.1874942\ttotal: 979ms\tremaining: 2.14s\n",
      "157:\tlearn: 0.1863791\ttotal: 983ms\tremaining: 2.13s\n",
      "158:\tlearn: 0.1850565\ttotal: 993ms\tremaining: 2.13s\n",
      "159:\tlearn: 0.1838203\ttotal: 1s\tremaining: 2.13s\n",
      "160:\tlearn: 0.1829791\ttotal: 1.01s\tremaining: 2.13s\n",
      "161:\tlearn: 0.1817588\ttotal: 1.02s\tremaining: 2.13s\n",
      "162:\tlearn: 0.1807496\ttotal: 1.03s\tremaining: 2.13s\n",
      "163:\tlearn: 0.1794760\ttotal: 1.04s\tremaining: 2.13s\n",
      "164:\tlearn: 0.1782485\ttotal: 1.05s\tremaining: 2.13s\n",
      "165:\tlearn: 0.1769392\ttotal: 1.06s\tremaining: 2.13s\n",
      "166:\tlearn: 0.1759608\ttotal: 1.07s\tremaining: 2.13s\n",
      "167:\tlearn: 0.1751031\ttotal: 1.08s\tremaining: 2.13s\n",
      "168:\tlearn: 0.1740414\ttotal: 1.08s\tremaining: 2.13s\n",
      "169:\tlearn: 0.1730971\ttotal: 1.09s\tremaining: 2.12s\n",
      "170:\tlearn: 0.1719880\ttotal: 1.1s\tremaining: 2.11s\n",
      "171:\tlearn: 0.1710487\ttotal: 1.1s\tremaining: 2.1s\n",
      "172:\tlearn: 0.1704505\ttotal: 1.11s\tremaining: 2.09s\n",
      "173:\tlearn: 0.1697047\ttotal: 1.11s\tremaining: 2.08s\n",
      "174:\tlearn: 0.1687789\ttotal: 1.12s\tremaining: 2.07s\n",
      "175:\tlearn: 0.1678739\ttotal: 1.12s\tremaining: 2.06s\n",
      "176:\tlearn: 0.1668754\ttotal: 1.12s\tremaining: 2.05s\n",
      "177:\tlearn: 0.1653084\ttotal: 1.13s\tremaining: 2.04s\n",
      "178:\tlearn: 0.1638209\ttotal: 1.13s\tremaining: 2.03s\n",
      "179:\tlearn: 0.1628351\ttotal: 1.14s\tremaining: 2.02s\n",
      "180:\tlearn: 0.1619619\ttotal: 1.14s\tremaining: 2.01s\n",
      "181:\tlearn: 0.1610187\ttotal: 1.15s\tremaining: 2s\n",
      "182:\tlearn: 0.1602654\ttotal: 1.15s\tremaining: 1.99s\n",
      "183:\tlearn: 0.1595675\ttotal: 1.16s\tremaining: 1.99s\n",
      "184:\tlearn: 0.1587403\ttotal: 1.17s\tremaining: 1.98s\n",
      "185:\tlearn: 0.1580239\ttotal: 1.18s\tremaining: 1.98s\n",
      "186:\tlearn: 0.1567038\ttotal: 1.18s\tremaining: 1.98s\n",
      "187:\tlearn: 0.1562096\ttotal: 1.19s\tremaining: 1.98s\n",
      "188:\tlearn: 0.1553681\ttotal: 1.2s\tremaining: 1.98s\n",
      "189:\tlearn: 0.1543342\ttotal: 1.21s\tremaining: 1.98s\n",
      "190:\tlearn: 0.1533569\ttotal: 1.22s\tremaining: 1.98s\n",
      "191:\tlearn: 0.1525961\ttotal: 1.23s\tremaining: 1.98s\n",
      "192:\tlearn: 0.1518264\ttotal: 1.24s\tremaining: 1.98s\n",
      "193:\tlearn: 0.1510143\ttotal: 1.25s\tremaining: 1.97s\n",
      "194:\tlearn: 0.1500700\ttotal: 1.26s\tremaining: 1.96s\n",
      "195:\tlearn: 0.1494091\ttotal: 1.26s\tremaining: 1.96s\n",
      "196:\tlearn: 0.1487183\ttotal: 1.27s\tremaining: 1.95s\n",
      "197:\tlearn: 0.1479134\ttotal: 1.27s\tremaining: 1.94s\n",
      "198:\tlearn: 0.1469166\ttotal: 1.27s\tremaining: 1.93s\n",
      "199:\tlearn: 0.1458982\ttotal: 1.28s\tremaining: 1.92s\n",
      "200:\tlearn: 0.1451372\ttotal: 1.28s\tremaining: 1.91s\n",
      "201:\tlearn: 0.1442994\ttotal: 1.29s\tremaining: 1.9s\n",
      "202:\tlearn: 0.1435492\ttotal: 1.29s\tremaining: 1.89s\n",
      "203:\tlearn: 0.1431019\ttotal: 1.3s\tremaining: 1.88s\n",
      "204:\tlearn: 0.1423700\ttotal: 1.3s\tremaining: 1.87s\n",
      "205:\tlearn: 0.1415989\ttotal: 1.3s\tremaining: 1.86s\n",
      "206:\tlearn: 0.1408533\ttotal: 1.31s\tremaining: 1.85s\n",
      "207:\tlearn: 0.1399862\ttotal: 1.31s\tremaining: 1.84s\n",
      "208:\tlearn: 0.1394227\ttotal: 1.32s\tremaining: 1.83s\n",
      "209:\tlearn: 0.1386296\ttotal: 1.32s\tremaining: 1.82s\n",
      "210:\tlearn: 0.1378504\ttotal: 1.33s\tremaining: 1.82s\n",
      "211:\tlearn: 0.1374407\ttotal: 1.34s\tremaining: 1.82s\n",
      "212:\tlearn: 0.1366399\ttotal: 1.35s\tremaining: 1.82s\n",
      "213:\tlearn: 0.1358122\ttotal: 1.36s\tremaining: 1.82s\n",
      "214:\tlearn: 0.1346670\ttotal: 1.37s\tremaining: 1.81s\n",
      "215:\tlearn: 0.1332249\ttotal: 1.38s\tremaining: 1.81s\n",
      "216:\tlearn: 0.1325376\ttotal: 1.39s\tremaining: 1.81s\n",
      "217:\tlearn: 0.1318195\ttotal: 1.4s\tremaining: 1.81s\n",
      "218:\tlearn: 0.1312389\ttotal: 1.41s\tremaining: 1.81s\n",
      "219:\tlearn: 0.1306646\ttotal: 1.41s\tremaining: 1.8s\n",
      "220:\tlearn: 0.1298386\ttotal: 1.42s\tremaining: 1.79s\n",
      "221:\tlearn: 0.1291947\ttotal: 1.43s\tremaining: 1.79s\n",
      "222:\tlearn: 0.1278849\ttotal: 1.43s\tremaining: 1.78s\n",
      "223:\tlearn: 0.1273122\ttotal: 1.44s\tremaining: 1.77s\n",
      "224:\tlearn: 0.1262826\ttotal: 1.44s\tremaining: 1.76s\n",
      "225:\tlearn: 0.1250833\ttotal: 1.45s\tremaining: 1.76s\n",
      "226:\tlearn: 0.1238367\ttotal: 1.45s\tremaining: 1.75s\n",
      "227:\tlearn: 0.1232807\ttotal: 1.46s\tremaining: 1.74s\n",
      "228:\tlearn: 0.1226674\ttotal: 1.46s\tremaining: 1.73s\n",
      "229:\tlearn: 0.1220990\ttotal: 1.47s\tremaining: 1.72s\n",
      "230:\tlearn: 0.1214527\ttotal: 1.47s\tremaining: 1.71s\n",
      "231:\tlearn: 0.1207851\ttotal: 1.47s\tremaining: 1.7s\n",
      "232:\tlearn: 0.1201691\ttotal: 1.48s\tremaining: 1.69s\n",
      "233:\tlearn: 0.1195788\ttotal: 1.48s\tremaining: 1.69s\n",
      "234:\tlearn: 0.1189493\ttotal: 1.49s\tremaining: 1.68s\n",
      "235:\tlearn: 0.1181460\ttotal: 1.5s\tremaining: 1.68s\n",
      "236:\tlearn: 0.1176365\ttotal: 1.51s\tremaining: 1.68s\n",
      "237:\tlearn: 0.1170582\ttotal: 1.52s\tremaining: 1.68s\n",
      "238:\tlearn: 0.1167939\ttotal: 1.53s\tremaining: 1.67s\n",
      "239:\tlearn: 0.1162542\ttotal: 1.54s\tremaining: 1.67s\n",
      "240:\tlearn: 0.1156396\ttotal: 1.55s\tremaining: 1.67s\n",
      "241:\tlearn: 0.1150598\ttotal: 1.56s\tremaining: 1.67s\n",
      "242:\tlearn: 0.1144813\ttotal: 1.57s\tremaining: 1.66s\n",
      "243:\tlearn: 0.1136073\ttotal: 1.58s\tremaining: 1.66s\n",
      "244:\tlearn: 0.1131206\ttotal: 1.59s\tremaining: 1.65s\n",
      "245:\tlearn: 0.1125145\ttotal: 1.59s\tremaining: 1.64s\n",
      "246:\tlearn: 0.1118404\ttotal: 1.6s\tremaining: 1.64s\n",
      "247:\tlearn: 0.1108978\ttotal: 1.6s\tremaining: 1.63s\n",
      "248:\tlearn: 0.1102896\ttotal: 1.61s\tremaining: 1.62s\n",
      "249:\tlearn: 0.1094837\ttotal: 1.61s\tremaining: 1.61s\n",
      "250:\tlearn: 0.1090052\ttotal: 1.62s\tremaining: 1.6s\n",
      "251:\tlearn: 0.1084460\ttotal: 1.62s\tremaining: 1.6s\n",
      "252:\tlearn: 0.1078855\ttotal: 1.63s\tremaining: 1.59s\n",
      "253:\tlearn: 0.1073883\ttotal: 1.63s\tremaining: 1.58s\n",
      "254:\tlearn: 0.1068495\ttotal: 1.64s\tremaining: 1.57s\n",
      "255:\tlearn: 0.1063349\ttotal: 1.64s\tremaining: 1.56s\n",
      "256:\tlearn: 0.1057562\ttotal: 1.65s\tremaining: 1.56s\n",
      "257:\tlearn: 0.1051921\ttotal: 1.65s\tremaining: 1.55s\n",
      "258:\tlearn: 0.1045992\ttotal: 1.66s\tremaining: 1.54s\n",
      "259:\tlearn: 0.1041443\ttotal: 1.66s\tremaining: 1.53s\n",
      "260:\tlearn: 0.1037630\ttotal: 1.67s\tremaining: 1.52s\n",
      "261:\tlearn: 0.1032621\ttotal: 1.67s\tremaining: 1.52s\n",
      "262:\tlearn: 0.1029042\ttotal: 1.67s\tremaining: 1.51s\n",
      "263:\tlearn: 0.1024399\ttotal: 1.68s\tremaining: 1.5s\n",
      "264:\tlearn: 0.1019221\ttotal: 1.68s\tremaining: 1.49s\n",
      "265:\tlearn: 0.1013520\ttotal: 1.69s\tremaining: 1.48s\n",
      "266:\tlearn: 0.1008757\ttotal: 1.69s\tremaining: 1.48s\n",
      "267:\tlearn: 0.1003902\ttotal: 1.7s\tremaining: 1.47s\n",
      "268:\tlearn: 0.0999278\ttotal: 1.7s\tremaining: 1.46s\n",
      "269:\tlearn: 0.0994908\ttotal: 1.71s\tremaining: 1.45s\n",
      "270:\tlearn: 0.0989603\ttotal: 1.71s\tremaining: 1.45s\n",
      "271:\tlearn: 0.0983868\ttotal: 1.72s\tremaining: 1.44s\n",
      "272:\tlearn: 0.0979160\ttotal: 1.73s\tremaining: 1.44s\n",
      "273:\tlearn: 0.0973167\ttotal: 1.74s\tremaining: 1.43s\n",
      "274:\tlearn: 0.0966442\ttotal: 1.75s\tremaining: 1.43s\n",
      "275:\tlearn: 0.0961118\ttotal: 1.76s\tremaining: 1.43s\n",
      "276:\tlearn: 0.0957003\ttotal: 1.77s\tremaining: 1.42s\n",
      "277:\tlearn: 0.0950498\ttotal: 1.78s\tremaining: 1.42s\n",
      "278:\tlearn: 0.0946514\ttotal: 1.79s\tremaining: 1.42s\n",
      "279:\tlearn: 0.0942072\ttotal: 1.79s\tremaining: 1.41s\n",
      "280:\tlearn: 0.0936645\ttotal: 1.8s\tremaining: 1.4s\n",
      "281:\tlearn: 0.0932450\ttotal: 1.81s\tremaining: 1.4s\n",
      "282:\tlearn: 0.0927754\ttotal: 1.81s\tremaining: 1.39s\n",
      "283:\tlearn: 0.0922405\ttotal: 1.82s\tremaining: 1.39s\n",
      "284:\tlearn: 0.0921758\ttotal: 1.83s\tremaining: 1.38s\n",
      "285:\tlearn: 0.0916129\ttotal: 1.83s\tremaining: 1.37s\n",
      "286:\tlearn: 0.0912637\ttotal: 1.83s\tremaining: 1.36s\n",
      "287:\tlearn: 0.0908673\ttotal: 1.84s\tremaining: 1.35s\n",
      "288:\tlearn: 0.0899927\ttotal: 1.84s\tremaining: 1.35s\n",
      "289:\tlearn: 0.0892794\ttotal: 1.85s\tremaining: 1.34s\n",
      "290:\tlearn: 0.0889198\ttotal: 1.85s\tremaining: 1.33s\n",
      "291:\tlearn: 0.0884880\ttotal: 1.86s\tremaining: 1.32s\n",
      "292:\tlearn: 0.0878482\ttotal: 1.86s\tremaining: 1.32s\n",
      "293:\tlearn: 0.0874038\ttotal: 1.87s\tremaining: 1.31s\n",
      "294:\tlearn: 0.0869591\ttotal: 1.87s\tremaining: 1.3s\n",
      "295:\tlearn: 0.0865517\ttotal: 1.88s\tremaining: 1.29s\n",
      "296:\tlearn: 0.0860374\ttotal: 1.88s\tremaining: 1.28s\n",
      "297:\tlearn: 0.0855874\ttotal: 1.89s\tremaining: 1.28s\n",
      "298:\tlearn: 0.0852102\ttotal: 1.9s\tremaining: 1.28s\n",
      "299:\tlearn: 0.0848811\ttotal: 1.91s\tremaining: 1.27s\n",
      "300:\tlearn: 0.0845519\ttotal: 1.92s\tremaining: 1.27s\n",
      "301:\tlearn: 0.0844959\ttotal: 1.93s\tremaining: 1.26s\n",
      "302:\tlearn: 0.0841158\ttotal: 1.94s\tremaining: 1.26s\n",
      "303:\tlearn: 0.0838276\ttotal: 1.95s\tremaining: 1.26s\n",
      "304:\tlearn: 0.0832794\ttotal: 1.96s\tremaining: 1.25s\n",
      "305:\tlearn: 0.0829380\ttotal: 1.97s\tremaining: 1.25s\n",
      "306:\tlearn: 0.0824474\ttotal: 1.97s\tremaining: 1.24s\n",
      "307:\tlearn: 0.0820666\ttotal: 1.98s\tremaining: 1.24s\n",
      "308:\tlearn: 0.0816902\ttotal: 1.99s\tremaining: 1.23s\n",
      "309:\tlearn: 0.0812878\ttotal: 1.99s\tremaining: 1.22s\n",
      "310:\tlearn: 0.0809069\ttotal: 2s\tremaining: 1.21s\n",
      "311:\tlearn: 0.0807253\ttotal: 2s\tremaining: 1.21s\n",
      "312:\tlearn: 0.0804344\ttotal: 2.01s\tremaining: 1.2s\n",
      "313:\tlearn: 0.0801983\ttotal: 2.01s\tremaining: 1.19s\n",
      "314:\tlearn: 0.0797566\ttotal: 2.02s\tremaining: 1.19s\n",
      "315:\tlearn: 0.0793944\ttotal: 2.02s\tremaining: 1.18s\n",
      "316:\tlearn: 0.0790295\ttotal: 2.03s\tremaining: 1.17s\n",
      "317:\tlearn: 0.0785838\ttotal: 2.03s\tremaining: 1.16s\n",
      "318:\tlearn: 0.0782602\ttotal: 2.04s\tremaining: 1.16s\n",
      "319:\tlearn: 0.0778703\ttotal: 2.04s\tremaining: 1.15s\n",
      "320:\tlearn: 0.0774913\ttotal: 2.04s\tremaining: 1.14s\n",
      "321:\tlearn: 0.0770546\ttotal: 2.05s\tremaining: 1.13s\n",
      "322:\tlearn: 0.0766604\ttotal: 2.06s\tremaining: 1.13s\n",
      "323:\tlearn: 0.0762928\ttotal: 2.07s\tremaining: 1.12s\n",
      "324:\tlearn: 0.0759726\ttotal: 2.08s\tremaining: 1.12s\n",
      "325:\tlearn: 0.0756670\ttotal: 2.09s\tremaining: 1.11s\n",
      "326:\tlearn: 0.0753542\ttotal: 2.1s\tremaining: 1.11s\n",
      "327:\tlearn: 0.0749088\ttotal: 2.11s\tremaining: 1.1s\n",
      "328:\tlearn: 0.0745364\ttotal: 2.12s\tremaining: 1.1s\n",
      "329:\tlearn: 0.0742471\ttotal: 2.13s\tremaining: 1.09s\n",
      "330:\tlearn: 0.0738896\ttotal: 2.13s\tremaining: 1.09s\n",
      "331:\tlearn: 0.0734948\ttotal: 2.14s\tremaining: 1.08s\n",
      "332:\tlearn: 0.0733216\ttotal: 2.15s\tremaining: 1.08s\n",
      "333:\tlearn: 0.0730157\ttotal: 2.16s\tremaining: 1.07s\n",
      "334:\tlearn: 0.0726684\ttotal: 2.17s\tremaining: 1.07s\n",
      "335:\tlearn: 0.0723695\ttotal: 2.17s\tremaining: 1.06s\n",
      "336:\tlearn: 0.0720894\ttotal: 2.17s\tremaining: 1.05s\n",
      "337:\tlearn: 0.0717701\ttotal: 2.18s\tremaining: 1.04s\n",
      "338:\tlearn: 0.0713787\ttotal: 2.18s\tremaining: 1.04s\n",
      "339:\tlearn: 0.0711548\ttotal: 2.19s\tremaining: 1.03s\n",
      "340:\tlearn: 0.0706856\ttotal: 2.19s\tremaining: 1.02s\n",
      "341:\tlearn: 0.0703681\ttotal: 2.2s\tremaining: 1.01s\n",
      "342:\tlearn: 0.0700230\ttotal: 2.2s\tremaining: 1.01s\n",
      "343:\tlearn: 0.0697426\ttotal: 2.21s\tremaining: 1s\n",
      "344:\tlearn: 0.0695306\ttotal: 2.21s\tremaining: 993ms\n",
      "345:\tlearn: 0.0690812\ttotal: 2.21s\tremaining: 985ms\n",
      "346:\tlearn: 0.0686725\ttotal: 2.22s\tremaining: 978ms\n",
      "347:\tlearn: 0.0682920\ttotal: 2.23s\tremaining: 973ms\n",
      "348:\tlearn: 0.0679304\ttotal: 2.24s\tremaining: 968ms\n",
      "349:\tlearn: 0.0676618\ttotal: 2.25s\tremaining: 963ms\n",
      "350:\tlearn: 0.0673026\ttotal: 2.26s\tremaining: 958ms\n",
      "351:\tlearn: 0.0671296\ttotal: 2.27s\tremaining: 953ms\n",
      "352:\tlearn: 0.0668706\ttotal: 2.28s\tremaining: 948ms\n",
      "353:\tlearn: 0.0664467\ttotal: 2.29s\tremaining: 943ms\n",
      "354:\tlearn: 0.0662586\ttotal: 2.29s\tremaining: 938ms\n",
      "355:\tlearn: 0.0658876\ttotal: 2.31s\tremaining: 933ms\n",
      "356:\tlearn: 0.0653785\ttotal: 2.31s\tremaining: 927ms\n",
      "357:\tlearn: 0.0648612\ttotal: 2.32s\tremaining: 921ms\n",
      "358:\tlearn: 0.0645416\ttotal: 2.33s\tremaining: 914ms\n",
      "359:\tlearn: 0.0643081\ttotal: 2.33s\tremaining: 908ms\n",
      "360:\tlearn: 0.0640694\ttotal: 2.34s\tremaining: 901ms\n",
      "361:\tlearn: 0.0638244\ttotal: 2.35s\tremaining: 894ms\n",
      "362:\tlearn: 0.0635666\ttotal: 2.35s\tremaining: 888ms\n",
      "363:\tlearn: 0.0632961\ttotal: 2.36s\tremaining: 881ms\n",
      "364:\tlearn: 0.0630050\ttotal: 2.36s\tremaining: 874ms\n",
      "365:\tlearn: 0.0626876\ttotal: 2.37s\tremaining: 867ms\n",
      "366:\tlearn: 0.0624792\ttotal: 2.37s\tremaining: 860ms\n",
      "367:\tlearn: 0.0621816\ttotal: 2.38s\tremaining: 853ms\n",
      "368:\tlearn: 0.0619867\ttotal: 2.38s\tremaining: 845ms\n",
      "369:\tlearn: 0.0616828\ttotal: 2.38s\tremaining: 838ms\n",
      "370:\tlearn: 0.0613783\ttotal: 2.39s\tremaining: 831ms\n",
      "371:\tlearn: 0.0610879\ttotal: 2.4s\tremaining: 825ms\n",
      "372:\tlearn: 0.0608011\ttotal: 2.41s\tremaining: 820ms\n",
      "373:\tlearn: 0.0604742\ttotal: 2.42s\tremaining: 815ms\n",
      "374:\tlearn: 0.0601631\ttotal: 2.43s\tremaining: 809ms\n",
      "375:\tlearn: 0.0597221\ttotal: 2.44s\tremaining: 804ms\n",
      "376:\tlearn: 0.0594719\ttotal: 2.45s\tremaining: 799ms\n",
      "377:\tlearn: 0.0592137\ttotal: 2.46s\tremaining: 793ms\n",
      "378:\tlearn: 0.0591877\ttotal: 2.47s\tremaining: 788ms\n",
      "379:\tlearn: 0.0589375\ttotal: 2.48s\tremaining: 782ms\n",
      "380:\tlearn: 0.0587390\ttotal: 2.48s\tremaining: 776ms\n",
      "381:\tlearn: 0.0584438\ttotal: 2.49s\tremaining: 769ms\n",
      "382:\tlearn: 0.0581513\ttotal: 2.5s\tremaining: 763ms\n",
      "383:\tlearn: 0.0578052\ttotal: 2.5s\tremaining: 756ms\n",
      "384:\tlearn: 0.0575744\ttotal: 2.51s\tremaining: 750ms\n",
      "385:\tlearn: 0.0573507\ttotal: 2.51s\tremaining: 743ms\n",
      "386:\tlearn: 0.0570947\ttotal: 2.52s\tremaining: 736ms\n",
      "387:\tlearn: 0.0567791\ttotal: 2.52s\tremaining: 729ms\n",
      "388:\tlearn: 0.0565479\ttotal: 2.53s\tremaining: 722ms\n",
      "389:\tlearn: 0.0561851\ttotal: 2.53s\tremaining: 715ms\n",
      "390:\tlearn: 0.0556732\ttotal: 2.54s\tremaining: 707ms\n",
      "391:\tlearn: 0.0553932\ttotal: 2.54s\tremaining: 700ms\n",
      "392:\tlearn: 0.0551634\ttotal: 2.54s\tremaining: 692ms\n",
      "393:\tlearn: 0.0549243\ttotal: 2.55s\tremaining: 685ms\n",
      "394:\tlearn: 0.0548147\ttotal: 2.55s\tremaining: 678ms\n",
      "395:\tlearn: 0.0545954\ttotal: 2.56s\tremaining: 671ms\n",
      "396:\tlearn: 0.0543784\ttotal: 2.56s\tremaining: 664ms\n",
      "397:\tlearn: 0.0540722\ttotal: 2.56s\tremaining: 657ms\n",
      "398:\tlearn: 0.0538650\ttotal: 2.57s\tremaining: 652ms\n",
      "399:\tlearn: 0.0535920\ttotal: 2.58s\tremaining: 646ms\n",
      "400:\tlearn: 0.0533372\ttotal: 2.59s\tremaining: 640ms\n",
      "401:\tlearn: 0.0530609\ttotal: 2.6s\tremaining: 635ms\n",
      "402:\tlearn: 0.0528474\ttotal: 2.61s\tremaining: 629ms\n",
      "403:\tlearn: 0.0526502\ttotal: 2.62s\tremaining: 623ms\n",
      "404:\tlearn: 0.0524053\ttotal: 2.63s\tremaining: 618ms\n",
      "405:\tlearn: 0.0521874\ttotal: 2.64s\tremaining: 612ms\n",
      "406:\tlearn: 0.0519619\ttotal: 2.65s\tremaining: 606ms\n",
      "407:\tlearn: 0.0517368\ttotal: 2.66s\tremaining: 599ms\n",
      "408:\tlearn: 0.0515717\ttotal: 2.66s\tremaining: 593ms\n",
      "409:\tlearn: 0.0513183\ttotal: 2.67s\tremaining: 586ms\n",
      "410:\tlearn: 0.0510201\ttotal: 2.67s\tremaining: 579ms\n",
      "411:\tlearn: 0.0507688\ttotal: 2.68s\tremaining: 573ms\n",
      "412:\tlearn: 0.0505539\ttotal: 2.69s\tremaining: 566ms\n",
      "413:\tlearn: 0.0503147\ttotal: 2.69s\tremaining: 559ms\n",
      "414:\tlearn: 0.0500945\ttotal: 2.69s\tremaining: 552ms\n",
      "415:\tlearn: 0.0498949\ttotal: 2.7s\tremaining: 545ms\n",
      "416:\tlearn: 0.0496852\ttotal: 2.7s\tremaining: 538ms\n",
      "417:\tlearn: 0.0494853\ttotal: 2.71s\tremaining: 532ms\n",
      "418:\tlearn: 0.0492586\ttotal: 2.71s\tremaining: 525ms\n",
      "419:\tlearn: 0.0490401\ttotal: 2.72s\tremaining: 518ms\n",
      "420:\tlearn: 0.0488269\ttotal: 2.72s\tremaining: 511ms\n",
      "421:\tlearn: 0.0486879\ttotal: 2.73s\tremaining: 504ms\n",
      "422:\tlearn: 0.0484518\ttotal: 2.73s\tremaining: 497ms\n",
      "423:\tlearn: 0.0481009\ttotal: 2.74s\tremaining: 491ms\n",
      "424:\tlearn: 0.0478238\ttotal: 2.75s\tremaining: 485ms\n",
      "425:\tlearn: 0.0476302\ttotal: 2.76s\tremaining: 480ms\n",
      "426:\tlearn: 0.0474207\ttotal: 2.77s\tremaining: 474ms\n",
      "427:\tlearn: 0.0472972\ttotal: 2.78s\tremaining: 468ms\n",
      "428:\tlearn: 0.0471747\ttotal: 2.79s\tremaining: 462ms\n",
      "429:\tlearn: 0.0468956\ttotal: 2.8s\tremaining: 456ms\n",
      "430:\tlearn: 0.0466738\ttotal: 2.81s\tremaining: 450ms\n",
      "431:\tlearn: 0.0464983\ttotal: 2.82s\tremaining: 444ms\n",
      "432:\tlearn: 0.0462903\ttotal: 2.83s\tremaining: 438ms\n",
      "433:\tlearn: 0.0460972\ttotal: 2.83s\tremaining: 431ms\n",
      "434:\tlearn: 0.0459699\ttotal: 2.84s\tremaining: 425ms\n",
      "435:\tlearn: 0.0457647\ttotal: 2.85s\tremaining: 418ms\n",
      "436:\tlearn: 0.0455859\ttotal: 2.85s\tremaining: 411ms\n",
      "437:\tlearn: 0.0454080\ttotal: 2.86s\tremaining: 404ms\n",
      "438:\tlearn: 0.0451863\ttotal: 2.86s\tremaining: 398ms\n",
      "439:\tlearn: 0.0449481\ttotal: 2.87s\tremaining: 391ms\n",
      "440:\tlearn: 0.0447278\ttotal: 2.87s\tremaining: 384ms\n",
      "441:\tlearn: 0.0445448\ttotal: 2.88s\tremaining: 377ms\n",
      "442:\tlearn: 0.0443196\ttotal: 2.88s\tremaining: 370ms\n",
      "443:\tlearn: 0.0441100\ttotal: 2.88s\tremaining: 364ms\n",
      "444:\tlearn: 0.0439243\ttotal: 2.89s\tremaining: 357ms\n",
      "445:\tlearn: 0.0438369\ttotal: 2.89s\tremaining: 350ms\n",
      "446:\tlearn: 0.0435962\ttotal: 2.9s\tremaining: 343ms\n",
      "447:\tlearn: 0.0433797\ttotal: 2.9s\tremaining: 337ms\n",
      "448:\tlearn: 0.0431293\ttotal: 2.9s\tremaining: 330ms\n",
      "449:\tlearn: 0.0429483\ttotal: 2.92s\tremaining: 324ms\n",
      "450:\tlearn: 0.0428468\ttotal: 2.92s\tremaining: 318ms\n",
      "451:\tlearn: 0.0426645\ttotal: 2.93s\tremaining: 312ms\n",
      "452:\tlearn: 0.0425273\ttotal: 2.94s\tremaining: 306ms\n",
      "453:\tlearn: 0.0423663\ttotal: 2.95s\tremaining: 299ms\n",
      "454:\tlearn: 0.0422034\ttotal: 2.96s\tremaining: 293ms\n",
      "455:\tlearn: 0.0420121\ttotal: 2.97s\tremaining: 286ms\n",
      "456:\tlearn: 0.0418427\ttotal: 2.98s\tremaining: 280ms\n",
      "457:\tlearn: 0.0416804\ttotal: 2.98s\tremaining: 274ms\n",
      "458:\tlearn: 0.0414064\ttotal: 2.99s\tremaining: 267ms\n",
      "459:\tlearn: 0.0411284\ttotal: 2.99s\tremaining: 260ms\n",
      "460:\tlearn: 0.0409420\ttotal: 3s\tremaining: 254ms\n",
      "461:\tlearn: 0.0407666\ttotal: 3s\tremaining: 247ms\n",
      "462:\tlearn: 0.0406326\ttotal: 3.01s\tremaining: 240ms\n",
      "463:\tlearn: 0.0404612\ttotal: 3.01s\tremaining: 234ms\n",
      "464:\tlearn: 0.0403898\ttotal: 3.02s\tremaining: 227ms\n",
      "465:\tlearn: 0.0401880\ttotal: 3.02s\tremaining: 220ms\n",
      "466:\tlearn: 0.0400085\ttotal: 3.02s\tremaining: 214ms\n",
      "467:\tlearn: 0.0398193\ttotal: 3.03s\tremaining: 207ms\n",
      "468:\tlearn: 0.0396556\ttotal: 3.03s\tremaining: 201ms\n",
      "469:\tlearn: 0.0395589\ttotal: 3.04s\tremaining: 194ms\n",
      "470:\tlearn: 0.0393616\ttotal: 3.04s\tremaining: 187ms\n",
      "471:\tlearn: 0.0391581\ttotal: 3.05s\tremaining: 181ms\n",
      "472:\tlearn: 0.0389501\ttotal: 3.06s\tremaining: 174ms\n",
      "473:\tlearn: 0.0388016\ttotal: 3.07s\tremaining: 168ms\n",
      "474:\tlearn: 0.0386081\ttotal: 3.08s\tremaining: 162ms\n",
      "475:\tlearn: 0.0383057\ttotal: 3.08s\tremaining: 156ms\n",
      "476:\tlearn: 0.0381607\ttotal: 3.1s\tremaining: 149ms\n",
      "477:\tlearn: 0.0380352\ttotal: 3.1s\tremaining: 143ms\n",
      "478:\tlearn: 0.0378139\ttotal: 3.12s\tremaining: 137ms\n",
      "479:\tlearn: 0.0376307\ttotal: 3.13s\tremaining: 130ms\n",
      "480:\tlearn: 0.0374780\ttotal: 3.13s\tremaining: 124ms\n",
      "481:\tlearn: 0.0373547\ttotal: 3.13s\tremaining: 117ms\n",
      "482:\tlearn: 0.0371898\ttotal: 3.14s\tremaining: 111ms\n",
      "483:\tlearn: 0.0370603\ttotal: 3.15s\tremaining: 104ms\n",
      "484:\tlearn: 0.0368433\ttotal: 3.15s\tremaining: 97.4ms\n",
      "485:\tlearn: 0.0366569\ttotal: 3.15s\tremaining: 90.9ms\n",
      "486:\tlearn: 0.0365159\ttotal: 3.16s\tremaining: 84.3ms\n",
      "487:\tlearn: 0.0364198\ttotal: 3.16s\tremaining: 77.8ms\n",
      "488:\tlearn: 0.0362416\ttotal: 3.17s\tremaining: 71.3ms\n",
      "489:\tlearn: 0.0361106\ttotal: 3.17s\tremaining: 64.7ms\n",
      "490:\tlearn: 0.0359668\ttotal: 3.18s\tremaining: 58.2ms\n",
      "491:\tlearn: 0.0359551\ttotal: 3.18s\tremaining: 51.7ms\n",
      "492:\tlearn: 0.0357923\ttotal: 3.19s\tremaining: 45.2ms\n",
      "493:\tlearn: 0.0356315\ttotal: 3.19s\tremaining: 38.7ms\n",
      "494:\tlearn: 0.0354784\ttotal: 3.2s\tremaining: 32.3ms\n",
      "495:\tlearn: 0.0353488\ttotal: 3.21s\tremaining: 25.9ms\n",
      "496:\tlearn: 0.0351705\ttotal: 3.22s\tremaining: 19.4ms\n",
      "497:\tlearn: 0.0350135\ttotal: 3.23s\tremaining: 13ms\n",
      "498:\tlearn: 0.0348653\ttotal: 3.24s\tremaining: 6.49ms\n",
      "499:\tlearn: 0.0346991\ttotal: 3.25s\tremaining: 0us\n",
      "0:\tlearn: 0.6811257\ttotal: 6.76ms\tremaining: 3.38s\n",
      "1:\tlearn: 0.6709124\ttotal: 12.8ms\tremaining: 3.18s\n",
      "2:\tlearn: 0.6617074\ttotal: 19.2ms\tremaining: 3.19s\n",
      "3:\tlearn: 0.6497986\ttotal: 25.3ms\tremaining: 3.13s\n",
      "4:\tlearn: 0.6412796\ttotal: 31.2ms\tremaining: 3.09s\n",
      "5:\tlearn: 0.6300957\ttotal: 37.4ms\tremaining: 3.08s\n",
      "6:\tlearn: 0.6221316\ttotal: 43.5ms\tremaining: 3.06s\n",
      "7:\tlearn: 0.6146502\ttotal: 49.5ms\tremaining: 3.04s\n",
      "8:\tlearn: 0.6089062\ttotal: 54.3ms\tremaining: 2.96s\n",
      "9:\tlearn: 0.6017857\ttotal: 59ms\tremaining: 2.89s\n",
      "10:\tlearn: 0.5930923\ttotal: 63.7ms\tremaining: 2.83s\n",
      "11:\tlearn: 0.5855518\ttotal: 68.5ms\tremaining: 2.78s\n",
      "12:\tlearn: 0.5778428\ttotal: 73.1ms\tremaining: 2.74s\n",
      "13:\tlearn: 0.5735220\ttotal: 77.9ms\tremaining: 2.7s\n",
      "14:\tlearn: 0.5665922\ttotal: 82.2ms\tremaining: 2.66s\n",
      "15:\tlearn: 0.5558394\ttotal: 86.4ms\tremaining: 2.61s\n",
      "16:\tlearn: 0.5497477\ttotal: 90.6ms\tremaining: 2.57s\n",
      "17:\tlearn: 0.5438729\ttotal: 95ms\tremaining: 2.54s\n",
      "18:\tlearn: 0.5360254\ttotal: 99.2ms\tremaining: 2.51s\n",
      "19:\tlearn: 0.5303749\ttotal: 103ms\tremaining: 2.48s\n",
      "20:\tlearn: 0.5244144\ttotal: 108ms\tremaining: 2.46s\n",
      "21:\tlearn: 0.5202737\ttotal: 118ms\tremaining: 2.56s\n",
      "22:\tlearn: 0.5156911\ttotal: 127ms\tremaining: 2.64s\n",
      "23:\tlearn: 0.5107832\ttotal: 137ms\tremaining: 2.71s\n",
      "24:\tlearn: 0.5055644\ttotal: 146ms\tremaining: 2.78s\n",
      "25:\tlearn: 0.5016556\ttotal: 156ms\tremaining: 2.84s\n",
      "26:\tlearn: 0.4980113\ttotal: 165ms\tremaining: 2.89s\n",
      "27:\tlearn: 0.4942337\ttotal: 175ms\tremaining: 2.95s\n",
      "28:\tlearn: 0.4894938\ttotal: 184ms\tremaining: 3s\n",
      "29:\tlearn: 0.4833437\ttotal: 191ms\tremaining: 2.99s\n",
      "30:\tlearn: 0.4782527\ttotal: 197ms\tremaining: 2.98s\n",
      "31:\tlearn: 0.4743097\ttotal: 202ms\tremaining: 2.95s\n",
      "32:\tlearn: 0.4709728\ttotal: 209ms\tremaining: 2.95s\n",
      "33:\tlearn: 0.4680897\ttotal: 215ms\tremaining: 2.94s\n",
      "34:\tlearn: 0.4632753\ttotal: 220ms\tremaining: 2.92s\n",
      "35:\tlearn: 0.4586243\ttotal: 224ms\tremaining: 2.89s\n",
      "36:\tlearn: 0.4557784\ttotal: 229ms\tremaining: 2.87s\n",
      "37:\tlearn: 0.4520150\ttotal: 234ms\tremaining: 2.84s\n",
      "38:\tlearn: 0.4474542\ttotal: 239ms\tremaining: 2.82s\n",
      "39:\tlearn: 0.4443236\ttotal: 243ms\tremaining: 2.79s\n",
      "40:\tlearn: 0.4371665\ttotal: 247ms\tremaining: 2.77s\n",
      "41:\tlearn: 0.4323907\ttotal: 252ms\tremaining: 2.74s\n",
      "42:\tlearn: 0.4295117\ttotal: 256ms\tremaining: 2.72s\n",
      "43:\tlearn: 0.4249737\ttotal: 260ms\tremaining: 2.7s\n",
      "44:\tlearn: 0.4215694\ttotal: 265ms\tremaining: 2.67s\n",
      "45:\tlearn: 0.4177609\ttotal: 269ms\tremaining: 2.65s\n",
      "46:\tlearn: 0.4137853\ttotal: 273ms\tremaining: 2.63s\n",
      "47:\tlearn: 0.4097425\ttotal: 283ms\tremaining: 2.66s\n",
      "48:\tlearn: 0.4054811\ttotal: 293ms\tremaining: 2.69s\n",
      "49:\tlearn: 0.4026469\ttotal: 302ms\tremaining: 2.72s\n",
      "50:\tlearn: 0.3998846\ttotal: 312ms\tremaining: 2.75s\n",
      "51:\tlearn: 0.3975200\ttotal: 322ms\tremaining: 2.77s\n",
      "52:\tlearn: 0.3948860\ttotal: 331ms\tremaining: 2.79s\n",
      "53:\tlearn: 0.3918633\ttotal: 341ms\tremaining: 2.81s\n",
      "54:\tlearn: 0.3898975\ttotal: 350ms\tremaining: 2.83s\n",
      "55:\tlearn: 0.3875894\ttotal: 360ms\tremaining: 2.85s\n",
      "56:\tlearn: 0.3856001\ttotal: 367ms\tremaining: 2.85s\n",
      "57:\tlearn: 0.3832690\ttotal: 371ms\tremaining: 2.83s\n",
      "58:\tlearn: 0.3789835\ttotal: 380ms\tremaining: 2.84s\n",
      "59:\tlearn: 0.3765638\ttotal: 386ms\tremaining: 2.83s\n",
      "60:\tlearn: 0.3741106\ttotal: 391ms\tremaining: 2.81s\n",
      "61:\tlearn: 0.3716159\ttotal: 396ms\tremaining: 2.79s\n",
      "62:\tlearn: 0.3687173\ttotal: 400ms\tremaining: 2.77s\n",
      "63:\tlearn: 0.3666328\ttotal: 405ms\tremaining: 2.76s\n",
      "64:\tlearn: 0.3628141\ttotal: 409ms\tremaining: 2.74s\n",
      "65:\tlearn: 0.3603766\ttotal: 414ms\tremaining: 2.72s\n",
      "66:\tlearn: 0.3571615\ttotal: 418ms\tremaining: 2.7s\n",
      "67:\tlearn: 0.3546111\ttotal: 423ms\tremaining: 2.69s\n",
      "68:\tlearn: 0.3519616\ttotal: 427ms\tremaining: 2.67s\n",
      "69:\tlearn: 0.3496386\ttotal: 432ms\tremaining: 2.65s\n",
      "70:\tlearn: 0.3472731\ttotal: 436ms\tremaining: 2.63s\n",
      "71:\tlearn: 0.3446115\ttotal: 440ms\tremaining: 2.62s\n",
      "72:\tlearn: 0.3420152\ttotal: 445ms\tremaining: 2.6s\n",
      "73:\tlearn: 0.3398405\ttotal: 455ms\tremaining: 2.62s\n",
      "74:\tlearn: 0.3347400\ttotal: 464ms\tremaining: 2.63s\n",
      "75:\tlearn: 0.3330334\ttotal: 474ms\tremaining: 2.64s\n",
      "76:\tlearn: 0.3306193\ttotal: 483ms\tremaining: 2.65s\n",
      "77:\tlearn: 0.3283875\ttotal: 493ms\tremaining: 2.67s\n",
      "78:\tlearn: 0.3269050\ttotal: 503ms\tremaining: 2.68s\n",
      "79:\tlearn: 0.3243031\ttotal: 512ms\tremaining: 2.69s\n",
      "80:\tlearn: 0.3223334\ttotal: 522ms\tremaining: 2.7s\n",
      "81:\tlearn: 0.3203150\ttotal: 532ms\tremaining: 2.71s\n",
      "82:\tlearn: 0.3175260\ttotal: 539ms\tremaining: 2.71s\n",
      "83:\tlearn: 0.3154909\ttotal: 545ms\tremaining: 2.7s\n",
      "84:\tlearn: 0.3134918\ttotal: 551ms\tremaining: 2.69s\n",
      "85:\tlearn: 0.3109023\ttotal: 559ms\tremaining: 2.69s\n",
      "86:\tlearn: 0.3089885\ttotal: 564ms\tremaining: 2.67s\n",
      "87:\tlearn: 0.3065221\ttotal: 569ms\tremaining: 2.66s\n",
      "88:\tlearn: 0.3021913\ttotal: 573ms\tremaining: 2.65s\n",
      "89:\tlearn: 0.2982436\ttotal: 578ms\tremaining: 2.63s\n",
      "90:\tlearn: 0.2961326\ttotal: 582ms\tremaining: 2.62s\n",
      "91:\tlearn: 0.2943182\ttotal: 586ms\tremaining: 2.6s\n",
      "92:\tlearn: 0.2924509\ttotal: 590ms\tremaining: 2.58s\n",
      "93:\tlearn: 0.2907479\ttotal: 595ms\tremaining: 2.57s\n",
      "94:\tlearn: 0.2874593\ttotal: 599ms\tremaining: 2.56s\n",
      "95:\tlearn: 0.2853977\ttotal: 603ms\tremaining: 2.54s\n",
      "96:\tlearn: 0.2833133\ttotal: 607ms\tremaining: 2.52s\n",
      "97:\tlearn: 0.2815678\ttotal: 612ms\tremaining: 2.51s\n",
      "98:\tlearn: 0.2790952\ttotal: 616ms\tremaining: 2.49s\n",
      "99:\tlearn: 0.2733508\ttotal: 620ms\tremaining: 2.48s\n",
      "100:\tlearn: 0.2713104\ttotal: 630ms\tremaining: 2.49s\n",
      "101:\tlearn: 0.2692855\ttotal: 639ms\tremaining: 2.5s\n",
      "102:\tlearn: 0.2676126\ttotal: 649ms\tremaining: 2.5s\n",
      "103:\tlearn: 0.2656536\ttotal: 659ms\tremaining: 2.51s\n",
      "104:\tlearn: 0.2638552\ttotal: 668ms\tremaining: 2.51s\n",
      "105:\tlearn: 0.2606696\ttotal: 678ms\tremaining: 2.52s\n",
      "106:\tlearn: 0.2589850\ttotal: 688ms\tremaining: 2.53s\n",
      "107:\tlearn: 0.2572569\ttotal: 698ms\tremaining: 2.53s\n",
      "108:\tlearn: 0.2552021\ttotal: 707ms\tremaining: 2.54s\n",
      "109:\tlearn: 0.2534125\ttotal: 714ms\tremaining: 2.53s\n",
      "110:\tlearn: 0.2519143\ttotal: 720ms\tremaining: 2.52s\n",
      "111:\tlearn: 0.2502213\ttotal: 727ms\tremaining: 2.52s\n",
      "112:\tlearn: 0.2482817\ttotal: 734ms\tremaining: 2.51s\n",
      "113:\tlearn: 0.2467396\ttotal: 739ms\tremaining: 2.5s\n",
      "114:\tlearn: 0.2452305\ttotal: 744ms\tremaining: 2.49s\n",
      "115:\tlearn: 0.2436216\ttotal: 749ms\tremaining: 2.48s\n",
      "116:\tlearn: 0.2421041\ttotal: 754ms\tremaining: 2.47s\n",
      "117:\tlearn: 0.2407127\ttotal: 758ms\tremaining: 2.45s\n",
      "118:\tlearn: 0.2392712\ttotal: 762ms\tremaining: 2.44s\n",
      "119:\tlearn: 0.2378940\ttotal: 767ms\tremaining: 2.43s\n",
      "120:\tlearn: 0.2366252\ttotal: 771ms\tremaining: 2.42s\n",
      "121:\tlearn: 0.2353142\ttotal: 775ms\tremaining: 2.4s\n",
      "122:\tlearn: 0.2339380\ttotal: 779ms\tremaining: 2.39s\n",
      "123:\tlearn: 0.2324190\ttotal: 784ms\tremaining: 2.38s\n",
      "124:\tlearn: 0.2308081\ttotal: 788ms\tremaining: 2.36s\n",
      "125:\tlearn: 0.2294580\ttotal: 798ms\tremaining: 2.37s\n",
      "126:\tlearn: 0.2277531\ttotal: 807ms\tremaining: 2.37s\n",
      "127:\tlearn: 0.2252177\ttotal: 817ms\tremaining: 2.37s\n",
      "128:\tlearn: 0.2232065\ttotal: 827ms\tremaining: 2.38s\n",
      "129:\tlearn: 0.2216418\ttotal: 836ms\tremaining: 2.38s\n",
      "130:\tlearn: 0.2198337\ttotal: 846ms\tremaining: 2.38s\n",
      "131:\tlearn: 0.2187949\ttotal: 855ms\tremaining: 2.38s\n",
      "132:\tlearn: 0.2174246\ttotal: 865ms\tremaining: 2.39s\n",
      "133:\tlearn: 0.2161378\ttotal: 875ms\tremaining: 2.39s\n",
      "134:\tlearn: 0.2145632\ttotal: 885ms\tremaining: 2.39s\n",
      "135:\tlearn: 0.2134329\ttotal: 894ms\tremaining: 2.39s\n",
      "136:\tlearn: 0.2122781\ttotal: 902ms\tremaining: 2.39s\n",
      "137:\tlearn: 0.2109550\ttotal: 908ms\tremaining: 2.38s\n",
      "138:\tlearn: 0.2092918\ttotal: 915ms\tremaining: 2.38s\n",
      "139:\tlearn: 0.2080966\ttotal: 924ms\tremaining: 2.37s\n",
      "140:\tlearn: 0.2068712\ttotal: 931ms\tremaining: 2.37s\n",
      "141:\tlearn: 0.2055679\ttotal: 934ms\tremaining: 2.35s\n",
      "142:\tlearn: 0.2044933\ttotal: 939ms\tremaining: 2.34s\n",
      "143:\tlearn: 0.2033042\ttotal: 944ms\tremaining: 2.33s\n",
      "144:\tlearn: 0.2019702\ttotal: 949ms\tremaining: 2.32s\n",
      "145:\tlearn: 0.2008845\ttotal: 954ms\tremaining: 2.31s\n",
      "146:\tlearn: 0.1993871\ttotal: 959ms\tremaining: 2.3s\n",
      "147:\tlearn: 0.1980502\ttotal: 963ms\tremaining: 2.29s\n",
      "148:\tlearn: 0.1967741\ttotal: 967ms\tremaining: 2.28s\n",
      "149:\tlearn: 0.1956255\ttotal: 971ms\tremaining: 2.27s\n",
      "150:\tlearn: 0.1946542\ttotal: 975ms\tremaining: 2.25s\n",
      "151:\tlearn: 0.1936175\ttotal: 980ms\tremaining: 2.24s\n",
      "152:\tlearn: 0.1926168\ttotal: 983ms\tremaining: 2.23s\n",
      "153:\tlearn: 0.1913010\ttotal: 993ms\tremaining: 2.23s\n",
      "154:\tlearn: 0.1903399\ttotal: 1s\tremaining: 2.23s\n",
      "155:\tlearn: 0.1889187\ttotal: 1.01s\tremaining: 2.23s\n",
      "156:\tlearn: 0.1879012\ttotal: 1.02s\tremaining: 2.23s\n",
      "157:\tlearn: 0.1867491\ttotal: 1.03s\tremaining: 2.23s\n",
      "158:\tlearn: 0.1857087\ttotal: 1.04s\tremaining: 2.23s\n",
      "159:\tlearn: 0.1847604\ttotal: 1.05s\tremaining: 2.23s\n",
      "160:\tlearn: 0.1837137\ttotal: 1.06s\tremaining: 2.23s\n",
      "161:\tlearn: 0.1827983\ttotal: 1.07s\tremaining: 2.23s\n",
      "162:\tlearn: 0.1816852\ttotal: 1.08s\tremaining: 2.23s\n",
      "163:\tlearn: 0.1808007\ttotal: 1.08s\tremaining: 2.22s\n",
      "164:\tlearn: 0.1796073\ttotal: 1.09s\tremaining: 2.21s\n",
      "165:\tlearn: 0.1787735\ttotal: 1.1s\tremaining: 2.21s\n",
      "166:\tlearn: 0.1777163\ttotal: 1.1s\tremaining: 2.2s\n",
      "167:\tlearn: 0.1765388\ttotal: 1.11s\tremaining: 2.19s\n",
      "168:\tlearn: 0.1754864\ttotal: 1.11s\tremaining: 2.18s\n",
      "169:\tlearn: 0.1747123\ttotal: 1.12s\tremaining: 2.17s\n",
      "170:\tlearn: 0.1738649\ttotal: 1.12s\tremaining: 2.16s\n",
      "171:\tlearn: 0.1727673\ttotal: 1.13s\tremaining: 2.15s\n",
      "172:\tlearn: 0.1714739\ttotal: 1.13s\tremaining: 2.14s\n",
      "173:\tlearn: 0.1704278\ttotal: 1.14s\tremaining: 2.13s\n",
      "174:\tlearn: 0.1695656\ttotal: 1.14s\tremaining: 2.12s\n",
      "175:\tlearn: 0.1682569\ttotal: 1.14s\tremaining: 2.11s\n",
      "176:\tlearn: 0.1666314\ttotal: 1.15s\tremaining: 2.1s\n",
      "177:\tlearn: 0.1656689\ttotal: 1.15s\tremaining: 2.09s\n",
      "178:\tlearn: 0.1647653\ttotal: 1.16s\tremaining: 2.07s\n",
      "179:\tlearn: 0.1637975\ttotal: 1.16s\tremaining: 2.06s\n",
      "180:\tlearn: 0.1628070\ttotal: 1.17s\tremaining: 2.05s\n",
      "181:\tlearn: 0.1618969\ttotal: 1.17s\tremaining: 2.04s\n",
      "182:\tlearn: 0.1609589\ttotal: 1.17s\tremaining: 2.03s\n",
      "183:\tlearn: 0.1601314\ttotal: 1.18s\tremaining: 2.02s\n",
      "184:\tlearn: 0.1592346\ttotal: 1.18s\tremaining: 2.01s\n",
      "185:\tlearn: 0.1582525\ttotal: 1.19s\tremaining: 2s\n",
      "186:\tlearn: 0.1573450\ttotal: 1.2s\tremaining: 2s\n",
      "187:\tlearn: 0.1566289\ttotal: 1.21s\tremaining: 2s\n",
      "188:\tlearn: 0.1557165\ttotal: 1.22s\tremaining: 2s\n",
      "189:\tlearn: 0.1548945\ttotal: 1.23s\tremaining: 2s\n",
      "190:\tlearn: 0.1540089\ttotal: 1.24s\tremaining: 2s\n",
      "191:\tlearn: 0.1531412\ttotal: 1.25s\tremaining: 2s\n",
      "192:\tlearn: 0.1522130\ttotal: 1.25s\tremaining: 2s\n",
      "193:\tlearn: 0.1511480\ttotal: 1.26s\tremaining: 2s\n",
      "194:\tlearn: 0.1502310\ttotal: 1.27s\tremaining: 1.99s\n",
      "195:\tlearn: 0.1495328\ttotal: 1.28s\tremaining: 1.99s\n",
      "196:\tlearn: 0.1483721\ttotal: 1.29s\tremaining: 1.98s\n",
      "197:\tlearn: 0.1476859\ttotal: 1.29s\tremaining: 1.97s\n",
      "198:\tlearn: 0.1467824\ttotal: 1.3s\tremaining: 1.97s\n",
      "199:\tlearn: 0.1461554\ttotal: 1.31s\tremaining: 1.96s\n",
      "200:\tlearn: 0.1451825\ttotal: 1.31s\tremaining: 1.95s\n",
      "201:\tlearn: 0.1444037\ttotal: 1.32s\tremaining: 1.94s\n",
      "202:\tlearn: 0.1435637\ttotal: 1.32s\tremaining: 1.93s\n",
      "203:\tlearn: 0.1426722\ttotal: 1.32s\tremaining: 1.92s\n",
      "204:\tlearn: 0.1419110\ttotal: 1.33s\tremaining: 1.92s\n",
      "205:\tlearn: 0.1411520\ttotal: 1.34s\tremaining: 1.91s\n",
      "206:\tlearn: 0.1403645\ttotal: 1.34s\tremaining: 1.9s\n",
      "207:\tlearn: 0.1397215\ttotal: 1.35s\tremaining: 1.89s\n",
      "208:\tlearn: 0.1387807\ttotal: 1.35s\tremaining: 1.88s\n",
      "209:\tlearn: 0.1381381\ttotal: 1.35s\tremaining: 1.87s\n",
      "210:\tlearn: 0.1374601\ttotal: 1.36s\tremaining: 1.86s\n",
      "211:\tlearn: 0.1357854\ttotal: 1.36s\tremaining: 1.85s\n",
      "212:\tlearn: 0.1350790\ttotal: 1.37s\tremaining: 1.84s\n",
      "213:\tlearn: 0.1341531\ttotal: 1.37s\tremaining: 1.83s\n",
      "214:\tlearn: 0.1334394\ttotal: 1.38s\tremaining: 1.83s\n",
      "215:\tlearn: 0.1327326\ttotal: 1.38s\tremaining: 1.82s\n",
      "216:\tlearn: 0.1320731\ttotal: 1.39s\tremaining: 1.81s\n",
      "217:\tlearn: 0.1314636\ttotal: 1.4s\tremaining: 1.8s\n",
      "218:\tlearn: 0.1307911\ttotal: 1.41s\tremaining: 1.8s\n",
      "219:\tlearn: 0.1300539\ttotal: 1.42s\tremaining: 1.8s\n",
      "220:\tlearn: 0.1295138\ttotal: 1.43s\tremaining: 1.8s\n",
      "221:\tlearn: 0.1288639\ttotal: 1.43s\tremaining: 1.8s\n",
      "222:\tlearn: 0.1282087\ttotal: 1.44s\tremaining: 1.79s\n",
      "223:\tlearn: 0.1276112\ttotal: 1.45s\tremaining: 1.79s\n",
      "224:\tlearn: 0.1269923\ttotal: 1.46s\tremaining: 1.79s\n",
      "225:\tlearn: 0.1263189\ttotal: 1.47s\tremaining: 1.78s\n",
      "226:\tlearn: 0.1257009\ttotal: 1.47s\tremaining: 1.77s\n",
      "227:\tlearn: 0.1249418\ttotal: 1.48s\tremaining: 1.76s\n",
      "228:\tlearn: 0.1243706\ttotal: 1.48s\tremaining: 1.75s\n",
      "229:\tlearn: 0.1238264\ttotal: 1.49s\tremaining: 1.74s\n",
      "230:\tlearn: 0.1233115\ttotal: 1.49s\tremaining: 1.74s\n",
      "231:\tlearn: 0.1225950\ttotal: 1.49s\tremaining: 1.73s\n",
      "232:\tlearn: 0.1219445\ttotal: 1.5s\tremaining: 1.72s\n",
      "233:\tlearn: 0.1210354\ttotal: 1.5s\tremaining: 1.71s\n",
      "234:\tlearn: 0.1203181\ttotal: 1.51s\tremaining: 1.7s\n",
      "235:\tlearn: 0.1199862\ttotal: 1.51s\tremaining: 1.69s\n",
      "236:\tlearn: 0.1194061\ttotal: 1.52s\tremaining: 1.69s\n",
      "237:\tlearn: 0.1189351\ttotal: 1.52s\tremaining: 1.68s\n",
      "238:\tlearn: 0.1183586\ttotal: 1.53s\tremaining: 1.67s\n",
      "239:\tlearn: 0.1177307\ttotal: 1.53s\tremaining: 1.66s\n",
      "240:\tlearn: 0.1172482\ttotal: 1.53s\tremaining: 1.65s\n",
      "241:\tlearn: 0.1166737\ttotal: 1.54s\tremaining: 1.64s\n",
      "242:\tlearn: 0.1161583\ttotal: 1.54s\tremaining: 1.63s\n",
      "243:\tlearn: 0.1155608\ttotal: 1.55s\tremaining: 1.63s\n",
      "244:\tlearn: 0.1150819\ttotal: 1.56s\tremaining: 1.63s\n",
      "245:\tlearn: 0.1142820\ttotal: 1.57s\tremaining: 1.62s\n",
      "246:\tlearn: 0.1137544\ttotal: 1.58s\tremaining: 1.62s\n",
      "247:\tlearn: 0.1132017\ttotal: 1.59s\tremaining: 1.62s\n",
      "248:\tlearn: 0.1127244\ttotal: 1.6s\tremaining: 1.61s\n",
      "249:\tlearn: 0.1121947\ttotal: 1.61s\tremaining: 1.61s\n",
      "250:\tlearn: 0.1116229\ttotal: 1.62s\tremaining: 1.61s\n",
      "251:\tlearn: 0.1110729\ttotal: 1.63s\tremaining: 1.6s\n",
      "252:\tlearn: 0.1106273\ttotal: 1.63s\tremaining: 1.59s\n",
      "253:\tlearn: 0.1099869\ttotal: 1.64s\tremaining: 1.59s\n",
      "254:\tlearn: 0.1094760\ttotal: 1.64s\tremaining: 1.58s\n",
      "255:\tlearn: 0.1088934\ttotal: 1.65s\tremaining: 1.57s\n",
      "256:\tlearn: 0.1083341\ttotal: 1.66s\tremaining: 1.57s\n",
      "257:\tlearn: 0.1076310\ttotal: 1.66s\tremaining: 1.56s\n",
      "258:\tlearn: 0.1070107\ttotal: 1.67s\tremaining: 1.55s\n",
      "259:\tlearn: 0.1066888\ttotal: 1.67s\tremaining: 1.54s\n",
      "260:\tlearn: 0.1061701\ttotal: 1.67s\tremaining: 1.53s\n",
      "261:\tlearn: 0.1057337\ttotal: 1.68s\tremaining: 1.52s\n",
      "262:\tlearn: 0.1052022\ttotal: 1.68s\tremaining: 1.52s\n",
      "263:\tlearn: 0.1046527\ttotal: 1.69s\tremaining: 1.51s\n",
      "264:\tlearn: 0.1043372\ttotal: 1.69s\tremaining: 1.5s\n",
      "265:\tlearn: 0.1039350\ttotal: 1.7s\tremaining: 1.49s\n",
      "266:\tlearn: 0.1033999\ttotal: 1.7s\tremaining: 1.48s\n",
      "267:\tlearn: 0.1028645\ttotal: 1.71s\tremaining: 1.48s\n",
      "268:\tlearn: 0.1024041\ttotal: 1.71s\tremaining: 1.47s\n",
      "269:\tlearn: 0.1019515\ttotal: 1.72s\tremaining: 1.47s\n",
      "270:\tlearn: 0.1014975\ttotal: 1.73s\tremaining: 1.46s\n",
      "271:\tlearn: 0.1007887\ttotal: 1.74s\tremaining: 1.46s\n",
      "272:\tlearn: 0.1003829\ttotal: 1.75s\tremaining: 1.45s\n",
      "273:\tlearn: 0.0998218\ttotal: 1.76s\tremaining: 1.45s\n",
      "274:\tlearn: 0.0993785\ttotal: 1.77s\tremaining: 1.45s\n",
      "275:\tlearn: 0.0989270\ttotal: 1.78s\tremaining: 1.44s\n",
      "276:\tlearn: 0.0983879\ttotal: 1.79s\tremaining: 1.44s\n",
      "277:\tlearn: 0.0978241\ttotal: 1.8s\tremaining: 1.43s\n",
      "278:\tlearn: 0.0973784\ttotal: 1.81s\tremaining: 1.43s\n",
      "279:\tlearn: 0.0969470\ttotal: 1.81s\tremaining: 1.42s\n",
      "280:\tlearn: 0.0959310\ttotal: 1.82s\tremaining: 1.42s\n",
      "281:\tlearn: 0.0954761\ttotal: 1.82s\tremaining: 1.41s\n",
      "282:\tlearn: 0.0947810\ttotal: 1.83s\tremaining: 1.4s\n",
      "283:\tlearn: 0.0943039\ttotal: 1.83s\tremaining: 1.4s\n",
      "284:\tlearn: 0.0937465\ttotal: 1.84s\tremaining: 1.39s\n",
      "285:\tlearn: 0.0932724\ttotal: 1.84s\tremaining: 1.38s\n",
      "286:\tlearn: 0.0927710\ttotal: 1.85s\tremaining: 1.37s\n",
      "287:\tlearn: 0.0922386\ttotal: 1.85s\tremaining: 1.36s\n",
      "288:\tlearn: 0.0918794\ttotal: 1.86s\tremaining: 1.36s\n",
      "289:\tlearn: 0.0913805\ttotal: 1.86s\tremaining: 1.35s\n",
      "290:\tlearn: 0.0911205\ttotal: 1.87s\tremaining: 1.34s\n",
      "291:\tlearn: 0.0906935\ttotal: 1.87s\tremaining: 1.33s\n",
      "292:\tlearn: 0.0901281\ttotal: 1.88s\tremaining: 1.32s\n",
      "293:\tlearn: 0.0895768\ttotal: 1.88s\tremaining: 1.32s\n",
      "294:\tlearn: 0.0891457\ttotal: 1.88s\tremaining: 1.31s\n",
      "295:\tlearn: 0.0886558\ttotal: 1.89s\tremaining: 1.3s\n",
      "296:\tlearn: 0.0882537\ttotal: 1.9s\tremaining: 1.3s\n",
      "297:\tlearn: 0.0878454\ttotal: 1.91s\tremaining: 1.29s\n",
      "298:\tlearn: 0.0874383\ttotal: 1.92s\tremaining: 1.29s\n",
      "299:\tlearn: 0.0872473\ttotal: 1.93s\tremaining: 1.28s\n",
      "300:\tlearn: 0.0869446\ttotal: 1.94s\tremaining: 1.28s\n",
      "301:\tlearn: 0.0865298\ttotal: 1.95s\tremaining: 1.28s\n",
      "302:\tlearn: 0.0863365\ttotal: 1.96s\tremaining: 1.27s\n",
      "303:\tlearn: 0.0859768\ttotal: 1.97s\tremaining: 1.27s\n",
      "304:\tlearn: 0.0855478\ttotal: 1.97s\tremaining: 1.26s\n",
      "305:\tlearn: 0.0851554\ttotal: 1.98s\tremaining: 1.26s\n",
      "306:\tlearn: 0.0844483\ttotal: 1.99s\tremaining: 1.25s\n",
      "307:\tlearn: 0.0839826\ttotal: 2s\tremaining: 1.24s\n",
      "308:\tlearn: 0.0836403\ttotal: 2s\tremaining: 1.24s\n",
      "309:\tlearn: 0.0832253\ttotal: 2s\tremaining: 1.23s\n",
      "310:\tlearn: 0.0828558\ttotal: 2.01s\tremaining: 1.22s\n",
      "311:\tlearn: 0.0824084\ttotal: 2.01s\tremaining: 1.21s\n",
      "312:\tlearn: 0.0819431\ttotal: 2.02s\tremaining: 1.21s\n",
      "313:\tlearn: 0.0813570\ttotal: 2.02s\tremaining: 1.2s\n",
      "314:\tlearn: 0.0809989\ttotal: 2.03s\tremaining: 1.19s\n",
      "315:\tlearn: 0.0808406\ttotal: 2.03s\tremaining: 1.18s\n",
      "316:\tlearn: 0.0802236\ttotal: 2.04s\tremaining: 1.17s\n",
      "317:\tlearn: 0.0796981\ttotal: 2.04s\tremaining: 1.17s\n",
      "318:\tlearn: 0.0792407\ttotal: 2.04s\tremaining: 1.16s\n",
      "319:\tlearn: 0.0788785\ttotal: 2.05s\tremaining: 1.15s\n",
      "320:\tlearn: 0.0783782\ttotal: 2.05s\tremaining: 1.14s\n",
      "321:\tlearn: 0.0780611\ttotal: 2.06s\tremaining: 1.14s\n",
      "322:\tlearn: 0.0777372\ttotal: 2.06s\tremaining: 1.13s\n",
      "323:\tlearn: 0.0771913\ttotal: 2.07s\tremaining: 1.12s\n",
      "324:\tlearn: 0.0768555\ttotal: 2.08s\tremaining: 1.12s\n",
      "325:\tlearn: 0.0766628\ttotal: 2.09s\tremaining: 1.11s\n",
      "326:\tlearn: 0.0762932\ttotal: 2.1s\tremaining: 1.11s\n",
      "327:\tlearn: 0.0761546\ttotal: 2.11s\tremaining: 1.11s\n",
      "328:\tlearn: 0.0757687\ttotal: 2.12s\tremaining: 1.1s\n",
      "329:\tlearn: 0.0754639\ttotal: 2.13s\tremaining: 1.1s\n",
      "330:\tlearn: 0.0750208\ttotal: 2.14s\tremaining: 1.09s\n",
      "331:\tlearn: 0.0746865\ttotal: 2.14s\tremaining: 1.08s\n",
      "332:\tlearn: 0.0742982\ttotal: 2.15s\tremaining: 1.08s\n",
      "333:\tlearn: 0.0739363\ttotal: 2.16s\tremaining: 1.07s\n",
      "334:\tlearn: 0.0736245\ttotal: 2.16s\tremaining: 1.06s\n",
      "335:\tlearn: 0.0733722\ttotal: 2.17s\tremaining: 1.06s\n",
      "336:\tlearn: 0.0730224\ttotal: 2.17s\tremaining: 1.05s\n",
      "337:\tlearn: 0.0723935\ttotal: 2.18s\tremaining: 1.04s\n",
      "338:\tlearn: 0.0720178\ttotal: 2.18s\tremaining: 1.04s\n",
      "339:\tlearn: 0.0716036\ttotal: 2.19s\tremaining: 1.03s\n",
      "340:\tlearn: 0.0712781\ttotal: 2.19s\tremaining: 1.02s\n",
      "341:\tlearn: 0.0708840\ttotal: 2.2s\tremaining: 1.01s\n",
      "342:\tlearn: 0.0705063\ttotal: 2.2s\tremaining: 1.01s\n",
      "343:\tlearn: 0.0701356\ttotal: 2.2s\tremaining: 1000ms\n",
      "344:\tlearn: 0.0699196\ttotal: 2.21s\tremaining: 992ms\n",
      "345:\tlearn: 0.0695223\ttotal: 2.21s\tremaining: 985ms\n",
      "346:\tlearn: 0.0691999\ttotal: 2.22s\tremaining: 977ms\n",
      "347:\tlearn: 0.0689281\ttotal: 2.22s\tremaining: 970ms\n",
      "348:\tlearn: 0.0686406\ttotal: 2.23s\tremaining: 963ms\n",
      "349:\tlearn: 0.0680985\ttotal: 2.23s\tremaining: 958ms\n",
      "350:\tlearn: 0.0678470\ttotal: 2.25s\tremaining: 953ms\n",
      "351:\tlearn: 0.0675816\ttotal: 2.25s\tremaining: 948ms\n",
      "352:\tlearn: 0.0672924\ttotal: 2.27s\tremaining: 943ms\n",
      "353:\tlearn: 0.0669899\ttotal: 2.27s\tremaining: 938ms\n",
      "354:\tlearn: 0.0666426\ttotal: 2.28s\tremaining: 933ms\n",
      "355:\tlearn: 0.0662613\ttotal: 2.29s\tremaining: 928ms\n",
      "356:\tlearn: 0.0658737\ttotal: 2.3s\tremaining: 923ms\n",
      "357:\tlearn: 0.0655403\ttotal: 2.31s\tremaining: 918ms\n",
      "358:\tlearn: 0.0651531\ttotal: 2.32s\tremaining: 911ms\n",
      "359:\tlearn: 0.0649135\ttotal: 2.33s\tremaining: 905ms\n",
      "360:\tlearn: 0.0645492\ttotal: 2.33s\tremaining: 898ms\n",
      "361:\tlearn: 0.0642622\ttotal: 2.34s\tremaining: 892ms\n",
      "362:\tlearn: 0.0639153\ttotal: 2.34s\tremaining: 885ms\n",
      "363:\tlearn: 0.0635769\ttotal: 2.35s\tremaining: 878ms\n",
      "364:\tlearn: 0.0633215\ttotal: 2.35s\tremaining: 871ms\n",
      "365:\tlearn: 0.0630339\ttotal: 2.36s\tremaining: 864ms\n",
      "366:\tlearn: 0.0627354\ttotal: 2.36s\tremaining: 857ms\n",
      "367:\tlearn: 0.0624231\ttotal: 2.37s\tremaining: 850ms\n",
      "368:\tlearn: 0.0620287\ttotal: 2.37s\tremaining: 842ms\n",
      "369:\tlearn: 0.0617007\ttotal: 2.38s\tremaining: 835ms\n",
      "370:\tlearn: 0.0613260\ttotal: 2.38s\tremaining: 828ms\n",
      "371:\tlearn: 0.0610482\ttotal: 2.39s\tremaining: 821ms\n",
      "372:\tlearn: 0.0606952\ttotal: 2.39s\tremaining: 814ms\n",
      "373:\tlearn: 0.0604289\ttotal: 2.4s\tremaining: 809ms\n",
      "374:\tlearn: 0.0602674\ttotal: 2.41s\tremaining: 803ms\n",
      "375:\tlearn: 0.0598224\ttotal: 2.42s\tremaining: 798ms\n",
      "376:\tlearn: 0.0595859\ttotal: 2.43s\tremaining: 793ms\n",
      "377:\tlearn: 0.0592811\ttotal: 2.44s\tremaining: 787ms\n",
      "378:\tlearn: 0.0590837\ttotal: 2.45s\tremaining: 782ms\n",
      "379:\tlearn: 0.0587773\ttotal: 2.46s\tremaining: 776ms\n",
      "380:\tlearn: 0.0584606\ttotal: 2.47s\tremaining: 771ms\n",
      "381:\tlearn: 0.0582282\ttotal: 2.48s\tremaining: 765ms\n",
      "382:\tlearn: 0.0579546\ttotal: 2.49s\tremaining: 760ms\n",
      "383:\tlearn: 0.0576772\ttotal: 2.49s\tremaining: 753ms\n",
      "384:\tlearn: 0.0573960\ttotal: 2.5s\tremaining: 747ms\n",
      "385:\tlearn: 0.0570206\ttotal: 2.51s\tremaining: 740ms\n",
      "386:\tlearn: 0.0567300\ttotal: 2.51s\tremaining: 734ms\n",
      "387:\tlearn: 0.0564717\ttotal: 2.52s\tremaining: 727ms\n",
      "388:\tlearn: 0.0562060\ttotal: 2.52s\tremaining: 721ms\n",
      "389:\tlearn: 0.0557912\ttotal: 2.53s\tremaining: 714ms\n",
      "390:\tlearn: 0.0555498\ttotal: 2.54s\tremaining: 707ms\n",
      "391:\tlearn: 0.0553010\ttotal: 2.54s\tremaining: 700ms\n",
      "392:\tlearn: 0.0550203\ttotal: 2.54s\tremaining: 693ms\n",
      "393:\tlearn: 0.0547792\ttotal: 2.55s\tremaining: 686ms\n",
      "394:\tlearn: 0.0545560\ttotal: 2.55s\tremaining: 679ms\n",
      "395:\tlearn: 0.0543352\ttotal: 2.56s\tremaining: 672ms\n",
      "396:\tlearn: 0.0540653\ttotal: 2.56s\tremaining: 665ms\n",
      "397:\tlearn: 0.0538312\ttotal: 2.57s\tremaining: 659ms\n",
      "398:\tlearn: 0.0534969\ttotal: 2.58s\tremaining: 653ms\n",
      "399:\tlearn: 0.0532332\ttotal: 2.59s\tremaining: 648ms\n",
      "400:\tlearn: 0.0530277\ttotal: 2.6s\tremaining: 642ms\n",
      "401:\tlearn: 0.0527863\ttotal: 2.61s\tremaining: 636ms\n",
      "402:\tlearn: 0.0526222\ttotal: 2.62s\tremaining: 630ms\n",
      "403:\tlearn: 0.0523559\ttotal: 2.63s\tremaining: 624ms\n",
      "404:\tlearn: 0.0520696\ttotal: 2.63s\tremaining: 617ms\n",
      "405:\tlearn: 0.0518706\ttotal: 2.64s\tremaining: 611ms\n",
      "406:\tlearn: 0.0517650\ttotal: 2.64s\tremaining: 604ms\n",
      "407:\tlearn: 0.0514623\ttotal: 2.65s\tremaining: 597ms\n",
      "408:\tlearn: 0.0512096\ttotal: 2.65s\tremaining: 591ms\n",
      "409:\tlearn: 0.0509941\ttotal: 2.66s\tremaining: 584ms\n",
      "410:\tlearn: 0.0507074\ttotal: 2.66s\tremaining: 577ms\n",
      "411:\tlearn: 0.0504856\ttotal: 2.67s\tremaining: 570ms\n",
      "412:\tlearn: 0.0501728\ttotal: 2.67s\tremaining: 563ms\n",
      "413:\tlearn: 0.0498805\ttotal: 2.68s\tremaining: 556ms\n",
      "414:\tlearn: 0.0495309\ttotal: 2.68s\tremaining: 549ms\n",
      "415:\tlearn: 0.0492832\ttotal: 2.69s\tremaining: 543ms\n",
      "416:\tlearn: 0.0490539\ttotal: 2.69s\tremaining: 535ms\n",
      "417:\tlearn: 0.0488201\ttotal: 2.69s\tremaining: 529ms\n",
      "418:\tlearn: 0.0486151\ttotal: 2.7s\tremaining: 522ms\n",
      "419:\tlearn: 0.0484290\ttotal: 2.7s\tremaining: 515ms\n",
      "420:\tlearn: 0.0481668\ttotal: 2.71s\tremaining: 508ms\n",
      "421:\tlearn: 0.0479481\ttotal: 2.71s\tremaining: 501ms\n",
      "422:\tlearn: 0.0477515\ttotal: 2.72s\tremaining: 494ms\n",
      "423:\tlearn: 0.0475122\ttotal: 2.72s\tremaining: 488ms\n",
      "424:\tlearn: 0.0473229\ttotal: 2.72s\tremaining: 481ms\n",
      "425:\tlearn: 0.0471249\ttotal: 2.73s\tremaining: 474ms\n",
      "426:\tlearn: 0.0469179\ttotal: 2.73s\tremaining: 467ms\n",
      "427:\tlearn: 0.0466610\ttotal: 2.74s\tremaining: 461ms\n",
      "428:\tlearn: 0.0464541\ttotal: 2.75s\tremaining: 455ms\n",
      "429:\tlearn: 0.0462309\ttotal: 2.76s\tremaining: 450ms\n",
      "430:\tlearn: 0.0460353\ttotal: 2.77s\tremaining: 444ms\n",
      "431:\tlearn: 0.0455103\ttotal: 2.78s\tremaining: 438ms\n",
      "432:\tlearn: 0.0451157\ttotal: 2.79s\tremaining: 432ms\n",
      "433:\tlearn: 0.0449311\ttotal: 2.8s\tremaining: 426ms\n",
      "434:\tlearn: 0.0447542\ttotal: 2.81s\tremaining: 420ms\n",
      "435:\tlearn: 0.0445426\ttotal: 2.82s\tremaining: 414ms\n",
      "436:\tlearn: 0.0442009\ttotal: 2.83s\tremaining: 408ms\n",
      "437:\tlearn: 0.0440563\ttotal: 2.84s\tremaining: 402ms\n",
      "438:\tlearn: 0.0437554\ttotal: 2.85s\tremaining: 396ms\n",
      "439:\tlearn: 0.0434761\ttotal: 2.86s\tremaining: 390ms\n",
      "440:\tlearn: 0.0433005\ttotal: 2.87s\tremaining: 384ms\n",
      "441:\tlearn: 0.0431069\ttotal: 2.88s\tremaining: 378ms\n",
      "442:\tlearn: 0.0429149\ttotal: 2.89s\tremaining: 372ms\n",
      "443:\tlearn: 0.0427545\ttotal: 2.9s\tremaining: 366ms\n",
      "444:\tlearn: 0.0424900\ttotal: 2.91s\tremaining: 360ms\n",
      "445:\tlearn: 0.0422933\ttotal: 2.92s\tremaining: 354ms\n",
      "446:\tlearn: 0.0421026\ttotal: 2.93s\tremaining: 348ms\n",
      "447:\tlearn: 0.0420265\ttotal: 2.94s\tremaining: 342ms\n",
      "448:\tlearn: 0.0418607\ttotal: 2.95s\tremaining: 335ms\n",
      "449:\tlearn: 0.0415347\ttotal: 2.96s\tremaining: 329ms\n",
      "450:\tlearn: 0.0413794\ttotal: 2.97s\tremaining: 322ms\n",
      "451:\tlearn: 0.0410424\ttotal: 2.97s\tremaining: 315ms\n",
      "452:\tlearn: 0.0408385\ttotal: 2.97s\tremaining: 309ms\n",
      "453:\tlearn: 0.0406770\ttotal: 2.98s\tremaining: 302ms\n",
      "454:\tlearn: 0.0404899\ttotal: 2.98s\tremaining: 295ms\n",
      "455:\tlearn: 0.0402992\ttotal: 2.99s\tremaining: 288ms\n",
      "456:\tlearn: 0.0400674\ttotal: 2.99s\tremaining: 281ms\n",
      "457:\tlearn: 0.0398389\ttotal: 3s\tremaining: 275ms\n",
      "458:\tlearn: 0.0396667\ttotal: 3s\tremaining: 268ms\n",
      "459:\tlearn: 0.0395455\ttotal: 3.01s\tremaining: 262ms\n",
      "460:\tlearn: 0.0393157\ttotal: 3.02s\tremaining: 256ms\n",
      "461:\tlearn: 0.0391572\ttotal: 3.03s\tremaining: 250ms\n",
      "462:\tlearn: 0.0389974\ttotal: 3.04s\tremaining: 243ms\n",
      "463:\tlearn: 0.0388311\ttotal: 3.05s\tremaining: 237ms\n",
      "464:\tlearn: 0.0386421\ttotal: 3.06s\tremaining: 230ms\n",
      "465:\tlearn: 0.0384356\ttotal: 3.07s\tremaining: 224ms\n",
      "466:\tlearn: 0.0382715\ttotal: 3.08s\tremaining: 218ms\n",
      "467:\tlearn: 0.0380155\ttotal: 3.09s\tremaining: 211ms\n",
      "468:\tlearn: 0.0378329\ttotal: 3.1s\tremaining: 205ms\n",
      "469:\tlearn: 0.0376585\ttotal: 3.1s\tremaining: 198ms\n",
      "470:\tlearn: 0.0374685\ttotal: 3.11s\tremaining: 191ms\n",
      "471:\tlearn: 0.0372917\ttotal: 3.11s\tremaining: 185ms\n",
      "472:\tlearn: 0.0371762\ttotal: 3.12s\tremaining: 178ms\n",
      "473:\tlearn: 0.0370885\ttotal: 3.12s\tremaining: 171ms\n",
      "474:\tlearn: 0.0369567\ttotal: 3.12s\tremaining: 164ms\n",
      "475:\tlearn: 0.0368006\ttotal: 3.13s\tremaining: 158ms\n",
      "476:\tlearn: 0.0366388\ttotal: 3.14s\tremaining: 151ms\n",
      "477:\tlearn: 0.0364974\ttotal: 3.15s\tremaining: 145ms\n",
      "478:\tlearn: 0.0363156\ttotal: 3.16s\tremaining: 138ms\n",
      "479:\tlearn: 0.0361275\ttotal: 3.17s\tremaining: 132ms\n",
      "480:\tlearn: 0.0360021\ttotal: 3.18s\tremaining: 125ms\n",
      "481:\tlearn: 0.0358232\ttotal: 3.19s\tremaining: 119ms\n",
      "482:\tlearn: 0.0356054\ttotal: 3.19s\tremaining: 112ms\n",
      "483:\tlearn: 0.0354438\ttotal: 3.19s\tremaining: 106ms\n",
      "484:\tlearn: 0.0353499\ttotal: 3.2s\tremaining: 99ms\n",
      "485:\tlearn: 0.0351852\ttotal: 3.2s\tremaining: 92.3ms\n",
      "486:\tlearn: 0.0350022\ttotal: 3.21s\tremaining: 85.7ms\n",
      "487:\tlearn: 0.0348320\ttotal: 3.21s\tremaining: 79ms\n",
      "488:\tlearn: 0.0346668\ttotal: 3.22s\tremaining: 72.4ms\n",
      "489:\tlearn: 0.0344908\ttotal: 3.22s\tremaining: 65.8ms\n",
      "490:\tlearn: 0.0343546\ttotal: 3.23s\tremaining: 59.2ms\n",
      "491:\tlearn: 0.0341746\ttotal: 3.23s\tremaining: 52.6ms\n",
      "492:\tlearn: 0.0340041\ttotal: 3.23s\tremaining: 45.9ms\n",
      "493:\tlearn: 0.0338409\ttotal: 3.24s\tremaining: 39.4ms\n",
      "494:\tlearn: 0.0336412\ttotal: 3.24s\tremaining: 32.8ms\n",
      "495:\tlearn: 0.0335305\ttotal: 3.25s\tremaining: 26.2ms\n",
      "496:\tlearn: 0.0333933\ttotal: 3.25s\tremaining: 19.6ms\n",
      "497:\tlearn: 0.0332823\ttotal: 3.26s\tremaining: 13.1ms\n",
      "498:\tlearn: 0.0331386\ttotal: 3.26s\tremaining: 6.54ms\n",
      "499:\tlearn: 0.0330029\ttotal: 3.27s\tremaining: 0us\n",
      "0:\tlearn: 0.6829995\ttotal: 5.08ms\tremaining: 2.54s\n",
      "1:\tlearn: 0.6719860\ttotal: 9.73ms\tremaining: 2.42s\n",
      "2:\tlearn: 0.6591922\ttotal: 14.3ms\tremaining: 2.37s\n",
      "3:\tlearn: 0.6481240\ttotal: 19.2ms\tremaining: 2.38s\n",
      "4:\tlearn: 0.6362933\ttotal: 23.6ms\tremaining: 2.34s\n",
      "5:\tlearn: 0.6270850\ttotal: 27.9ms\tremaining: 2.29s\n",
      "6:\tlearn: 0.6168203\ttotal: 32.3ms\tremaining: 2.27s\n",
      "7:\tlearn: 0.6085195\ttotal: 36.8ms\tremaining: 2.26s\n",
      "8:\tlearn: 0.5994792\ttotal: 41ms\tremaining: 2.24s\n",
      "9:\tlearn: 0.5929177\ttotal: 45.1ms\tremaining: 2.21s\n",
      "10:\tlearn: 0.5860063\ttotal: 49.5ms\tremaining: 2.2s\n",
      "11:\tlearn: 0.5813774\ttotal: 59ms\tremaining: 2.4s\n",
      "12:\tlearn: 0.5749021\ttotal: 68.8ms\tremaining: 2.58s\n",
      "13:\tlearn: 0.5680583\ttotal: 78.4ms\tremaining: 2.72s\n",
      "14:\tlearn: 0.5624822\ttotal: 88.1ms\tremaining: 2.85s\n",
      "15:\tlearn: 0.5567457\ttotal: 97.7ms\tremaining: 2.96s\n",
      "16:\tlearn: 0.5498884\ttotal: 107ms\tremaining: 3.05s\n",
      "17:\tlearn: 0.5453624\ttotal: 117ms\tremaining: 3.13s\n",
      "18:\tlearn: 0.5398115\ttotal: 127ms\tremaining: 3.21s\n",
      "19:\tlearn: 0.5338379\ttotal: 136ms\tremaining: 3.26s\n",
      "20:\tlearn: 0.5283974\ttotal: 143ms\tremaining: 3.27s\n",
      "21:\tlearn: 0.5231939\ttotal: 149ms\tremaining: 3.24s\n",
      "22:\tlearn: 0.5165753\ttotal: 156ms\tremaining: 3.23s\n",
      "23:\tlearn: 0.5126826\ttotal: 162ms\tremaining: 3.21s\n",
      "24:\tlearn: 0.5088914\ttotal: 168ms\tremaining: 3.19s\n",
      "25:\tlearn: 0.5034558\ttotal: 173ms\tremaining: 3.15s\n",
      "26:\tlearn: 0.4966008\ttotal: 177ms\tremaining: 3.11s\n",
      "27:\tlearn: 0.4922758\ttotal: 183ms\tremaining: 3.08s\n",
      "28:\tlearn: 0.4872501\ttotal: 188ms\tremaining: 3.06s\n",
      "29:\tlearn: 0.4841873\ttotal: 191ms\tremaining: 3s\n",
      "30:\tlearn: 0.4781238\ttotal: 195ms\tremaining: 2.95s\n",
      "31:\tlearn: 0.4746464\ttotal: 200ms\tremaining: 2.92s\n",
      "32:\tlearn: 0.4719752\ttotal: 204ms\tremaining: 2.88s\n",
      "33:\tlearn: 0.4679550\ttotal: 208ms\tremaining: 2.85s\n",
      "34:\tlearn: 0.4637163\ttotal: 213ms\tremaining: 2.82s\n",
      "35:\tlearn: 0.4592735\ttotal: 217ms\tremaining: 2.79s\n",
      "36:\tlearn: 0.4564356\ttotal: 221ms\tremaining: 2.76s\n",
      "37:\tlearn: 0.4527506\ttotal: 230ms\tremaining: 2.8s\n",
      "38:\tlearn: 0.4497922\ttotal: 240ms\tremaining: 2.84s\n",
      "39:\tlearn: 0.4463711\ttotal: 250ms\tremaining: 2.87s\n",
      "40:\tlearn: 0.4435545\ttotal: 259ms\tremaining: 2.9s\n",
      "41:\tlearn: 0.4402332\ttotal: 269ms\tremaining: 2.94s\n",
      "42:\tlearn: 0.4362058\ttotal: 279ms\tremaining: 2.96s\n",
      "43:\tlearn: 0.4335965\ttotal: 289ms\tremaining: 2.99s\n",
      "44:\tlearn: 0.4295000\ttotal: 298ms\tremaining: 3.01s\n",
      "45:\tlearn: 0.4266132\ttotal: 307ms\tremaining: 3.03s\n",
      "46:\tlearn: 0.4229021\ttotal: 318ms\tremaining: 3.07s\n",
      "47:\tlearn: 0.4193985\ttotal: 324ms\tremaining: 3.06s\n",
      "48:\tlearn: 0.4166559\ttotal: 333ms\tremaining: 3.07s\n",
      "49:\tlearn: 0.4097362\ttotal: 340ms\tremaining: 3.06s\n",
      "50:\tlearn: 0.4060111\ttotal: 345ms\tremaining: 3.03s\n",
      "51:\tlearn: 0.4038426\ttotal: 349ms\tremaining: 3.01s\n",
      "52:\tlearn: 0.4012657\ttotal: 354ms\tremaining: 2.98s\n",
      "53:\tlearn: 0.3985508\ttotal: 359ms\tremaining: 2.96s\n",
      "54:\tlearn: 0.3958938\ttotal: 362ms\tremaining: 2.93s\n",
      "55:\tlearn: 0.3924846\ttotal: 365ms\tremaining: 2.9s\n",
      "56:\tlearn: 0.3896393\ttotal: 369ms\tremaining: 2.87s\n",
      "57:\tlearn: 0.3866255\ttotal: 374ms\tremaining: 2.85s\n",
      "58:\tlearn: 0.3841571\ttotal: 377ms\tremaining: 2.82s\n",
      "59:\tlearn: 0.3824125\ttotal: 382ms\tremaining: 2.8s\n",
      "60:\tlearn: 0.3786525\ttotal: 387ms\tremaining: 2.78s\n",
      "61:\tlearn: 0.3766201\ttotal: 390ms\tremaining: 2.76s\n",
      "62:\tlearn: 0.3736792\ttotal: 400ms\tremaining: 2.77s\n",
      "63:\tlearn: 0.3714550\ttotal: 410ms\tremaining: 2.79s\n",
      "64:\tlearn: 0.3686508\ttotal: 419ms\tremaining: 2.81s\n",
      "65:\tlearn: 0.3660821\ttotal: 429ms\tremaining: 2.82s\n",
      "66:\tlearn: 0.3637202\ttotal: 439ms\tremaining: 2.83s\n",
      "67:\tlearn: 0.3588940\ttotal: 448ms\tremaining: 2.85s\n",
      "68:\tlearn: 0.3565030\ttotal: 458ms\tremaining: 2.86s\n",
      "69:\tlearn: 0.3545646\ttotal: 468ms\tremaining: 2.87s\n",
      "70:\tlearn: 0.3520757\ttotal: 477ms\tremaining: 2.88s\n",
      "71:\tlearn: 0.3498087\ttotal: 486ms\tremaining: 2.89s\n",
      "72:\tlearn: 0.3473084\ttotal: 493ms\tremaining: 2.88s\n",
      "73:\tlearn: 0.3448425\ttotal: 499ms\tremaining: 2.87s\n",
      "74:\tlearn: 0.3417775\ttotal: 506ms\tremaining: 2.86s\n",
      "75:\tlearn: 0.3392323\ttotal: 511ms\tremaining: 2.85s\n",
      "76:\tlearn: 0.3371770\ttotal: 518ms\tremaining: 2.84s\n",
      "77:\tlearn: 0.3352326\ttotal: 524ms\tremaining: 2.83s\n",
      "78:\tlearn: 0.3331231\ttotal: 530ms\tremaining: 2.82s\n",
      "79:\tlearn: 0.3306266\ttotal: 536ms\tremaining: 2.81s\n",
      "80:\tlearn: 0.3287664\ttotal: 540ms\tremaining: 2.79s\n",
      "81:\tlearn: 0.3264142\ttotal: 543ms\tremaining: 2.77s\n",
      "82:\tlearn: 0.3238804\ttotal: 549ms\tremaining: 2.75s\n",
      "83:\tlearn: 0.3216397\ttotal: 552ms\tremaining: 2.73s\n",
      "84:\tlearn: 0.3194382\ttotal: 557ms\tremaining: 2.72s\n",
      "85:\tlearn: 0.3168913\ttotal: 562ms\tremaining: 2.7s\n",
      "86:\tlearn: 0.3149878\ttotal: 565ms\tremaining: 2.68s\n",
      "87:\tlearn: 0.3128159\ttotal: 570ms\tremaining: 2.67s\n",
      "88:\tlearn: 0.3109421\ttotal: 574ms\tremaining: 2.65s\n",
      "89:\tlearn: 0.3084334\ttotal: 579ms\tremaining: 2.64s\n",
      "90:\tlearn: 0.3034243\ttotal: 583ms\tremaining: 2.62s\n",
      "91:\tlearn: 0.3010932\ttotal: 588ms\tremaining: 2.6s\n",
      "92:\tlearn: 0.2970109\ttotal: 592ms\tremaining: 2.59s\n",
      "93:\tlearn: 0.2930636\ttotal: 596ms\tremaining: 2.57s\n",
      "94:\tlearn: 0.2910298\ttotal: 606ms\tremaining: 2.58s\n",
      "95:\tlearn: 0.2891827\ttotal: 616ms\tremaining: 2.59s\n",
      "96:\tlearn: 0.2873552\ttotal: 626ms\tremaining: 2.6s\n",
      "97:\tlearn: 0.2851207\ttotal: 635ms\tremaining: 2.6s\n",
      "98:\tlearn: 0.2828998\ttotal: 645ms\tremaining: 2.61s\n",
      "99:\tlearn: 0.2809647\ttotal: 654ms\tremaining: 2.62s\n",
      "100:\tlearn: 0.2792585\ttotal: 664ms\tremaining: 2.62s\n",
      "101:\tlearn: 0.2762367\ttotal: 674ms\tremaining: 2.63s\n",
      "102:\tlearn: 0.2745173\ttotal: 680ms\tremaining: 2.62s\n",
      "103:\tlearn: 0.2724650\ttotal: 686ms\tremaining: 2.61s\n",
      "104:\tlearn: 0.2704713\ttotal: 692ms\tremaining: 2.6s\n",
      "105:\tlearn: 0.2688129\ttotal: 698ms\tremaining: 2.6s\n",
      "106:\tlearn: 0.2666942\ttotal: 704ms\tremaining: 2.59s\n",
      "107:\tlearn: 0.2649359\ttotal: 709ms\tremaining: 2.57s\n",
      "108:\tlearn: 0.2632741\ttotal: 714ms\tremaining: 2.56s\n",
      "109:\tlearn: 0.2605709\ttotal: 719ms\tremaining: 2.55s\n",
      "110:\tlearn: 0.2589193\ttotal: 724ms\tremaining: 2.54s\n",
      "111:\tlearn: 0.2573334\ttotal: 728ms\tremaining: 2.52s\n",
      "112:\tlearn: 0.2556730\ttotal: 732ms\tremaining: 2.51s\n",
      "113:\tlearn: 0.2540307\ttotal: 736ms\tremaining: 2.49s\n",
      "114:\tlearn: 0.2526095\ttotal: 740ms\tremaining: 2.48s\n",
      "115:\tlearn: 0.2495455\ttotal: 744ms\tremaining: 2.46s\n",
      "116:\tlearn: 0.2481584\ttotal: 749ms\tremaining: 2.45s\n",
      "117:\tlearn: 0.2467256\ttotal: 753ms\tremaining: 2.44s\n",
      "118:\tlearn: 0.2453822\ttotal: 757ms\tremaining: 2.42s\n",
      "119:\tlearn: 0.2437788\ttotal: 762ms\tremaining: 2.41s\n",
      "120:\tlearn: 0.2418786\ttotal: 767ms\tremaining: 2.4s\n",
      "121:\tlearn: 0.2400713\ttotal: 777ms\tremaining: 2.41s\n",
      "122:\tlearn: 0.2388961\ttotal: 787ms\tremaining: 2.41s\n",
      "123:\tlearn: 0.2367442\ttotal: 797ms\tremaining: 2.42s\n",
      "124:\tlearn: 0.2337670\ttotal: 806ms\tremaining: 2.42s\n",
      "125:\tlearn: 0.2323551\ttotal: 816ms\tremaining: 2.42s\n",
      "126:\tlearn: 0.2307599\ttotal: 826ms\tremaining: 2.42s\n",
      "127:\tlearn: 0.2292376\ttotal: 835ms\tremaining: 2.43s\n",
      "128:\tlearn: 0.2278730\ttotal: 844ms\tremaining: 2.43s\n",
      "129:\tlearn: 0.2266316\ttotal: 850ms\tremaining: 2.42s\n",
      "130:\tlearn: 0.2254225\ttotal: 856ms\tremaining: 2.41s\n",
      "131:\tlearn: 0.2234277\ttotal: 863ms\tremaining: 2.4s\n",
      "132:\tlearn: 0.2223175\ttotal: 869ms\tremaining: 2.4s\n",
      "133:\tlearn: 0.2205965\ttotal: 875ms\tremaining: 2.39s\n",
      "134:\tlearn: 0.2181019\ttotal: 881ms\tremaining: 2.38s\n",
      "135:\tlearn: 0.2168940\ttotal: 886ms\tremaining: 2.37s\n",
      "136:\tlearn: 0.2155681\ttotal: 893ms\tremaining: 2.37s\n",
      "137:\tlearn: 0.2142854\ttotal: 899ms\tremaining: 2.36s\n",
      "138:\tlearn: 0.2129633\ttotal: 904ms\tremaining: 2.35s\n",
      "139:\tlearn: 0.2117825\ttotal: 908ms\tremaining: 2.34s\n",
      "140:\tlearn: 0.2104458\ttotal: 913ms\tremaining: 2.33s\n",
      "141:\tlearn: 0.2089307\ttotal: 918ms\tremaining: 2.31s\n",
      "142:\tlearn: 0.2076599\ttotal: 922ms\tremaining: 2.3s\n",
      "143:\tlearn: 0.2066069\ttotal: 927ms\tremaining: 2.29s\n",
      "144:\tlearn: 0.2054278\ttotal: 931ms\tremaining: 2.28s\n",
      "145:\tlearn: 0.2038100\ttotal: 940ms\tremaining: 2.28s\n",
      "146:\tlearn: 0.2024821\ttotal: 950ms\tremaining: 2.28s\n",
      "147:\tlearn: 0.2014205\ttotal: 960ms\tremaining: 2.28s\n",
      "148:\tlearn: 0.2002784\ttotal: 970ms\tremaining: 2.29s\n",
      "149:\tlearn: 0.1991221\ttotal: 980ms\tremaining: 2.29s\n",
      "150:\tlearn: 0.1979035\ttotal: 989ms\tremaining: 2.29s\n",
      "151:\tlearn: 0.1967100\ttotal: 997ms\tremaining: 2.28s\n",
      "152:\tlearn: 0.1956609\ttotal: 1s\tremaining: 2.28s\n",
      "153:\tlearn: 0.1945809\ttotal: 1.01s\tremaining: 2.27s\n",
      "154:\tlearn: 0.1928339\ttotal: 1.02s\tremaining: 2.26s\n",
      "155:\tlearn: 0.1915917\ttotal: 1.02s\tremaining: 2.25s\n",
      "156:\tlearn: 0.1907103\ttotal: 1.03s\tremaining: 2.25s\n",
      "157:\tlearn: 0.1893575\ttotal: 1.03s\tremaining: 2.24s\n",
      "158:\tlearn: 0.1880789\ttotal: 1.04s\tremaining: 2.23s\n",
      "159:\tlearn: 0.1869216\ttotal: 1.05s\tremaining: 2.22s\n",
      "160:\tlearn: 0.1857135\ttotal: 1.05s\tremaining: 2.21s\n",
      "161:\tlearn: 0.1844977\ttotal: 1.05s\tremaining: 2.2s\n",
      "162:\tlearn: 0.1834825\ttotal: 1.06s\tremaining: 2.19s\n",
      "163:\tlearn: 0.1825246\ttotal: 1.06s\tremaining: 2.18s\n",
      "164:\tlearn: 0.1816308\ttotal: 1.07s\tremaining: 2.18s\n",
      "165:\tlearn: 0.1806264\ttotal: 1.07s\tremaining: 2.16s\n",
      "166:\tlearn: 0.1793739\ttotal: 1.08s\tremaining: 2.15s\n",
      "167:\tlearn: 0.1783566\ttotal: 1.08s\tremaining: 2.14s\n",
      "168:\tlearn: 0.1774966\ttotal: 1.09s\tremaining: 2.13s\n",
      "169:\tlearn: 0.1765920\ttotal: 1.09s\tremaining: 2.12s\n",
      "170:\tlearn: 0.1749038\ttotal: 1.1s\tremaining: 2.11s\n",
      "171:\tlearn: 0.1738125\ttotal: 1.1s\tremaining: 2.1s\n",
      "172:\tlearn: 0.1728648\ttotal: 1.11s\tremaining: 2.1s\n",
      "173:\tlearn: 0.1719486\ttotal: 1.12s\tremaining: 2.1s\n",
      "174:\tlearn: 0.1702601\ttotal: 1.13s\tremaining: 2.1s\n",
      "175:\tlearn: 0.1694311\ttotal: 1.14s\tremaining: 2.1s\n",
      "176:\tlearn: 0.1682404\ttotal: 1.15s\tremaining: 2.1s\n",
      "177:\tlearn: 0.1672362\ttotal: 1.16s\tremaining: 2.1s\n",
      "178:\tlearn: 0.1663258\ttotal: 1.17s\tremaining: 2.1s\n",
      "179:\tlearn: 0.1654743\ttotal: 1.18s\tremaining: 2.1s\n",
      "180:\tlearn: 0.1646705\ttotal: 1.19s\tremaining: 2.1s\n",
      "181:\tlearn: 0.1637178\ttotal: 1.2s\tremaining: 2.09s\n",
      "182:\tlearn: 0.1627775\ttotal: 1.2s\tremaining: 2.08s\n",
      "183:\tlearn: 0.1619064\ttotal: 1.21s\tremaining: 2.07s\n",
      "184:\tlearn: 0.1609520\ttotal: 1.21s\tremaining: 2.07s\n",
      "185:\tlearn: 0.1599613\ttotal: 1.22s\tremaining: 2.06s\n",
      "186:\tlearn: 0.1591897\ttotal: 1.22s\tremaining: 2.05s\n",
      "187:\tlearn: 0.1584611\ttotal: 1.23s\tremaining: 2.04s\n",
      "188:\tlearn: 0.1577481\ttotal: 1.23s\tremaining: 2.03s\n",
      "189:\tlearn: 0.1569857\ttotal: 1.24s\tremaining: 2.02s\n",
      "190:\tlearn: 0.1560075\ttotal: 1.24s\tremaining: 2.01s\n",
      "191:\tlearn: 0.1550791\ttotal: 1.25s\tremaining: 2s\n",
      "192:\tlearn: 0.1543224\ttotal: 1.25s\tremaining: 1.99s\n",
      "193:\tlearn: 0.1532316\ttotal: 1.25s\tremaining: 1.98s\n",
      "194:\tlearn: 0.1524997\ttotal: 1.26s\tremaining: 1.97s\n",
      "195:\tlearn: 0.1517541\ttotal: 1.26s\tremaining: 1.96s\n",
      "196:\tlearn: 0.1510048\ttotal: 1.26s\tremaining: 1.95s\n",
      "197:\tlearn: 0.1503648\ttotal: 1.27s\tremaining: 1.94s\n",
      "198:\tlearn: 0.1493658\ttotal: 1.27s\tremaining: 1.93s\n",
      "199:\tlearn: 0.1486531\ttotal: 1.28s\tremaining: 1.93s\n",
      "200:\tlearn: 0.1477313\ttotal: 1.29s\tremaining: 1.92s\n",
      "201:\tlearn: 0.1469855\ttotal: 1.3s\tremaining: 1.92s\n",
      "202:\tlearn: 0.1457262\ttotal: 1.31s\tremaining: 1.92s\n",
      "203:\tlearn: 0.1449185\ttotal: 1.32s\tremaining: 1.92s\n",
      "204:\tlearn: 0.1433479\ttotal: 1.33s\tremaining: 1.92s\n",
      "205:\tlearn: 0.1426229\ttotal: 1.34s\tremaining: 1.91s\n",
      "206:\tlearn: 0.1418428\ttotal: 1.35s\tremaining: 1.91s\n",
      "207:\tlearn: 0.1410813\ttotal: 1.36s\tremaining: 1.91s\n",
      "208:\tlearn: 0.1395060\ttotal: 1.37s\tremaining: 1.9s\n",
      "209:\tlearn: 0.1383731\ttotal: 1.37s\tremaining: 1.9s\n",
      "210:\tlearn: 0.1372384\ttotal: 1.38s\tremaining: 1.89s\n",
      "211:\tlearn: 0.1365099\ttotal: 1.39s\tremaining: 1.88s\n",
      "212:\tlearn: 0.1357369\ttotal: 1.39s\tremaining: 1.87s\n",
      "213:\tlearn: 0.1350774\ttotal: 1.39s\tremaining: 1.86s\n",
      "214:\tlearn: 0.1344068\ttotal: 1.4s\tremaining: 1.85s\n",
      "215:\tlearn: 0.1337126\ttotal: 1.4s\tremaining: 1.84s\n",
      "216:\tlearn: 0.1328613\ttotal: 1.41s\tremaining: 1.84s\n",
      "217:\tlearn: 0.1320488\ttotal: 1.41s\tremaining: 1.83s\n",
      "218:\tlearn: 0.1313745\ttotal: 1.42s\tremaining: 1.82s\n",
      "219:\tlearn: 0.1300444\ttotal: 1.42s\tremaining: 1.81s\n",
      "220:\tlearn: 0.1294553\ttotal: 1.43s\tremaining: 1.8s\n",
      "221:\tlearn: 0.1286293\ttotal: 1.43s\tremaining: 1.79s\n",
      "222:\tlearn: 0.1277889\ttotal: 1.44s\tremaining: 1.78s\n",
      "223:\tlearn: 0.1271069\ttotal: 1.44s\tremaining: 1.77s\n",
      "224:\tlearn: 0.1262494\ttotal: 1.45s\tremaining: 1.77s\n",
      "225:\tlearn: 0.1256402\ttotal: 1.46s\tremaining: 1.77s\n",
      "226:\tlearn: 0.1250138\ttotal: 1.47s\tremaining: 1.77s\n",
      "227:\tlearn: 0.1243147\ttotal: 1.48s\tremaining: 1.76s\n",
      "228:\tlearn: 0.1236624\ttotal: 1.49s\tremaining: 1.76s\n",
      "229:\tlearn: 0.1227392\ttotal: 1.5s\tremaining: 1.76s\n",
      "230:\tlearn: 0.1220821\ttotal: 1.51s\tremaining: 1.76s\n",
      "231:\tlearn: 0.1216397\ttotal: 1.52s\tremaining: 1.75s\n",
      "232:\tlearn: 0.1211455\ttotal: 1.53s\tremaining: 1.75s\n",
      "233:\tlearn: 0.1205488\ttotal: 1.54s\tremaining: 1.75s\n",
      "234:\tlearn: 0.1199381\ttotal: 1.54s\tremaining: 1.74s\n",
      "235:\tlearn: 0.1193798\ttotal: 1.55s\tremaining: 1.73s\n",
      "236:\tlearn: 0.1188319\ttotal: 1.55s\tremaining: 1.73s\n",
      "237:\tlearn: 0.1178232\ttotal: 1.56s\tremaining: 1.72s\n",
      "238:\tlearn: 0.1172312\ttotal: 1.57s\tremaining: 1.71s\n",
      "239:\tlearn: 0.1164103\ttotal: 1.57s\tremaining: 1.7s\n",
      "240:\tlearn: 0.1159040\ttotal: 1.58s\tremaining: 1.7s\n",
      "241:\tlearn: 0.1148013\ttotal: 1.58s\tremaining: 1.69s\n",
      "242:\tlearn: 0.1142086\ttotal: 1.59s\tremaining: 1.68s\n",
      "243:\tlearn: 0.1135805\ttotal: 1.59s\tremaining: 1.67s\n",
      "244:\tlearn: 0.1130189\ttotal: 1.59s\tremaining: 1.66s\n",
      "245:\tlearn: 0.1121960\ttotal: 1.6s\tremaining: 1.65s\n",
      "246:\tlearn: 0.1115941\ttotal: 1.6s\tremaining: 1.64s\n",
      "247:\tlearn: 0.1110113\ttotal: 1.61s\tremaining: 1.63s\n",
      "248:\tlearn: 0.1104815\ttotal: 1.61s\tremaining: 1.63s\n",
      "249:\tlearn: 0.1098562\ttotal: 1.62s\tremaining: 1.62s\n",
      "250:\tlearn: 0.1092854\ttotal: 1.63s\tremaining: 1.61s\n",
      "251:\tlearn: 0.1086647\ttotal: 1.64s\tremaining: 1.61s\n",
      "252:\tlearn: 0.1080868\ttotal: 1.65s\tremaining: 1.61s\n",
      "253:\tlearn: 0.1075572\ttotal: 1.66s\tremaining: 1.6s\n",
      "254:\tlearn: 0.1067612\ttotal: 1.67s\tremaining: 1.6s\n",
      "255:\tlearn: 0.1062661\ttotal: 1.68s\tremaining: 1.6s\n",
      "256:\tlearn: 0.1058196\ttotal: 1.69s\tremaining: 1.59s\n",
      "257:\tlearn: 0.1047128\ttotal: 1.7s\tremaining: 1.59s\n",
      "258:\tlearn: 0.1042068\ttotal: 1.71s\tremaining: 1.59s\n",
      "259:\tlearn: 0.1037577\ttotal: 1.71s\tremaining: 1.58s\n",
      "260:\tlearn: 0.1032094\ttotal: 1.72s\tremaining: 1.57s\n",
      "261:\tlearn: 0.1027499\ttotal: 1.73s\tremaining: 1.57s\n",
      "262:\tlearn: 0.1022494\ttotal: 1.73s\tremaining: 1.56s\n",
      "263:\tlearn: 0.1017009\ttotal: 1.74s\tremaining: 1.55s\n",
      "264:\tlearn: 0.1011472\ttotal: 1.74s\tremaining: 1.54s\n",
      "265:\tlearn: 0.1006080\ttotal: 1.75s\tremaining: 1.54s\n",
      "266:\tlearn: 0.1001304\ttotal: 1.75s\tremaining: 1.53s\n",
      "267:\tlearn: 0.0996672\ttotal: 1.76s\tremaining: 1.52s\n",
      "268:\tlearn: 0.0991341\ttotal: 1.76s\tremaining: 1.51s\n",
      "269:\tlearn: 0.0985361\ttotal: 1.77s\tremaining: 1.5s\n",
      "270:\tlearn: 0.0979550\ttotal: 1.77s\tremaining: 1.5s\n",
      "271:\tlearn: 0.0973725\ttotal: 1.77s\tremaining: 1.49s\n",
      "272:\tlearn: 0.0969153\ttotal: 1.78s\tremaining: 1.48s\n",
      "273:\tlearn: 0.0964175\ttotal: 1.78s\tremaining: 1.47s\n",
      "274:\tlearn: 0.0962173\ttotal: 1.79s\tremaining: 1.47s\n",
      "275:\tlearn: 0.0956566\ttotal: 1.8s\tremaining: 1.46s\n",
      "276:\tlearn: 0.0952061\ttotal: 1.81s\tremaining: 1.46s\n",
      "277:\tlearn: 0.0946331\ttotal: 1.82s\tremaining: 1.46s\n",
      "278:\tlearn: 0.0941927\ttotal: 1.83s\tremaining: 1.45s\n",
      "279:\tlearn: 0.0935545\ttotal: 1.84s\tremaining: 1.45s\n",
      "280:\tlearn: 0.0931862\ttotal: 1.85s\tremaining: 1.44s\n",
      "281:\tlearn: 0.0926760\ttotal: 1.86s\tremaining: 1.44s\n",
      "282:\tlearn: 0.0920097\ttotal: 1.87s\tremaining: 1.44s\n",
      "283:\tlearn: 0.0916068\ttotal: 1.88s\tremaining: 1.43s\n",
      "284:\tlearn: 0.0909730\ttotal: 1.88s\tremaining: 1.42s\n",
      "285:\tlearn: 0.0904867\ttotal: 1.89s\tremaining: 1.41s\n",
      "286:\tlearn: 0.0902302\ttotal: 1.9s\tremaining: 1.41s\n",
      "287:\tlearn: 0.0898078\ttotal: 1.91s\tremaining: 1.4s\n",
      "288:\tlearn: 0.0892565\ttotal: 1.91s\tremaining: 1.4s\n",
      "289:\tlearn: 0.0889475\ttotal: 1.92s\tremaining: 1.39s\n",
      "290:\tlearn: 0.0885797\ttotal: 1.92s\tremaining: 1.38s\n",
      "291:\tlearn: 0.0880556\ttotal: 1.93s\tremaining: 1.37s\n",
      "292:\tlearn: 0.0875340\ttotal: 1.93s\tremaining: 1.36s\n",
      "293:\tlearn: 0.0869868\ttotal: 1.93s\tremaining: 1.35s\n",
      "294:\tlearn: 0.0864897\ttotal: 1.94s\tremaining: 1.35s\n",
      "295:\tlearn: 0.0859711\ttotal: 1.94s\tremaining: 1.34s\n",
      "296:\tlearn: 0.0855170\ttotal: 1.95s\tremaining: 1.33s\n",
      "297:\tlearn: 0.0849700\ttotal: 1.95s\tremaining: 1.32s\n",
      "298:\tlearn: 0.0845817\ttotal: 1.96s\tremaining: 1.31s\n",
      "299:\tlearn: 0.0843752\ttotal: 1.97s\tremaining: 1.31s\n",
      "300:\tlearn: 0.0840421\ttotal: 1.98s\tremaining: 1.31s\n",
      "301:\tlearn: 0.0836588\ttotal: 1.99s\tremaining: 1.3s\n",
      "302:\tlearn: 0.0832184\ttotal: 2s\tremaining: 1.3s\n",
      "303:\tlearn: 0.0827319\ttotal: 2s\tremaining: 1.29s\n",
      "304:\tlearn: 0.0822705\ttotal: 2.01s\tremaining: 1.29s\n",
      "305:\tlearn: 0.0819807\ttotal: 2.02s\tremaining: 1.28s\n",
      "306:\tlearn: 0.0817691\ttotal: 2.03s\tremaining: 1.28s\n",
      "307:\tlearn: 0.0813436\ttotal: 2.04s\tremaining: 1.27s\n",
      "308:\tlearn: 0.0810017\ttotal: 2.05s\tremaining: 1.26s\n",
      "309:\tlearn: 0.0806288\ttotal: 2.05s\tremaining: 1.26s\n",
      "310:\tlearn: 0.0798177\ttotal: 2.06s\tremaining: 1.25s\n",
      "311:\tlearn: 0.0793942\ttotal: 2.07s\tremaining: 1.24s\n",
      "312:\tlearn: 0.0790266\ttotal: 2.07s\tremaining: 1.24s\n",
      "313:\tlearn: 0.0786241\ttotal: 2.08s\tremaining: 1.23s\n",
      "314:\tlearn: 0.0784174\ttotal: 2.08s\tremaining: 1.22s\n",
      "315:\tlearn: 0.0780290\ttotal: 2.09s\tremaining: 1.22s\n",
      "316:\tlearn: 0.0775030\ttotal: 2.09s\tremaining: 1.21s\n",
      "317:\tlearn: 0.0771288\ttotal: 2.1s\tremaining: 1.2s\n",
      "318:\tlearn: 0.0767764\ttotal: 2.1s\tremaining: 1.19s\n",
      "319:\tlearn: 0.0763922\ttotal: 2.1s\tremaining: 1.18s\n",
      "320:\tlearn: 0.0760275\ttotal: 2.11s\tremaining: 1.18s\n",
      "321:\tlearn: 0.0756572\ttotal: 2.11s\tremaining: 1.17s\n",
      "322:\tlearn: 0.0753808\ttotal: 2.12s\tremaining: 1.16s\n",
      "323:\tlearn: 0.0749623\ttotal: 2.12s\tremaining: 1.15s\n",
      "324:\tlearn: 0.0745336\ttotal: 2.13s\tremaining: 1.14s\n",
      "325:\tlearn: 0.0742378\ttotal: 2.13s\tremaining: 1.14s\n",
      "326:\tlearn: 0.0739909\ttotal: 2.13s\tremaining: 1.13s\n",
      "327:\tlearn: 0.0736555\ttotal: 2.14s\tremaining: 1.12s\n",
      "328:\tlearn: 0.0732402\ttotal: 2.15s\tremaining: 1.12s\n",
      "329:\tlearn: 0.0728748\ttotal: 2.16s\tremaining: 1.11s\n",
      "330:\tlearn: 0.0725676\ttotal: 2.17s\tremaining: 1.11s\n",
      "331:\tlearn: 0.0722297\ttotal: 2.18s\tremaining: 1.1s\n",
      "332:\tlearn: 0.0718782\ttotal: 2.19s\tremaining: 1.1s\n",
      "333:\tlearn: 0.0715062\ttotal: 2.2s\tremaining: 1.09s\n",
      "334:\tlearn: 0.0712721\ttotal: 2.21s\tremaining: 1.09s\n",
      "335:\tlearn: 0.0709002\ttotal: 2.21s\tremaining: 1.08s\n",
      "336:\tlearn: 0.0705202\ttotal: 2.22s\tremaining: 1.07s\n",
      "337:\tlearn: 0.0701761\ttotal: 2.22s\tremaining: 1.06s\n",
      "338:\tlearn: 0.0698620\ttotal: 2.23s\tremaining: 1.06s\n",
      "339:\tlearn: 0.0694447\ttotal: 2.23s\tremaining: 1.05s\n",
      "340:\tlearn: 0.0690605\ttotal: 2.24s\tremaining: 1.04s\n",
      "341:\tlearn: 0.0687002\ttotal: 2.24s\tremaining: 1.03s\n",
      "342:\tlearn: 0.0683443\ttotal: 2.25s\tremaining: 1.03s\n",
      "343:\tlearn: 0.0678490\ttotal: 2.25s\tremaining: 1.02s\n",
      "344:\tlearn: 0.0674595\ttotal: 2.25s\tremaining: 1.01s\n",
      "345:\tlearn: 0.0669195\ttotal: 2.26s\tremaining: 1s\n",
      "346:\tlearn: 0.0665809\ttotal: 2.26s\tremaining: 998ms\n",
      "347:\tlearn: 0.0662404\ttotal: 2.27s\tremaining: 991ms\n",
      "348:\tlearn: 0.0657913\ttotal: 2.27s\tremaining: 983ms\n",
      "349:\tlearn: 0.0655411\ttotal: 2.28s\tremaining: 976ms\n",
      "350:\tlearn: 0.0652389\ttotal: 2.28s\tremaining: 968ms\n",
      "351:\tlearn: 0.0646434\ttotal: 2.29s\tremaining: 962ms\n",
      "352:\tlearn: 0.0644017\ttotal: 2.3s\tremaining: 957ms\n",
      "353:\tlearn: 0.0640711\ttotal: 2.31s\tremaining: 952ms\n",
      "354:\tlearn: 0.0637899\ttotal: 2.32s\tremaining: 947ms\n",
      "355:\tlearn: 0.0635475\ttotal: 2.33s\tremaining: 941ms\n",
      "356:\tlearn: 0.0631364\ttotal: 2.34s\tremaining: 936ms\n",
      "357:\tlearn: 0.0628330\ttotal: 2.35s\tremaining: 931ms\n",
      "358:\tlearn: 0.0625033\ttotal: 2.36s\tremaining: 926ms\n",
      "359:\tlearn: 0.0622288\ttotal: 2.37s\tremaining: 920ms\n",
      "360:\tlearn: 0.0619676\ttotal: 2.37s\tremaining: 914ms\n",
      "361:\tlearn: 0.0616603\ttotal: 2.38s\tremaining: 907ms\n",
      "362:\tlearn: 0.0614757\ttotal: 2.38s\tremaining: 900ms\n",
      "363:\tlearn: 0.0613091\ttotal: 2.39s\tremaining: 894ms\n",
      "364:\tlearn: 0.0610093\ttotal: 2.4s\tremaining: 887ms\n",
      "365:\tlearn: 0.0605116\ttotal: 2.4s\tremaining: 879ms\n",
      "366:\tlearn: 0.0602214\ttotal: 2.41s\tremaining: 872ms\n",
      "367:\tlearn: 0.0599714\ttotal: 2.41s\tremaining: 865ms\n",
      "368:\tlearn: 0.0597220\ttotal: 2.42s\tremaining: 858ms\n",
      "369:\tlearn: 0.0594611\ttotal: 2.42s\tremaining: 850ms\n",
      "370:\tlearn: 0.0591723\ttotal: 2.42s\tremaining: 843ms\n",
      "371:\tlearn: 0.0589321\ttotal: 2.43s\tremaining: 836ms\n",
      "372:\tlearn: 0.0587024\ttotal: 2.43s\tremaining: 829ms\n",
      "373:\tlearn: 0.0584178\ttotal: 2.44s\tremaining: 821ms\n",
      "374:\tlearn: 0.0581626\ttotal: 2.44s\tremaining: 814ms\n",
      "375:\tlearn: 0.0578342\ttotal: 2.45s\tremaining: 807ms\n",
      "376:\tlearn: 0.0574974\ttotal: 2.45s\tremaining: 800ms\n",
      "377:\tlearn: 0.0572319\ttotal: 2.46s\tremaining: 793ms\n",
      "378:\tlearn: 0.0568647\ttotal: 2.46s\tremaining: 787ms\n",
      "379:\tlearn: 0.0565929\ttotal: 2.48s\tremaining: 782ms\n",
      "380:\tlearn: 0.0563722\ttotal: 2.48s\tremaining: 776ms\n",
      "381:\tlearn: 0.0561624\ttotal: 2.49s\tremaining: 771ms\n",
      "382:\tlearn: 0.0559351\ttotal: 2.5s\tremaining: 765ms\n",
      "383:\tlearn: 0.0556186\ttotal: 2.51s\tremaining: 759ms\n",
      "384:\tlearn: 0.0554391\ttotal: 2.52s\tremaining: 754ms\n",
      "385:\tlearn: 0.0551441\ttotal: 2.53s\tremaining: 748ms\n",
      "386:\tlearn: 0.0549941\ttotal: 2.54s\tremaining: 742ms\n",
      "387:\tlearn: 0.0547807\ttotal: 2.55s\tremaining: 735ms\n",
      "388:\tlearn: 0.0545768\ttotal: 2.55s\tremaining: 728ms\n",
      "389:\tlearn: 0.0543245\ttotal: 2.56s\tremaining: 722ms\n",
      "390:\tlearn: 0.0541096\ttotal: 2.56s\tremaining: 715ms\n",
      "391:\tlearn: 0.0538555\ttotal: 2.57s\tremaining: 708ms\n",
      "392:\tlearn: 0.0536387\ttotal: 2.57s\tremaining: 701ms\n",
      "393:\tlearn: 0.0533971\ttotal: 2.58s\tremaining: 694ms\n",
      "394:\tlearn: 0.0531694\ttotal: 2.58s\tremaining: 687ms\n",
      "395:\tlearn: 0.0530681\ttotal: 2.59s\tremaining: 680ms\n",
      "396:\tlearn: 0.0528700\ttotal: 2.59s\tremaining: 673ms\n",
      "397:\tlearn: 0.0526443\ttotal: 2.6s\tremaining: 666ms\n",
      "398:\tlearn: 0.0523735\ttotal: 2.6s\tremaining: 659ms\n",
      "399:\tlearn: 0.0522229\ttotal: 2.6s\tremaining: 651ms\n",
      "400:\tlearn: 0.0520974\ttotal: 2.61s\tremaining: 644ms\n",
      "401:\tlearn: 0.0518336\ttotal: 2.61s\tremaining: 637ms\n",
      "402:\tlearn: 0.0514345\ttotal: 2.62s\tremaining: 630ms\n",
      "403:\tlearn: 0.0511979\ttotal: 2.62s\tremaining: 623ms\n",
      "404:\tlearn: 0.0510159\ttotal: 2.63s\tremaining: 616ms\n",
      "405:\tlearn: 0.0508040\ttotal: 2.64s\tremaining: 610ms\n",
      "406:\tlearn: 0.0504551\ttotal: 2.65s\tremaining: 605ms\n",
      "407:\tlearn: 0.0502469\ttotal: 2.66s\tremaining: 599ms\n",
      "408:\tlearn: 0.0500969\ttotal: 2.67s\tremaining: 593ms\n",
      "409:\tlearn: 0.0497921\ttotal: 2.67s\tremaining: 587ms\n",
      "410:\tlearn: 0.0494972\ttotal: 2.69s\tremaining: 581ms\n",
      "411:\tlearn: 0.0493518\ttotal: 2.69s\tremaining: 576ms\n",
      "412:\tlearn: 0.0491792\ttotal: 2.7s\tremaining: 569ms\n",
      "413:\tlearn: 0.0489811\ttotal: 2.71s\tremaining: 562ms\n",
      "414:\tlearn: 0.0486808\ttotal: 2.71s\tremaining: 555ms\n",
      "415:\tlearn: 0.0484728\ttotal: 2.71s\tremaining: 548ms\n",
      "416:\tlearn: 0.0482476\ttotal: 2.72s\tremaining: 542ms\n",
      "417:\tlearn: 0.0480485\ttotal: 2.73s\tremaining: 535ms\n",
      "418:\tlearn: 0.0478191\ttotal: 2.73s\tremaining: 528ms\n",
      "419:\tlearn: 0.0476630\ttotal: 2.73s\tremaining: 521ms\n",
      "420:\tlearn: 0.0474706\ttotal: 2.74s\tremaining: 514ms\n",
      "421:\tlearn: 0.0473534\ttotal: 2.74s\tremaining: 507ms\n",
      "422:\tlearn: 0.0471704\ttotal: 2.75s\tremaining: 500ms\n",
      "423:\tlearn: 0.0469505\ttotal: 2.75s\tremaining: 493ms\n",
      "424:\tlearn: 0.0467222\ttotal: 2.76s\tremaining: 486ms\n",
      "425:\tlearn: 0.0464999\ttotal: 2.76s\tremaining: 479ms\n",
      "426:\tlearn: 0.0463969\ttotal: 2.77s\tremaining: 474ms\n",
      "427:\tlearn: 0.0461426\ttotal: 2.78s\tremaining: 468ms\n",
      "428:\tlearn: 0.0459154\ttotal: 2.79s\tremaining: 462ms\n",
      "429:\tlearn: 0.0457112\ttotal: 2.8s\tremaining: 456ms\n",
      "430:\tlearn: 0.0455944\ttotal: 2.81s\tremaining: 450ms\n",
      "431:\tlearn: 0.0454300\ttotal: 2.82s\tremaining: 444ms\n",
      "432:\tlearn: 0.0452669\ttotal: 2.83s\tremaining: 438ms\n",
      "433:\tlearn: 0.0448854\ttotal: 2.84s\tremaining: 432ms\n",
      "434:\tlearn: 0.0446896\ttotal: 2.85s\tremaining: 425ms\n",
      "435:\tlearn: 0.0443171\ttotal: 2.85s\tremaining: 419ms\n",
      "436:\tlearn: 0.0441846\ttotal: 2.86s\tremaining: 412ms\n",
      "437:\tlearn: 0.0440059\ttotal: 2.87s\tremaining: 406ms\n",
      "438:\tlearn: 0.0438058\ttotal: 2.87s\tremaining: 399ms\n",
      "439:\tlearn: 0.0435889\ttotal: 2.88s\tremaining: 392ms\n",
      "440:\tlearn: 0.0433930\ttotal: 2.88s\tremaining: 386ms\n",
      "441:\tlearn: 0.0432031\ttotal: 2.89s\tremaining: 379ms\n",
      "442:\tlearn: 0.0429802\ttotal: 2.89s\tremaining: 372ms\n",
      "443:\tlearn: 0.0427784\ttotal: 2.9s\tremaining: 365ms\n",
      "444:\tlearn: 0.0426367\ttotal: 2.9s\tremaining: 358ms\n",
      "445:\tlearn: 0.0424540\ttotal: 2.9s\tremaining: 352ms\n",
      "446:\tlearn: 0.0422940\ttotal: 2.91s\tremaining: 345ms\n",
      "447:\tlearn: 0.0421152\ttotal: 2.91s\tremaining: 338ms\n",
      "448:\tlearn: 0.0417228\ttotal: 2.92s\tremaining: 331ms\n",
      "449:\tlearn: 0.0415371\ttotal: 2.92s\tremaining: 325ms\n",
      "450:\tlearn: 0.0413297\ttotal: 2.92s\tremaining: 318ms\n",
      "451:\tlearn: 0.0411452\ttotal: 2.93s\tremaining: 311ms\n",
      "452:\tlearn: 0.0409636\ttotal: 2.93s\tremaining: 304ms\n",
      "453:\tlearn: 0.0407451\ttotal: 2.94s\tremaining: 298ms\n",
      "454:\tlearn: 0.0405578\ttotal: 2.94s\tremaining: 291ms\n",
      "455:\tlearn: 0.0403864\ttotal: 2.95s\tremaining: 285ms\n",
      "456:\tlearn: 0.0402336\ttotal: 2.96s\tremaining: 279ms\n",
      "457:\tlearn: 0.0400673\ttotal: 2.97s\tremaining: 273ms\n",
      "458:\tlearn: 0.0398849\ttotal: 2.98s\tremaining: 266ms\n",
      "459:\tlearn: 0.0396975\ttotal: 2.99s\tremaining: 260ms\n",
      "460:\tlearn: 0.0394503\ttotal: 3s\tremaining: 254ms\n",
      "461:\tlearn: 0.0392639\ttotal: 3.01s\tremaining: 248ms\n",
      "462:\tlearn: 0.0391536\ttotal: 3.02s\tremaining: 241ms\n",
      "463:\tlearn: 0.0389820\ttotal: 3.02s\tremaining: 235ms\n",
      "464:\tlearn: 0.0389699\ttotal: 3.03s\tremaining: 228ms\n",
      "465:\tlearn: 0.0387648\ttotal: 3.04s\tremaining: 222ms\n",
      "466:\tlearn: 0.0386000\ttotal: 3.05s\tremaining: 215ms\n",
      "467:\tlearn: 0.0383963\ttotal: 3.05s\tremaining: 209ms\n",
      "468:\tlearn: 0.0381680\ttotal: 3.05s\tremaining: 202ms\n",
      "469:\tlearn: 0.0380232\ttotal: 3.06s\tremaining: 195ms\n",
      "470:\tlearn: 0.0378466\ttotal: 3.06s\tremaining: 189ms\n",
      "471:\tlearn: 0.0376174\ttotal: 3.07s\tremaining: 182ms\n",
      "472:\tlearn: 0.0374344\ttotal: 3.07s\tremaining: 175ms\n",
      "473:\tlearn: 0.0373526\ttotal: 3.08s\tremaining: 169ms\n",
      "474:\tlearn: 0.0371810\ttotal: 3.08s\tremaining: 162ms\n",
      "475:\tlearn: 0.0370805\ttotal: 3.08s\tremaining: 156ms\n",
      "476:\tlearn: 0.0369330\ttotal: 3.09s\tremaining: 149ms\n",
      "477:\tlearn: 0.0367654\ttotal: 3.1s\tremaining: 143ms\n",
      "478:\tlearn: 0.0366005\ttotal: 3.1s\tremaining: 136ms\n",
      "479:\tlearn: 0.0364593\ttotal: 3.11s\tremaining: 130ms\n",
      "480:\tlearn: 0.0363746\ttotal: 3.12s\tremaining: 123ms\n",
      "481:\tlearn: 0.0361773\ttotal: 3.13s\tremaining: 117ms\n",
      "482:\tlearn: 0.0359888\ttotal: 3.14s\tremaining: 111ms\n",
      "483:\tlearn: 0.0357424\ttotal: 3.15s\tremaining: 104ms\n",
      "484:\tlearn: 0.0355586\ttotal: 3.16s\tremaining: 97.7ms\n",
      "485:\tlearn: 0.0354554\ttotal: 3.17s\tremaining: 91.3ms\n",
      "486:\tlearn: 0.0352997\ttotal: 3.18s\tremaining: 84.9ms\n",
      "487:\tlearn: 0.0352079\ttotal: 3.19s\tremaining: 78.4ms\n",
      "488:\tlearn: 0.0350840\ttotal: 3.19s\tremaining: 71.9ms\n",
      "489:\tlearn: 0.0349394\ttotal: 3.2s\tremaining: 65.3ms\n",
      "490:\tlearn: 0.0347876\ttotal: 3.21s\tremaining: 58.8ms\n",
      "491:\tlearn: 0.0346266\ttotal: 3.21s\tremaining: 52.2ms\n",
      "492:\tlearn: 0.0344376\ttotal: 3.22s\tremaining: 45.7ms\n",
      "493:\tlearn: 0.0342660\ttotal: 3.23s\tremaining: 39.2ms\n",
      "494:\tlearn: 0.0341402\ttotal: 3.23s\tremaining: 32.6ms\n",
      "495:\tlearn: 0.0340067\ttotal: 3.24s\tremaining: 26.1ms\n",
      "496:\tlearn: 0.0338462\ttotal: 3.24s\tremaining: 19.6ms\n",
      "497:\tlearn: 0.0337029\ttotal: 3.25s\tremaining: 13ms\n",
      "498:\tlearn: 0.0335664\ttotal: 3.25s\tremaining: 6.52ms\n",
      "499:\tlearn: 0.0334129\ttotal: 3.26s\tremaining: 0us\n",
      "0:\tlearn: 0.6829559\ttotal: 4.93ms\tremaining: 2.46s\n",
      "1:\tlearn: 0.6716890\ttotal: 9.46ms\tremaining: 2.36s\n",
      "2:\tlearn: 0.6594387\ttotal: 13.8ms\tremaining: 2.28s\n",
      "3:\tlearn: 0.6475306\ttotal: 18.1ms\tremaining: 2.25s\n",
      "4:\tlearn: 0.6390020\ttotal: 22.7ms\tremaining: 2.25s\n",
      "5:\tlearn: 0.6306270\ttotal: 27.2ms\tremaining: 2.24s\n",
      "6:\tlearn: 0.6195168\ttotal: 32.1ms\tremaining: 2.26s\n",
      "7:\tlearn: 0.6097581\ttotal: 42ms\tremaining: 2.58s\n",
      "8:\tlearn: 0.6045060\ttotal: 51.6ms\tremaining: 2.81s\n",
      "9:\tlearn: 0.5993394\ttotal: 61.4ms\tremaining: 3.01s\n",
      "10:\tlearn: 0.5930097\ttotal: 70.9ms\tremaining: 3.15s\n",
      "11:\tlearn: 0.5850126\ttotal: 80.3ms\tremaining: 3.27s\n",
      "12:\tlearn: 0.5747632\ttotal: 89.9ms\tremaining: 3.37s\n",
      "13:\tlearn: 0.5669456\ttotal: 99.2ms\tremaining: 3.44s\n",
      "14:\tlearn: 0.5620951\ttotal: 109ms\tremaining: 3.52s\n",
      "15:\tlearn: 0.5554446\ttotal: 118ms\tremaining: 3.58s\n",
      "16:\tlearn: 0.5515128\ttotal: 125ms\tremaining: 3.55s\n",
      "17:\tlearn: 0.5437253\ttotal: 131ms\tremaining: 3.51s\n",
      "18:\tlearn: 0.5393971\ttotal: 137ms\tremaining: 3.48s\n",
      "19:\tlearn: 0.5342103\ttotal: 143ms\tremaining: 3.44s\n",
      "20:\tlearn: 0.5292480\ttotal: 149ms\tremaining: 3.4s\n",
      "21:\tlearn: 0.5238913\ttotal: 154ms\tremaining: 3.34s\n",
      "22:\tlearn: 0.5189085\ttotal: 158ms\tremaining: 3.28s\n",
      "23:\tlearn: 0.5152614\ttotal: 163ms\tremaining: 3.23s\n",
      "24:\tlearn: 0.5112530\ttotal: 168ms\tremaining: 3.19s\n",
      "25:\tlearn: 0.5054727\ttotal: 173ms\tremaining: 3.15s\n",
      "26:\tlearn: 0.5002998\ttotal: 177ms\tremaining: 3.09s\n",
      "27:\tlearn: 0.4949638\ttotal: 180ms\tremaining: 3.04s\n",
      "28:\tlearn: 0.4895357\ttotal: 184ms\tremaining: 3s\n",
      "29:\tlearn: 0.4848361\ttotal: 189ms\tremaining: 2.96s\n",
      "30:\tlearn: 0.4775119\ttotal: 193ms\tremaining: 2.92s\n",
      "31:\tlearn: 0.4733099\ttotal: 197ms\tremaining: 2.89s\n",
      "32:\tlearn: 0.4697202\ttotal: 202ms\tremaining: 2.86s\n",
      "33:\tlearn: 0.4651319\ttotal: 206ms\tremaining: 2.83s\n",
      "34:\tlearn: 0.4617201\ttotal: 216ms\tremaining: 2.87s\n",
      "35:\tlearn: 0.4560354\ttotal: 226ms\tremaining: 2.91s\n",
      "36:\tlearn: 0.4517951\ttotal: 236ms\tremaining: 2.95s\n",
      "37:\tlearn: 0.4479651\ttotal: 245ms\tremaining: 2.98s\n",
      "38:\tlearn: 0.4444089\ttotal: 255ms\tremaining: 3.02s\n",
      "39:\tlearn: 0.4397324\ttotal: 265ms\tremaining: 3.05s\n",
      "40:\tlearn: 0.4347820\ttotal: 275ms\tremaining: 3.07s\n",
      "41:\tlearn: 0.4317196\ttotal: 284ms\tremaining: 3.1s\n",
      "42:\tlearn: 0.4290790\ttotal: 291ms\tremaining: 3.09s\n",
      "43:\tlearn: 0.4235423\ttotal: 297ms\tremaining: 3.08s\n",
      "44:\tlearn: 0.4212398\ttotal: 304ms\tremaining: 3.07s\n",
      "45:\tlearn: 0.4156923\ttotal: 310ms\tremaining: 3.05s\n",
      "46:\tlearn: 0.4098756\ttotal: 316ms\tremaining: 3.04s\n",
      "47:\tlearn: 0.4073486\ttotal: 321ms\tremaining: 3.02s\n",
      "48:\tlearn: 0.4036170\ttotal: 325ms\tremaining: 2.99s\n",
      "49:\tlearn: 0.3970651\ttotal: 330ms\tremaining: 2.97s\n",
      "50:\tlearn: 0.3928856\ttotal: 335ms\tremaining: 2.95s\n",
      "51:\tlearn: 0.3896513\ttotal: 339ms\tremaining: 2.92s\n",
      "52:\tlearn: 0.3861387\ttotal: 344ms\tremaining: 2.9s\n",
      "53:\tlearn: 0.3827502\ttotal: 348ms\tremaining: 2.88s\n",
      "54:\tlearn: 0.3802071\ttotal: 352ms\tremaining: 2.85s\n",
      "55:\tlearn: 0.3774085\ttotal: 356ms\tremaining: 2.82s\n",
      "56:\tlearn: 0.3744468\ttotal: 360ms\tremaining: 2.8s\n",
      "57:\tlearn: 0.3724257\ttotal: 364ms\tremaining: 2.78s\n",
      "58:\tlearn: 0.3706215\ttotal: 368ms\tremaining: 2.75s\n",
      "59:\tlearn: 0.3689617\ttotal: 372ms\tremaining: 2.73s\n",
      "60:\tlearn: 0.3667672\ttotal: 376ms\tremaining: 2.71s\n",
      "61:\tlearn: 0.3628493\ttotal: 386ms\tremaining: 2.73s\n",
      "62:\tlearn: 0.3611498\ttotal: 396ms\tremaining: 2.75s\n",
      "63:\tlearn: 0.3590314\ttotal: 406ms\tremaining: 2.76s\n",
      "64:\tlearn: 0.3566967\ttotal: 415ms\tremaining: 2.78s\n",
      "65:\tlearn: 0.3546805\ttotal: 425ms\tremaining: 2.79s\n",
      "66:\tlearn: 0.3495152\ttotal: 435ms\tremaining: 2.81s\n",
      "67:\tlearn: 0.3453801\ttotal: 444ms\tremaining: 2.82s\n",
      "68:\tlearn: 0.3427542\ttotal: 454ms\tremaining: 2.83s\n",
      "69:\tlearn: 0.3409352\ttotal: 462ms\tremaining: 2.83s\n",
      "70:\tlearn: 0.3371073\ttotal: 468ms\tremaining: 2.83s\n",
      "71:\tlearn: 0.3354979\ttotal: 474ms\tremaining: 2.82s\n",
      "72:\tlearn: 0.3334634\ttotal: 480ms\tremaining: 2.81s\n",
      "73:\tlearn: 0.3314191\ttotal: 487ms\tremaining: 2.8s\n",
      "74:\tlearn: 0.3290999\ttotal: 492ms\tremaining: 2.79s\n",
      "75:\tlearn: 0.3265595\ttotal: 497ms\tremaining: 2.77s\n",
      "76:\tlearn: 0.3246493\ttotal: 501ms\tremaining: 2.75s\n",
      "77:\tlearn: 0.3224852\ttotal: 506ms\tremaining: 2.74s\n",
      "78:\tlearn: 0.3202141\ttotal: 511ms\tremaining: 2.72s\n",
      "79:\tlearn: 0.3179683\ttotal: 515ms\tremaining: 2.71s\n",
      "80:\tlearn: 0.3139411\ttotal: 520ms\tremaining: 2.69s\n",
      "81:\tlearn: 0.3117015\ttotal: 524ms\tremaining: 2.67s\n",
      "82:\tlearn: 0.3093389\ttotal: 528ms\tremaining: 2.65s\n",
      "83:\tlearn: 0.3064276\ttotal: 532ms\tremaining: 2.64s\n",
      "84:\tlearn: 0.3038516\ttotal: 537ms\tremaining: 2.62s\n",
      "85:\tlearn: 0.3019760\ttotal: 541ms\tremaining: 2.6s\n",
      "86:\tlearn: 0.3000883\ttotal: 545ms\tremaining: 2.58s\n",
      "87:\tlearn: 0.2981896\ttotal: 548ms\tremaining: 2.57s\n",
      "88:\tlearn: 0.2959624\ttotal: 558ms\tremaining: 2.58s\n",
      "89:\tlearn: 0.2939464\ttotal: 568ms\tremaining: 2.58s\n",
      "90:\tlearn: 0.2920095\ttotal: 577ms\tremaining: 2.59s\n",
      "91:\tlearn: 0.2894185\ttotal: 587ms\tremaining: 2.6s\n",
      "92:\tlearn: 0.2874640\ttotal: 597ms\tremaining: 2.61s\n",
      "93:\tlearn: 0.2841959\ttotal: 606ms\tremaining: 2.62s\n",
      "94:\tlearn: 0.2822860\ttotal: 617ms\tremaining: 2.63s\n",
      "95:\tlearn: 0.2804639\ttotal: 626ms\tremaining: 2.63s\n",
      "96:\tlearn: 0.2789264\ttotal: 635ms\tremaining: 2.64s\n",
      "97:\tlearn: 0.2771666\ttotal: 642ms\tremaining: 2.63s\n",
      "98:\tlearn: 0.2751441\ttotal: 648ms\tremaining: 2.62s\n",
      "99:\tlearn: 0.2736884\ttotal: 654ms\tremaining: 2.61s\n",
      "100:\tlearn: 0.2718354\ttotal: 660ms\tremaining: 2.61s\n",
      "101:\tlearn: 0.2696089\ttotal: 666ms\tremaining: 2.6s\n",
      "102:\tlearn: 0.2675769\ttotal: 672ms\tremaining: 2.59s\n",
      "103:\tlearn: 0.2659228\ttotal: 681ms\tremaining: 2.59s\n",
      "104:\tlearn: 0.2642911\ttotal: 686ms\tremaining: 2.58s\n",
      "105:\tlearn: 0.2628574\ttotal: 692ms\tremaining: 2.57s\n",
      "106:\tlearn: 0.2612918\ttotal: 697ms\tremaining: 2.56s\n",
      "107:\tlearn: 0.2597715\ttotal: 702ms\tremaining: 2.55s\n",
      "108:\tlearn: 0.2583611\ttotal: 707ms\tremaining: 2.53s\n",
      "109:\tlearn: 0.2567366\ttotal: 711ms\tremaining: 2.52s\n",
      "110:\tlearn: 0.2548413\ttotal: 715ms\tremaining: 2.5s\n",
      "111:\tlearn: 0.2534365\ttotal: 719ms\tremaining: 2.49s\n",
      "112:\tlearn: 0.2517431\ttotal: 724ms\tremaining: 2.48s\n",
      "113:\tlearn: 0.2503996\ttotal: 727ms\tremaining: 2.46s\n",
      "114:\tlearn: 0.2488470\ttotal: 732ms\tremaining: 2.45s\n",
      "115:\tlearn: 0.2475916\ttotal: 736ms\tremaining: 2.44s\n",
      "116:\tlearn: 0.2459719\ttotal: 740ms\tremaining: 2.42s\n",
      "117:\tlearn: 0.2444774\ttotal: 750ms\tremaining: 2.43s\n",
      "118:\tlearn: 0.2425986\ttotal: 759ms\tremaining: 2.43s\n",
      "119:\tlearn: 0.2398245\ttotal: 769ms\tremaining: 2.44s\n",
      "120:\tlearn: 0.2381867\ttotal: 779ms\tremaining: 2.44s\n",
      "121:\tlearn: 0.2365591\ttotal: 789ms\tremaining: 2.44s\n",
      "122:\tlearn: 0.2350496\ttotal: 798ms\tremaining: 2.45s\n",
      "123:\tlearn: 0.2338670\ttotal: 808ms\tremaining: 2.45s\n",
      "124:\tlearn: 0.2326102\ttotal: 818ms\tremaining: 2.45s\n",
      "125:\tlearn: 0.2311887\ttotal: 827ms\tremaining: 2.46s\n",
      "126:\tlearn: 0.2293708\ttotal: 837ms\tremaining: 2.46s\n",
      "127:\tlearn: 0.2280737\ttotal: 844ms\tremaining: 2.45s\n",
      "128:\tlearn: 0.2268196\ttotal: 850ms\tremaining: 2.44s\n",
      "129:\tlearn: 0.2253689\ttotal: 855ms\tremaining: 2.43s\n",
      "130:\tlearn: 0.2243041\ttotal: 861ms\tremaining: 2.42s\n",
      "131:\tlearn: 0.2230316\ttotal: 866ms\tremaining: 2.42s\n",
      "132:\tlearn: 0.2218415\ttotal: 871ms\tremaining: 2.4s\n",
      "133:\tlearn: 0.2206701\ttotal: 876ms\tremaining: 2.39s\n",
      "134:\tlearn: 0.2188203\ttotal: 881ms\tremaining: 2.38s\n",
      "135:\tlearn: 0.2175914\ttotal: 885ms\tremaining: 2.37s\n",
      "136:\tlearn: 0.2161580\ttotal: 889ms\tremaining: 2.35s\n",
      "137:\tlearn: 0.2138957\ttotal: 894ms\tremaining: 2.34s\n",
      "138:\tlearn: 0.2124811\ttotal: 898ms\tremaining: 2.33s\n",
      "139:\tlearn: 0.2113370\ttotal: 902ms\tremaining: 2.32s\n",
      "140:\tlearn: 0.2093202\ttotal: 906ms\tremaining: 2.31s\n",
      "141:\tlearn: 0.2083092\ttotal: 910ms\tremaining: 2.29s\n",
      "142:\tlearn: 0.2071960\ttotal: 915ms\tremaining: 2.28s\n",
      "143:\tlearn: 0.2058671\ttotal: 925ms\tremaining: 2.29s\n",
      "144:\tlearn: 0.2043098\ttotal: 935ms\tremaining: 2.29s\n",
      "145:\tlearn: 0.2026556\ttotal: 944ms\tremaining: 2.29s\n",
      "146:\tlearn: 0.2010436\ttotal: 954ms\tremaining: 2.29s\n",
      "147:\tlearn: 0.2000601\ttotal: 964ms\tremaining: 2.29s\n",
      "148:\tlearn: 0.1988903\ttotal: 974ms\tremaining: 2.29s\n",
      "149:\tlearn: 0.1979706\ttotal: 983ms\tremaining: 2.29s\n",
      "150:\tlearn: 0.1968390\ttotal: 993ms\tremaining: 2.29s\n",
      "151:\tlearn: 0.1958400\ttotal: 1s\tremaining: 2.29s\n",
      "152:\tlearn: 0.1947798\ttotal: 1.01s\tremaining: 2.28s\n",
      "153:\tlearn: 0.1935858\ttotal: 1.01s\tremaining: 2.28s\n",
      "154:\tlearn: 0.1925121\ttotal: 1.02s\tremaining: 2.27s\n",
      "155:\tlearn: 0.1916591\ttotal: 1.03s\tremaining: 2.26s\n",
      "156:\tlearn: 0.1906049\ttotal: 1.03s\tremaining: 2.25s\n",
      "157:\tlearn: 0.1883682\ttotal: 1.04s\tremaining: 2.25s\n",
      "158:\tlearn: 0.1873496\ttotal: 1.04s\tremaining: 2.24s\n",
      "159:\tlearn: 0.1852076\ttotal: 1.05s\tremaining: 2.24s\n",
      "160:\tlearn: 0.1840157\ttotal: 1.06s\tremaining: 2.23s\n",
      "161:\tlearn: 0.1829733\ttotal: 1.06s\tremaining: 2.21s\n",
      "162:\tlearn: 0.1818785\ttotal: 1.06s\tremaining: 2.2s\n",
      "163:\tlearn: 0.1806991\ttotal: 1.07s\tremaining: 2.19s\n",
      "164:\tlearn: 0.1786722\ttotal: 1.07s\tremaining: 2.18s\n",
      "165:\tlearn: 0.1777141\ttotal: 1.08s\tremaining: 2.17s\n",
      "166:\tlearn: 0.1768020\ttotal: 1.08s\tremaining: 2.16s\n",
      "167:\tlearn: 0.1744976\ttotal: 1.09s\tremaining: 2.15s\n",
      "168:\tlearn: 0.1736491\ttotal: 1.09s\tremaining: 2.14s\n",
      "169:\tlearn: 0.1728604\ttotal: 1.09s\tremaining: 2.13s\n",
      "170:\tlearn: 0.1709310\ttotal: 1.1s\tremaining: 2.12s\n",
      "171:\tlearn: 0.1696438\ttotal: 1.1s\tremaining: 2.11s\n",
      "172:\tlearn: 0.1685351\ttotal: 1.11s\tremaining: 2.1s\n",
      "173:\tlearn: 0.1676217\ttotal: 1.11s\tremaining: 2.09s\n",
      "174:\tlearn: 0.1667035\ttotal: 1.12s\tremaining: 2.08s\n",
      "175:\tlearn: 0.1656435\ttotal: 1.13s\tremaining: 2.08s\n",
      "176:\tlearn: 0.1646784\ttotal: 1.14s\tremaining: 2.08s\n",
      "177:\tlearn: 0.1633478\ttotal: 1.15s\tremaining: 2.08s\n",
      "178:\tlearn: 0.1625036\ttotal: 1.16s\tremaining: 2.08s\n",
      "179:\tlearn: 0.1613648\ttotal: 1.17s\tremaining: 2.08s\n",
      "180:\tlearn: 0.1604186\ttotal: 1.18s\tremaining: 2.08s\n",
      "181:\tlearn: 0.1596486\ttotal: 1.19s\tremaining: 2.08s\n",
      "182:\tlearn: 0.1588977\ttotal: 1.2s\tremaining: 2.08s\n",
      "183:\tlearn: 0.1578893\ttotal: 1.21s\tremaining: 2.07s\n",
      "184:\tlearn: 0.1564497\ttotal: 1.21s\tremaining: 2.07s\n",
      "185:\tlearn: 0.1557038\ttotal: 1.22s\tremaining: 2.06s\n",
      "186:\tlearn: 0.1548583\ttotal: 1.23s\tremaining: 2.05s\n",
      "187:\tlearn: 0.1538334\ttotal: 1.23s\tremaining: 2.04s\n",
      "188:\tlearn: 0.1531652\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.1521263\ttotal: 1.25s\tremaining: 2.03s\n",
      "190:\tlearn: 0.1512474\ttotal: 1.25s\tremaining: 2.02s\n",
      "191:\tlearn: 0.1506334\ttotal: 1.25s\tremaining: 2.01s\n",
      "192:\tlearn: 0.1497137\ttotal: 1.26s\tremaining: 2s\n",
      "193:\tlearn: 0.1489432\ttotal: 1.26s\tremaining: 2s\n",
      "194:\tlearn: 0.1481211\ttotal: 1.27s\tremaining: 1.98s\n",
      "195:\tlearn: 0.1474058\ttotal: 1.27s\tremaining: 1.97s\n",
      "196:\tlearn: 0.1468142\ttotal: 1.28s\tremaining: 1.96s\n",
      "197:\tlearn: 0.1459400\ttotal: 1.28s\tremaining: 1.95s\n",
      "198:\tlearn: 0.1448032\ttotal: 1.29s\tremaining: 1.95s\n",
      "199:\tlearn: 0.1440241\ttotal: 1.3s\tremaining: 1.95s\n",
      "200:\tlearn: 0.1432861\ttotal: 1.31s\tremaining: 1.95s\n",
      "201:\tlearn: 0.1424448\ttotal: 1.32s\tremaining: 1.95s\n",
      "202:\tlearn: 0.1416350\ttotal: 1.33s\tremaining: 1.94s\n",
      "203:\tlearn: 0.1409112\ttotal: 1.34s\tremaining: 1.94s\n",
      "204:\tlearn: 0.1401228\ttotal: 1.35s\tremaining: 1.94s\n",
      "205:\tlearn: 0.1394592\ttotal: 1.36s\tremaining: 1.94s\n",
      "206:\tlearn: 0.1387349\ttotal: 1.37s\tremaining: 1.94s\n",
      "207:\tlearn: 0.1382140\ttotal: 1.37s\tremaining: 1.93s\n",
      "208:\tlearn: 0.1374220\ttotal: 1.38s\tremaining: 1.92s\n",
      "209:\tlearn: 0.1366955\ttotal: 1.39s\tremaining: 1.91s\n",
      "210:\tlearn: 0.1354277\ttotal: 1.39s\tremaining: 1.91s\n",
      "211:\tlearn: 0.1347886\ttotal: 1.4s\tremaining: 1.9s\n",
      "212:\tlearn: 0.1338752\ttotal: 1.4s\tremaining: 1.89s\n",
      "213:\tlearn: 0.1325601\ttotal: 1.41s\tremaining: 1.88s\n",
      "214:\tlearn: 0.1317927\ttotal: 1.41s\tremaining: 1.87s\n",
      "215:\tlearn: 0.1309737\ttotal: 1.42s\tremaining: 1.86s\n",
      "216:\tlearn: 0.1302630\ttotal: 1.42s\tremaining: 1.85s\n",
      "217:\tlearn: 0.1294832\ttotal: 1.43s\tremaining: 1.84s\n",
      "218:\tlearn: 0.1288632\ttotal: 1.43s\tremaining: 1.84s\n",
      "219:\tlearn: 0.1282676\ttotal: 1.44s\tremaining: 1.83s\n",
      "220:\tlearn: 0.1275399\ttotal: 1.44s\tremaining: 1.82s\n",
      "221:\tlearn: 0.1268744\ttotal: 1.44s\tremaining: 1.81s\n",
      "222:\tlearn: 0.1264317\ttotal: 1.45s\tremaining: 1.8s\n",
      "223:\tlearn: 0.1258399\ttotal: 1.45s\tremaining: 1.79s\n",
      "224:\tlearn: 0.1252867\ttotal: 1.46s\tremaining: 1.78s\n",
      "225:\tlearn: 0.1244877\ttotal: 1.47s\tremaining: 1.78s\n",
      "226:\tlearn: 0.1238026\ttotal: 1.48s\tremaining: 1.78s\n",
      "227:\tlearn: 0.1232779\ttotal: 1.49s\tremaining: 1.77s\n",
      "228:\tlearn: 0.1226226\ttotal: 1.5s\tremaining: 1.77s\n",
      "229:\tlearn: 0.1220304\ttotal: 1.51s\tremaining: 1.77s\n",
      "230:\tlearn: 0.1214276\ttotal: 1.52s\tremaining: 1.76s\n",
      "231:\tlearn: 0.1202511\ttotal: 1.53s\tremaining: 1.76s\n",
      "232:\tlearn: 0.1195644\ttotal: 1.53s\tremaining: 1.76s\n",
      "233:\tlearn: 0.1189983\ttotal: 1.54s\tremaining: 1.75s\n",
      "234:\tlearn: 0.1183244\ttotal: 1.55s\tremaining: 1.75s\n",
      "235:\tlearn: 0.1175363\ttotal: 1.56s\tremaining: 1.74s\n",
      "236:\tlearn: 0.1168130\ttotal: 1.56s\tremaining: 1.73s\n",
      "237:\tlearn: 0.1161562\ttotal: 1.57s\tremaining: 1.73s\n",
      "238:\tlearn: 0.1155379\ttotal: 1.57s\tremaining: 1.72s\n",
      "239:\tlearn: 0.1149051\ttotal: 1.58s\tremaining: 1.71s\n",
      "240:\tlearn: 0.1142669\ttotal: 1.58s\tremaining: 1.7s\n",
      "241:\tlearn: 0.1134945\ttotal: 1.59s\tremaining: 1.69s\n",
      "242:\tlearn: 0.1128445\ttotal: 1.59s\tremaining: 1.69s\n",
      "243:\tlearn: 0.1123866\ttotal: 1.6s\tremaining: 1.68s\n",
      "244:\tlearn: 0.1118679\ttotal: 1.6s\tremaining: 1.67s\n",
      "245:\tlearn: 0.1111550\ttotal: 1.61s\tremaining: 1.66s\n",
      "246:\tlearn: 0.1106062\ttotal: 1.61s\tremaining: 1.65s\n",
      "247:\tlearn: 0.1100148\ttotal: 1.62s\tremaining: 1.64s\n",
      "248:\tlearn: 0.1092545\ttotal: 1.62s\tremaining: 1.63s\n",
      "249:\tlearn: 0.1086568\ttotal: 1.63s\tremaining: 1.63s\n",
      "250:\tlearn: 0.1082142\ttotal: 1.64s\tremaining: 1.62s\n",
      "251:\tlearn: 0.1076961\ttotal: 1.65s\tremaining: 1.62s\n",
      "252:\tlearn: 0.1070766\ttotal: 1.66s\tremaining: 1.61s\n",
      "253:\tlearn: 0.1065498\ttotal: 1.67s\tremaining: 1.61s\n",
      "254:\tlearn: 0.1060490\ttotal: 1.67s\tremaining: 1.61s\n",
      "255:\tlearn: 0.1056018\ttotal: 1.68s\tremaining: 1.6s\n",
      "256:\tlearn: 0.1047557\ttotal: 1.69s\tremaining: 1.6s\n",
      "257:\tlearn: 0.1042531\ttotal: 1.7s\tremaining: 1.6s\n",
      "258:\tlearn: 0.1037823\ttotal: 1.71s\tremaining: 1.59s\n",
      "259:\tlearn: 0.1032458\ttotal: 1.72s\tremaining: 1.59s\n",
      "260:\tlearn: 0.1027449\ttotal: 1.73s\tremaining: 1.58s\n",
      "261:\tlearn: 0.1021542\ttotal: 1.73s\tremaining: 1.57s\n",
      "262:\tlearn: 0.1017366\ttotal: 1.74s\tremaining: 1.57s\n",
      "263:\tlearn: 0.1011768\ttotal: 1.75s\tremaining: 1.56s\n",
      "264:\tlearn: 0.1001744\ttotal: 1.75s\tremaining: 1.55s\n",
      "265:\tlearn: 0.0996975\ttotal: 1.75s\tremaining: 1.54s\n",
      "266:\tlearn: 0.0992922\ttotal: 1.76s\tremaining: 1.53s\n",
      "267:\tlearn: 0.0987114\ttotal: 1.76s\tremaining: 1.53s\n",
      "268:\tlearn: 0.0982397\ttotal: 1.77s\tremaining: 1.52s\n",
      "269:\tlearn: 0.0977864\ttotal: 1.77s\tremaining: 1.51s\n",
      "270:\tlearn: 0.0973140\ttotal: 1.78s\tremaining: 1.5s\n",
      "271:\tlearn: 0.0968752\ttotal: 1.78s\tremaining: 1.49s\n",
      "272:\tlearn: 0.0958944\ttotal: 1.79s\tremaining: 1.49s\n",
      "273:\tlearn: 0.0955489\ttotal: 1.79s\tremaining: 1.48s\n",
      "274:\tlearn: 0.0946862\ttotal: 1.8s\tremaining: 1.47s\n",
      "275:\tlearn: 0.0942476\ttotal: 1.8s\tremaining: 1.46s\n",
      "276:\tlearn: 0.0938153\ttotal: 1.8s\tremaining: 1.45s\n",
      "277:\tlearn: 0.0934164\ttotal: 1.82s\tremaining: 1.45s\n",
      "278:\tlearn: 0.0929059\ttotal: 1.83s\tremaining: 1.45s\n",
      "279:\tlearn: 0.0922844\ttotal: 1.84s\tremaining: 1.44s\n",
      "280:\tlearn: 0.0916991\ttotal: 1.85s\tremaining: 1.44s\n",
      "281:\tlearn: 0.0911646\ttotal: 1.86s\tremaining: 1.44s\n",
      "282:\tlearn: 0.0906237\ttotal: 1.87s\tremaining: 1.43s\n",
      "283:\tlearn: 0.0901719\ttotal: 1.88s\tremaining: 1.43s\n",
      "284:\tlearn: 0.0897437\ttotal: 1.89s\tremaining: 1.42s\n",
      "285:\tlearn: 0.0892567\ttotal: 1.89s\tremaining: 1.42s\n",
      "286:\tlearn: 0.0887825\ttotal: 1.9s\tremaining: 1.41s\n",
      "287:\tlearn: 0.0883474\ttotal: 1.91s\tremaining: 1.4s\n",
      "288:\tlearn: 0.0879047\ttotal: 1.91s\tremaining: 1.4s\n",
      "289:\tlearn: 0.0875655\ttotal: 1.92s\tremaining: 1.39s\n",
      "290:\tlearn: 0.0870534\ttotal: 1.92s\tremaining: 1.38s\n",
      "291:\tlearn: 0.0866517\ttotal: 1.93s\tremaining: 1.37s\n",
      "292:\tlearn: 0.0861682\ttotal: 1.93s\tremaining: 1.36s\n",
      "293:\tlearn: 0.0857549\ttotal: 1.94s\tremaining: 1.36s\n",
      "294:\tlearn: 0.0850000\ttotal: 1.94s\tremaining: 1.35s\n",
      "295:\tlearn: 0.0845777\ttotal: 1.95s\tremaining: 1.34s\n",
      "296:\tlearn: 0.0841652\ttotal: 1.95s\tremaining: 1.33s\n",
      "297:\tlearn: 0.0837458\ttotal: 1.96s\tremaining: 1.33s\n",
      "298:\tlearn: 0.0832771\ttotal: 1.96s\tremaining: 1.32s\n",
      "299:\tlearn: 0.0825737\ttotal: 1.97s\tremaining: 1.31s\n",
      "300:\tlearn: 0.0822344\ttotal: 1.97s\tremaining: 1.3s\n",
      "301:\tlearn: 0.0816419\ttotal: 1.98s\tremaining: 1.3s\n",
      "302:\tlearn: 0.0812295\ttotal: 1.98s\tremaining: 1.29s\n",
      "303:\tlearn: 0.0808422\ttotal: 1.99s\tremaining: 1.28s\n",
      "304:\tlearn: 0.0805836\ttotal: 1.99s\tremaining: 1.27s\n",
      "305:\tlearn: 0.0801374\ttotal: 2s\tremaining: 1.26s\n",
      "306:\tlearn: 0.0798386\ttotal: 2s\tremaining: 1.26s\n",
      "307:\tlearn: 0.0795441\ttotal: 2s\tremaining: 1.25s\n",
      "308:\tlearn: 0.0791127\ttotal: 2.01s\tremaining: 1.24s\n",
      "309:\tlearn: 0.0786207\ttotal: 2.01s\tremaining: 1.23s\n",
      "310:\tlearn: 0.0782506\ttotal: 2.02s\tremaining: 1.23s\n",
      "311:\tlearn: 0.0779413\ttotal: 2.03s\tremaining: 1.22s\n",
      "312:\tlearn: 0.0776575\ttotal: 2.04s\tremaining: 1.22s\n",
      "313:\tlearn: 0.0772511\ttotal: 2.05s\tremaining: 1.21s\n",
      "314:\tlearn: 0.0768696\ttotal: 2.06s\tremaining: 1.21s\n",
      "315:\tlearn: 0.0764769\ttotal: 2.07s\tremaining: 1.2s\n",
      "316:\tlearn: 0.0760901\ttotal: 2.08s\tremaining: 1.2s\n",
      "317:\tlearn: 0.0757120\ttotal: 2.08s\tremaining: 1.19s\n",
      "318:\tlearn: 0.0754745\ttotal: 2.1s\tremaining: 1.19s\n",
      "319:\tlearn: 0.0751020\ttotal: 2.1s\tremaining: 1.18s\n",
      "320:\tlearn: 0.0748258\ttotal: 2.11s\tremaining: 1.18s\n",
      "321:\tlearn: 0.0744492\ttotal: 2.12s\tremaining: 1.17s\n",
      "322:\tlearn: 0.0739517\ttotal: 2.13s\tremaining: 1.16s\n",
      "323:\tlearn: 0.0735895\ttotal: 2.13s\tremaining: 1.16s\n",
      "324:\tlearn: 0.0733484\ttotal: 2.14s\tremaining: 1.15s\n",
      "325:\tlearn: 0.0729775\ttotal: 2.14s\tremaining: 1.14s\n",
      "326:\tlearn: 0.0726715\ttotal: 2.15s\tremaining: 1.14s\n",
      "327:\tlearn: 0.0723642\ttotal: 2.16s\tremaining: 1.13s\n",
      "328:\tlearn: 0.0720294\ttotal: 2.16s\tremaining: 1.12s\n",
      "329:\tlearn: 0.0717224\ttotal: 2.17s\tremaining: 1.12s\n",
      "330:\tlearn: 0.0714930\ttotal: 2.17s\tremaining: 1.11s\n",
      "331:\tlearn: 0.0711584\ttotal: 2.18s\tremaining: 1.1s\n",
      "332:\tlearn: 0.0708179\ttotal: 2.18s\tremaining: 1.09s\n",
      "333:\tlearn: 0.0704174\ttotal: 2.19s\tremaining: 1.09s\n",
      "334:\tlearn: 0.0701306\ttotal: 2.19s\tremaining: 1.08s\n",
      "335:\tlearn: 0.0696558\ttotal: 2.19s\tremaining: 1.07s\n",
      "336:\tlearn: 0.0692350\ttotal: 2.2s\tremaining: 1.06s\n",
      "337:\tlearn: 0.0689064\ttotal: 2.2s\tremaining: 1.06s\n",
      "338:\tlearn: 0.0685859\ttotal: 2.21s\tremaining: 1.05s\n",
      "339:\tlearn: 0.0682500\ttotal: 2.21s\tremaining: 1.04s\n",
      "340:\tlearn: 0.0678964\ttotal: 2.22s\tremaining: 1.03s\n",
      "341:\tlearn: 0.0675782\ttotal: 2.22s\tremaining: 1.03s\n",
      "342:\tlearn: 0.0673164\ttotal: 2.23s\tremaining: 1.02s\n",
      "343:\tlearn: 0.0669027\ttotal: 2.23s\tremaining: 1.01s\n",
      "344:\tlearn: 0.0666825\ttotal: 2.25s\tremaining: 1.01s\n",
      "345:\tlearn: 0.0664008\ttotal: 2.25s\tremaining: 1s\n",
      "346:\tlearn: 0.0660762\ttotal: 2.26s\tremaining: 999ms\n",
      "347:\tlearn: 0.0654960\ttotal: 2.27s\tremaining: 994ms\n",
      "348:\tlearn: 0.0652383\ttotal: 2.28s\tremaining: 988ms\n",
      "349:\tlearn: 0.0649134\ttotal: 2.29s\tremaining: 983ms\n",
      "350:\tlearn: 0.0646253\ttotal: 2.3s\tremaining: 978ms\n",
      "351:\tlearn: 0.0642976\ttotal: 2.31s\tremaining: 973ms\n",
      "352:\tlearn: 0.0640189\ttotal: 2.32s\tremaining: 966ms\n",
      "353:\tlearn: 0.0637306\ttotal: 2.33s\tremaining: 959ms\n",
      "354:\tlearn: 0.0634280\ttotal: 2.33s\tremaining: 952ms\n",
      "355:\tlearn: 0.0631181\ttotal: 2.34s\tremaining: 946ms\n",
      "356:\tlearn: 0.0627996\ttotal: 2.34s\tremaining: 939ms\n",
      "357:\tlearn: 0.0623484\ttotal: 2.35s\tremaining: 932ms\n",
      "358:\tlearn: 0.0620446\ttotal: 2.35s\tremaining: 925ms\n",
      "359:\tlearn: 0.0617583\ttotal: 2.36s\tremaining: 917ms\n",
      "360:\tlearn: 0.0614487\ttotal: 2.36s\tremaining: 909ms\n",
      "361:\tlearn: 0.0609984\ttotal: 2.37s\tremaining: 902ms\n",
      "362:\tlearn: 0.0606847\ttotal: 2.37s\tremaining: 895ms\n",
      "363:\tlearn: 0.0603953\ttotal: 2.37s\tremaining: 887ms\n",
      "364:\tlearn: 0.0601469\ttotal: 2.38s\tremaining: 880ms\n",
      "365:\tlearn: 0.0598571\ttotal: 2.38s\tremaining: 873ms\n",
      "366:\tlearn: 0.0595514\ttotal: 2.39s\tremaining: 865ms\n",
      "367:\tlearn: 0.0592352\ttotal: 2.39s\tremaining: 858ms\n",
      "368:\tlearn: 0.0590039\ttotal: 2.4s\tremaining: 852ms\n",
      "369:\tlearn: 0.0587497\ttotal: 2.41s\tremaining: 847ms\n",
      "370:\tlearn: 0.0584158\ttotal: 2.42s\tremaining: 842ms\n",
      "371:\tlearn: 0.0580636\ttotal: 2.43s\tremaining: 836ms\n",
      "372:\tlearn: 0.0577897\ttotal: 2.44s\tremaining: 831ms\n",
      "373:\tlearn: 0.0575332\ttotal: 2.45s\tremaining: 825ms\n",
      "374:\tlearn: 0.0573188\ttotal: 2.46s\tremaining: 820ms\n",
      "375:\tlearn: 0.0570359\ttotal: 2.47s\tremaining: 814ms\n",
      "376:\tlearn: 0.0567767\ttotal: 2.48s\tremaining: 809ms\n",
      "377:\tlearn: 0.0564932\ttotal: 2.49s\tremaining: 803ms\n",
      "378:\tlearn: 0.0561572\ttotal: 2.5s\tremaining: 797ms\n",
      "379:\tlearn: 0.0559235\ttotal: 2.5s\tremaining: 790ms\n",
      "380:\tlearn: 0.0556612\ttotal: 2.51s\tremaining: 783ms\n",
      "381:\tlearn: 0.0554033\ttotal: 2.51s\tremaining: 776ms\n",
      "382:\tlearn: 0.0551998\ttotal: 2.52s\tremaining: 768ms\n",
      "383:\tlearn: 0.0550605\ttotal: 2.52s\tremaining: 761ms\n",
      "384:\tlearn: 0.0548398\ttotal: 2.52s\tremaining: 754ms\n",
      "385:\tlearn: 0.0547069\ttotal: 2.53s\tremaining: 747ms\n",
      "386:\tlearn: 0.0544231\ttotal: 2.53s\tremaining: 740ms\n",
      "387:\tlearn: 0.0542058\ttotal: 2.54s\tremaining: 733ms\n",
      "388:\tlearn: 0.0539535\ttotal: 2.54s\tremaining: 726ms\n",
      "389:\tlearn: 0.0537363\ttotal: 2.55s\tremaining: 719ms\n",
      "390:\tlearn: 0.0535178\ttotal: 2.55s\tremaining: 711ms\n",
      "391:\tlearn: 0.0533249\ttotal: 2.56s\tremaining: 704ms\n",
      "392:\tlearn: 0.0530950\ttotal: 2.56s\tremaining: 697ms\n",
      "393:\tlearn: 0.0529232\ttotal: 2.57s\tremaining: 691ms\n",
      "394:\tlearn: 0.0526256\ttotal: 2.58s\tremaining: 685ms\n",
      "395:\tlearn: 0.0522788\ttotal: 2.59s\tremaining: 679ms\n",
      "396:\tlearn: 0.0519274\ttotal: 2.6s\tremaining: 674ms\n",
      "397:\tlearn: 0.0516232\ttotal: 2.61s\tremaining: 668ms\n",
      "398:\tlearn: 0.0513454\ttotal: 2.62s\tremaining: 662ms\n",
      "399:\tlearn: 0.0511586\ttotal: 2.63s\tremaining: 657ms\n",
      "400:\tlearn: 0.0507491\ttotal: 2.64s\tremaining: 651ms\n",
      "401:\tlearn: 0.0505252\ttotal: 2.65s\tremaining: 645ms\n",
      "402:\tlearn: 0.0501101\ttotal: 2.65s\tremaining: 638ms\n",
      "403:\tlearn: 0.0499037\ttotal: 2.66s\tremaining: 632ms\n",
      "404:\tlearn: 0.0497483\ttotal: 2.67s\tremaining: 625ms\n",
      "405:\tlearn: 0.0495677\ttotal: 2.67s\tremaining: 618ms\n",
      "406:\tlearn: 0.0492119\ttotal: 2.68s\tremaining: 612ms\n",
      "407:\tlearn: 0.0490065\ttotal: 2.68s\tremaining: 605ms\n",
      "408:\tlearn: 0.0487624\ttotal: 2.69s\tremaining: 598ms\n",
      "409:\tlearn: 0.0485775\ttotal: 2.69s\tremaining: 591ms\n",
      "410:\tlearn: 0.0484088\ttotal: 2.69s\tremaining: 584ms\n",
      "411:\tlearn: 0.0481315\ttotal: 2.7s\tremaining: 577ms\n",
      "412:\tlearn: 0.0479297\ttotal: 2.71s\tremaining: 570ms\n",
      "413:\tlearn: 0.0476675\ttotal: 2.71s\tremaining: 563ms\n",
      "414:\tlearn: 0.0474900\ttotal: 2.71s\tremaining: 556ms\n",
      "415:\tlearn: 0.0472684\ttotal: 2.72s\tremaining: 549ms\n",
      "416:\tlearn: 0.0470363\ttotal: 2.72s\tremaining: 542ms\n",
      "417:\tlearn: 0.0467957\ttotal: 2.73s\tremaining: 535ms\n",
      "418:\tlearn: 0.0465825\ttotal: 2.73s\tremaining: 528ms\n",
      "419:\tlearn: 0.0464486\ttotal: 2.74s\tremaining: 521ms\n",
      "420:\tlearn: 0.0462078\ttotal: 2.75s\tremaining: 515ms\n",
      "421:\tlearn: 0.0459521\ttotal: 2.75s\tremaining: 509ms\n",
      "422:\tlearn: 0.0456985\ttotal: 2.77s\tremaining: 503ms\n",
      "423:\tlearn: 0.0455152\ttotal: 2.77s\tremaining: 497ms\n",
      "424:\tlearn: 0.0452489\ttotal: 2.79s\tremaining: 492ms\n",
      "425:\tlearn: 0.0450251\ttotal: 2.79s\tremaining: 486ms\n",
      "426:\tlearn: 0.0448238\ttotal: 2.81s\tremaining: 480ms\n",
      "427:\tlearn: 0.0446086\ttotal: 2.81s\tremaining: 474ms\n",
      "428:\tlearn: 0.0443617\ttotal: 2.82s\tremaining: 467ms\n",
      "429:\tlearn: 0.0441954\ttotal: 2.83s\tremaining: 461ms\n",
      "430:\tlearn: 0.0438971\ttotal: 2.84s\tremaining: 454ms\n",
      "431:\tlearn: 0.0437061\ttotal: 2.84s\tremaining: 447ms\n",
      "432:\tlearn: 0.0435237\ttotal: 2.85s\tremaining: 441ms\n",
      "433:\tlearn: 0.0433895\ttotal: 2.85s\tremaining: 434ms\n",
      "434:\tlearn: 0.0432016\ttotal: 2.86s\tremaining: 427ms\n",
      "435:\tlearn: 0.0430180\ttotal: 2.86s\tremaining: 420ms\n",
      "436:\tlearn: 0.0428550\ttotal: 2.87s\tremaining: 413ms\n",
      "437:\tlearn: 0.0426885\ttotal: 2.87s\tremaining: 407ms\n",
      "438:\tlearn: 0.0425650\ttotal: 2.88s\tremaining: 400ms\n",
      "439:\tlearn: 0.0423822\ttotal: 2.88s\tremaining: 393ms\n",
      "440:\tlearn: 0.0421350\ttotal: 2.88s\tremaining: 386ms\n",
      "441:\tlearn: 0.0419767\ttotal: 2.89s\tremaining: 379ms\n",
      "442:\tlearn: 0.0418107\ttotal: 2.89s\tremaining: 372ms\n",
      "443:\tlearn: 0.0416635\ttotal: 2.9s\tremaining: 366ms\n",
      "444:\tlearn: 0.0414605\ttotal: 2.9s\tremaining: 359ms\n",
      "445:\tlearn: 0.0412525\ttotal: 2.91s\tremaining: 352ms\n",
      "446:\tlearn: 0.0409515\ttotal: 2.92s\tremaining: 346ms\n",
      "447:\tlearn: 0.0407046\ttotal: 2.93s\tremaining: 340ms\n",
      "448:\tlearn: 0.0405186\ttotal: 2.94s\tremaining: 334ms\n",
      "449:\tlearn: 0.0403631\ttotal: 2.95s\tremaining: 328ms\n",
      "450:\tlearn: 0.0399564\ttotal: 2.96s\tremaining: 322ms\n",
      "451:\tlearn: 0.0398005\ttotal: 2.97s\tremaining: 315ms\n",
      "452:\tlearn: 0.0396210\ttotal: 2.98s\tremaining: 309ms\n",
      "453:\tlearn: 0.0394841\ttotal: 2.99s\tremaining: 303ms\n",
      "454:\tlearn: 0.0392780\ttotal: 3s\tremaining: 297ms\n",
      "455:\tlearn: 0.0390838\ttotal: 3s\tremaining: 290ms\n",
      "456:\tlearn: 0.0387222\ttotal: 3.01s\tremaining: 283ms\n",
      "457:\tlearn: 0.0385737\ttotal: 3.02s\tremaining: 277ms\n",
      "458:\tlearn: 0.0384040\ttotal: 3.02s\tremaining: 270ms\n",
      "459:\tlearn: 0.0382570\ttotal: 3.03s\tremaining: 263ms\n",
      "460:\tlearn: 0.0380813\ttotal: 3.03s\tremaining: 257ms\n",
      "461:\tlearn: 0.0378669\ttotal: 3.04s\tremaining: 250ms\n",
      "462:\tlearn: 0.0377192\ttotal: 3.04s\tremaining: 243ms\n",
      "463:\tlearn: 0.0374838\ttotal: 3.05s\tremaining: 237ms\n",
      "464:\tlearn: 0.0373247\ttotal: 3.05s\tremaining: 230ms\n",
      "465:\tlearn: 0.0371145\ttotal: 3.06s\tremaining: 223ms\n",
      "466:\tlearn: 0.0368956\ttotal: 3.06s\tremaining: 216ms\n",
      "467:\tlearn: 0.0366825\ttotal: 3.07s\tremaining: 210ms\n",
      "468:\tlearn: 0.0364985\ttotal: 3.07s\tremaining: 203ms\n",
      "469:\tlearn: 0.0363311\ttotal: 3.08s\tremaining: 196ms\n",
      "470:\tlearn: 0.0361778\ttotal: 3.08s\tremaining: 190ms\n",
      "471:\tlearn: 0.0360076\ttotal: 3.09s\tremaining: 184ms\n",
      "472:\tlearn: 0.0358578\ttotal: 3.1s\tremaining: 177ms\n",
      "473:\tlearn: 0.0356542\ttotal: 3.11s\tremaining: 171ms\n",
      "474:\tlearn: 0.0354907\ttotal: 3.12s\tremaining: 164ms\n",
      "475:\tlearn: 0.0353270\ttotal: 3.13s\tremaining: 158ms\n",
      "476:\tlearn: 0.0351765\ttotal: 3.14s\tremaining: 152ms\n",
      "477:\tlearn: 0.0350136\ttotal: 3.15s\tremaining: 145ms\n",
      "478:\tlearn: 0.0348437\ttotal: 3.16s\tremaining: 139ms\n",
      "479:\tlearn: 0.0347409\ttotal: 3.17s\tremaining: 132ms\n",
      "480:\tlearn: 0.0345093\ttotal: 3.17s\tremaining: 125ms\n",
      "481:\tlearn: 0.0343655\ttotal: 3.18s\tremaining: 119ms\n",
      "482:\tlearn: 0.0342118\ttotal: 3.19s\tremaining: 112ms\n",
      "483:\tlearn: 0.0340646\ttotal: 3.19s\tremaining: 106ms\n",
      "484:\tlearn: 0.0339082\ttotal: 3.2s\tremaining: 98.9ms\n",
      "485:\tlearn: 0.0336730\ttotal: 3.2s\tremaining: 92.2ms\n",
      "486:\tlearn: 0.0335014\ttotal: 3.21s\tremaining: 85.6ms\n",
      "487:\tlearn: 0.0333960\ttotal: 3.21s\tremaining: 78.9ms\n",
      "488:\tlearn: 0.0332561\ttotal: 3.21s\tremaining: 72.3ms\n",
      "489:\tlearn: 0.0330725\ttotal: 3.22s\tremaining: 65.7ms\n",
      "490:\tlearn: 0.0328475\ttotal: 3.22s\tremaining: 59.1ms\n",
      "491:\tlearn: 0.0327223\ttotal: 3.23s\tremaining: 52.5ms\n",
      "492:\tlearn: 0.0325652\ttotal: 3.23s\tremaining: 45.9ms\n",
      "493:\tlearn: 0.0324464\ttotal: 3.24s\tremaining: 39.3ms\n",
      "494:\tlearn: 0.0322410\ttotal: 3.24s\tremaining: 32.7ms\n",
      "495:\tlearn: 0.0320827\ttotal: 3.24s\tremaining: 26.2ms\n",
      "496:\tlearn: 0.0318990\ttotal: 3.25s\tremaining: 19.6ms\n",
      "497:\tlearn: 0.0317102\ttotal: 3.26s\tremaining: 13.1ms\n",
      "498:\tlearn: 0.0316053\ttotal: 3.27s\tremaining: 6.55ms\n",
      "499:\tlearn: 0.0314636\ttotal: 3.28s\tremaining: 0us\n",
      "0:\tlearn: 0.6810260\ttotal: 5.09ms\tremaining: 2.54s\n",
      "1:\tlearn: 0.6695622\ttotal: 9.96ms\tremaining: 2.48s\n",
      "2:\tlearn: 0.6577321\ttotal: 14.9ms\tremaining: 2.47s\n",
      "3:\tlearn: 0.6487102\ttotal: 19.5ms\tremaining: 2.42s\n",
      "4:\tlearn: 0.6372305\ttotal: 24.4ms\tremaining: 2.42s\n",
      "5:\tlearn: 0.6257648\ttotal: 28.7ms\tremaining: 2.36s\n",
      "6:\tlearn: 0.6171610\ttotal: 33.1ms\tremaining: 2.33s\n",
      "7:\tlearn: 0.6098153\ttotal: 37.5ms\tremaining: 2.31s\n",
      "8:\tlearn: 0.6007542\ttotal: 42.1ms\tremaining: 2.29s\n",
      "9:\tlearn: 0.5953701\ttotal: 46ms\tremaining: 2.25s\n",
      "10:\tlearn: 0.5845792\ttotal: 50.3ms\tremaining: 2.23s\n",
      "11:\tlearn: 0.5784981\ttotal: 54.5ms\tremaining: 2.22s\n",
      "12:\tlearn: 0.5714926\ttotal: 58.9ms\tremaining: 2.21s\n",
      "13:\tlearn: 0.5647411\ttotal: 63.4ms\tremaining: 2.2s\n",
      "14:\tlearn: 0.5554574\ttotal: 67.7ms\tremaining: 2.19s\n",
      "15:\tlearn: 0.5498111\ttotal: 71.6ms\tremaining: 2.17s\n",
      "16:\tlearn: 0.5431167\ttotal: 81.5ms\tremaining: 2.31s\n",
      "17:\tlearn: 0.5380335\ttotal: 91.2ms\tremaining: 2.44s\n",
      "18:\tlearn: 0.5333057\ttotal: 101ms\tremaining: 2.55s\n",
      "19:\tlearn: 0.5253913\ttotal: 110ms\tremaining: 2.65s\n",
      "20:\tlearn: 0.5195221\ttotal: 120ms\tremaining: 2.74s\n",
      "21:\tlearn: 0.5139244\ttotal: 130ms\tremaining: 2.82s\n",
      "22:\tlearn: 0.5089861\ttotal: 147ms\tremaining: 3.06s\n",
      "23:\tlearn: 0.5052340\ttotal: 158ms\tremaining: 3.13s\n",
      "24:\tlearn: 0.5011739\ttotal: 170ms\tremaining: 3.23s\n",
      "25:\tlearn: 0.4964793\ttotal: 181ms\tremaining: 3.3s\n",
      "26:\tlearn: 0.4911228\ttotal: 191ms\tremaining: 3.35s\n",
      "27:\tlearn: 0.4858363\ttotal: 201ms\tremaining: 3.38s\n",
      "28:\tlearn: 0.4825145\ttotal: 210ms\tremaining: 3.41s\n",
      "29:\tlearn: 0.4771610\ttotal: 220ms\tremaining: 3.45s\n",
      "30:\tlearn: 0.4737297\ttotal: 229ms\tremaining: 3.47s\n",
      "31:\tlearn: 0.4703680\ttotal: 239ms\tremaining: 3.49s\n",
      "32:\tlearn: 0.4653394\ttotal: 248ms\tremaining: 3.51s\n",
      "33:\tlearn: 0.4611197\ttotal: 257ms\tremaining: 3.53s\n",
      "34:\tlearn: 0.4581545\ttotal: 267ms\tremaining: 3.55s\n",
      "35:\tlearn: 0.4543599\ttotal: 272ms\tremaining: 3.5s\n",
      "36:\tlearn: 0.4501807\ttotal: 276ms\tremaining: 3.45s\n",
      "37:\tlearn: 0.4441487\ttotal: 280ms\tremaining: 3.41s\n",
      "38:\tlearn: 0.4389001\ttotal: 285ms\tremaining: 3.37s\n",
      "39:\tlearn: 0.4362587\ttotal: 289ms\tremaining: 3.32s\n",
      "40:\tlearn: 0.4328636\ttotal: 293ms\tremaining: 3.28s\n",
      "41:\tlearn: 0.4305264\ttotal: 298ms\tremaining: 3.25s\n",
      "42:\tlearn: 0.4275585\ttotal: 302ms\tremaining: 3.21s\n",
      "43:\tlearn: 0.4252188\ttotal: 306ms\tremaining: 3.17s\n",
      "44:\tlearn: 0.4198017\ttotal: 311ms\tremaining: 3.14s\n",
      "45:\tlearn: 0.4171911\ttotal: 315ms\tremaining: 3.11s\n",
      "46:\tlearn: 0.4147120\ttotal: 319ms\tremaining: 3.08s\n",
      "47:\tlearn: 0.4105597\ttotal: 324ms\tremaining: 3.05s\n",
      "48:\tlearn: 0.4081127\ttotal: 337ms\tremaining: 3.1s\n",
      "49:\tlearn: 0.4050550\ttotal: 346ms\tremaining: 3.12s\n",
      "50:\tlearn: 0.4009130\ttotal: 356ms\tremaining: 3.13s\n",
      "51:\tlearn: 0.3989047\ttotal: 365ms\tremaining: 3.15s\n",
      "52:\tlearn: 0.3961312\ttotal: 375ms\tremaining: 3.17s\n",
      "53:\tlearn: 0.3941431\ttotal: 385ms\tremaining: 3.18s\n",
      "54:\tlearn: 0.3917407\ttotal: 395ms\tremaining: 3.19s\n",
      "55:\tlearn: 0.3894067\ttotal: 404ms\tremaining: 3.2s\n",
      "56:\tlearn: 0.3873135\ttotal: 411ms\tremaining: 3.2s\n",
      "57:\tlearn: 0.3844402\ttotal: 415ms\tremaining: 3.16s\n",
      "58:\tlearn: 0.3810152\ttotal: 417ms\tremaining: 3.12s\n",
      "59:\tlearn: 0.3784431\ttotal: 419ms\tremaining: 3.07s\n",
      "60:\tlearn: 0.3756085\ttotal: 421ms\tremaining: 3.03s\n",
      "61:\tlearn: 0.3720696\ttotal: 423ms\tremaining: 2.99s\n",
      "62:\tlearn: 0.3696351\ttotal: 426ms\tremaining: 2.95s\n",
      "63:\tlearn: 0.3663976\ttotal: 428ms\tremaining: 2.92s\n",
      "64:\tlearn: 0.3634994\ttotal: 431ms\tremaining: 2.88s\n",
      "65:\tlearn: 0.3612268\ttotal: 435ms\tremaining: 2.86s\n",
      "66:\tlearn: 0.3562615\ttotal: 438ms\tremaining: 2.83s\n",
      "67:\tlearn: 0.3538979\ttotal: 448ms\tremaining: 2.85s\n",
      "68:\tlearn: 0.3519898\ttotal: 457ms\tremaining: 2.86s\n",
      "69:\tlearn: 0.3502085\ttotal: 467ms\tremaining: 2.87s\n",
      "70:\tlearn: 0.3477153\ttotal: 476ms\tremaining: 2.88s\n",
      "71:\tlearn: 0.3456874\ttotal: 486ms\tremaining: 2.89s\n",
      "72:\tlearn: 0.3440005\ttotal: 496ms\tremaining: 2.9s\n",
      "73:\tlearn: 0.3417385\ttotal: 506ms\tremaining: 2.91s\n",
      "74:\tlearn: 0.3392227\ttotal: 515ms\tremaining: 2.92s\n",
      "75:\tlearn: 0.3327873\ttotal: 523ms\tremaining: 2.92s\n",
      "76:\tlearn: 0.3293280\ttotal: 531ms\tremaining: 2.92s\n",
      "77:\tlearn: 0.3273013\ttotal: 537ms\tremaining: 2.91s\n",
      "78:\tlearn: 0.3248006\ttotal: 544ms\tremaining: 2.9s\n",
      "79:\tlearn: 0.3228394\ttotal: 548ms\tremaining: 2.88s\n",
      "80:\tlearn: 0.3203796\ttotal: 553ms\tremaining: 2.86s\n",
      "81:\tlearn: 0.3182322\ttotal: 557ms\tremaining: 2.84s\n",
      "82:\tlearn: 0.3147914\ttotal: 562ms\tremaining: 2.82s\n",
      "83:\tlearn: 0.3129067\ttotal: 567ms\tremaining: 2.81s\n",
      "84:\tlearn: 0.3110373\ttotal: 572ms\tremaining: 2.79s\n",
      "85:\tlearn: 0.3088014\ttotal: 576ms\tremaining: 2.77s\n",
      "86:\tlearn: 0.3065748\ttotal: 581ms\tremaining: 2.76s\n",
      "87:\tlearn: 0.3044974\ttotal: 585ms\tremaining: 2.74s\n",
      "88:\tlearn: 0.3008126\ttotal: 589ms\tremaining: 2.72s\n",
      "89:\tlearn: 0.2988503\ttotal: 593ms\tremaining: 2.7s\n",
      "90:\tlearn: 0.2967475\ttotal: 597ms\tremaining: 2.69s\n",
      "91:\tlearn: 0.2928143\ttotal: 602ms\tremaining: 2.67s\n",
      "92:\tlearn: 0.2909726\ttotal: 606ms\tremaining: 2.65s\n",
      "93:\tlearn: 0.2888639\ttotal: 612ms\tremaining: 2.64s\n",
      "94:\tlearn: 0.2869029\ttotal: 622ms\tremaining: 2.65s\n",
      "95:\tlearn: 0.2845565\ttotal: 631ms\tremaining: 2.66s\n",
      "96:\tlearn: 0.2826067\ttotal: 641ms\tremaining: 2.66s\n",
      "97:\tlearn: 0.2804015\ttotal: 651ms\tremaining: 2.67s\n",
      "98:\tlearn: 0.2782486\ttotal: 660ms\tremaining: 2.67s\n",
      "99:\tlearn: 0.2764305\ttotal: 670ms\tremaining: 2.68s\n",
      "100:\tlearn: 0.2747616\ttotal: 680ms\tremaining: 2.68s\n",
      "101:\tlearn: 0.2731813\ttotal: 689ms\tremaining: 2.69s\n",
      "102:\tlearn: 0.2714403\ttotal: 699ms\tremaining: 2.69s\n",
      "103:\tlearn: 0.2681774\ttotal: 707ms\tremaining: 2.69s\n",
      "104:\tlearn: 0.2664405\ttotal: 714ms\tremaining: 2.69s\n",
      "105:\tlearn: 0.2649031\ttotal: 722ms\tremaining: 2.68s\n",
      "106:\tlearn: 0.2632697\ttotal: 727ms\tremaining: 2.67s\n",
      "107:\tlearn: 0.2613773\ttotal: 732ms\tremaining: 2.65s\n",
      "108:\tlearn: 0.2594887\ttotal: 736ms\tremaining: 2.64s\n",
      "109:\tlearn: 0.2574748\ttotal: 741ms\tremaining: 2.63s\n",
      "110:\tlearn: 0.2555181\ttotal: 746ms\tremaining: 2.61s\n",
      "111:\tlearn: 0.2538751\ttotal: 750ms\tremaining: 2.6s\n",
      "112:\tlearn: 0.2514765\ttotal: 754ms\tremaining: 2.58s\n",
      "113:\tlearn: 0.2492436\ttotal: 758ms\tremaining: 2.57s\n",
      "114:\tlearn: 0.2478296\ttotal: 762ms\tremaining: 2.55s\n",
      "115:\tlearn: 0.2462345\ttotal: 766ms\tremaining: 2.54s\n",
      "116:\tlearn: 0.2443190\ttotal: 771ms\tremaining: 2.52s\n",
      "117:\tlearn: 0.2424973\ttotal: 775ms\tremaining: 2.51s\n",
      "118:\tlearn: 0.2410273\ttotal: 779ms\tremaining: 2.5s\n",
      "119:\tlearn: 0.2394200\ttotal: 784ms\tremaining: 2.48s\n",
      "120:\tlearn: 0.2381986\ttotal: 794ms\tremaining: 2.49s\n",
      "121:\tlearn: 0.2368647\ttotal: 804ms\tremaining: 2.49s\n",
      "122:\tlearn: 0.2354804\ttotal: 814ms\tremaining: 2.49s\n",
      "123:\tlearn: 0.2322404\ttotal: 824ms\tremaining: 2.5s\n",
      "124:\tlearn: 0.2307482\ttotal: 834ms\tremaining: 2.5s\n",
      "125:\tlearn: 0.2292382\ttotal: 844ms\tremaining: 2.5s\n",
      "126:\tlearn: 0.2278129\ttotal: 854ms\tremaining: 2.51s\n",
      "127:\tlearn: 0.2263766\ttotal: 864ms\tremaining: 2.51s\n",
      "128:\tlearn: 0.2250875\ttotal: 873ms\tremaining: 2.51s\n",
      "129:\tlearn: 0.2236053\ttotal: 882ms\tremaining: 2.51s\n",
      "130:\tlearn: 0.2219633\ttotal: 889ms\tremaining: 2.5s\n",
      "131:\tlearn: 0.2207261\ttotal: 894ms\tremaining: 2.49s\n",
      "132:\tlearn: 0.2184726\ttotal: 900ms\tremaining: 2.48s\n",
      "133:\tlearn: 0.2170551\ttotal: 905ms\tremaining: 2.47s\n",
      "134:\tlearn: 0.2157611\ttotal: 910ms\tremaining: 2.46s\n",
      "135:\tlearn: 0.2142390\ttotal: 915ms\tremaining: 2.45s\n",
      "136:\tlearn: 0.2129933\ttotal: 920ms\tremaining: 2.44s\n",
      "137:\tlearn: 0.2119717\ttotal: 924ms\tremaining: 2.42s\n",
      "138:\tlearn: 0.2106204\ttotal: 929ms\tremaining: 2.41s\n",
      "139:\tlearn: 0.2086084\ttotal: 933ms\tremaining: 2.4s\n",
      "140:\tlearn: 0.2071951\ttotal: 938ms\tremaining: 2.39s\n",
      "141:\tlearn: 0.2061893\ttotal: 942ms\tremaining: 2.37s\n",
      "142:\tlearn: 0.2049829\ttotal: 946ms\tremaining: 2.36s\n",
      "143:\tlearn: 0.2039670\ttotal: 951ms\tremaining: 2.35s\n",
      "144:\tlearn: 0.2022667\ttotal: 955ms\tremaining: 2.34s\n",
      "145:\tlearn: 0.2008682\ttotal: 965ms\tremaining: 2.34s\n",
      "146:\tlearn: 0.1996043\ttotal: 975ms\tremaining: 2.34s\n",
      "147:\tlearn: 0.1984456\ttotal: 985ms\tremaining: 2.34s\n",
      "148:\tlearn: 0.1969464\ttotal: 994ms\tremaining: 2.34s\n",
      "149:\tlearn: 0.1952202\ttotal: 1s\tremaining: 2.34s\n",
      "150:\tlearn: 0.1941341\ttotal: 1.01s\tremaining: 2.34s\n",
      "151:\tlearn: 0.1931661\ttotal: 1.02s\tremaining: 2.34s\n",
      "152:\tlearn: 0.1914124\ttotal: 1.03s\tremaining: 2.35s\n",
      "153:\tlearn: 0.1899051\ttotal: 1.04s\tremaining: 2.35s\n",
      "154:\tlearn: 0.1888518\ttotal: 1.06s\tremaining: 2.35s\n",
      "155:\tlearn: 0.1876463\ttotal: 1.06s\tremaining: 2.35s\n",
      "156:\tlearn: 0.1864722\ttotal: 1.07s\tremaining: 2.35s\n",
      "157:\tlearn: 0.1853868\ttotal: 1.08s\tremaining: 2.33s\n",
      "158:\tlearn: 0.1834077\ttotal: 1.08s\tremaining: 2.32s\n",
      "159:\tlearn: 0.1822340\ttotal: 1.08s\tremaining: 2.31s\n",
      "160:\tlearn: 0.1813133\ttotal: 1.09s\tremaining: 2.29s\n",
      "161:\tlearn: 0.1800384\ttotal: 1.09s\tremaining: 2.28s\n",
      "162:\tlearn: 0.1792971\ttotal: 1.1s\tremaining: 2.27s\n",
      "163:\tlearn: 0.1774996\ttotal: 1.1s\tremaining: 2.26s\n",
      "164:\tlearn: 0.1761528\ttotal: 1.11s\tremaining: 2.25s\n",
      "165:\tlearn: 0.1749643\ttotal: 1.11s\tremaining: 2.23s\n",
      "166:\tlearn: 0.1740698\ttotal: 1.11s\tremaining: 2.22s\n",
      "167:\tlearn: 0.1729971\ttotal: 1.12s\tremaining: 2.21s\n",
      "168:\tlearn: 0.1718597\ttotal: 1.13s\tremaining: 2.21s\n",
      "169:\tlearn: 0.1700786\ttotal: 1.14s\tremaining: 2.21s\n",
      "170:\tlearn: 0.1687142\ttotal: 1.15s\tremaining: 2.21s\n",
      "171:\tlearn: 0.1678178\ttotal: 1.16s\tremaining: 2.21s\n",
      "172:\tlearn: 0.1670421\ttotal: 1.17s\tremaining: 2.21s\n",
      "173:\tlearn: 0.1661634\ttotal: 1.18s\tremaining: 2.21s\n",
      "174:\tlearn: 0.1651713\ttotal: 1.19s\tremaining: 2.21s\n",
      "175:\tlearn: 0.1641626\ttotal: 1.2s\tremaining: 2.2s\n",
      "176:\tlearn: 0.1633578\ttotal: 1.21s\tremaining: 2.2s\n",
      "177:\tlearn: 0.1624819\ttotal: 1.21s\tremaining: 2.19s\n",
      "178:\tlearn: 0.1616392\ttotal: 1.22s\tremaining: 2.19s\n",
      "179:\tlearn: 0.1607577\ttotal: 1.23s\tremaining: 2.18s\n",
      "180:\tlearn: 0.1599120\ttotal: 1.23s\tremaining: 2.17s\n",
      "181:\tlearn: 0.1590314\ttotal: 1.24s\tremaining: 2.16s\n",
      "182:\tlearn: 0.1581317\ttotal: 1.24s\tremaining: 2.15s\n",
      "183:\tlearn: 0.1572845\ttotal: 1.25s\tremaining: 2.14s\n",
      "184:\tlearn: 0.1565291\ttotal: 1.25s\tremaining: 2.13s\n",
      "185:\tlearn: 0.1558577\ttotal: 1.26s\tremaining: 2.13s\n",
      "186:\tlearn: 0.1550249\ttotal: 1.26s\tremaining: 2.12s\n",
      "187:\tlearn: 0.1542857\ttotal: 1.27s\tremaining: 2.1s\n",
      "188:\tlearn: 0.1533303\ttotal: 1.27s\tremaining: 2.09s\n",
      "189:\tlearn: 0.1524052\ttotal: 1.28s\tremaining: 2.08s\n",
      "190:\tlearn: 0.1505056\ttotal: 1.28s\tremaining: 2.07s\n",
      "191:\tlearn: 0.1494134\ttotal: 1.29s\tremaining: 2.06s\n",
      "192:\tlearn: 0.1486346\ttotal: 1.29s\tremaining: 2.05s\n",
      "193:\tlearn: 0.1476446\ttotal: 1.29s\tremaining: 2.04s\n",
      "194:\tlearn: 0.1466174\ttotal: 1.3s\tremaining: 2.04s\n",
      "195:\tlearn: 0.1458081\ttotal: 1.31s\tremaining: 2.04s\n",
      "196:\tlearn: 0.1451106\ttotal: 1.32s\tremaining: 2.04s\n",
      "197:\tlearn: 0.1444519\ttotal: 1.33s\tremaining: 2.04s\n",
      "198:\tlearn: 0.1426313\ttotal: 1.34s\tremaining: 2.03s\n",
      "199:\tlearn: 0.1419335\ttotal: 1.35s\tremaining: 2.03s\n",
      "200:\tlearn: 0.1409470\ttotal: 1.36s\tremaining: 2.03s\n",
      "201:\tlearn: 0.1400513\ttotal: 1.37s\tremaining: 2.03s\n",
      "202:\tlearn: 0.1392624\ttotal: 1.38s\tremaining: 2.02s\n",
      "203:\tlearn: 0.1387491\ttotal: 1.39s\tremaining: 2.01s\n",
      "204:\tlearn: 0.1377817\ttotal: 1.39s\tremaining: 2.01s\n",
      "205:\tlearn: 0.1368056\ttotal: 1.4s\tremaining: 2s\n",
      "206:\tlearn: 0.1359054\ttotal: 1.41s\tremaining: 1.99s\n",
      "207:\tlearn: 0.1351571\ttotal: 1.41s\tremaining: 1.98s\n",
      "208:\tlearn: 0.1345238\ttotal: 1.42s\tremaining: 1.97s\n",
      "209:\tlearn: 0.1338504\ttotal: 1.42s\tremaining: 1.97s\n",
      "210:\tlearn: 0.1334354\ttotal: 1.43s\tremaining: 1.96s\n",
      "211:\tlearn: 0.1327656\ttotal: 1.43s\tremaining: 1.95s\n",
      "212:\tlearn: 0.1321014\ttotal: 1.44s\tremaining: 1.94s\n",
      "213:\tlearn: 0.1314826\ttotal: 1.44s\tremaining: 1.93s\n",
      "214:\tlearn: 0.1308703\ttotal: 1.45s\tremaining: 1.92s\n",
      "215:\tlearn: 0.1302555\ttotal: 1.45s\tremaining: 1.91s\n",
      "216:\tlearn: 0.1293429\ttotal: 1.46s\tremaining: 1.9s\n",
      "217:\tlearn: 0.1286302\ttotal: 1.46s\tremaining: 1.89s\n",
      "218:\tlearn: 0.1278237\ttotal: 1.46s\tremaining: 1.88s\n",
      "219:\tlearn: 0.1272310\ttotal: 1.47s\tremaining: 1.86s\n",
      "220:\tlearn: 0.1265347\ttotal: 1.48s\tremaining: 1.86s\n",
      "221:\tlearn: 0.1257632\ttotal: 1.49s\tremaining: 1.86s\n",
      "222:\tlearn: 0.1251167\ttotal: 1.5s\tremaining: 1.86s\n",
      "223:\tlearn: 0.1245111\ttotal: 1.5s\tremaining: 1.85s\n",
      "224:\tlearn: 0.1237900\ttotal: 1.51s\tremaining: 1.85s\n",
      "225:\tlearn: 0.1232404\ttotal: 1.52s\tremaining: 1.85s\n",
      "226:\tlearn: 0.1224237\ttotal: 1.53s\tremaining: 1.85s\n",
      "227:\tlearn: 0.1218007\ttotal: 1.55s\tremaining: 1.84s\n",
      "228:\tlearn: 0.1212421\ttotal: 1.55s\tremaining: 1.84s\n",
      "229:\tlearn: 0.1205549\ttotal: 1.56s\tremaining: 1.83s\n",
      "230:\tlearn: 0.1200127\ttotal: 1.57s\tremaining: 1.82s\n",
      "231:\tlearn: 0.1193725\ttotal: 1.57s\tremaining: 1.82s\n",
      "232:\tlearn: 0.1187326\ttotal: 1.58s\tremaining: 1.81s\n",
      "233:\tlearn: 0.1179116\ttotal: 1.58s\tremaining: 1.8s\n",
      "234:\tlearn: 0.1166709\ttotal: 1.59s\tremaining: 1.79s\n",
      "235:\tlearn: 0.1159465\ttotal: 1.6s\tremaining: 1.79s\n",
      "236:\tlearn: 0.1153164\ttotal: 1.6s\tremaining: 1.78s\n",
      "237:\tlearn: 0.1148414\ttotal: 1.61s\tremaining: 1.77s\n",
      "238:\tlearn: 0.1141744\ttotal: 1.61s\tremaining: 1.76s\n",
      "239:\tlearn: 0.1135749\ttotal: 1.62s\tremaining: 1.75s\n",
      "240:\tlearn: 0.1129270\ttotal: 1.62s\tremaining: 1.74s\n",
      "241:\tlearn: 0.1122742\ttotal: 1.63s\tremaining: 1.73s\n",
      "242:\tlearn: 0.1117541\ttotal: 1.63s\tremaining: 1.72s\n",
      "243:\tlearn: 0.1111959\ttotal: 1.63s\tremaining: 1.71s\n",
      "244:\tlearn: 0.1106377\ttotal: 1.64s\tremaining: 1.7s\n",
      "245:\tlearn: 0.1101792\ttotal: 1.64s\tremaining: 1.7s\n",
      "246:\tlearn: 0.1096415\ttotal: 1.65s\tremaining: 1.69s\n",
      "247:\tlearn: 0.1091318\ttotal: 1.66s\tremaining: 1.68s\n",
      "248:\tlearn: 0.1084830\ttotal: 1.67s\tremaining: 1.68s\n",
      "249:\tlearn: 0.1078447\ttotal: 1.68s\tremaining: 1.68s\n",
      "250:\tlearn: 0.1073782\ttotal: 1.69s\tremaining: 1.67s\n",
      "251:\tlearn: 0.1067978\ttotal: 1.69s\tremaining: 1.67s\n",
      "252:\tlearn: 0.1062737\ttotal: 1.7s\tremaining: 1.66s\n",
      "253:\tlearn: 0.1057580\ttotal: 1.71s\tremaining: 1.66s\n",
      "254:\tlearn: 0.1051745\ttotal: 1.72s\tremaining: 1.66s\n",
      "255:\tlearn: 0.1047529\ttotal: 1.73s\tremaining: 1.65s\n",
      "256:\tlearn: 0.1042316\ttotal: 1.74s\tremaining: 1.64s\n",
      "257:\tlearn: 0.1033129\ttotal: 1.74s\tremaining: 1.64s\n",
      "258:\tlearn: 0.1028285\ttotal: 1.75s\tremaining: 1.63s\n",
      "259:\tlearn: 0.1021827\ttotal: 1.76s\tremaining: 1.62s\n",
      "260:\tlearn: 0.1015544\ttotal: 1.76s\tremaining: 1.61s\n",
      "261:\tlearn: 0.1011755\ttotal: 1.77s\tremaining: 1.6s\n",
      "262:\tlearn: 0.1006255\ttotal: 1.77s\tremaining: 1.59s\n",
      "263:\tlearn: 0.1001688\ttotal: 1.77s\tremaining: 1.59s\n",
      "264:\tlearn: 0.0996824\ttotal: 1.78s\tremaining: 1.58s\n",
      "265:\tlearn: 0.0991186\ttotal: 1.78s\tremaining: 1.57s\n",
      "266:\tlearn: 0.0986748\ttotal: 1.79s\tremaining: 1.56s\n",
      "267:\tlearn: 0.0980334\ttotal: 1.79s\tremaining: 1.55s\n",
      "268:\tlearn: 0.0974914\ttotal: 1.8s\tremaining: 1.54s\n",
      "269:\tlearn: 0.0969795\ttotal: 1.8s\tremaining: 1.53s\n",
      "270:\tlearn: 0.0964443\ttotal: 1.81s\tremaining: 1.53s\n",
      "271:\tlearn: 0.0961723\ttotal: 1.81s\tremaining: 1.52s\n",
      "272:\tlearn: 0.0956726\ttotal: 1.81s\tremaining: 1.51s\n",
      "273:\tlearn: 0.0949625\ttotal: 1.82s\tremaining: 1.5s\n",
      "274:\tlearn: 0.0943615\ttotal: 1.83s\tremaining: 1.5s\n",
      "275:\tlearn: 0.0936549\ttotal: 1.84s\tremaining: 1.5s\n",
      "276:\tlearn: 0.0930617\ttotal: 1.85s\tremaining: 1.49s\n",
      "277:\tlearn: 0.0926152\ttotal: 1.86s\tremaining: 1.49s\n",
      "278:\tlearn: 0.0916787\ttotal: 1.87s\tremaining: 1.48s\n",
      "279:\tlearn: 0.0912829\ttotal: 1.88s\tremaining: 1.48s\n",
      "280:\tlearn: 0.0909713\ttotal: 1.89s\tremaining: 1.48s\n",
      "281:\tlearn: 0.0904954\ttotal: 1.9s\tremaining: 1.47s\n",
      "282:\tlearn: 0.0900428\ttotal: 1.91s\tremaining: 1.47s\n",
      "283:\tlearn: 0.0895150\ttotal: 1.92s\tremaining: 1.46s\n",
      "284:\tlearn: 0.0890526\ttotal: 1.92s\tremaining: 1.45s\n",
      "285:\tlearn: 0.0885793\ttotal: 1.93s\tremaining: 1.44s\n",
      "286:\tlearn: 0.0881404\ttotal: 1.94s\tremaining: 1.44s\n",
      "287:\tlearn: 0.0876349\ttotal: 1.94s\tremaining: 1.43s\n",
      "288:\tlearn: 0.0872115\ttotal: 1.94s\tremaining: 1.42s\n",
      "289:\tlearn: 0.0867424\ttotal: 1.95s\tremaining: 1.41s\n",
      "290:\tlearn: 0.0862381\ttotal: 1.95s\tremaining: 1.4s\n",
      "291:\tlearn: 0.0857731\ttotal: 1.96s\tremaining: 1.4s\n",
      "292:\tlearn: 0.0856248\ttotal: 1.96s\tremaining: 1.39s\n",
      "293:\tlearn: 0.0851089\ttotal: 1.97s\tremaining: 1.38s\n",
      "294:\tlearn: 0.0847377\ttotal: 1.97s\tremaining: 1.37s\n",
      "295:\tlearn: 0.0845467\ttotal: 1.98s\tremaining: 1.36s\n",
      "296:\tlearn: 0.0841099\ttotal: 1.98s\tremaining: 1.35s\n",
      "297:\tlearn: 0.0836768\ttotal: 1.99s\tremaining: 1.35s\n",
      "298:\tlearn: 0.0831998\ttotal: 2s\tremaining: 1.34s\n",
      "299:\tlearn: 0.0828680\ttotal: 2s\tremaining: 1.34s\n",
      "300:\tlearn: 0.0824332\ttotal: 2.02s\tremaining: 1.33s\n",
      "301:\tlearn: 0.0820016\ttotal: 2.02s\tremaining: 1.33s\n",
      "302:\tlearn: 0.0816304\ttotal: 2.03s\tremaining: 1.32s\n",
      "303:\tlearn: 0.0813672\ttotal: 2.04s\tremaining: 1.32s\n",
      "304:\tlearn: 0.0809749\ttotal: 2.05s\tremaining: 1.31s\n",
      "305:\tlearn: 0.0805961\ttotal: 2.06s\tremaining: 1.31s\n",
      "306:\tlearn: 0.0798560\ttotal: 2.07s\tremaining: 1.3s\n",
      "307:\tlearn: 0.0794315\ttotal: 2.08s\tremaining: 1.3s\n",
      "308:\tlearn: 0.0790446\ttotal: 2.09s\tremaining: 1.29s\n",
      "309:\tlearn: 0.0786406\ttotal: 2.1s\tremaining: 1.28s\n",
      "310:\tlearn: 0.0782968\ttotal: 2.1s\tremaining: 1.28s\n",
      "311:\tlearn: 0.0780042\ttotal: 2.11s\tremaining: 1.27s\n",
      "312:\tlearn: 0.0776101\ttotal: 2.11s\tremaining: 1.26s\n",
      "313:\tlearn: 0.0771151\ttotal: 2.12s\tremaining: 1.25s\n",
      "314:\tlearn: 0.0766956\ttotal: 2.12s\tremaining: 1.25s\n",
      "315:\tlearn: 0.0762931\ttotal: 2.13s\tremaining: 1.24s\n",
      "316:\tlearn: 0.0758637\ttotal: 2.13s\tremaining: 1.23s\n",
      "317:\tlearn: 0.0755415\ttotal: 2.13s\tremaining: 1.22s\n",
      "318:\tlearn: 0.0750851\ttotal: 2.14s\tremaining: 1.21s\n",
      "319:\tlearn: 0.0747229\ttotal: 2.14s\tremaining: 1.21s\n",
      "320:\tlearn: 0.0744987\ttotal: 2.15s\tremaining: 1.2s\n",
      "321:\tlearn: 0.0741422\ttotal: 2.15s\tremaining: 1.19s\n",
      "322:\tlearn: 0.0736705\ttotal: 2.16s\tremaining: 1.18s\n",
      "323:\tlearn: 0.0733835\ttotal: 2.16s\tremaining: 1.17s\n",
      "324:\tlearn: 0.0730083\ttotal: 2.17s\tremaining: 1.17s\n",
      "325:\tlearn: 0.0725830\ttotal: 2.18s\tremaining: 1.16s\n",
      "326:\tlearn: 0.0721273\ttotal: 2.19s\tremaining: 1.16s\n",
      "327:\tlearn: 0.0718235\ttotal: 2.2s\tremaining: 1.15s\n",
      "328:\tlearn: 0.0715425\ttotal: 2.21s\tremaining: 1.15s\n",
      "329:\tlearn: 0.0712272\ttotal: 2.22s\tremaining: 1.14s\n",
      "330:\tlearn: 0.0708690\ttotal: 2.23s\tremaining: 1.14s\n",
      "331:\tlearn: 0.0704655\ttotal: 2.24s\tremaining: 1.13s\n",
      "332:\tlearn: 0.0700455\ttotal: 2.24s\tremaining: 1.13s\n",
      "333:\tlearn: 0.0697489\ttotal: 2.25s\tremaining: 1.12s\n",
      "334:\tlearn: 0.0694441\ttotal: 2.26s\tremaining: 1.11s\n",
      "335:\tlearn: 0.0694143\ttotal: 2.26s\tremaining: 1.1s\n",
      "336:\tlearn: 0.0690757\ttotal: 2.27s\tremaining: 1.1s\n",
      "337:\tlearn: 0.0687081\ttotal: 2.27s\tremaining: 1.09s\n",
      "338:\tlearn: 0.0683587\ttotal: 2.28s\tremaining: 1.08s\n",
      "339:\tlearn: 0.0681718\ttotal: 2.28s\tremaining: 1.07s\n",
      "340:\tlearn: 0.0678060\ttotal: 2.29s\tremaining: 1.07s\n",
      "341:\tlearn: 0.0674520\ttotal: 2.29s\tremaining: 1.06s\n",
      "342:\tlearn: 0.0671241\ttotal: 2.3s\tremaining: 1.05s\n",
      "343:\tlearn: 0.0667993\ttotal: 2.3s\tremaining: 1.04s\n",
      "344:\tlearn: 0.0665169\ttotal: 2.31s\tremaining: 1.04s\n",
      "345:\tlearn: 0.0662844\ttotal: 2.31s\tremaining: 1.03s\n",
      "346:\tlearn: 0.0659384\ttotal: 2.31s\tremaining: 1.02s\n",
      "347:\tlearn: 0.0656861\ttotal: 2.32s\tremaining: 1.01s\n",
      "348:\tlearn: 0.0654010\ttotal: 2.32s\tremaining: 1s\n",
      "349:\tlearn: 0.0650889\ttotal: 2.33s\tremaining: 998ms\n",
      "350:\tlearn: 0.0647751\ttotal: 2.34s\tremaining: 993ms\n",
      "351:\tlearn: 0.0645214\ttotal: 2.35s\tremaining: 988ms\n",
      "352:\tlearn: 0.0637689\ttotal: 2.36s\tremaining: 982ms\n",
      "353:\tlearn: 0.0634903\ttotal: 2.37s\tremaining: 977ms\n",
      "354:\tlearn: 0.0628969\ttotal: 2.38s\tremaining: 971ms\n",
      "355:\tlearn: 0.0626462\ttotal: 2.39s\tremaining: 966ms\n",
      "356:\tlearn: 0.0622656\ttotal: 2.4s\tremaining: 960ms\n",
      "357:\tlearn: 0.0619015\ttotal: 2.41s\tremaining: 955ms\n",
      "358:\tlearn: 0.0616192\ttotal: 2.41s\tremaining: 948ms\n",
      "359:\tlearn: 0.0612793\ttotal: 2.42s\tremaining: 941ms\n",
      "360:\tlearn: 0.0610141\ttotal: 2.43s\tremaining: 935ms\n",
      "361:\tlearn: 0.0606525\ttotal: 2.43s\tremaining: 928ms\n",
      "362:\tlearn: 0.0603403\ttotal: 2.44s\tremaining: 921ms\n",
      "363:\tlearn: 0.0600951\ttotal: 2.44s\tremaining: 913ms\n",
      "364:\tlearn: 0.0598059\ttotal: 2.45s\tremaining: 906ms\n",
      "365:\tlearn: 0.0595763\ttotal: 2.45s\tremaining: 899ms\n",
      "366:\tlearn: 0.0592258\ttotal: 2.46s\tremaining: 891ms\n",
      "367:\tlearn: 0.0589651\ttotal: 2.46s\tremaining: 884ms\n",
      "368:\tlearn: 0.0587428\ttotal: 2.47s\tremaining: 876ms\n",
      "369:\tlearn: 0.0584548\ttotal: 2.47s\tremaining: 869ms\n",
      "370:\tlearn: 0.0582024\ttotal: 2.48s\tremaining: 861ms\n",
      "371:\tlearn: 0.0578749\ttotal: 2.48s\tremaining: 854ms\n",
      "372:\tlearn: 0.0576119\ttotal: 2.48s\tremaining: 846ms\n",
      "373:\tlearn: 0.0572774\ttotal: 2.49s\tremaining: 839ms\n",
      "374:\tlearn: 0.0570168\ttotal: 2.49s\tremaining: 832ms\n",
      "375:\tlearn: 0.0568117\ttotal: 2.5s\tremaining: 824ms\n",
      "376:\tlearn: 0.0564778\ttotal: 2.51s\tremaining: 818ms\n",
      "377:\tlearn: 0.0562327\ttotal: 2.52s\tremaining: 813ms\n",
      "378:\tlearn: 0.0559664\ttotal: 2.53s\tremaining: 807ms\n",
      "379:\tlearn: 0.0559422\ttotal: 2.54s\tremaining: 801ms\n",
      "380:\tlearn: 0.0557106\ttotal: 2.55s\tremaining: 795ms\n",
      "381:\tlearn: 0.0554147\ttotal: 2.56s\tremaining: 790ms\n",
      "382:\tlearn: 0.0551545\ttotal: 2.57s\tremaining: 784ms\n",
      "383:\tlearn: 0.0547315\ttotal: 2.58s\tremaining: 778ms\n",
      "384:\tlearn: 0.0545164\ttotal: 2.58s\tremaining: 771ms\n",
      "385:\tlearn: 0.0543007\ttotal: 2.59s\tremaining: 764ms\n",
      "386:\tlearn: 0.0540200\ttotal: 2.59s\tremaining: 756ms\n",
      "387:\tlearn: 0.0538209\ttotal: 2.6s\tremaining: 749ms\n",
      "388:\tlearn: 0.0535890\ttotal: 2.6s\tremaining: 742ms\n",
      "389:\tlearn: 0.0532760\ttotal: 2.6s\tremaining: 735ms\n",
      "390:\tlearn: 0.0530236\ttotal: 2.61s\tremaining: 727ms\n",
      "391:\tlearn: 0.0527712\ttotal: 2.61s\tremaining: 720ms\n",
      "392:\tlearn: 0.0525359\ttotal: 2.62s\tremaining: 713ms\n",
      "393:\tlearn: 0.0522333\ttotal: 2.62s\tremaining: 706ms\n",
      "394:\tlearn: 0.0520028\ttotal: 2.63s\tremaining: 698ms\n",
      "395:\tlearn: 0.0517029\ttotal: 2.63s\tremaining: 691ms\n",
      "396:\tlearn: 0.0514684\ttotal: 2.63s\tremaining: 684ms\n",
      "397:\tlearn: 0.0512243\ttotal: 2.64s\tremaining: 677ms\n",
      "398:\tlearn: 0.0510455\ttotal: 2.65s\tremaining: 670ms\n",
      "399:\tlearn: 0.0507644\ttotal: 2.65s\tremaining: 664ms\n",
      "400:\tlearn: 0.0504986\ttotal: 2.66s\tremaining: 658ms\n",
      "401:\tlearn: 0.0502727\ttotal: 2.67s\tremaining: 652ms\n",
      "402:\tlearn: 0.0499796\ttotal: 2.68s\tremaining: 646ms\n",
      "403:\tlearn: 0.0497884\ttotal: 2.69s\tremaining: 640ms\n",
      "404:\tlearn: 0.0495527\ttotal: 2.7s\tremaining: 634ms\n",
      "405:\tlearn: 0.0492438\ttotal: 2.71s\tremaining: 628ms\n",
      "406:\tlearn: 0.0489395\ttotal: 2.72s\tremaining: 622ms\n",
      "407:\tlearn: 0.0487240\ttotal: 2.73s\tremaining: 616ms\n",
      "408:\tlearn: 0.0485008\ttotal: 2.74s\tremaining: 609ms\n",
      "409:\tlearn: 0.0483000\ttotal: 2.75s\tremaining: 603ms\n",
      "410:\tlearn: 0.0481092\ttotal: 2.75s\tremaining: 596ms\n",
      "411:\tlearn: 0.0478574\ttotal: 2.76s\tremaining: 589ms\n",
      "412:\tlearn: 0.0476016\ttotal: 2.76s\tremaining: 582ms\n",
      "413:\tlearn: 0.0473988\ttotal: 2.77s\tremaining: 575ms\n",
      "414:\tlearn: 0.0473259\ttotal: 2.77s\tremaining: 568ms\n",
      "415:\tlearn: 0.0470698\ttotal: 2.77s\tremaining: 561ms\n",
      "416:\tlearn: 0.0468745\ttotal: 2.78s\tremaining: 553ms\n",
      "417:\tlearn: 0.0465466\ttotal: 2.78s\tremaining: 546ms\n",
      "418:\tlearn: 0.0463907\ttotal: 2.79s\tremaining: 539ms\n",
      "419:\tlearn: 0.0462067\ttotal: 2.79s\tremaining: 532ms\n",
      "420:\tlearn: 0.0460390\ttotal: 2.8s\tremaining: 525ms\n",
      "421:\tlearn: 0.0457878\ttotal: 2.8s\tremaining: 518ms\n",
      "422:\tlearn: 0.0455556\ttotal: 2.81s\tremaining: 512ms\n",
      "423:\tlearn: 0.0454266\ttotal: 2.82s\tremaining: 506ms\n",
      "424:\tlearn: 0.0451986\ttotal: 2.83s\tremaining: 500ms\n",
      "425:\tlearn: 0.0450182\ttotal: 2.84s\tremaining: 494ms\n",
      "426:\tlearn: 0.0448564\ttotal: 2.85s\tremaining: 488ms\n",
      "427:\tlearn: 0.0445946\ttotal: 2.86s\tremaining: 482ms\n",
      "428:\tlearn: 0.0443650\ttotal: 2.88s\tremaining: 476ms\n",
      "429:\tlearn: 0.0441355\ttotal: 2.88s\tremaining: 470ms\n",
      "430:\tlearn: 0.0439456\ttotal: 2.89s\tremaining: 463ms\n",
      "431:\tlearn: 0.0438288\ttotal: 2.9s\tremaining: 456ms\n",
      "432:\tlearn: 0.0436576\ttotal: 2.9s\tremaining: 449ms\n",
      "433:\tlearn: 0.0435342\ttotal: 2.9s\tremaining: 442ms\n",
      "434:\tlearn: 0.0433384\ttotal: 2.91s\tremaining: 435ms\n",
      "435:\tlearn: 0.0431641\ttotal: 2.92s\tremaining: 428ms\n",
      "436:\tlearn: 0.0429361\ttotal: 2.92s\tremaining: 421ms\n",
      "437:\tlearn: 0.0428599\ttotal: 2.92s\tremaining: 414ms\n",
      "438:\tlearn: 0.0426791\ttotal: 2.93s\tremaining: 407ms\n",
      "439:\tlearn: 0.0424533\ttotal: 2.93s\tremaining: 400ms\n",
      "440:\tlearn: 0.0422621\ttotal: 2.94s\tremaining: 393ms\n",
      "441:\tlearn: 0.0420968\ttotal: 2.94s\tremaining: 386ms\n",
      "442:\tlearn: 0.0419945\ttotal: 2.95s\tremaining: 379ms\n",
      "443:\tlearn: 0.0417746\ttotal: 2.96s\tremaining: 373ms\n",
      "444:\tlearn: 0.0415242\ttotal: 2.96s\tremaining: 367ms\n",
      "445:\tlearn: 0.0412701\ttotal: 2.98s\tremaining: 360ms\n",
      "446:\tlearn: 0.0411200\ttotal: 2.98s\tremaining: 354ms\n",
      "447:\tlearn: 0.0409716\ttotal: 3s\tremaining: 348ms\n",
      "448:\tlearn: 0.0407448\ttotal: 3s\tremaining: 341ms\n",
      "449:\tlearn: 0.0406027\ttotal: 3.01s\tremaining: 335ms\n",
      "450:\tlearn: 0.0404035\ttotal: 3.02s\tremaining: 329ms\n",
      "451:\tlearn: 0.0402448\ttotal: 3.03s\tremaining: 322ms\n",
      "452:\tlearn: 0.0400747\ttotal: 3.04s\tremaining: 315ms\n",
      "453:\tlearn: 0.0398985\ttotal: 3.04s\tremaining: 309ms\n",
      "454:\tlearn: 0.0397696\ttotal: 3.05s\tremaining: 302ms\n",
      "455:\tlearn: 0.0395645\ttotal: 3.06s\tremaining: 295ms\n",
      "456:\tlearn: 0.0393587\ttotal: 3.06s\tremaining: 288ms\n",
      "457:\tlearn: 0.0391357\ttotal: 3.07s\tremaining: 282ms\n",
      "458:\tlearn: 0.0389168\ttotal: 3.08s\tremaining: 275ms\n",
      "459:\tlearn: 0.0386588\ttotal: 3.08s\tremaining: 268ms\n",
      "460:\tlearn: 0.0383540\ttotal: 3.09s\tremaining: 261ms\n",
      "461:\tlearn: 0.0381709\ttotal: 3.09s\tremaining: 254ms\n",
      "462:\tlearn: 0.0380051\ttotal: 3.1s\tremaining: 247ms\n",
      "463:\tlearn: 0.0378600\ttotal: 3.1s\tremaining: 241ms\n",
      "464:\tlearn: 0.0376418\ttotal: 3.1s\tremaining: 234ms\n",
      "465:\tlearn: 0.0374473\ttotal: 3.11s\tremaining: 227ms\n",
      "466:\tlearn: 0.0373337\ttotal: 3.11s\tremaining: 220ms\n",
      "467:\tlearn: 0.0371939\ttotal: 3.12s\tremaining: 213ms\n",
      "468:\tlearn: 0.0370668\ttotal: 3.12s\tremaining: 206ms\n",
      "469:\tlearn: 0.0369310\ttotal: 3.13s\tremaining: 200ms\n",
      "470:\tlearn: 0.0367161\ttotal: 3.13s\tremaining: 193ms\n",
      "471:\tlearn: 0.0365597\ttotal: 3.13s\tremaining: 186ms\n",
      "472:\tlearn: 0.0363877\ttotal: 3.14s\tremaining: 179ms\n",
      "473:\tlearn: 0.0362585\ttotal: 3.14s\tremaining: 172ms\n",
      "474:\tlearn: 0.0361692\ttotal: 3.15s\tremaining: 166ms\n",
      "475:\tlearn: 0.0360430\ttotal: 3.16s\tremaining: 159ms\n",
      "476:\tlearn: 0.0357702\ttotal: 3.17s\tremaining: 153ms\n",
      "477:\tlearn: 0.0355351\ttotal: 3.18s\tremaining: 146ms\n",
      "478:\tlearn: 0.0353496\ttotal: 3.19s\tremaining: 140ms\n",
      "479:\tlearn: 0.0351812\ttotal: 3.2s\tremaining: 133ms\n",
      "480:\tlearn: 0.0350204\ttotal: 3.21s\tremaining: 127ms\n",
      "481:\tlearn: 0.0348651\ttotal: 3.22s\tremaining: 120ms\n",
      "482:\tlearn: 0.0347222\ttotal: 3.23s\tremaining: 114ms\n",
      "483:\tlearn: 0.0345884\ttotal: 3.24s\tremaining: 107ms\n",
      "484:\tlearn: 0.0344371\ttotal: 3.24s\tremaining: 100ms\n",
      "485:\tlearn: 0.0342738\ttotal: 3.25s\tremaining: 93.6ms\n",
      "486:\tlearn: 0.0340991\ttotal: 3.25s\tremaining: 86.9ms\n",
      "487:\tlearn: 0.0339402\ttotal: 3.26s\tremaining: 80.2ms\n",
      "488:\tlearn: 0.0337967\ttotal: 3.27s\tremaining: 73.5ms\n",
      "489:\tlearn: 0.0336281\ttotal: 3.27s\tremaining: 66.8ms\n",
      "490:\tlearn: 0.0334935\ttotal: 3.28s\tremaining: 60.1ms\n",
      "491:\tlearn: 0.0333056\ttotal: 3.28s\tremaining: 53.4ms\n",
      "492:\tlearn: 0.0331603\ttotal: 3.29s\tremaining: 46.7ms\n",
      "493:\tlearn: 0.0329903\ttotal: 3.29s\tremaining: 40ms\n",
      "494:\tlearn: 0.0328452\ttotal: 3.29s\tremaining: 33.3ms\n",
      "495:\tlearn: 0.0326651\ttotal: 3.3s\tremaining: 26.6ms\n",
      "496:\tlearn: 0.0325297\ttotal: 3.3s\tremaining: 19.9ms\n",
      "497:\tlearn: 0.0323269\ttotal: 3.31s\tremaining: 13.3ms\n",
      "498:\tlearn: 0.0321814\ttotal: 3.31s\tremaining: 6.64ms\n",
      "499:\tlearn: 0.0320420\ttotal: 3.32s\tremaining: 0us\n",
      "0:\tlearn: 0.6816849\ttotal: 11.1ms\tremaining: 5.53s\n",
      "1:\tlearn: 0.6693164\ttotal: 20.9ms\tremaining: 5.21s\n",
      "2:\tlearn: 0.6608089\ttotal: 30.6ms\tremaining: 5.06s\n",
      "3:\tlearn: 0.6500132\ttotal: 40.2ms\tremaining: 4.99s\n",
      "4:\tlearn: 0.6404195\ttotal: 50.2ms\tremaining: 4.97s\n",
      "5:\tlearn: 0.6280002\ttotal: 56.4ms\tremaining: 4.64s\n",
      "6:\tlearn: 0.6175805\ttotal: 63.5ms\tremaining: 4.47s\n",
      "7:\tlearn: 0.6089171\ttotal: 69.6ms\tremaining: 4.28s\n",
      "8:\tlearn: 0.5996874\ttotal: 75.9ms\tremaining: 4.14s\n",
      "9:\tlearn: 0.5901527\ttotal: 81.5ms\tremaining: 4s\n",
      "10:\tlearn: 0.5834967\ttotal: 86.4ms\tremaining: 3.84s\n",
      "11:\tlearn: 0.5768924\ttotal: 91.2ms\tremaining: 3.71s\n",
      "12:\tlearn: 0.5715884\ttotal: 95.7ms\tremaining: 3.58s\n",
      "13:\tlearn: 0.5662411\ttotal: 99.8ms\tremaining: 3.46s\n",
      "14:\tlearn: 0.5592372\ttotal: 104ms\tremaining: 3.37s\n",
      "15:\tlearn: 0.5538193\ttotal: 108ms\tremaining: 3.28s\n",
      "16:\tlearn: 0.5477669\ttotal: 113ms\tremaining: 3.2s\n",
      "17:\tlearn: 0.5416780\ttotal: 117ms\tremaining: 3.13s\n",
      "18:\tlearn: 0.5375650\ttotal: 121ms\tremaining: 3.06s\n",
      "19:\tlearn: 0.5307677\ttotal: 127ms\tremaining: 3.04s\n",
      "20:\tlearn: 0.5263229\ttotal: 136ms\tremaining: 3.11s\n",
      "21:\tlearn: 0.5166489\ttotal: 146ms\tremaining: 3.17s\n",
      "22:\tlearn: 0.5119994\ttotal: 156ms\tremaining: 3.23s\n",
      "23:\tlearn: 0.5047921\ttotal: 165ms\tremaining: 3.27s\n",
      "24:\tlearn: 0.5008714\ttotal: 174ms\tremaining: 3.31s\n",
      "25:\tlearn: 0.4968449\ttotal: 184ms\tremaining: 3.35s\n",
      "26:\tlearn: 0.4928844\ttotal: 194ms\tremaining: 3.39s\n",
      "27:\tlearn: 0.4893108\ttotal: 203ms\tremaining: 3.42s\n",
      "28:\tlearn: 0.4861879\ttotal: 212ms\tremaining: 3.44s\n",
      "29:\tlearn: 0.4804608\ttotal: 217ms\tremaining: 3.4s\n",
      "30:\tlearn: 0.4749028\ttotal: 221ms\tremaining: 3.35s\n",
      "31:\tlearn: 0.4697032\ttotal: 226ms\tremaining: 3.3s\n",
      "32:\tlearn: 0.4648959\ttotal: 230ms\tremaining: 3.25s\n",
      "33:\tlearn: 0.4612280\ttotal: 234ms\tremaining: 3.21s\n",
      "34:\tlearn: 0.4571911\ttotal: 245ms\tremaining: 3.25s\n",
      "35:\tlearn: 0.4538158\ttotal: 254ms\tremaining: 3.28s\n",
      "36:\tlearn: 0.4515037\ttotal: 264ms\tremaining: 3.3s\n",
      "37:\tlearn: 0.4455250\ttotal: 273ms\tremaining: 3.33s\n",
      "38:\tlearn: 0.4431530\ttotal: 283ms\tremaining: 3.35s\n",
      "39:\tlearn: 0.4403071\ttotal: 293ms\tremaining: 3.37s\n",
      "40:\tlearn: 0.4362868\ttotal: 302ms\tremaining: 3.38s\n",
      "41:\tlearn: 0.4316852\ttotal: 312ms\tremaining: 3.4s\n",
      "42:\tlearn: 0.4288081\ttotal: 321ms\tremaining: 3.42s\n",
      "43:\tlearn: 0.4253354\ttotal: 329ms\tremaining: 3.41s\n",
      "44:\tlearn: 0.4230836\ttotal: 335ms\tremaining: 3.39s\n",
      "45:\tlearn: 0.4207161\ttotal: 342ms\tremaining: 3.37s\n",
      "46:\tlearn: 0.4178284\ttotal: 348ms\tremaining: 3.35s\n",
      "47:\tlearn: 0.4147873\ttotal: 354ms\tremaining: 3.33s\n",
      "48:\tlearn: 0.4110991\ttotal: 359ms\tremaining: 3.3s\n",
      "49:\tlearn: 0.4086289\ttotal: 364ms\tremaining: 3.28s\n",
      "50:\tlearn: 0.4065290\ttotal: 370ms\tremaining: 3.25s\n",
      "51:\tlearn: 0.4041229\ttotal: 374ms\tremaining: 3.22s\n",
      "52:\tlearn: 0.4002631\ttotal: 378ms\tremaining: 3.19s\n",
      "53:\tlearn: 0.3973268\ttotal: 382ms\tremaining: 3.16s\n",
      "54:\tlearn: 0.3957162\ttotal: 386ms\tremaining: 3.13s\n",
      "55:\tlearn: 0.3927482\ttotal: 391ms\tremaining: 3.1s\n",
      "56:\tlearn: 0.3910674\ttotal: 395ms\tremaining: 3.07s\n",
      "57:\tlearn: 0.3869367\ttotal: 399ms\tremaining: 3.04s\n",
      "58:\tlearn: 0.3830829\ttotal: 402ms\tremaining: 3.01s\n",
      "59:\tlearn: 0.3807932\ttotal: 407ms\tremaining: 2.98s\n",
      "60:\tlearn: 0.3783459\ttotal: 411ms\tremaining: 2.96s\n",
      "61:\tlearn: 0.3749518\ttotal: 421ms\tremaining: 2.97s\n",
      "62:\tlearn: 0.3689804\ttotal: 430ms\tremaining: 2.98s\n",
      "63:\tlearn: 0.3670079\ttotal: 440ms\tremaining: 3s\n",
      "64:\tlearn: 0.3644553\ttotal: 450ms\tremaining: 3.01s\n",
      "65:\tlearn: 0.3623486\ttotal: 460ms\tremaining: 3.02s\n",
      "66:\tlearn: 0.3595484\ttotal: 469ms\tremaining: 3.03s\n",
      "67:\tlearn: 0.3565869\ttotal: 479ms\tremaining: 3.04s\n",
      "68:\tlearn: 0.3536707\ttotal: 488ms\tremaining: 3.05s\n",
      "69:\tlearn: 0.3511734\ttotal: 497ms\tremaining: 3.05s\n",
      "70:\tlearn: 0.3495376\ttotal: 503ms\tremaining: 3.04s\n",
      "71:\tlearn: 0.3470250\ttotal: 509ms\tremaining: 3.02s\n",
      "72:\tlearn: 0.3424574\ttotal: 515ms\tremaining: 3.01s\n",
      "73:\tlearn: 0.3405453\ttotal: 521ms\tremaining: 3s\n",
      "74:\tlearn: 0.3367137\ttotal: 527ms\tremaining: 2.98s\n",
      "75:\tlearn: 0.3341353\ttotal: 531ms\tremaining: 2.96s\n",
      "76:\tlearn: 0.3311432\ttotal: 536ms\tremaining: 2.94s\n",
      "77:\tlearn: 0.3293588\ttotal: 541ms\tremaining: 2.92s\n",
      "78:\tlearn: 0.3272999\ttotal: 547ms\tremaining: 2.91s\n",
      "79:\tlearn: 0.3229655\ttotal: 553ms\tremaining: 2.9s\n",
      "80:\tlearn: 0.3210973\ttotal: 557ms\tremaining: 2.88s\n",
      "81:\tlearn: 0.3188734\ttotal: 560ms\tremaining: 2.86s\n",
      "82:\tlearn: 0.3164760\ttotal: 565ms\tremaining: 2.84s\n",
      "83:\tlearn: 0.3139309\ttotal: 569ms\tremaining: 2.82s\n",
      "84:\tlearn: 0.3114552\ttotal: 573ms\tremaining: 2.8s\n",
      "85:\tlearn: 0.3089408\ttotal: 578ms\tremaining: 2.78s\n",
      "86:\tlearn: 0.3068224\ttotal: 582ms\tremaining: 2.76s\n",
      "87:\tlearn: 0.3046084\ttotal: 587ms\tremaining: 2.75s\n",
      "88:\tlearn: 0.3029599\ttotal: 597ms\tremaining: 2.76s\n",
      "89:\tlearn: 0.3010145\ttotal: 606ms\tremaining: 2.76s\n",
      "90:\tlearn: 0.2986599\ttotal: 616ms\tremaining: 2.77s\n",
      "91:\tlearn: 0.2968766\ttotal: 626ms\tremaining: 2.77s\n",
      "92:\tlearn: 0.2934727\ttotal: 636ms\tremaining: 2.78s\n",
      "93:\tlearn: 0.2916272\ttotal: 645ms\tremaining: 2.79s\n",
      "94:\tlearn: 0.2897544\ttotal: 654ms\tremaining: 2.79s\n",
      "95:\tlearn: 0.2881082\ttotal: 664ms\tremaining: 2.79s\n",
      "96:\tlearn: 0.2861597\ttotal: 669ms\tremaining: 2.78s\n",
      "97:\tlearn: 0.2841937\ttotal: 674ms\tremaining: 2.76s\n",
      "98:\tlearn: 0.2823471\ttotal: 679ms\tremaining: 2.75s\n",
      "99:\tlearn: 0.2786421\ttotal: 684ms\tremaining: 2.73s\n",
      "100:\tlearn: 0.2769438\ttotal: 689ms\tremaining: 2.72s\n",
      "101:\tlearn: 0.2751279\ttotal: 693ms\tremaining: 2.71s\n",
      "102:\tlearn: 0.2727901\ttotal: 698ms\tremaining: 2.69s\n",
      "103:\tlearn: 0.2709111\ttotal: 702ms\tremaining: 2.67s\n",
      "104:\tlearn: 0.2693737\ttotal: 707ms\tremaining: 2.66s\n",
      "105:\tlearn: 0.2676729\ttotal: 711ms\tremaining: 2.64s\n",
      "106:\tlearn: 0.2658962\ttotal: 715ms\tremaining: 2.63s\n",
      "107:\tlearn: 0.2639385\ttotal: 719ms\tremaining: 2.61s\n",
      "108:\tlearn: 0.2624290\ttotal: 722ms\tremaining: 2.59s\n",
      "109:\tlearn: 0.2605699\ttotal: 726ms\tremaining: 2.57s\n",
      "110:\tlearn: 0.2585168\ttotal: 735ms\tremaining: 2.58s\n",
      "111:\tlearn: 0.2567592\ttotal: 745ms\tremaining: 2.58s\n",
      "112:\tlearn: 0.2535481\ttotal: 754ms\tremaining: 2.58s\n",
      "113:\tlearn: 0.2520066\ttotal: 764ms\tremaining: 2.59s\n",
      "114:\tlearn: 0.2504069\ttotal: 774ms\tremaining: 2.59s\n",
      "115:\tlearn: 0.2489909\ttotal: 784ms\tremaining: 2.59s\n",
      "116:\tlearn: 0.2473205\ttotal: 793ms\tremaining: 2.6s\n",
      "117:\tlearn: 0.2460172\ttotal: 803ms\tremaining: 2.6s\n",
      "118:\tlearn: 0.2446783\ttotal: 812ms\tremaining: 2.6s\n",
      "119:\tlearn: 0.2431824\ttotal: 820ms\tremaining: 2.6s\n",
      "120:\tlearn: 0.2407073\ttotal: 827ms\tremaining: 2.59s\n",
      "121:\tlearn: 0.2394514\ttotal: 833ms\tremaining: 2.58s\n",
      "122:\tlearn: 0.2379664\ttotal: 839ms\tremaining: 2.57s\n",
      "123:\tlearn: 0.2356778\ttotal: 845ms\tremaining: 2.56s\n",
      "124:\tlearn: 0.2330223\ttotal: 850ms\tremaining: 2.55s\n",
      "125:\tlearn: 0.2318406\ttotal: 854ms\tremaining: 2.54s\n",
      "126:\tlearn: 0.2300115\ttotal: 859ms\tremaining: 2.52s\n",
      "127:\tlearn: 0.2288335\ttotal: 864ms\tremaining: 2.51s\n",
      "128:\tlearn: 0.2274400\ttotal: 868ms\tremaining: 2.5s\n",
      "129:\tlearn: 0.2248550\ttotal: 873ms\tremaining: 2.48s\n",
      "130:\tlearn: 0.2235088\ttotal: 877ms\tremaining: 2.47s\n",
      "131:\tlearn: 0.2222358\ttotal: 881ms\tremaining: 2.46s\n",
      "132:\tlearn: 0.2210866\ttotal: 885ms\tremaining: 2.44s\n",
      "133:\tlearn: 0.2186778\ttotal: 890ms\tremaining: 2.43s\n",
      "134:\tlearn: 0.2173115\ttotal: 903ms\tremaining: 2.44s\n",
      "135:\tlearn: 0.2158610\ttotal: 913ms\tremaining: 2.44s\n",
      "136:\tlearn: 0.2144098\ttotal: 922ms\tremaining: 2.44s\n",
      "137:\tlearn: 0.2134315\ttotal: 932ms\tremaining: 2.44s\n",
      "138:\tlearn: 0.2121518\ttotal: 942ms\tremaining: 2.44s\n",
      "139:\tlearn: 0.2106878\ttotal: 951ms\tremaining: 2.45s\n",
      "140:\tlearn: 0.2094322\ttotal: 961ms\tremaining: 2.45s\n",
      "141:\tlearn: 0.2080844\ttotal: 971ms\tremaining: 2.45s\n",
      "142:\tlearn: 0.2065362\ttotal: 981ms\tremaining: 2.45s\n",
      "143:\tlearn: 0.2052298\ttotal: 991ms\tremaining: 2.45s\n",
      "144:\tlearn: 0.2027617\ttotal: 997ms\tremaining: 2.44s\n",
      "145:\tlearn: 0.2015780\ttotal: 1s\tremaining: 2.43s\n",
      "146:\tlearn: 0.2002551\ttotal: 1.01s\tremaining: 2.42s\n",
      "147:\tlearn: 0.1991313\ttotal: 1.01s\tremaining: 2.41s\n",
      "148:\tlearn: 0.1970010\ttotal: 1.02s\tremaining: 2.4s\n",
      "149:\tlearn: 0.1957855\ttotal: 1.02s\tremaining: 2.39s\n",
      "150:\tlearn: 0.1943552\ttotal: 1.03s\tremaining: 2.38s\n",
      "151:\tlearn: 0.1926761\ttotal: 1.03s\tremaining: 2.36s\n",
      "152:\tlearn: 0.1914787\ttotal: 1.04s\tremaining: 2.35s\n",
      "153:\tlearn: 0.1905907\ttotal: 1.04s\tremaining: 2.34s\n",
      "154:\tlearn: 0.1895469\ttotal: 1.04s\tremaining: 2.33s\n",
      "155:\tlearn: 0.1882576\ttotal: 1.05s\tremaining: 2.31s\n",
      "156:\tlearn: 0.1865198\ttotal: 1.05s\tremaining: 2.3s\n",
      "157:\tlearn: 0.1835338\ttotal: 1.06s\tremaining: 2.29s\n",
      "158:\tlearn: 0.1825646\ttotal: 1.06s\tremaining: 2.28s\n",
      "159:\tlearn: 0.1812934\ttotal: 1.07s\tremaining: 2.28s\n",
      "160:\tlearn: 0.1803972\ttotal: 1.08s\tremaining: 2.28s\n",
      "161:\tlearn: 0.1792828\ttotal: 1.09s\tremaining: 2.28s\n",
      "162:\tlearn: 0.1778862\ttotal: 1.1s\tremaining: 2.28s\n",
      "163:\tlearn: 0.1769462\ttotal: 1.11s\tremaining: 2.28s\n",
      "164:\tlearn: 0.1756604\ttotal: 1.12s\tremaining: 2.27s\n",
      "165:\tlearn: 0.1745377\ttotal: 1.13s\tremaining: 2.27s\n",
      "166:\tlearn: 0.1734735\ttotal: 1.14s\tremaining: 2.27s\n",
      "167:\tlearn: 0.1725163\ttotal: 1.15s\tremaining: 2.27s\n",
      "168:\tlearn: 0.1710958\ttotal: 1.16s\tremaining: 2.27s\n",
      "169:\tlearn: 0.1701496\ttotal: 1.17s\tremaining: 2.26s\n",
      "170:\tlearn: 0.1690908\ttotal: 1.17s\tremaining: 2.25s\n",
      "171:\tlearn: 0.1679493\ttotal: 1.18s\tremaining: 2.24s\n",
      "172:\tlearn: 0.1669410\ttotal: 1.18s\tremaining: 2.24s\n",
      "173:\tlearn: 0.1659332\ttotal: 1.19s\tremaining: 2.23s\n",
      "174:\tlearn: 0.1650789\ttotal: 1.19s\tremaining: 2.22s\n",
      "175:\tlearn: 0.1635700\ttotal: 1.2s\tremaining: 2.21s\n",
      "176:\tlearn: 0.1626454\ttotal: 1.2s\tremaining: 2.2s\n",
      "177:\tlearn: 0.1617595\ttotal: 1.21s\tremaining: 2.19s\n",
      "178:\tlearn: 0.1608910\ttotal: 1.21s\tremaining: 2.17s\n",
      "179:\tlearn: 0.1600318\ttotal: 1.22s\tremaining: 2.16s\n",
      "180:\tlearn: 0.1592021\ttotal: 1.22s\tremaining: 2.15s\n",
      "181:\tlearn: 0.1578902\ttotal: 1.23s\tremaining: 2.14s\n",
      "182:\tlearn: 0.1572167\ttotal: 1.23s\tremaining: 2.13s\n",
      "183:\tlearn: 0.1563389\ttotal: 1.24s\tremaining: 2.12s\n",
      "184:\tlearn: 0.1555889\ttotal: 1.24s\tremaining: 2.11s\n",
      "185:\tlearn: 0.1544391\ttotal: 1.24s\tremaining: 2.1s\n",
      "186:\tlearn: 0.1536270\ttotal: 1.25s\tremaining: 2.09s\n",
      "187:\tlearn: 0.1526431\ttotal: 1.25s\tremaining: 2.08s\n",
      "188:\tlearn: 0.1518217\ttotal: 1.26s\tremaining: 2.07s\n",
      "189:\tlearn: 0.1508456\ttotal: 1.27s\tremaining: 2.07s\n",
      "190:\tlearn: 0.1500198\ttotal: 1.28s\tremaining: 2.06s\n",
      "191:\tlearn: 0.1492238\ttotal: 1.29s\tremaining: 2.06s\n",
      "192:\tlearn: 0.1484360\ttotal: 1.29s\tremaining: 2.06s\n",
      "193:\tlearn: 0.1477471\ttotal: 1.3s\tremaining: 2.06s\n",
      "194:\tlearn: 0.1469692\ttotal: 1.31s\tremaining: 2.06s\n",
      "195:\tlearn: 0.1461060\ttotal: 1.32s\tremaining: 2.05s\n",
      "196:\tlearn: 0.1444778\ttotal: 1.33s\tremaining: 2.05s\n",
      "197:\tlearn: 0.1435067\ttotal: 1.34s\tremaining: 2.05s\n",
      "198:\tlearn: 0.1427781\ttotal: 1.35s\tremaining: 2.04s\n",
      "199:\tlearn: 0.1420728\ttotal: 1.36s\tremaining: 2.04s\n",
      "200:\tlearn: 0.1416002\ttotal: 1.36s\tremaining: 2.03s\n",
      "201:\tlearn: 0.1408991\ttotal: 1.37s\tremaining: 2.02s\n",
      "202:\tlearn: 0.1400888\ttotal: 1.38s\tremaining: 2.01s\n",
      "203:\tlearn: 0.1386741\ttotal: 1.38s\tremaining: 2s\n",
      "204:\tlearn: 0.1377937\ttotal: 1.39s\tremaining: 2s\n",
      "205:\tlearn: 0.1370744\ttotal: 1.39s\tremaining: 1.99s\n",
      "206:\tlearn: 0.1364164\ttotal: 1.4s\tremaining: 1.98s\n",
      "207:\tlearn: 0.1355340\ttotal: 1.4s\tremaining: 1.97s\n",
      "208:\tlearn: 0.1345865\ttotal: 1.41s\tremaining: 1.96s\n",
      "209:\tlearn: 0.1339403\ttotal: 1.41s\tremaining: 1.95s\n",
      "210:\tlearn: 0.1329884\ttotal: 1.42s\tremaining: 1.94s\n",
      "211:\tlearn: 0.1324206\ttotal: 1.42s\tremaining: 1.93s\n",
      "212:\tlearn: 0.1317092\ttotal: 1.42s\tremaining: 1.92s\n",
      "213:\tlearn: 0.1310019\ttotal: 1.43s\tremaining: 1.91s\n",
      "214:\tlearn: 0.1302842\ttotal: 1.43s\tremaining: 1.9s\n",
      "215:\tlearn: 0.1295046\ttotal: 1.44s\tremaining: 1.89s\n",
      "216:\tlearn: 0.1285481\ttotal: 1.45s\tremaining: 1.89s\n",
      "217:\tlearn: 0.1280138\ttotal: 1.46s\tremaining: 1.89s\n",
      "218:\tlearn: 0.1272234\ttotal: 1.47s\tremaining: 1.89s\n",
      "219:\tlearn: 0.1265544\ttotal: 1.48s\tremaining: 1.88s\n",
      "220:\tlearn: 0.1258451\ttotal: 1.49s\tremaining: 1.88s\n",
      "221:\tlearn: 0.1253019\ttotal: 1.5s\tremaining: 1.88s\n",
      "222:\tlearn: 0.1246147\ttotal: 1.51s\tremaining: 1.87s\n",
      "223:\tlearn: 0.1239423\ttotal: 1.52s\tremaining: 1.87s\n",
      "224:\tlearn: 0.1232771\ttotal: 1.53s\tremaining: 1.86s\n",
      "225:\tlearn: 0.1226337\ttotal: 1.53s\tremaining: 1.86s\n",
      "226:\tlearn: 0.1220235\ttotal: 1.54s\tremaining: 1.85s\n",
      "227:\tlearn: 0.1213475\ttotal: 1.54s\tremaining: 1.84s\n",
      "228:\tlearn: 0.1204567\ttotal: 1.55s\tremaining: 1.83s\n",
      "229:\tlearn: 0.1198572\ttotal: 1.55s\tremaining: 1.83s\n",
      "230:\tlearn: 0.1191917\ttotal: 1.56s\tremaining: 1.82s\n",
      "231:\tlearn: 0.1183482\ttotal: 1.56s\tremaining: 1.81s\n",
      "232:\tlearn: 0.1171619\ttotal: 1.57s\tremaining: 1.8s\n",
      "233:\tlearn: 0.1165861\ttotal: 1.57s\tremaining: 1.79s\n",
      "234:\tlearn: 0.1161314\ttotal: 1.58s\tremaining: 1.78s\n",
      "235:\tlearn: 0.1152589\ttotal: 1.58s\tremaining: 1.77s\n",
      "236:\tlearn: 0.1145195\ttotal: 1.59s\tremaining: 1.76s\n",
      "237:\tlearn: 0.1138809\ttotal: 1.59s\tremaining: 1.75s\n",
      "238:\tlearn: 0.1133002\ttotal: 1.6s\tremaining: 1.74s\n",
      "239:\tlearn: 0.1128195\ttotal: 1.6s\tremaining: 1.74s\n",
      "240:\tlearn: 0.1120766\ttotal: 1.61s\tremaining: 1.73s\n",
      "241:\tlearn: 0.1117308\ttotal: 1.62s\tremaining: 1.73s\n",
      "242:\tlearn: 0.1111950\ttotal: 1.63s\tremaining: 1.73s\n",
      "243:\tlearn: 0.1105524\ttotal: 1.64s\tremaining: 1.72s\n",
      "244:\tlearn: 0.1100768\ttotal: 1.65s\tremaining: 1.72s\n",
      "245:\tlearn: 0.1096031\ttotal: 1.66s\tremaining: 1.72s\n",
      "246:\tlearn: 0.1089821\ttotal: 1.67s\tremaining: 1.71s\n",
      "247:\tlearn: 0.1083608\ttotal: 1.68s\tremaining: 1.71s\n",
      "248:\tlearn: 0.1078339\ttotal: 1.69s\tremaining: 1.7s\n",
      "249:\tlearn: 0.1072425\ttotal: 1.7s\tremaining: 1.7s\n",
      "250:\tlearn: 0.1066327\ttotal: 1.71s\tremaining: 1.69s\n",
      "251:\tlearn: 0.1059629\ttotal: 1.71s\tremaining: 1.68s\n",
      "252:\tlearn: 0.1052972\ttotal: 1.72s\tremaining: 1.68s\n",
      "253:\tlearn: 0.1045839\ttotal: 1.72s\tremaining: 1.67s\n",
      "254:\tlearn: 0.1039448\ttotal: 1.73s\tremaining: 1.66s\n",
      "255:\tlearn: 0.1034920\ttotal: 1.73s\tremaining: 1.65s\n",
      "256:\tlearn: 0.1030650\ttotal: 1.74s\tremaining: 1.64s\n",
      "257:\tlearn: 0.1024729\ttotal: 1.74s\tremaining: 1.64s\n",
      "258:\tlearn: 0.1015817\ttotal: 1.75s\tremaining: 1.63s\n",
      "259:\tlearn: 0.1011120\ttotal: 1.75s\tremaining: 1.62s\n",
      "260:\tlearn: 0.1005673\ttotal: 1.76s\tremaining: 1.61s\n",
      "261:\tlearn: 0.1002179\ttotal: 1.76s\tremaining: 1.6s\n",
      "262:\tlearn: 0.0996853\ttotal: 1.77s\tremaining: 1.59s\n",
      "263:\tlearn: 0.0991291\ttotal: 1.77s\tremaining: 1.58s\n",
      "264:\tlearn: 0.0986683\ttotal: 1.78s\tremaining: 1.58s\n",
      "265:\tlearn: 0.0982391\ttotal: 1.79s\tremaining: 1.57s\n",
      "266:\tlearn: 0.0976947\ttotal: 1.8s\tremaining: 1.57s\n",
      "267:\tlearn: 0.0972620\ttotal: 1.81s\tremaining: 1.57s\n",
      "268:\tlearn: 0.0968523\ttotal: 1.82s\tremaining: 1.56s\n",
      "269:\tlearn: 0.0962319\ttotal: 1.83s\tremaining: 1.56s\n",
      "270:\tlearn: 0.0957105\ttotal: 1.84s\tremaining: 1.55s\n",
      "271:\tlearn: 0.0952949\ttotal: 1.85s\tremaining: 1.55s\n",
      "272:\tlearn: 0.0948023\ttotal: 1.86s\tremaining: 1.54s\n",
      "273:\tlearn: 0.0943679\ttotal: 1.87s\tremaining: 1.54s\n",
      "274:\tlearn: 0.0938477\ttotal: 1.88s\tremaining: 1.53s\n",
      "275:\tlearn: 0.0934915\ttotal: 1.88s\tremaining: 1.53s\n",
      "276:\tlearn: 0.0929331\ttotal: 1.89s\tremaining: 1.52s\n",
      "277:\tlearn: 0.0923185\ttotal: 1.89s\tremaining: 1.51s\n",
      "278:\tlearn: 0.0914580\ttotal: 1.9s\tremaining: 1.5s\n",
      "279:\tlearn: 0.0907645\ttotal: 1.9s\tremaining: 1.5s\n",
      "280:\tlearn: 0.0902289\ttotal: 1.91s\tremaining: 1.49s\n",
      "281:\tlearn: 0.0898206\ttotal: 1.91s\tremaining: 1.48s\n",
      "282:\tlearn: 0.0894393\ttotal: 1.92s\tremaining: 1.47s\n",
      "283:\tlearn: 0.0889712\ttotal: 1.92s\tremaining: 1.46s\n",
      "284:\tlearn: 0.0885675\ttotal: 1.93s\tremaining: 1.45s\n",
      "285:\tlearn: 0.0881777\ttotal: 1.93s\tremaining: 1.44s\n",
      "286:\tlearn: 0.0877596\ttotal: 1.93s\tremaining: 1.44s\n",
      "287:\tlearn: 0.0869939\ttotal: 1.94s\tremaining: 1.43s\n",
      "288:\tlearn: 0.0864818\ttotal: 1.94s\tremaining: 1.42s\n",
      "289:\tlearn: 0.0856250\ttotal: 1.95s\tremaining: 1.41s\n",
      "290:\tlearn: 0.0852126\ttotal: 1.95s\tremaining: 1.4s\n",
      "291:\tlearn: 0.0847869\ttotal: 1.96s\tremaining: 1.39s\n",
      "292:\tlearn: 0.0842618\ttotal: 1.96s\tremaining: 1.38s\n",
      "293:\tlearn: 0.0838068\ttotal: 1.96s\tremaining: 1.38s\n",
      "294:\tlearn: 0.0832879\ttotal: 1.97s\tremaining: 1.37s\n",
      "295:\tlearn: 0.0829441\ttotal: 1.97s\tremaining: 1.36s\n",
      "296:\tlearn: 0.0823405\ttotal: 1.98s\tremaining: 1.35s\n",
      "297:\tlearn: 0.0819568\ttotal: 1.99s\tremaining: 1.35s\n",
      "298:\tlearn: 0.0815127\ttotal: 2s\tremaining: 1.34s\n",
      "299:\tlearn: 0.0811494\ttotal: 2.01s\tremaining: 1.34s\n",
      "300:\tlearn: 0.0807328\ttotal: 2.02s\tremaining: 1.34s\n",
      "301:\tlearn: 0.0803559\ttotal: 2.03s\tremaining: 1.33s\n",
      "302:\tlearn: 0.0800869\ttotal: 2.04s\tremaining: 1.33s\n",
      "303:\tlearn: 0.0797204\ttotal: 2.05s\tremaining: 1.32s\n",
      "304:\tlearn: 0.0792494\ttotal: 2.06s\tremaining: 1.32s\n",
      "305:\tlearn: 0.0788793\ttotal: 2.06s\tremaining: 1.31s\n",
      "306:\tlearn: 0.0787415\ttotal: 2.07s\tremaining: 1.3s\n",
      "307:\tlearn: 0.0783404\ttotal: 2.08s\tremaining: 1.29s\n",
      "308:\tlearn: 0.0779856\ttotal: 2.08s\tremaining: 1.29s\n",
      "309:\tlearn: 0.0775722\ttotal: 2.09s\tremaining: 1.28s\n",
      "310:\tlearn: 0.0769905\ttotal: 2.09s\tremaining: 1.27s\n",
      "311:\tlearn: 0.0765903\ttotal: 2.1s\tremaining: 1.26s\n",
      "312:\tlearn: 0.0761963\ttotal: 2.1s\tremaining: 1.26s\n",
      "313:\tlearn: 0.0758342\ttotal: 2.11s\tremaining: 1.25s\n",
      "314:\tlearn: 0.0755159\ttotal: 2.11s\tremaining: 1.24s\n",
      "315:\tlearn: 0.0751407\ttotal: 2.12s\tremaining: 1.23s\n",
      "316:\tlearn: 0.0747724\ttotal: 2.12s\tremaining: 1.22s\n",
      "317:\tlearn: 0.0744139\ttotal: 2.13s\tremaining: 1.22s\n",
      "318:\tlearn: 0.0740920\ttotal: 2.13s\tremaining: 1.21s\n",
      "319:\tlearn: 0.0737961\ttotal: 2.13s\tremaining: 1.2s\n",
      "320:\tlearn: 0.0735163\ttotal: 2.14s\tremaining: 1.19s\n",
      "321:\tlearn: 0.0732366\ttotal: 2.15s\tremaining: 1.19s\n",
      "322:\tlearn: 0.0728170\ttotal: 2.16s\tremaining: 1.18s\n",
      "323:\tlearn: 0.0725167\ttotal: 2.17s\tremaining: 1.18s\n",
      "324:\tlearn: 0.0720234\ttotal: 2.18s\tremaining: 1.17s\n",
      "325:\tlearn: 0.0716449\ttotal: 2.19s\tremaining: 1.17s\n",
      "326:\tlearn: 0.0712954\ttotal: 2.2s\tremaining: 1.16s\n",
      "327:\tlearn: 0.0709376\ttotal: 2.21s\tremaining: 1.16s\n",
      "328:\tlearn: 0.0705406\ttotal: 2.22s\tremaining: 1.15s\n",
      "329:\tlearn: 0.0703664\ttotal: 2.23s\tremaining: 1.15s\n",
      "330:\tlearn: 0.0700392\ttotal: 2.24s\tremaining: 1.14s\n",
      "331:\tlearn: 0.0696167\ttotal: 2.24s\tremaining: 1.14s\n",
      "332:\tlearn: 0.0692819\ttotal: 2.25s\tremaining: 1.13s\n",
      "333:\tlearn: 0.0690013\ttotal: 2.25s\tremaining: 1.12s\n",
      "334:\tlearn: 0.0686616\ttotal: 2.26s\tremaining: 1.11s\n",
      "335:\tlearn: 0.0682609\ttotal: 2.27s\tremaining: 1.11s\n",
      "336:\tlearn: 0.0678757\ttotal: 2.27s\tremaining: 1.1s\n",
      "337:\tlearn: 0.0675920\ttotal: 2.28s\tremaining: 1.09s\n",
      "338:\tlearn: 0.0673250\ttotal: 2.28s\tremaining: 1.08s\n",
      "339:\tlearn: 0.0670134\ttotal: 2.29s\tremaining: 1.08s\n",
      "340:\tlearn: 0.0666869\ttotal: 2.29s\tremaining: 1.07s\n",
      "341:\tlearn: 0.0661904\ttotal: 2.29s\tremaining: 1.06s\n",
      "342:\tlearn: 0.0659128\ttotal: 2.3s\tremaining: 1.05s\n",
      "343:\tlearn: 0.0655592\ttotal: 2.3s\tremaining: 1.04s\n",
      "344:\tlearn: 0.0650899\ttotal: 2.31s\tremaining: 1.04s\n",
      "345:\tlearn: 0.0648243\ttotal: 2.31s\tremaining: 1.03s\n",
      "346:\tlearn: 0.0645255\ttotal: 2.32s\tremaining: 1.02s\n",
      "347:\tlearn: 0.0642383\ttotal: 2.32s\tremaining: 1.01s\n",
      "348:\tlearn: 0.0639459\ttotal: 2.33s\tremaining: 1.01s\n",
      "349:\tlearn: 0.0637239\ttotal: 2.33s\tremaining: 999ms\n",
      "350:\tlearn: 0.0634694\ttotal: 2.34s\tremaining: 992ms\n",
      "351:\tlearn: 0.0631743\ttotal: 2.34s\tremaining: 985ms\n",
      "352:\tlearn: 0.0628614\ttotal: 2.35s\tremaining: 979ms\n",
      "353:\tlearn: 0.0627185\ttotal: 2.36s\tremaining: 974ms\n",
      "354:\tlearn: 0.0622653\ttotal: 2.37s\tremaining: 968ms\n",
      "355:\tlearn: 0.0619955\ttotal: 2.38s\tremaining: 963ms\n",
      "356:\tlearn: 0.0616890\ttotal: 2.39s\tremaining: 957ms\n",
      "357:\tlearn: 0.0613579\ttotal: 2.4s\tremaining: 952ms\n",
      "358:\tlearn: 0.0610705\ttotal: 2.41s\tremaining: 946ms\n",
      "359:\tlearn: 0.0608115\ttotal: 2.42s\tremaining: 941ms\n",
      "360:\tlearn: 0.0605350\ttotal: 2.43s\tremaining: 935ms\n",
      "361:\tlearn: 0.0602338\ttotal: 2.43s\tremaining: 928ms\n",
      "362:\tlearn: 0.0599330\ttotal: 2.44s\tremaining: 921ms\n",
      "363:\tlearn: 0.0596130\ttotal: 2.45s\tremaining: 914ms\n",
      "364:\tlearn: 0.0592862\ttotal: 2.45s\tremaining: 907ms\n",
      "365:\tlearn: 0.0590284\ttotal: 2.46s\tremaining: 900ms\n",
      "366:\tlearn: 0.0586908\ttotal: 2.46s\tremaining: 893ms\n",
      "367:\tlearn: 0.0584593\ttotal: 2.47s\tremaining: 885ms\n",
      "368:\tlearn: 0.0581423\ttotal: 2.47s\tremaining: 878ms\n",
      "369:\tlearn: 0.0578555\ttotal: 2.48s\tremaining: 870ms\n",
      "370:\tlearn: 0.0576359\ttotal: 2.48s\tremaining: 863ms\n",
      "371:\tlearn: 0.0573422\ttotal: 2.49s\tremaining: 856ms\n",
      "372:\tlearn: 0.0569902\ttotal: 2.49s\tremaining: 848ms\n",
      "373:\tlearn: 0.0567136\ttotal: 2.5s\tremaining: 841ms\n",
      "374:\tlearn: 0.0565448\ttotal: 2.5s\tremaining: 834ms\n",
      "375:\tlearn: 0.0563092\ttotal: 2.5s\tremaining: 826ms\n",
      "376:\tlearn: 0.0561060\ttotal: 2.51s\tremaining: 819ms\n",
      "377:\tlearn: 0.0558519\ttotal: 2.51s\tremaining: 811ms\n",
      "378:\tlearn: 0.0554952\ttotal: 2.52s\tremaining: 804ms\n",
      "379:\tlearn: 0.0552885\ttotal: 2.52s\tremaining: 797ms\n",
      "380:\tlearn: 0.0550553\ttotal: 2.53s\tremaining: 789ms\n",
      "381:\tlearn: 0.0548275\ttotal: 2.53s\tremaining: 782ms\n",
      "382:\tlearn: 0.0543893\ttotal: 2.54s\tremaining: 775ms\n",
      "383:\tlearn: 0.0540349\ttotal: 2.54s\tremaining: 769ms\n",
      "384:\tlearn: 0.0537141\ttotal: 2.55s\tremaining: 763ms\n",
      "385:\tlearn: 0.0535162\ttotal: 2.56s\tremaining: 757ms\n",
      "386:\tlearn: 0.0532868\ttotal: 2.57s\tremaining: 752ms\n",
      "387:\tlearn: 0.0530510\ttotal: 2.58s\tremaining: 746ms\n",
      "388:\tlearn: 0.0528576\ttotal: 2.59s\tremaining: 740ms\n",
      "389:\tlearn: 0.0526077\ttotal: 2.6s\tremaining: 734ms\n",
      "390:\tlearn: 0.0523854\ttotal: 2.61s\tremaining: 729ms\n",
      "391:\tlearn: 0.0522122\ttotal: 2.62s\tremaining: 723ms\n",
      "392:\tlearn: 0.0519656\ttotal: 2.63s\tremaining: 716ms\n",
      "393:\tlearn: 0.0517183\ttotal: 2.63s\tremaining: 708ms\n",
      "394:\tlearn: 0.0514206\ttotal: 2.64s\tremaining: 701ms\n",
      "395:\tlearn: 0.0511977\ttotal: 2.64s\tremaining: 694ms\n",
      "396:\tlearn: 0.0509353\ttotal: 2.65s\tremaining: 686ms\n",
      "397:\tlearn: 0.0507115\ttotal: 2.65s\tremaining: 679ms\n",
      "398:\tlearn: 0.0504725\ttotal: 2.66s\tremaining: 673ms\n",
      "399:\tlearn: 0.0502404\ttotal: 2.67s\tremaining: 668ms\n",
      "400:\tlearn: 0.0499983\ttotal: 2.68s\tremaining: 662ms\n",
      "401:\tlearn: 0.0498166\ttotal: 2.69s\tremaining: 656ms\n",
      "402:\tlearn: 0.0494680\ttotal: 2.7s\tremaining: 650ms\n",
      "403:\tlearn: 0.0492703\ttotal: 2.71s\tremaining: 644ms\n",
      "404:\tlearn: 0.0489959\ttotal: 2.72s\tremaining: 638ms\n",
      "405:\tlearn: 0.0487446\ttotal: 2.73s\tremaining: 632ms\n",
      "406:\tlearn: 0.0485054\ttotal: 2.74s\tremaining: 626ms\n",
      "407:\tlearn: 0.0483229\ttotal: 2.74s\tremaining: 619ms\n",
      "408:\tlearn: 0.0481030\ttotal: 2.75s\tremaining: 612ms\n",
      "409:\tlearn: 0.0479113\ttotal: 2.76s\tremaining: 605ms\n",
      "410:\tlearn: 0.0477099\ttotal: 2.76s\tremaining: 598ms\n",
      "411:\tlearn: 0.0474314\ttotal: 2.77s\tremaining: 591ms\n",
      "412:\tlearn: 0.0472692\ttotal: 2.77s\tremaining: 584ms\n",
      "413:\tlearn: 0.0470860\ttotal: 2.78s\tremaining: 577ms\n",
      "414:\tlearn: 0.0468632\ttotal: 2.78s\tremaining: 570ms\n",
      "415:\tlearn: 0.0466934\ttotal: 2.79s\tremaining: 563ms\n",
      "416:\tlearn: 0.0463294\ttotal: 2.79s\tremaining: 556ms\n",
      "417:\tlearn: 0.0460868\ttotal: 2.8s\tremaining: 549ms\n",
      "418:\tlearn: 0.0459375\ttotal: 2.8s\tremaining: 542ms\n",
      "419:\tlearn: 0.0457416\ttotal: 2.81s\tremaining: 534ms\n",
      "420:\tlearn: 0.0455041\ttotal: 2.81s\tremaining: 527ms\n",
      "421:\tlearn: 0.0452984\ttotal: 2.81s\tremaining: 520ms\n",
      "422:\tlearn: 0.0450784\ttotal: 2.82s\tremaining: 513ms\n",
      "423:\tlearn: 0.0449317\ttotal: 2.82s\tremaining: 506ms\n",
      "424:\tlearn: 0.0447250\ttotal: 2.83s\tremaining: 499ms\n",
      "425:\tlearn: 0.0445121\ttotal: 2.84s\tremaining: 493ms\n",
      "426:\tlearn: 0.0443808\ttotal: 2.85s\tremaining: 487ms\n",
      "427:\tlearn: 0.0441829\ttotal: 2.86s\tremaining: 481ms\n",
      "428:\tlearn: 0.0439662\ttotal: 2.87s\tremaining: 474ms\n",
      "429:\tlearn: 0.0437914\ttotal: 2.88s\tremaining: 468ms\n",
      "430:\tlearn: 0.0435251\ttotal: 2.89s\tremaining: 462ms\n",
      "431:\tlearn: 0.0433339\ttotal: 2.9s\tremaining: 456ms\n",
      "432:\tlearn: 0.0430593\ttotal: 2.9s\tremaining: 450ms\n",
      "433:\tlearn: 0.0428662\ttotal: 2.91s\tremaining: 443ms\n",
      "434:\tlearn: 0.0426958\ttotal: 2.92s\tremaining: 436ms\n",
      "435:\tlearn: 0.0424511\ttotal: 2.92s\tremaining: 429ms\n",
      "436:\tlearn: 0.0422691\ttotal: 2.93s\tremaining: 422ms\n",
      "437:\tlearn: 0.0420730\ttotal: 2.94s\tremaining: 416ms\n",
      "438:\tlearn: 0.0418957\ttotal: 2.94s\tremaining: 409ms\n",
      "439:\tlearn: 0.0417493\ttotal: 2.95s\tremaining: 402ms\n",
      "440:\tlearn: 0.0415544\ttotal: 2.95s\tremaining: 395ms\n",
      "441:\tlearn: 0.0413766\ttotal: 2.96s\tremaining: 388ms\n",
      "442:\tlearn: 0.0412160\ttotal: 2.96s\tremaining: 381ms\n",
      "443:\tlearn: 0.0410263\ttotal: 2.96s\tremaining: 374ms\n",
      "444:\tlearn: 0.0408332\ttotal: 2.97s\tremaining: 367ms\n",
      "445:\tlearn: 0.0406052\ttotal: 2.97s\tremaining: 360ms\n",
      "446:\tlearn: 0.0404140\ttotal: 2.98s\tremaining: 353ms\n",
      "447:\tlearn: 0.0402474\ttotal: 2.98s\tremaining: 346ms\n",
      "448:\tlearn: 0.0400470\ttotal: 2.98s\tremaining: 339ms\n",
      "449:\tlearn: 0.0397310\ttotal: 3s\tremaining: 333ms\n",
      "450:\tlearn: 0.0396488\ttotal: 3s\tremaining: 327ms\n",
      "451:\tlearn: 0.0394781\ttotal: 3.01s\tremaining: 320ms\n",
      "452:\tlearn: 0.0393305\ttotal: 3.02s\tremaining: 314ms\n",
      "453:\tlearn: 0.0392437\ttotal: 3.03s\tremaining: 307ms\n",
      "454:\tlearn: 0.0389910\ttotal: 3.04s\tremaining: 301ms\n",
      "455:\tlearn: 0.0388267\ttotal: 3.05s\tremaining: 295ms\n",
      "456:\tlearn: 0.0386124\ttotal: 3.06s\tremaining: 288ms\n",
      "457:\tlearn: 0.0384885\ttotal: 3.07s\tremaining: 281ms\n",
      "458:\tlearn: 0.0382479\ttotal: 3.07s\tremaining: 275ms\n",
      "459:\tlearn: 0.0380824\ttotal: 3.08s\tremaining: 268ms\n",
      "460:\tlearn: 0.0378757\ttotal: 3.08s\tremaining: 261ms\n",
      "461:\tlearn: 0.0377181\ttotal: 3.09s\tremaining: 254ms\n",
      "462:\tlearn: 0.0375851\ttotal: 3.09s\tremaining: 247ms\n",
      "463:\tlearn: 0.0373763\ttotal: 3.1s\tremaining: 240ms\n",
      "464:\tlearn: 0.0371848\ttotal: 3.1s\tremaining: 234ms\n",
      "465:\tlearn: 0.0370077\ttotal: 3.11s\tremaining: 227ms\n",
      "466:\tlearn: 0.0368258\ttotal: 3.11s\tremaining: 220ms\n",
      "467:\tlearn: 0.0366681\ttotal: 3.11s\tremaining: 213ms\n",
      "468:\tlearn: 0.0364755\ttotal: 3.12s\tremaining: 206ms\n",
      "469:\tlearn: 0.0363276\ttotal: 3.12s\tremaining: 199ms\n",
      "470:\tlearn: 0.0361751\ttotal: 3.13s\tremaining: 193ms\n",
      "471:\tlearn: 0.0360120\ttotal: 3.14s\tremaining: 186ms\n",
      "472:\tlearn: 0.0358401\ttotal: 3.15s\tremaining: 180ms\n",
      "473:\tlearn: 0.0356921\ttotal: 3.16s\tremaining: 173ms\n",
      "474:\tlearn: 0.0355306\ttotal: 3.17s\tremaining: 167ms\n",
      "475:\tlearn: 0.0353387\ttotal: 3.18s\tremaining: 160ms\n",
      "476:\tlearn: 0.0350763\ttotal: 3.19s\tremaining: 154ms\n",
      "477:\tlearn: 0.0349224\ttotal: 3.2s\tremaining: 147ms\n",
      "478:\tlearn: 0.0348429\ttotal: 3.21s\tremaining: 141ms\n",
      "479:\tlearn: 0.0345833\ttotal: 3.22s\tremaining: 134ms\n",
      "480:\tlearn: 0.0344227\ttotal: 3.23s\tremaining: 127ms\n",
      "481:\tlearn: 0.0342325\ttotal: 3.23s\tremaining: 121ms\n",
      "482:\tlearn: 0.0341011\ttotal: 3.24s\tremaining: 114ms\n",
      "483:\tlearn: 0.0339632\ttotal: 3.25s\tremaining: 107ms\n",
      "484:\tlearn: 0.0338508\ttotal: 3.25s\tremaining: 101ms\n",
      "485:\tlearn: 0.0337226\ttotal: 3.25s\tremaining: 93.7ms\n",
      "486:\tlearn: 0.0335832\ttotal: 3.26s\tremaining: 87ms\n",
      "487:\tlearn: 0.0334244\ttotal: 3.26s\tremaining: 80.2ms\n",
      "488:\tlearn: 0.0332814\ttotal: 3.27s\tremaining: 73.5ms\n",
      "489:\tlearn: 0.0331336\ttotal: 3.27s\tremaining: 66.8ms\n",
      "490:\tlearn: 0.0329896\ttotal: 3.27s\tremaining: 60ms\n",
      "491:\tlearn: 0.0328577\ttotal: 3.28s\tremaining: 53.4ms\n",
      "492:\tlearn: 0.0326926\ttotal: 3.29s\tremaining: 46.7ms\n",
      "493:\tlearn: 0.0325477\ttotal: 3.29s\tremaining: 40ms\n",
      "494:\tlearn: 0.0323481\ttotal: 3.29s\tremaining: 33.3ms\n",
      "495:\tlearn: 0.0322472\ttotal: 3.3s\tremaining: 26.6ms\n",
      "496:\tlearn: 0.0321011\ttotal: 3.3s\tremaining: 19.9ms\n",
      "497:\tlearn: 0.0319669\ttotal: 3.31s\tremaining: 13.3ms\n",
      "498:\tlearn: 0.0317942\ttotal: 3.32s\tremaining: 6.66ms\n",
      "499:\tlearn: 0.0316519\ttotal: 3.33s\tremaining: 0us\n",
      "0:\tlearn: 0.6396040\ttotal: 11.1ms\tremaining: 5.56s\n",
      "1:\tlearn: 0.5870003\ttotal: 17.5ms\tremaining: 4.35s\n",
      "2:\tlearn: 0.5470720\ttotal: 23.6ms\tremaining: 3.92s\n",
      "3:\tlearn: 0.4999242\ttotal: 29.8ms\tremaining: 3.69s\n",
      "4:\tlearn: 0.4637679\ttotal: 35.9ms\tremaining: 3.55s\n",
      "5:\tlearn: 0.4366061\ttotal: 42.1ms\tremaining: 3.46s\n",
      "6:\tlearn: 0.4071259\ttotal: 47.2ms\tremaining: 3.32s\n",
      "7:\tlearn: 0.3802217\ttotal: 51.7ms\tremaining: 3.18s\n",
      "8:\tlearn: 0.3549765\ttotal: 56.3ms\tremaining: 3.07s\n",
      "9:\tlearn: 0.3306239\ttotal: 60.8ms\tremaining: 2.98s\n",
      "10:\tlearn: 0.3093299\ttotal: 65.4ms\tremaining: 2.91s\n",
      "11:\tlearn: 0.2879902\ttotal: 70.1ms\tremaining: 2.85s\n",
      "12:\tlearn: 0.2690476\ttotal: 74.6ms\tremaining: 2.79s\n",
      "13:\tlearn: 0.2480869\ttotal: 78.7ms\tremaining: 2.73s\n",
      "14:\tlearn: 0.2342327\ttotal: 82.9ms\tremaining: 2.68s\n",
      "15:\tlearn: 0.2213591\ttotal: 87.1ms\tremaining: 2.63s\n",
      "16:\tlearn: 0.2047268\ttotal: 91.4ms\tremaining: 2.6s\n",
      "17:\tlearn: 0.1902367\ttotal: 95.2ms\tremaining: 2.55s\n",
      "18:\tlearn: 0.1838166\ttotal: 105ms\tremaining: 2.65s\n",
      "19:\tlearn: 0.1740807\ttotal: 114ms\tremaining: 2.75s\n",
      "20:\tlearn: 0.1647789\ttotal: 124ms\tremaining: 2.83s\n",
      "21:\tlearn: 0.1547091\ttotal: 134ms\tremaining: 2.91s\n",
      "22:\tlearn: 0.1475405\ttotal: 143ms\tremaining: 2.97s\n",
      "23:\tlearn: 0.1383323\ttotal: 153ms\tremaining: 3.04s\n",
      "24:\tlearn: 0.1300121\ttotal: 163ms\tremaining: 3.1s\n",
      "25:\tlearn: 0.1214402\ttotal: 173ms\tremaining: 3.15s\n",
      "26:\tlearn: 0.1142833\ttotal: 183ms\tremaining: 3.2s\n",
      "27:\tlearn: 0.1079195\ttotal: 189ms\tremaining: 3.19s\n",
      "28:\tlearn: 0.1022836\ttotal: 196ms\tremaining: 3.19s\n",
      "29:\tlearn: 0.0967197\ttotal: 204ms\tremaining: 3.2s\n",
      "30:\tlearn: 0.0928019\ttotal: 209ms\tremaining: 3.15s\n",
      "31:\tlearn: 0.0875678\ttotal: 212ms\tremaining: 3.1s\n",
      "32:\tlearn: 0.0843610\ttotal: 216ms\tremaining: 3.06s\n",
      "33:\tlearn: 0.0803772\ttotal: 220ms\tremaining: 3.01s\n",
      "34:\tlearn: 0.0730442\ttotal: 223ms\tremaining: 2.96s\n",
      "35:\tlearn: 0.0686520\ttotal: 226ms\tremaining: 2.92s\n",
      "36:\tlearn: 0.0647654\ttotal: 231ms\tremaining: 2.89s\n",
      "37:\tlearn: 0.0617568\ttotal: 235ms\tremaining: 2.86s\n",
      "38:\tlearn: 0.0590436\ttotal: 240ms\tremaining: 2.83s\n",
      "39:\tlearn: 0.0551047\ttotal: 244ms\tremaining: 2.81s\n",
      "40:\tlearn: 0.0520821\ttotal: 249ms\tremaining: 2.79s\n",
      "41:\tlearn: 0.0500338\ttotal: 253ms\tremaining: 2.76s\n",
      "42:\tlearn: 0.0479286\ttotal: 258ms\tremaining: 2.74s\n",
      "43:\tlearn: 0.0463423\ttotal: 265ms\tremaining: 2.75s\n",
      "44:\tlearn: 0.0436206\ttotal: 275ms\tremaining: 2.78s\n",
      "45:\tlearn: 0.0420671\ttotal: 285ms\tremaining: 2.81s\n",
      "46:\tlearn: 0.0396897\ttotal: 295ms\tremaining: 2.84s\n",
      "47:\tlearn: 0.0369105\ttotal: 305ms\tremaining: 2.87s\n",
      "48:\tlearn: 0.0350733\ttotal: 314ms\tremaining: 2.89s\n",
      "49:\tlearn: 0.0342968\ttotal: 324ms\tremaining: 2.92s\n",
      "50:\tlearn: 0.0318400\ttotal: 334ms\tremaining: 2.94s\n",
      "51:\tlearn: 0.0295695\ttotal: 343ms\tremaining: 2.96s\n",
      "52:\tlearn: 0.0283486\ttotal: 352ms\tremaining: 2.97s\n",
      "53:\tlearn: 0.0265243\ttotal: 360ms\tremaining: 2.98s\n",
      "54:\tlearn: 0.0253747\ttotal: 367ms\tremaining: 2.97s\n",
      "55:\tlearn: 0.0243440\ttotal: 374ms\tremaining: 2.96s\n",
      "56:\tlearn: 0.0237031\ttotal: 379ms\tremaining: 2.94s\n",
      "57:\tlearn: 0.0227383\ttotal: 383ms\tremaining: 2.92s\n",
      "58:\tlearn: 0.0222673\ttotal: 388ms\tremaining: 2.9s\n",
      "59:\tlearn: 0.0221385\ttotal: 393ms\tremaining: 2.88s\n",
      "60:\tlearn: 0.0215250\ttotal: 397ms\tremaining: 2.86s\n",
      "61:\tlearn: 0.0209954\ttotal: 402ms\tremaining: 2.84s\n",
      "62:\tlearn: 0.0201534\ttotal: 406ms\tremaining: 2.82s\n",
      "63:\tlearn: 0.0196312\ttotal: 411ms\tremaining: 2.8s\n",
      "64:\tlearn: 0.0192158\ttotal: 415ms\tremaining: 2.78s\n",
      "65:\tlearn: 0.0181737\ttotal: 420ms\tremaining: 2.76s\n",
      "66:\tlearn: 0.0177223\ttotal: 424ms\tremaining: 2.74s\n",
      "67:\tlearn: 0.0167482\ttotal: 428ms\tremaining: 2.72s\n",
      "68:\tlearn: 0.0166546\ttotal: 433ms\tremaining: 2.7s\n",
      "69:\tlearn: 0.0157738\ttotal: 442ms\tremaining: 2.72s\n",
      "70:\tlearn: 0.0151717\ttotal: 452ms\tremaining: 2.73s\n",
      "71:\tlearn: 0.0143709\ttotal: 462ms\tremaining: 2.74s\n",
      "72:\tlearn: 0.0140264\ttotal: 471ms\tremaining: 2.76s\n",
      "73:\tlearn: 0.0140263\ttotal: 480ms\tremaining: 2.77s\n",
      "74:\tlearn: 0.0139584\ttotal: 490ms\tremaining: 2.78s\n",
      "75:\tlearn: 0.0136152\ttotal: 500ms\tremaining: 2.79s\n",
      "76:\tlearn: 0.0131774\ttotal: 510ms\tremaining: 2.8s\n",
      "77:\tlearn: 0.0127305\ttotal: 519ms\tremaining: 2.81s\n",
      "78:\tlearn: 0.0123182\ttotal: 527ms\tremaining: 2.81s\n",
      "79:\tlearn: 0.0115910\ttotal: 533ms\tremaining: 2.8s\n",
      "80:\tlearn: 0.0112952\ttotal: 539ms\tremaining: 2.79s\n",
      "81:\tlearn: 0.0111101\ttotal: 548ms\tremaining: 2.79s\n",
      "82:\tlearn: 0.0106314\ttotal: 555ms\tremaining: 2.79s\n",
      "83:\tlearn: 0.0105702\ttotal: 560ms\tremaining: 2.77s\n",
      "84:\tlearn: 0.0100951\ttotal: 565ms\tremaining: 2.76s\n",
      "85:\tlearn: 0.0099642\ttotal: 570ms\tremaining: 2.74s\n",
      "86:\tlearn: 0.0092688\ttotal: 574ms\tremaining: 2.73s\n",
      "87:\tlearn: 0.0089666\ttotal: 578ms\tremaining: 2.71s\n",
      "88:\tlearn: 0.0087218\ttotal: 583ms\tremaining: 2.69s\n",
      "89:\tlearn: 0.0083656\ttotal: 587ms\tremaining: 2.67s\n",
      "90:\tlearn: 0.0078381\ttotal: 591ms\tremaining: 2.65s\n",
      "91:\tlearn: 0.0076909\ttotal: 595ms\tremaining: 2.64s\n",
      "92:\tlearn: 0.0073641\ttotal: 599ms\tremaining: 2.62s\n",
      "93:\tlearn: 0.0069531\ttotal: 604ms\tremaining: 2.61s\n",
      "94:\tlearn: 0.0066308\ttotal: 608ms\tremaining: 2.59s\n",
      "95:\tlearn: 0.0064740\ttotal: 618ms\tremaining: 2.6s\n",
      "96:\tlearn: 0.0064735\ttotal: 627ms\tremaining: 2.6s\n",
      "97:\tlearn: 0.0063162\ttotal: 637ms\tremaining: 2.61s\n",
      "98:\tlearn: 0.0059971\ttotal: 647ms\tremaining: 2.62s\n",
      "99:\tlearn: 0.0059964\ttotal: 656ms\tremaining: 2.62s\n",
      "100:\tlearn: 0.0058641\ttotal: 666ms\tremaining: 2.63s\n",
      "101:\tlearn: 0.0058641\ttotal: 675ms\tremaining: 2.63s\n",
      "102:\tlearn: 0.0058639\ttotal: 684ms\tremaining: 2.64s\n",
      "103:\tlearn: 0.0058622\ttotal: 694ms\tremaining: 2.64s\n",
      "104:\tlearn: 0.0058622\ttotal: 701ms\tremaining: 2.64s\n",
      "105:\tlearn: 0.0058427\ttotal: 708ms\tremaining: 2.63s\n",
      "106:\tlearn: 0.0058425\ttotal: 714ms\tremaining: 2.62s\n",
      "107:\tlearn: 0.0058419\ttotal: 720ms\tremaining: 2.61s\n",
      "108:\tlearn: 0.0058417\ttotal: 725ms\tremaining: 2.6s\n",
      "109:\tlearn: 0.0058412\ttotal: 730ms\tremaining: 2.59s\n",
      "110:\tlearn: 0.0058387\ttotal: 736ms\tremaining: 2.58s\n",
      "111:\tlearn: 0.0058386\ttotal: 739ms\tremaining: 2.56s\n",
      "112:\tlearn: 0.0058384\ttotal: 742ms\tremaining: 2.54s\n",
      "113:\tlearn: 0.0057400\ttotal: 747ms\tremaining: 2.53s\n",
      "114:\tlearn: 0.0057398\ttotal: 751ms\tremaining: 2.51s\n",
      "115:\tlearn: 0.0057398\ttotal: 755ms\tremaining: 2.5s\n",
      "116:\tlearn: 0.0057397\ttotal: 759ms\tremaining: 2.48s\n",
      "117:\tlearn: 0.0057395\ttotal: 762ms\tremaining: 2.47s\n",
      "118:\tlearn: 0.0057394\ttotal: 766ms\tremaining: 2.45s\n",
      "119:\tlearn: 0.0057394\ttotal: 770ms\tremaining: 2.44s\n",
      "120:\tlearn: 0.0057090\ttotal: 775ms\tremaining: 2.43s\n",
      "121:\tlearn: 0.0055953\ttotal: 785ms\tremaining: 2.43s\n",
      "122:\tlearn: 0.0055045\ttotal: 795ms\tremaining: 2.44s\n",
      "123:\tlearn: 0.0053445\ttotal: 806ms\tremaining: 2.44s\n",
      "124:\tlearn: 0.0053445\ttotal: 815ms\tremaining: 2.44s\n",
      "125:\tlearn: 0.0052359\ttotal: 825ms\tremaining: 2.45s\n",
      "126:\tlearn: 0.0052359\ttotal: 834ms\tremaining: 2.45s\n",
      "127:\tlearn: 0.0050240\ttotal: 840ms\tremaining: 2.44s\n",
      "128:\tlearn: 0.0050213\ttotal: 846ms\tremaining: 2.43s\n",
      "129:\tlearn: 0.0048606\ttotal: 853ms\tremaining: 2.43s\n",
      "130:\tlearn: 0.0047114\ttotal: 859ms\tremaining: 2.42s\n",
      "131:\tlearn: 0.0047113\ttotal: 865ms\tremaining: 2.41s\n",
      "132:\tlearn: 0.0045307\ttotal: 870ms\tremaining: 2.4s\n",
      "133:\tlearn: 0.0045307\ttotal: 874ms\tremaining: 2.39s\n",
      "134:\tlearn: 0.0045306\ttotal: 879ms\tremaining: 2.38s\n",
      "135:\tlearn: 0.0045304\ttotal: 883ms\tremaining: 2.36s\n",
      "136:\tlearn: 0.0045304\ttotal: 888ms\tremaining: 2.35s\n",
      "137:\tlearn: 0.0045297\ttotal: 892ms\tremaining: 2.34s\n",
      "138:\tlearn: 0.0045255\ttotal: 897ms\tremaining: 2.33s\n",
      "139:\tlearn: 0.0045177\ttotal: 901ms\tremaining: 2.32s\n",
      "140:\tlearn: 0.0045140\ttotal: 905ms\tremaining: 2.3s\n",
      "141:\tlearn: 0.0043690\ttotal: 909ms\tremaining: 2.29s\n",
      "142:\tlearn: 0.0043690\ttotal: 913ms\tremaining: 2.28s\n",
      "143:\tlearn: 0.0043690\ttotal: 918ms\tremaining: 2.27s\n",
      "144:\tlearn: 0.0043690\ttotal: 927ms\tremaining: 2.27s\n",
      "145:\tlearn: 0.0043689\ttotal: 937ms\tremaining: 2.27s\n",
      "146:\tlearn: 0.0043689\ttotal: 946ms\tremaining: 2.27s\n",
      "147:\tlearn: 0.0043687\ttotal: 955ms\tremaining: 2.27s\n",
      "148:\tlearn: 0.0043681\ttotal: 965ms\tremaining: 2.27s\n",
      "149:\tlearn: 0.0043680\ttotal: 974ms\tremaining: 2.27s\n",
      "150:\tlearn: 0.0043680\ttotal: 983ms\tremaining: 2.27s\n",
      "151:\tlearn: 0.0043680\ttotal: 993ms\tremaining: 2.27s\n",
      "152:\tlearn: 0.0043679\ttotal: 1s\tremaining: 2.27s\n",
      "153:\tlearn: 0.0043679\ttotal: 1.01s\tremaining: 2.26s\n",
      "154:\tlearn: 0.0043678\ttotal: 1.01s\tremaining: 2.25s\n",
      "155:\tlearn: 0.0043678\ttotal: 1.02s\tremaining: 2.25s\n",
      "156:\tlearn: 0.0043677\ttotal: 1.02s\tremaining: 2.24s\n",
      "157:\tlearn: 0.0043677\ttotal: 1.03s\tremaining: 2.23s\n",
      "158:\tlearn: 0.0043677\ttotal: 1.03s\tremaining: 2.22s\n",
      "159:\tlearn: 0.0043676\ttotal: 1.04s\tremaining: 2.21s\n",
      "160:\tlearn: 0.0043674\ttotal: 1.04s\tremaining: 2.2s\n",
      "161:\tlearn: 0.0043674\ttotal: 1.05s\tremaining: 2.19s\n",
      "162:\tlearn: 0.0043673\ttotal: 1.05s\tremaining: 2.17s\n",
      "163:\tlearn: 0.0043673\ttotal: 1.06s\tremaining: 2.16s\n",
      "164:\tlearn: 0.0043673\ttotal: 1.06s\tremaining: 2.15s\n",
      "165:\tlearn: 0.0043671\ttotal: 1.06s\tremaining: 2.14s\n",
      "166:\tlearn: 0.0043670\ttotal: 1.07s\tremaining: 2.13s\n",
      "167:\tlearn: 0.0043669\ttotal: 1.07s\tremaining: 2.12s\n",
      "168:\tlearn: 0.0043670\ttotal: 1.08s\tremaining: 2.11s\n",
      "169:\tlearn: 0.0042538\ttotal: 1.08s\tremaining: 2.1s\n",
      "170:\tlearn: 0.0042528\ttotal: 1.09s\tremaining: 2.09s\n",
      "171:\tlearn: 0.0042528\ttotal: 1.1s\tremaining: 2.1s\n",
      "172:\tlearn: 0.0042527\ttotal: 1.11s\tremaining: 2.09s\n",
      "173:\tlearn: 0.0042526\ttotal: 1.12s\tremaining: 2.09s\n",
      "174:\tlearn: 0.0042526\ttotal: 1.13s\tremaining: 2.09s\n",
      "175:\tlearn: 0.0042526\ttotal: 1.14s\tremaining: 2.09s\n",
      "176:\tlearn: 0.0042524\ttotal: 1.15s\tremaining: 2.09s\n",
      "177:\tlearn: 0.0042517\ttotal: 1.15s\tremaining: 2.09s\n",
      "178:\tlearn: 0.0042511\ttotal: 1.16s\tremaining: 2.09s\n",
      "179:\tlearn: 0.0040883\ttotal: 1.17s\tremaining: 2.09s\n",
      "180:\tlearn: 0.0039399\ttotal: 1.18s\tremaining: 2.08s\n",
      "181:\tlearn: 0.0039397\ttotal: 1.19s\tremaining: 2.07s\n",
      "182:\tlearn: 0.0038561\ttotal: 1.19s\tremaining: 2.06s\n",
      "183:\tlearn: 0.0037439\ttotal: 1.2s\tremaining: 2.06s\n",
      "184:\tlearn: 0.0037436\ttotal: 1.2s\tremaining: 2.05s\n",
      "185:\tlearn: 0.0037436\ttotal: 1.21s\tremaining: 2.04s\n",
      "186:\tlearn: 0.0037397\ttotal: 1.21s\tremaining: 2.03s\n",
      "187:\tlearn: 0.0037397\ttotal: 1.22s\tremaining: 2.02s\n",
      "188:\tlearn: 0.0037393\ttotal: 1.22s\tremaining: 2.01s\n",
      "189:\tlearn: 0.0037393\ttotal: 1.22s\tremaining: 2s\n",
      "190:\tlearn: 0.0036825\ttotal: 1.23s\tremaining: 1.99s\n",
      "191:\tlearn: 0.0036821\ttotal: 1.23s\tremaining: 1.98s\n",
      "192:\tlearn: 0.0036821\ttotal: 1.24s\tremaining: 1.97s\n",
      "193:\tlearn: 0.0036815\ttotal: 1.24s\tremaining: 1.96s\n",
      "194:\tlearn: 0.0035850\ttotal: 1.25s\tremaining: 1.95s\n",
      "195:\tlearn: 0.0035848\ttotal: 1.25s\tremaining: 1.94s\n",
      "196:\tlearn: 0.0035847\ttotal: 1.25s\tremaining: 1.93s\n",
      "197:\tlearn: 0.0035847\ttotal: 1.26s\tremaining: 1.92s\n",
      "198:\tlearn: 0.0035846\ttotal: 1.26s\tremaining: 1.91s\n",
      "199:\tlearn: 0.0035846\ttotal: 1.27s\tremaining: 1.91s\n",
      "200:\tlearn: 0.0035081\ttotal: 1.28s\tremaining: 1.91s\n",
      "201:\tlearn: 0.0035081\ttotal: 1.29s\tremaining: 1.91s\n",
      "202:\tlearn: 0.0035081\ttotal: 1.3s\tremaining: 1.91s\n",
      "203:\tlearn: 0.0035080\ttotal: 1.31s\tremaining: 1.9s\n",
      "204:\tlearn: 0.0033611\ttotal: 1.32s\tremaining: 1.9s\n",
      "205:\tlearn: 0.0033605\ttotal: 1.33s\tremaining: 1.9s\n",
      "206:\tlearn: 0.0033602\ttotal: 1.34s\tremaining: 1.9s\n",
      "207:\tlearn: 0.0032226\ttotal: 1.35s\tremaining: 1.89s\n",
      "208:\tlearn: 0.0030869\ttotal: 1.36s\tremaining: 1.89s\n",
      "209:\tlearn: 0.0029739\ttotal: 1.36s\tremaining: 1.88s\n",
      "210:\tlearn: 0.0028733\ttotal: 1.37s\tremaining: 1.87s\n",
      "211:\tlearn: 0.0027706\ttotal: 1.37s\tremaining: 1.86s\n",
      "212:\tlearn: 0.0027706\ttotal: 1.38s\tremaining: 1.85s\n",
      "213:\tlearn: 0.0027706\ttotal: 1.38s\tremaining: 1.84s\n",
      "214:\tlearn: 0.0027706\ttotal: 1.38s\tremaining: 1.83s\n",
      "215:\tlearn: 0.0027705\ttotal: 1.39s\tremaining: 1.83s\n",
      "216:\tlearn: 0.0027706\ttotal: 1.39s\tremaining: 1.82s\n",
      "217:\tlearn: 0.0027706\ttotal: 1.4s\tremaining: 1.81s\n",
      "218:\tlearn: 0.0027704\ttotal: 1.4s\tremaining: 1.8s\n",
      "219:\tlearn: 0.0027703\ttotal: 1.41s\tremaining: 1.79s\n",
      "220:\tlearn: 0.0027703\ttotal: 1.41s\tremaining: 1.78s\n",
      "221:\tlearn: 0.0027702\ttotal: 1.41s\tremaining: 1.77s\n",
      "222:\tlearn: 0.0027702\ttotal: 1.42s\tremaining: 1.76s\n",
      "223:\tlearn: 0.0027702\ttotal: 1.42s\tremaining: 1.75s\n",
      "224:\tlearn: 0.0027701\ttotal: 1.43s\tremaining: 1.74s\n",
      "225:\tlearn: 0.0027701\ttotal: 1.43s\tremaining: 1.74s\n",
      "226:\tlearn: 0.0027699\ttotal: 1.44s\tremaining: 1.73s\n",
      "227:\tlearn: 0.0027699\ttotal: 1.45s\tremaining: 1.73s\n",
      "228:\tlearn: 0.0027698\ttotal: 1.46s\tremaining: 1.73s\n",
      "229:\tlearn: 0.0027699\ttotal: 1.47s\tremaining: 1.72s\n",
      "230:\tlearn: 0.0027698\ttotal: 1.47s\tremaining: 1.71s\n",
      "231:\tlearn: 0.0027693\ttotal: 1.48s\tremaining: 1.71s\n",
      "232:\tlearn: 0.0027692\ttotal: 1.48s\tremaining: 1.7s\n",
      "233:\tlearn: 0.0027692\ttotal: 1.49s\tremaining: 1.69s\n",
      "234:\tlearn: 0.0027692\ttotal: 1.49s\tremaining: 1.68s\n",
      "235:\tlearn: 0.0027691\ttotal: 1.5s\tremaining: 1.67s\n",
      "236:\tlearn: 0.0027691\ttotal: 1.5s\tremaining: 1.66s\n",
      "237:\tlearn: 0.0027690\ttotal: 1.5s\tremaining: 1.66s\n",
      "238:\tlearn: 0.0027689\ttotal: 1.51s\tremaining: 1.65s\n",
      "239:\tlearn: 0.0027689\ttotal: 1.51s\tremaining: 1.64s\n",
      "240:\tlearn: 0.0027689\ttotal: 1.52s\tremaining: 1.63s\n",
      "241:\tlearn: 0.0027689\ttotal: 1.52s\tremaining: 1.62s\n",
      "242:\tlearn: 0.0027688\ttotal: 1.53s\tremaining: 1.61s\n",
      "243:\tlearn: 0.0027687\ttotal: 1.53s\tremaining: 1.61s\n",
      "244:\tlearn: 0.0027682\ttotal: 1.53s\tremaining: 1.6s\n",
      "245:\tlearn: 0.0027682\ttotal: 1.54s\tremaining: 1.59s\n",
      "246:\tlearn: 0.0027681\ttotal: 1.54s\tremaining: 1.58s\n",
      "247:\tlearn: 0.0027681\ttotal: 1.55s\tremaining: 1.57s\n",
      "248:\tlearn: 0.0027681\ttotal: 1.55s\tremaining: 1.56s\n",
      "249:\tlearn: 0.0027681\ttotal: 1.56s\tremaining: 1.56s\n",
      "250:\tlearn: 0.0027678\ttotal: 1.56s\tremaining: 1.55s\n",
      "251:\tlearn: 0.0026522\ttotal: 1.57s\tremaining: 1.54s\n",
      "252:\tlearn: 0.0025164\ttotal: 1.57s\tremaining: 1.53s\n",
      "253:\tlearn: 0.0025164\ttotal: 1.58s\tremaining: 1.53s\n",
      "254:\tlearn: 0.0025164\ttotal: 1.58s\tremaining: 1.52s\n",
      "255:\tlearn: 0.0025164\ttotal: 1.58s\tremaining: 1.51s\n",
      "256:\tlearn: 0.0025164\ttotal: 1.59s\tremaining: 1.5s\n",
      "257:\tlearn: 0.0025164\ttotal: 1.59s\tremaining: 1.49s\n",
      "258:\tlearn: 0.0025159\ttotal: 1.6s\tremaining: 1.49s\n",
      "259:\tlearn: 0.0025153\ttotal: 1.6s\tremaining: 1.48s\n",
      "260:\tlearn: 0.0025149\ttotal: 1.61s\tremaining: 1.47s\n",
      "261:\tlearn: 0.0025148\ttotal: 1.62s\tremaining: 1.47s\n",
      "262:\tlearn: 0.0025146\ttotal: 1.62s\tremaining: 1.46s\n",
      "263:\tlearn: 0.0025145\ttotal: 1.63s\tremaining: 1.45s\n",
      "264:\tlearn: 0.0024786\ttotal: 1.63s\tremaining: 1.45s\n",
      "265:\tlearn: 0.0024780\ttotal: 1.64s\tremaining: 1.44s\n",
      "266:\tlearn: 0.0024780\ttotal: 1.65s\tremaining: 1.44s\n",
      "267:\tlearn: 0.0024780\ttotal: 1.65s\tremaining: 1.43s\n",
      "268:\tlearn: 0.0024779\ttotal: 1.66s\tremaining: 1.42s\n",
      "269:\tlearn: 0.0024779\ttotal: 1.66s\tremaining: 1.42s\n",
      "270:\tlearn: 0.0024772\ttotal: 1.67s\tremaining: 1.41s\n",
      "271:\tlearn: 0.0024773\ttotal: 1.68s\tremaining: 1.4s\n",
      "272:\tlearn: 0.0024773\ttotal: 1.68s\tremaining: 1.4s\n",
      "273:\tlearn: 0.0024771\ttotal: 1.69s\tremaining: 1.4s\n",
      "274:\tlearn: 0.0024771\ttotal: 1.7s\tremaining: 1.39s\n",
      "275:\tlearn: 0.0024771\ttotal: 1.71s\tremaining: 1.39s\n",
      "276:\tlearn: 0.0024771\ttotal: 1.72s\tremaining: 1.38s\n",
      "277:\tlearn: 0.0024770\ttotal: 1.73s\tremaining: 1.38s\n",
      "278:\tlearn: 0.0024770\ttotal: 1.74s\tremaining: 1.38s\n",
      "279:\tlearn: 0.0024770\ttotal: 1.75s\tremaining: 1.37s\n",
      "280:\tlearn: 0.0024759\ttotal: 1.76s\tremaining: 1.37s\n",
      "281:\tlearn: 0.0024758\ttotal: 1.76s\tremaining: 1.36s\n",
      "282:\tlearn: 0.0024752\ttotal: 1.76s\tremaining: 1.35s\n",
      "283:\tlearn: 0.0024752\ttotal: 1.77s\tremaining: 1.35s\n",
      "284:\tlearn: 0.0024751\ttotal: 1.77s\tremaining: 1.34s\n",
      "285:\tlearn: 0.0024723\ttotal: 1.78s\tremaining: 1.33s\n",
      "286:\tlearn: 0.0024723\ttotal: 1.78s\tremaining: 1.32s\n",
      "287:\tlearn: 0.0024695\ttotal: 1.79s\tremaining: 1.32s\n",
      "288:\tlearn: 0.0024692\ttotal: 1.79s\tremaining: 1.31s\n",
      "289:\tlearn: 0.0024692\ttotal: 1.8s\tremaining: 1.3s\n",
      "290:\tlearn: 0.0024680\ttotal: 1.8s\tremaining: 1.29s\n",
      "291:\tlearn: 0.0024678\ttotal: 1.8s\tremaining: 1.28s\n",
      "292:\tlearn: 0.0024672\ttotal: 1.81s\tremaining: 1.28s\n",
      "293:\tlearn: 0.0024666\ttotal: 1.81s\tremaining: 1.27s\n",
      "294:\tlearn: 0.0024666\ttotal: 1.82s\tremaining: 1.26s\n",
      "295:\tlearn: 0.0024638\ttotal: 1.83s\tremaining: 1.26s\n",
      "296:\tlearn: 0.0024638\ttotal: 1.84s\tremaining: 1.25s\n",
      "297:\tlearn: 0.0024637\ttotal: 1.84s\tremaining: 1.25s\n",
      "298:\tlearn: 0.0024636\ttotal: 1.85s\tremaining: 1.24s\n",
      "299:\tlearn: 0.0024636\ttotal: 1.85s\tremaining: 1.24s\n",
      "300:\tlearn: 0.0024636\ttotal: 1.86s\tremaining: 1.23s\n",
      "301:\tlearn: 0.0024634\ttotal: 1.86s\tremaining: 1.22s\n",
      "302:\tlearn: 0.0024634\ttotal: 1.87s\tremaining: 1.22s\n",
      "303:\tlearn: 0.0024629\ttotal: 1.87s\tremaining: 1.21s\n",
      "304:\tlearn: 0.0024625\ttotal: 1.88s\tremaining: 1.2s\n",
      "305:\tlearn: 0.0024617\ttotal: 1.88s\tremaining: 1.2s\n",
      "306:\tlearn: 0.0024431\ttotal: 1.89s\tremaining: 1.19s\n",
      "307:\tlearn: 0.0024430\ttotal: 1.9s\tremaining: 1.18s\n",
      "308:\tlearn: 0.0024427\ttotal: 1.9s\tremaining: 1.17s\n",
      "309:\tlearn: 0.0024427\ttotal: 1.9s\tremaining: 1.17s\n",
      "310:\tlearn: 0.0024424\ttotal: 1.91s\tremaining: 1.16s\n",
      "311:\tlearn: 0.0024423\ttotal: 1.91s\tremaining: 1.15s\n",
      "312:\tlearn: 0.0024411\ttotal: 1.92s\tremaining: 1.15s\n",
      "313:\tlearn: 0.0024411\ttotal: 1.92s\tremaining: 1.14s\n",
      "314:\tlearn: 0.0024406\ttotal: 1.93s\tremaining: 1.13s\n",
      "315:\tlearn: 0.0024405\ttotal: 1.93s\tremaining: 1.13s\n",
      "316:\tlearn: 0.0024404\ttotal: 1.94s\tremaining: 1.12s\n",
      "317:\tlearn: 0.0024399\ttotal: 1.94s\tremaining: 1.11s\n",
      "318:\tlearn: 0.0024398\ttotal: 1.95s\tremaining: 1.1s\n",
      "319:\tlearn: 0.0024397\ttotal: 1.95s\tremaining: 1.1s\n",
      "320:\tlearn: 0.0024397\ttotal: 1.95s\tremaining: 1.09s\n",
      "321:\tlearn: 0.0024397\ttotal: 1.96s\tremaining: 1.08s\n",
      "322:\tlearn: 0.0024396\ttotal: 1.96s\tremaining: 1.07s\n",
      "323:\tlearn: 0.0024396\ttotal: 1.97s\tremaining: 1.07s\n",
      "324:\tlearn: 0.0024397\ttotal: 1.97s\tremaining: 1.06s\n",
      "325:\tlearn: 0.0024395\ttotal: 1.98s\tremaining: 1.06s\n",
      "326:\tlearn: 0.0024391\ttotal: 1.99s\tremaining: 1.05s\n",
      "327:\tlearn: 0.0024390\ttotal: 2s\tremaining: 1.05s\n",
      "328:\tlearn: 0.0024388\ttotal: 2.01s\tremaining: 1.04s\n",
      "329:\tlearn: 0.0024386\ttotal: 2.02s\tremaining: 1.04s\n",
      "330:\tlearn: 0.0024377\ttotal: 2.03s\tremaining: 1.04s\n",
      "331:\tlearn: 0.0024375\ttotal: 2.04s\tremaining: 1.03s\n",
      "332:\tlearn: 0.0024374\ttotal: 2.05s\tremaining: 1.03s\n",
      "333:\tlearn: 0.0024370\ttotal: 2.05s\tremaining: 1.02s\n",
      "334:\tlearn: 0.0024370\ttotal: 2.06s\tremaining: 1.01s\n",
      "335:\tlearn: 0.0024369\ttotal: 2.06s\tremaining: 1.01s\n",
      "336:\tlearn: 0.0024363\ttotal: 2.07s\tremaining: 1s\n",
      "337:\tlearn: 0.0024361\ttotal: 2.08s\tremaining: 996ms\n",
      "338:\tlearn: 0.0024358\ttotal: 2.08s\tremaining: 989ms\n",
      "339:\tlearn: 0.0024358\ttotal: 2.09s\tremaining: 983ms\n",
      "340:\tlearn: 0.0024358\ttotal: 2.09s\tremaining: 977ms\n",
      "341:\tlearn: 0.0024356\ttotal: 2.1s\tremaining: 970ms\n",
      "342:\tlearn: 0.0024355\ttotal: 2.1s\tremaining: 963ms\n",
      "343:\tlearn: 0.0024350\ttotal: 2.11s\tremaining: 956ms\n",
      "344:\tlearn: 0.0024347\ttotal: 2.11s\tremaining: 949ms\n",
      "345:\tlearn: 0.0024345\ttotal: 2.12s\tremaining: 942ms\n",
      "346:\tlearn: 0.0024126\ttotal: 2.12s\tremaining: 935ms\n",
      "347:\tlearn: 0.0024123\ttotal: 2.13s\tremaining: 928ms\n",
      "348:\tlearn: 0.0024121\ttotal: 2.13s\tremaining: 921ms\n",
      "349:\tlearn: 0.0024117\ttotal: 2.13s\tremaining: 914ms\n",
      "350:\tlearn: 0.0024111\ttotal: 2.14s\tremaining: 907ms\n",
      "351:\tlearn: 0.0023279\ttotal: 2.14s\tremaining: 901ms\n",
      "352:\tlearn: 0.0023275\ttotal: 2.15s\tremaining: 893ms\n",
      "353:\tlearn: 0.0023274\ttotal: 2.15s\tremaining: 886ms\n",
      "354:\tlearn: 0.0023273\ttotal: 2.15s\tremaining: 880ms\n",
      "355:\tlearn: 0.0023271\ttotal: 2.16s\tremaining: 875ms\n",
      "356:\tlearn: 0.0023271\ttotal: 2.17s\tremaining: 870ms\n",
      "357:\tlearn: 0.0023268\ttotal: 2.18s\tremaining: 866ms\n",
      "358:\tlearn: 0.0023267\ttotal: 2.19s\tremaining: 861ms\n",
      "359:\tlearn: 0.0023267\ttotal: 2.2s\tremaining: 856ms\n",
      "360:\tlearn: 0.0023266\ttotal: 2.21s\tremaining: 851ms\n",
      "361:\tlearn: 0.0023259\ttotal: 2.22s\tremaining: 847ms\n",
      "362:\tlearn: 0.0023259\ttotal: 2.23s\tremaining: 842ms\n",
      "363:\tlearn: 0.0023254\ttotal: 2.24s\tremaining: 837ms\n",
      "364:\tlearn: 0.0023254\ttotal: 2.25s\tremaining: 831ms\n",
      "365:\tlearn: 0.0023254\ttotal: 2.25s\tremaining: 825ms\n",
      "366:\tlearn: 0.0023254\ttotal: 2.26s\tremaining: 819ms\n",
      "367:\tlearn: 0.0023254\ttotal: 2.26s\tremaining: 812ms\n",
      "368:\tlearn: 0.0023254\ttotal: 2.27s\tremaining: 806ms\n",
      "369:\tlearn: 0.0023254\ttotal: 2.27s\tremaining: 800ms\n",
      "370:\tlearn: 0.0023251\ttotal: 2.28s\tremaining: 793ms\n",
      "371:\tlearn: 0.0023248\ttotal: 2.29s\tremaining: 786ms\n",
      "372:\tlearn: 0.0023247\ttotal: 2.29s\tremaining: 780ms\n",
      "373:\tlearn: 0.0023247\ttotal: 2.29s\tremaining: 773ms\n",
      "374:\tlearn: 0.0023245\ttotal: 2.3s\tremaining: 766ms\n",
      "375:\tlearn: 0.0023245\ttotal: 2.3s\tremaining: 759ms\n",
      "376:\tlearn: 0.0023241\ttotal: 2.31s\tremaining: 753ms\n",
      "377:\tlearn: 0.0023239\ttotal: 2.31s\tremaining: 746ms\n",
      "378:\tlearn: 0.0023236\ttotal: 2.31s\tremaining: 739ms\n",
      "379:\tlearn: 0.0023235\ttotal: 2.32s\tremaining: 732ms\n",
      "380:\tlearn: 0.0023234\ttotal: 2.32s\tremaining: 726ms\n",
      "381:\tlearn: 0.0023234\ttotal: 2.33s\tremaining: 719ms\n",
      "382:\tlearn: 0.0023234\ttotal: 2.33s\tremaining: 712ms\n",
      "383:\tlearn: 0.0023233\ttotal: 2.34s\tremaining: 708ms\n",
      "384:\tlearn: 0.0023232\ttotal: 2.35s\tremaining: 703ms\n",
      "385:\tlearn: 0.0022176\ttotal: 2.36s\tremaining: 698ms\n",
      "386:\tlearn: 0.0022175\ttotal: 2.37s\tremaining: 693ms\n",
      "387:\tlearn: 0.0021580\ttotal: 2.38s\tremaining: 688ms\n",
      "388:\tlearn: 0.0021580\ttotal: 2.39s\tremaining: 683ms\n",
      "389:\tlearn: 0.0021041\ttotal: 2.4s\tremaining: 677ms\n",
      "390:\tlearn: 0.0021041\ttotal: 2.41s\tremaining: 672ms\n",
      "391:\tlearn: 0.0021041\ttotal: 2.42s\tremaining: 666ms\n",
      "392:\tlearn: 0.0021037\ttotal: 2.42s\tremaining: 660ms\n",
      "393:\tlearn: 0.0021036\ttotal: 2.43s\tremaining: 653ms\n",
      "394:\tlearn: 0.0021035\ttotal: 2.43s\tremaining: 646ms\n",
      "395:\tlearn: 0.0021035\ttotal: 2.44s\tremaining: 640ms\n",
      "396:\tlearn: 0.0021035\ttotal: 2.44s\tremaining: 633ms\n",
      "397:\tlearn: 0.0021036\ttotal: 2.44s\tremaining: 626ms\n",
      "398:\tlearn: 0.0021035\ttotal: 2.45s\tremaining: 620ms\n",
      "399:\tlearn: 0.0021033\ttotal: 2.45s\tremaining: 613ms\n",
      "400:\tlearn: 0.0021031\ttotal: 2.46s\tremaining: 606ms\n",
      "401:\tlearn: 0.0021032\ttotal: 2.46s\tremaining: 600ms\n",
      "402:\tlearn: 0.0021031\ttotal: 2.46s\tremaining: 593ms\n",
      "403:\tlearn: 0.0021030\ttotal: 2.47s\tremaining: 587ms\n",
      "404:\tlearn: 0.0021017\ttotal: 2.47s\tremaining: 580ms\n",
      "405:\tlearn: 0.0021016\ttotal: 2.48s\tremaining: 573ms\n",
      "406:\tlearn: 0.0021012\ttotal: 2.49s\tremaining: 568ms\n",
      "407:\tlearn: 0.0021010\ttotal: 2.5s\tremaining: 563ms\n",
      "408:\tlearn: 0.0021009\ttotal: 2.5s\tremaining: 557ms\n",
      "409:\tlearn: 0.0021006\ttotal: 2.51s\tremaining: 552ms\n",
      "410:\tlearn: 0.0021004\ttotal: 2.52s\tremaining: 547ms\n",
      "411:\tlearn: 0.0021003\ttotal: 2.53s\tremaining: 541ms\n",
      "412:\tlearn: 0.0021003\ttotal: 2.54s\tremaining: 536ms\n",
      "413:\tlearn: 0.0021001\ttotal: 2.55s\tremaining: 530ms\n",
      "414:\tlearn: 0.0021000\ttotal: 2.55s\tremaining: 523ms\n",
      "415:\tlearn: 0.0020998\ttotal: 2.56s\tremaining: 517ms\n",
      "416:\tlearn: 0.0020998\ttotal: 2.56s\tremaining: 510ms\n",
      "417:\tlearn: 0.0020998\ttotal: 2.57s\tremaining: 504ms\n",
      "418:\tlearn: 0.0020998\ttotal: 2.57s\tremaining: 497ms\n",
      "419:\tlearn: 0.0020998\ttotal: 2.58s\tremaining: 491ms\n",
      "420:\tlearn: 0.0020983\ttotal: 2.58s\tremaining: 484ms\n",
      "421:\tlearn: 0.0020983\ttotal: 2.58s\tremaining: 478ms\n",
      "422:\tlearn: 0.0020983\ttotal: 2.59s\tremaining: 471ms\n",
      "423:\tlearn: 0.0020982\ttotal: 2.59s\tremaining: 465ms\n",
      "424:\tlearn: 0.0020982\ttotal: 2.6s\tremaining: 458ms\n",
      "425:\tlearn: 0.0020980\ttotal: 2.6s\tremaining: 452ms\n",
      "426:\tlearn: 0.0020979\ttotal: 2.61s\tremaining: 446ms\n",
      "427:\tlearn: 0.0020978\ttotal: 2.62s\tremaining: 441ms\n",
      "428:\tlearn: 0.0020978\ttotal: 2.63s\tremaining: 435ms\n",
      "429:\tlearn: 0.0020979\ttotal: 2.64s\tremaining: 429ms\n",
      "430:\tlearn: 0.0020977\ttotal: 2.65s\tremaining: 424ms\n",
      "431:\tlearn: 0.0020976\ttotal: 2.66s\tremaining: 418ms\n",
      "432:\tlearn: 0.0020976\ttotal: 2.67s\tremaining: 413ms\n",
      "433:\tlearn: 0.0020976\ttotal: 2.68s\tremaining: 407ms\n",
      "434:\tlearn: 0.0020971\ttotal: 2.69s\tremaining: 401ms\n",
      "435:\tlearn: 0.0020971\ttotal: 2.69s\tremaining: 395ms\n",
      "436:\tlearn: 0.0020969\ttotal: 2.7s\tremaining: 389ms\n",
      "437:\tlearn: 0.0020966\ttotal: 2.71s\tremaining: 383ms\n",
      "438:\tlearn: 0.0020967\ttotal: 2.71s\tremaining: 377ms\n",
      "439:\tlearn: 0.0020965\ttotal: 2.72s\tremaining: 371ms\n",
      "440:\tlearn: 0.0020952\ttotal: 2.72s\tremaining: 365ms\n",
      "441:\tlearn: 0.0020952\ttotal: 2.73s\tremaining: 358ms\n",
      "442:\tlearn: 0.0020950\ttotal: 2.73s\tremaining: 352ms\n",
      "443:\tlearn: 0.0020948\ttotal: 2.74s\tremaining: 345ms\n",
      "444:\tlearn: 0.0020947\ttotal: 2.74s\tremaining: 339ms\n",
      "445:\tlearn: 0.0020941\ttotal: 2.75s\tremaining: 333ms\n",
      "446:\tlearn: 0.0020940\ttotal: 2.75s\tremaining: 326ms\n",
      "447:\tlearn: 0.0020940\ttotal: 2.75s\tremaining: 320ms\n",
      "448:\tlearn: 0.0020940\ttotal: 2.76s\tremaining: 313ms\n",
      "449:\tlearn: 0.0020939\ttotal: 2.76s\tremaining: 307ms\n",
      "450:\tlearn: 0.0020939\ttotal: 2.77s\tremaining: 301ms\n",
      "451:\tlearn: 0.0020936\ttotal: 2.77s\tremaining: 294ms\n",
      "452:\tlearn: 0.0020936\ttotal: 2.77s\tremaining: 288ms\n",
      "453:\tlearn: 0.0020935\ttotal: 2.78s\tremaining: 282ms\n",
      "454:\tlearn: 0.0020934\ttotal: 2.79s\tremaining: 276ms\n",
      "455:\tlearn: 0.0020932\ttotal: 2.8s\tremaining: 271ms\n",
      "456:\tlearn: 0.0020931\ttotal: 2.81s\tremaining: 265ms\n",
      "457:\tlearn: 0.0020931\ttotal: 2.82s\tremaining: 259ms\n",
      "458:\tlearn: 0.0020928\ttotal: 2.83s\tremaining: 253ms\n",
      "459:\tlearn: 0.0020924\ttotal: 2.84s\tremaining: 247ms\n",
      "460:\tlearn: 0.0020924\ttotal: 2.85s\tremaining: 241ms\n",
      "461:\tlearn: 0.0020924\ttotal: 2.86s\tremaining: 235ms\n",
      "462:\tlearn: 0.0020923\ttotal: 2.87s\tremaining: 229ms\n",
      "463:\tlearn: 0.0020923\ttotal: 2.87s\tremaining: 223ms\n",
      "464:\tlearn: 0.0020922\ttotal: 2.88s\tremaining: 217ms\n",
      "465:\tlearn: 0.0020922\ttotal: 2.88s\tremaining: 210ms\n",
      "466:\tlearn: 0.0020921\ttotal: 2.89s\tremaining: 204ms\n",
      "467:\tlearn: 0.0020919\ttotal: 2.9s\tremaining: 198ms\n",
      "468:\tlearn: 0.0020919\ttotal: 2.9s\tremaining: 192ms\n",
      "469:\tlearn: 0.0020917\ttotal: 2.91s\tremaining: 186ms\n",
      "470:\tlearn: 0.0020917\ttotal: 2.91s\tremaining: 179ms\n",
      "471:\tlearn: 0.0020916\ttotal: 2.92s\tremaining: 173ms\n",
      "472:\tlearn: 0.0020916\ttotal: 2.92s\tremaining: 167ms\n",
      "473:\tlearn: 0.0020915\ttotal: 2.92s\tremaining: 160ms\n",
      "474:\tlearn: 0.0020912\ttotal: 2.93s\tremaining: 154ms\n",
      "475:\tlearn: 0.0020912\ttotal: 2.93s\tremaining: 148ms\n",
      "476:\tlearn: 0.0020910\ttotal: 2.94s\tremaining: 142ms\n",
      "477:\tlearn: 0.0020909\ttotal: 2.94s\tremaining: 135ms\n",
      "478:\tlearn: 0.0020908\ttotal: 2.94s\tremaining: 129ms\n",
      "479:\tlearn: 0.0020905\ttotal: 2.95s\tremaining: 123ms\n",
      "480:\tlearn: 0.0020904\ttotal: 2.96s\tremaining: 117ms\n",
      "481:\tlearn: 0.0020901\ttotal: 2.97s\tremaining: 111ms\n",
      "482:\tlearn: 0.0020901\ttotal: 2.98s\tremaining: 105ms\n",
      "483:\tlearn: 0.0020900\ttotal: 2.99s\tremaining: 98.9ms\n",
      "484:\tlearn: 0.0020899\ttotal: 3s\tremaining: 92.8ms\n",
      "485:\tlearn: 0.0020899\ttotal: 3.01s\tremaining: 86.7ms\n",
      "486:\tlearn: 0.0020893\ttotal: 3.02s\tremaining: 80.6ms\n",
      "487:\tlearn: 0.0020892\ttotal: 3.03s\tremaining: 74.5ms\n",
      "488:\tlearn: 0.0020892\ttotal: 3.04s\tremaining: 68.3ms\n",
      "489:\tlearn: 0.0020892\ttotal: 3.04s\tremaining: 62.1ms\n",
      "490:\tlearn: 0.0020889\ttotal: 3.05s\tremaining: 55.9ms\n",
      "491:\tlearn: 0.0020887\ttotal: 3.05s\tremaining: 49.7ms\n",
      "492:\tlearn: 0.0020887\ttotal: 3.06s\tremaining: 43.5ms\n",
      "493:\tlearn: 0.0020887\ttotal: 3.07s\tremaining: 37.2ms\n",
      "494:\tlearn: 0.0020886\ttotal: 3.07s\tremaining: 31ms\n",
      "495:\tlearn: 0.0020884\ttotal: 3.08s\tremaining: 24.8ms\n",
      "496:\tlearn: 0.0020884\ttotal: 3.08s\tremaining: 18.6ms\n",
      "497:\tlearn: 0.0020884\ttotal: 3.09s\tremaining: 12.4ms\n",
      "498:\tlearn: 0.0020884\ttotal: 3.09s\tremaining: 6.19ms\n",
      "499:\tlearn: 0.0020880\ttotal: 3.09s\tremaining: 0us\n",
      "0:\tlearn: 0.6340864\ttotal: 9.23ms\tremaining: 4.61s\n",
      "1:\tlearn: 0.5680585\ttotal: 15.5ms\tremaining: 3.86s\n",
      "2:\tlearn: 0.5212075\ttotal: 21.6ms\tremaining: 3.58s\n",
      "3:\tlearn: 0.4819121\ttotal: 27.9ms\tremaining: 3.45s\n",
      "4:\tlearn: 0.4491338\ttotal: 33.5ms\tremaining: 3.32s\n",
      "5:\tlearn: 0.4224827\ttotal: 38.5ms\tremaining: 3.17s\n",
      "6:\tlearn: 0.3972611\ttotal: 43.5ms\tremaining: 3.06s\n",
      "7:\tlearn: 0.3773141\ttotal: 47.9ms\tremaining: 2.95s\n",
      "8:\tlearn: 0.3570276\ttotal: 52.7ms\tremaining: 2.88s\n",
      "9:\tlearn: 0.3338814\ttotal: 57.5ms\tremaining: 2.82s\n",
      "10:\tlearn: 0.3122737\ttotal: 61.8ms\tremaining: 2.75s\n",
      "11:\tlearn: 0.2845996\ttotal: 66.2ms\tremaining: 2.69s\n",
      "12:\tlearn: 0.2609930\ttotal: 70.4ms\tremaining: 2.64s\n",
      "13:\tlearn: 0.2456134\ttotal: 74.4ms\tremaining: 2.58s\n",
      "14:\tlearn: 0.2282760\ttotal: 78.9ms\tremaining: 2.55s\n",
      "15:\tlearn: 0.2146305\ttotal: 83.1ms\tremaining: 2.51s\n",
      "16:\tlearn: 0.2002974\ttotal: 87.2ms\tremaining: 2.48s\n",
      "17:\tlearn: 0.1901097\ttotal: 92.2ms\tremaining: 2.47s\n",
      "18:\tlearn: 0.1749375\ttotal: 102ms\tremaining: 2.58s\n",
      "19:\tlearn: 0.1642375\ttotal: 112ms\tremaining: 2.68s\n",
      "20:\tlearn: 0.1535183\ttotal: 122ms\tremaining: 2.77s\n",
      "21:\tlearn: 0.1459493\ttotal: 131ms\tremaining: 2.85s\n",
      "22:\tlearn: 0.1368662\ttotal: 141ms\tremaining: 2.92s\n",
      "23:\tlearn: 0.1258997\ttotal: 151ms\tremaining: 2.99s\n",
      "24:\tlearn: 0.1179634\ttotal: 160ms\tremaining: 3.04s\n",
      "25:\tlearn: 0.1098145\ttotal: 168ms\tremaining: 3.06s\n",
      "26:\tlearn: 0.1041086\ttotal: 175ms\tremaining: 3.07s\n",
      "27:\tlearn: 0.0992539\ttotal: 182ms\tremaining: 3.06s\n",
      "28:\tlearn: 0.0951264\ttotal: 191ms\tremaining: 3.09s\n",
      "29:\tlearn: 0.0917956\ttotal: 197ms\tremaining: 3.09s\n",
      "30:\tlearn: 0.0884303\ttotal: 200ms\tremaining: 3.03s\n",
      "31:\tlearn: 0.0857799\ttotal: 206ms\tremaining: 3s\n",
      "32:\tlearn: 0.0827127\ttotal: 210ms\tremaining: 2.97s\n",
      "33:\tlearn: 0.0770942\ttotal: 215ms\tremaining: 2.94s\n",
      "34:\tlearn: 0.0744662\ttotal: 218ms\tremaining: 2.9s\n",
      "35:\tlearn: 0.0704876\ttotal: 222ms\tremaining: 2.86s\n",
      "36:\tlearn: 0.0676055\ttotal: 226ms\tremaining: 2.83s\n",
      "37:\tlearn: 0.0644087\ttotal: 231ms\tremaining: 2.8s\n",
      "38:\tlearn: 0.0619371\ttotal: 235ms\tremaining: 2.78s\n",
      "39:\tlearn: 0.0587496\ttotal: 239ms\tremaining: 2.75s\n",
      "40:\tlearn: 0.0574156\ttotal: 243ms\tremaining: 2.72s\n",
      "41:\tlearn: 0.0544411\ttotal: 247ms\tremaining: 2.7s\n",
      "42:\tlearn: 0.0518477\ttotal: 252ms\tremaining: 2.67s\n",
      "43:\tlearn: 0.0486658\ttotal: 256ms\tremaining: 2.65s\n",
      "44:\tlearn: 0.0475053\ttotal: 265ms\tremaining: 2.68s\n",
      "45:\tlearn: 0.0449241\ttotal: 275ms\tremaining: 2.72s\n",
      "46:\tlearn: 0.0422554\ttotal: 285ms\tremaining: 2.74s\n",
      "47:\tlearn: 0.0399581\ttotal: 294ms\tremaining: 2.77s\n",
      "48:\tlearn: 0.0390687\ttotal: 304ms\tremaining: 2.8s\n",
      "49:\tlearn: 0.0378810\ttotal: 313ms\tremaining: 2.82s\n",
      "50:\tlearn: 0.0352057\ttotal: 323ms\tremaining: 2.84s\n",
      "51:\tlearn: 0.0332869\ttotal: 333ms\tremaining: 2.87s\n",
      "52:\tlearn: 0.0329167\ttotal: 342ms\tremaining: 2.88s\n",
      "53:\tlearn: 0.0315940\ttotal: 349ms\tremaining: 2.88s\n",
      "54:\tlearn: 0.0303643\ttotal: 358ms\tremaining: 2.9s\n",
      "55:\tlearn: 0.0287585\ttotal: 365ms\tremaining: 2.89s\n",
      "56:\tlearn: 0.0285629\ttotal: 370ms\tremaining: 2.87s\n",
      "57:\tlearn: 0.0269711\ttotal: 374ms\tremaining: 2.85s\n",
      "58:\tlearn: 0.0254975\ttotal: 379ms\tremaining: 2.83s\n",
      "59:\tlearn: 0.0242244\ttotal: 383ms\tremaining: 2.81s\n",
      "60:\tlearn: 0.0233934\ttotal: 388ms\tremaining: 2.79s\n",
      "61:\tlearn: 0.0225290\ttotal: 393ms\tremaining: 2.77s\n",
      "62:\tlearn: 0.0213890\ttotal: 397ms\tremaining: 2.75s\n",
      "63:\tlearn: 0.0207806\ttotal: 401ms\tremaining: 2.73s\n",
      "64:\tlearn: 0.0202060\ttotal: 405ms\tremaining: 2.71s\n",
      "65:\tlearn: 0.0192470\ttotal: 410ms\tremaining: 2.69s\n",
      "66:\tlearn: 0.0181619\ttotal: 414ms\tremaining: 2.68s\n",
      "67:\tlearn: 0.0172278\ttotal: 419ms\tremaining: 2.66s\n",
      "68:\tlearn: 0.0168123\ttotal: 423ms\tremaining: 2.64s\n",
      "69:\tlearn: 0.0167633\ttotal: 427ms\tremaining: 2.62s\n",
      "70:\tlearn: 0.0161492\ttotal: 431ms\tremaining: 2.6s\n",
      "71:\tlearn: 0.0155215\ttotal: 441ms\tremaining: 2.62s\n",
      "72:\tlearn: 0.0150646\ttotal: 451ms\tremaining: 2.64s\n",
      "73:\tlearn: 0.0143877\ttotal: 460ms\tremaining: 2.65s\n",
      "74:\tlearn: 0.0143113\ttotal: 470ms\tremaining: 2.67s\n",
      "75:\tlearn: 0.0134978\ttotal: 480ms\tremaining: 2.68s\n",
      "76:\tlearn: 0.0131999\ttotal: 490ms\tremaining: 2.69s\n",
      "77:\tlearn: 0.0129251\ttotal: 499ms\tremaining: 2.7s\n",
      "78:\tlearn: 0.0128553\ttotal: 509ms\tremaining: 2.71s\n",
      "79:\tlearn: 0.0120549\ttotal: 515ms\tremaining: 2.71s\n",
      "80:\tlearn: 0.0118147\ttotal: 522ms\tremaining: 2.7s\n",
      "81:\tlearn: 0.0114765\ttotal: 528ms\tremaining: 2.69s\n",
      "82:\tlearn: 0.0114319\ttotal: 534ms\tremaining: 2.68s\n",
      "83:\tlearn: 0.0110781\ttotal: 540ms\tremaining: 2.67s\n",
      "84:\tlearn: 0.0106545\ttotal: 546ms\tremaining: 2.67s\n",
      "85:\tlearn: 0.0099743\ttotal: 553ms\tremaining: 2.66s\n",
      "86:\tlearn: 0.0094689\ttotal: 559ms\tremaining: 2.65s\n",
      "87:\tlearn: 0.0091356\ttotal: 564ms\tremaining: 2.64s\n",
      "88:\tlearn: 0.0087079\ttotal: 569ms\tremaining: 2.63s\n",
      "89:\tlearn: 0.0085640\ttotal: 573ms\tremaining: 2.61s\n",
      "90:\tlearn: 0.0083091\ttotal: 578ms\tremaining: 2.6s\n",
      "91:\tlearn: 0.0082078\ttotal: 582ms\tremaining: 2.58s\n",
      "92:\tlearn: 0.0078600\ttotal: 586ms\tremaining: 2.56s\n",
      "93:\tlearn: 0.0077274\ttotal: 590ms\tremaining: 2.55s\n",
      "94:\tlearn: 0.0072587\ttotal: 595ms\tremaining: 2.54s\n",
      "95:\tlearn: 0.0069780\ttotal: 599ms\tremaining: 2.52s\n",
      "96:\tlearn: 0.0068488\ttotal: 609ms\tremaining: 2.53s\n",
      "97:\tlearn: 0.0065978\ttotal: 618ms\tremaining: 2.54s\n",
      "98:\tlearn: 0.0065103\ttotal: 628ms\tremaining: 2.54s\n",
      "99:\tlearn: 0.0062563\ttotal: 638ms\tremaining: 2.55s\n",
      "100:\tlearn: 0.0062558\ttotal: 647ms\tremaining: 2.56s\n",
      "101:\tlearn: 0.0059585\ttotal: 657ms\tremaining: 2.56s\n",
      "102:\tlearn: 0.0058150\ttotal: 665ms\tremaining: 2.56s\n",
      "103:\tlearn: 0.0056479\ttotal: 671ms\tremaining: 2.55s\n",
      "104:\tlearn: 0.0055458\ttotal: 677ms\tremaining: 2.55s\n",
      "105:\tlearn: 0.0055458\ttotal: 683ms\tremaining: 2.54s\n",
      "106:\tlearn: 0.0053797\ttotal: 689ms\tremaining: 2.53s\n",
      "107:\tlearn: 0.0053798\ttotal: 695ms\tremaining: 2.52s\n",
      "108:\tlearn: 0.0053720\ttotal: 700ms\tremaining: 2.51s\n",
      "109:\tlearn: 0.0052717\ttotal: 707ms\tremaining: 2.51s\n",
      "110:\tlearn: 0.0051671\ttotal: 711ms\tremaining: 2.49s\n",
      "111:\tlearn: 0.0049009\ttotal: 715ms\tremaining: 2.48s\n",
      "112:\tlearn: 0.0048880\ttotal: 720ms\tremaining: 2.46s\n",
      "113:\tlearn: 0.0047251\ttotal: 724ms\tremaining: 2.45s\n",
      "114:\tlearn: 0.0047250\ttotal: 728ms\tremaining: 2.44s\n",
      "115:\tlearn: 0.0047251\ttotal: 732ms\tremaining: 2.42s\n",
      "116:\tlearn: 0.0045503\ttotal: 737ms\tremaining: 2.41s\n",
      "117:\tlearn: 0.0044245\ttotal: 741ms\tremaining: 2.4s\n",
      "118:\tlearn: 0.0044245\ttotal: 745ms\tremaining: 2.39s\n",
      "119:\tlearn: 0.0042801\ttotal: 749ms\tremaining: 2.37s\n",
      "120:\tlearn: 0.0041618\ttotal: 753ms\tremaining: 2.36s\n",
      "121:\tlearn: 0.0040734\ttotal: 758ms\tremaining: 2.35s\n",
      "122:\tlearn: 0.0040733\ttotal: 762ms\tremaining: 2.33s\n",
      "123:\tlearn: 0.0039683\ttotal: 766ms\tremaining: 2.32s\n",
      "124:\tlearn: 0.0038179\ttotal: 776ms\tremaining: 2.33s\n",
      "125:\tlearn: 0.0038178\ttotal: 785ms\tremaining: 2.33s\n",
      "126:\tlearn: 0.0038175\ttotal: 794ms\tremaining: 2.33s\n",
      "127:\tlearn: 0.0038175\ttotal: 804ms\tremaining: 2.33s\n",
      "128:\tlearn: 0.0038174\ttotal: 813ms\tremaining: 2.34s\n",
      "129:\tlearn: 0.0038172\ttotal: 822ms\tremaining: 2.34s\n",
      "130:\tlearn: 0.0038172\ttotal: 831ms\tremaining: 2.34s\n",
      "131:\tlearn: 0.0038171\ttotal: 841ms\tremaining: 2.34s\n",
      "132:\tlearn: 0.0038171\ttotal: 850ms\tremaining: 2.35s\n",
      "133:\tlearn: 0.0038171\ttotal: 859ms\tremaining: 2.35s\n",
      "134:\tlearn: 0.0038168\ttotal: 865ms\tremaining: 2.34s\n",
      "135:\tlearn: 0.0038165\ttotal: 870ms\tremaining: 2.33s\n",
      "136:\tlearn: 0.0038154\ttotal: 877ms\tremaining: 2.32s\n",
      "137:\tlearn: 0.0037507\ttotal: 882ms\tremaining: 2.31s\n",
      "138:\tlearn: 0.0036663\ttotal: 888ms\tremaining: 2.31s\n",
      "139:\tlearn: 0.0035130\ttotal: 894ms\tremaining: 2.3s\n",
      "140:\tlearn: 0.0035130\ttotal: 900ms\tremaining: 2.29s\n",
      "141:\tlearn: 0.0035126\ttotal: 905ms\tremaining: 2.28s\n",
      "142:\tlearn: 0.0035122\ttotal: 907ms\tremaining: 2.27s\n",
      "143:\tlearn: 0.0035121\ttotal: 911ms\tremaining: 2.25s\n",
      "144:\tlearn: 0.0035115\ttotal: 915ms\tremaining: 2.24s\n",
      "145:\tlearn: 0.0035112\ttotal: 919ms\tremaining: 2.23s\n",
      "146:\tlearn: 0.0035112\ttotal: 922ms\tremaining: 2.21s\n",
      "147:\tlearn: 0.0035112\ttotal: 925ms\tremaining: 2.2s\n",
      "148:\tlearn: 0.0035107\ttotal: 929ms\tremaining: 2.19s\n",
      "149:\tlearn: 0.0035105\ttotal: 933ms\tremaining: 2.18s\n",
      "150:\tlearn: 0.0035105\ttotal: 943ms\tremaining: 2.18s\n",
      "151:\tlearn: 0.0035104\ttotal: 952ms\tremaining: 2.18s\n",
      "152:\tlearn: 0.0035104\ttotal: 961ms\tremaining: 2.18s\n",
      "153:\tlearn: 0.0035100\ttotal: 971ms\tremaining: 2.18s\n",
      "154:\tlearn: 0.0035100\ttotal: 980ms\tremaining: 2.18s\n",
      "155:\tlearn: 0.0035099\ttotal: 990ms\tremaining: 2.18s\n",
      "156:\tlearn: 0.0035099\ttotal: 999ms\tremaining: 2.18s\n",
      "157:\tlearn: 0.0035099\ttotal: 1.01s\tremaining: 2.18s\n",
      "158:\tlearn: 0.0035095\ttotal: 1.02s\tremaining: 2.18s\n",
      "159:\tlearn: 0.0035094\ttotal: 1.03s\tremaining: 2.18s\n",
      "160:\tlearn: 0.0035086\ttotal: 1.04s\tremaining: 2.18s\n",
      "161:\tlearn: 0.0035052\ttotal: 1.04s\tremaining: 2.18s\n",
      "162:\tlearn: 0.0035050\ttotal: 1.05s\tremaining: 2.18s\n",
      "163:\tlearn: 0.0035036\ttotal: 1.06s\tremaining: 2.18s\n",
      "164:\tlearn: 0.0035032\ttotal: 1.07s\tremaining: 2.18s\n",
      "165:\tlearn: 0.0035030\ttotal: 1.08s\tremaining: 2.17s\n",
      "166:\tlearn: 0.0035028\ttotal: 1.09s\tremaining: 2.17s\n",
      "167:\tlearn: 0.0035025\ttotal: 1.09s\tremaining: 2.17s\n",
      "168:\tlearn: 0.0035025\ttotal: 1.1s\tremaining: 2.16s\n",
      "169:\tlearn: 0.0035024\ttotal: 1.11s\tremaining: 2.15s\n",
      "170:\tlearn: 0.0035003\ttotal: 1.11s\tremaining: 2.14s\n",
      "171:\tlearn: 0.0035000\ttotal: 1.12s\tremaining: 2.13s\n",
      "172:\tlearn: 0.0034994\ttotal: 1.12s\tremaining: 2.12s\n",
      "173:\tlearn: 0.0034994\ttotal: 1.13s\tremaining: 2.11s\n",
      "174:\tlearn: 0.0034989\ttotal: 1.13s\tremaining: 2.1s\n",
      "175:\tlearn: 0.0034989\ttotal: 1.13s\tremaining: 2.09s\n",
      "176:\tlearn: 0.0034984\ttotal: 1.14s\tremaining: 2.08s\n",
      "177:\tlearn: 0.0034984\ttotal: 1.14s\tremaining: 2.07s\n",
      "178:\tlearn: 0.0034984\ttotal: 1.15s\tremaining: 2.06s\n",
      "179:\tlearn: 0.0034983\ttotal: 1.15s\tremaining: 2.05s\n",
      "180:\tlearn: 0.0034982\ttotal: 1.16s\tremaining: 2.04s\n",
      "181:\tlearn: 0.0034981\ttotal: 1.16s\tremaining: 2.03s\n",
      "182:\tlearn: 0.0034980\ttotal: 1.16s\tremaining: 2.02s\n",
      "183:\tlearn: 0.0034976\ttotal: 1.17s\tremaining: 2.01s\n",
      "184:\tlearn: 0.0034972\ttotal: 1.17s\tremaining: 2s\n",
      "185:\tlearn: 0.0034972\ttotal: 1.18s\tremaining: 1.99s\n",
      "186:\tlearn: 0.0034971\ttotal: 1.18s\tremaining: 1.98s\n",
      "187:\tlearn: 0.0034971\ttotal: 1.19s\tremaining: 1.97s\n",
      "188:\tlearn: 0.0034917\ttotal: 1.19s\tremaining: 1.96s\n",
      "189:\tlearn: 0.0034916\ttotal: 1.2s\tremaining: 1.96s\n",
      "190:\tlearn: 0.0034916\ttotal: 1.21s\tremaining: 1.95s\n",
      "191:\tlearn: 0.0034916\ttotal: 1.22s\tremaining: 1.95s\n",
      "192:\tlearn: 0.0034916\ttotal: 1.23s\tremaining: 1.95s\n",
      "193:\tlearn: 0.0034915\ttotal: 1.24s\tremaining: 1.95s\n",
      "194:\tlearn: 0.0034913\ttotal: 1.25s\tremaining: 1.95s\n",
      "195:\tlearn: 0.0034912\ttotal: 1.25s\tremaining: 1.95s\n",
      "196:\tlearn: 0.0034908\ttotal: 1.26s\tremaining: 1.95s\n",
      "197:\tlearn: 0.0034908\ttotal: 1.27s\tremaining: 1.94s\n",
      "198:\tlearn: 0.0034906\ttotal: 1.28s\tremaining: 1.93s\n",
      "199:\tlearn: 0.0034900\ttotal: 1.28s\tremaining: 1.93s\n",
      "200:\tlearn: 0.0034898\ttotal: 1.29s\tremaining: 1.92s\n",
      "201:\tlearn: 0.0034898\ttotal: 1.29s\tremaining: 1.91s\n",
      "202:\tlearn: 0.0034899\ttotal: 1.3s\tremaining: 1.9s\n",
      "203:\tlearn: 0.0034897\ttotal: 1.3s\tremaining: 1.89s\n",
      "204:\tlearn: 0.0034895\ttotal: 1.3s\tremaining: 1.88s\n",
      "205:\tlearn: 0.0034893\ttotal: 1.31s\tremaining: 1.87s\n",
      "206:\tlearn: 0.0034893\ttotal: 1.31s\tremaining: 1.86s\n",
      "207:\tlearn: 0.0034893\ttotal: 1.32s\tremaining: 1.85s\n",
      "208:\tlearn: 0.0034892\ttotal: 1.32s\tremaining: 1.84s\n",
      "209:\tlearn: 0.0034892\ttotal: 1.32s\tremaining: 1.83s\n",
      "210:\tlearn: 0.0034892\ttotal: 1.33s\tremaining: 1.82s\n",
      "211:\tlearn: 0.0034892\ttotal: 1.33s\tremaining: 1.81s\n",
      "212:\tlearn: 0.0034887\ttotal: 1.34s\tremaining: 1.81s\n",
      "213:\tlearn: 0.0034884\ttotal: 1.35s\tremaining: 1.81s\n",
      "214:\tlearn: 0.0034883\ttotal: 1.36s\tremaining: 1.8s\n",
      "215:\tlearn: 0.0034883\ttotal: 1.37s\tremaining: 1.8s\n",
      "216:\tlearn: 0.0034883\ttotal: 1.38s\tremaining: 1.8s\n",
      "217:\tlearn: 0.0034868\ttotal: 1.39s\tremaining: 1.8s\n",
      "218:\tlearn: 0.0034868\ttotal: 1.4s\tremaining: 1.79s\n",
      "219:\tlearn: 0.0034868\ttotal: 1.41s\tremaining: 1.79s\n",
      "220:\tlearn: 0.0034868\ttotal: 1.42s\tremaining: 1.79s\n",
      "221:\tlearn: 0.0034864\ttotal: 1.42s\tremaining: 1.78s\n",
      "222:\tlearn: 0.0034862\ttotal: 1.43s\tremaining: 1.78s\n",
      "223:\tlearn: 0.0034862\ttotal: 1.44s\tremaining: 1.77s\n",
      "224:\tlearn: 0.0034860\ttotal: 1.44s\tremaining: 1.76s\n",
      "225:\tlearn: 0.0034858\ttotal: 1.45s\tremaining: 1.76s\n",
      "226:\tlearn: 0.0034852\ttotal: 1.45s\tremaining: 1.75s\n",
      "227:\tlearn: 0.0034845\ttotal: 1.46s\tremaining: 1.74s\n",
      "228:\tlearn: 0.0034844\ttotal: 1.46s\tremaining: 1.73s\n",
      "229:\tlearn: 0.0034842\ttotal: 1.47s\tremaining: 1.72s\n",
      "230:\tlearn: 0.0034834\ttotal: 1.47s\tremaining: 1.72s\n",
      "231:\tlearn: 0.0034833\ttotal: 1.48s\tremaining: 1.71s\n",
      "232:\tlearn: 0.0034825\ttotal: 1.48s\tremaining: 1.7s\n",
      "233:\tlearn: 0.0034825\ttotal: 1.49s\tremaining: 1.69s\n",
      "234:\tlearn: 0.0034825\ttotal: 1.49s\tremaining: 1.68s\n",
      "235:\tlearn: 0.0034823\ttotal: 1.49s\tremaining: 1.67s\n",
      "236:\tlearn: 0.0034822\ttotal: 1.5s\tremaining: 1.66s\n",
      "237:\tlearn: 0.0034822\ttotal: 1.5s\tremaining: 1.65s\n",
      "238:\tlearn: 0.0034818\ttotal: 1.5s\tremaining: 1.64s\n",
      "239:\tlearn: 0.0034816\ttotal: 1.51s\tremaining: 1.64s\n",
      "240:\tlearn: 0.0034816\ttotal: 1.52s\tremaining: 1.64s\n",
      "241:\tlearn: 0.0034816\ttotal: 1.53s\tremaining: 1.63s\n",
      "242:\tlearn: 0.0034816\ttotal: 1.54s\tremaining: 1.63s\n",
      "243:\tlearn: 0.0034816\ttotal: 1.55s\tremaining: 1.63s\n",
      "244:\tlearn: 0.0034816\ttotal: 1.56s\tremaining: 1.62s\n",
      "245:\tlearn: 0.0034815\ttotal: 1.57s\tremaining: 1.62s\n",
      "246:\tlearn: 0.0034814\ttotal: 1.58s\tremaining: 1.62s\n",
      "247:\tlearn: 0.0034813\ttotal: 1.59s\tremaining: 1.61s\n",
      "248:\tlearn: 0.0034813\ttotal: 1.59s\tremaining: 1.61s\n",
      "249:\tlearn: 0.0034811\ttotal: 1.6s\tremaining: 1.6s\n",
      "250:\tlearn: 0.0034810\ttotal: 1.6s\tremaining: 1.59s\n",
      "251:\tlearn: 0.0034803\ttotal: 1.61s\tremaining: 1.58s\n",
      "252:\tlearn: 0.0034796\ttotal: 1.62s\tremaining: 1.58s\n",
      "253:\tlearn: 0.0034794\ttotal: 1.62s\tremaining: 1.57s\n",
      "254:\tlearn: 0.0034793\ttotal: 1.63s\tremaining: 1.56s\n",
      "255:\tlearn: 0.0034791\ttotal: 1.63s\tremaining: 1.56s\n",
      "256:\tlearn: 0.0034789\ttotal: 1.64s\tremaining: 1.55s\n",
      "257:\tlearn: 0.0034788\ttotal: 1.64s\tremaining: 1.54s\n",
      "258:\tlearn: 0.0034785\ttotal: 1.64s\tremaining: 1.53s\n",
      "259:\tlearn: 0.0034784\ttotal: 1.65s\tremaining: 1.52s\n",
      "260:\tlearn: 0.0034782\ttotal: 1.65s\tremaining: 1.51s\n",
      "261:\tlearn: 0.0034782\ttotal: 1.65s\tremaining: 1.5s\n",
      "262:\tlearn: 0.0034781\ttotal: 1.66s\tremaining: 1.49s\n",
      "263:\tlearn: 0.0034779\ttotal: 1.66s\tremaining: 1.49s\n",
      "264:\tlearn: 0.0034776\ttotal: 1.67s\tremaining: 1.48s\n",
      "265:\tlearn: 0.0034774\ttotal: 1.67s\tremaining: 1.47s\n",
      "266:\tlearn: 0.0034764\ttotal: 1.68s\tremaining: 1.47s\n",
      "267:\tlearn: 0.0034764\ttotal: 1.69s\tremaining: 1.46s\n",
      "268:\tlearn: 0.0034764\ttotal: 1.7s\tremaining: 1.46s\n",
      "269:\tlearn: 0.0034764\ttotal: 1.71s\tremaining: 1.45s\n",
      "270:\tlearn: 0.0034764\ttotal: 1.72s\tremaining: 1.45s\n",
      "271:\tlearn: 0.0034762\ttotal: 1.73s\tremaining: 1.45s\n",
      "272:\tlearn: 0.0034761\ttotal: 1.74s\tremaining: 1.44s\n",
      "273:\tlearn: 0.0034760\ttotal: 1.74s\tremaining: 1.44s\n",
      "274:\tlearn: 0.0034750\ttotal: 1.75s\tremaining: 1.43s\n",
      "275:\tlearn: 0.0034750\ttotal: 1.76s\tremaining: 1.43s\n",
      "276:\tlearn: 0.0034743\ttotal: 1.77s\tremaining: 1.43s\n",
      "277:\tlearn: 0.0034743\ttotal: 1.78s\tremaining: 1.42s\n",
      "278:\tlearn: 0.0034741\ttotal: 1.79s\tremaining: 1.42s\n",
      "279:\tlearn: 0.0034731\ttotal: 1.81s\tremaining: 1.42s\n",
      "280:\tlearn: 0.0034728\ttotal: 1.82s\tremaining: 1.42s\n",
      "281:\tlearn: 0.0034726\ttotal: 1.82s\tremaining: 1.41s\n",
      "282:\tlearn: 0.0034726\ttotal: 1.82s\tremaining: 1.4s\n",
      "283:\tlearn: 0.0034725\ttotal: 1.83s\tremaining: 1.39s\n",
      "284:\tlearn: 0.0034722\ttotal: 1.83s\tremaining: 1.38s\n",
      "285:\tlearn: 0.0034721\ttotal: 1.84s\tremaining: 1.37s\n",
      "286:\tlearn: 0.0034720\ttotal: 1.84s\tremaining: 1.37s\n",
      "287:\tlearn: 0.0034719\ttotal: 1.85s\tremaining: 1.36s\n",
      "288:\tlearn: 0.0034711\ttotal: 1.86s\tremaining: 1.36s\n",
      "289:\tlearn: 0.0034711\ttotal: 1.87s\tremaining: 1.35s\n",
      "290:\tlearn: 0.0034710\ttotal: 1.88s\tremaining: 1.35s\n",
      "291:\tlearn: 0.0034710\ttotal: 1.89s\tremaining: 1.34s\n",
      "292:\tlearn: 0.0034709\ttotal: 1.9s\tremaining: 1.34s\n",
      "293:\tlearn: 0.0034709\ttotal: 1.91s\tremaining: 1.34s\n",
      "294:\tlearn: 0.0034707\ttotal: 1.92s\tremaining: 1.33s\n",
      "295:\tlearn: 0.0034707\ttotal: 1.93s\tremaining: 1.33s\n",
      "296:\tlearn: 0.0034708\ttotal: 1.93s\tremaining: 1.32s\n",
      "297:\tlearn: 0.0034687\ttotal: 1.93s\tremaining: 1.31s\n",
      "298:\tlearn: 0.0034687\ttotal: 1.94s\tremaining: 1.3s\n",
      "299:\tlearn: 0.0034687\ttotal: 1.94s\tremaining: 1.29s\n",
      "300:\tlearn: 0.0034686\ttotal: 1.95s\tremaining: 1.29s\n",
      "301:\tlearn: 0.0034686\ttotal: 1.95s\tremaining: 1.28s\n",
      "302:\tlearn: 0.0034686\ttotal: 1.96s\tremaining: 1.27s\n",
      "303:\tlearn: 0.0034685\ttotal: 1.96s\tremaining: 1.26s\n",
      "304:\tlearn: 0.0034685\ttotal: 1.97s\tremaining: 1.26s\n",
      "305:\tlearn: 0.0034686\ttotal: 1.97s\tremaining: 1.25s\n",
      "306:\tlearn: 0.0034686\ttotal: 1.97s\tremaining: 1.24s\n",
      "307:\tlearn: 0.0034685\ttotal: 1.98s\tremaining: 1.23s\n",
      "308:\tlearn: 0.0034685\ttotal: 1.98s\tremaining: 1.22s\n",
      "309:\tlearn: 0.0034682\ttotal: 1.99s\tremaining: 1.22s\n",
      "310:\tlearn: 0.0034680\ttotal: 2s\tremaining: 1.21s\n",
      "311:\tlearn: 0.0034680\ttotal: 2s\tremaining: 1.21s\n",
      "312:\tlearn: 0.0034675\ttotal: 2.01s\tremaining: 1.2s\n",
      "313:\tlearn: 0.0034675\ttotal: 2.02s\tremaining: 1.2s\n",
      "314:\tlearn: 0.0034674\ttotal: 2.03s\tremaining: 1.19s\n",
      "315:\tlearn: 0.0034673\ttotal: 2.04s\tremaining: 1.19s\n",
      "316:\tlearn: 0.0034669\ttotal: 2.05s\tremaining: 1.18s\n",
      "317:\tlearn: 0.0034669\ttotal: 2.06s\tremaining: 1.18s\n",
      "318:\tlearn: 0.0034664\ttotal: 2.07s\tremaining: 1.17s\n",
      "319:\tlearn: 0.0034664\ttotal: 2.08s\tremaining: 1.17s\n",
      "320:\tlearn: 0.0034663\ttotal: 2.08s\tremaining: 1.16s\n",
      "321:\tlearn: 0.0034663\ttotal: 2.09s\tremaining: 1.15s\n",
      "322:\tlearn: 0.0034663\ttotal: 2.09s\tremaining: 1.15s\n",
      "323:\tlearn: 0.0034662\ttotal: 2.1s\tremaining: 1.14s\n",
      "324:\tlearn: 0.0034662\ttotal: 2.1s\tremaining: 1.13s\n",
      "325:\tlearn: 0.0034661\ttotal: 2.11s\tremaining: 1.13s\n",
      "326:\tlearn: 0.0034660\ttotal: 2.11s\tremaining: 1.12s\n",
      "327:\tlearn: 0.0034659\ttotal: 2.12s\tremaining: 1.11s\n",
      "328:\tlearn: 0.0034658\ttotal: 2.12s\tremaining: 1.1s\n",
      "329:\tlearn: 0.0034658\ttotal: 2.13s\tremaining: 1.1s\n",
      "330:\tlearn: 0.0034658\ttotal: 2.13s\tremaining: 1.09s\n",
      "331:\tlearn: 0.0034657\ttotal: 2.14s\tremaining: 1.08s\n",
      "332:\tlearn: 0.0034657\ttotal: 2.14s\tremaining: 1.07s\n",
      "333:\tlearn: 0.0034656\ttotal: 2.15s\tremaining: 1.07s\n",
      "334:\tlearn: 0.0034656\ttotal: 2.15s\tremaining: 1.06s\n",
      "335:\tlearn: 0.0034655\ttotal: 2.15s\tremaining: 1.05s\n",
      "336:\tlearn: 0.0034655\ttotal: 2.16s\tremaining: 1.04s\n",
      "337:\tlearn: 0.0034654\ttotal: 2.16s\tremaining: 1.04s\n",
      "338:\tlearn: 0.0034649\ttotal: 2.17s\tremaining: 1.03s\n",
      "339:\tlearn: 0.0034647\ttotal: 2.17s\tremaining: 1.02s\n",
      "340:\tlearn: 0.0034645\ttotal: 2.17s\tremaining: 1.01s\n",
      "341:\tlearn: 0.0034643\ttotal: 2.18s\tremaining: 1.01s\n",
      "342:\tlearn: 0.0034642\ttotal: 2.18s\tremaining: 999ms\n",
      "343:\tlearn: 0.0034642\ttotal: 2.19s\tremaining: 995ms\n",
      "344:\tlearn: 0.0034641\ttotal: 2.2s\tremaining: 990ms\n",
      "345:\tlearn: 0.0034640\ttotal: 2.21s\tremaining: 985ms\n",
      "346:\tlearn: 0.0034640\ttotal: 2.22s\tremaining: 980ms\n",
      "347:\tlearn: 0.0034640\ttotal: 2.23s\tremaining: 975ms\n",
      "348:\tlearn: 0.0034634\ttotal: 2.24s\tremaining: 970ms\n",
      "349:\tlearn: 0.0034633\ttotal: 2.25s\tremaining: 964ms\n",
      "350:\tlearn: 0.0034632\ttotal: 2.26s\tremaining: 959ms\n",
      "351:\tlearn: 0.0034629\ttotal: 2.27s\tremaining: 954ms\n",
      "352:\tlearn: 0.0034627\ttotal: 2.27s\tremaining: 948ms\n",
      "353:\tlearn: 0.0034627\ttotal: 2.28s\tremaining: 941ms\n",
      "354:\tlearn: 0.0034626\ttotal: 2.29s\tremaining: 934ms\n",
      "355:\tlearn: 0.0034624\ttotal: 2.29s\tremaining: 928ms\n",
      "356:\tlearn: 0.0034625\ttotal: 2.3s\tremaining: 921ms\n",
      "357:\tlearn: 0.0034617\ttotal: 2.3s\tremaining: 914ms\n",
      "358:\tlearn: 0.0034614\ttotal: 2.31s\tremaining: 907ms\n",
      "359:\tlearn: 0.0034606\ttotal: 2.31s\tremaining: 899ms\n",
      "360:\tlearn: 0.0034605\ttotal: 2.32s\tremaining: 892ms\n",
      "361:\tlearn: 0.0034605\ttotal: 2.32s\tremaining: 885ms\n",
      "362:\tlearn: 0.0034605\ttotal: 2.33s\tremaining: 878ms\n",
      "363:\tlearn: 0.0034603\ttotal: 2.33s\tremaining: 871ms\n",
      "364:\tlearn: 0.0034602\ttotal: 2.33s\tremaining: 863ms\n",
      "365:\tlearn: 0.0034601\ttotal: 2.34s\tremaining: 856ms\n",
      "366:\tlearn: 0.0034601\ttotal: 2.34s\tremaining: 849ms\n",
      "367:\tlearn: 0.0034599\ttotal: 2.35s\tremaining: 842ms\n",
      "368:\tlearn: 0.0034599\ttotal: 2.35s\tremaining: 834ms\n",
      "369:\tlearn: 0.0034595\ttotal: 2.35s\tremaining: 827ms\n",
      "370:\tlearn: 0.0034595\ttotal: 2.36s\tremaining: 820ms\n",
      "371:\tlearn: 0.0034593\ttotal: 2.36s\tremaining: 812ms\n",
      "372:\tlearn: 0.0034587\ttotal: 2.37s\tremaining: 807ms\n",
      "373:\tlearn: 0.0034587\ttotal: 2.38s\tremaining: 802ms\n",
      "374:\tlearn: 0.0034587\ttotal: 2.39s\tremaining: 797ms\n",
      "375:\tlearn: 0.0034586\ttotal: 2.4s\tremaining: 791ms\n",
      "376:\tlearn: 0.0034585\ttotal: 2.41s\tremaining: 786ms\n",
      "377:\tlearn: 0.0033113\ttotal: 2.42s\tremaining: 780ms\n",
      "378:\tlearn: 0.0033109\ttotal: 2.43s\tremaining: 775ms\n",
      "379:\tlearn: 0.0033107\ttotal: 2.44s\tremaining: 769ms\n",
      "380:\tlearn: 0.0033105\ttotal: 2.44s\tremaining: 763ms\n",
      "381:\tlearn: 0.0033105\ttotal: 2.45s\tremaining: 756ms\n",
      "382:\tlearn: 0.0033104\ttotal: 2.45s\tremaining: 750ms\n",
      "383:\tlearn: 0.0033103\ttotal: 2.46s\tremaining: 743ms\n",
      "384:\tlearn: 0.0033100\ttotal: 2.47s\tremaining: 737ms\n",
      "385:\tlearn: 0.0033099\ttotal: 2.47s\tremaining: 730ms\n",
      "386:\tlearn: 0.0033098\ttotal: 2.47s\tremaining: 723ms\n",
      "387:\tlearn: 0.0033098\ttotal: 2.48s\tremaining: 716ms\n",
      "388:\tlearn: 0.0033094\ttotal: 2.48s\tremaining: 709ms\n",
      "389:\tlearn: 0.0033094\ttotal: 2.49s\tremaining: 702ms\n",
      "390:\tlearn: 0.0032068\ttotal: 2.49s\tremaining: 695ms\n",
      "391:\tlearn: 0.0032068\ttotal: 2.5s\tremaining: 688ms\n",
      "392:\tlearn: 0.0032068\ttotal: 2.5s\tremaining: 681ms\n",
      "393:\tlearn: 0.0032066\ttotal: 2.5s\tremaining: 674ms\n",
      "394:\tlearn: 0.0032066\ttotal: 2.51s\tremaining: 667ms\n",
      "395:\tlearn: 0.0032063\ttotal: 2.51s\tremaining: 660ms\n",
      "396:\tlearn: 0.0031378\ttotal: 2.52s\tremaining: 653ms\n",
      "397:\tlearn: 0.0031370\ttotal: 2.52s\tremaining: 646ms\n",
      "398:\tlearn: 0.0029955\ttotal: 2.52s\tremaining: 639ms\n",
      "399:\tlearn: 0.0029954\ttotal: 2.53s\tremaining: 634ms\n",
      "400:\tlearn: 0.0029953\ttotal: 2.54s\tremaining: 628ms\n",
      "401:\tlearn: 0.0029304\ttotal: 2.55s\tremaining: 623ms\n",
      "402:\tlearn: 0.0028368\ttotal: 2.56s\tremaining: 617ms\n",
      "403:\tlearn: 0.0028368\ttotal: 2.57s\tremaining: 611ms\n",
      "404:\tlearn: 0.0028368\ttotal: 2.58s\tremaining: 606ms\n",
      "405:\tlearn: 0.0028368\ttotal: 2.59s\tremaining: 600ms\n",
      "406:\tlearn: 0.0028365\ttotal: 2.6s\tremaining: 594ms\n",
      "407:\tlearn: 0.0028364\ttotal: 2.61s\tremaining: 588ms\n",
      "408:\tlearn: 0.0028365\ttotal: 2.61s\tremaining: 581ms\n",
      "409:\tlearn: 0.0028364\ttotal: 2.62s\tremaining: 574ms\n",
      "410:\tlearn: 0.0028363\ttotal: 2.62s\tremaining: 567ms\n",
      "411:\tlearn: 0.0028363\ttotal: 2.62s\tremaining: 560ms\n",
      "412:\tlearn: 0.0028362\ttotal: 2.63s\tremaining: 554ms\n",
      "413:\tlearn: 0.0028359\ttotal: 2.63s\tremaining: 547ms\n",
      "414:\tlearn: 0.0028359\ttotal: 2.64s\tremaining: 540ms\n",
      "415:\tlearn: 0.0028359\ttotal: 2.64s\tremaining: 533ms\n",
      "416:\tlearn: 0.0028359\ttotal: 2.64s\tremaining: 526ms\n",
      "417:\tlearn: 0.0028359\ttotal: 2.65s\tremaining: 520ms\n",
      "418:\tlearn: 0.0028358\ttotal: 2.65s\tremaining: 513ms\n",
      "419:\tlearn: 0.0028358\ttotal: 2.66s\tremaining: 506ms\n",
      "420:\tlearn: 0.0028356\ttotal: 2.66s\tremaining: 499ms\n",
      "421:\tlearn: 0.0028350\ttotal: 2.67s\tremaining: 493ms\n",
      "422:\tlearn: 0.0028347\ttotal: 2.67s\tremaining: 486ms\n",
      "423:\tlearn: 0.0028343\ttotal: 2.67s\tremaining: 479ms\n",
      "424:\tlearn: 0.0028342\ttotal: 2.68s\tremaining: 473ms\n",
      "425:\tlearn: 0.0028340\ttotal: 2.68s\tremaining: 466ms\n",
      "426:\tlearn: 0.0028337\ttotal: 2.69s\tremaining: 459ms\n",
      "427:\tlearn: 0.0028337\ttotal: 2.69s\tremaining: 453ms\n",
      "428:\tlearn: 0.0028336\ttotal: 2.69s\tremaining: 446ms\n",
      "429:\tlearn: 0.0028331\ttotal: 2.7s\tremaining: 440ms\n",
      "430:\tlearn: 0.0028332\ttotal: 2.71s\tremaining: 434ms\n",
      "431:\tlearn: 0.0028329\ttotal: 2.72s\tremaining: 428ms\n",
      "432:\tlearn: 0.0028066\ttotal: 2.73s\tremaining: 423ms\n",
      "433:\tlearn: 0.0028062\ttotal: 2.74s\tremaining: 417ms\n",
      "434:\tlearn: 0.0028062\ttotal: 2.75s\tremaining: 411ms\n",
      "435:\tlearn: 0.0028061\ttotal: 2.76s\tremaining: 405ms\n",
      "436:\tlearn: 0.0028061\ttotal: 2.77s\tremaining: 399ms\n",
      "437:\tlearn: 0.0028060\ttotal: 2.77s\tremaining: 393ms\n",
      "438:\tlearn: 0.0028059\ttotal: 2.78s\tremaining: 386ms\n",
      "439:\tlearn: 0.0028058\ttotal: 2.78s\tremaining: 379ms\n",
      "440:\tlearn: 0.0028058\ttotal: 2.79s\tremaining: 373ms\n",
      "441:\tlearn: 0.0028055\ttotal: 2.79s\tremaining: 366ms\n",
      "442:\tlearn: 0.0028054\ttotal: 2.8s\tremaining: 360ms\n",
      "443:\tlearn: 0.0028053\ttotal: 2.8s\tremaining: 353ms\n",
      "444:\tlearn: 0.0028050\ttotal: 2.8s\tremaining: 347ms\n",
      "445:\tlearn: 0.0028050\ttotal: 2.81s\tremaining: 340ms\n",
      "446:\tlearn: 0.0028048\ttotal: 2.81s\tremaining: 333ms\n",
      "447:\tlearn: 0.0028043\ttotal: 2.82s\tremaining: 327ms\n",
      "448:\tlearn: 0.0028043\ttotal: 2.82s\tremaining: 320ms\n",
      "449:\tlearn: 0.0028042\ttotal: 2.83s\tremaining: 314ms\n",
      "450:\tlearn: 0.0028042\ttotal: 2.84s\tremaining: 309ms\n",
      "451:\tlearn: 0.0028039\ttotal: 2.85s\tremaining: 303ms\n",
      "452:\tlearn: 0.0028039\ttotal: 2.86s\tremaining: 297ms\n",
      "453:\tlearn: 0.0028040\ttotal: 2.87s\tremaining: 291ms\n",
      "454:\tlearn: 0.0028037\ttotal: 2.88s\tremaining: 285ms\n",
      "455:\tlearn: 0.0028037\ttotal: 2.89s\tremaining: 279ms\n",
      "456:\tlearn: 0.0028033\ttotal: 2.9s\tremaining: 272ms\n",
      "457:\tlearn: 0.0028033\ttotal: 2.9s\tremaining: 266ms\n",
      "458:\tlearn: 0.0028032\ttotal: 2.91s\tremaining: 260ms\n",
      "459:\tlearn: 0.0028032\ttotal: 2.92s\tremaining: 254ms\n",
      "460:\tlearn: 0.0028028\ttotal: 2.92s\tremaining: 247ms\n",
      "461:\tlearn: 0.0028028\ttotal: 2.93s\tremaining: 241ms\n",
      "462:\tlearn: 0.0028027\ttotal: 2.94s\tremaining: 235ms\n",
      "463:\tlearn: 0.0028027\ttotal: 2.94s\tremaining: 228ms\n",
      "464:\tlearn: 0.0028027\ttotal: 2.95s\tremaining: 222ms\n",
      "465:\tlearn: 0.0028027\ttotal: 2.95s\tremaining: 215ms\n",
      "466:\tlearn: 0.0028025\ttotal: 2.96s\tremaining: 209ms\n",
      "467:\tlearn: 0.0028021\ttotal: 2.96s\tremaining: 202ms\n",
      "468:\tlearn: 0.0028021\ttotal: 2.96s\tremaining: 196ms\n",
      "469:\tlearn: 0.0028021\ttotal: 2.97s\tremaining: 190ms\n",
      "470:\tlearn: 0.0028022\ttotal: 2.97s\tremaining: 183ms\n",
      "471:\tlearn: 0.0028020\ttotal: 2.98s\tremaining: 177ms\n",
      "472:\tlearn: 0.0028020\ttotal: 2.98s\tremaining: 170ms\n",
      "473:\tlearn: 0.0028020\ttotal: 2.98s\tremaining: 164ms\n",
      "474:\tlearn: 0.0028019\ttotal: 2.99s\tremaining: 157ms\n",
      "475:\tlearn: 0.0028019\ttotal: 2.99s\tremaining: 151ms\n",
      "476:\tlearn: 0.0028019\ttotal: 3s\tremaining: 145ms\n",
      "477:\tlearn: 0.0028018\ttotal: 3.01s\tremaining: 139ms\n",
      "478:\tlearn: 0.0028017\ttotal: 3.02s\tremaining: 132ms\n",
      "479:\tlearn: 0.0028016\ttotal: 3.03s\tremaining: 126ms\n",
      "480:\tlearn: 0.0028016\ttotal: 3.04s\tremaining: 120ms\n",
      "481:\tlearn: 0.0028017\ttotal: 3.05s\tremaining: 114ms\n",
      "482:\tlearn: 0.0028016\ttotal: 3.06s\tremaining: 108ms\n",
      "483:\tlearn: 0.0028016\ttotal: 3.07s\tremaining: 101ms\n",
      "484:\tlearn: 0.0028016\ttotal: 3.08s\tremaining: 95.2ms\n",
      "485:\tlearn: 0.0028013\ttotal: 3.09s\tremaining: 88.9ms\n",
      "486:\tlearn: 0.0028013\ttotal: 3.09s\tremaining: 82.6ms\n",
      "487:\tlearn: 0.0028013\ttotal: 3.1s\tremaining: 76.2ms\n",
      "488:\tlearn: 0.0028012\ttotal: 3.1s\tremaining: 69.8ms\n",
      "489:\tlearn: 0.0028012\ttotal: 3.11s\tremaining: 63.5ms\n",
      "490:\tlearn: 0.0028012\ttotal: 3.12s\tremaining: 57.1ms\n",
      "491:\tlearn: 0.0028011\ttotal: 3.12s\tremaining: 50.8ms\n",
      "492:\tlearn: 0.0028011\ttotal: 3.13s\tremaining: 44.4ms\n",
      "493:\tlearn: 0.0028010\ttotal: 3.13s\tremaining: 38ms\n",
      "494:\tlearn: 0.0028006\ttotal: 3.13s\tremaining: 31.7ms\n",
      "495:\tlearn: 0.0028004\ttotal: 3.14s\tremaining: 25.3ms\n",
      "496:\tlearn: 0.0028003\ttotal: 3.14s\tremaining: 19ms\n",
      "497:\tlearn: 0.0028003\ttotal: 3.15s\tremaining: 12.6ms\n",
      "498:\tlearn: 0.0028003\ttotal: 3.15s\tremaining: 6.31ms\n",
      "499:\tlearn: 0.0028003\ttotal: 3.15s\tremaining: 0us\n",
      "0:\tlearn: 0.6347583\ttotal: 6.84ms\tremaining: 3.41s\n",
      "1:\tlearn: 0.5854940\ttotal: 13.1ms\tremaining: 3.27s\n",
      "2:\tlearn: 0.5367634\ttotal: 19.1ms\tremaining: 3.17s\n",
      "3:\tlearn: 0.5098673\ttotal: 25.5ms\tremaining: 3.16s\n",
      "4:\tlearn: 0.4836523\ttotal: 31.7ms\tremaining: 3.13s\n",
      "5:\tlearn: 0.4558210\ttotal: 38ms\tremaining: 3.13s\n",
      "6:\tlearn: 0.4213961\ttotal: 43.3ms\tremaining: 3.05s\n",
      "7:\tlearn: 0.3955892\ttotal: 48.3ms\tremaining: 2.97s\n",
      "8:\tlearn: 0.3570145\ttotal: 53ms\tremaining: 2.89s\n",
      "9:\tlearn: 0.3309267\ttotal: 57.7ms\tremaining: 2.83s\n",
      "10:\tlearn: 0.3049106\ttotal: 62.3ms\tremaining: 2.77s\n",
      "11:\tlearn: 0.2863777\ttotal: 66.8ms\tremaining: 2.72s\n",
      "12:\tlearn: 0.2658933\ttotal: 71.7ms\tremaining: 2.69s\n",
      "13:\tlearn: 0.2496739\ttotal: 76ms\tremaining: 2.64s\n",
      "14:\tlearn: 0.2312936\ttotal: 80.2ms\tremaining: 2.59s\n",
      "15:\tlearn: 0.2149896\ttotal: 84.8ms\tremaining: 2.56s\n",
      "16:\tlearn: 0.1987747\ttotal: 89.3ms\tremaining: 2.54s\n",
      "17:\tlearn: 0.1840095\ttotal: 93.7ms\tremaining: 2.51s\n",
      "18:\tlearn: 0.1732831\ttotal: 98.1ms\tremaining: 2.48s\n",
      "19:\tlearn: 0.1565043\ttotal: 102ms\tremaining: 2.46s\n",
      "20:\tlearn: 0.1464909\ttotal: 112ms\tremaining: 2.56s\n",
      "21:\tlearn: 0.1369595\ttotal: 122ms\tremaining: 2.65s\n",
      "22:\tlearn: 0.1318331\ttotal: 132ms\tremaining: 2.73s\n",
      "23:\tlearn: 0.1234471\ttotal: 141ms\tremaining: 2.8s\n",
      "24:\tlearn: 0.1166124\ttotal: 151ms\tremaining: 2.86s\n",
      "25:\tlearn: 0.1083592\ttotal: 161ms\tremaining: 2.93s\n",
      "26:\tlearn: 0.0994299\ttotal: 170ms\tremaining: 2.98s\n",
      "27:\tlearn: 0.0950245\ttotal: 180ms\tremaining: 3.03s\n",
      "28:\tlearn: 0.0893637\ttotal: 187ms\tremaining: 3.03s\n",
      "29:\tlearn: 0.0833558\ttotal: 193ms\tremaining: 3.03s\n",
      "30:\tlearn: 0.0807565\ttotal: 203ms\tremaining: 3.07s\n",
      "31:\tlearn: 0.0749140\ttotal: 209ms\tremaining: 3.06s\n",
      "32:\tlearn: 0.0723185\ttotal: 214ms\tremaining: 3.03s\n",
      "33:\tlearn: 0.0702027\ttotal: 219ms\tremaining: 3s\n",
      "34:\tlearn: 0.0662819\ttotal: 223ms\tremaining: 2.97s\n",
      "35:\tlearn: 0.0638255\ttotal: 228ms\tremaining: 2.93s\n",
      "36:\tlearn: 0.0613740\ttotal: 232ms\tremaining: 2.91s\n",
      "37:\tlearn: 0.0589365\ttotal: 237ms\tremaining: 2.88s\n",
      "38:\tlearn: 0.0558925\ttotal: 241ms\tremaining: 2.85s\n",
      "39:\tlearn: 0.0531519\ttotal: 246ms\tremaining: 2.83s\n",
      "40:\tlearn: 0.0505287\ttotal: 250ms\tremaining: 2.8s\n",
      "41:\tlearn: 0.0479277\ttotal: 254ms\tremaining: 2.77s\n",
      "42:\tlearn: 0.0438653\ttotal: 259ms\tremaining: 2.75s\n",
      "43:\tlearn: 0.0414841\ttotal: 263ms\tremaining: 2.73s\n",
      "44:\tlearn: 0.0388891\ttotal: 267ms\tremaining: 2.7s\n",
      "45:\tlearn: 0.0370134\ttotal: 272ms\tremaining: 2.68s\n",
      "46:\tlearn: 0.0347341\ttotal: 276ms\tremaining: 2.66s\n",
      "47:\tlearn: 0.0328234\ttotal: 280ms\tremaining: 2.64s\n",
      "48:\tlearn: 0.0316222\ttotal: 290ms\tremaining: 2.67s\n",
      "49:\tlearn: 0.0298462\ttotal: 300ms\tremaining: 2.69s\n",
      "50:\tlearn: 0.0280957\ttotal: 309ms\tremaining: 2.72s\n",
      "51:\tlearn: 0.0261735\ttotal: 319ms\tremaining: 2.75s\n",
      "52:\tlearn: 0.0251483\ttotal: 329ms\tremaining: 2.77s\n",
      "53:\tlearn: 0.0241607\ttotal: 338ms\tremaining: 2.79s\n",
      "54:\tlearn: 0.0232434\ttotal: 348ms\tremaining: 2.81s\n",
      "55:\tlearn: 0.0223279\ttotal: 356ms\tremaining: 2.83s\n",
      "56:\tlearn: 0.0216961\ttotal: 365ms\tremaining: 2.83s\n",
      "57:\tlearn: 0.0207752\ttotal: 371ms\tremaining: 2.83s\n",
      "58:\tlearn: 0.0198340\ttotal: 378ms\tremaining: 2.83s\n",
      "59:\tlearn: 0.0188848\ttotal: 386ms\tremaining: 2.83s\n",
      "60:\tlearn: 0.0181985\ttotal: 391ms\tremaining: 2.81s\n",
      "61:\tlearn: 0.0175267\ttotal: 395ms\tremaining: 2.79s\n",
      "62:\tlearn: 0.0168402\ttotal: 399ms\tremaining: 2.77s\n",
      "63:\tlearn: 0.0163497\ttotal: 404ms\tremaining: 2.75s\n",
      "64:\tlearn: 0.0159883\ttotal: 408ms\tremaining: 2.73s\n",
      "65:\tlearn: 0.0154453\ttotal: 413ms\tremaining: 2.71s\n",
      "66:\tlearn: 0.0147092\ttotal: 417ms\tremaining: 2.69s\n",
      "67:\tlearn: 0.0138175\ttotal: 421ms\tremaining: 2.68s\n",
      "68:\tlearn: 0.0130312\ttotal: 426ms\tremaining: 2.66s\n",
      "69:\tlearn: 0.0126833\ttotal: 430ms\tremaining: 2.64s\n",
      "70:\tlearn: 0.0121267\ttotal: 434ms\tremaining: 2.62s\n",
      "71:\tlearn: 0.0117968\ttotal: 439ms\tremaining: 2.61s\n",
      "72:\tlearn: 0.0115904\ttotal: 450ms\tremaining: 2.63s\n",
      "73:\tlearn: 0.0111530\ttotal: 460ms\tremaining: 2.65s\n",
      "74:\tlearn: 0.0105918\ttotal: 470ms\tremaining: 2.66s\n",
      "75:\tlearn: 0.0102915\ttotal: 479ms\tremaining: 2.67s\n",
      "76:\tlearn: 0.0097327\ttotal: 489ms\tremaining: 2.69s\n",
      "77:\tlearn: 0.0097307\ttotal: 496ms\tremaining: 2.68s\n",
      "78:\tlearn: 0.0092520\ttotal: 503ms\tremaining: 2.68s\n",
      "79:\tlearn: 0.0091108\ttotal: 509ms\tremaining: 2.67s\n",
      "80:\tlearn: 0.0088317\ttotal: 516ms\tremaining: 2.67s\n",
      "81:\tlearn: 0.0085868\ttotal: 523ms\tremaining: 2.66s\n",
      "82:\tlearn: 0.0082329\ttotal: 529ms\tremaining: 2.66s\n",
      "83:\tlearn: 0.0080948\ttotal: 535ms\tremaining: 2.65s\n",
      "84:\tlearn: 0.0080947\ttotal: 539ms\tremaining: 2.63s\n",
      "85:\tlearn: 0.0080401\ttotal: 544ms\tremaining: 2.62s\n",
      "86:\tlearn: 0.0079614\ttotal: 548ms\tremaining: 2.6s\n",
      "87:\tlearn: 0.0079209\ttotal: 552ms\tremaining: 2.58s\n",
      "88:\tlearn: 0.0076802\ttotal: 556ms\tremaining: 2.57s\n",
      "89:\tlearn: 0.0074650\ttotal: 560ms\tremaining: 2.55s\n",
      "90:\tlearn: 0.0070800\ttotal: 564ms\tremaining: 2.54s\n",
      "91:\tlearn: 0.0070800\ttotal: 568ms\tremaining: 2.52s\n",
      "92:\tlearn: 0.0070797\ttotal: 572ms\tremaining: 2.5s\n",
      "93:\tlearn: 0.0069501\ttotal: 577ms\tremaining: 2.49s\n",
      "94:\tlearn: 0.0066437\ttotal: 586ms\tremaining: 2.5s\n",
      "95:\tlearn: 0.0063460\ttotal: 596ms\tremaining: 2.51s\n",
      "96:\tlearn: 0.0063458\ttotal: 605ms\tremaining: 2.51s\n",
      "97:\tlearn: 0.0063453\ttotal: 615ms\tremaining: 2.52s\n",
      "98:\tlearn: 0.0063421\ttotal: 624ms\tremaining: 2.53s\n",
      "99:\tlearn: 0.0062223\ttotal: 634ms\tremaining: 2.53s\n",
      "100:\tlearn: 0.0062221\ttotal: 643ms\tremaining: 2.54s\n",
      "101:\tlearn: 0.0062218\ttotal: 652ms\tremaining: 2.54s\n",
      "102:\tlearn: 0.0062216\ttotal: 661ms\tremaining: 2.55s\n",
      "103:\tlearn: 0.0059602\ttotal: 666ms\tremaining: 2.54s\n",
      "104:\tlearn: 0.0059595\ttotal: 670ms\tremaining: 2.52s\n",
      "105:\tlearn: 0.0059593\ttotal: 675ms\tremaining: 2.51s\n",
      "106:\tlearn: 0.0059593\ttotal: 679ms\tremaining: 2.49s\n",
      "107:\tlearn: 0.0059592\ttotal: 684ms\tremaining: 2.48s\n",
      "108:\tlearn: 0.0059591\ttotal: 688ms\tremaining: 2.47s\n",
      "109:\tlearn: 0.0059591\ttotal: 692ms\tremaining: 2.45s\n",
      "110:\tlearn: 0.0059591\ttotal: 697ms\tremaining: 2.44s\n",
      "111:\tlearn: 0.0059589\ttotal: 701ms\tremaining: 2.43s\n",
      "112:\tlearn: 0.0059587\ttotal: 705ms\tremaining: 2.41s\n",
      "113:\tlearn: 0.0059587\ttotal: 709ms\tremaining: 2.4s\n",
      "114:\tlearn: 0.0059586\ttotal: 713ms\tremaining: 2.39s\n",
      "115:\tlearn: 0.0059584\ttotal: 722ms\tremaining: 2.39s\n",
      "116:\tlearn: 0.0059583\ttotal: 732ms\tremaining: 2.4s\n",
      "117:\tlearn: 0.0059583\ttotal: 741ms\tremaining: 2.4s\n",
      "118:\tlearn: 0.0059582\ttotal: 750ms\tremaining: 2.4s\n",
      "119:\tlearn: 0.0059581\ttotal: 760ms\tremaining: 2.4s\n",
      "120:\tlearn: 0.0059580\ttotal: 769ms\tremaining: 2.41s\n",
      "121:\tlearn: 0.0059579\ttotal: 778ms\tremaining: 2.41s\n",
      "122:\tlearn: 0.0059569\ttotal: 788ms\tremaining: 2.41s\n",
      "123:\tlearn: 0.0059568\ttotal: 797ms\tremaining: 2.42s\n",
      "124:\tlearn: 0.0059568\ttotal: 806ms\tremaining: 2.42s\n",
      "125:\tlearn: 0.0059567\ttotal: 812ms\tremaining: 2.41s\n",
      "126:\tlearn: 0.0059566\ttotal: 818ms\tremaining: 2.4s\n",
      "127:\tlearn: 0.0059566\ttotal: 824ms\tremaining: 2.4s\n",
      "128:\tlearn: 0.0059563\ttotal: 830ms\tremaining: 2.39s\n",
      "129:\tlearn: 0.0059562\ttotal: 834ms\tremaining: 2.37s\n",
      "130:\tlearn: 0.0059559\ttotal: 838ms\tremaining: 2.36s\n",
      "131:\tlearn: 0.0059557\ttotal: 842ms\tremaining: 2.35s\n",
      "132:\tlearn: 0.0059555\ttotal: 846ms\tremaining: 2.33s\n",
      "133:\tlearn: 0.0059555\ttotal: 850ms\tremaining: 2.32s\n",
      "134:\tlearn: 0.0059553\ttotal: 854ms\tremaining: 2.31s\n",
      "135:\tlearn: 0.0059553\ttotal: 858ms\tremaining: 2.3s\n",
      "136:\tlearn: 0.0059553\ttotal: 862ms\tremaining: 2.28s\n",
      "137:\tlearn: 0.0059552\ttotal: 866ms\tremaining: 2.27s\n",
      "138:\tlearn: 0.0059550\ttotal: 870ms\tremaining: 2.26s\n",
      "139:\tlearn: 0.0059548\ttotal: 874ms\tremaining: 2.25s\n",
      "140:\tlearn: 0.0059548\ttotal: 878ms\tremaining: 2.23s\n",
      "141:\tlearn: 0.0059543\ttotal: 883ms\tremaining: 2.23s\n",
      "142:\tlearn: 0.0059542\ttotal: 892ms\tremaining: 2.23s\n",
      "143:\tlearn: 0.0059537\ttotal: 902ms\tremaining: 2.23s\n",
      "144:\tlearn: 0.0059536\ttotal: 911ms\tremaining: 2.23s\n",
      "145:\tlearn: 0.0059536\ttotal: 920ms\tremaining: 2.23s\n",
      "146:\tlearn: 0.0059535\ttotal: 930ms\tremaining: 2.23s\n",
      "147:\tlearn: 0.0059533\ttotal: 940ms\tremaining: 2.23s\n",
      "148:\tlearn: 0.0059528\ttotal: 949ms\tremaining: 2.24s\n",
      "149:\tlearn: 0.0059528\ttotal: 959ms\tremaining: 2.24s\n",
      "150:\tlearn: 0.0059528\ttotal: 968ms\tremaining: 2.24s\n",
      "151:\tlearn: 0.0059528\ttotal: 977ms\tremaining: 2.23s\n",
      "152:\tlearn: 0.0059524\ttotal: 982ms\tremaining: 2.23s\n",
      "153:\tlearn: 0.0059520\ttotal: 988ms\tremaining: 2.22s\n",
      "154:\tlearn: 0.0059458\ttotal: 994ms\tremaining: 2.21s\n",
      "155:\tlearn: 0.0059317\ttotal: 1s\tremaining: 2.21s\n",
      "156:\tlearn: 0.0058459\ttotal: 1.01s\tremaining: 2.2s\n",
      "157:\tlearn: 0.0057496\ttotal: 1.01s\tremaining: 2.19s\n",
      "158:\tlearn: 0.0055287\ttotal: 1.01s\tremaining: 2.18s\n",
      "159:\tlearn: 0.0055287\ttotal: 1.02s\tremaining: 2.17s\n",
      "160:\tlearn: 0.0055284\ttotal: 1.02s\tremaining: 2.16s\n",
      "161:\tlearn: 0.0052678\ttotal: 1.03s\tremaining: 2.15s\n",
      "162:\tlearn: 0.0050623\ttotal: 1.03s\tremaining: 2.14s\n",
      "163:\tlearn: 0.0050607\ttotal: 1.04s\tremaining: 2.13s\n",
      "164:\tlearn: 0.0048999\ttotal: 1.04s\tremaining: 2.12s\n",
      "165:\tlearn: 0.0048995\ttotal: 1.05s\tremaining: 2.1s\n",
      "166:\tlearn: 0.0045954\ttotal: 1.05s\tremaining: 2.1s\n",
      "167:\tlearn: 0.0044232\ttotal: 1.05s\tremaining: 2.08s\n",
      "168:\tlearn: 0.0044231\ttotal: 1.06s\tremaining: 2.07s\n",
      "169:\tlearn: 0.0044231\ttotal: 1.06s\tremaining: 2.06s\n",
      "170:\tlearn: 0.0044231\ttotal: 1.07s\tremaining: 2.07s\n",
      "171:\tlearn: 0.0044231\ttotal: 1.08s\tremaining: 2.07s\n",
      "172:\tlearn: 0.0044230\ttotal: 1.09s\tremaining: 2.07s\n",
      "173:\tlearn: 0.0044229\ttotal: 1.1s\tremaining: 2.07s\n",
      "174:\tlearn: 0.0044228\ttotal: 1.11s\tremaining: 2.07s\n",
      "175:\tlearn: 0.0044229\ttotal: 1.12s\tremaining: 2.06s\n",
      "176:\tlearn: 0.0044227\ttotal: 1.13s\tremaining: 2.06s\n",
      "177:\tlearn: 0.0043254\ttotal: 1.14s\tremaining: 2.06s\n",
      "178:\tlearn: 0.0041864\ttotal: 1.15s\tremaining: 2.06s\n",
      "179:\tlearn: 0.0041862\ttotal: 1.16s\tremaining: 2.05s\n",
      "180:\tlearn: 0.0041857\ttotal: 1.16s\tremaining: 2.05s\n",
      "181:\tlearn: 0.0041855\ttotal: 1.17s\tremaining: 2.04s\n",
      "182:\tlearn: 0.0041852\ttotal: 1.17s\tremaining: 2.03s\n",
      "183:\tlearn: 0.0041847\ttotal: 1.18s\tremaining: 2.02s\n",
      "184:\tlearn: 0.0041846\ttotal: 1.18s\tremaining: 2.01s\n",
      "185:\tlearn: 0.0041454\ttotal: 1.19s\tremaining: 2s\n",
      "186:\tlearn: 0.0041454\ttotal: 1.19s\tremaining: 2s\n",
      "187:\tlearn: 0.0040585\ttotal: 1.2s\tremaining: 1.99s\n",
      "188:\tlearn: 0.0039446\ttotal: 1.2s\tremaining: 1.98s\n",
      "189:\tlearn: 0.0038464\ttotal: 1.21s\tremaining: 1.97s\n",
      "190:\tlearn: 0.0038462\ttotal: 1.21s\tremaining: 1.96s\n",
      "191:\tlearn: 0.0038461\ttotal: 1.22s\tremaining: 1.95s\n",
      "192:\tlearn: 0.0038461\ttotal: 1.22s\tremaining: 1.94s\n",
      "193:\tlearn: 0.0036756\ttotal: 1.22s\tremaining: 1.93s\n",
      "194:\tlearn: 0.0036152\ttotal: 1.23s\tremaining: 1.92s\n",
      "195:\tlearn: 0.0036146\ttotal: 1.23s\tremaining: 1.91s\n",
      "196:\tlearn: 0.0036143\ttotal: 1.24s\tremaining: 1.9s\n",
      "197:\tlearn: 0.0036143\ttotal: 1.25s\tremaining: 1.9s\n",
      "198:\tlearn: 0.0036143\ttotal: 1.25s\tremaining: 1.9s\n",
      "199:\tlearn: 0.0036136\ttotal: 1.26s\tremaining: 1.9s\n",
      "200:\tlearn: 0.0036128\ttotal: 1.27s\tremaining: 1.9s\n",
      "201:\tlearn: 0.0036126\ttotal: 1.28s\tremaining: 1.89s\n",
      "202:\tlearn: 0.0036110\ttotal: 1.29s\tremaining: 1.89s\n",
      "203:\tlearn: 0.0036101\ttotal: 1.3s\tremaining: 1.89s\n",
      "204:\tlearn: 0.0036101\ttotal: 1.31s\tremaining: 1.89s\n",
      "205:\tlearn: 0.0036101\ttotal: 1.32s\tremaining: 1.88s\n",
      "206:\tlearn: 0.0036101\ttotal: 1.32s\tremaining: 1.87s\n",
      "207:\tlearn: 0.0036089\ttotal: 1.33s\tremaining: 1.87s\n",
      "208:\tlearn: 0.0036087\ttotal: 1.33s\tremaining: 1.86s\n",
      "209:\tlearn: 0.0036085\ttotal: 1.34s\tremaining: 1.85s\n",
      "210:\tlearn: 0.0036082\ttotal: 1.35s\tremaining: 1.84s\n",
      "211:\tlearn: 0.0036080\ttotal: 1.35s\tremaining: 1.83s\n",
      "212:\tlearn: 0.0036072\ttotal: 1.35s\tremaining: 1.83s\n",
      "213:\tlearn: 0.0036070\ttotal: 1.36s\tremaining: 1.82s\n",
      "214:\tlearn: 0.0036070\ttotal: 1.36s\tremaining: 1.81s\n",
      "215:\tlearn: 0.0036047\ttotal: 1.37s\tremaining: 1.8s\n",
      "216:\tlearn: 0.0036040\ttotal: 1.37s\tremaining: 1.79s\n",
      "217:\tlearn: 0.0036033\ttotal: 1.38s\tremaining: 1.78s\n",
      "218:\tlearn: 0.0036031\ttotal: 1.38s\tremaining: 1.77s\n",
      "219:\tlearn: 0.0036031\ttotal: 1.38s\tremaining: 1.76s\n",
      "220:\tlearn: 0.0036031\ttotal: 1.39s\tremaining: 1.75s\n",
      "221:\tlearn: 0.0036030\ttotal: 1.39s\tremaining: 1.74s\n",
      "222:\tlearn: 0.0036023\ttotal: 1.4s\tremaining: 1.74s\n",
      "223:\tlearn: 0.0036022\ttotal: 1.41s\tremaining: 1.74s\n",
      "224:\tlearn: 0.0036018\ttotal: 1.42s\tremaining: 1.74s\n",
      "225:\tlearn: 0.0036016\ttotal: 1.43s\tremaining: 1.73s\n",
      "226:\tlearn: 0.0036013\ttotal: 1.44s\tremaining: 1.73s\n",
      "227:\tlearn: 0.0036013\ttotal: 1.45s\tremaining: 1.73s\n",
      "228:\tlearn: 0.0036011\ttotal: 1.46s\tremaining: 1.73s\n",
      "229:\tlearn: 0.0036009\ttotal: 1.47s\tremaining: 1.72s\n",
      "230:\tlearn: 0.0036007\ttotal: 1.48s\tremaining: 1.72s\n",
      "231:\tlearn: 0.0036000\ttotal: 1.48s\tremaining: 1.71s\n",
      "232:\tlearn: 0.0035996\ttotal: 1.49s\tremaining: 1.7s\n",
      "233:\tlearn: 0.0035993\ttotal: 1.49s\tremaining: 1.7s\n",
      "234:\tlearn: 0.0035991\ttotal: 1.5s\tremaining: 1.69s\n",
      "235:\tlearn: 0.0035989\ttotal: 1.5s\tremaining: 1.68s\n",
      "236:\tlearn: 0.0035988\ttotal: 1.5s\tremaining: 1.67s\n",
      "237:\tlearn: 0.0035987\ttotal: 1.51s\tremaining: 1.66s\n",
      "238:\tlearn: 0.0035980\ttotal: 1.51s\tremaining: 1.65s\n",
      "239:\tlearn: 0.0035980\ttotal: 1.52s\tremaining: 1.64s\n",
      "240:\tlearn: 0.0035977\ttotal: 1.52s\tremaining: 1.63s\n",
      "241:\tlearn: 0.0035976\ttotal: 1.52s\tremaining: 1.63s\n",
      "242:\tlearn: 0.0035963\ttotal: 1.53s\tremaining: 1.62s\n",
      "243:\tlearn: 0.0035959\ttotal: 1.53s\tremaining: 1.61s\n",
      "244:\tlearn: 0.0035958\ttotal: 1.54s\tremaining: 1.6s\n",
      "245:\tlearn: 0.0035952\ttotal: 1.54s\tremaining: 1.59s\n",
      "246:\tlearn: 0.0035952\ttotal: 1.54s\tremaining: 1.58s\n",
      "247:\tlearn: 0.0035950\ttotal: 1.55s\tremaining: 1.57s\n",
      "248:\tlearn: 0.0035950\ttotal: 1.55s\tremaining: 1.56s\n",
      "249:\tlearn: 0.0035950\ttotal: 1.56s\tremaining: 1.56s\n",
      "250:\tlearn: 0.0035947\ttotal: 1.56s\tremaining: 1.55s\n",
      "251:\tlearn: 0.0035940\ttotal: 1.57s\tremaining: 1.54s\n",
      "252:\tlearn: 0.0035934\ttotal: 1.58s\tremaining: 1.54s\n",
      "253:\tlearn: 0.0035930\ttotal: 1.59s\tremaining: 1.54s\n",
      "254:\tlearn: 0.0035929\ttotal: 1.6s\tremaining: 1.54s\n",
      "255:\tlearn: 0.0035923\ttotal: 1.61s\tremaining: 1.53s\n",
      "256:\tlearn: 0.0035922\ttotal: 1.62s\tremaining: 1.53s\n",
      "257:\tlearn: 0.0035922\ttotal: 1.63s\tremaining: 1.52s\n",
      "258:\tlearn: 0.0035921\ttotal: 1.64s\tremaining: 1.52s\n",
      "259:\tlearn: 0.0035914\ttotal: 1.64s\tremaining: 1.52s\n",
      "260:\tlearn: 0.0035902\ttotal: 1.65s\tremaining: 1.51s\n",
      "261:\tlearn: 0.0035899\ttotal: 1.65s\tremaining: 1.5s\n",
      "262:\tlearn: 0.0035896\ttotal: 1.66s\tremaining: 1.49s\n",
      "263:\tlearn: 0.0035896\ttotal: 1.66s\tremaining: 1.49s\n",
      "264:\tlearn: 0.0035894\ttotal: 1.67s\tremaining: 1.48s\n",
      "265:\tlearn: 0.0035893\ttotal: 1.67s\tremaining: 1.47s\n",
      "266:\tlearn: 0.0035891\ttotal: 1.67s\tremaining: 1.46s\n",
      "267:\tlearn: 0.0035891\ttotal: 1.68s\tremaining: 1.45s\n",
      "268:\tlearn: 0.0035886\ttotal: 1.68s\tremaining: 1.45s\n",
      "269:\tlearn: 0.0035881\ttotal: 1.69s\tremaining: 1.44s\n",
      "270:\tlearn: 0.0035878\ttotal: 1.69s\tremaining: 1.43s\n",
      "271:\tlearn: 0.0035876\ttotal: 1.7s\tremaining: 1.42s\n",
      "272:\tlearn: 0.0035868\ttotal: 1.7s\tremaining: 1.41s\n",
      "273:\tlearn: 0.0035866\ttotal: 1.7s\tremaining: 1.41s\n",
      "274:\tlearn: 0.0035864\ttotal: 1.71s\tremaining: 1.4s\n",
      "275:\tlearn: 0.0035864\ttotal: 1.72s\tremaining: 1.4s\n",
      "276:\tlearn: 0.0035864\ttotal: 1.73s\tremaining: 1.39s\n",
      "277:\tlearn: 0.0035860\ttotal: 1.74s\tremaining: 1.39s\n",
      "278:\tlearn: 0.0035860\ttotal: 1.75s\tremaining: 1.39s\n",
      "279:\tlearn: 0.0035846\ttotal: 1.76s\tremaining: 1.38s\n",
      "280:\tlearn: 0.0035846\ttotal: 1.77s\tremaining: 1.38s\n",
      "281:\tlearn: 0.0035845\ttotal: 1.78s\tremaining: 1.38s\n",
      "282:\tlearn: 0.0035843\ttotal: 1.79s\tremaining: 1.37s\n",
      "283:\tlearn: 0.0034877\ttotal: 1.8s\tremaining: 1.37s\n",
      "284:\tlearn: 0.0033429\ttotal: 1.8s\tremaining: 1.36s\n",
      "285:\tlearn: 0.0033426\ttotal: 1.81s\tremaining: 1.35s\n",
      "286:\tlearn: 0.0032093\ttotal: 1.81s\tremaining: 1.34s\n",
      "287:\tlearn: 0.0032089\ttotal: 1.82s\tremaining: 1.34s\n",
      "288:\tlearn: 0.0030702\ttotal: 1.82s\tremaining: 1.33s\n",
      "289:\tlearn: 0.0030701\ttotal: 1.82s\tremaining: 1.32s\n",
      "290:\tlearn: 0.0030698\ttotal: 1.83s\tremaining: 1.31s\n",
      "291:\tlearn: 0.0030697\ttotal: 1.83s\tremaining: 1.3s\n",
      "292:\tlearn: 0.0029487\ttotal: 1.83s\tremaining: 1.3s\n",
      "293:\tlearn: 0.0029485\ttotal: 1.84s\tremaining: 1.29s\n",
      "294:\tlearn: 0.0029485\ttotal: 1.84s\tremaining: 1.28s\n",
      "295:\tlearn: 0.0029485\ttotal: 1.85s\tremaining: 1.28s\n",
      "296:\tlearn: 0.0029485\ttotal: 1.86s\tremaining: 1.27s\n",
      "297:\tlearn: 0.0029485\ttotal: 1.87s\tremaining: 1.27s\n",
      "298:\tlearn: 0.0029485\ttotal: 1.88s\tremaining: 1.26s\n",
      "299:\tlearn: 0.0029485\ttotal: 1.89s\tremaining: 1.26s\n",
      "300:\tlearn: 0.0029485\ttotal: 1.9s\tremaining: 1.25s\n",
      "301:\tlearn: 0.0029485\ttotal: 1.91s\tremaining: 1.25s\n",
      "302:\tlearn: 0.0029485\ttotal: 1.92s\tremaining: 1.25s\n",
      "303:\tlearn: 0.0029485\ttotal: 1.93s\tremaining: 1.24s\n",
      "304:\tlearn: 0.0029485\ttotal: 1.94s\tremaining: 1.24s\n",
      "305:\tlearn: 0.0029485\ttotal: 1.94s\tremaining: 1.23s\n",
      "306:\tlearn: 0.0029485\ttotal: 1.95s\tremaining: 1.23s\n",
      "307:\tlearn: 0.0029485\ttotal: 1.95s\tremaining: 1.22s\n",
      "308:\tlearn: 0.0029485\ttotal: 1.96s\tremaining: 1.21s\n",
      "309:\tlearn: 0.0029485\ttotal: 1.96s\tremaining: 1.2s\n",
      "310:\tlearn: 0.0029485\ttotal: 1.97s\tremaining: 1.2s\n",
      "311:\tlearn: 0.0029485\ttotal: 1.97s\tremaining: 1.19s\n",
      "312:\tlearn: 0.0029485\ttotal: 1.98s\tremaining: 1.18s\n",
      "313:\tlearn: 0.0029485\ttotal: 1.98s\tremaining: 1.17s\n",
      "314:\tlearn: 0.0029485\ttotal: 1.99s\tremaining: 1.17s\n",
      "315:\tlearn: 0.0029485\ttotal: 1.99s\tremaining: 1.16s\n",
      "316:\tlearn: 0.0029470\ttotal: 1.99s\tremaining: 1.15s\n",
      "317:\tlearn: 0.0029469\ttotal: 2s\tremaining: 1.14s\n",
      "318:\tlearn: 0.0029469\ttotal: 2s\tremaining: 1.14s\n",
      "319:\tlearn: 0.0029468\ttotal: 2s\tremaining: 1.13s\n",
      "320:\tlearn: 0.0029467\ttotal: 2.01s\tremaining: 1.12s\n",
      "321:\tlearn: 0.0029461\ttotal: 2.01s\tremaining: 1.11s\n",
      "322:\tlearn: 0.0029461\ttotal: 2.02s\tremaining: 1.11s\n",
      "323:\tlearn: 0.0029461\ttotal: 2.03s\tremaining: 1.1s\n",
      "324:\tlearn: 0.0029460\ttotal: 2.04s\tremaining: 1.1s\n",
      "325:\tlearn: 0.0029460\ttotal: 2.05s\tremaining: 1.09s\n",
      "326:\tlearn: 0.0029460\ttotal: 2.06s\tremaining: 1.09s\n",
      "327:\tlearn: 0.0029460\ttotal: 2.07s\tremaining: 1.08s\n",
      "328:\tlearn: 0.0029459\ttotal: 2.08s\tremaining: 1.08s\n",
      "329:\tlearn: 0.0029457\ttotal: 2.09s\tremaining: 1.08s\n",
      "330:\tlearn: 0.0029454\ttotal: 2.1s\tremaining: 1.07s\n",
      "331:\tlearn: 0.0029454\ttotal: 2.1s\tremaining: 1.06s\n",
      "332:\tlearn: 0.0029451\ttotal: 2.11s\tremaining: 1.06s\n",
      "333:\tlearn: 0.0029447\ttotal: 2.12s\tremaining: 1.05s\n",
      "334:\tlearn: 0.0029447\ttotal: 2.12s\tremaining: 1.04s\n",
      "335:\tlearn: 0.0029439\ttotal: 2.13s\tremaining: 1.04s\n",
      "336:\tlearn: 0.0029439\ttotal: 2.13s\tremaining: 1.03s\n",
      "337:\tlearn: 0.0029438\ttotal: 2.14s\tremaining: 1.02s\n",
      "338:\tlearn: 0.0029435\ttotal: 2.14s\tremaining: 1.02s\n",
      "339:\tlearn: 0.0029433\ttotal: 2.15s\tremaining: 1.01s\n",
      "340:\tlearn: 0.0029433\ttotal: 2.15s\tremaining: 1s\n",
      "341:\tlearn: 0.0029433\ttotal: 2.15s\tremaining: 996ms\n",
      "342:\tlearn: 0.0029433\ttotal: 2.16s\tremaining: 989ms\n",
      "343:\tlearn: 0.0029433\ttotal: 2.16s\tremaining: 981ms\n",
      "344:\tlearn: 0.0029433\ttotal: 2.17s\tremaining: 974ms\n",
      "345:\tlearn: 0.0029433\ttotal: 2.17s\tremaining: 967ms\n",
      "346:\tlearn: 0.0029433\ttotal: 2.18s\tremaining: 960ms\n",
      "347:\tlearn: 0.0029432\ttotal: 2.18s\tremaining: 952ms\n",
      "348:\tlearn: 0.0029432\ttotal: 2.18s\tremaining: 945ms\n",
      "349:\tlearn: 0.0029430\ttotal: 2.19s\tremaining: 937ms\n",
      "350:\tlearn: 0.0029430\ttotal: 2.2s\tremaining: 932ms\n",
      "351:\tlearn: 0.0029427\ttotal: 2.21s\tremaining: 927ms\n",
      "352:\tlearn: 0.0029427\ttotal: 2.21s\tremaining: 923ms\n",
      "353:\tlearn: 0.0029426\ttotal: 2.22s\tremaining: 918ms\n",
      "354:\tlearn: 0.0029426\ttotal: 2.23s\tremaining: 913ms\n",
      "355:\tlearn: 0.0029425\ttotal: 2.24s\tremaining: 908ms\n",
      "356:\tlearn: 0.0029422\ttotal: 2.25s\tremaining: 903ms\n",
      "357:\tlearn: 0.0029422\ttotal: 2.26s\tremaining: 898ms\n",
      "358:\tlearn: 0.0029421\ttotal: 2.27s\tremaining: 893ms\n",
      "359:\tlearn: 0.0029421\ttotal: 2.28s\tremaining: 887ms\n",
      "360:\tlearn: 0.0029420\ttotal: 2.29s\tremaining: 880ms\n",
      "361:\tlearn: 0.0029419\ttotal: 2.29s\tremaining: 874ms\n",
      "362:\tlearn: 0.0029417\ttotal: 2.3s\tremaining: 867ms\n",
      "363:\tlearn: 0.0029417\ttotal: 2.3s\tremaining: 861ms\n",
      "364:\tlearn: 0.0029417\ttotal: 2.31s\tremaining: 854ms\n",
      "365:\tlearn: 0.0029416\ttotal: 2.31s\tremaining: 847ms\n",
      "366:\tlearn: 0.0029416\ttotal: 2.32s\tremaining: 840ms\n",
      "367:\tlearn: 0.0029415\ttotal: 2.32s\tremaining: 834ms\n",
      "368:\tlearn: 0.0029414\ttotal: 2.33s\tremaining: 827ms\n",
      "369:\tlearn: 0.0029413\ttotal: 2.33s\tremaining: 820ms\n",
      "370:\tlearn: 0.0029411\ttotal: 2.34s\tremaining: 813ms\n",
      "371:\tlearn: 0.0029410\ttotal: 2.34s\tremaining: 806ms\n",
      "372:\tlearn: 0.0029410\ttotal: 2.35s\tremaining: 798ms\n",
      "373:\tlearn: 0.0029409\ttotal: 2.35s\tremaining: 791ms\n",
      "374:\tlearn: 0.0029409\ttotal: 2.35s\tremaining: 784ms\n",
      "375:\tlearn: 0.0029408\ttotal: 2.37s\tremaining: 780ms\n",
      "376:\tlearn: 0.0029407\ttotal: 2.38s\tremaining: 775ms\n",
      "377:\tlearn: 0.0029406\ttotal: 2.38s\tremaining: 770ms\n",
      "378:\tlearn: 0.0029404\ttotal: 2.39s\tremaining: 764ms\n",
      "379:\tlearn: 0.0029393\ttotal: 2.4s\tremaining: 759ms\n",
      "380:\tlearn: 0.0029394\ttotal: 2.41s\tremaining: 754ms\n",
      "381:\tlearn: 0.0029393\ttotal: 2.42s\tremaining: 749ms\n",
      "382:\tlearn: 0.0029390\ttotal: 2.43s\tremaining: 743ms\n",
      "383:\tlearn: 0.0029389\ttotal: 2.44s\tremaining: 738ms\n",
      "384:\tlearn: 0.0029386\ttotal: 2.45s\tremaining: 732ms\n",
      "385:\tlearn: 0.0029382\ttotal: 2.46s\tremaining: 726ms\n",
      "386:\tlearn: 0.0029381\ttotal: 2.46s\tremaining: 719ms\n",
      "387:\tlearn: 0.0029381\ttotal: 2.47s\tremaining: 713ms\n",
      "388:\tlearn: 0.0029381\ttotal: 2.47s\tremaining: 706ms\n",
      "389:\tlearn: 0.0029381\ttotal: 2.48s\tremaining: 699ms\n",
      "390:\tlearn: 0.0029379\ttotal: 2.48s\tremaining: 692ms\n",
      "391:\tlearn: 0.0029377\ttotal: 2.49s\tremaining: 685ms\n",
      "392:\tlearn: 0.0029376\ttotal: 2.49s\tremaining: 678ms\n",
      "393:\tlearn: 0.0029376\ttotal: 2.5s\tremaining: 672ms\n",
      "394:\tlearn: 0.0029374\ttotal: 2.5s\tremaining: 665ms\n",
      "395:\tlearn: 0.0029373\ttotal: 2.5s\tremaining: 658ms\n",
      "396:\tlearn: 0.0029369\ttotal: 2.51s\tremaining: 651ms\n",
      "397:\tlearn: 0.0029369\ttotal: 2.51s\tremaining: 644ms\n",
      "398:\tlearn: 0.0029369\ttotal: 2.52s\tremaining: 637ms\n",
      "399:\tlearn: 0.0029368\ttotal: 2.52s\tremaining: 630ms\n",
      "400:\tlearn: 0.0029367\ttotal: 2.52s\tremaining: 623ms\n",
      "401:\tlearn: 0.0029361\ttotal: 2.53s\tremaining: 618ms\n",
      "402:\tlearn: 0.0029357\ttotal: 2.54s\tremaining: 612ms\n",
      "403:\tlearn: 0.0029355\ttotal: 2.55s\tremaining: 607ms\n",
      "404:\tlearn: 0.0027935\ttotal: 2.56s\tremaining: 601ms\n",
      "405:\tlearn: 0.0026220\ttotal: 2.57s\tremaining: 596ms\n",
      "406:\tlearn: 0.0026216\ttotal: 2.58s\tremaining: 590ms\n",
      "407:\tlearn: 0.0026216\ttotal: 2.59s\tremaining: 584ms\n",
      "408:\tlearn: 0.0025777\ttotal: 2.6s\tremaining: 579ms\n",
      "409:\tlearn: 0.0025777\ttotal: 2.61s\tremaining: 573ms\n",
      "410:\tlearn: 0.0025774\ttotal: 2.62s\tremaining: 566ms\n",
      "411:\tlearn: 0.0025773\ttotal: 2.62s\tremaining: 560ms\n",
      "412:\tlearn: 0.0025773\ttotal: 2.63s\tremaining: 553ms\n",
      "413:\tlearn: 0.0025771\ttotal: 2.63s\tremaining: 547ms\n",
      "414:\tlearn: 0.0025770\ttotal: 2.64s\tremaining: 540ms\n",
      "415:\tlearn: 0.0025770\ttotal: 2.64s\tremaining: 534ms\n",
      "416:\tlearn: 0.0025765\ttotal: 2.65s\tremaining: 527ms\n",
      "417:\tlearn: 0.0025765\ttotal: 2.65s\tremaining: 520ms\n",
      "418:\tlearn: 0.0025763\ttotal: 2.65s\tremaining: 513ms\n",
      "419:\tlearn: 0.0025763\ttotal: 2.66s\tremaining: 507ms\n",
      "420:\tlearn: 0.0025762\ttotal: 2.66s\tremaining: 500ms\n",
      "421:\tlearn: 0.0025759\ttotal: 2.67s\tremaining: 493ms\n",
      "422:\tlearn: 0.0025759\ttotal: 2.67s\tremaining: 487ms\n",
      "423:\tlearn: 0.0025759\ttotal: 2.68s\tremaining: 480ms\n",
      "424:\tlearn: 0.0025758\ttotal: 2.68s\tremaining: 473ms\n",
      "425:\tlearn: 0.0025757\ttotal: 2.68s\tremaining: 466ms\n",
      "426:\tlearn: 0.0025756\ttotal: 2.69s\tremaining: 460ms\n",
      "427:\tlearn: 0.0025755\ttotal: 2.69s\tremaining: 453ms\n",
      "428:\tlearn: 0.0025755\ttotal: 2.7s\tremaining: 447ms\n",
      "429:\tlearn: 0.0025755\ttotal: 2.71s\tremaining: 441ms\n",
      "430:\tlearn: 0.0025755\ttotal: 2.72s\tremaining: 436ms\n",
      "431:\tlearn: 0.0025754\ttotal: 2.73s\tremaining: 430ms\n",
      "432:\tlearn: 0.0025752\ttotal: 2.74s\tremaining: 424ms\n",
      "433:\tlearn: 0.0025752\ttotal: 2.75s\tremaining: 418ms\n",
      "434:\tlearn: 0.0025751\ttotal: 2.76s\tremaining: 412ms\n",
      "435:\tlearn: 0.0025751\ttotal: 2.77s\tremaining: 406ms\n",
      "436:\tlearn: 0.0025749\ttotal: 2.78s\tremaining: 400ms\n",
      "437:\tlearn: 0.0025749\ttotal: 2.78s\tremaining: 394ms\n",
      "438:\tlearn: 0.0025747\ttotal: 2.79s\tremaining: 388ms\n",
      "439:\tlearn: 0.0025747\ttotal: 2.79s\tremaining: 381ms\n",
      "440:\tlearn: 0.0025747\ttotal: 2.8s\tremaining: 375ms\n",
      "441:\tlearn: 0.0025743\ttotal: 2.81s\tremaining: 368ms\n",
      "442:\tlearn: 0.0025740\ttotal: 2.81s\tremaining: 362ms\n",
      "443:\tlearn: 0.0025740\ttotal: 2.81s\tremaining: 355ms\n",
      "444:\tlearn: 0.0025740\ttotal: 2.82s\tremaining: 349ms\n",
      "445:\tlearn: 0.0025736\ttotal: 2.82s\tremaining: 342ms\n",
      "446:\tlearn: 0.0025734\ttotal: 2.83s\tremaining: 335ms\n",
      "447:\tlearn: 0.0025733\ttotal: 2.83s\tremaining: 329ms\n",
      "448:\tlearn: 0.0025732\ttotal: 2.84s\tremaining: 322ms\n",
      "449:\tlearn: 0.0025731\ttotal: 2.84s\tremaining: 316ms\n",
      "450:\tlearn: 0.0025730\ttotal: 2.85s\tremaining: 309ms\n",
      "451:\tlearn: 0.0025724\ttotal: 2.85s\tremaining: 303ms\n",
      "452:\tlearn: 0.0025022\ttotal: 2.85s\tremaining: 296ms\n",
      "453:\tlearn: 0.0024312\ttotal: 2.86s\tremaining: 290ms\n",
      "454:\tlearn: 0.0024312\ttotal: 2.86s\tremaining: 283ms\n",
      "455:\tlearn: 0.0024310\ttotal: 2.87s\tremaining: 277ms\n",
      "456:\tlearn: 0.0024309\ttotal: 2.88s\tremaining: 271ms\n",
      "457:\tlearn: 0.0024309\ttotal: 2.88s\tremaining: 265ms\n",
      "458:\tlearn: 0.0024305\ttotal: 2.89s\tremaining: 259ms\n",
      "459:\tlearn: 0.0024305\ttotal: 2.9s\tremaining: 253ms\n",
      "460:\tlearn: 0.0023873\ttotal: 2.91s\tremaining: 247ms\n",
      "461:\tlearn: 0.0022983\ttotal: 2.92s\tremaining: 241ms\n",
      "462:\tlearn: 0.0022979\ttotal: 2.93s\tremaining: 234ms\n",
      "463:\tlearn: 0.0022969\ttotal: 2.94s\tremaining: 228ms\n",
      "464:\tlearn: 0.0022969\ttotal: 2.95s\tremaining: 222ms\n",
      "465:\tlearn: 0.0022967\ttotal: 2.95s\tremaining: 215ms\n",
      "466:\tlearn: 0.0022963\ttotal: 2.96s\tremaining: 209ms\n",
      "467:\tlearn: 0.0022963\ttotal: 2.96s\tremaining: 203ms\n",
      "468:\tlearn: 0.0022964\ttotal: 2.97s\tremaining: 196ms\n",
      "469:\tlearn: 0.0022961\ttotal: 2.97s\tremaining: 190ms\n",
      "470:\tlearn: 0.0022960\ttotal: 2.98s\tremaining: 183ms\n",
      "471:\tlearn: 0.0022960\ttotal: 2.98s\tremaining: 177ms\n",
      "472:\tlearn: 0.0022957\ttotal: 2.98s\tremaining: 170ms\n",
      "473:\tlearn: 0.0022957\ttotal: 2.99s\tremaining: 164ms\n",
      "474:\tlearn: 0.0022956\ttotal: 2.99s\tremaining: 158ms\n",
      "475:\tlearn: 0.0022934\ttotal: 3s\tremaining: 151ms\n",
      "476:\tlearn: 0.0022933\ttotal: 3s\tremaining: 145ms\n",
      "477:\tlearn: 0.0021861\ttotal: 3s\tremaining: 138ms\n",
      "478:\tlearn: 0.0021859\ttotal: 3.01s\tremaining: 132ms\n",
      "479:\tlearn: 0.0021858\ttotal: 3.01s\tremaining: 126ms\n",
      "480:\tlearn: 0.0021858\ttotal: 3.02s\tremaining: 119ms\n",
      "481:\tlearn: 0.0021857\ttotal: 3.02s\tremaining: 113ms\n",
      "482:\tlearn: 0.0021856\ttotal: 3.02s\tremaining: 106ms\n",
      "483:\tlearn: 0.0021856\ttotal: 3.03s\tremaining: 100ms\n",
      "484:\tlearn: 0.0021846\ttotal: 3.03s\tremaining: 93.8ms\n",
      "485:\tlearn: 0.0021841\ttotal: 3.04s\tremaining: 87.7ms\n",
      "486:\tlearn: 0.0021837\ttotal: 3.05s\tremaining: 81.5ms\n",
      "487:\tlearn: 0.0021831\ttotal: 3.06s\tremaining: 75.3ms\n",
      "488:\tlearn: 0.0021829\ttotal: 3.07s\tremaining: 69.1ms\n",
      "489:\tlearn: 0.0021829\ttotal: 3.08s\tremaining: 62.9ms\n",
      "490:\tlearn: 0.0021829\ttotal: 3.09s\tremaining: 56.7ms\n",
      "491:\tlearn: 0.0021827\ttotal: 3.1s\tremaining: 50.4ms\n",
      "492:\tlearn: 0.0021824\ttotal: 3.11s\tremaining: 44.1ms\n",
      "493:\tlearn: 0.0021824\ttotal: 3.11s\tremaining: 37.8ms\n",
      "494:\tlearn: 0.0021824\ttotal: 3.12s\tremaining: 31.5ms\n",
      "495:\tlearn: 0.0021823\ttotal: 3.12s\tremaining: 25.2ms\n",
      "496:\tlearn: 0.0021823\ttotal: 3.13s\tremaining: 18.9ms\n",
      "497:\tlearn: 0.0021822\ttotal: 3.13s\tremaining: 12.6ms\n",
      "498:\tlearn: 0.0021821\ttotal: 3.14s\tremaining: 6.29ms\n",
      "499:\tlearn: 0.0021821\ttotal: 3.14s\tremaining: 0us\n",
      "0:\tlearn: 0.6353084\ttotal: 6.6ms\tremaining: 3.29s\n",
      "1:\tlearn: 0.5911950\ttotal: 12.9ms\tremaining: 3.22s\n",
      "2:\tlearn: 0.5505101\ttotal: 19.2ms\tremaining: 3.17s\n",
      "3:\tlearn: 0.5097706\ttotal: 25.3ms\tremaining: 3.14s\n",
      "4:\tlearn: 0.4676831\ttotal: 31.5ms\tremaining: 3.12s\n",
      "5:\tlearn: 0.4430277\ttotal: 37.7ms\tremaining: 3.1s\n",
      "6:\tlearn: 0.4121852\ttotal: 42.3ms\tremaining: 2.98s\n",
      "7:\tlearn: 0.3844799\ttotal: 46.8ms\tremaining: 2.88s\n",
      "8:\tlearn: 0.3613238\ttotal: 51.3ms\tremaining: 2.8s\n",
      "9:\tlearn: 0.3298554\ttotal: 56.3ms\tremaining: 2.76s\n",
      "10:\tlearn: 0.3087097\ttotal: 60.9ms\tremaining: 2.71s\n",
      "11:\tlearn: 0.2837633\ttotal: 65.5ms\tremaining: 2.66s\n",
      "12:\tlearn: 0.2638780\ttotal: 70.1ms\tremaining: 2.63s\n",
      "13:\tlearn: 0.2499784\ttotal: 74.4ms\tremaining: 2.58s\n",
      "14:\tlearn: 0.2339231\ttotal: 78.6ms\tremaining: 2.54s\n",
      "15:\tlearn: 0.2192553\ttotal: 83ms\tremaining: 2.51s\n",
      "16:\tlearn: 0.2031577\ttotal: 87ms\tremaining: 2.47s\n",
      "17:\tlearn: 0.1923008\ttotal: 91.2ms\tremaining: 2.44s\n",
      "18:\tlearn: 0.1790403\ttotal: 95.5ms\tremaining: 2.42s\n",
      "19:\tlearn: 0.1692537\ttotal: 100ms\tremaining: 2.4s\n",
      "20:\tlearn: 0.1588120\ttotal: 110ms\tremaining: 2.51s\n",
      "21:\tlearn: 0.1475572\ttotal: 120ms\tremaining: 2.6s\n",
      "22:\tlearn: 0.1393386\ttotal: 130ms\tremaining: 2.69s\n",
      "23:\tlearn: 0.1300054\ttotal: 139ms\tremaining: 2.76s\n",
      "24:\tlearn: 0.1243444\ttotal: 149ms\tremaining: 2.83s\n",
      "25:\tlearn: 0.1211531\ttotal: 159ms\tremaining: 2.89s\n",
      "26:\tlearn: 0.1139294\ttotal: 168ms\tremaining: 2.94s\n",
      "27:\tlearn: 0.1086062\ttotal: 175ms\tremaining: 2.96s\n",
      "28:\tlearn: 0.1039239\ttotal: 182ms\tremaining: 2.96s\n",
      "29:\tlearn: 0.1001129\ttotal: 186ms\tremaining: 2.92s\n",
      "30:\tlearn: 0.0925077\ttotal: 194ms\tremaining: 2.94s\n",
      "31:\tlearn: 0.0871271\ttotal: 201ms\tremaining: 2.93s\n",
      "32:\tlearn: 0.0823796\ttotal: 205ms\tremaining: 2.9s\n",
      "33:\tlearn: 0.0790435\ttotal: 210ms\tremaining: 2.87s\n",
      "34:\tlearn: 0.0759862\ttotal: 214ms\tremaining: 2.84s\n",
      "35:\tlearn: 0.0700331\ttotal: 218ms\tremaining: 2.81s\n",
      "36:\tlearn: 0.0666475\ttotal: 223ms\tremaining: 2.79s\n",
      "37:\tlearn: 0.0634796\ttotal: 227ms\tremaining: 2.76s\n",
      "38:\tlearn: 0.0611484\ttotal: 231ms\tremaining: 2.73s\n",
      "39:\tlearn: 0.0571258\ttotal: 236ms\tremaining: 2.71s\n",
      "40:\tlearn: 0.0554467\ttotal: 245ms\tremaining: 2.75s\n",
      "41:\tlearn: 0.0522443\ttotal: 255ms\tremaining: 2.79s\n",
      "42:\tlearn: 0.0499122\ttotal: 265ms\tremaining: 2.82s\n",
      "43:\tlearn: 0.0480808\ttotal: 275ms\tremaining: 2.85s\n",
      "44:\tlearn: 0.0450330\ttotal: 285ms\tremaining: 2.88s\n",
      "45:\tlearn: 0.0433780\ttotal: 294ms\tremaining: 2.9s\n",
      "46:\tlearn: 0.0418934\ttotal: 304ms\tremaining: 2.93s\n",
      "47:\tlearn: 0.0405643\ttotal: 314ms\tremaining: 2.95s\n",
      "48:\tlearn: 0.0394504\ttotal: 323ms\tremaining: 2.97s\n",
      "49:\tlearn: 0.0376680\ttotal: 330ms\tremaining: 2.97s\n",
      "50:\tlearn: 0.0354862\ttotal: 336ms\tremaining: 2.96s\n",
      "51:\tlearn: 0.0328380\ttotal: 342ms\tremaining: 2.95s\n",
      "52:\tlearn: 0.0312960\ttotal: 348ms\tremaining: 2.94s\n",
      "53:\tlearn: 0.0304205\ttotal: 355ms\tremaining: 2.93s\n",
      "54:\tlearn: 0.0291440\ttotal: 361ms\tremaining: 2.92s\n",
      "55:\tlearn: 0.0275406\ttotal: 368ms\tremaining: 2.91s\n",
      "56:\tlearn: 0.0263544\ttotal: 374ms\tremaining: 2.91s\n",
      "57:\tlearn: 0.0256214\ttotal: 378ms\tremaining: 2.88s\n",
      "58:\tlearn: 0.0243899\ttotal: 383ms\tremaining: 2.86s\n",
      "59:\tlearn: 0.0229250\ttotal: 387ms\tremaining: 2.83s\n",
      "60:\tlearn: 0.0219451\ttotal: 391ms\tremaining: 2.81s\n",
      "61:\tlearn: 0.0216803\ttotal: 395ms\tremaining: 2.79s\n",
      "62:\tlearn: 0.0206694\ttotal: 400ms\tremaining: 2.77s\n",
      "63:\tlearn: 0.0199812\ttotal: 409ms\tremaining: 2.79s\n",
      "64:\tlearn: 0.0194106\ttotal: 419ms\tremaining: 2.8s\n",
      "65:\tlearn: 0.0187823\ttotal: 429ms\tremaining: 2.82s\n",
      "66:\tlearn: 0.0178739\ttotal: 438ms\tremaining: 2.83s\n",
      "67:\tlearn: 0.0170656\ttotal: 448ms\tremaining: 2.85s\n",
      "68:\tlearn: 0.0161985\ttotal: 458ms\tremaining: 2.86s\n",
      "69:\tlearn: 0.0153152\ttotal: 468ms\tremaining: 2.87s\n",
      "70:\tlearn: 0.0148580\ttotal: 477ms\tremaining: 2.88s\n",
      "71:\tlearn: 0.0142508\ttotal: 487ms\tremaining: 2.89s\n",
      "72:\tlearn: 0.0134730\ttotal: 495ms\tremaining: 2.89s\n",
      "73:\tlearn: 0.0131838\ttotal: 501ms\tremaining: 2.88s\n",
      "74:\tlearn: 0.0127181\ttotal: 507ms\tremaining: 2.87s\n",
      "75:\tlearn: 0.0125556\ttotal: 514ms\tremaining: 2.87s\n",
      "76:\tlearn: 0.0120469\ttotal: 520ms\tremaining: 2.85s\n",
      "77:\tlearn: 0.0114483\ttotal: 526ms\tremaining: 2.85s\n",
      "78:\tlearn: 0.0108334\ttotal: 532ms\tremaining: 2.83s\n",
      "79:\tlearn: 0.0102443\ttotal: 537ms\tremaining: 2.82s\n",
      "80:\tlearn: 0.0096196\ttotal: 541ms\tremaining: 2.8s\n",
      "81:\tlearn: 0.0091004\ttotal: 546ms\tremaining: 2.78s\n",
      "82:\tlearn: 0.0087571\ttotal: 551ms\tremaining: 2.77s\n",
      "83:\tlearn: 0.0084952\ttotal: 554ms\tremaining: 2.74s\n",
      "84:\tlearn: 0.0083291\ttotal: 558ms\tremaining: 2.72s\n",
      "85:\tlearn: 0.0080397\ttotal: 562ms\tremaining: 2.7s\n",
      "86:\tlearn: 0.0078461\ttotal: 566ms\tremaining: 2.69s\n",
      "87:\tlearn: 0.0075398\ttotal: 570ms\tremaining: 2.67s\n",
      "88:\tlearn: 0.0073678\ttotal: 575ms\tremaining: 2.65s\n",
      "89:\tlearn: 0.0071996\ttotal: 585ms\tremaining: 2.66s\n",
      "90:\tlearn: 0.0070812\ttotal: 594ms\tremaining: 2.67s\n",
      "91:\tlearn: 0.0068131\ttotal: 604ms\tremaining: 2.68s\n",
      "92:\tlearn: 0.0066030\ttotal: 614ms\tremaining: 2.69s\n",
      "93:\tlearn: 0.0063587\ttotal: 624ms\tremaining: 2.69s\n",
      "94:\tlearn: 0.0061738\ttotal: 633ms\tremaining: 2.7s\n",
      "95:\tlearn: 0.0059509\ttotal: 643ms\tremaining: 2.71s\n",
      "96:\tlearn: 0.0058559\ttotal: 653ms\tremaining: 2.71s\n",
      "97:\tlearn: 0.0055819\ttotal: 662ms\tremaining: 2.72s\n",
      "98:\tlearn: 0.0055338\ttotal: 670ms\tremaining: 2.71s\n",
      "99:\tlearn: 0.0052658\ttotal: 676ms\tremaining: 2.71s\n",
      "100:\tlearn: 0.0050268\ttotal: 683ms\tremaining: 2.7s\n",
      "101:\tlearn: 0.0048894\ttotal: 689ms\tremaining: 2.69s\n",
      "102:\tlearn: 0.0048894\ttotal: 695ms\tremaining: 2.68s\n",
      "103:\tlearn: 0.0046716\ttotal: 700ms\tremaining: 2.67s\n",
      "104:\tlearn: 0.0045516\ttotal: 705ms\tremaining: 2.65s\n",
      "105:\tlearn: 0.0044072\ttotal: 710ms\tremaining: 2.64s\n",
      "106:\tlearn: 0.0044071\ttotal: 714ms\tremaining: 2.62s\n",
      "107:\tlearn: 0.0044069\ttotal: 718ms\tremaining: 2.61s\n",
      "108:\tlearn: 0.0044070\ttotal: 723ms\tremaining: 2.59s\n",
      "109:\tlearn: 0.0044067\ttotal: 727ms\tremaining: 2.58s\n",
      "110:\tlearn: 0.0043302\ttotal: 733ms\tremaining: 2.57s\n",
      "111:\tlearn: 0.0043118\ttotal: 737ms\tremaining: 2.55s\n",
      "112:\tlearn: 0.0041617\ttotal: 741ms\tremaining: 2.54s\n",
      "113:\tlearn: 0.0041616\ttotal: 744ms\tremaining: 2.52s\n",
      "114:\tlearn: 0.0041616\ttotal: 753ms\tremaining: 2.52s\n",
      "115:\tlearn: 0.0041611\ttotal: 763ms\tremaining: 2.52s\n",
      "116:\tlearn: 0.0041149\ttotal: 773ms\tremaining: 2.53s\n",
      "117:\tlearn: 0.0041148\ttotal: 782ms\tremaining: 2.53s\n",
      "118:\tlearn: 0.0041145\ttotal: 792ms\tremaining: 2.53s\n",
      "119:\tlearn: 0.0041145\ttotal: 801ms\tremaining: 2.54s\n",
      "120:\tlearn: 0.0040200\ttotal: 810ms\tremaining: 2.54s\n",
      "121:\tlearn: 0.0039428\ttotal: 820ms\tremaining: 2.54s\n",
      "122:\tlearn: 0.0038442\ttotal: 830ms\tremaining: 2.54s\n",
      "123:\tlearn: 0.0038441\ttotal: 839ms\tremaining: 2.54s\n",
      "124:\tlearn: 0.0038441\ttotal: 845ms\tremaining: 2.54s\n",
      "125:\tlearn: 0.0038439\ttotal: 851ms\tremaining: 2.53s\n",
      "126:\tlearn: 0.0038438\ttotal: 857ms\tremaining: 2.52s\n",
      "127:\tlearn: 0.0038438\ttotal: 863ms\tremaining: 2.51s\n",
      "128:\tlearn: 0.0038431\ttotal: 869ms\tremaining: 2.5s\n",
      "129:\tlearn: 0.0038431\ttotal: 874ms\tremaining: 2.49s\n",
      "130:\tlearn: 0.0038430\ttotal: 878ms\tremaining: 2.47s\n",
      "131:\tlearn: 0.0038425\ttotal: 883ms\tremaining: 2.46s\n",
      "132:\tlearn: 0.0038423\ttotal: 887ms\tremaining: 2.45s\n",
      "133:\tlearn: 0.0038422\ttotal: 891ms\tremaining: 2.43s\n",
      "134:\tlearn: 0.0038422\ttotal: 895ms\tremaining: 2.42s\n",
      "135:\tlearn: 0.0038420\ttotal: 899ms\tremaining: 2.41s\n",
      "136:\tlearn: 0.0038420\ttotal: 903ms\tremaining: 2.39s\n",
      "137:\tlearn: 0.0038418\ttotal: 908ms\tremaining: 2.38s\n",
      "138:\tlearn: 0.0038417\ttotal: 911ms\tremaining: 2.37s\n",
      "139:\tlearn: 0.0038377\ttotal: 915ms\tremaining: 2.35s\n",
      "140:\tlearn: 0.0038375\ttotal: 928ms\tremaining: 2.36s\n",
      "141:\tlearn: 0.0038374\ttotal: 937ms\tremaining: 2.36s\n",
      "142:\tlearn: 0.0038373\ttotal: 947ms\tremaining: 2.36s\n",
      "143:\tlearn: 0.0038371\ttotal: 956ms\tremaining: 2.36s\n",
      "144:\tlearn: 0.0038371\ttotal: 966ms\tremaining: 2.36s\n",
      "145:\tlearn: 0.0038368\ttotal: 975ms\tremaining: 2.36s\n",
      "146:\tlearn: 0.0038364\ttotal: 984ms\tremaining: 2.36s\n",
      "147:\tlearn: 0.0036837\ttotal: 994ms\tremaining: 2.36s\n",
      "148:\tlearn: 0.0036829\ttotal: 1s\tremaining: 2.36s\n",
      "149:\tlearn: 0.0036672\ttotal: 1.01s\tremaining: 2.37s\n",
      "150:\tlearn: 0.0035181\ttotal: 1.02s\tremaining: 2.36s\n",
      "151:\tlearn: 0.0035181\ttotal: 1.02s\tremaining: 2.35s\n",
      "152:\tlearn: 0.0035179\ttotal: 1.03s\tremaining: 2.34s\n",
      "153:\tlearn: 0.0035177\ttotal: 1.03s\tremaining: 2.33s\n",
      "154:\tlearn: 0.0035177\ttotal: 1.04s\tremaining: 2.31s\n",
      "155:\tlearn: 0.0035176\ttotal: 1.04s\tremaining: 2.3s\n",
      "156:\tlearn: 0.0035175\ttotal: 1.05s\tremaining: 2.29s\n",
      "157:\tlearn: 0.0035175\ttotal: 1.05s\tremaining: 2.28s\n",
      "158:\tlearn: 0.0035175\ttotal: 1.06s\tremaining: 2.27s\n",
      "159:\tlearn: 0.0035175\ttotal: 1.06s\tremaining: 2.26s\n",
      "160:\tlearn: 0.0035175\ttotal: 1.06s\tremaining: 2.24s\n",
      "161:\tlearn: 0.0035174\ttotal: 1.07s\tremaining: 2.23s\n",
      "162:\tlearn: 0.0035170\ttotal: 1.07s\tremaining: 2.22s\n",
      "163:\tlearn: 0.0035165\ttotal: 1.08s\tremaining: 2.21s\n",
      "164:\tlearn: 0.0035163\ttotal: 1.08s\tremaining: 2.2s\n",
      "165:\tlearn: 0.0035161\ttotal: 1.09s\tremaining: 2.19s\n",
      "166:\tlearn: 0.0033688\ttotal: 1.09s\tremaining: 2.18s\n",
      "167:\tlearn: 0.0033683\ttotal: 1.1s\tremaining: 2.17s\n",
      "168:\tlearn: 0.0033678\ttotal: 1.11s\tremaining: 2.17s\n",
      "169:\tlearn: 0.0033672\ttotal: 1.12s\tremaining: 2.17s\n",
      "170:\tlearn: 0.0033672\ttotal: 1.13s\tremaining: 2.17s\n",
      "171:\tlearn: 0.0033671\ttotal: 1.14s\tremaining: 2.17s\n",
      "172:\tlearn: 0.0033669\ttotal: 1.15s\tremaining: 2.17s\n",
      "173:\tlearn: 0.0033664\ttotal: 1.16s\tremaining: 2.17s\n",
      "174:\tlearn: 0.0033660\ttotal: 1.17s\tremaining: 2.16s\n",
      "175:\tlearn: 0.0033659\ttotal: 1.17s\tremaining: 2.16s\n",
      "176:\tlearn: 0.0033657\ttotal: 1.18s\tremaining: 2.15s\n",
      "177:\tlearn: 0.0033656\ttotal: 1.18s\tremaining: 2.14s\n",
      "178:\tlearn: 0.0033656\ttotal: 1.19s\tremaining: 2.13s\n",
      "179:\tlearn: 0.0033655\ttotal: 1.19s\tremaining: 2.12s\n",
      "180:\tlearn: 0.0033654\ttotal: 1.2s\tremaining: 2.11s\n",
      "181:\tlearn: 0.0033148\ttotal: 1.2s\tremaining: 2.1s\n",
      "182:\tlearn: 0.0032953\ttotal: 1.21s\tremaining: 2.09s\n",
      "183:\tlearn: 0.0032952\ttotal: 1.21s\tremaining: 2.08s\n",
      "184:\tlearn: 0.0032951\ttotal: 1.21s\tremaining: 2.06s\n",
      "185:\tlearn: 0.0032950\ttotal: 1.22s\tremaining: 2.05s\n",
      "186:\tlearn: 0.0032948\ttotal: 1.22s\tremaining: 2.04s\n",
      "187:\tlearn: 0.0032948\ttotal: 1.23s\tremaining: 2.03s\n",
      "188:\tlearn: 0.0032948\ttotal: 1.23s\tremaining: 2.02s\n",
      "189:\tlearn: 0.0032947\ttotal: 1.23s\tremaining: 2.01s\n",
      "190:\tlearn: 0.0032945\ttotal: 1.24s\tremaining: 2.01s\n",
      "191:\tlearn: 0.0032941\ttotal: 1.25s\tremaining: 2.01s\n",
      "192:\tlearn: 0.0032941\ttotal: 1.26s\tremaining: 2s\n",
      "193:\tlearn: 0.0032937\ttotal: 1.27s\tremaining: 2s\n",
      "194:\tlearn: 0.0032934\ttotal: 1.28s\tremaining: 2s\n",
      "195:\tlearn: 0.0032933\ttotal: 1.29s\tremaining: 2s\n",
      "196:\tlearn: 0.0032928\ttotal: 1.3s\tremaining: 2s\n",
      "197:\tlearn: 0.0032923\ttotal: 1.31s\tremaining: 1.99s\n",
      "198:\tlearn: 0.0032923\ttotal: 1.31s\tremaining: 1.98s\n",
      "199:\tlearn: 0.0032922\ttotal: 1.32s\tremaining: 1.98s\n",
      "200:\tlearn: 0.0032922\ttotal: 1.32s\tremaining: 1.97s\n",
      "201:\tlearn: 0.0032921\ttotal: 1.33s\tremaining: 1.96s\n",
      "202:\tlearn: 0.0032921\ttotal: 1.33s\tremaining: 1.95s\n",
      "203:\tlearn: 0.0032919\ttotal: 1.33s\tremaining: 1.94s\n",
      "204:\tlearn: 0.0032919\ttotal: 1.34s\tremaining: 1.93s\n",
      "205:\tlearn: 0.0032913\ttotal: 1.35s\tremaining: 1.92s\n",
      "206:\tlearn: 0.0032911\ttotal: 1.36s\tremaining: 1.92s\n",
      "207:\tlearn: 0.0032909\ttotal: 1.37s\tremaining: 1.92s\n",
      "208:\tlearn: 0.0032906\ttotal: 1.38s\tremaining: 1.92s\n",
      "209:\tlearn: 0.0032904\ttotal: 1.39s\tremaining: 1.91s\n",
      "210:\tlearn: 0.0032904\ttotal: 1.39s\tremaining: 1.91s\n",
      "211:\tlearn: 0.0032902\ttotal: 1.4s\tremaining: 1.91s\n",
      "212:\tlearn: 0.0032902\ttotal: 1.41s\tremaining: 1.9s\n",
      "213:\tlearn: 0.0032901\ttotal: 1.42s\tremaining: 1.9s\n",
      "214:\tlearn: 0.0032900\ttotal: 1.43s\tremaining: 1.9s\n",
      "215:\tlearn: 0.0032899\ttotal: 1.44s\tremaining: 1.89s\n",
      "216:\tlearn: 0.0032897\ttotal: 1.44s\tremaining: 1.88s\n",
      "217:\tlearn: 0.0032893\ttotal: 1.45s\tremaining: 1.88s\n",
      "218:\tlearn: 0.0032892\ttotal: 1.45s\tremaining: 1.87s\n",
      "219:\tlearn: 0.0032890\ttotal: 1.46s\tremaining: 1.86s\n",
      "220:\tlearn: 0.0032887\ttotal: 1.46s\tremaining: 1.85s\n",
      "221:\tlearn: 0.0032886\ttotal: 1.47s\tremaining: 1.84s\n",
      "222:\tlearn: 0.0032759\ttotal: 1.47s\tremaining: 1.83s\n",
      "223:\tlearn: 0.0032518\ttotal: 1.48s\tremaining: 1.82s\n",
      "224:\tlearn: 0.0031889\ttotal: 1.48s\tremaining: 1.81s\n",
      "225:\tlearn: 0.0031308\ttotal: 1.49s\tremaining: 1.8s\n",
      "226:\tlearn: 0.0031308\ttotal: 1.49s\tremaining: 1.79s\n",
      "227:\tlearn: 0.0031307\ttotal: 1.49s\tremaining: 1.78s\n",
      "228:\tlearn: 0.0031307\ttotal: 1.5s\tremaining: 1.77s\n",
      "229:\tlearn: 0.0031303\ttotal: 1.5s\tremaining: 1.76s\n",
      "230:\tlearn: 0.0031300\ttotal: 1.5s\tremaining: 1.75s\n",
      "231:\tlearn: 0.0031298\ttotal: 1.51s\tremaining: 1.74s\n",
      "232:\tlearn: 0.0031298\ttotal: 1.52s\tremaining: 1.74s\n",
      "233:\tlearn: 0.0031295\ttotal: 1.53s\tremaining: 1.74s\n",
      "234:\tlearn: 0.0031295\ttotal: 1.54s\tremaining: 1.73s\n",
      "235:\tlearn: 0.0031280\ttotal: 1.55s\tremaining: 1.73s\n",
      "236:\tlearn: 0.0030107\ttotal: 1.56s\tremaining: 1.73s\n",
      "237:\tlearn: 0.0030107\ttotal: 1.56s\tremaining: 1.72s\n",
      "238:\tlearn: 0.0030105\ttotal: 1.57s\tremaining: 1.71s\n",
      "239:\tlearn: 0.0030105\ttotal: 1.57s\tremaining: 1.71s\n",
      "240:\tlearn: 0.0030102\ttotal: 1.58s\tremaining: 1.7s\n",
      "241:\tlearn: 0.0030102\ttotal: 1.59s\tremaining: 1.69s\n",
      "242:\tlearn: 0.0030102\ttotal: 1.59s\tremaining: 1.68s\n",
      "243:\tlearn: 0.0030101\ttotal: 1.6s\tremaining: 1.67s\n",
      "244:\tlearn: 0.0030099\ttotal: 1.6s\tremaining: 1.67s\n",
      "245:\tlearn: 0.0030098\ttotal: 1.6s\tremaining: 1.66s\n",
      "246:\tlearn: 0.0030097\ttotal: 1.61s\tremaining: 1.65s\n",
      "247:\tlearn: 0.0030095\ttotal: 1.61s\tremaining: 1.64s\n",
      "248:\tlearn: 0.0030093\ttotal: 1.62s\tremaining: 1.63s\n",
      "249:\tlearn: 0.0030091\ttotal: 1.62s\tremaining: 1.62s\n",
      "250:\tlearn: 0.0030088\ttotal: 1.63s\tremaining: 1.61s\n",
      "251:\tlearn: 0.0030083\ttotal: 1.63s\tremaining: 1.6s\n",
      "252:\tlearn: 0.0030078\ttotal: 1.63s\tremaining: 1.6s\n",
      "253:\tlearn: 0.0030078\ttotal: 1.64s\tremaining: 1.59s\n",
      "254:\tlearn: 0.0030078\ttotal: 1.64s\tremaining: 1.58s\n",
      "255:\tlearn: 0.0030077\ttotal: 1.65s\tremaining: 1.57s\n",
      "256:\tlearn: 0.0030077\ttotal: 1.66s\tremaining: 1.57s\n",
      "257:\tlearn: 0.0030076\ttotal: 1.67s\tremaining: 1.56s\n",
      "258:\tlearn: 0.0030076\ttotal: 1.68s\tremaining: 1.56s\n",
      "259:\tlearn: 0.0030076\ttotal: 1.69s\tremaining: 1.56s\n",
      "260:\tlearn: 0.0030071\ttotal: 1.7s\tremaining: 1.55s\n",
      "261:\tlearn: 0.0030071\ttotal: 1.71s\tremaining: 1.55s\n",
      "262:\tlearn: 0.0030069\ttotal: 1.72s\tremaining: 1.55s\n",
      "263:\tlearn: 0.0030067\ttotal: 1.73s\tremaining: 1.54s\n",
      "264:\tlearn: 0.0030065\ttotal: 1.73s\tremaining: 1.54s\n",
      "265:\tlearn: 0.0030065\ttotal: 1.74s\tremaining: 1.53s\n",
      "266:\tlearn: 0.0030063\ttotal: 1.75s\tremaining: 1.52s\n",
      "267:\tlearn: 0.0030062\ttotal: 1.75s\tremaining: 1.52s\n",
      "268:\tlearn: 0.0030061\ttotal: 1.76s\tremaining: 1.51s\n",
      "269:\tlearn: 0.0030060\ttotal: 1.76s\tremaining: 1.5s\n",
      "270:\tlearn: 0.0030059\ttotal: 1.77s\tremaining: 1.49s\n",
      "271:\tlearn: 0.0030059\ttotal: 1.77s\tremaining: 1.49s\n",
      "272:\tlearn: 0.0030058\ttotal: 1.78s\tremaining: 1.48s\n",
      "273:\tlearn: 0.0030059\ttotal: 1.78s\tremaining: 1.47s\n",
      "274:\tlearn: 0.0030057\ttotal: 1.78s\tremaining: 1.46s\n",
      "275:\tlearn: 0.0030057\ttotal: 1.79s\tremaining: 1.45s\n",
      "276:\tlearn: 0.0030057\ttotal: 1.79s\tremaining: 1.44s\n",
      "277:\tlearn: 0.0030023\ttotal: 1.8s\tremaining: 1.44s\n",
      "278:\tlearn: 0.0030021\ttotal: 1.8s\tremaining: 1.43s\n",
      "279:\tlearn: 0.0030021\ttotal: 1.81s\tremaining: 1.42s\n",
      "280:\tlearn: 0.0028911\ttotal: 1.81s\tremaining: 1.41s\n",
      "281:\tlearn: 0.0028461\ttotal: 1.81s\tremaining: 1.4s\n",
      "282:\tlearn: 0.0027294\ttotal: 1.82s\tremaining: 1.4s\n",
      "283:\tlearn: 0.0027292\ttotal: 1.83s\tremaining: 1.4s\n",
      "284:\tlearn: 0.0025912\ttotal: 1.84s\tremaining: 1.39s\n",
      "285:\tlearn: 0.0025910\ttotal: 1.85s\tremaining: 1.39s\n",
      "286:\tlearn: 0.0024790\ttotal: 1.86s\tremaining: 1.38s\n",
      "287:\tlearn: 0.0024790\ttotal: 1.87s\tremaining: 1.38s\n",
      "288:\tlearn: 0.0024789\ttotal: 1.88s\tremaining: 1.37s\n",
      "289:\tlearn: 0.0024789\ttotal: 1.89s\tremaining: 1.37s\n",
      "290:\tlearn: 0.0024788\ttotal: 1.9s\tremaining: 1.36s\n",
      "291:\tlearn: 0.0023771\ttotal: 1.91s\tremaining: 1.36s\n",
      "292:\tlearn: 0.0023770\ttotal: 1.91s\tremaining: 1.35s\n",
      "293:\tlearn: 0.0023769\ttotal: 1.92s\tremaining: 1.34s\n",
      "294:\tlearn: 0.0023767\ttotal: 1.93s\tremaining: 1.34s\n",
      "295:\tlearn: 0.0023766\ttotal: 1.93s\tremaining: 1.33s\n",
      "296:\tlearn: 0.0023763\ttotal: 1.94s\tremaining: 1.32s\n",
      "297:\tlearn: 0.0023763\ttotal: 1.94s\tremaining: 1.31s\n",
      "298:\tlearn: 0.0023763\ttotal: 1.94s\tremaining: 1.31s\n",
      "299:\tlearn: 0.0023464\ttotal: 1.95s\tremaining: 1.3s\n",
      "300:\tlearn: 0.0023463\ttotal: 1.95s\tremaining: 1.29s\n",
      "301:\tlearn: 0.0022200\ttotal: 1.96s\tremaining: 1.28s\n",
      "302:\tlearn: 0.0022200\ttotal: 1.96s\tremaining: 1.27s\n",
      "303:\tlearn: 0.0022200\ttotal: 1.97s\tremaining: 1.27s\n",
      "304:\tlearn: 0.0022198\ttotal: 1.97s\tremaining: 1.26s\n",
      "305:\tlearn: 0.0022197\ttotal: 1.97s\tremaining: 1.25s\n",
      "306:\tlearn: 0.0022197\ttotal: 1.98s\tremaining: 1.24s\n",
      "307:\tlearn: 0.0022197\ttotal: 1.98s\tremaining: 1.24s\n",
      "308:\tlearn: 0.0022193\ttotal: 1.99s\tremaining: 1.23s\n",
      "309:\tlearn: 0.0022194\ttotal: 1.99s\tremaining: 1.22s\n",
      "310:\tlearn: 0.0021946\ttotal: 2s\tremaining: 1.22s\n",
      "311:\tlearn: 0.0021940\ttotal: 2.01s\tremaining: 1.21s\n",
      "312:\tlearn: 0.0021940\ttotal: 2.02s\tremaining: 1.21s\n",
      "313:\tlearn: 0.0021939\ttotal: 2.03s\tremaining: 1.2s\n",
      "314:\tlearn: 0.0021939\ttotal: 2.04s\tremaining: 1.2s\n",
      "315:\tlearn: 0.0021939\ttotal: 2.05s\tremaining: 1.19s\n",
      "316:\tlearn: 0.0021938\ttotal: 2.06s\tremaining: 1.19s\n",
      "317:\tlearn: 0.0021937\ttotal: 2.07s\tremaining: 1.18s\n",
      "318:\tlearn: 0.0021937\ttotal: 2.07s\tremaining: 1.18s\n",
      "319:\tlearn: 0.0021936\ttotal: 2.08s\tremaining: 1.17s\n",
      "320:\tlearn: 0.0021935\ttotal: 2.08s\tremaining: 1.16s\n",
      "321:\tlearn: 0.0021935\ttotal: 2.09s\tremaining: 1.16s\n",
      "322:\tlearn: 0.0021936\ttotal: 2.1s\tremaining: 1.15s\n",
      "323:\tlearn: 0.0021936\ttotal: 2.1s\tremaining: 1.14s\n",
      "324:\tlearn: 0.0021934\ttotal: 2.1s\tremaining: 1.13s\n",
      "325:\tlearn: 0.0021931\ttotal: 2.11s\tremaining: 1.13s\n",
      "326:\tlearn: 0.0021930\ttotal: 2.11s\tremaining: 1.12s\n",
      "327:\tlearn: 0.0021930\ttotal: 2.12s\tremaining: 1.11s\n",
      "328:\tlearn: 0.0021930\ttotal: 2.12s\tremaining: 1.1s\n",
      "329:\tlearn: 0.0021929\ttotal: 2.13s\tremaining: 1.1s\n",
      "330:\tlearn: 0.0021929\ttotal: 2.13s\tremaining: 1.09s\n",
      "331:\tlearn: 0.0021927\ttotal: 2.14s\tremaining: 1.08s\n",
      "332:\tlearn: 0.0021927\ttotal: 2.14s\tremaining: 1.07s\n",
      "333:\tlearn: 0.0021925\ttotal: 2.15s\tremaining: 1.07s\n",
      "334:\tlearn: 0.0021923\ttotal: 2.15s\tremaining: 1.06s\n",
      "335:\tlearn: 0.0021669\ttotal: 2.15s\tremaining: 1.05s\n",
      "336:\tlearn: 0.0021513\ttotal: 2.16s\tremaining: 1.04s\n",
      "337:\tlearn: 0.0021513\ttotal: 2.16s\tremaining: 1.04s\n",
      "338:\tlearn: 0.0021512\ttotal: 2.17s\tremaining: 1.03s\n",
      "339:\tlearn: 0.0021512\ttotal: 2.17s\tremaining: 1.02s\n",
      "340:\tlearn: 0.0021512\ttotal: 2.18s\tremaining: 1.01s\n",
      "341:\tlearn: 0.0021512\ttotal: 2.18s\tremaining: 1.01s\n",
      "342:\tlearn: 0.0021504\ttotal: 2.18s\tremaining: 1000ms\n",
      "343:\tlearn: 0.0021503\ttotal: 2.19s\tremaining: 992ms\n",
      "344:\tlearn: 0.0020627\ttotal: 2.2s\tremaining: 989ms\n",
      "345:\tlearn: 0.0020627\ttotal: 2.21s\tremaining: 984ms\n",
      "346:\tlearn: 0.0020625\ttotal: 2.22s\tremaining: 979ms\n",
      "347:\tlearn: 0.0020622\ttotal: 2.23s\tremaining: 974ms\n",
      "348:\tlearn: 0.0020622\ttotal: 2.24s\tremaining: 969ms\n",
      "349:\tlearn: 0.0020622\ttotal: 2.25s\tremaining: 963ms\n",
      "350:\tlearn: 0.0020622\ttotal: 2.26s\tremaining: 958ms\n",
      "351:\tlearn: 0.0020622\ttotal: 2.27s\tremaining: 953ms\n",
      "352:\tlearn: 0.0020622\ttotal: 2.27s\tremaining: 947ms\n",
      "353:\tlearn: 0.0020622\ttotal: 2.28s\tremaining: 940ms\n",
      "354:\tlearn: 0.0020621\ttotal: 2.29s\tremaining: 934ms\n",
      "355:\tlearn: 0.0020620\ttotal: 2.29s\tremaining: 927ms\n",
      "356:\tlearn: 0.0020620\ttotal: 2.3s\tremaining: 920ms\n",
      "357:\tlearn: 0.0020620\ttotal: 2.3s\tremaining: 913ms\n",
      "358:\tlearn: 0.0020620\ttotal: 2.31s\tremaining: 905ms\n",
      "359:\tlearn: 0.0020620\ttotal: 2.31s\tremaining: 898ms\n",
      "360:\tlearn: 0.0020619\ttotal: 2.31s\tremaining: 891ms\n",
      "361:\tlearn: 0.0020619\ttotal: 2.32s\tremaining: 884ms\n",
      "362:\tlearn: 0.0020619\ttotal: 2.32s\tremaining: 876ms\n",
      "363:\tlearn: 0.0020617\ttotal: 2.33s\tremaining: 869ms\n",
      "364:\tlearn: 0.0020614\ttotal: 2.33s\tremaining: 862ms\n",
      "365:\tlearn: 0.0020614\ttotal: 2.33s\tremaining: 855ms\n",
      "366:\tlearn: 0.0020613\ttotal: 2.34s\tremaining: 847ms\n",
      "367:\tlearn: 0.0019841\ttotal: 2.34s\tremaining: 840ms\n",
      "368:\tlearn: 0.0019841\ttotal: 2.35s\tremaining: 833ms\n",
      "369:\tlearn: 0.0019840\ttotal: 2.35s\tremaining: 826ms\n",
      "370:\tlearn: 0.0019838\ttotal: 2.35s\tremaining: 819ms\n",
      "371:\tlearn: 0.0019837\ttotal: 2.36s\tremaining: 812ms\n",
      "372:\tlearn: 0.0019837\ttotal: 2.37s\tremaining: 806ms\n",
      "373:\tlearn: 0.0019834\ttotal: 2.38s\tremaining: 801ms\n",
      "374:\tlearn: 0.0019833\ttotal: 2.39s\tremaining: 796ms\n",
      "375:\tlearn: 0.0019833\ttotal: 2.4s\tremaining: 790ms\n",
      "376:\tlearn: 0.0019833\ttotal: 2.4s\tremaining: 785ms\n",
      "377:\tlearn: 0.0019832\ttotal: 2.42s\tremaining: 779ms\n",
      "378:\tlearn: 0.0019831\ttotal: 2.42s\tremaining: 774ms\n",
      "379:\tlearn: 0.0019829\ttotal: 2.43s\tremaining: 769ms\n",
      "380:\tlearn: 0.0019829\ttotal: 2.44s\tremaining: 763ms\n",
      "381:\tlearn: 0.0019829\ttotal: 2.45s\tremaining: 756ms\n",
      "382:\tlearn: 0.0019827\ttotal: 2.45s\tremaining: 749ms\n",
      "383:\tlearn: 0.0019827\ttotal: 2.46s\tremaining: 742ms\n",
      "384:\tlearn: 0.0019827\ttotal: 2.46s\tremaining: 735ms\n",
      "385:\tlearn: 0.0019826\ttotal: 2.46s\tremaining: 728ms\n",
      "386:\tlearn: 0.0019826\ttotal: 2.47s\tremaining: 721ms\n",
      "387:\tlearn: 0.0019826\ttotal: 2.47s\tremaining: 714ms\n",
      "388:\tlearn: 0.0019825\ttotal: 2.48s\tremaining: 707ms\n",
      "389:\tlearn: 0.0019825\ttotal: 2.48s\tremaining: 700ms\n",
      "390:\tlearn: 0.0019825\ttotal: 2.49s\tremaining: 693ms\n",
      "391:\tlearn: 0.0019825\ttotal: 2.49s\tremaining: 686ms\n",
      "392:\tlearn: 0.0019823\ttotal: 2.5s\tremaining: 679ms\n",
      "393:\tlearn: 0.0019821\ttotal: 2.5s\tremaining: 672ms\n",
      "394:\tlearn: 0.0019820\ttotal: 2.5s\tremaining: 665ms\n",
      "395:\tlearn: 0.0019820\ttotal: 2.51s\tremaining: 659ms\n",
      "396:\tlearn: 0.0019820\ttotal: 2.51s\tremaining: 652ms\n",
      "397:\tlearn: 0.0019789\ttotal: 2.52s\tremaining: 645ms\n",
      "398:\tlearn: 0.0019789\ttotal: 2.52s\tremaining: 638ms\n",
      "399:\tlearn: 0.0019789\ttotal: 2.52s\tremaining: 631ms\n",
      "400:\tlearn: 0.0019789\ttotal: 2.53s\tremaining: 624ms\n",
      "401:\tlearn: 0.0019788\ttotal: 2.53s\tremaining: 617ms\n",
      "402:\tlearn: 0.0019788\ttotal: 2.54s\tremaining: 611ms\n",
      "403:\tlearn: 0.0019787\ttotal: 2.55s\tremaining: 606ms\n",
      "404:\tlearn: 0.0019786\ttotal: 2.56s\tremaining: 600ms\n",
      "405:\tlearn: 0.0019786\ttotal: 2.57s\tremaining: 595ms\n",
      "406:\tlearn: 0.0019786\ttotal: 2.58s\tremaining: 589ms\n",
      "407:\tlearn: 0.0019786\ttotal: 2.59s\tremaining: 583ms\n",
      "408:\tlearn: 0.0019785\ttotal: 2.6s\tremaining: 578ms\n",
      "409:\tlearn: 0.0019784\ttotal: 2.6s\tremaining: 572ms\n",
      "410:\tlearn: 0.0019785\ttotal: 2.61s\tremaining: 565ms\n",
      "411:\tlearn: 0.0019785\ttotal: 2.62s\tremaining: 559ms\n",
      "412:\tlearn: 0.0019784\ttotal: 2.62s\tremaining: 552ms\n",
      "413:\tlearn: 0.0019784\ttotal: 2.63s\tremaining: 546ms\n",
      "414:\tlearn: 0.0019783\ttotal: 2.63s\tremaining: 539ms\n",
      "415:\tlearn: 0.0019783\ttotal: 2.64s\tremaining: 533ms\n",
      "416:\tlearn: 0.0019783\ttotal: 2.64s\tremaining: 526ms\n",
      "417:\tlearn: 0.0019782\ttotal: 2.65s\tremaining: 519ms\n",
      "418:\tlearn: 0.0019783\ttotal: 2.65s\tremaining: 513ms\n",
      "419:\tlearn: 0.0019783\ttotal: 2.65s\tremaining: 506ms\n",
      "420:\tlearn: 0.0019782\ttotal: 2.66s\tremaining: 499ms\n",
      "421:\tlearn: 0.0019779\ttotal: 2.66s\tremaining: 492ms\n",
      "422:\tlearn: 0.0019776\ttotal: 2.67s\tremaining: 486ms\n",
      "423:\tlearn: 0.0019773\ttotal: 2.67s\tremaining: 479ms\n",
      "424:\tlearn: 0.0019773\ttotal: 2.68s\tremaining: 472ms\n",
      "425:\tlearn: 0.0019769\ttotal: 2.68s\tremaining: 466ms\n",
      "426:\tlearn: 0.0019768\ttotal: 2.68s\tremaining: 459ms\n",
      "427:\tlearn: 0.0019768\ttotal: 2.69s\tremaining: 452ms\n",
      "428:\tlearn: 0.0019768\ttotal: 2.69s\tremaining: 446ms\n",
      "429:\tlearn: 0.0019767\ttotal: 2.7s\tremaining: 440ms\n",
      "430:\tlearn: 0.0019767\ttotal: 2.71s\tremaining: 434ms\n",
      "431:\tlearn: 0.0019767\ttotal: 2.72s\tremaining: 428ms\n",
      "432:\tlearn: 0.0019765\ttotal: 2.73s\tremaining: 422ms\n",
      "433:\tlearn: 0.0019765\ttotal: 2.74s\tremaining: 416ms\n",
      "434:\tlearn: 0.0019765\ttotal: 2.75s\tremaining: 411ms\n",
      "435:\tlearn: 0.0019764\ttotal: 2.76s\tremaining: 405ms\n",
      "436:\tlearn: 0.0019763\ttotal: 2.77s\tremaining: 399ms\n",
      "437:\tlearn: 0.0019763\ttotal: 2.77s\tremaining: 393ms\n",
      "438:\tlearn: 0.0019762\ttotal: 2.78s\tremaining: 386ms\n",
      "439:\tlearn: 0.0019761\ttotal: 2.79s\tremaining: 380ms\n",
      "440:\tlearn: 0.0019761\ttotal: 2.79s\tremaining: 373ms\n",
      "441:\tlearn: 0.0019761\ttotal: 2.79s\tremaining: 367ms\n",
      "442:\tlearn: 0.0019760\ttotal: 2.8s\tremaining: 360ms\n",
      "443:\tlearn: 0.0019761\ttotal: 2.8s\tremaining: 354ms\n",
      "444:\tlearn: 0.0019760\ttotal: 2.81s\tremaining: 347ms\n",
      "445:\tlearn: 0.0019759\ttotal: 2.81s\tremaining: 341ms\n",
      "446:\tlearn: 0.0019758\ttotal: 2.82s\tremaining: 334ms\n",
      "447:\tlearn: 0.0019757\ttotal: 2.82s\tremaining: 327ms\n",
      "448:\tlearn: 0.0019758\ttotal: 2.83s\tremaining: 321ms\n",
      "449:\tlearn: 0.0019756\ttotal: 2.83s\tremaining: 314ms\n",
      "450:\tlearn: 0.0019756\ttotal: 2.83s\tremaining: 308ms\n",
      "451:\tlearn: 0.0019756\ttotal: 2.84s\tremaining: 301ms\n",
      "452:\tlearn: 0.0019755\ttotal: 2.84s\tremaining: 295ms\n",
      "453:\tlearn: 0.0019754\ttotal: 2.85s\tremaining: 288ms\n",
      "454:\tlearn: 0.0019754\ttotal: 2.85s\tremaining: 282ms\n",
      "455:\tlearn: 0.0019752\ttotal: 2.85s\tremaining: 275ms\n",
      "456:\tlearn: 0.0019751\ttotal: 2.86s\tremaining: 269ms\n",
      "457:\tlearn: 0.0019751\ttotal: 2.87s\tremaining: 263ms\n",
      "458:\tlearn: 0.0019750\ttotal: 2.88s\tremaining: 257ms\n",
      "459:\tlearn: 0.0019750\ttotal: 2.89s\tremaining: 251ms\n",
      "460:\tlearn: 0.0019750\ttotal: 2.9s\tremaining: 245ms\n",
      "461:\tlearn: 0.0019749\ttotal: 2.91s\tremaining: 239ms\n",
      "462:\tlearn: 0.0019747\ttotal: 2.92s\tremaining: 233ms\n",
      "463:\tlearn: 0.0019746\ttotal: 2.93s\tremaining: 227ms\n",
      "464:\tlearn: 0.0019745\ttotal: 2.94s\tremaining: 221ms\n",
      "465:\tlearn: 0.0019744\ttotal: 2.94s\tremaining: 215ms\n",
      "466:\tlearn: 0.0019745\ttotal: 2.95s\tremaining: 208ms\n",
      "467:\tlearn: 0.0019744\ttotal: 2.95s\tremaining: 202ms\n",
      "468:\tlearn: 0.0019743\ttotal: 2.96s\tremaining: 196ms\n",
      "469:\tlearn: 0.0019743\ttotal: 2.97s\tremaining: 189ms\n",
      "470:\tlearn: 0.0019741\ttotal: 2.97s\tremaining: 183ms\n",
      "471:\tlearn: 0.0019741\ttotal: 2.98s\tremaining: 177ms\n",
      "472:\tlearn: 0.0019740\ttotal: 2.98s\tremaining: 170ms\n",
      "473:\tlearn: 0.0019739\ttotal: 2.99s\tremaining: 164ms\n",
      "474:\tlearn: 0.0019738\ttotal: 2.99s\tremaining: 158ms\n",
      "475:\tlearn: 0.0019738\ttotal: 3s\tremaining: 151ms\n",
      "476:\tlearn: 0.0019738\ttotal: 3s\tremaining: 145ms\n",
      "477:\tlearn: 0.0019737\ttotal: 3.01s\tremaining: 138ms\n",
      "478:\tlearn: 0.0019737\ttotal: 3.01s\tremaining: 132ms\n",
      "479:\tlearn: 0.0019737\ttotal: 3.02s\tremaining: 126ms\n",
      "480:\tlearn: 0.0019736\ttotal: 3.02s\tremaining: 119ms\n",
      "481:\tlearn: 0.0019735\ttotal: 3.02s\tremaining: 113ms\n",
      "482:\tlearn: 0.0019735\ttotal: 3.03s\tremaining: 107ms\n",
      "483:\tlearn: 0.0019731\ttotal: 3.03s\tremaining: 100ms\n",
      "484:\tlearn: 0.0019731\ttotal: 3.04s\tremaining: 93.9ms\n",
      "485:\tlearn: 0.0019731\ttotal: 3.04s\tremaining: 87.6ms\n",
      "486:\tlearn: 0.0019731\ttotal: 3.04s\tremaining: 81.3ms\n",
      "487:\tlearn: 0.0019730\ttotal: 3.05s\tremaining: 75ms\n",
      "488:\tlearn: 0.0019730\ttotal: 3.05s\tremaining: 68.7ms\n",
      "489:\tlearn: 0.0019729\ttotal: 3.06s\tremaining: 62.5ms\n",
      "490:\tlearn: 0.0019730\ttotal: 3.07s\tremaining: 56.3ms\n",
      "491:\tlearn: 0.0019729\ttotal: 3.08s\tremaining: 50.1ms\n",
      "492:\tlearn: 0.0019729\ttotal: 3.09s\tremaining: 43.9ms\n",
      "493:\tlearn: 0.0019729\ttotal: 3.1s\tremaining: 37.7ms\n",
      "494:\tlearn: 0.0019728\ttotal: 3.11s\tremaining: 31.4ms\n",
      "495:\tlearn: 0.0019724\ttotal: 3.12s\tremaining: 25.2ms\n",
      "496:\tlearn: 0.0019724\ttotal: 3.13s\tremaining: 18.9ms\n",
      "497:\tlearn: 0.0019724\ttotal: 3.14s\tremaining: 12.6ms\n",
      "498:\tlearn: 0.0019724\ttotal: 3.14s\tremaining: 6.3ms\n",
      "499:\tlearn: 0.0019723\ttotal: 3.15s\tremaining: 0us\n",
      "0:\tlearn: 0.6343551\ttotal: 4.47ms\tremaining: 2.23s\n",
      "1:\tlearn: 0.5940607\ttotal: 9.21ms\tremaining: 2.29s\n",
      "2:\tlearn: 0.5499490\ttotal: 13.5ms\tremaining: 2.23s\n",
      "3:\tlearn: 0.5037753\ttotal: 17.8ms\tremaining: 2.21s\n",
      "4:\tlearn: 0.4681513\ttotal: 22.1ms\tremaining: 2.19s\n",
      "5:\tlearn: 0.4433711\ttotal: 26.4ms\tremaining: 2.17s\n",
      "6:\tlearn: 0.4275172\ttotal: 30.7ms\tremaining: 2.17s\n",
      "7:\tlearn: 0.3991325\ttotal: 35.1ms\tremaining: 2.16s\n",
      "8:\tlearn: 0.3638738\ttotal: 39.4ms\tremaining: 2.15s\n",
      "9:\tlearn: 0.3409049\ttotal: 43.8ms\tremaining: 2.15s\n",
      "10:\tlearn: 0.3166877\ttotal: 48.1ms\tremaining: 2.14s\n",
      "11:\tlearn: 0.2943907\ttotal: 52.6ms\tremaining: 2.14s\n",
      "12:\tlearn: 0.2690541\ttotal: 56.8ms\tremaining: 2.13s\n",
      "13:\tlearn: 0.2483668\ttotal: 61.1ms\tremaining: 2.12s\n",
      "14:\tlearn: 0.2349432\ttotal: 65.7ms\tremaining: 2.12s\n",
      "15:\tlearn: 0.2252385\ttotal: 70.1ms\tremaining: 2.12s\n",
      "16:\tlearn: 0.2107259\ttotal: 79.8ms\tremaining: 2.27s\n",
      "17:\tlearn: 0.1965432\ttotal: 89.7ms\tremaining: 2.4s\n",
      "18:\tlearn: 0.1840598\ttotal: 99.4ms\tremaining: 2.52s\n",
      "19:\tlearn: 0.1723240\ttotal: 109ms\tremaining: 2.61s\n",
      "20:\tlearn: 0.1643034\ttotal: 118ms\tremaining: 2.7s\n",
      "21:\tlearn: 0.1507026\ttotal: 128ms\tremaining: 2.78s\n",
      "22:\tlearn: 0.1392418\ttotal: 137ms\tremaining: 2.85s\n",
      "23:\tlearn: 0.1319734\ttotal: 147ms\tremaining: 2.91s\n",
      "24:\tlearn: 0.1256364\ttotal: 156ms\tremaining: 2.97s\n",
      "25:\tlearn: 0.1157609\ttotal: 167ms\tremaining: 3.04s\n",
      "26:\tlearn: 0.1079060\ttotal: 171ms\tremaining: 3s\n",
      "27:\tlearn: 0.1018842\ttotal: 176ms\tremaining: 2.97s\n",
      "28:\tlearn: 0.0984007\ttotal: 183ms\tremaining: 2.97s\n",
      "29:\tlearn: 0.0919474\ttotal: 188ms\tremaining: 2.94s\n",
      "30:\tlearn: 0.0876081\ttotal: 192ms\tremaining: 2.9s\n",
      "31:\tlearn: 0.0832531\ttotal: 197ms\tremaining: 2.88s\n",
      "32:\tlearn: 0.0776260\ttotal: 202ms\tremaining: 2.85s\n",
      "33:\tlearn: 0.0741596\ttotal: 206ms\tremaining: 2.83s\n",
      "34:\tlearn: 0.0698581\ttotal: 210ms\tremaining: 2.79s\n",
      "35:\tlearn: 0.0669471\ttotal: 215ms\tremaining: 2.77s\n",
      "36:\tlearn: 0.0632955\ttotal: 219ms\tremaining: 2.74s\n",
      "37:\tlearn: 0.0589489\ttotal: 223ms\tremaining: 2.71s\n",
      "38:\tlearn: 0.0549466\ttotal: 228ms\tremaining: 2.69s\n",
      "39:\tlearn: 0.0528831\ttotal: 232ms\tremaining: 2.67s\n",
      "40:\tlearn: 0.0482792\ttotal: 236ms\tremaining: 2.65s\n",
      "41:\tlearn: 0.0458257\ttotal: 241ms\tremaining: 2.62s\n",
      "42:\tlearn: 0.0432651\ttotal: 245ms\tremaining: 2.6s\n",
      "43:\tlearn: 0.0405416\ttotal: 249ms\tremaining: 2.58s\n",
      "44:\tlearn: 0.0385084\ttotal: 259ms\tremaining: 2.62s\n",
      "45:\tlearn: 0.0368186\ttotal: 269ms\tremaining: 2.65s\n",
      "46:\tlearn: 0.0346524\ttotal: 278ms\tremaining: 2.68s\n",
      "47:\tlearn: 0.0330116\ttotal: 288ms\tremaining: 2.71s\n",
      "48:\tlearn: 0.0319099\ttotal: 298ms\tremaining: 2.74s\n",
      "49:\tlearn: 0.0305171\ttotal: 308ms\tremaining: 2.77s\n",
      "50:\tlearn: 0.0290882\ttotal: 317ms\tremaining: 2.79s\n",
      "51:\tlearn: 0.0271247\ttotal: 327ms\tremaining: 2.82s\n",
      "52:\tlearn: 0.0259505\ttotal: 333ms\tremaining: 2.81s\n",
      "53:\tlearn: 0.0249422\ttotal: 339ms\tremaining: 2.8s\n",
      "54:\tlearn: 0.0237284\ttotal: 345ms\tremaining: 2.79s\n",
      "55:\tlearn: 0.0230667\ttotal: 351ms\tremaining: 2.78s\n",
      "56:\tlearn: 0.0221978\ttotal: 357ms\tremaining: 2.77s\n",
      "57:\tlearn: 0.0210889\ttotal: 364ms\tremaining: 2.77s\n",
      "58:\tlearn: 0.0207294\ttotal: 370ms\tremaining: 2.77s\n",
      "59:\tlearn: 0.0195763\ttotal: 377ms\tremaining: 2.77s\n",
      "60:\tlearn: 0.0187851\ttotal: 382ms\tremaining: 2.75s\n",
      "61:\tlearn: 0.0180378\ttotal: 386ms\tremaining: 2.73s\n",
      "62:\tlearn: 0.0169391\ttotal: 390ms\tremaining: 2.71s\n",
      "63:\tlearn: 0.0161176\ttotal: 395ms\tremaining: 2.69s\n",
      "64:\tlearn: 0.0153729\ttotal: 399ms\tremaining: 2.67s\n",
      "65:\tlearn: 0.0149748\ttotal: 403ms\tremaining: 2.65s\n",
      "66:\tlearn: 0.0143480\ttotal: 407ms\tremaining: 2.63s\n",
      "67:\tlearn: 0.0135513\ttotal: 411ms\tremaining: 2.61s\n",
      "68:\tlearn: 0.0129860\ttotal: 421ms\tremaining: 2.63s\n",
      "69:\tlearn: 0.0125177\ttotal: 431ms\tremaining: 2.64s\n",
      "70:\tlearn: 0.0121440\ttotal: 440ms\tremaining: 2.66s\n",
      "71:\tlearn: 0.0117655\ttotal: 450ms\tremaining: 2.67s\n",
      "72:\tlearn: 0.0114051\ttotal: 459ms\tremaining: 2.69s\n",
      "73:\tlearn: 0.0110839\ttotal: 469ms\tremaining: 2.7s\n",
      "74:\tlearn: 0.0105421\ttotal: 479ms\tremaining: 2.71s\n",
      "75:\tlearn: 0.0102878\ttotal: 488ms\tremaining: 2.72s\n",
      "76:\tlearn: 0.0097757\ttotal: 497ms\tremaining: 2.73s\n",
      "77:\tlearn: 0.0095760\ttotal: 507ms\tremaining: 2.74s\n",
      "78:\tlearn: 0.0093563\ttotal: 513ms\tremaining: 2.73s\n",
      "79:\tlearn: 0.0089892\ttotal: 519ms\tremaining: 2.72s\n",
      "80:\tlearn: 0.0087656\ttotal: 525ms\tremaining: 2.71s\n",
      "81:\tlearn: 0.0085317\ttotal: 529ms\tremaining: 2.7s\n",
      "82:\tlearn: 0.0082307\ttotal: 534ms\tremaining: 2.68s\n",
      "83:\tlearn: 0.0079220\ttotal: 539ms\tremaining: 2.67s\n",
      "84:\tlearn: 0.0076618\ttotal: 545ms\tremaining: 2.66s\n",
      "85:\tlearn: 0.0072142\ttotal: 550ms\tremaining: 2.65s\n",
      "86:\tlearn: 0.0070467\ttotal: 555ms\tremaining: 2.63s\n",
      "87:\tlearn: 0.0067074\ttotal: 559ms\tremaining: 2.62s\n",
      "88:\tlearn: 0.0066989\ttotal: 563ms\tremaining: 2.6s\n",
      "89:\tlearn: 0.0063852\ttotal: 567ms\tremaining: 2.58s\n",
      "90:\tlearn: 0.0062466\ttotal: 570ms\tremaining: 2.56s\n",
      "91:\tlearn: 0.0060884\ttotal: 574ms\tremaining: 2.54s\n",
      "92:\tlearn: 0.0060883\ttotal: 578ms\tremaining: 2.53s\n",
      "93:\tlearn: 0.0058461\ttotal: 582ms\tremaining: 2.51s\n",
      "94:\tlearn: 0.0058461\ttotal: 587ms\tremaining: 2.5s\n",
      "95:\tlearn: 0.0058461\ttotal: 596ms\tremaining: 2.51s\n",
      "96:\tlearn: 0.0058460\ttotal: 605ms\tremaining: 2.52s\n",
      "97:\tlearn: 0.0058459\ttotal: 615ms\tremaining: 2.52s\n",
      "98:\tlearn: 0.0058459\ttotal: 624ms\tremaining: 2.53s\n",
      "99:\tlearn: 0.0058458\ttotal: 633ms\tremaining: 2.53s\n",
      "100:\tlearn: 0.0058458\ttotal: 642ms\tremaining: 2.54s\n",
      "101:\tlearn: 0.0058457\ttotal: 652ms\tremaining: 2.54s\n",
      "102:\tlearn: 0.0058456\ttotal: 661ms\tremaining: 2.55s\n",
      "103:\tlearn: 0.0058452\ttotal: 670ms\tremaining: 2.55s\n",
      "104:\tlearn: 0.0058452\ttotal: 678ms\tremaining: 2.55s\n",
      "105:\tlearn: 0.0058450\ttotal: 684ms\tremaining: 2.54s\n",
      "106:\tlearn: 0.0058449\ttotal: 689ms\tremaining: 2.53s\n",
      "107:\tlearn: 0.0058446\ttotal: 695ms\tremaining: 2.52s\n",
      "108:\tlearn: 0.0058445\ttotal: 702ms\tremaining: 2.52s\n",
      "109:\tlearn: 0.0058444\ttotal: 707ms\tremaining: 2.51s\n",
      "110:\tlearn: 0.0058444\ttotal: 711ms\tremaining: 2.49s\n",
      "111:\tlearn: 0.0058444\ttotal: 716ms\tremaining: 2.48s\n",
      "112:\tlearn: 0.0058443\ttotal: 720ms\tremaining: 2.47s\n",
      "113:\tlearn: 0.0058442\ttotal: 726ms\tremaining: 2.46s\n",
      "114:\tlearn: 0.0058441\ttotal: 728ms\tremaining: 2.44s\n",
      "115:\tlearn: 0.0058441\ttotal: 732ms\tremaining: 2.42s\n",
      "116:\tlearn: 0.0058438\ttotal: 735ms\tremaining: 2.4s\n",
      "117:\tlearn: 0.0058439\ttotal: 739ms\tremaining: 2.39s\n",
      "118:\tlearn: 0.0058436\ttotal: 743ms\tremaining: 2.38s\n",
      "119:\tlearn: 0.0058435\ttotal: 747ms\tremaining: 2.37s\n",
      "120:\tlearn: 0.0058433\ttotal: 751ms\tremaining: 2.35s\n",
      "121:\tlearn: 0.0058434\ttotal: 755ms\tremaining: 2.34s\n",
      "122:\tlearn: 0.0058433\ttotal: 758ms\tremaining: 2.32s\n",
      "123:\tlearn: 0.0058433\ttotal: 768ms\tremaining: 2.33s\n",
      "124:\tlearn: 0.0058433\ttotal: 777ms\tremaining: 2.33s\n",
      "125:\tlearn: 0.0058433\ttotal: 786ms\tremaining: 2.33s\n",
      "126:\tlearn: 0.0058431\ttotal: 796ms\tremaining: 2.34s\n",
      "127:\tlearn: 0.0058431\ttotal: 805ms\tremaining: 2.34s\n",
      "128:\tlearn: 0.0058430\ttotal: 814ms\tremaining: 2.34s\n",
      "129:\tlearn: 0.0058429\ttotal: 824ms\tremaining: 2.34s\n",
      "130:\tlearn: 0.0058429\ttotal: 833ms\tremaining: 2.35s\n",
      "131:\tlearn: 0.0058425\ttotal: 842ms\tremaining: 2.35s\n",
      "132:\tlearn: 0.0058424\ttotal: 848ms\tremaining: 2.34s\n",
      "133:\tlearn: 0.0058425\ttotal: 854ms\tremaining: 2.33s\n",
      "134:\tlearn: 0.0058423\ttotal: 860ms\tremaining: 2.32s\n",
      "135:\tlearn: 0.0058419\ttotal: 866ms\tremaining: 2.32s\n",
      "136:\tlearn: 0.0058419\ttotal: 872ms\tremaining: 2.31s\n",
      "137:\tlearn: 0.0058410\ttotal: 878ms\tremaining: 2.3s\n",
      "138:\tlearn: 0.0058409\ttotal: 882ms\tremaining: 2.29s\n",
      "139:\tlearn: 0.0058406\ttotal: 886ms\tremaining: 2.28s\n",
      "140:\tlearn: 0.0058405\ttotal: 891ms\tremaining: 2.27s\n",
      "141:\tlearn: 0.0058402\ttotal: 895ms\tremaining: 2.26s\n",
      "142:\tlearn: 0.0058401\ttotal: 900ms\tremaining: 2.25s\n",
      "143:\tlearn: 0.0058401\ttotal: 904ms\tremaining: 2.23s\n",
      "144:\tlearn: 0.0058399\ttotal: 909ms\tremaining: 2.22s\n",
      "145:\tlearn: 0.0058397\ttotal: 913ms\tremaining: 2.21s\n",
      "146:\tlearn: 0.0058391\ttotal: 917ms\tremaining: 2.2s\n",
      "147:\tlearn: 0.0058389\ttotal: 922ms\tremaining: 2.19s\n",
      "148:\tlearn: 0.0058389\ttotal: 931ms\tremaining: 2.19s\n",
      "149:\tlearn: 0.0058388\ttotal: 941ms\tremaining: 2.19s\n",
      "150:\tlearn: 0.0058380\ttotal: 950ms\tremaining: 2.19s\n",
      "151:\tlearn: 0.0058381\ttotal: 959ms\tremaining: 2.2s\n",
      "152:\tlearn: 0.0058380\ttotal: 969ms\tremaining: 2.2s\n",
      "153:\tlearn: 0.0058380\ttotal: 978ms\tremaining: 2.2s\n",
      "154:\tlearn: 0.0058378\ttotal: 988ms\tremaining: 2.2s\n",
      "155:\tlearn: 0.0058372\ttotal: 997ms\tremaining: 2.2s\n",
      "156:\tlearn: 0.0058371\ttotal: 1.01s\tremaining: 2.2s\n",
      "157:\tlearn: 0.0058366\ttotal: 1.01s\tremaining: 2.2s\n",
      "158:\tlearn: 0.0058364\ttotal: 1.02s\tremaining: 2.19s\n",
      "159:\tlearn: 0.0058364\ttotal: 1.03s\tremaining: 2.19s\n",
      "160:\tlearn: 0.0055391\ttotal: 1.03s\tremaining: 2.18s\n",
      "161:\tlearn: 0.0053604\ttotal: 1.04s\tremaining: 2.17s\n",
      "162:\tlearn: 0.0051043\ttotal: 1.05s\tremaining: 2.17s\n",
      "163:\tlearn: 0.0051039\ttotal: 1.05s\tremaining: 2.16s\n",
      "164:\tlearn: 0.0050044\ttotal: 1.06s\tremaining: 2.15s\n",
      "165:\tlearn: 0.0050043\ttotal: 1.06s\tremaining: 2.14s\n",
      "166:\tlearn: 0.0049933\ttotal: 1.07s\tremaining: 2.13s\n",
      "167:\tlearn: 0.0048869\ttotal: 1.07s\tremaining: 2.12s\n",
      "168:\tlearn: 0.0048134\ttotal: 1.08s\tremaining: 2.11s\n",
      "169:\tlearn: 0.0048134\ttotal: 1.08s\tremaining: 2.1s\n",
      "170:\tlearn: 0.0046821\ttotal: 1.08s\tremaining: 2.09s\n",
      "171:\tlearn: 0.0044879\ttotal: 1.09s\tremaining: 2.08s\n",
      "172:\tlearn: 0.0042783\ttotal: 1.09s\tremaining: 2.07s\n",
      "173:\tlearn: 0.0042778\ttotal: 1.1s\tremaining: 2.06s\n",
      "174:\tlearn: 0.0041729\ttotal: 1.1s\tremaining: 2.05s\n",
      "175:\tlearn: 0.0041724\ttotal: 1.11s\tremaining: 2.04s\n",
      "176:\tlearn: 0.0041442\ttotal: 1.11s\tremaining: 2.03s\n",
      "177:\tlearn: 0.0039805\ttotal: 1.12s\tremaining: 2.03s\n",
      "178:\tlearn: 0.0039805\ttotal: 1.13s\tremaining: 2.02s\n",
      "179:\tlearn: 0.0038891\ttotal: 1.14s\tremaining: 2.02s\n",
      "180:\tlearn: 0.0038490\ttotal: 1.15s\tremaining: 2.02s\n",
      "181:\tlearn: 0.0038490\ttotal: 1.16s\tremaining: 2.02s\n",
      "182:\tlearn: 0.0038484\ttotal: 1.17s\tremaining: 2.02s\n",
      "183:\tlearn: 0.0038474\ttotal: 1.18s\tremaining: 2.02s\n",
      "184:\tlearn: 0.0038473\ttotal: 1.19s\tremaining: 2.02s\n",
      "185:\tlearn: 0.0038471\ttotal: 1.2s\tremaining: 2.02s\n",
      "186:\tlearn: 0.0038462\ttotal: 1.2s\tremaining: 2.02s\n",
      "187:\tlearn: 0.0038451\ttotal: 1.21s\tremaining: 2.01s\n",
      "188:\tlearn: 0.0038447\ttotal: 1.22s\tremaining: 2.01s\n",
      "189:\tlearn: 0.0038446\ttotal: 1.23s\tremaining: 2s\n",
      "190:\tlearn: 0.0038445\ttotal: 1.23s\tremaining: 1.99s\n",
      "191:\tlearn: 0.0038358\ttotal: 1.24s\tremaining: 1.98s\n",
      "192:\tlearn: 0.0038150\ttotal: 1.24s\tremaining: 1.97s\n",
      "193:\tlearn: 0.0038145\ttotal: 1.24s\tremaining: 1.96s\n",
      "194:\tlearn: 0.0038144\ttotal: 1.25s\tremaining: 1.95s\n",
      "195:\tlearn: 0.0038143\ttotal: 1.25s\tremaining: 1.94s\n",
      "196:\tlearn: 0.0038045\ttotal: 1.26s\tremaining: 1.94s\n",
      "197:\tlearn: 0.0036827\ttotal: 1.26s\tremaining: 1.93s\n",
      "198:\tlearn: 0.0035820\ttotal: 1.27s\tremaining: 1.92s\n",
      "199:\tlearn: 0.0035812\ttotal: 1.27s\tremaining: 1.91s\n",
      "200:\tlearn: 0.0034048\ttotal: 1.27s\tremaining: 1.9s\n",
      "201:\tlearn: 0.0034048\ttotal: 1.28s\tremaining: 1.89s\n",
      "202:\tlearn: 0.0034047\ttotal: 1.28s\tremaining: 1.88s\n",
      "203:\tlearn: 0.0034046\ttotal: 1.29s\tremaining: 1.87s\n",
      "204:\tlearn: 0.0033338\ttotal: 1.3s\tremaining: 1.87s\n",
      "205:\tlearn: 0.0033337\ttotal: 1.31s\tremaining: 1.87s\n",
      "206:\tlearn: 0.0033337\ttotal: 1.32s\tremaining: 1.87s\n",
      "207:\tlearn: 0.0033333\ttotal: 1.33s\tremaining: 1.87s\n",
      "208:\tlearn: 0.0033333\ttotal: 1.34s\tremaining: 1.86s\n",
      "209:\tlearn: 0.0033332\ttotal: 1.34s\tremaining: 1.86s\n",
      "210:\tlearn: 0.0033332\ttotal: 1.35s\tremaining: 1.85s\n",
      "211:\tlearn: 0.0033332\ttotal: 1.35s\tremaining: 1.84s\n",
      "212:\tlearn: 0.0033332\ttotal: 1.36s\tremaining: 1.83s\n",
      "213:\tlearn: 0.0033332\ttotal: 1.36s\tremaining: 1.82s\n",
      "214:\tlearn: 0.0033331\ttotal: 1.37s\tremaining: 1.81s\n",
      "215:\tlearn: 0.0033331\ttotal: 1.37s\tremaining: 1.81s\n",
      "216:\tlearn: 0.0033331\ttotal: 1.38s\tremaining: 1.8s\n",
      "217:\tlearn: 0.0033331\ttotal: 1.38s\tremaining: 1.79s\n",
      "218:\tlearn: 0.0033331\ttotal: 1.39s\tremaining: 1.78s\n",
      "219:\tlearn: 0.0033329\ttotal: 1.39s\tremaining: 1.77s\n",
      "220:\tlearn: 0.0033329\ttotal: 1.4s\tremaining: 1.76s\n",
      "221:\tlearn: 0.0033329\ttotal: 1.4s\tremaining: 1.75s\n",
      "222:\tlearn: 0.0033329\ttotal: 1.4s\tremaining: 1.74s\n",
      "223:\tlearn: 0.0032113\ttotal: 1.41s\tremaining: 1.73s\n",
      "224:\tlearn: 0.0032113\ttotal: 1.41s\tremaining: 1.73s\n",
      "225:\tlearn: 0.0032112\ttotal: 1.42s\tremaining: 1.72s\n",
      "226:\tlearn: 0.0032111\ttotal: 1.42s\tremaining: 1.71s\n",
      "227:\tlearn: 0.0032111\ttotal: 1.42s\tremaining: 1.7s\n",
      "228:\tlearn: 0.0032108\ttotal: 1.44s\tremaining: 1.7s\n",
      "229:\tlearn: 0.0032108\ttotal: 1.45s\tremaining: 1.7s\n",
      "230:\tlearn: 0.0032109\ttotal: 1.45s\tremaining: 1.69s\n",
      "231:\tlearn: 0.0032108\ttotal: 1.46s\tremaining: 1.69s\n",
      "232:\tlearn: 0.0032109\ttotal: 1.47s\tremaining: 1.69s\n",
      "233:\tlearn: 0.0032104\ttotal: 1.48s\tremaining: 1.69s\n",
      "234:\tlearn: 0.0032104\ttotal: 1.49s\tremaining: 1.68s\n",
      "235:\tlearn: 0.0032103\ttotal: 1.5s\tremaining: 1.68s\n",
      "236:\tlearn: 0.0032102\ttotal: 1.51s\tremaining: 1.67s\n",
      "237:\tlearn: 0.0032100\ttotal: 1.51s\tremaining: 1.67s\n",
      "238:\tlearn: 0.0032099\ttotal: 1.52s\tremaining: 1.66s\n",
      "239:\tlearn: 0.0032097\ttotal: 1.53s\tremaining: 1.65s\n",
      "240:\tlearn: 0.0032092\ttotal: 1.53s\tremaining: 1.65s\n",
      "241:\tlearn: 0.0032092\ttotal: 1.54s\tremaining: 1.64s\n",
      "242:\tlearn: 0.0032091\ttotal: 1.54s\tremaining: 1.63s\n",
      "243:\tlearn: 0.0032091\ttotal: 1.55s\tremaining: 1.62s\n",
      "244:\tlearn: 0.0032090\ttotal: 1.55s\tremaining: 1.61s\n",
      "245:\tlearn: 0.0032090\ttotal: 1.55s\tremaining: 1.61s\n",
      "246:\tlearn: 0.0032065\ttotal: 1.56s\tremaining: 1.6s\n",
      "247:\tlearn: 0.0032062\ttotal: 1.56s\tremaining: 1.59s\n",
      "248:\tlearn: 0.0032060\ttotal: 1.57s\tremaining: 1.58s\n",
      "249:\tlearn: 0.0032056\ttotal: 1.57s\tremaining: 1.57s\n",
      "250:\tlearn: 0.0031988\ttotal: 1.58s\tremaining: 1.56s\n",
      "251:\tlearn: 0.0031985\ttotal: 1.58s\tremaining: 1.55s\n",
      "252:\tlearn: 0.0031985\ttotal: 1.58s\tremaining: 1.55s\n",
      "253:\tlearn: 0.0031959\ttotal: 1.59s\tremaining: 1.54s\n",
      "254:\tlearn: 0.0031955\ttotal: 1.59s\tremaining: 1.53s\n",
      "255:\tlearn: 0.0031908\ttotal: 1.6s\tremaining: 1.52s\n",
      "256:\tlearn: 0.0031907\ttotal: 1.61s\tremaining: 1.52s\n",
      "257:\tlearn: 0.0031905\ttotal: 1.62s\tremaining: 1.52s\n",
      "258:\tlearn: 0.0031904\ttotal: 1.63s\tremaining: 1.51s\n",
      "259:\tlearn: 0.0031880\ttotal: 1.64s\tremaining: 1.51s\n",
      "260:\tlearn: 0.0031879\ttotal: 1.65s\tremaining: 1.51s\n",
      "261:\tlearn: 0.0031862\ttotal: 1.66s\tremaining: 1.5s\n",
      "262:\tlearn: 0.0031861\ttotal: 1.66s\tremaining: 1.5s\n",
      "263:\tlearn: 0.0031861\ttotal: 1.67s\tremaining: 1.5s\n",
      "264:\tlearn: 0.0031854\ttotal: 1.68s\tremaining: 1.49s\n",
      "265:\tlearn: 0.0031853\ttotal: 1.69s\tremaining: 1.48s\n",
      "266:\tlearn: 0.0031845\ttotal: 1.69s\tremaining: 1.48s\n",
      "267:\tlearn: 0.0031841\ttotal: 1.7s\tremaining: 1.47s\n",
      "268:\tlearn: 0.0031820\ttotal: 1.7s\tremaining: 1.46s\n",
      "269:\tlearn: 0.0031810\ttotal: 1.71s\tremaining: 1.45s\n",
      "270:\tlearn: 0.0031808\ttotal: 1.71s\tremaining: 1.45s\n",
      "271:\tlearn: 0.0031806\ttotal: 1.72s\tremaining: 1.44s\n",
      "272:\tlearn: 0.0031805\ttotal: 1.72s\tremaining: 1.43s\n",
      "273:\tlearn: 0.0031802\ttotal: 1.73s\tremaining: 1.42s\n",
      "274:\tlearn: 0.0031797\ttotal: 1.73s\tremaining: 1.42s\n",
      "275:\tlearn: 0.0031797\ttotal: 1.73s\tremaining: 1.41s\n",
      "276:\tlearn: 0.0031796\ttotal: 1.74s\tremaining: 1.4s\n",
      "277:\tlearn: 0.0031773\ttotal: 1.74s\tremaining: 1.39s\n",
      "278:\tlearn: 0.0031772\ttotal: 1.75s\tremaining: 1.38s\n",
      "279:\tlearn: 0.0031762\ttotal: 1.75s\tremaining: 1.38s\n",
      "280:\tlearn: 0.0031758\ttotal: 1.75s\tremaining: 1.37s\n",
      "281:\tlearn: 0.0031758\ttotal: 1.76s\tremaining: 1.36s\n",
      "282:\tlearn: 0.0031758\ttotal: 1.77s\tremaining: 1.36s\n",
      "283:\tlearn: 0.0031753\ttotal: 1.78s\tremaining: 1.36s\n",
      "284:\tlearn: 0.0031753\ttotal: 1.79s\tremaining: 1.35s\n",
      "285:\tlearn: 0.0031743\ttotal: 1.8s\tremaining: 1.35s\n",
      "286:\tlearn: 0.0031739\ttotal: 1.81s\tremaining: 1.34s\n",
      "287:\tlearn: 0.0031738\ttotal: 1.82s\tremaining: 1.34s\n",
      "288:\tlearn: 0.0031730\ttotal: 1.83s\tremaining: 1.33s\n",
      "289:\tlearn: 0.0031730\ttotal: 1.84s\tremaining: 1.33s\n",
      "290:\tlearn: 0.0031729\ttotal: 1.84s\tremaining: 1.32s\n",
      "291:\tlearn: 0.0031726\ttotal: 1.85s\tremaining: 1.32s\n",
      "292:\tlearn: 0.0031723\ttotal: 1.85s\tremaining: 1.31s\n",
      "293:\tlearn: 0.0031721\ttotal: 1.86s\tremaining: 1.3s\n",
      "294:\tlearn: 0.0031719\ttotal: 1.86s\tremaining: 1.29s\n",
      "295:\tlearn: 0.0031161\ttotal: 1.87s\tremaining: 1.29s\n",
      "296:\tlearn: 0.0031161\ttotal: 1.87s\tremaining: 1.28s\n",
      "297:\tlearn: 0.0031161\ttotal: 1.87s\tremaining: 1.27s\n",
      "298:\tlearn: 0.0031160\ttotal: 1.88s\tremaining: 1.26s\n",
      "299:\tlearn: 0.0031156\ttotal: 1.88s\tremaining: 1.25s\n",
      "300:\tlearn: 0.0031155\ttotal: 1.89s\tremaining: 1.25s\n",
      "301:\tlearn: 0.0031155\ttotal: 1.89s\tremaining: 1.24s\n",
      "302:\tlearn: 0.0031155\ttotal: 1.89s\tremaining: 1.23s\n",
      "303:\tlearn: 0.0031146\ttotal: 1.9s\tremaining: 1.23s\n",
      "304:\tlearn: 0.0031145\ttotal: 1.91s\tremaining: 1.22s\n",
      "305:\tlearn: 0.0031141\ttotal: 1.92s\tremaining: 1.22s\n",
      "306:\tlearn: 0.0031138\ttotal: 1.93s\tremaining: 1.21s\n",
      "307:\tlearn: 0.0031138\ttotal: 1.94s\tremaining: 1.21s\n",
      "308:\tlearn: 0.0031138\ttotal: 1.95s\tremaining: 1.21s\n",
      "309:\tlearn: 0.0031138\ttotal: 1.96s\tremaining: 1.2s\n",
      "310:\tlearn: 0.0031126\ttotal: 1.97s\tremaining: 1.2s\n",
      "311:\tlearn: 0.0031126\ttotal: 1.98s\tremaining: 1.19s\n",
      "312:\tlearn: 0.0031125\ttotal: 1.99s\tremaining: 1.19s\n",
      "313:\tlearn: 0.0031121\ttotal: 2s\tremaining: 1.18s\n",
      "314:\tlearn: 0.0031120\ttotal: 2s\tremaining: 1.18s\n",
      "315:\tlearn: 0.0031119\ttotal: 2.01s\tremaining: 1.17s\n",
      "316:\tlearn: 0.0031119\ttotal: 2.01s\tremaining: 1.16s\n",
      "317:\tlearn: 0.0031119\ttotal: 2.02s\tremaining: 1.15s\n",
      "318:\tlearn: 0.0031116\ttotal: 2.02s\tremaining: 1.15s\n",
      "319:\tlearn: 0.0031115\ttotal: 2.03s\tremaining: 1.14s\n",
      "320:\tlearn: 0.0031113\ttotal: 2.03s\tremaining: 1.13s\n",
      "321:\tlearn: 0.0031112\ttotal: 2.04s\tremaining: 1.13s\n",
      "322:\tlearn: 0.0031107\ttotal: 2.04s\tremaining: 1.12s\n",
      "323:\tlearn: 0.0031106\ttotal: 2.04s\tremaining: 1.11s\n",
      "324:\tlearn: 0.0031106\ttotal: 2.05s\tremaining: 1.1s\n",
      "325:\tlearn: 0.0031104\ttotal: 2.05s\tremaining: 1.09s\n",
      "326:\tlearn: 0.0031097\ttotal: 2.06s\tremaining: 1.09s\n",
      "327:\tlearn: 0.0029881\ttotal: 2.06s\tremaining: 1.08s\n",
      "328:\tlearn: 0.0029880\ttotal: 2.06s\tremaining: 1.07s\n",
      "329:\tlearn: 0.0029880\ttotal: 2.07s\tremaining: 1.06s\n",
      "330:\tlearn: 0.0029877\ttotal: 2.07s\tremaining: 1.06s\n",
      "331:\tlearn: 0.0029877\ttotal: 2.08s\tremaining: 1.05s\n",
      "332:\tlearn: 0.0029877\ttotal: 2.08s\tremaining: 1.04s\n",
      "333:\tlearn: 0.0029876\ttotal: 2.09s\tremaining: 1.04s\n",
      "334:\tlearn: 0.0029876\ttotal: 2.1s\tremaining: 1.03s\n",
      "335:\tlearn: 0.0029875\ttotal: 2.11s\tremaining: 1.03s\n",
      "336:\tlearn: 0.0029872\ttotal: 2.12s\tremaining: 1.03s\n",
      "337:\tlearn: 0.0029873\ttotal: 2.13s\tremaining: 1.02s\n",
      "338:\tlearn: 0.0029869\ttotal: 2.14s\tremaining: 1.02s\n",
      "339:\tlearn: 0.0029868\ttotal: 2.15s\tremaining: 1.01s\n",
      "340:\tlearn: 0.0029867\ttotal: 2.15s\tremaining: 1s\n",
      "341:\tlearn: 0.0029868\ttotal: 2.16s\tremaining: 999ms\n",
      "342:\tlearn: 0.0029864\ttotal: 2.17s\tremaining: 992ms\n",
      "343:\tlearn: 0.0029863\ttotal: 2.17s\tremaining: 986ms\n",
      "344:\tlearn: 0.0029863\ttotal: 2.18s\tremaining: 979ms\n",
      "345:\tlearn: 0.0029862\ttotal: 2.18s\tremaining: 972ms\n",
      "346:\tlearn: 0.0029861\ttotal: 2.19s\tremaining: 966ms\n",
      "347:\tlearn: 0.0029859\ttotal: 2.19s\tremaining: 959ms\n",
      "348:\tlearn: 0.0029859\ttotal: 2.2s\tremaining: 952ms\n",
      "349:\tlearn: 0.0029857\ttotal: 2.2s\tremaining: 944ms\n",
      "350:\tlearn: 0.0029856\ttotal: 2.21s\tremaining: 937ms\n",
      "351:\tlearn: 0.0029851\ttotal: 2.21s\tremaining: 929ms\n",
      "352:\tlearn: 0.0029817\ttotal: 2.21s\tremaining: 922ms\n",
      "353:\tlearn: 0.0029812\ttotal: 2.22s\tremaining: 915ms\n",
      "354:\tlearn: 0.0029794\ttotal: 2.22s\tremaining: 908ms\n",
      "355:\tlearn: 0.0029792\ttotal: 2.23s\tremaining: 900ms\n",
      "356:\tlearn: 0.0029791\ttotal: 2.23s\tremaining: 893ms\n",
      "357:\tlearn: 0.0029788\ttotal: 2.23s\tremaining: 886ms\n",
      "358:\tlearn: 0.0029787\ttotal: 2.24s\tremaining: 879ms\n",
      "359:\tlearn: 0.0029783\ttotal: 2.24s\tremaining: 872ms\n",
      "360:\tlearn: 0.0029782\ttotal: 2.25s\tremaining: 867ms\n",
      "361:\tlearn: 0.0029735\ttotal: 2.26s\tremaining: 862ms\n",
      "362:\tlearn: 0.0029734\ttotal: 2.27s\tremaining: 857ms\n",
      "363:\tlearn: 0.0029733\ttotal: 2.28s\tremaining: 852ms\n",
      "364:\tlearn: 0.0029729\ttotal: 2.29s\tremaining: 846ms\n",
      "365:\tlearn: 0.0029724\ttotal: 2.3s\tremaining: 841ms\n",
      "366:\tlearn: 0.0029724\ttotal: 2.31s\tremaining: 836ms\n",
      "367:\tlearn: 0.0029724\ttotal: 2.32s\tremaining: 831ms\n",
      "368:\tlearn: 0.0029722\ttotal: 2.32s\tremaining: 825ms\n",
      "369:\tlearn: 0.0029721\ttotal: 2.33s\tremaining: 819ms\n",
      "370:\tlearn: 0.0029719\ttotal: 2.34s\tremaining: 812ms\n",
      "371:\tlearn: 0.0029718\ttotal: 2.34s\tremaining: 806ms\n",
      "372:\tlearn: 0.0029718\ttotal: 2.35s\tremaining: 799ms\n",
      "373:\tlearn: 0.0029716\ttotal: 2.35s\tremaining: 793ms\n",
      "374:\tlearn: 0.0029715\ttotal: 2.36s\tremaining: 787ms\n",
      "375:\tlearn: 0.0029714\ttotal: 2.36s\tremaining: 780ms\n",
      "376:\tlearn: 0.0029714\ttotal: 2.37s\tremaining: 773ms\n",
      "377:\tlearn: 0.0029714\ttotal: 2.37s\tremaining: 766ms\n",
      "378:\tlearn: 0.0029698\ttotal: 2.38s\tremaining: 759ms\n",
      "379:\tlearn: 0.0029696\ttotal: 2.38s\tremaining: 752ms\n",
      "380:\tlearn: 0.0029697\ttotal: 2.39s\tremaining: 745ms\n",
      "381:\tlearn: 0.0029689\ttotal: 2.39s\tremaining: 738ms\n",
      "382:\tlearn: 0.0029689\ttotal: 2.39s\tremaining: 731ms\n",
      "383:\tlearn: 0.0029688\ttotal: 2.4s\tremaining: 725ms\n",
      "384:\tlearn: 0.0029688\ttotal: 2.4s\tremaining: 718ms\n",
      "385:\tlearn: 0.0029688\ttotal: 2.41s\tremaining: 711ms\n",
      "386:\tlearn: 0.0029688\ttotal: 2.41s\tremaining: 704ms\n",
      "387:\tlearn: 0.0029688\ttotal: 2.42s\tremaining: 698ms\n",
      "388:\tlearn: 0.0029685\ttotal: 2.43s\tremaining: 693ms\n",
      "389:\tlearn: 0.0029684\ttotal: 2.44s\tremaining: 688ms\n",
      "390:\tlearn: 0.0029683\ttotal: 2.45s\tremaining: 682ms\n",
      "391:\tlearn: 0.0029683\ttotal: 2.46s\tremaining: 677ms\n",
      "392:\tlearn: 0.0029682\ttotal: 2.46s\tremaining: 671ms\n",
      "393:\tlearn: 0.0029682\ttotal: 2.47s\tremaining: 666ms\n",
      "394:\tlearn: 0.0029665\ttotal: 2.48s\tremaining: 660ms\n",
      "395:\tlearn: 0.0029663\ttotal: 2.49s\tremaining: 655ms\n",
      "396:\tlearn: 0.0029662\ttotal: 2.5s\tremaining: 649ms\n",
      "397:\tlearn: 0.0029659\ttotal: 2.51s\tremaining: 643ms\n",
      "398:\tlearn: 0.0029659\ttotal: 2.51s\tremaining: 636ms\n",
      "399:\tlearn: 0.0029657\ttotal: 2.52s\tremaining: 631ms\n",
      "400:\tlearn: 0.0029655\ttotal: 2.53s\tremaining: 624ms\n",
      "401:\tlearn: 0.0029655\ttotal: 2.54s\tremaining: 618ms\n",
      "402:\tlearn: 0.0029654\ttotal: 2.54s\tremaining: 611ms\n",
      "403:\tlearn: 0.0029648\ttotal: 2.54s\tremaining: 605ms\n",
      "404:\tlearn: 0.0029648\ttotal: 2.55s\tremaining: 598ms\n",
      "405:\tlearn: 0.0029648\ttotal: 2.55s\tremaining: 591ms\n",
      "406:\tlearn: 0.0029647\ttotal: 2.56s\tremaining: 584ms\n",
      "407:\tlearn: 0.0029647\ttotal: 2.56s\tremaining: 578ms\n",
      "408:\tlearn: 0.0029648\ttotal: 2.57s\tremaining: 571ms\n",
      "409:\tlearn: 0.0029645\ttotal: 2.57s\tremaining: 564ms\n",
      "410:\tlearn: 0.0029644\ttotal: 2.58s\tremaining: 558ms\n",
      "411:\tlearn: 0.0029644\ttotal: 2.58s\tremaining: 551ms\n",
      "412:\tlearn: 0.0029644\ttotal: 2.58s\tremaining: 544ms\n",
      "413:\tlearn: 0.0029642\ttotal: 2.59s\tremaining: 538ms\n",
      "414:\tlearn: 0.0029635\ttotal: 2.59s\tremaining: 531ms\n",
      "415:\tlearn: 0.0029635\ttotal: 2.6s\tremaining: 524ms\n",
      "416:\tlearn: 0.0029631\ttotal: 2.6s\tremaining: 517ms\n",
      "417:\tlearn: 0.0029622\ttotal: 2.6s\tremaining: 511ms\n",
      "418:\tlearn: 0.0029621\ttotal: 2.61s\tremaining: 504ms\n",
      "419:\tlearn: 0.0029619\ttotal: 2.61s\tremaining: 497ms\n",
      "420:\tlearn: 0.0029618\ttotal: 2.62s\tremaining: 492ms\n",
      "421:\tlearn: 0.0029613\ttotal: 2.63s\tremaining: 486ms\n",
      "422:\tlearn: 0.0029610\ttotal: 2.64s\tremaining: 481ms\n",
      "423:\tlearn: 0.0029604\ttotal: 2.65s\tremaining: 475ms\n",
      "424:\tlearn: 0.0028153\ttotal: 2.66s\tremaining: 469ms\n",
      "425:\tlearn: 0.0028152\ttotal: 2.67s\tremaining: 464ms\n",
      "426:\tlearn: 0.0028148\ttotal: 2.68s\tremaining: 458ms\n",
      "427:\tlearn: 0.0028146\ttotal: 2.69s\tremaining: 452ms\n",
      "428:\tlearn: 0.0028145\ttotal: 2.69s\tremaining: 446ms\n",
      "429:\tlearn: 0.0028137\ttotal: 2.7s\tremaining: 439ms\n",
      "430:\tlearn: 0.0028137\ttotal: 2.71s\tremaining: 433ms\n",
      "431:\tlearn: 0.0028136\ttotal: 2.71s\tremaining: 427ms\n",
      "432:\tlearn: 0.0027152\ttotal: 2.72s\tremaining: 421ms\n",
      "433:\tlearn: 0.0027151\ttotal: 2.72s\tremaining: 414ms\n",
      "434:\tlearn: 0.0027149\ttotal: 2.73s\tremaining: 407ms\n",
      "435:\tlearn: 0.0027149\ttotal: 2.73s\tremaining: 401ms\n",
      "436:\tlearn: 0.0027149\ttotal: 2.73s\tremaining: 394ms\n",
      "437:\tlearn: 0.0027147\ttotal: 2.74s\tremaining: 388ms\n",
      "438:\tlearn: 0.0026289\ttotal: 2.74s\tremaining: 381ms\n",
      "439:\tlearn: 0.0026288\ttotal: 2.75s\tremaining: 375ms\n",
      "440:\tlearn: 0.0026280\ttotal: 2.75s\tremaining: 368ms\n",
      "441:\tlearn: 0.0026280\ttotal: 2.76s\tremaining: 362ms\n",
      "442:\tlearn: 0.0026280\ttotal: 2.76s\tremaining: 355ms\n",
      "443:\tlearn: 0.0026276\ttotal: 2.76s\tremaining: 349ms\n",
      "444:\tlearn: 0.0026275\ttotal: 2.77s\tremaining: 342ms\n",
      "445:\tlearn: 0.0026273\ttotal: 2.77s\tremaining: 336ms\n",
      "446:\tlearn: 0.0026271\ttotal: 2.78s\tremaining: 329ms\n",
      "447:\tlearn: 0.0026271\ttotal: 2.78s\tremaining: 323ms\n",
      "448:\tlearn: 0.0026271\ttotal: 2.79s\tremaining: 317ms\n",
      "449:\tlearn: 0.0026270\ttotal: 2.8s\tremaining: 311ms\n",
      "450:\tlearn: 0.0026266\ttotal: 2.81s\tremaining: 305ms\n",
      "451:\tlearn: 0.0026262\ttotal: 2.82s\tremaining: 299ms\n",
      "452:\tlearn: 0.0026260\ttotal: 2.83s\tremaining: 293ms\n",
      "453:\tlearn: 0.0026260\ttotal: 2.84s\tremaining: 287ms\n",
      "454:\tlearn: 0.0026260\ttotal: 2.85s\tremaining: 281ms\n",
      "455:\tlearn: 0.0026260\ttotal: 2.85s\tremaining: 275ms\n",
      "456:\tlearn: 0.0026256\ttotal: 2.86s\tremaining: 269ms\n",
      "457:\tlearn: 0.0026256\ttotal: 2.87s\tremaining: 263ms\n",
      "458:\tlearn: 0.0026255\ttotal: 2.87s\tremaining: 257ms\n",
      "459:\tlearn: 0.0025422\ttotal: 2.88s\tremaining: 251ms\n",
      "460:\tlearn: 0.0025421\ttotal: 2.89s\tremaining: 244ms\n",
      "461:\tlearn: 0.0024382\ttotal: 2.89s\tremaining: 238ms\n",
      "462:\tlearn: 0.0024382\ttotal: 2.9s\tremaining: 232ms\n",
      "463:\tlearn: 0.0024380\ttotal: 2.9s\tremaining: 225ms\n",
      "464:\tlearn: 0.0024380\ttotal: 2.91s\tremaining: 219ms\n",
      "465:\tlearn: 0.0024380\ttotal: 2.91s\tremaining: 212ms\n",
      "466:\tlearn: 0.0024379\ttotal: 2.92s\tremaining: 206ms\n",
      "467:\tlearn: 0.0023650\ttotal: 2.92s\tremaining: 200ms\n",
      "468:\tlearn: 0.0023650\ttotal: 2.92s\tremaining: 193ms\n",
      "469:\tlearn: 0.0023649\ttotal: 2.93s\tremaining: 187ms\n",
      "470:\tlearn: 0.0023647\ttotal: 2.93s\tremaining: 181ms\n",
      "471:\tlearn: 0.0023647\ttotal: 2.94s\tremaining: 174ms\n",
      "472:\tlearn: 0.0023646\ttotal: 2.94s\tremaining: 168ms\n",
      "473:\tlearn: 0.0023645\ttotal: 2.95s\tremaining: 162ms\n",
      "474:\tlearn: 0.0023645\ttotal: 2.96s\tremaining: 156ms\n",
      "475:\tlearn: 0.0023645\ttotal: 2.97s\tremaining: 150ms\n",
      "476:\tlearn: 0.0023644\ttotal: 2.98s\tremaining: 144ms\n",
      "477:\tlearn: 0.0023643\ttotal: 2.98s\tremaining: 137ms\n",
      "478:\tlearn: 0.0023643\ttotal: 2.99s\tremaining: 131ms\n",
      "479:\tlearn: 0.0023643\ttotal: 3s\tremaining: 125ms\n",
      "480:\tlearn: 0.0023640\ttotal: 3.01s\tremaining: 119ms\n",
      "481:\tlearn: 0.0023639\ttotal: 3.02s\tremaining: 113ms\n",
      "482:\tlearn: 0.0023639\ttotal: 3.03s\tremaining: 107ms\n",
      "483:\tlearn: 0.0023630\ttotal: 3.04s\tremaining: 100ms\n",
      "484:\tlearn: 0.0023628\ttotal: 3.04s\tremaining: 94.1ms\n",
      "485:\tlearn: 0.0023628\ttotal: 3.05s\tremaining: 87.9ms\n",
      "486:\tlearn: 0.0023628\ttotal: 3.06s\tremaining: 81.6ms\n",
      "487:\tlearn: 0.0023627\ttotal: 3.06s\tremaining: 75.3ms\n",
      "488:\tlearn: 0.0023627\ttotal: 3.07s\tremaining: 69ms\n",
      "489:\tlearn: 0.0023627\ttotal: 3.07s\tremaining: 62.7ms\n",
      "490:\tlearn: 0.0023626\ttotal: 3.08s\tremaining: 56.4ms\n",
      "491:\tlearn: 0.0023625\ttotal: 3.08s\tremaining: 50.1ms\n",
      "492:\tlearn: 0.0023624\ttotal: 3.09s\tremaining: 43.9ms\n",
      "493:\tlearn: 0.0023624\ttotal: 3.09s\tremaining: 37.6ms\n",
      "494:\tlearn: 0.0023623\ttotal: 3.1s\tremaining: 31.3ms\n",
      "495:\tlearn: 0.0023621\ttotal: 3.1s\tremaining: 25ms\n",
      "496:\tlearn: 0.0023621\ttotal: 3.11s\tremaining: 18.8ms\n",
      "497:\tlearn: 0.0023621\ttotal: 3.11s\tremaining: 12.5ms\n",
      "498:\tlearn: 0.0023621\ttotal: 3.12s\tremaining: 6.24ms\n",
      "499:\tlearn: 0.0023621\ttotal: 3.12s\tremaining: 0us\n",
      "0:\tlearn: 0.6351713\ttotal: 4.65ms\tremaining: 2.32s\n",
      "1:\tlearn: 0.5909224\ttotal: 9.11ms\tremaining: 2.27s\n",
      "2:\tlearn: 0.5512901\ttotal: 13.6ms\tremaining: 2.25s\n",
      "3:\tlearn: 0.5047394\ttotal: 17.8ms\tremaining: 2.21s\n",
      "4:\tlearn: 0.4585848\ttotal: 22.4ms\tremaining: 2.21s\n",
      "5:\tlearn: 0.4343544\ttotal: 26.8ms\tremaining: 2.21s\n",
      "6:\tlearn: 0.4063912\ttotal: 31.1ms\tremaining: 2.19s\n",
      "7:\tlearn: 0.3775000\ttotal: 35.4ms\tremaining: 2.17s\n",
      "8:\tlearn: 0.3492471\ttotal: 39.7ms\tremaining: 2.17s\n",
      "9:\tlearn: 0.3250725\ttotal: 43.8ms\tremaining: 2.15s\n",
      "10:\tlearn: 0.3040658\ttotal: 48.4ms\tremaining: 2.15s\n",
      "11:\tlearn: 0.2833086\ttotal: 52.8ms\tremaining: 2.15s\n",
      "12:\tlearn: 0.2616792\ttotal: 62.5ms\tremaining: 2.34s\n",
      "13:\tlearn: 0.2425558\ttotal: 72.1ms\tremaining: 2.5s\n",
      "14:\tlearn: 0.2299796\ttotal: 81.5ms\tremaining: 2.64s\n",
      "15:\tlearn: 0.2144132\ttotal: 91.2ms\tremaining: 2.76s\n",
      "16:\tlearn: 0.1948661\ttotal: 101ms\tremaining: 2.87s\n",
      "17:\tlearn: 0.1853157\ttotal: 111ms\tremaining: 2.97s\n",
      "18:\tlearn: 0.1742335\ttotal: 120ms\tremaining: 3.05s\n",
      "19:\tlearn: 0.1637804\ttotal: 129ms\tremaining: 3.1s\n",
      "20:\tlearn: 0.1539218\ttotal: 135ms\tremaining: 3.09s\n",
      "21:\tlearn: 0.1451414\ttotal: 142ms\tremaining: 3.08s\n",
      "22:\tlearn: 0.1331065\ttotal: 148ms\tremaining: 3.07s\n",
      "23:\tlearn: 0.1257898\ttotal: 154ms\tremaining: 3.06s\n",
      "24:\tlearn: 0.1182473\ttotal: 160ms\tremaining: 3.03s\n",
      "25:\tlearn: 0.1111742\ttotal: 164ms\tremaining: 2.99s\n",
      "26:\tlearn: 0.1050311\ttotal: 169ms\tremaining: 2.95s\n",
      "27:\tlearn: 0.0978373\ttotal: 173ms\tremaining: 2.92s\n",
      "28:\tlearn: 0.0926338\ttotal: 179ms\tremaining: 2.91s\n",
      "29:\tlearn: 0.0892660\ttotal: 183ms\tremaining: 2.86s\n",
      "30:\tlearn: 0.0850999\ttotal: 187ms\tremaining: 2.82s\n",
      "31:\tlearn: 0.0823216\ttotal: 190ms\tremaining: 2.78s\n",
      "32:\tlearn: 0.0781714\ttotal: 209ms\tremaining: 2.96s\n",
      "33:\tlearn: 0.0738890\ttotal: 219ms\tremaining: 3s\n",
      "34:\tlearn: 0.0700305\ttotal: 229ms\tremaining: 3.04s\n",
      "35:\tlearn: 0.0662744\ttotal: 238ms\tremaining: 3.07s\n",
      "36:\tlearn: 0.0647224\ttotal: 249ms\tremaining: 3.11s\n",
      "37:\tlearn: 0.0613355\ttotal: 258ms\tremaining: 3.14s\n",
      "38:\tlearn: 0.0579412\ttotal: 268ms\tremaining: 3.16s\n",
      "39:\tlearn: 0.0558926\ttotal: 277ms\tremaining: 3.19s\n",
      "40:\tlearn: 0.0529030\ttotal: 287ms\tremaining: 3.21s\n",
      "41:\tlearn: 0.0515494\ttotal: 297ms\tremaining: 3.23s\n",
      "42:\tlearn: 0.0482930\ttotal: 305ms\tremaining: 3.24s\n",
      "43:\tlearn: 0.0457020\ttotal: 311ms\tremaining: 3.22s\n",
      "44:\tlearn: 0.0438530\ttotal: 317ms\tremaining: 3.21s\n",
      "45:\tlearn: 0.0417209\ttotal: 324ms\tremaining: 3.2s\n",
      "46:\tlearn: 0.0400152\ttotal: 330ms\tremaining: 3.18s\n",
      "47:\tlearn: 0.0394642\ttotal: 335ms\tremaining: 3.15s\n",
      "48:\tlearn: 0.0372621\ttotal: 340ms\tremaining: 3.13s\n",
      "49:\tlearn: 0.0354223\ttotal: 344ms\tremaining: 3.1s\n",
      "50:\tlearn: 0.0345281\ttotal: 349ms\tremaining: 3.07s\n",
      "51:\tlearn: 0.0342669\ttotal: 354ms\tremaining: 3.05s\n",
      "52:\tlearn: 0.0324570\ttotal: 358ms\tremaining: 3.02s\n",
      "53:\tlearn: 0.0316156\ttotal: 363ms\tremaining: 3s\n",
      "54:\tlearn: 0.0302190\ttotal: 368ms\tremaining: 2.97s\n",
      "55:\tlearn: 0.0277420\ttotal: 372ms\tremaining: 2.95s\n",
      "56:\tlearn: 0.0264320\ttotal: 376ms\tremaining: 2.92s\n",
      "57:\tlearn: 0.0255557\ttotal: 380ms\tremaining: 2.89s\n",
      "58:\tlearn: 0.0240911\ttotal: 389ms\tremaining: 2.91s\n",
      "59:\tlearn: 0.0227397\ttotal: 399ms\tremaining: 2.93s\n",
      "60:\tlearn: 0.0222636\ttotal: 409ms\tremaining: 2.94s\n",
      "61:\tlearn: 0.0209345\ttotal: 419ms\tremaining: 2.96s\n",
      "62:\tlearn: 0.0205054\ttotal: 429ms\tremaining: 2.97s\n",
      "63:\tlearn: 0.0202600\ttotal: 438ms\tremaining: 2.98s\n",
      "64:\tlearn: 0.0193376\ttotal: 448ms\tremaining: 3s\n",
      "65:\tlearn: 0.0186885\ttotal: 458ms\tremaining: 3.01s\n",
      "66:\tlearn: 0.0185352\ttotal: 467ms\tremaining: 3.02s\n",
      "67:\tlearn: 0.0177430\ttotal: 477ms\tremaining: 3.03s\n",
      "68:\tlearn: 0.0172081\ttotal: 484ms\tremaining: 3.02s\n",
      "69:\tlearn: 0.0169529\ttotal: 490ms\tremaining: 3.01s\n",
      "70:\tlearn: 0.0157780\ttotal: 496ms\tremaining: 3s\n",
      "71:\tlearn: 0.0147906\ttotal: 502ms\tremaining: 2.98s\n",
      "72:\tlearn: 0.0139641\ttotal: 508ms\tremaining: 2.97s\n",
      "73:\tlearn: 0.0135871\ttotal: 513ms\tremaining: 2.95s\n",
      "74:\tlearn: 0.0128880\ttotal: 518ms\tremaining: 2.93s\n",
      "75:\tlearn: 0.0123132\ttotal: 523ms\tremaining: 2.92s\n",
      "76:\tlearn: 0.0120263\ttotal: 528ms\tremaining: 2.9s\n",
      "77:\tlearn: 0.0117656\ttotal: 532ms\tremaining: 2.88s\n",
      "78:\tlearn: 0.0114871\ttotal: 536ms\tremaining: 2.86s\n",
      "79:\tlearn: 0.0110605\ttotal: 540ms\tremaining: 2.84s\n",
      "80:\tlearn: 0.0104351\ttotal: 545ms\tremaining: 2.82s\n",
      "81:\tlearn: 0.0100866\ttotal: 549ms\tremaining: 2.8s\n",
      "82:\tlearn: 0.0098180\ttotal: 554ms\tremaining: 2.78s\n",
      "83:\tlearn: 0.0095876\ttotal: 559ms\tremaining: 2.77s\n",
      "84:\tlearn: 0.0091354\ttotal: 568ms\tremaining: 2.77s\n",
      "85:\tlearn: 0.0088758\ttotal: 578ms\tremaining: 2.78s\n",
      "86:\tlearn: 0.0085255\ttotal: 588ms\tremaining: 2.79s\n",
      "87:\tlearn: 0.0081169\ttotal: 597ms\tremaining: 2.8s\n",
      "88:\tlearn: 0.0078041\ttotal: 607ms\tremaining: 2.8s\n",
      "89:\tlearn: 0.0076529\ttotal: 617ms\tremaining: 2.81s\n",
      "90:\tlearn: 0.0073090\ttotal: 627ms\tremaining: 2.82s\n",
      "91:\tlearn: 0.0071638\ttotal: 637ms\tremaining: 2.82s\n",
      "92:\tlearn: 0.0070532\ttotal: 646ms\tremaining: 2.83s\n",
      "93:\tlearn: 0.0066312\ttotal: 654ms\tremaining: 2.82s\n",
      "94:\tlearn: 0.0064307\ttotal: 660ms\tremaining: 2.81s\n",
      "95:\tlearn: 0.0062087\ttotal: 666ms\tremaining: 2.8s\n",
      "96:\tlearn: 0.0060125\ttotal: 674ms\tremaining: 2.8s\n",
      "97:\tlearn: 0.0058451\ttotal: 681ms\tremaining: 2.79s\n",
      "98:\tlearn: 0.0057308\ttotal: 688ms\tremaining: 2.79s\n",
      "99:\tlearn: 0.0054164\ttotal: 693ms\tremaining: 2.77s\n",
      "100:\tlearn: 0.0053452\ttotal: 698ms\tremaining: 2.75s\n",
      "101:\tlearn: 0.0051702\ttotal: 703ms\tremaining: 2.74s\n",
      "102:\tlearn: 0.0050773\ttotal: 707ms\tremaining: 2.73s\n",
      "103:\tlearn: 0.0048872\ttotal: 712ms\tremaining: 2.71s\n",
      "104:\tlearn: 0.0047830\ttotal: 717ms\tremaining: 2.7s\n",
      "105:\tlearn: 0.0045329\ttotal: 721ms\tremaining: 2.68s\n",
      "106:\tlearn: 0.0045326\ttotal: 725ms\tremaining: 2.66s\n",
      "107:\tlearn: 0.0042810\ttotal: 738ms\tremaining: 2.68s\n",
      "108:\tlearn: 0.0042808\ttotal: 748ms\tremaining: 2.68s\n",
      "109:\tlearn: 0.0042752\ttotal: 757ms\tremaining: 2.68s\n",
      "110:\tlearn: 0.0042752\ttotal: 766ms\tremaining: 2.69s\n",
      "111:\tlearn: 0.0042670\ttotal: 776ms\tremaining: 2.69s\n",
      "112:\tlearn: 0.0042670\ttotal: 785ms\tremaining: 2.69s\n",
      "113:\tlearn: 0.0042500\ttotal: 795ms\tremaining: 2.69s\n",
      "114:\tlearn: 0.0042496\ttotal: 804ms\tremaining: 2.69s\n",
      "115:\tlearn: 0.0041670\ttotal: 813ms\tremaining: 2.69s\n",
      "116:\tlearn: 0.0039999\ttotal: 821ms\tremaining: 2.69s\n",
      "117:\tlearn: 0.0038537\ttotal: 827ms\tremaining: 2.68s\n",
      "118:\tlearn: 0.0036751\ttotal: 833ms\tremaining: 2.67s\n",
      "119:\tlearn: 0.0035548\ttotal: 840ms\tremaining: 2.66s\n",
      "120:\tlearn: 0.0033437\ttotal: 846ms\tremaining: 2.65s\n",
      "121:\tlearn: 0.0033435\ttotal: 851ms\tremaining: 2.64s\n",
      "122:\tlearn: 0.0033306\ttotal: 855ms\tremaining: 2.62s\n",
      "123:\tlearn: 0.0032095\ttotal: 860ms\tremaining: 2.61s\n",
      "124:\tlearn: 0.0032095\ttotal: 864ms\tremaining: 2.59s\n",
      "125:\tlearn: 0.0032095\ttotal: 869ms\tremaining: 2.58s\n",
      "126:\tlearn: 0.0032095\ttotal: 873ms\tremaining: 2.56s\n",
      "127:\tlearn: 0.0032093\ttotal: 877ms\tremaining: 2.55s\n",
      "128:\tlearn: 0.0032092\ttotal: 881ms\tremaining: 2.54s\n",
      "129:\tlearn: 0.0032092\ttotal: 886ms\tremaining: 2.52s\n",
      "130:\tlearn: 0.0032092\ttotal: 889ms\tremaining: 2.5s\n",
      "131:\tlearn: 0.0031123\ttotal: 894ms\tremaining: 2.49s\n",
      "132:\tlearn: 0.0031121\ttotal: 897ms\tremaining: 2.48s\n",
      "133:\tlearn: 0.0031121\ttotal: 901ms\tremaining: 2.46s\n",
      "134:\tlearn: 0.0031121\ttotal: 910ms\tremaining: 2.46s\n",
      "135:\tlearn: 0.0031121\ttotal: 919ms\tremaining: 2.46s\n",
      "136:\tlearn: 0.0031120\ttotal: 926ms\tremaining: 2.45s\n",
      "137:\tlearn: 0.0031120\ttotal: 931ms\tremaining: 2.44s\n",
      "138:\tlearn: 0.0031120\ttotal: 936ms\tremaining: 2.43s\n",
      "139:\tlearn: 0.0031120\ttotal: 943ms\tremaining: 2.42s\n",
      "140:\tlearn: 0.0031120\ttotal: 956ms\tremaining: 2.43s\n",
      "141:\tlearn: 0.0031120\ttotal: 960ms\tremaining: 2.42s\n",
      "142:\tlearn: 0.0031120\ttotal: 966ms\tremaining: 2.41s\n",
      "143:\tlearn: 0.0031120\ttotal: 972ms\tremaining: 2.4s\n",
      "144:\tlearn: 0.0031120\ttotal: 979ms\tremaining: 2.4s\n",
      "145:\tlearn: 0.0031120\ttotal: 985ms\tremaining: 2.39s\n",
      "146:\tlearn: 0.0031119\ttotal: 991ms\tremaining: 2.38s\n",
      "147:\tlearn: 0.0031119\ttotal: 996ms\tremaining: 2.37s\n",
      "148:\tlearn: 0.0031119\ttotal: 1s\tremaining: 2.36s\n",
      "149:\tlearn: 0.0031118\ttotal: 1.01s\tremaining: 2.35s\n",
      "150:\tlearn: 0.0031117\ttotal: 1.01s\tremaining: 2.34s\n",
      "151:\tlearn: 0.0031116\ttotal: 1.02s\tremaining: 2.33s\n",
      "152:\tlearn: 0.0031116\ttotal: 1.02s\tremaining: 2.32s\n",
      "153:\tlearn: 0.0031116\ttotal: 1.03s\tremaining: 2.31s\n",
      "154:\tlearn: 0.0031115\ttotal: 1.03s\tremaining: 2.3s\n",
      "155:\tlearn: 0.0031114\ttotal: 1.04s\tremaining: 2.29s\n",
      "156:\tlearn: 0.0031114\ttotal: 1.04s\tremaining: 2.28s\n",
      "157:\tlearn: 0.0031114\ttotal: 1.05s\tremaining: 2.28s\n",
      "158:\tlearn: 0.0031114\ttotal: 1.06s\tremaining: 2.27s\n",
      "159:\tlearn: 0.0031114\ttotal: 1.06s\tremaining: 2.26s\n",
      "160:\tlearn: 0.0031113\ttotal: 1.07s\tremaining: 2.25s\n",
      "161:\tlearn: 0.0031113\ttotal: 1.08s\tremaining: 2.25s\n",
      "162:\tlearn: 0.0031113\ttotal: 1.08s\tremaining: 2.24s\n",
      "163:\tlearn: 0.0031111\ttotal: 1.09s\tremaining: 2.23s\n",
      "164:\tlearn: 0.0031108\ttotal: 1.1s\tremaining: 2.23s\n",
      "165:\tlearn: 0.0031108\ttotal: 1.1s\tremaining: 2.22s\n",
      "166:\tlearn: 0.0031108\ttotal: 1.11s\tremaining: 2.21s\n",
      "167:\tlearn: 0.0031108\ttotal: 1.11s\tremaining: 2.2s\n",
      "168:\tlearn: 0.0031107\ttotal: 1.12s\tremaining: 2.19s\n",
      "169:\tlearn: 0.0031106\ttotal: 1.13s\tremaining: 2.19s\n",
      "170:\tlearn: 0.0031104\ttotal: 1.14s\tremaining: 2.19s\n",
      "171:\tlearn: 0.0031105\ttotal: 1.15s\tremaining: 2.19s\n",
      "172:\tlearn: 0.0031101\ttotal: 1.16s\tremaining: 2.19s\n",
      "173:\tlearn: 0.0031102\ttotal: 1.17s\tremaining: 2.19s\n",
      "174:\tlearn: 0.0031101\ttotal: 1.18s\tremaining: 2.18s\n",
      "175:\tlearn: 0.0031101\ttotal: 1.18s\tremaining: 2.18s\n",
      "176:\tlearn: 0.0031101\ttotal: 1.19s\tremaining: 2.18s\n",
      "177:\tlearn: 0.0031101\ttotal: 1.2s\tremaining: 2.18s\n",
      "178:\tlearn: 0.0031099\ttotal: 1.21s\tremaining: 2.17s\n",
      "179:\tlearn: 0.0031099\ttotal: 1.21s\tremaining: 2.15s\n",
      "180:\tlearn: 0.0031098\ttotal: 1.21s\tremaining: 2.14s\n",
      "181:\tlearn: 0.0031098\ttotal: 1.22s\tremaining: 2.12s\n",
      "182:\tlearn: 0.0031098\ttotal: 1.22s\tremaining: 2.11s\n",
      "183:\tlearn: 0.0031098\ttotal: 1.22s\tremaining: 2.1s\n",
      "184:\tlearn: 0.0031097\ttotal: 1.22s\tremaining: 2.08s\n",
      "185:\tlearn: 0.0031096\ttotal: 1.23s\tremaining: 2.07s\n",
      "186:\tlearn: 0.0031095\ttotal: 1.23s\tremaining: 2.06s\n",
      "187:\tlearn: 0.0031095\ttotal: 1.23s\tremaining: 2.05s\n",
      "188:\tlearn: 0.0031094\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.0031094\ttotal: 1.25s\tremaining: 2.04s\n",
      "190:\tlearn: 0.0031094\ttotal: 1.26s\tremaining: 2.04s\n",
      "191:\tlearn: 0.0031094\ttotal: 1.26s\tremaining: 2.03s\n",
      "192:\tlearn: 0.0031094\ttotal: 1.27s\tremaining: 2.02s\n",
      "193:\tlearn: 0.0031094\ttotal: 1.27s\tremaining: 2.01s\n",
      "194:\tlearn: 0.0031094\ttotal: 1.28s\tremaining: 2s\n",
      "195:\tlearn: 0.0031094\ttotal: 1.28s\tremaining: 1.99s\n",
      "196:\tlearn: 0.0031094\ttotal: 1.28s\tremaining: 1.98s\n",
      "197:\tlearn: 0.0031091\ttotal: 1.29s\tremaining: 1.97s\n",
      "198:\tlearn: 0.0030631\ttotal: 1.29s\tremaining: 1.96s\n",
      "199:\tlearn: 0.0030631\ttotal: 1.3s\tremaining: 1.95s\n",
      "200:\tlearn: 0.0030631\ttotal: 1.3s\tremaining: 1.94s\n",
      "201:\tlearn: 0.0030631\ttotal: 1.3s\tremaining: 1.93s\n",
      "202:\tlearn: 0.0030630\ttotal: 1.31s\tremaining: 1.92s\n",
      "203:\tlearn: 0.0030630\ttotal: 1.31s\tremaining: 1.9s\n",
      "204:\tlearn: 0.0030629\ttotal: 1.32s\tremaining: 1.9s\n",
      "205:\tlearn: 0.0030626\ttotal: 1.32s\tremaining: 1.89s\n",
      "206:\tlearn: 0.0030626\ttotal: 1.32s\tremaining: 1.87s\n",
      "207:\tlearn: 0.0029745\ttotal: 1.33s\tremaining: 1.87s\n",
      "208:\tlearn: 0.0029745\ttotal: 1.33s\tremaining: 1.86s\n",
      "209:\tlearn: 0.0029745\ttotal: 1.34s\tremaining: 1.85s\n",
      "210:\tlearn: 0.0029744\ttotal: 1.34s\tremaining: 1.84s\n",
      "211:\tlearn: 0.0029744\ttotal: 1.35s\tremaining: 1.83s\n",
      "212:\tlearn: 0.0029744\ttotal: 1.36s\tremaining: 1.83s\n",
      "213:\tlearn: 0.0029740\ttotal: 1.37s\tremaining: 1.83s\n",
      "214:\tlearn: 0.0029739\ttotal: 1.38s\tremaining: 1.83s\n",
      "215:\tlearn: 0.0029738\ttotal: 1.39s\tremaining: 1.82s\n",
      "216:\tlearn: 0.0029738\ttotal: 1.4s\tremaining: 1.82s\n",
      "217:\tlearn: 0.0029738\ttotal: 1.41s\tremaining: 1.82s\n",
      "218:\tlearn: 0.0029737\ttotal: 1.42s\tremaining: 1.82s\n",
      "219:\tlearn: 0.0029736\ttotal: 1.43s\tremaining: 1.81s\n",
      "220:\tlearn: 0.0029736\ttotal: 1.43s\tremaining: 1.81s\n",
      "221:\tlearn: 0.0029736\ttotal: 1.44s\tremaining: 1.81s\n",
      "222:\tlearn: 0.0029736\ttotal: 1.45s\tremaining: 1.8s\n",
      "223:\tlearn: 0.0029736\ttotal: 1.46s\tremaining: 1.8s\n",
      "224:\tlearn: 0.0029736\ttotal: 1.46s\tremaining: 1.79s\n",
      "225:\tlearn: 0.0029735\ttotal: 1.47s\tremaining: 1.78s\n",
      "226:\tlearn: 0.0029735\ttotal: 1.48s\tremaining: 1.77s\n",
      "227:\tlearn: 0.0029735\ttotal: 1.48s\tremaining: 1.77s\n",
      "228:\tlearn: 0.0029734\ttotal: 1.49s\tremaining: 1.76s\n",
      "229:\tlearn: 0.0029731\ttotal: 1.49s\tremaining: 1.75s\n",
      "230:\tlearn: 0.0029730\ttotal: 1.5s\tremaining: 1.74s\n",
      "231:\tlearn: 0.0029728\ttotal: 1.5s\tremaining: 1.73s\n",
      "232:\tlearn: 0.0029728\ttotal: 1.5s\tremaining: 1.72s\n",
      "233:\tlearn: 0.0029728\ttotal: 1.51s\tremaining: 1.72s\n",
      "234:\tlearn: 0.0029728\ttotal: 1.51s\tremaining: 1.71s\n",
      "235:\tlearn: 0.0029728\ttotal: 1.52s\tremaining: 1.7s\n",
      "236:\tlearn: 0.0029727\ttotal: 1.52s\tremaining: 1.69s\n",
      "237:\tlearn: 0.0029727\ttotal: 1.52s\tremaining: 1.68s\n",
      "238:\tlearn: 0.0029726\ttotal: 1.53s\tremaining: 1.67s\n",
      "239:\tlearn: 0.0029726\ttotal: 1.53s\tremaining: 1.66s\n",
      "240:\tlearn: 0.0029725\ttotal: 1.54s\tremaining: 1.65s\n",
      "241:\tlearn: 0.0029725\ttotal: 1.54s\tremaining: 1.64s\n",
      "242:\tlearn: 0.0029724\ttotal: 1.54s\tremaining: 1.64s\n",
      "243:\tlearn: 0.0029724\ttotal: 1.55s\tremaining: 1.63s\n",
      "244:\tlearn: 0.0029724\ttotal: 1.56s\tremaining: 1.63s\n",
      "245:\tlearn: 0.0029724\ttotal: 1.57s\tremaining: 1.62s\n",
      "246:\tlearn: 0.0029723\ttotal: 1.58s\tremaining: 1.62s\n",
      "247:\tlearn: 0.0029721\ttotal: 1.59s\tremaining: 1.62s\n",
      "248:\tlearn: 0.0029718\ttotal: 1.6s\tremaining: 1.61s\n",
      "249:\tlearn: 0.0029718\ttotal: 1.61s\tremaining: 1.61s\n",
      "250:\tlearn: 0.0029718\ttotal: 1.62s\tremaining: 1.61s\n",
      "251:\tlearn: 0.0029717\ttotal: 1.63s\tremaining: 1.6s\n",
      "252:\tlearn: 0.0029717\ttotal: 1.64s\tremaining: 1.6s\n",
      "253:\tlearn: 0.0029717\ttotal: 1.64s\tremaining: 1.59s\n",
      "254:\tlearn: 0.0029716\ttotal: 1.65s\tremaining: 1.58s\n",
      "255:\tlearn: 0.0029717\ttotal: 1.65s\tremaining: 1.58s\n",
      "256:\tlearn: 0.0029717\ttotal: 1.66s\tremaining: 1.57s\n",
      "257:\tlearn: 0.0029716\ttotal: 1.66s\tremaining: 1.56s\n",
      "258:\tlearn: 0.0029716\ttotal: 1.67s\tremaining: 1.55s\n",
      "259:\tlearn: 0.0029717\ttotal: 1.67s\tremaining: 1.54s\n",
      "260:\tlearn: 0.0029716\ttotal: 1.68s\tremaining: 1.53s\n",
      "261:\tlearn: 0.0029712\ttotal: 1.68s\tremaining: 1.53s\n",
      "262:\tlearn: 0.0029712\ttotal: 1.69s\tremaining: 1.52s\n",
      "263:\tlearn: 0.0029712\ttotal: 1.69s\tremaining: 1.51s\n",
      "264:\tlearn: 0.0029711\ttotal: 1.69s\tremaining: 1.5s\n",
      "265:\tlearn: 0.0029710\ttotal: 1.7s\tremaining: 1.49s\n",
      "266:\tlearn: 0.0029711\ttotal: 1.7s\tremaining: 1.49s\n",
      "267:\tlearn: 0.0029710\ttotal: 1.71s\tremaining: 1.48s\n",
      "268:\tlearn: 0.0029710\ttotal: 1.71s\tremaining: 1.47s\n",
      "269:\tlearn: 0.0029711\ttotal: 1.71s\tremaining: 1.46s\n",
      "270:\tlearn: 0.0029710\ttotal: 1.72s\tremaining: 1.45s\n",
      "271:\tlearn: 0.0029710\ttotal: 1.72s\tremaining: 1.44s\n",
      "272:\tlearn: 0.0029711\ttotal: 1.73s\tremaining: 1.44s\n",
      "273:\tlearn: 0.0029705\ttotal: 1.74s\tremaining: 1.44s\n",
      "274:\tlearn: 0.0029706\ttotal: 1.75s\tremaining: 1.43s\n",
      "275:\tlearn: 0.0029704\ttotal: 1.76s\tremaining: 1.43s\n",
      "276:\tlearn: 0.0029700\ttotal: 1.77s\tremaining: 1.42s\n",
      "277:\tlearn: 0.0029699\ttotal: 1.78s\tremaining: 1.42s\n",
      "278:\tlearn: 0.0029695\ttotal: 1.79s\tremaining: 1.42s\n",
      "279:\tlearn: 0.0029695\ttotal: 1.8s\tremaining: 1.41s\n",
      "280:\tlearn: 0.0029695\ttotal: 1.8s\tremaining: 1.41s\n",
      "281:\tlearn: 0.0029695\ttotal: 1.81s\tremaining: 1.4s\n",
      "282:\tlearn: 0.0029694\ttotal: 1.82s\tremaining: 1.39s\n",
      "283:\tlearn: 0.0029692\ttotal: 1.82s\tremaining: 1.39s\n",
      "284:\tlearn: 0.0029692\ttotal: 1.83s\tremaining: 1.38s\n",
      "285:\tlearn: 0.0029691\ttotal: 1.83s\tremaining: 1.37s\n",
      "286:\tlearn: 0.0029690\ttotal: 1.84s\tremaining: 1.36s\n",
      "287:\tlearn: 0.0029689\ttotal: 1.84s\tremaining: 1.36s\n",
      "288:\tlearn: 0.0029687\ttotal: 1.85s\tremaining: 1.35s\n",
      "289:\tlearn: 0.0029687\ttotal: 1.85s\tremaining: 1.34s\n",
      "290:\tlearn: 0.0029687\ttotal: 1.86s\tremaining: 1.33s\n",
      "291:\tlearn: 0.0029686\ttotal: 1.86s\tremaining: 1.32s\n",
      "292:\tlearn: 0.0029686\ttotal: 1.86s\tremaining: 1.32s\n",
      "293:\tlearn: 0.0029686\ttotal: 1.87s\tremaining: 1.31s\n",
      "294:\tlearn: 0.0029686\ttotal: 1.87s\tremaining: 1.3s\n",
      "295:\tlearn: 0.0029685\ttotal: 1.88s\tremaining: 1.29s\n",
      "296:\tlearn: 0.0029684\ttotal: 1.88s\tremaining: 1.28s\n",
      "297:\tlearn: 0.0029682\ttotal: 1.89s\tremaining: 1.28s\n",
      "298:\tlearn: 0.0029681\ttotal: 1.9s\tremaining: 1.28s\n",
      "299:\tlearn: 0.0029681\ttotal: 1.91s\tremaining: 1.27s\n",
      "300:\tlearn: 0.0029681\ttotal: 1.92s\tremaining: 1.27s\n",
      "301:\tlearn: 0.0029681\ttotal: 1.93s\tremaining: 1.26s\n",
      "302:\tlearn: 0.0029678\ttotal: 1.94s\tremaining: 1.26s\n",
      "303:\tlearn: 0.0029677\ttotal: 1.95s\tremaining: 1.25s\n",
      "304:\tlearn: 0.0029676\ttotal: 1.96s\tremaining: 1.25s\n",
      "305:\tlearn: 0.0029675\ttotal: 1.97s\tremaining: 1.25s\n",
      "306:\tlearn: 0.0029675\ttotal: 1.97s\tremaining: 1.24s\n",
      "307:\tlearn: 0.0029673\ttotal: 1.98s\tremaining: 1.23s\n",
      "308:\tlearn: 0.0029666\ttotal: 1.99s\tremaining: 1.23s\n",
      "309:\tlearn: 0.0029666\ttotal: 1.99s\tremaining: 1.22s\n",
      "310:\tlearn: 0.0029663\ttotal: 2s\tremaining: 1.21s\n",
      "311:\tlearn: 0.0029660\ttotal: 2s\tremaining: 1.21s\n",
      "312:\tlearn: 0.0029660\ttotal: 2.01s\tremaining: 1.2s\n",
      "313:\tlearn: 0.0029655\ttotal: 2.01s\tremaining: 1.19s\n",
      "314:\tlearn: 0.0029652\ttotal: 2.02s\tremaining: 1.18s\n",
      "315:\tlearn: 0.0029651\ttotal: 2.02s\tremaining: 1.18s\n",
      "316:\tlearn: 0.0029651\ttotal: 2.02s\tremaining: 1.17s\n",
      "317:\tlearn: 0.0029650\ttotal: 2.03s\tremaining: 1.16s\n",
      "318:\tlearn: 0.0029649\ttotal: 2.03s\tremaining: 1.15s\n",
      "319:\tlearn: 0.0029648\ttotal: 2.04s\tremaining: 1.15s\n",
      "320:\tlearn: 0.0028477\ttotal: 2.04s\tremaining: 1.14s\n",
      "321:\tlearn: 0.0028476\ttotal: 2.04s\tremaining: 1.13s\n",
      "322:\tlearn: 0.0028476\ttotal: 2.05s\tremaining: 1.12s\n",
      "323:\tlearn: 0.0028476\ttotal: 2.05s\tremaining: 1.11s\n",
      "324:\tlearn: 0.0028476\ttotal: 2.06s\tremaining: 1.11s\n",
      "325:\tlearn: 0.0028466\ttotal: 2.07s\tremaining: 1.11s\n",
      "326:\tlearn: 0.0027461\ttotal: 2.08s\tremaining: 1.1s\n",
      "327:\tlearn: 0.0027460\ttotal: 2.09s\tremaining: 1.1s\n",
      "328:\tlearn: 0.0027459\ttotal: 2.1s\tremaining: 1.09s\n",
      "329:\tlearn: 0.0027458\ttotal: 2.11s\tremaining: 1.09s\n",
      "330:\tlearn: 0.0027457\ttotal: 2.12s\tremaining: 1.08s\n",
      "331:\tlearn: 0.0027451\ttotal: 2.13s\tremaining: 1.08s\n",
      "332:\tlearn: 0.0027449\ttotal: 2.14s\tremaining: 1.07s\n",
      "333:\tlearn: 0.0027448\ttotal: 2.15s\tremaining: 1.07s\n",
      "334:\tlearn: 0.0027448\ttotal: 2.15s\tremaining: 1.06s\n",
      "335:\tlearn: 0.0027448\ttotal: 2.16s\tremaining: 1.05s\n",
      "336:\tlearn: 0.0027448\ttotal: 2.17s\tremaining: 1.05s\n",
      "337:\tlearn: 0.0027448\ttotal: 2.17s\tremaining: 1.04s\n",
      "338:\tlearn: 0.0027448\ttotal: 2.17s\tremaining: 1.03s\n",
      "339:\tlearn: 0.0027448\ttotal: 2.18s\tremaining: 1.02s\n",
      "340:\tlearn: 0.0027447\ttotal: 2.18s\tremaining: 1.02s\n",
      "341:\tlearn: 0.0027445\ttotal: 2.19s\tremaining: 1.01s\n",
      "342:\tlearn: 0.0027445\ttotal: 2.19s\tremaining: 1s\n",
      "343:\tlearn: 0.0027443\ttotal: 2.2s\tremaining: 996ms\n",
      "344:\tlearn: 0.0027442\ttotal: 2.2s\tremaining: 989ms\n",
      "345:\tlearn: 0.0027441\ttotal: 2.2s\tremaining: 981ms\n",
      "346:\tlearn: 0.0027440\ttotal: 2.21s\tremaining: 973ms\n",
      "347:\tlearn: 0.0027440\ttotal: 2.21s\tremaining: 966ms\n",
      "348:\tlearn: 0.0027438\ttotal: 2.21s\tremaining: 959ms\n",
      "349:\tlearn: 0.0027438\ttotal: 2.22s\tremaining: 951ms\n",
      "350:\tlearn: 0.0027437\ttotal: 2.22s\tremaining: 944ms\n",
      "351:\tlearn: 0.0027437\ttotal: 2.23s\tremaining: 936ms\n",
      "352:\tlearn: 0.0027435\ttotal: 2.24s\tremaining: 932ms\n",
      "353:\tlearn: 0.0027432\ttotal: 2.25s\tremaining: 927ms\n",
      "354:\tlearn: 0.0027430\ttotal: 2.26s\tremaining: 921ms\n",
      "355:\tlearn: 0.0027430\ttotal: 2.27s\tremaining: 916ms\n",
      "356:\tlearn: 0.0027430\ttotal: 2.27s\tremaining: 911ms\n",
      "357:\tlearn: 0.0027429\ttotal: 2.28s\tremaining: 906ms\n",
      "358:\tlearn: 0.0027428\ttotal: 2.29s\tremaining: 901ms\n",
      "359:\tlearn: 0.0027428\ttotal: 2.3s\tremaining: 895ms\n",
      "360:\tlearn: 0.0027428\ttotal: 2.31s\tremaining: 890ms\n",
      "361:\tlearn: 0.0027427\ttotal: 2.32s\tremaining: 884ms\n",
      "362:\tlearn: 0.0027426\ttotal: 2.32s\tremaining: 877ms\n",
      "363:\tlearn: 0.0027426\ttotal: 2.33s\tremaining: 871ms\n",
      "364:\tlearn: 0.0027425\ttotal: 2.34s\tremaining: 864ms\n",
      "365:\tlearn: 0.0027424\ttotal: 2.34s\tremaining: 858ms\n",
      "366:\tlearn: 0.0027423\ttotal: 2.35s\tremaining: 851ms\n",
      "367:\tlearn: 0.0027423\ttotal: 2.35s\tremaining: 844ms\n",
      "368:\tlearn: 0.0027422\ttotal: 2.36s\tremaining: 837ms\n",
      "369:\tlearn: 0.0027421\ttotal: 2.36s\tremaining: 830ms\n",
      "370:\tlearn: 0.0027420\ttotal: 2.37s\tremaining: 823ms\n",
      "371:\tlearn: 0.0027419\ttotal: 2.37s\tremaining: 816ms\n",
      "372:\tlearn: 0.0027418\ttotal: 2.38s\tremaining: 809ms\n",
      "373:\tlearn: 0.0027418\ttotal: 2.38s\tremaining: 802ms\n",
      "374:\tlearn: 0.0027418\ttotal: 2.38s\tremaining: 795ms\n",
      "375:\tlearn: 0.0027418\ttotal: 2.38s\tremaining: 787ms\n",
      "376:\tlearn: 0.0027416\ttotal: 2.39s\tremaining: 780ms\n",
      "377:\tlearn: 0.0027416\ttotal: 2.39s\tremaining: 772ms\n",
      "378:\tlearn: 0.0027415\ttotal: 2.4s\tremaining: 765ms\n",
      "379:\tlearn: 0.0027415\ttotal: 2.4s\tremaining: 758ms\n",
      "380:\tlearn: 0.0027411\ttotal: 2.4s\tremaining: 751ms\n",
      "381:\tlearn: 0.0027411\ttotal: 2.41s\tremaining: 744ms\n",
      "382:\tlearn: 0.0027410\ttotal: 2.41s\tremaining: 737ms\n",
      "383:\tlearn: 0.0027410\ttotal: 2.42s\tremaining: 730ms\n",
      "384:\tlearn: 0.0027408\ttotal: 2.42s\tremaining: 723ms\n",
      "385:\tlearn: 0.0027407\ttotal: 2.42s\tremaining: 716ms\n",
      "386:\tlearn: 0.0027341\ttotal: 2.44s\tremaining: 711ms\n",
      "387:\tlearn: 0.0027340\ttotal: 2.44s\tremaining: 706ms\n",
      "388:\tlearn: 0.0027339\ttotal: 2.45s\tremaining: 700ms\n",
      "389:\tlearn: 0.0027339\ttotal: 2.46s\tremaining: 695ms\n",
      "390:\tlearn: 0.0027338\ttotal: 2.47s\tremaining: 690ms\n",
      "391:\tlearn: 0.0027337\ttotal: 2.48s\tremaining: 684ms\n",
      "392:\tlearn: 0.0027335\ttotal: 2.49s\tremaining: 679ms\n",
      "393:\tlearn: 0.0027332\ttotal: 2.5s\tremaining: 673ms\n",
      "394:\tlearn: 0.0027331\ttotal: 2.51s\tremaining: 667ms\n",
      "395:\tlearn: 0.0027331\ttotal: 2.51s\tremaining: 660ms\n",
      "396:\tlearn: 0.0027328\ttotal: 2.52s\tremaining: 654ms\n",
      "397:\tlearn: 0.0027327\ttotal: 2.53s\tremaining: 648ms\n",
      "398:\tlearn: 0.0027327\ttotal: 2.53s\tremaining: 642ms\n",
      "399:\tlearn: 0.0027327\ttotal: 2.54s\tremaining: 635ms\n",
      "400:\tlearn: 0.0027325\ttotal: 2.54s\tremaining: 628ms\n",
      "401:\tlearn: 0.0027324\ttotal: 2.55s\tremaining: 621ms\n",
      "402:\tlearn: 0.0027325\ttotal: 2.55s\tremaining: 614ms\n",
      "403:\tlearn: 0.0027307\ttotal: 2.56s\tremaining: 608ms\n",
      "404:\tlearn: 0.0027307\ttotal: 2.56s\tremaining: 601ms\n",
      "405:\tlearn: 0.0027306\ttotal: 2.57s\tremaining: 594ms\n",
      "406:\tlearn: 0.0027303\ttotal: 2.57s\tremaining: 587ms\n",
      "407:\tlearn: 0.0027302\ttotal: 2.58s\tremaining: 581ms\n",
      "408:\tlearn: 0.0027302\ttotal: 2.58s\tremaining: 574ms\n",
      "409:\tlearn: 0.0027301\ttotal: 2.58s\tremaining: 567ms\n",
      "410:\tlearn: 0.0027298\ttotal: 2.59s\tremaining: 560ms\n",
      "411:\tlearn: 0.0027296\ttotal: 2.6s\tremaining: 555ms\n",
      "412:\tlearn: 0.0027296\ttotal: 2.61s\tremaining: 549ms\n",
      "413:\tlearn: 0.0027293\ttotal: 2.62s\tremaining: 543ms\n",
      "414:\tlearn: 0.0027293\ttotal: 2.63s\tremaining: 538ms\n",
      "415:\tlearn: 0.0027292\ttotal: 2.63s\tremaining: 532ms\n",
      "416:\tlearn: 0.0027291\ttotal: 2.64s\tremaining: 526ms\n",
      "417:\tlearn: 0.0027285\ttotal: 2.65s\tremaining: 521ms\n",
      "418:\tlearn: 0.0027284\ttotal: 2.66s\tremaining: 515ms\n",
      "419:\tlearn: 0.0027283\ttotal: 2.67s\tremaining: 509ms\n",
      "420:\tlearn: 0.0027283\ttotal: 2.68s\tremaining: 503ms\n",
      "421:\tlearn: 0.0027278\ttotal: 2.69s\tremaining: 496ms\n",
      "422:\tlearn: 0.0027276\ttotal: 2.69s\tremaining: 490ms\n",
      "423:\tlearn: 0.0027273\ttotal: 2.7s\tremaining: 484ms\n",
      "424:\tlearn: 0.0027273\ttotal: 2.71s\tremaining: 478ms\n",
      "425:\tlearn: 0.0027273\ttotal: 2.71s\tremaining: 471ms\n",
      "426:\tlearn: 0.0027273\ttotal: 2.71s\tremaining: 464ms\n",
      "427:\tlearn: 0.0027271\ttotal: 2.72s\tremaining: 458ms\n",
      "428:\tlearn: 0.0027271\ttotal: 2.72s\tremaining: 451ms\n",
      "429:\tlearn: 0.0027271\ttotal: 2.73s\tremaining: 444ms\n",
      "430:\tlearn: 0.0027271\ttotal: 2.73s\tremaining: 438ms\n",
      "431:\tlearn: 0.0027270\ttotal: 2.74s\tremaining: 431ms\n",
      "432:\tlearn: 0.0027270\ttotal: 2.74s\tremaining: 424ms\n",
      "433:\tlearn: 0.0027269\ttotal: 2.75s\tremaining: 418ms\n",
      "434:\tlearn: 0.0027264\ttotal: 2.75s\tremaining: 411ms\n",
      "435:\tlearn: 0.0027263\ttotal: 2.75s\tremaining: 404ms\n",
      "436:\tlearn: 0.0027262\ttotal: 2.76s\tremaining: 398ms\n",
      "437:\tlearn: 0.0027261\ttotal: 2.76s\tremaining: 391ms\n",
      "438:\tlearn: 0.0027261\ttotal: 2.77s\tremaining: 385ms\n",
      "439:\tlearn: 0.0027261\ttotal: 2.77s\tremaining: 378ms\n",
      "440:\tlearn: 0.0027227\ttotal: 2.78s\tremaining: 371ms\n",
      "441:\tlearn: 0.0026057\ttotal: 2.78s\tremaining: 365ms\n",
      "442:\tlearn: 0.0026056\ttotal: 2.78s\tremaining: 358ms\n",
      "443:\tlearn: 0.0026057\ttotal: 2.79s\tremaining: 352ms\n",
      "444:\tlearn: 0.0026055\ttotal: 2.79s\tremaining: 345ms\n",
      "445:\tlearn: 0.0026052\ttotal: 2.8s\tremaining: 339ms\n",
      "446:\tlearn: 0.0026051\ttotal: 2.81s\tremaining: 333ms\n",
      "447:\tlearn: 0.0026049\ttotal: 2.82s\tremaining: 327ms\n",
      "448:\tlearn: 0.0026046\ttotal: 2.83s\tremaining: 322ms\n",
      "449:\tlearn: 0.0026039\ttotal: 2.84s\tremaining: 316ms\n",
      "450:\tlearn: 0.0026037\ttotal: 2.85s\tremaining: 310ms\n",
      "451:\tlearn: 0.0026035\ttotal: 2.86s\tremaining: 304ms\n",
      "452:\tlearn: 0.0026034\ttotal: 2.87s\tremaining: 298ms\n",
      "453:\tlearn: 0.0026033\ttotal: 2.88s\tremaining: 292ms\n",
      "454:\tlearn: 0.0026034\ttotal: 2.88s\tremaining: 285ms\n",
      "455:\tlearn: 0.0026034\ttotal: 2.89s\tremaining: 279ms\n",
      "456:\tlearn: 0.0026033\ttotal: 2.89s\tremaining: 272ms\n",
      "457:\tlearn: 0.0026026\ttotal: 2.9s\tremaining: 266ms\n",
      "458:\tlearn: 0.0026026\ttotal: 2.9s\tremaining: 259ms\n",
      "459:\tlearn: 0.0026022\ttotal: 2.91s\tremaining: 253ms\n",
      "460:\tlearn: 0.0026020\ttotal: 2.91s\tremaining: 246ms\n",
      "461:\tlearn: 0.0026021\ttotal: 2.92s\tremaining: 240ms\n",
      "462:\tlearn: 0.0026019\ttotal: 2.92s\tremaining: 233ms\n",
      "463:\tlearn: 0.0026019\ttotal: 2.92s\tremaining: 227ms\n",
      "464:\tlearn: 0.0026018\ttotal: 2.93s\tremaining: 220ms\n",
      "465:\tlearn: 0.0026017\ttotal: 2.93s\tremaining: 214ms\n",
      "466:\tlearn: 0.0026016\ttotal: 2.94s\tremaining: 208ms\n",
      "467:\tlearn: 0.0025998\ttotal: 2.94s\tremaining: 201ms\n",
      "468:\tlearn: 0.0025992\ttotal: 2.94s\tremaining: 195ms\n",
      "469:\tlearn: 0.0025991\ttotal: 2.95s\tremaining: 188ms\n",
      "470:\tlearn: 0.0025991\ttotal: 2.95s\tremaining: 182ms\n",
      "471:\tlearn: 0.0025991\ttotal: 2.96s\tremaining: 175ms\n",
      "472:\tlearn: 0.0025991\ttotal: 2.96s\tremaining: 169ms\n",
      "473:\tlearn: 0.0025991\ttotal: 2.96s\tremaining: 163ms\n",
      "474:\tlearn: 0.0025991\ttotal: 2.98s\tremaining: 157ms\n",
      "475:\tlearn: 0.0025990\ttotal: 2.98s\tremaining: 150ms\n",
      "476:\tlearn: 0.0025990\ttotal: 2.99s\tremaining: 144ms\n",
      "477:\tlearn: 0.0025973\ttotal: 3s\tremaining: 138ms\n",
      "478:\tlearn: 0.0025973\ttotal: 3.01s\tremaining: 132ms\n",
      "479:\tlearn: 0.0025960\ttotal: 3.02s\tremaining: 126ms\n",
      "480:\tlearn: 0.0025960\ttotal: 3.03s\tremaining: 120ms\n",
      "481:\tlearn: 0.0025954\ttotal: 3.04s\tremaining: 114ms\n",
      "482:\tlearn: 0.0025950\ttotal: 3.05s\tremaining: 107ms\n",
      "483:\tlearn: 0.0025949\ttotal: 3.06s\tremaining: 101ms\n",
      "484:\tlearn: 0.0025949\ttotal: 3.07s\tremaining: 94.8ms\n",
      "485:\tlearn: 0.0025949\ttotal: 3.07s\tremaining: 88.5ms\n",
      "486:\tlearn: 0.0025476\ttotal: 3.08s\tremaining: 82.2ms\n",
      "487:\tlearn: 0.0024382\ttotal: 3.09s\tremaining: 75.9ms\n",
      "488:\tlearn: 0.0024380\ttotal: 3.09s\tremaining: 69.6ms\n",
      "489:\tlearn: 0.0024375\ttotal: 3.1s\tremaining: 63.2ms\n",
      "490:\tlearn: 0.0024374\ttotal: 3.1s\tremaining: 56.9ms\n",
      "491:\tlearn: 0.0024372\ttotal: 3.11s\tremaining: 50.5ms\n",
      "492:\tlearn: 0.0024369\ttotal: 3.11s\tremaining: 44.2ms\n",
      "493:\tlearn: 0.0024369\ttotal: 3.12s\tremaining: 37.9ms\n",
      "494:\tlearn: 0.0024370\ttotal: 3.12s\tremaining: 31.5ms\n",
      "495:\tlearn: 0.0024366\ttotal: 3.13s\tremaining: 25.2ms\n",
      "496:\tlearn: 0.0024366\ttotal: 3.13s\tremaining: 18.9ms\n",
      "497:\tlearn: 0.0024365\ttotal: 3.13s\tremaining: 12.6ms\n",
      "498:\tlearn: 0.0024362\ttotal: 3.14s\tremaining: 6.29ms\n",
      "499:\tlearn: 0.0024361\ttotal: 3.14s\tremaining: 0us\n",
      "0:\tlearn: 0.6435839\ttotal: 6.62ms\tremaining: 3.3s\n",
      "1:\tlearn: 0.5905930\ttotal: 13.1ms\tremaining: 3.27s\n",
      "2:\tlearn: 0.5626224\ttotal: 19.2ms\tremaining: 3.18s\n",
      "3:\tlearn: 0.5209480\ttotal: 25.7ms\tremaining: 3.18s\n",
      "4:\tlearn: 0.4918718\ttotal: 31.7ms\tremaining: 3.14s\n",
      "5:\tlearn: 0.4551236\ttotal: 38ms\tremaining: 3.12s\n",
      "6:\tlearn: 0.4229776\ttotal: 44.1ms\tremaining: 3.1s\n",
      "7:\tlearn: 0.3982501\ttotal: 48.7ms\tremaining: 3s\n",
      "8:\tlearn: 0.3642198\ttotal: 53.5ms\tremaining: 2.92s\n",
      "9:\tlearn: 0.3410161\ttotal: 58.1ms\tremaining: 2.85s\n",
      "10:\tlearn: 0.3208189\ttotal: 62.5ms\tremaining: 2.78s\n",
      "11:\tlearn: 0.2957386\ttotal: 67.5ms\tremaining: 2.74s\n",
      "12:\tlearn: 0.2688665\ttotal: 72.2ms\tremaining: 2.71s\n",
      "13:\tlearn: 0.2477091\ttotal: 76.7ms\tremaining: 2.66s\n",
      "14:\tlearn: 0.2331287\ttotal: 81.2ms\tremaining: 2.63s\n",
      "15:\tlearn: 0.2220679\ttotal: 85.8ms\tremaining: 2.6s\n",
      "16:\tlearn: 0.2074493\ttotal: 89.9ms\tremaining: 2.55s\n",
      "17:\tlearn: 0.1905318\ttotal: 94.3ms\tremaining: 2.52s\n",
      "18:\tlearn: 0.1812335\ttotal: 98.1ms\tremaining: 2.48s\n",
      "19:\tlearn: 0.1696420\ttotal: 102ms\tremaining: 2.46s\n",
      "20:\tlearn: 0.1591093\ttotal: 107ms\tremaining: 2.44s\n",
      "21:\tlearn: 0.1505093\ttotal: 111ms\tremaining: 2.41s\n",
      "22:\tlearn: 0.1409894\ttotal: 115ms\tremaining: 2.38s\n",
      "23:\tlearn: 0.1321166\ttotal: 124ms\tremaining: 2.47s\n",
      "24:\tlearn: 0.1270168\ttotal: 134ms\tremaining: 2.55s\n",
      "25:\tlearn: 0.1199046\ttotal: 144ms\tremaining: 2.63s\n",
      "26:\tlearn: 0.1116394\ttotal: 153ms\tremaining: 2.69s\n",
      "27:\tlearn: 0.1062360\ttotal: 163ms\tremaining: 2.75s\n",
      "28:\tlearn: 0.1012070\ttotal: 173ms\tremaining: 2.81s\n",
      "29:\tlearn: 0.0985034\ttotal: 183ms\tremaining: 2.86s\n",
      "30:\tlearn: 0.0929900\ttotal: 192ms\tremaining: 2.9s\n",
      "31:\tlearn: 0.0873086\ttotal: 199ms\tremaining: 2.91s\n",
      "32:\tlearn: 0.0834189\ttotal: 205ms\tremaining: 2.9s\n",
      "33:\tlearn: 0.0778257\ttotal: 211ms\tremaining: 2.9s\n",
      "34:\tlearn: 0.0743671\ttotal: 216ms\tremaining: 2.88s\n",
      "35:\tlearn: 0.0709581\ttotal: 222ms\tremaining: 2.85s\n",
      "36:\tlearn: 0.0663184\ttotal: 226ms\tremaining: 2.83s\n",
      "37:\tlearn: 0.0634407\ttotal: 231ms\tremaining: 2.8s\n",
      "38:\tlearn: 0.0596553\ttotal: 235ms\tremaining: 2.78s\n",
      "39:\tlearn: 0.0575762\ttotal: 240ms\tremaining: 2.76s\n",
      "40:\tlearn: 0.0534347\ttotal: 245ms\tremaining: 2.74s\n",
      "41:\tlearn: 0.0526381\ttotal: 249ms\tremaining: 2.71s\n",
      "42:\tlearn: 0.0485175\ttotal: 253ms\tremaining: 2.69s\n",
      "43:\tlearn: 0.0462417\ttotal: 257ms\tremaining: 2.67s\n",
      "44:\tlearn: 0.0450338\ttotal: 261ms\tremaining: 2.64s\n",
      "45:\tlearn: 0.0433614\ttotal: 265ms\tremaining: 2.62s\n",
      "46:\tlearn: 0.0419112\ttotal: 270ms\tremaining: 2.6s\n",
      "47:\tlearn: 0.0403535\ttotal: 274ms\tremaining: 2.58s\n",
      "48:\tlearn: 0.0390191\ttotal: 284ms\tremaining: 2.61s\n",
      "49:\tlearn: 0.0369277\ttotal: 294ms\tremaining: 2.64s\n",
      "50:\tlearn: 0.0360578\ttotal: 303ms\tremaining: 2.67s\n",
      "51:\tlearn: 0.0337575\ttotal: 313ms\tremaining: 2.7s\n",
      "52:\tlearn: 0.0322869\ttotal: 323ms\tremaining: 2.72s\n",
      "53:\tlearn: 0.0304951\ttotal: 333ms\tremaining: 2.75s\n",
      "54:\tlearn: 0.0300723\ttotal: 342ms\tremaining: 2.77s\n",
      "55:\tlearn: 0.0291743\ttotal: 352ms\tremaining: 2.79s\n",
      "56:\tlearn: 0.0285044\ttotal: 359ms\tremaining: 2.79s\n",
      "57:\tlearn: 0.0270531\ttotal: 366ms\tremaining: 2.79s\n",
      "58:\tlearn: 0.0255644\ttotal: 374ms\tremaining: 2.79s\n",
      "59:\tlearn: 0.0249485\ttotal: 380ms\tremaining: 2.79s\n",
      "60:\tlearn: 0.0241924\ttotal: 386ms\tremaining: 2.77s\n",
      "61:\tlearn: 0.0236094\ttotal: 390ms\tremaining: 2.76s\n",
      "62:\tlearn: 0.0224406\ttotal: 395ms\tremaining: 2.74s\n",
      "63:\tlearn: 0.0218267\ttotal: 399ms\tremaining: 2.72s\n",
      "64:\tlearn: 0.0208972\ttotal: 404ms\tremaining: 2.7s\n",
      "65:\tlearn: 0.0201918\ttotal: 408ms\tremaining: 2.68s\n",
      "66:\tlearn: 0.0193090\ttotal: 412ms\tremaining: 2.66s\n",
      "67:\tlearn: 0.0189419\ttotal: 416ms\tremaining: 2.64s\n",
      "68:\tlearn: 0.0182113\ttotal: 420ms\tremaining: 2.63s\n",
      "69:\tlearn: 0.0177060\ttotal: 425ms\tremaining: 2.61s\n",
      "70:\tlearn: 0.0171520\ttotal: 429ms\tremaining: 2.59s\n",
      "71:\tlearn: 0.0158401\ttotal: 433ms\tremaining: 2.58s\n",
      "72:\tlearn: 0.0154014\ttotal: 438ms\tremaining: 2.56s\n",
      "73:\tlearn: 0.0150415\ttotal: 442ms\tremaining: 2.54s\n",
      "74:\tlearn: 0.0145201\ttotal: 446ms\tremaining: 2.53s\n",
      "75:\tlearn: 0.0137681\ttotal: 456ms\tremaining: 2.54s\n",
      "76:\tlearn: 0.0134135\ttotal: 466ms\tremaining: 2.56s\n",
      "77:\tlearn: 0.0126715\ttotal: 476ms\tremaining: 2.58s\n",
      "78:\tlearn: 0.0120702\ttotal: 486ms\tremaining: 2.59s\n",
      "79:\tlearn: 0.0116978\ttotal: 496ms\tremaining: 2.6s\n",
      "80:\tlearn: 0.0114009\ttotal: 506ms\tremaining: 2.62s\n",
      "81:\tlearn: 0.0110564\ttotal: 515ms\tremaining: 2.63s\n",
      "82:\tlearn: 0.0106891\ttotal: 525ms\tremaining: 2.64s\n",
      "83:\tlearn: 0.0104084\ttotal: 532ms\tremaining: 2.63s\n",
      "84:\tlearn: 0.0098457\ttotal: 539ms\tremaining: 2.63s\n",
      "85:\tlearn: 0.0095833\ttotal: 547ms\tremaining: 2.63s\n",
      "86:\tlearn: 0.0095828\ttotal: 551ms\tremaining: 2.62s\n",
      "87:\tlearn: 0.0092313\ttotal: 556ms\tremaining: 2.6s\n",
      "88:\tlearn: 0.0090445\ttotal: 561ms\tremaining: 2.59s\n",
      "89:\tlearn: 0.0087263\ttotal: 565ms\tremaining: 2.57s\n",
      "90:\tlearn: 0.0084986\ttotal: 570ms\tremaining: 2.56s\n",
      "91:\tlearn: 0.0081649\ttotal: 575ms\tremaining: 2.55s\n",
      "92:\tlearn: 0.0079928\ttotal: 579ms\tremaining: 2.54s\n",
      "93:\tlearn: 0.0077915\ttotal: 584ms\tremaining: 2.52s\n",
      "94:\tlearn: 0.0075534\ttotal: 588ms\tremaining: 2.51s\n",
      "95:\tlearn: 0.0072728\ttotal: 593ms\tremaining: 2.49s\n",
      "96:\tlearn: 0.0070379\ttotal: 597ms\tremaining: 2.48s\n",
      "97:\tlearn: 0.0070377\ttotal: 601ms\tremaining: 2.46s\n",
      "98:\tlearn: 0.0067538\ttotal: 605ms\tremaining: 2.45s\n",
      "99:\tlearn: 0.0064444\ttotal: 615ms\tremaining: 2.46s\n",
      "100:\tlearn: 0.0063218\ttotal: 625ms\tremaining: 2.47s\n",
      "101:\tlearn: 0.0063217\ttotal: 634ms\tremaining: 2.47s\n",
      "102:\tlearn: 0.0062972\ttotal: 643ms\tremaining: 2.48s\n",
      "103:\tlearn: 0.0061644\ttotal: 653ms\tremaining: 2.49s\n",
      "104:\tlearn: 0.0061638\ttotal: 663ms\tremaining: 2.49s\n",
      "105:\tlearn: 0.0061638\ttotal: 672ms\tremaining: 2.5s\n",
      "106:\tlearn: 0.0059341\ttotal: 682ms\tremaining: 2.5s\n",
      "107:\tlearn: 0.0056859\ttotal: 692ms\tremaining: 2.51s\n",
      "108:\tlearn: 0.0055699\ttotal: 701ms\tremaining: 2.51s\n",
      "109:\tlearn: 0.0055697\ttotal: 709ms\tremaining: 2.51s\n",
      "110:\tlearn: 0.0055110\ttotal: 716ms\tremaining: 2.51s\n",
      "111:\tlearn: 0.0052187\ttotal: 723ms\tremaining: 2.5s\n",
      "112:\tlearn: 0.0050337\ttotal: 729ms\tremaining: 2.5s\n",
      "113:\tlearn: 0.0049506\ttotal: 734ms\tremaining: 2.48s\n",
      "114:\tlearn: 0.0046728\ttotal: 738ms\tremaining: 2.47s\n",
      "115:\tlearn: 0.0046728\ttotal: 743ms\tremaining: 2.46s\n",
      "116:\tlearn: 0.0046727\ttotal: 747ms\tremaining: 2.45s\n",
      "117:\tlearn: 0.0045229\ttotal: 751ms\tremaining: 2.43s\n",
      "118:\tlearn: 0.0045229\ttotal: 755ms\tremaining: 2.42s\n",
      "119:\tlearn: 0.0045228\ttotal: 759ms\tremaining: 2.4s\n",
      "120:\tlearn: 0.0043401\ttotal: 764ms\tremaining: 2.39s\n",
      "121:\tlearn: 0.0043401\ttotal: 767ms\tremaining: 2.38s\n",
      "122:\tlearn: 0.0043008\ttotal: 772ms\tremaining: 2.37s\n",
      "123:\tlearn: 0.0043008\ttotal: 776ms\tremaining: 2.35s\n",
      "124:\tlearn: 0.0043006\ttotal: 780ms\tremaining: 2.34s\n",
      "125:\tlearn: 0.0043002\ttotal: 784ms\tremaining: 2.33s\n",
      "126:\tlearn: 0.0040576\ttotal: 794ms\tremaining: 2.33s\n",
      "127:\tlearn: 0.0039565\ttotal: 804ms\tremaining: 2.33s\n",
      "128:\tlearn: 0.0036976\ttotal: 814ms\tremaining: 2.34s\n",
      "129:\tlearn: 0.0035385\ttotal: 823ms\tremaining: 2.34s\n",
      "130:\tlearn: 0.0035385\ttotal: 833ms\tremaining: 2.35s\n",
      "131:\tlearn: 0.0033324\ttotal: 842ms\tremaining: 2.35s\n",
      "132:\tlearn: 0.0032022\ttotal: 852ms\tremaining: 2.35s\n",
      "133:\tlearn: 0.0032014\ttotal: 860ms\tremaining: 2.35s\n",
      "134:\tlearn: 0.0032014\ttotal: 866ms\tremaining: 2.34s\n",
      "135:\tlearn: 0.0032014\ttotal: 874ms\tremaining: 2.34s\n",
      "136:\tlearn: 0.0032014\ttotal: 881ms\tremaining: 2.33s\n",
      "137:\tlearn: 0.0032014\ttotal: 886ms\tremaining: 2.32s\n",
      "138:\tlearn: 0.0032014\ttotal: 891ms\tremaining: 2.31s\n",
      "139:\tlearn: 0.0032014\ttotal: 895ms\tremaining: 2.3s\n",
      "140:\tlearn: 0.0032014\ttotal: 899ms\tremaining: 2.29s\n",
      "141:\tlearn: 0.0032012\ttotal: 904ms\tremaining: 2.28s\n",
      "142:\tlearn: 0.0032004\ttotal: 909ms\tremaining: 2.27s\n",
      "143:\tlearn: 0.0031998\ttotal: 915ms\tremaining: 2.26s\n",
      "144:\tlearn: 0.0031997\ttotal: 919ms\tremaining: 2.25s\n",
      "145:\tlearn: 0.0031993\ttotal: 924ms\tremaining: 2.24s\n",
      "146:\tlearn: 0.0031992\ttotal: 928ms\tremaining: 2.23s\n",
      "147:\tlearn: 0.0031987\ttotal: 932ms\tremaining: 2.21s\n",
      "148:\tlearn: 0.0031986\ttotal: 936ms\tremaining: 2.2s\n",
      "149:\tlearn: 0.0031985\ttotal: 940ms\tremaining: 2.19s\n",
      "150:\tlearn: 0.0031985\ttotal: 944ms\tremaining: 2.18s\n",
      "151:\tlearn: 0.0031985\ttotal: 948ms\tremaining: 2.17s\n",
      "152:\tlearn: 0.0031985\ttotal: 957ms\tremaining: 2.17s\n",
      "153:\tlearn: 0.0031985\ttotal: 967ms\tremaining: 2.17s\n",
      "154:\tlearn: 0.0031985\ttotal: 976ms\tremaining: 2.17s\n",
      "155:\tlearn: 0.0031985\ttotal: 986ms\tremaining: 2.17s\n",
      "156:\tlearn: 0.0031985\ttotal: 995ms\tremaining: 2.17s\n",
      "157:\tlearn: 0.0031985\ttotal: 1s\tremaining: 2.17s\n",
      "158:\tlearn: 0.0031985\ttotal: 1.01s\tremaining: 2.17s\n",
      "159:\tlearn: 0.0031985\ttotal: 1.02s\tremaining: 2.17s\n",
      "160:\tlearn: 0.0031985\ttotal: 1.03s\tremaining: 2.17s\n",
      "161:\tlearn: 0.0031985\ttotal: 1.04s\tremaining: 2.17s\n",
      "162:\tlearn: 0.0031985\ttotal: 1.05s\tremaining: 2.17s\n",
      "163:\tlearn: 0.0031985\ttotal: 1.05s\tremaining: 2.16s\n",
      "164:\tlearn: 0.0031985\ttotal: 1.06s\tremaining: 2.16s\n",
      "165:\tlearn: 0.0031985\ttotal: 1.07s\tremaining: 2.15s\n",
      "166:\tlearn: 0.0031985\ttotal: 1.07s\tremaining: 2.14s\n",
      "167:\tlearn: 0.0031984\ttotal: 1.08s\tremaining: 2.13s\n",
      "168:\tlearn: 0.0031979\ttotal: 1.08s\tremaining: 2.12s\n",
      "169:\tlearn: 0.0031979\ttotal: 1.08s\tremaining: 2.11s\n",
      "170:\tlearn: 0.0031979\ttotal: 1.09s\tremaining: 2.1s\n",
      "171:\tlearn: 0.0031979\ttotal: 1.09s\tremaining: 2.08s\n",
      "172:\tlearn: 0.0031979\ttotal: 1.1s\tremaining: 2.07s\n",
      "173:\tlearn: 0.0031979\ttotal: 1.1s\tremaining: 2.06s\n",
      "174:\tlearn: 0.0031980\ttotal: 1.1s\tremaining: 2.05s\n",
      "175:\tlearn: 0.0031976\ttotal: 1.11s\tremaining: 2.04s\n",
      "176:\tlearn: 0.0031972\ttotal: 1.11s\tremaining: 2.03s\n",
      "177:\tlearn: 0.0031969\ttotal: 1.12s\tremaining: 2.02s\n",
      "178:\tlearn: 0.0031969\ttotal: 1.12s\tremaining: 2.01s\n",
      "179:\tlearn: 0.0031969\ttotal: 1.13s\tremaining: 2.01s\n",
      "180:\tlearn: 0.0031969\ttotal: 1.14s\tremaining: 2.01s\n",
      "181:\tlearn: 0.0031970\ttotal: 1.15s\tremaining: 2.01s\n",
      "182:\tlearn: 0.0031970\ttotal: 1.16s\tremaining: 2.01s\n",
      "183:\tlearn: 0.0031970\ttotal: 1.17s\tremaining: 2.01s\n",
      "184:\tlearn: 0.0031969\ttotal: 1.18s\tremaining: 2s\n",
      "185:\tlearn: 0.0031967\ttotal: 1.19s\tremaining: 2s\n",
      "186:\tlearn: 0.0031967\ttotal: 1.2s\tremaining: 2s\n",
      "187:\tlearn: 0.0031967\ttotal: 1.21s\tremaining: 2s\n",
      "188:\tlearn: 0.0031967\ttotal: 1.21s\tremaining: 2s\n",
      "189:\tlearn: 0.0031967\ttotal: 1.22s\tremaining: 1.99s\n",
      "190:\tlearn: 0.0031967\ttotal: 1.23s\tremaining: 1.98s\n",
      "191:\tlearn: 0.0031967\ttotal: 1.23s\tremaining: 1.98s\n",
      "192:\tlearn: 0.0031967\ttotal: 1.24s\tremaining: 1.97s\n",
      "193:\tlearn: 0.0031967\ttotal: 1.24s\tremaining: 1.96s\n",
      "194:\tlearn: 0.0031967\ttotal: 1.25s\tremaining: 1.95s\n",
      "195:\tlearn: 0.0031967\ttotal: 1.25s\tremaining: 1.94s\n",
      "196:\tlearn: 0.0031967\ttotal: 1.26s\tremaining: 1.94s\n",
      "197:\tlearn: 0.0031964\ttotal: 1.26s\tremaining: 1.93s\n",
      "198:\tlearn: 0.0031959\ttotal: 1.27s\tremaining: 1.92s\n",
      "199:\tlearn: 0.0031957\ttotal: 1.27s\tremaining: 1.91s\n",
      "200:\tlearn: 0.0031955\ttotal: 1.27s\tremaining: 1.9s\n",
      "201:\tlearn: 0.0031954\ttotal: 1.28s\tremaining: 1.89s\n",
      "202:\tlearn: 0.0031950\ttotal: 1.28s\tremaining: 1.88s\n",
      "203:\tlearn: 0.0031946\ttotal: 1.29s\tremaining: 1.87s\n",
      "204:\tlearn: 0.0031945\ttotal: 1.29s\tremaining: 1.86s\n",
      "205:\tlearn: 0.0031945\ttotal: 1.3s\tremaining: 1.85s\n",
      "206:\tlearn: 0.0031945\ttotal: 1.31s\tremaining: 1.85s\n",
      "207:\tlearn: 0.0031945\ttotal: 1.32s\tremaining: 1.85s\n",
      "208:\tlearn: 0.0031945\ttotal: 1.33s\tremaining: 1.85s\n",
      "209:\tlearn: 0.0031945\ttotal: 1.34s\tremaining: 1.85s\n",
      "210:\tlearn: 0.0031945\ttotal: 1.35s\tremaining: 1.84s\n",
      "211:\tlearn: 0.0031945\ttotal: 1.35s\tremaining: 1.84s\n",
      "212:\tlearn: 0.0031945\ttotal: 1.36s\tremaining: 1.84s\n",
      "213:\tlearn: 0.0031944\ttotal: 1.37s\tremaining: 1.84s\n",
      "214:\tlearn: 0.0031944\ttotal: 1.38s\tremaining: 1.83s\n",
      "215:\tlearn: 0.0031943\ttotal: 1.39s\tremaining: 1.83s\n",
      "216:\tlearn: 0.0031940\ttotal: 1.39s\tremaining: 1.82s\n",
      "217:\tlearn: 0.0031940\ttotal: 1.4s\tremaining: 1.81s\n",
      "218:\tlearn: 0.0031931\ttotal: 1.4s\tremaining: 1.8s\n",
      "219:\tlearn: 0.0031931\ttotal: 1.41s\tremaining: 1.79s\n",
      "220:\tlearn: 0.0031930\ttotal: 1.41s\tremaining: 1.78s\n",
      "221:\tlearn: 0.0031930\ttotal: 1.42s\tremaining: 1.78s\n",
      "222:\tlearn: 0.0031930\ttotal: 1.42s\tremaining: 1.76s\n",
      "223:\tlearn: 0.0031930\ttotal: 1.43s\tremaining: 1.76s\n",
      "224:\tlearn: 0.0031928\ttotal: 1.43s\tremaining: 1.75s\n",
      "225:\tlearn: 0.0031926\ttotal: 1.44s\tremaining: 1.75s\n",
      "226:\tlearn: 0.0031925\ttotal: 1.45s\tremaining: 1.74s\n",
      "227:\tlearn: 0.0031917\ttotal: 1.46s\tremaining: 1.74s\n",
      "228:\tlearn: 0.0031915\ttotal: 1.47s\tremaining: 1.74s\n",
      "229:\tlearn: 0.0031912\ttotal: 1.48s\tremaining: 1.73s\n",
      "230:\tlearn: 0.0031909\ttotal: 1.49s\tremaining: 1.73s\n",
      "231:\tlearn: 0.0031905\ttotal: 1.5s\tremaining: 1.73s\n",
      "232:\tlearn: 0.0031904\ttotal: 1.51s\tremaining: 1.73s\n",
      "233:\tlearn: 0.0031904\ttotal: 1.52s\tremaining: 1.73s\n",
      "234:\tlearn: 0.0031899\ttotal: 1.52s\tremaining: 1.72s\n",
      "235:\tlearn: 0.0031895\ttotal: 1.53s\tremaining: 1.72s\n",
      "236:\tlearn: 0.0031895\ttotal: 1.54s\tremaining: 1.71s\n",
      "237:\tlearn: 0.0031894\ttotal: 1.54s\tremaining: 1.7s\n",
      "238:\tlearn: 0.0031894\ttotal: 1.55s\tremaining: 1.69s\n",
      "239:\tlearn: 0.0031894\ttotal: 1.55s\tremaining: 1.68s\n",
      "240:\tlearn: 0.0031892\ttotal: 1.56s\tremaining: 1.68s\n",
      "241:\tlearn: 0.0031892\ttotal: 1.56s\tremaining: 1.67s\n",
      "242:\tlearn: 0.0031892\ttotal: 1.57s\tremaining: 1.66s\n",
      "243:\tlearn: 0.0031884\ttotal: 1.57s\tremaining: 1.65s\n",
      "244:\tlearn: 0.0031884\ttotal: 1.58s\tremaining: 1.64s\n",
      "245:\tlearn: 0.0031884\ttotal: 1.58s\tremaining: 1.63s\n",
      "246:\tlearn: 0.0031883\ttotal: 1.58s\tremaining: 1.62s\n",
      "247:\tlearn: 0.0031881\ttotal: 1.59s\tremaining: 1.61s\n",
      "248:\tlearn: 0.0031881\ttotal: 1.59s\tremaining: 1.6s\n",
      "249:\tlearn: 0.0031882\ttotal: 1.59s\tremaining: 1.59s\n",
      "250:\tlearn: 0.0031877\ttotal: 1.6s\tremaining: 1.59s\n",
      "251:\tlearn: 0.0031873\ttotal: 1.6s\tremaining: 1.58s\n",
      "252:\tlearn: 0.0031866\ttotal: 1.61s\tremaining: 1.57s\n",
      "253:\tlearn: 0.0031862\ttotal: 1.62s\tremaining: 1.57s\n",
      "254:\tlearn: 0.0031860\ttotal: 1.63s\tremaining: 1.57s\n",
      "255:\tlearn: 0.0030299\ttotal: 1.64s\tremaining: 1.56s\n",
      "256:\tlearn: 0.0028552\ttotal: 1.65s\tremaining: 1.56s\n",
      "257:\tlearn: 0.0027237\ttotal: 1.66s\tremaining: 1.56s\n",
      "258:\tlearn: 0.0027236\ttotal: 1.67s\tremaining: 1.55s\n",
      "259:\tlearn: 0.0025605\ttotal: 1.68s\tremaining: 1.55s\n",
      "260:\tlearn: 0.0025604\ttotal: 1.69s\tremaining: 1.55s\n",
      "261:\tlearn: 0.0025603\ttotal: 1.7s\tremaining: 1.54s\n",
      "262:\tlearn: 0.0025599\ttotal: 1.7s\tremaining: 1.53s\n",
      "263:\tlearn: 0.0025597\ttotal: 1.71s\tremaining: 1.53s\n",
      "264:\tlearn: 0.0025595\ttotal: 1.71s\tremaining: 1.52s\n",
      "265:\tlearn: 0.0025578\ttotal: 1.72s\tremaining: 1.51s\n",
      "266:\tlearn: 0.0025576\ttotal: 1.72s\tremaining: 1.5s\n",
      "267:\tlearn: 0.0025575\ttotal: 1.73s\tremaining: 1.5s\n",
      "268:\tlearn: 0.0025570\ttotal: 1.73s\tremaining: 1.49s\n",
      "269:\tlearn: 0.0025570\ttotal: 1.74s\tremaining: 1.48s\n",
      "270:\tlearn: 0.0025570\ttotal: 1.74s\tremaining: 1.47s\n",
      "271:\tlearn: 0.0025568\ttotal: 1.75s\tremaining: 1.46s\n",
      "272:\tlearn: 0.0025568\ttotal: 1.75s\tremaining: 1.46s\n",
      "273:\tlearn: 0.0025567\ttotal: 1.76s\tremaining: 1.45s\n",
      "274:\tlearn: 0.0025565\ttotal: 1.76s\tremaining: 1.44s\n",
      "275:\tlearn: 0.0025566\ttotal: 1.76s\tremaining: 1.43s\n",
      "276:\tlearn: 0.0025564\ttotal: 1.77s\tremaining: 1.42s\n",
      "277:\tlearn: 0.0025562\ttotal: 1.77s\tremaining: 1.42s\n",
      "278:\tlearn: 0.0025557\ttotal: 1.78s\tremaining: 1.41s\n",
      "279:\tlearn: 0.0025555\ttotal: 1.79s\tremaining: 1.41s\n",
      "280:\tlearn: 0.0025555\ttotal: 1.8s\tremaining: 1.4s\n",
      "281:\tlearn: 0.0025552\ttotal: 1.81s\tremaining: 1.4s\n",
      "282:\tlearn: 0.0025552\ttotal: 1.82s\tremaining: 1.4s\n",
      "283:\tlearn: 0.0025551\ttotal: 1.83s\tremaining: 1.39s\n",
      "284:\tlearn: 0.0025546\ttotal: 1.84s\tremaining: 1.39s\n",
      "285:\tlearn: 0.0025522\ttotal: 1.85s\tremaining: 1.38s\n",
      "286:\tlearn: 0.0025522\ttotal: 1.86s\tremaining: 1.38s\n",
      "287:\tlearn: 0.0025520\ttotal: 1.86s\tremaining: 1.37s\n",
      "288:\tlearn: 0.0025520\ttotal: 1.87s\tremaining: 1.37s\n",
      "289:\tlearn: 0.0025491\ttotal: 1.88s\tremaining: 1.36s\n",
      "290:\tlearn: 0.0025491\ttotal: 1.88s\tremaining: 1.35s\n",
      "291:\tlearn: 0.0025490\ttotal: 1.89s\tremaining: 1.34s\n",
      "292:\tlearn: 0.0025490\ttotal: 1.89s\tremaining: 1.34s\n",
      "293:\tlearn: 0.0025476\ttotal: 1.9s\tremaining: 1.33s\n",
      "294:\tlearn: 0.0025475\ttotal: 1.9s\tremaining: 1.32s\n",
      "295:\tlearn: 0.0025474\ttotal: 1.91s\tremaining: 1.31s\n",
      "296:\tlearn: 0.0025473\ttotal: 1.91s\tremaining: 1.31s\n",
      "297:\tlearn: 0.0025466\ttotal: 1.92s\tremaining: 1.3s\n",
      "298:\tlearn: 0.0025465\ttotal: 1.92s\tremaining: 1.29s\n",
      "299:\tlearn: 0.0025460\ttotal: 1.93s\tremaining: 1.28s\n",
      "300:\tlearn: 0.0025460\ttotal: 1.93s\tremaining: 1.28s\n",
      "301:\tlearn: 0.0025458\ttotal: 1.94s\tremaining: 1.27s\n",
      "302:\tlearn: 0.0025458\ttotal: 1.94s\tremaining: 1.26s\n",
      "303:\tlearn: 0.0025457\ttotal: 1.94s\tremaining: 1.25s\n",
      "304:\tlearn: 0.0025058\ttotal: 1.95s\tremaining: 1.25s\n",
      "305:\tlearn: 0.0025057\ttotal: 1.96s\tremaining: 1.24s\n",
      "306:\tlearn: 0.0025057\ttotal: 1.97s\tremaining: 1.24s\n",
      "307:\tlearn: 0.0025057\ttotal: 1.98s\tremaining: 1.23s\n",
      "308:\tlearn: 0.0025055\ttotal: 1.99s\tremaining: 1.23s\n",
      "309:\tlearn: 0.0025055\ttotal: 1.99s\tremaining: 1.22s\n",
      "310:\tlearn: 0.0025054\ttotal: 2s\tremaining: 1.22s\n",
      "311:\tlearn: 0.0025056\ttotal: 2.01s\tremaining: 1.21s\n",
      "312:\tlearn: 0.0025052\ttotal: 2.02s\tremaining: 1.21s\n",
      "313:\tlearn: 0.0025052\ttotal: 2.03s\tremaining: 1.2s\n",
      "314:\tlearn: 0.0025052\ttotal: 2.04s\tremaining: 1.2s\n",
      "315:\tlearn: 0.0025051\ttotal: 2.04s\tremaining: 1.19s\n",
      "316:\tlearn: 0.0025048\ttotal: 2.05s\tremaining: 1.18s\n",
      "317:\tlearn: 0.0025049\ttotal: 2.05s\tremaining: 1.18s\n",
      "318:\tlearn: 0.0025049\ttotal: 2.06s\tremaining: 1.17s\n",
      "319:\tlearn: 0.0025048\ttotal: 2.06s\tremaining: 1.16s\n",
      "320:\tlearn: 0.0025048\ttotal: 2.07s\tremaining: 1.16s\n",
      "321:\tlearn: 0.0025044\ttotal: 2.08s\tremaining: 1.15s\n",
      "322:\tlearn: 0.0025044\ttotal: 2.08s\tremaining: 1.14s\n",
      "323:\tlearn: 0.0025044\ttotal: 2.09s\tremaining: 1.13s\n",
      "324:\tlearn: 0.0025043\ttotal: 2.09s\tremaining: 1.13s\n",
      "325:\tlearn: 0.0025041\ttotal: 2.1s\tremaining: 1.12s\n",
      "326:\tlearn: 0.0025041\ttotal: 2.1s\tremaining: 1.11s\n",
      "327:\tlearn: 0.0025041\ttotal: 2.11s\tremaining: 1.1s\n",
      "328:\tlearn: 0.0025040\ttotal: 2.11s\tremaining: 1.1s\n",
      "329:\tlearn: 0.0025037\ttotal: 2.12s\tremaining: 1.09s\n",
      "330:\tlearn: 0.0025037\ttotal: 2.12s\tremaining: 1.08s\n",
      "331:\tlearn: 0.0025037\ttotal: 2.13s\tremaining: 1.07s\n",
      "332:\tlearn: 0.0025037\ttotal: 2.13s\tremaining: 1.07s\n",
      "333:\tlearn: 0.0025036\ttotal: 2.13s\tremaining: 1.06s\n",
      "334:\tlearn: 0.0025035\ttotal: 2.14s\tremaining: 1.05s\n",
      "335:\tlearn: 0.0025035\ttotal: 2.14s\tremaining: 1.04s\n",
      "336:\tlearn: 0.0025035\ttotal: 2.14s\tremaining: 1.04s\n",
      "337:\tlearn: 0.0025033\ttotal: 2.15s\tremaining: 1.03s\n",
      "338:\tlearn: 0.0025033\ttotal: 2.15s\tremaining: 1.02s\n",
      "339:\tlearn: 0.0025033\ttotal: 2.16s\tremaining: 1.01s\n",
      "340:\tlearn: 0.0025032\ttotal: 2.16s\tremaining: 1.01s\n",
      "341:\tlearn: 0.0025032\ttotal: 2.16s\tremaining: 1000ms\n",
      "342:\tlearn: 0.0025033\ttotal: 2.17s\tremaining: 995ms\n",
      "343:\tlearn: 0.0025031\ttotal: 2.18s\tremaining: 990ms\n",
      "344:\tlearn: 0.0025029\ttotal: 2.19s\tremaining: 985ms\n",
      "345:\tlearn: 0.0025029\ttotal: 2.2s\tremaining: 980ms\n",
      "346:\tlearn: 0.0025029\ttotal: 2.21s\tremaining: 975ms\n",
      "347:\tlearn: 0.0025027\ttotal: 2.22s\tremaining: 970ms\n",
      "348:\tlearn: 0.0025026\ttotal: 2.23s\tremaining: 965ms\n",
      "349:\tlearn: 0.0025022\ttotal: 2.24s\tremaining: 960ms\n",
      "350:\tlearn: 0.0025018\ttotal: 2.25s\tremaining: 955ms\n",
      "351:\tlearn: 0.0025016\ttotal: 2.25s\tremaining: 948ms\n",
      "352:\tlearn: 0.0025015\ttotal: 2.26s\tremaining: 941ms\n",
      "353:\tlearn: 0.0025014\ttotal: 2.27s\tremaining: 935ms\n",
      "354:\tlearn: 0.0025011\ttotal: 2.27s\tremaining: 928ms\n",
      "355:\tlearn: 0.0025008\ttotal: 2.28s\tremaining: 922ms\n",
      "356:\tlearn: 0.0025008\ttotal: 2.28s\tremaining: 915ms\n",
      "357:\tlearn: 0.0025003\ttotal: 2.29s\tremaining: 908ms\n",
      "358:\tlearn: 0.0025004\ttotal: 2.29s\tremaining: 900ms\n",
      "359:\tlearn: 0.0025003\ttotal: 2.3s\tremaining: 893ms\n",
      "360:\tlearn: 0.0025002\ttotal: 2.3s\tremaining: 886ms\n",
      "361:\tlearn: 0.0024964\ttotal: 2.31s\tremaining: 879ms\n",
      "362:\tlearn: 0.0023885\ttotal: 2.31s\tremaining: 872ms\n",
      "363:\tlearn: 0.0023885\ttotal: 2.31s\tremaining: 865ms\n",
      "364:\tlearn: 0.0023885\ttotal: 2.32s\tremaining: 858ms\n",
      "365:\tlearn: 0.0023883\ttotal: 2.32s\tremaining: 851ms\n",
      "366:\tlearn: 0.0023882\ttotal: 2.33s\tremaining: 843ms\n",
      "367:\tlearn: 0.0023881\ttotal: 2.33s\tremaining: 836ms\n",
      "368:\tlearn: 0.0023880\ttotal: 2.33s\tremaining: 828ms\n",
      "369:\tlearn: 0.0023879\ttotal: 2.34s\tremaining: 821ms\n",
      "370:\tlearn: 0.0023879\ttotal: 2.35s\tremaining: 816ms\n",
      "371:\tlearn: 0.0023879\ttotal: 2.35s\tremaining: 811ms\n",
      "372:\tlearn: 0.0023879\ttotal: 2.36s\tremaining: 805ms\n",
      "373:\tlearn: 0.0023879\ttotal: 2.37s\tremaining: 800ms\n",
      "374:\tlearn: 0.0023875\ttotal: 2.38s\tremaining: 794ms\n",
      "375:\tlearn: 0.0023875\ttotal: 2.39s\tremaining: 789ms\n",
      "376:\tlearn: 0.0023871\ttotal: 2.4s\tremaining: 784ms\n",
      "377:\tlearn: 0.0023868\ttotal: 2.41s\tremaining: 778ms\n",
      "378:\tlearn: 0.0023867\ttotal: 2.42s\tremaining: 773ms\n",
      "379:\tlearn: 0.0023866\ttotal: 2.43s\tremaining: 767ms\n",
      "380:\tlearn: 0.0023864\ttotal: 2.43s\tremaining: 760ms\n",
      "381:\tlearn: 0.0023855\ttotal: 2.44s\tremaining: 754ms\n",
      "382:\tlearn: 0.0023854\ttotal: 2.45s\tremaining: 747ms\n",
      "383:\tlearn: 0.0023853\ttotal: 2.45s\tremaining: 741ms\n",
      "384:\tlearn: 0.0023851\ttotal: 2.46s\tremaining: 734ms\n",
      "385:\tlearn: 0.0023848\ttotal: 2.46s\tremaining: 727ms\n",
      "386:\tlearn: 0.0023845\ttotal: 2.47s\tremaining: 720ms\n",
      "387:\tlearn: 0.0023845\ttotal: 2.47s\tremaining: 713ms\n",
      "388:\tlearn: 0.0023846\ttotal: 2.48s\tremaining: 707ms\n",
      "389:\tlearn: 0.0023845\ttotal: 2.48s\tremaining: 699ms\n",
      "390:\tlearn: 0.0023844\ttotal: 2.48s\tremaining: 693ms\n",
      "391:\tlearn: 0.0023841\ttotal: 2.49s\tremaining: 685ms\n",
      "392:\tlearn: 0.0023840\ttotal: 2.49s\tremaining: 678ms\n",
      "393:\tlearn: 0.0023840\ttotal: 2.5s\tremaining: 671ms\n",
      "394:\tlearn: 0.0023840\ttotal: 2.5s\tremaining: 665ms\n",
      "395:\tlearn: 0.0023837\ttotal: 2.51s\tremaining: 660ms\n",
      "396:\tlearn: 0.0023837\ttotal: 2.52s\tremaining: 654ms\n",
      "397:\tlearn: 0.0023834\ttotal: 2.53s\tremaining: 649ms\n",
      "398:\tlearn: 0.0023834\ttotal: 2.54s\tremaining: 643ms\n",
      "399:\tlearn: 0.0023833\ttotal: 2.55s\tremaining: 638ms\n",
      "400:\tlearn: 0.0023830\ttotal: 2.56s\tremaining: 632ms\n",
      "401:\tlearn: 0.0023828\ttotal: 2.57s\tremaining: 626ms\n",
      "402:\tlearn: 0.0023823\ttotal: 2.58s\tremaining: 621ms\n",
      "403:\tlearn: 0.0023821\ttotal: 2.59s\tremaining: 615ms\n",
      "404:\tlearn: 0.0023819\ttotal: 2.6s\tremaining: 609ms\n",
      "405:\tlearn: 0.0023814\ttotal: 2.6s\tremaining: 603ms\n",
      "406:\tlearn: 0.0023812\ttotal: 2.61s\tremaining: 596ms\n",
      "407:\tlearn: 0.0023785\ttotal: 2.62s\tremaining: 590ms\n",
      "408:\tlearn: 0.0023783\ttotal: 2.62s\tremaining: 583ms\n",
      "409:\tlearn: 0.0023781\ttotal: 2.62s\tremaining: 576ms\n",
      "410:\tlearn: 0.0023781\ttotal: 2.63s\tremaining: 569ms\n",
      "411:\tlearn: 0.0023780\ttotal: 2.63s\tremaining: 562ms\n",
      "412:\tlearn: 0.0023780\ttotal: 2.64s\tremaining: 556ms\n",
      "413:\tlearn: 0.0023779\ttotal: 2.64s\tremaining: 549ms\n",
      "414:\tlearn: 0.0023780\ttotal: 2.65s\tremaining: 542ms\n",
      "415:\tlearn: 0.0023780\ttotal: 2.65s\tremaining: 535ms\n",
      "416:\tlearn: 0.0023777\ttotal: 2.65s\tremaining: 528ms\n",
      "417:\tlearn: 0.0023581\ttotal: 2.66s\tremaining: 521ms\n",
      "418:\tlearn: 0.0023581\ttotal: 2.66s\tremaining: 515ms\n",
      "419:\tlearn: 0.0023581\ttotal: 2.67s\tremaining: 508ms\n",
      "420:\tlearn: 0.0023580\ttotal: 2.67s\tremaining: 501ms\n",
      "421:\tlearn: 0.0023578\ttotal: 2.67s\tremaining: 494ms\n",
      "422:\tlearn: 0.0023568\ttotal: 2.68s\tremaining: 488ms\n",
      "423:\tlearn: 0.0023567\ttotal: 2.69s\tremaining: 483ms\n",
      "424:\tlearn: 0.0023565\ttotal: 2.7s\tremaining: 477ms\n",
      "425:\tlearn: 0.0023555\ttotal: 2.71s\tremaining: 471ms\n",
      "426:\tlearn: 0.0023553\ttotal: 2.72s\tremaining: 465ms\n",
      "427:\tlearn: 0.0023553\ttotal: 2.73s\tremaining: 459ms\n",
      "428:\tlearn: 0.0023553\ttotal: 2.74s\tremaining: 454ms\n",
      "429:\tlearn: 0.0023552\ttotal: 2.75s\tremaining: 448ms\n",
      "430:\tlearn: 0.0023549\ttotal: 2.76s\tremaining: 442ms\n",
      "431:\tlearn: 0.0023548\ttotal: 2.76s\tremaining: 435ms\n",
      "432:\tlearn: 0.0023548\ttotal: 2.77s\tremaining: 429ms\n",
      "433:\tlearn: 0.0023548\ttotal: 2.77s\tremaining: 422ms\n",
      "434:\tlearn: 0.0023548\ttotal: 2.78s\tremaining: 416ms\n",
      "435:\tlearn: 0.0023548\ttotal: 2.79s\tremaining: 409ms\n",
      "436:\tlearn: 0.0023548\ttotal: 2.79s\tremaining: 402ms\n",
      "437:\tlearn: 0.0023548\ttotal: 2.79s\tremaining: 396ms\n",
      "438:\tlearn: 0.0023546\ttotal: 2.8s\tremaining: 389ms\n",
      "439:\tlearn: 0.0023546\ttotal: 2.8s\tremaining: 382ms\n",
      "440:\tlearn: 0.0023544\ttotal: 2.81s\tremaining: 376ms\n",
      "441:\tlearn: 0.0023537\ttotal: 2.81s\tremaining: 369ms\n",
      "442:\tlearn: 0.0023537\ttotal: 2.82s\tremaining: 363ms\n",
      "443:\tlearn: 0.0023528\ttotal: 2.82s\tremaining: 356ms\n",
      "444:\tlearn: 0.0023525\ttotal: 2.83s\tremaining: 349ms\n",
      "445:\tlearn: 0.0023523\ttotal: 2.83s\tremaining: 343ms\n",
      "446:\tlearn: 0.0023523\ttotal: 2.83s\tremaining: 336ms\n",
      "447:\tlearn: 0.0023520\ttotal: 2.84s\tremaining: 329ms\n",
      "448:\tlearn: 0.0023519\ttotal: 2.84s\tremaining: 323ms\n",
      "449:\tlearn: 0.0023519\ttotal: 2.85s\tremaining: 317ms\n",
      "450:\tlearn: 0.0023519\ttotal: 2.86s\tremaining: 311ms\n",
      "451:\tlearn: 0.0023519\ttotal: 2.87s\tremaining: 305ms\n",
      "452:\tlearn: 0.0023519\ttotal: 2.88s\tremaining: 299ms\n",
      "453:\tlearn: 0.0023519\ttotal: 2.89s\tremaining: 293ms\n",
      "454:\tlearn: 0.0023519\ttotal: 2.9s\tremaining: 286ms\n",
      "455:\tlearn: 0.0023517\ttotal: 2.91s\tremaining: 280ms\n",
      "456:\tlearn: 0.0023511\ttotal: 2.92s\tremaining: 274ms\n",
      "457:\tlearn: 0.0023511\ttotal: 2.92s\tremaining: 268ms\n",
      "458:\tlearn: 0.0023510\ttotal: 2.93s\tremaining: 262ms\n",
      "459:\tlearn: 0.0023504\ttotal: 2.94s\tremaining: 255ms\n",
      "460:\tlearn: 0.0023504\ttotal: 2.94s\tremaining: 249ms\n",
      "461:\tlearn: 0.0023503\ttotal: 2.95s\tremaining: 242ms\n",
      "462:\tlearn: 0.0023498\ttotal: 2.95s\tremaining: 236ms\n",
      "463:\tlearn: 0.0023496\ttotal: 2.96s\tremaining: 230ms\n",
      "464:\tlearn: 0.0023494\ttotal: 2.96s\tremaining: 223ms\n",
      "465:\tlearn: 0.0023493\ttotal: 2.97s\tremaining: 217ms\n",
      "466:\tlearn: 0.0023493\ttotal: 2.97s\tremaining: 210ms\n",
      "467:\tlearn: 0.0023492\ttotal: 2.98s\tremaining: 204ms\n",
      "468:\tlearn: 0.0023491\ttotal: 2.98s\tremaining: 197ms\n",
      "469:\tlearn: 0.0023491\ttotal: 2.99s\tremaining: 191ms\n",
      "470:\tlearn: 0.0023491\ttotal: 2.99s\tremaining: 184ms\n",
      "471:\tlearn: 0.0023487\ttotal: 3s\tremaining: 178ms\n",
      "472:\tlearn: 0.0023487\ttotal: 3s\tremaining: 171ms\n",
      "473:\tlearn: 0.0023487\ttotal: 3s\tremaining: 165ms\n",
      "474:\tlearn: 0.0023487\ttotal: 3.01s\tremaining: 159ms\n",
      "475:\tlearn: 0.0023487\ttotal: 3.02s\tremaining: 152ms\n",
      "476:\tlearn: 0.0023487\ttotal: 3.03s\tremaining: 146ms\n",
      "477:\tlearn: 0.0023487\ttotal: 3.04s\tremaining: 140ms\n",
      "478:\tlearn: 0.0023487\ttotal: 3.05s\tremaining: 134ms\n",
      "479:\tlearn: 0.0023487\ttotal: 3.06s\tremaining: 127ms\n",
      "480:\tlearn: 0.0023487\ttotal: 3.07s\tremaining: 121ms\n",
      "481:\tlearn: 0.0023487\ttotal: 3.08s\tremaining: 115ms\n",
      "482:\tlearn: 0.0023487\ttotal: 3.09s\tremaining: 109ms\n",
      "483:\tlearn: 0.0023487\ttotal: 3.09s\tremaining: 102ms\n",
      "484:\tlearn: 0.0023486\ttotal: 3.1s\tremaining: 95.8ms\n",
      "485:\tlearn: 0.0023486\ttotal: 3.1s\tremaining: 89.3ms\n",
      "486:\tlearn: 0.0023482\ttotal: 3.1s\tremaining: 82.9ms\n",
      "487:\tlearn: 0.0023483\ttotal: 3.11s\tremaining: 76.5ms\n",
      "488:\tlearn: 0.0023482\ttotal: 3.11s\tremaining: 70.1ms\n",
      "489:\tlearn: 0.0023482\ttotal: 3.12s\tremaining: 63.6ms\n",
      "490:\tlearn: 0.0023480\ttotal: 3.12s\tremaining: 57.2ms\n",
      "491:\tlearn: 0.0023477\ttotal: 3.13s\tremaining: 50.8ms\n",
      "492:\tlearn: 0.0023477\ttotal: 3.13s\tremaining: 44.5ms\n",
      "493:\tlearn: 0.0023476\ttotal: 3.13s\tremaining: 38.1ms\n",
      "494:\tlearn: 0.0023476\ttotal: 3.14s\tremaining: 31.7ms\n",
      "495:\tlearn: 0.0023473\ttotal: 3.14s\tremaining: 25.4ms\n",
      "496:\tlearn: 0.0023473\ttotal: 3.15s\tremaining: 19ms\n",
      "497:\tlearn: 0.0023473\ttotal: 3.15s\tremaining: 12.7ms\n",
      "498:\tlearn: 0.0023473\ttotal: 3.15s\tremaining: 6.32ms\n",
      "499:\tlearn: 0.0023472\ttotal: 3.16s\tremaining: 0us\n",
      "0:\tlearn: 0.6432257\ttotal: 4.5ms\tremaining: 2.25s\n",
      "1:\tlearn: 0.6044600\ttotal: 8.97ms\tremaining: 2.23s\n",
      "2:\tlearn: 0.5598446\ttotal: 13.3ms\tremaining: 2.21s\n",
      "3:\tlearn: 0.5083340\ttotal: 17.7ms\tremaining: 2.2s\n",
      "4:\tlearn: 0.4700938\ttotal: 22.1ms\tremaining: 2.18s\n",
      "5:\tlearn: 0.4389394\ttotal: 26.3ms\tremaining: 2.17s\n",
      "6:\tlearn: 0.4051162\ttotal: 30.8ms\tremaining: 2.17s\n",
      "7:\tlearn: 0.3739828\ttotal: 35.3ms\tremaining: 2.17s\n",
      "8:\tlearn: 0.3450858\ttotal: 39.5ms\tremaining: 2.16s\n",
      "9:\tlearn: 0.3154728\ttotal: 43.7ms\tremaining: 2.14s\n",
      "10:\tlearn: 0.2902119\ttotal: 47.8ms\tremaining: 2.13s\n",
      "11:\tlearn: 0.2687492\ttotal: 52.3ms\tremaining: 2.13s\n",
      "12:\tlearn: 0.2542746\ttotal: 62ms\tremaining: 2.32s\n",
      "13:\tlearn: 0.2382027\ttotal: 71.7ms\tremaining: 2.49s\n",
      "14:\tlearn: 0.2236681\ttotal: 81.2ms\tremaining: 2.63s\n",
      "15:\tlearn: 0.2099765\ttotal: 90.8ms\tremaining: 2.75s\n",
      "16:\tlearn: 0.1990774\ttotal: 101ms\tremaining: 2.86s\n",
      "17:\tlearn: 0.1869512\ttotal: 111ms\tremaining: 2.96s\n",
      "18:\tlearn: 0.1776075\ttotal: 120ms\tremaining: 3.04s\n",
      "19:\tlearn: 0.1650023\ttotal: 130ms\tremaining: 3.11s\n",
      "20:\tlearn: 0.1497603\ttotal: 135ms\tremaining: 3.07s\n",
      "21:\tlearn: 0.1413182\ttotal: 141ms\tremaining: 3.05s\n",
      "22:\tlearn: 0.1350832\ttotal: 146ms\tremaining: 3.02s\n",
      "23:\tlearn: 0.1304190\ttotal: 151ms\tremaining: 2.99s\n",
      "24:\tlearn: 0.1217164\ttotal: 155ms\tremaining: 2.95s\n",
      "25:\tlearn: 0.1162250\ttotal: 160ms\tremaining: 2.92s\n",
      "26:\tlearn: 0.1113935\ttotal: 164ms\tremaining: 2.88s\n",
      "27:\tlearn: 0.1076867\ttotal: 169ms\tremaining: 2.84s\n",
      "28:\tlearn: 0.1015410\ttotal: 173ms\tremaining: 2.81s\n",
      "29:\tlearn: 0.0958263\ttotal: 177ms\tremaining: 2.78s\n",
      "30:\tlearn: 0.0893261\ttotal: 182ms\tremaining: 2.75s\n",
      "31:\tlearn: 0.0843558\ttotal: 186ms\tremaining: 2.72s\n",
      "32:\tlearn: 0.0794904\ttotal: 191ms\tremaining: 2.7s\n",
      "33:\tlearn: 0.0762331\ttotal: 196ms\tremaining: 2.68s\n",
      "34:\tlearn: 0.0724169\ttotal: 199ms\tremaining: 2.64s\n",
      "35:\tlearn: 0.0676270\ttotal: 202ms\tremaining: 2.6s\n",
      "36:\tlearn: 0.0643064\ttotal: 205ms\tremaining: 2.56s\n",
      "37:\tlearn: 0.0625816\ttotal: 208ms\tremaining: 2.53s\n",
      "38:\tlearn: 0.0590428\ttotal: 213ms\tremaining: 2.52s\n",
      "39:\tlearn: 0.0573147\ttotal: 223ms\tremaining: 2.56s\n",
      "40:\tlearn: 0.0554885\ttotal: 232ms\tremaining: 2.6s\n",
      "41:\tlearn: 0.0530211\ttotal: 242ms\tremaining: 2.64s\n",
      "42:\tlearn: 0.0501707\ttotal: 252ms\tremaining: 2.67s\n",
      "43:\tlearn: 0.0482882\ttotal: 261ms\tremaining: 2.71s\n",
      "44:\tlearn: 0.0472461\ttotal: 271ms\tremaining: 2.74s\n",
      "45:\tlearn: 0.0453097\ttotal: 280ms\tremaining: 2.77s\n",
      "46:\tlearn: 0.0433618\ttotal: 290ms\tremaining: 2.79s\n",
      "47:\tlearn: 0.0420110\ttotal: 300ms\tremaining: 2.82s\n",
      "48:\tlearn: 0.0402345\ttotal: 305ms\tremaining: 2.81s\n",
      "49:\tlearn: 0.0379023\ttotal: 310ms\tremaining: 2.79s\n",
      "50:\tlearn: 0.0374113\ttotal: 314ms\tremaining: 2.77s\n",
      "51:\tlearn: 0.0353009\ttotal: 319ms\tremaining: 2.75s\n",
      "52:\tlearn: 0.0336322\ttotal: 324ms\tremaining: 2.73s\n",
      "53:\tlearn: 0.0325826\ttotal: 329ms\tremaining: 2.71s\n",
      "54:\tlearn: 0.0305343\ttotal: 333ms\tremaining: 2.69s\n",
      "55:\tlearn: 0.0282811\ttotal: 337ms\tremaining: 2.67s\n",
      "56:\tlearn: 0.0270785\ttotal: 341ms\tremaining: 2.65s\n",
      "57:\tlearn: 0.0259485\ttotal: 346ms\tremaining: 2.63s\n",
      "58:\tlearn: 0.0253210\ttotal: 350ms\tremaining: 2.62s\n",
      "59:\tlearn: 0.0238635\ttotal: 355ms\tremaining: 2.6s\n",
      "60:\tlearn: 0.0226870\ttotal: 359ms\tremaining: 2.58s\n",
      "61:\tlearn: 0.0214888\ttotal: 363ms\tremaining: 2.56s\n",
      "62:\tlearn: 0.0202632\ttotal: 372ms\tremaining: 2.58s\n",
      "63:\tlearn: 0.0196094\ttotal: 382ms\tremaining: 2.6s\n",
      "64:\tlearn: 0.0190307\ttotal: 392ms\tremaining: 2.62s\n",
      "65:\tlearn: 0.0181379\ttotal: 402ms\tremaining: 2.64s\n",
      "66:\tlearn: 0.0175176\ttotal: 411ms\tremaining: 2.66s\n",
      "67:\tlearn: 0.0166758\ttotal: 421ms\tremaining: 2.68s\n",
      "68:\tlearn: 0.0160524\ttotal: 431ms\tremaining: 2.69s\n",
      "69:\tlearn: 0.0154707\ttotal: 439ms\tremaining: 2.7s\n",
      "70:\tlearn: 0.0148092\ttotal: 446ms\tremaining: 2.69s\n",
      "71:\tlearn: 0.0143223\ttotal: 452ms\tremaining: 2.69s\n",
      "72:\tlearn: 0.0137689\ttotal: 458ms\tremaining: 2.68s\n",
      "73:\tlearn: 0.0132595\ttotal: 465ms\tremaining: 2.67s\n",
      "74:\tlearn: 0.0129332\ttotal: 471ms\tremaining: 2.67s\n",
      "75:\tlearn: 0.0127368\ttotal: 476ms\tremaining: 2.65s\n",
      "76:\tlearn: 0.0123701\ttotal: 480ms\tremaining: 2.64s\n",
      "77:\tlearn: 0.0116805\ttotal: 485ms\tremaining: 2.63s\n",
      "78:\tlearn: 0.0110213\ttotal: 490ms\tremaining: 2.61s\n",
      "79:\tlearn: 0.0105596\ttotal: 495ms\tremaining: 2.6s\n",
      "80:\tlearn: 0.0103517\ttotal: 500ms\tremaining: 2.58s\n",
      "81:\tlearn: 0.0098865\ttotal: 505ms\tremaining: 2.57s\n",
      "82:\tlearn: 0.0092076\ttotal: 509ms\tremaining: 2.56s\n",
      "83:\tlearn: 0.0089771\ttotal: 513ms\tremaining: 2.54s\n",
      "84:\tlearn: 0.0084890\ttotal: 517ms\tremaining: 2.52s\n",
      "85:\tlearn: 0.0080328\ttotal: 522ms\tremaining: 2.51s\n",
      "86:\tlearn: 0.0075270\ttotal: 526ms\tremaining: 2.5s\n",
      "87:\tlearn: 0.0072170\ttotal: 530ms\tremaining: 2.48s\n",
      "88:\tlearn: 0.0070234\ttotal: 535ms\tremaining: 2.47s\n",
      "89:\tlearn: 0.0067602\ttotal: 545ms\tremaining: 2.48s\n",
      "90:\tlearn: 0.0066125\ttotal: 554ms\tremaining: 2.49s\n",
      "91:\tlearn: 0.0063070\ttotal: 564ms\tremaining: 2.5s\n",
      "92:\tlearn: 0.0059579\ttotal: 573ms\tremaining: 2.51s\n",
      "93:\tlearn: 0.0056647\ttotal: 583ms\tremaining: 2.52s\n",
      "94:\tlearn: 0.0054111\ttotal: 593ms\tremaining: 2.53s\n",
      "95:\tlearn: 0.0054101\ttotal: 598ms\tremaining: 2.52s\n",
      "96:\tlearn: 0.0052552\ttotal: 603ms\tremaining: 2.5s\n",
      "97:\tlearn: 0.0051347\ttotal: 608ms\tremaining: 2.49s\n",
      "98:\tlearn: 0.0048784\ttotal: 612ms\tremaining: 2.48s\n",
      "99:\tlearn: 0.0047753\ttotal: 617ms\tremaining: 2.47s\n",
      "100:\tlearn: 0.0046544\ttotal: 622ms\tremaining: 2.46s\n",
      "101:\tlearn: 0.0044744\ttotal: 627ms\tremaining: 2.44s\n",
      "102:\tlearn: 0.0043596\ttotal: 631ms\tremaining: 2.43s\n",
      "103:\tlearn: 0.0043596\ttotal: 636ms\tremaining: 2.42s\n",
      "104:\tlearn: 0.0043596\ttotal: 640ms\tremaining: 2.41s\n",
      "105:\tlearn: 0.0041013\ttotal: 645ms\tremaining: 2.4s\n",
      "106:\tlearn: 0.0041012\ttotal: 649ms\tremaining: 2.38s\n",
      "107:\tlearn: 0.0039230\ttotal: 653ms\tremaining: 2.37s\n",
      "108:\tlearn: 0.0038363\ttotal: 663ms\tremaining: 2.38s\n",
      "109:\tlearn: 0.0038360\ttotal: 673ms\tremaining: 2.38s\n",
      "110:\tlearn: 0.0038352\ttotal: 682ms\tremaining: 2.39s\n",
      "111:\tlearn: 0.0038349\ttotal: 692ms\tremaining: 2.4s\n",
      "112:\tlearn: 0.0037790\ttotal: 702ms\tremaining: 2.4s\n",
      "113:\tlearn: 0.0037784\ttotal: 711ms\tremaining: 2.4s\n",
      "114:\tlearn: 0.0036643\ttotal: 721ms\tremaining: 2.41s\n",
      "115:\tlearn: 0.0036642\ttotal: 730ms\tremaining: 2.42s\n",
      "116:\tlearn: 0.0036642\ttotal: 738ms\tremaining: 2.42s\n",
      "117:\tlearn: 0.0036642\ttotal: 742ms\tremaining: 2.4s\n",
      "118:\tlearn: 0.0035242\ttotal: 747ms\tremaining: 2.39s\n",
      "119:\tlearn: 0.0034011\ttotal: 752ms\tremaining: 2.38s\n",
      "120:\tlearn: 0.0032423\ttotal: 757ms\tremaining: 2.37s\n",
      "121:\tlearn: 0.0032423\ttotal: 762ms\tremaining: 2.36s\n",
      "122:\tlearn: 0.0031602\ttotal: 766ms\tremaining: 2.35s\n",
      "123:\tlearn: 0.0031593\ttotal: 770ms\tremaining: 2.33s\n",
      "124:\tlearn: 0.0031590\ttotal: 774ms\tremaining: 2.32s\n",
      "125:\tlearn: 0.0031590\ttotal: 778ms\tremaining: 2.31s\n",
      "126:\tlearn: 0.0031588\ttotal: 782ms\tremaining: 2.3s\n",
      "127:\tlearn: 0.0031588\ttotal: 786ms\tremaining: 2.29s\n",
      "128:\tlearn: 0.0031588\ttotal: 790ms\tremaining: 2.27s\n",
      "129:\tlearn: 0.0031588\ttotal: 794ms\tremaining: 2.26s\n",
      "130:\tlearn: 0.0031587\ttotal: 798ms\tremaining: 2.25s\n",
      "131:\tlearn: 0.0031586\ttotal: 807ms\tremaining: 2.25s\n",
      "132:\tlearn: 0.0031587\ttotal: 817ms\tremaining: 2.25s\n",
      "133:\tlearn: 0.0031585\ttotal: 826ms\tremaining: 2.26s\n",
      "134:\tlearn: 0.0031581\ttotal: 835ms\tremaining: 2.26s\n",
      "135:\tlearn: 0.0031581\ttotal: 845ms\tremaining: 2.26s\n",
      "136:\tlearn: 0.0031582\ttotal: 854ms\tremaining: 2.26s\n",
      "137:\tlearn: 0.0031582\ttotal: 864ms\tremaining: 2.27s\n",
      "138:\tlearn: 0.0031580\ttotal: 873ms\tremaining: 2.27s\n",
      "139:\tlearn: 0.0031578\ttotal: 882ms\tremaining: 2.27s\n",
      "140:\tlearn: 0.0031578\ttotal: 891ms\tremaining: 2.27s\n",
      "141:\tlearn: 0.0031578\ttotal: 897ms\tremaining: 2.26s\n",
      "142:\tlearn: 0.0030844\ttotal: 904ms\tremaining: 2.26s\n",
      "143:\tlearn: 0.0030841\ttotal: 909ms\tremaining: 2.25s\n",
      "144:\tlearn: 0.0030841\ttotal: 913ms\tremaining: 2.24s\n",
      "145:\tlearn: 0.0030839\ttotal: 918ms\tremaining: 2.22s\n",
      "146:\tlearn: 0.0030839\ttotal: 922ms\tremaining: 2.21s\n",
      "147:\tlearn: 0.0029730\ttotal: 927ms\tremaining: 2.2s\n",
      "148:\tlearn: 0.0029730\ttotal: 931ms\tremaining: 2.19s\n",
      "149:\tlearn: 0.0029726\ttotal: 935ms\tremaining: 2.18s\n",
      "150:\tlearn: 0.0029725\ttotal: 939ms\tremaining: 2.17s\n",
      "151:\tlearn: 0.0029723\ttotal: 943ms\tremaining: 2.16s\n",
      "152:\tlearn: 0.0029722\ttotal: 947ms\tremaining: 2.15s\n",
      "153:\tlearn: 0.0029722\ttotal: 951ms\tremaining: 2.14s\n",
      "154:\tlearn: 0.0029718\ttotal: 955ms\tremaining: 2.13s\n",
      "155:\tlearn: 0.0029718\ttotal: 959ms\tremaining: 2.12s\n",
      "156:\tlearn: 0.0029717\ttotal: 964ms\tremaining: 2.1s\n",
      "157:\tlearn: 0.0029124\ttotal: 967ms\tremaining: 2.09s\n",
      "158:\tlearn: 0.0029123\ttotal: 977ms\tremaining: 2.1s\n",
      "159:\tlearn: 0.0027730\ttotal: 987ms\tremaining: 2.1s\n",
      "160:\tlearn: 0.0027730\ttotal: 996ms\tremaining: 2.1s\n",
      "161:\tlearn: 0.0027729\ttotal: 1s\tremaining: 2.1s\n",
      "162:\tlearn: 0.0027730\ttotal: 1.01s\tremaining: 2.1s\n",
      "163:\tlearn: 0.0027729\ttotal: 1.02s\tremaining: 2.1s\n",
      "164:\tlearn: 0.0027723\ttotal: 1.03s\tremaining: 2.1s\n",
      "165:\tlearn: 0.0027721\ttotal: 1.04s\tremaining: 2.1s\n",
      "166:\tlearn: 0.0027720\ttotal: 1.05s\tremaining: 2.1s\n",
      "167:\tlearn: 0.0027720\ttotal: 1.06s\tremaining: 2.09s\n",
      "168:\tlearn: 0.0027720\ttotal: 1.07s\tremaining: 2.09s\n",
      "169:\tlearn: 0.0027719\ttotal: 1.07s\tremaining: 2.08s\n",
      "170:\tlearn: 0.0027716\ttotal: 1.08s\tremaining: 2.08s\n",
      "171:\tlearn: 0.0027716\ttotal: 1.08s\tremaining: 2.06s\n",
      "172:\tlearn: 0.0027714\ttotal: 1.09s\tremaining: 2.06s\n",
      "173:\tlearn: 0.0027713\ttotal: 1.09s\tremaining: 2.04s\n",
      "174:\tlearn: 0.0027709\ttotal: 1.1s\tremaining: 2.04s\n",
      "175:\tlearn: 0.0027708\ttotal: 1.1s\tremaining: 2.03s\n",
      "176:\tlearn: 0.0027708\ttotal: 1.1s\tremaining: 2.02s\n",
      "177:\tlearn: 0.0027705\ttotal: 1.11s\tremaining: 2.01s\n",
      "178:\tlearn: 0.0027705\ttotal: 1.11s\tremaining: 2s\n",
      "179:\tlearn: 0.0027705\ttotal: 1.12s\tremaining: 1.99s\n",
      "180:\tlearn: 0.0027704\ttotal: 1.12s\tremaining: 1.98s\n",
      "181:\tlearn: 0.0027701\ttotal: 1.13s\tremaining: 1.97s\n",
      "182:\tlearn: 0.0027698\ttotal: 1.13s\tremaining: 1.96s\n",
      "183:\tlearn: 0.0027694\ttotal: 1.13s\tremaining: 1.95s\n",
      "184:\tlearn: 0.0027693\ttotal: 1.14s\tremaining: 1.94s\n",
      "185:\tlearn: 0.0027693\ttotal: 1.14s\tremaining: 1.93s\n",
      "186:\tlearn: 0.0027693\ttotal: 1.15s\tremaining: 1.93s\n",
      "187:\tlearn: 0.0027693\ttotal: 1.16s\tremaining: 1.93s\n",
      "188:\tlearn: 0.0027693\ttotal: 1.17s\tremaining: 1.93s\n",
      "189:\tlearn: 0.0027693\ttotal: 1.18s\tremaining: 1.92s\n",
      "190:\tlearn: 0.0027693\ttotal: 1.19s\tremaining: 1.92s\n",
      "191:\tlearn: 0.0027693\ttotal: 1.2s\tremaining: 1.92s\n",
      "192:\tlearn: 0.0027693\ttotal: 1.21s\tremaining: 1.92s\n",
      "193:\tlearn: 0.0027693\ttotal: 1.22s\tremaining: 1.92s\n",
      "194:\tlearn: 0.0027692\ttotal: 1.23s\tremaining: 1.92s\n",
      "195:\tlearn: 0.0027692\ttotal: 1.23s\tremaining: 1.91s\n",
      "196:\tlearn: 0.0027689\ttotal: 1.24s\tremaining: 1.91s\n",
      "197:\tlearn: 0.0027690\ttotal: 1.25s\tremaining: 1.9s\n",
      "198:\tlearn: 0.0027689\ttotal: 1.25s\tremaining: 1.89s\n",
      "199:\tlearn: 0.0027689\ttotal: 1.25s\tremaining: 1.88s\n",
      "200:\tlearn: 0.0027686\ttotal: 1.26s\tremaining: 1.88s\n",
      "201:\tlearn: 0.0027686\ttotal: 1.26s\tremaining: 1.86s\n",
      "202:\tlearn: 0.0027685\ttotal: 1.27s\tremaining: 1.85s\n",
      "203:\tlearn: 0.0027685\ttotal: 1.27s\tremaining: 1.84s\n",
      "204:\tlearn: 0.0027685\ttotal: 1.27s\tremaining: 1.83s\n",
      "205:\tlearn: 0.0027678\ttotal: 1.28s\tremaining: 1.82s\n",
      "206:\tlearn: 0.0027677\ttotal: 1.28s\tremaining: 1.82s\n",
      "207:\tlearn: 0.0027676\ttotal: 1.29s\tremaining: 1.81s\n",
      "208:\tlearn: 0.0027675\ttotal: 1.29s\tremaining: 1.8s\n",
      "209:\tlearn: 0.0027673\ttotal: 1.29s\tremaining: 1.79s\n",
      "210:\tlearn: 0.0027672\ttotal: 1.3s\tremaining: 1.78s\n",
      "211:\tlearn: 0.0027672\ttotal: 1.3s\tremaining: 1.77s\n",
      "212:\tlearn: 0.0027671\ttotal: 1.31s\tremaining: 1.76s\n",
      "213:\tlearn: 0.0027671\ttotal: 1.31s\tremaining: 1.76s\n",
      "214:\tlearn: 0.0027668\ttotal: 1.32s\tremaining: 1.76s\n",
      "215:\tlearn: 0.0027659\ttotal: 1.33s\tremaining: 1.75s\n",
      "216:\tlearn: 0.0027656\ttotal: 1.34s\tremaining: 1.75s\n",
      "217:\tlearn: 0.0027655\ttotal: 1.35s\tremaining: 1.75s\n",
      "218:\tlearn: 0.0027651\ttotal: 1.36s\tremaining: 1.75s\n",
      "219:\tlearn: 0.0027651\ttotal: 1.37s\tremaining: 1.75s\n",
      "220:\tlearn: 0.0027647\ttotal: 1.38s\tremaining: 1.74s\n",
      "221:\tlearn: 0.0027612\ttotal: 1.39s\tremaining: 1.74s\n",
      "222:\tlearn: 0.0027611\ttotal: 1.4s\tremaining: 1.73s\n",
      "223:\tlearn: 0.0027605\ttotal: 1.4s\tremaining: 1.73s\n",
      "224:\tlearn: 0.0027604\ttotal: 1.41s\tremaining: 1.72s\n",
      "225:\tlearn: 0.0027605\ttotal: 1.41s\tremaining: 1.71s\n",
      "226:\tlearn: 0.0027604\ttotal: 1.42s\tremaining: 1.71s\n",
      "227:\tlearn: 0.0027603\ttotal: 1.43s\tremaining: 1.7s\n",
      "228:\tlearn: 0.0027601\ttotal: 1.43s\tremaining: 1.69s\n",
      "229:\tlearn: 0.0027601\ttotal: 1.44s\tremaining: 1.69s\n",
      "230:\tlearn: 0.0027601\ttotal: 1.44s\tremaining: 1.68s\n",
      "231:\tlearn: 0.0027600\ttotal: 1.45s\tremaining: 1.67s\n",
      "232:\tlearn: 0.0027600\ttotal: 1.45s\tremaining: 1.66s\n",
      "233:\tlearn: 0.0027600\ttotal: 1.46s\tremaining: 1.65s\n",
      "234:\tlearn: 0.0027599\ttotal: 1.46s\tremaining: 1.65s\n",
      "235:\tlearn: 0.0027598\ttotal: 1.46s\tremaining: 1.64s\n",
      "236:\tlearn: 0.0027598\ttotal: 1.47s\tremaining: 1.63s\n",
      "237:\tlearn: 0.0027594\ttotal: 1.47s\tremaining: 1.62s\n",
      "238:\tlearn: 0.0027593\ttotal: 1.48s\tremaining: 1.61s\n",
      "239:\tlearn: 0.0027593\ttotal: 1.48s\tremaining: 1.6s\n",
      "240:\tlearn: 0.0027592\ttotal: 1.48s\tremaining: 1.59s\n",
      "241:\tlearn: 0.0027593\ttotal: 1.49s\tremaining: 1.58s\n",
      "242:\tlearn: 0.0027592\ttotal: 1.49s\tremaining: 1.58s\n",
      "243:\tlearn: 0.0027591\ttotal: 1.5s\tremaining: 1.57s\n",
      "244:\tlearn: 0.0027591\ttotal: 1.5s\tremaining: 1.56s\n",
      "245:\tlearn: 0.0027591\ttotal: 1.5s\tremaining: 1.55s\n",
      "246:\tlearn: 0.0027591\ttotal: 1.51s\tremaining: 1.54s\n",
      "247:\tlearn: 0.0027590\ttotal: 1.51s\tremaining: 1.54s\n",
      "248:\tlearn: 0.0027589\ttotal: 1.52s\tremaining: 1.53s\n",
      "249:\tlearn: 0.0027588\ttotal: 1.53s\tremaining: 1.53s\n",
      "250:\tlearn: 0.0027586\ttotal: 1.54s\tremaining: 1.53s\n",
      "251:\tlearn: 0.0027586\ttotal: 1.55s\tremaining: 1.52s\n",
      "252:\tlearn: 0.0027586\ttotal: 1.56s\tremaining: 1.52s\n",
      "253:\tlearn: 0.0027585\ttotal: 1.57s\tremaining: 1.52s\n",
      "254:\tlearn: 0.0027584\ttotal: 1.58s\tremaining: 1.51s\n",
      "255:\tlearn: 0.0027584\ttotal: 1.58s\tremaining: 1.51s\n",
      "256:\tlearn: 0.0027584\ttotal: 1.59s\tremaining: 1.51s\n",
      "257:\tlearn: 0.0027585\ttotal: 1.6s\tremaining: 1.5s\n",
      "258:\tlearn: 0.0027584\ttotal: 1.61s\tremaining: 1.5s\n",
      "259:\tlearn: 0.0027584\ttotal: 1.62s\tremaining: 1.49s\n",
      "260:\tlearn: 0.0027584\ttotal: 1.62s\tremaining: 1.48s\n",
      "261:\tlearn: 0.0027582\ttotal: 1.63s\tremaining: 1.48s\n",
      "262:\tlearn: 0.0027581\ttotal: 1.63s\tremaining: 1.47s\n",
      "263:\tlearn: 0.0027581\ttotal: 1.63s\tremaining: 1.46s\n",
      "264:\tlearn: 0.0027580\ttotal: 1.64s\tremaining: 1.45s\n",
      "265:\tlearn: 0.0027579\ttotal: 1.64s\tremaining: 1.45s\n",
      "266:\tlearn: 0.0027579\ttotal: 1.65s\tremaining: 1.44s\n",
      "267:\tlearn: 0.0027578\ttotal: 1.65s\tremaining: 1.43s\n",
      "268:\tlearn: 0.0027578\ttotal: 1.66s\tremaining: 1.42s\n",
      "269:\tlearn: 0.0027578\ttotal: 1.66s\tremaining: 1.41s\n",
      "270:\tlearn: 0.0027577\ttotal: 1.66s\tremaining: 1.41s\n",
      "271:\tlearn: 0.0027576\ttotal: 1.67s\tremaining: 1.4s\n",
      "272:\tlearn: 0.0027573\ttotal: 1.67s\tremaining: 1.39s\n",
      "273:\tlearn: 0.0027573\ttotal: 1.68s\tremaining: 1.38s\n",
      "274:\tlearn: 0.0027572\ttotal: 1.68s\tremaining: 1.37s\n",
      "275:\tlearn: 0.0027572\ttotal: 1.69s\tremaining: 1.37s\n",
      "276:\tlearn: 0.0027571\ttotal: 1.7s\tremaining: 1.37s\n",
      "277:\tlearn: 0.0027570\ttotal: 1.71s\tremaining: 1.36s\n",
      "278:\tlearn: 0.0027568\ttotal: 1.72s\tremaining: 1.36s\n",
      "279:\tlearn: 0.0027567\ttotal: 1.73s\tremaining: 1.36s\n",
      "280:\tlearn: 0.0027567\ttotal: 1.74s\tremaining: 1.35s\n",
      "281:\tlearn: 0.0027567\ttotal: 1.75s\tremaining: 1.35s\n",
      "282:\tlearn: 0.0027566\ttotal: 1.75s\tremaining: 1.35s\n",
      "283:\tlearn: 0.0027565\ttotal: 1.76s\tremaining: 1.34s\n",
      "284:\tlearn: 0.0027564\ttotal: 1.77s\tremaining: 1.33s\n",
      "285:\tlearn: 0.0027563\ttotal: 1.77s\tremaining: 1.33s\n",
      "286:\tlearn: 0.0027561\ttotal: 1.78s\tremaining: 1.32s\n",
      "287:\tlearn: 0.0027559\ttotal: 1.78s\tremaining: 1.31s\n",
      "288:\tlearn: 0.0027559\ttotal: 1.79s\tremaining: 1.31s\n",
      "289:\tlearn: 0.0027558\ttotal: 1.8s\tremaining: 1.3s\n",
      "290:\tlearn: 0.0027558\ttotal: 1.8s\tremaining: 1.29s\n",
      "291:\tlearn: 0.0027556\ttotal: 1.8s\tremaining: 1.28s\n",
      "292:\tlearn: 0.0027556\ttotal: 1.81s\tremaining: 1.28s\n",
      "293:\tlearn: 0.0027556\ttotal: 1.81s\tremaining: 1.27s\n",
      "294:\tlearn: 0.0027556\ttotal: 1.82s\tremaining: 1.26s\n",
      "295:\tlearn: 0.0027554\ttotal: 1.82s\tremaining: 1.25s\n",
      "296:\tlearn: 0.0027553\ttotal: 1.83s\tremaining: 1.25s\n",
      "297:\tlearn: 0.0027550\ttotal: 1.83s\tremaining: 1.24s\n",
      "298:\tlearn: 0.0027549\ttotal: 1.83s\tremaining: 1.23s\n",
      "299:\tlearn: 0.0027549\ttotal: 1.84s\tremaining: 1.23s\n",
      "300:\tlearn: 0.0027548\ttotal: 1.84s\tremaining: 1.22s\n",
      "301:\tlearn: 0.0027547\ttotal: 1.85s\tremaining: 1.21s\n",
      "302:\tlearn: 0.0027547\ttotal: 1.86s\tremaining: 1.21s\n",
      "303:\tlearn: 0.0027548\ttotal: 1.87s\tremaining: 1.2s\n",
      "304:\tlearn: 0.0027544\ttotal: 1.88s\tremaining: 1.2s\n",
      "305:\tlearn: 0.0027544\ttotal: 1.88s\tremaining: 1.19s\n",
      "306:\tlearn: 0.0027544\ttotal: 1.89s\tremaining: 1.19s\n",
      "307:\tlearn: 0.0027543\ttotal: 1.9s\tremaining: 1.18s\n",
      "308:\tlearn: 0.0027542\ttotal: 1.91s\tremaining: 1.18s\n",
      "309:\tlearn: 0.0027541\ttotal: 1.91s\tremaining: 1.17s\n",
      "310:\tlearn: 0.0027540\ttotal: 1.92s\tremaining: 1.17s\n",
      "311:\tlearn: 0.0027540\ttotal: 1.92s\tremaining: 1.16s\n",
      "312:\tlearn: 0.0027539\ttotal: 1.93s\tremaining: 1.15s\n",
      "313:\tlearn: 0.0027539\ttotal: 1.93s\tremaining: 1.14s\n",
      "314:\tlearn: 0.0027539\ttotal: 1.94s\tremaining: 1.14s\n",
      "315:\tlearn: 0.0027539\ttotal: 1.94s\tremaining: 1.13s\n",
      "316:\tlearn: 0.0027538\ttotal: 1.95s\tremaining: 1.12s\n",
      "317:\tlearn: 0.0027538\ttotal: 1.95s\tremaining: 1.12s\n",
      "318:\tlearn: 0.0027538\ttotal: 1.96s\tremaining: 1.11s\n",
      "319:\tlearn: 0.0027538\ttotal: 1.96s\tremaining: 1.1s\n",
      "320:\tlearn: 0.0027538\ttotal: 1.96s\tremaining: 1.09s\n",
      "321:\tlearn: 0.0027538\ttotal: 1.97s\tremaining: 1.09s\n",
      "322:\tlearn: 0.0027538\ttotal: 1.97s\tremaining: 1.08s\n",
      "323:\tlearn: 0.0027537\ttotal: 1.97s\tremaining: 1.07s\n",
      "324:\tlearn: 0.0027537\ttotal: 1.98s\tremaining: 1.06s\n",
      "325:\tlearn: 0.0027531\ttotal: 1.98s\tremaining: 1.06s\n",
      "326:\tlearn: 0.0027530\ttotal: 1.99s\tremaining: 1.05s\n",
      "327:\tlearn: 0.0027530\ttotal: 2s\tremaining: 1.05s\n",
      "328:\tlearn: 0.0027529\ttotal: 2s\tremaining: 1.04s\n",
      "329:\tlearn: 0.0027530\ttotal: 2.01s\tremaining: 1.04s\n",
      "330:\tlearn: 0.0027530\ttotal: 2.02s\tremaining: 1.03s\n",
      "331:\tlearn: 0.0027530\ttotal: 2.03s\tremaining: 1.03s\n",
      "332:\tlearn: 0.0027530\ttotal: 2.04s\tremaining: 1.02s\n",
      "333:\tlearn: 0.0027529\ttotal: 2.05s\tremaining: 1.02s\n",
      "334:\tlearn: 0.0027523\ttotal: 2.06s\tremaining: 1.01s\n",
      "335:\tlearn: 0.0027522\ttotal: 2.07s\tremaining: 1.01s\n",
      "336:\tlearn: 0.0027516\ttotal: 2.08s\tremaining: 1s\n",
      "337:\tlearn: 0.0027515\ttotal: 2.08s\tremaining: 998ms\n",
      "338:\tlearn: 0.0027515\ttotal: 2.09s\tremaining: 992ms\n",
      "339:\tlearn: 0.0027511\ttotal: 2.09s\tremaining: 985ms\n",
      "340:\tlearn: 0.0027051\ttotal: 2.1s\tremaining: 979ms\n",
      "341:\tlearn: 0.0027051\ttotal: 2.1s\tremaining: 972ms\n",
      "342:\tlearn: 0.0027045\ttotal: 2.11s\tremaining: 965ms\n",
      "343:\tlearn: 0.0027045\ttotal: 2.11s\tremaining: 958ms\n",
      "344:\tlearn: 0.0027042\ttotal: 2.12s\tremaining: 951ms\n",
      "345:\tlearn: 0.0027042\ttotal: 2.12s\tremaining: 944ms\n",
      "346:\tlearn: 0.0026967\ttotal: 2.13s\tremaining: 937ms\n",
      "347:\tlearn: 0.0025931\ttotal: 2.13s\tremaining: 931ms\n",
      "348:\tlearn: 0.0025928\ttotal: 2.14s\tremaining: 924ms\n",
      "349:\tlearn: 0.0025927\ttotal: 2.14s\tremaining: 917ms\n",
      "350:\tlearn: 0.0025923\ttotal: 2.14s\tremaining: 910ms\n",
      "351:\tlearn: 0.0025921\ttotal: 2.15s\tremaining: 902ms\n",
      "352:\tlearn: 0.0025919\ttotal: 2.15s\tremaining: 895ms\n",
      "353:\tlearn: 0.0025919\ttotal: 2.16s\tremaining: 891ms\n",
      "354:\tlearn: 0.0025918\ttotal: 2.17s\tremaining: 886ms\n",
      "355:\tlearn: 0.0025918\ttotal: 2.18s\tremaining: 881ms\n",
      "356:\tlearn: 0.0025909\ttotal: 2.19s\tremaining: 876ms\n",
      "357:\tlearn: 0.0025907\ttotal: 2.2s\tremaining: 872ms\n",
      "358:\tlearn: 0.0025561\ttotal: 2.21s\tremaining: 867ms\n",
      "359:\tlearn: 0.0025559\ttotal: 2.22s\tremaining: 862ms\n",
      "360:\tlearn: 0.0025110\ttotal: 2.23s\tremaining: 857ms\n",
      "361:\tlearn: 0.0024708\ttotal: 2.24s\tremaining: 852ms\n",
      "362:\tlearn: 0.0024707\ttotal: 2.24s\tremaining: 847ms\n",
      "363:\tlearn: 0.0023644\ttotal: 2.25s\tremaining: 841ms\n",
      "364:\tlearn: 0.0022699\ttotal: 2.26s\tremaining: 835ms\n",
      "365:\tlearn: 0.0022696\ttotal: 2.26s\tremaining: 828ms\n",
      "366:\tlearn: 0.0022696\ttotal: 2.27s\tremaining: 822ms\n",
      "367:\tlearn: 0.0022693\ttotal: 2.27s\tremaining: 816ms\n",
      "368:\tlearn: 0.0022691\ttotal: 2.28s\tremaining: 809ms\n",
      "369:\tlearn: 0.0022691\ttotal: 2.28s\tremaining: 802ms\n",
      "370:\tlearn: 0.0022690\ttotal: 2.29s\tremaining: 795ms\n",
      "371:\tlearn: 0.0022689\ttotal: 2.29s\tremaining: 789ms\n",
      "372:\tlearn: 0.0022687\ttotal: 2.3s\tremaining: 782ms\n",
      "373:\tlearn: 0.0022687\ttotal: 2.3s\tremaining: 775ms\n",
      "374:\tlearn: 0.0022685\ttotal: 2.31s\tremaining: 769ms\n",
      "375:\tlearn: 0.0022685\ttotal: 2.31s\tremaining: 761ms\n",
      "376:\tlearn: 0.0022686\ttotal: 2.31s\tremaining: 754ms\n",
      "377:\tlearn: 0.0022686\ttotal: 2.31s\tremaining: 747ms\n",
      "378:\tlearn: 0.0022685\ttotal: 2.32s\tremaining: 740ms\n",
      "379:\tlearn: 0.0022685\ttotal: 2.32s\tremaining: 733ms\n",
      "380:\tlearn: 0.0022684\ttotal: 2.33s\tremaining: 727ms\n",
      "381:\tlearn: 0.0022681\ttotal: 2.33s\tremaining: 720ms\n",
      "382:\tlearn: 0.0022681\ttotal: 2.33s\tremaining: 713ms\n",
      "383:\tlearn: 0.0022680\ttotal: 2.34s\tremaining: 706ms\n",
      "384:\tlearn: 0.0022678\ttotal: 2.34s\tremaining: 700ms\n",
      "385:\tlearn: 0.0022677\ttotal: 2.35s\tremaining: 693ms\n",
      "386:\tlearn: 0.0022675\ttotal: 2.35s\tremaining: 686ms\n",
      "387:\tlearn: 0.0022674\ttotal: 2.35s\tremaining: 679ms\n",
      "388:\tlearn: 0.0022671\ttotal: 2.36s\tremaining: 674ms\n",
      "389:\tlearn: 0.0022670\ttotal: 2.37s\tremaining: 669ms\n",
      "390:\tlearn: 0.0022666\ttotal: 2.38s\tremaining: 664ms\n",
      "391:\tlearn: 0.0022663\ttotal: 2.39s\tremaining: 659ms\n",
      "392:\tlearn: 0.0022663\ttotal: 2.4s\tremaining: 654ms\n",
      "393:\tlearn: 0.0022664\ttotal: 2.41s\tremaining: 649ms\n",
      "394:\tlearn: 0.0022662\ttotal: 2.42s\tremaining: 643ms\n",
      "395:\tlearn: 0.0022661\ttotal: 2.43s\tremaining: 638ms\n",
      "396:\tlearn: 0.0022657\ttotal: 2.44s\tremaining: 633ms\n",
      "397:\tlearn: 0.0022657\ttotal: 2.45s\tremaining: 627ms\n",
      "398:\tlearn: 0.0022654\ttotal: 2.45s\tremaining: 621ms\n",
      "399:\tlearn: 0.0022654\ttotal: 2.46s\tremaining: 615ms\n",
      "400:\tlearn: 0.0022654\ttotal: 2.46s\tremaining: 609ms\n",
      "401:\tlearn: 0.0022654\ttotal: 2.47s\tremaining: 602ms\n",
      "402:\tlearn: 0.0022654\ttotal: 2.48s\tremaining: 596ms\n",
      "403:\tlearn: 0.0022609\ttotal: 2.48s\tremaining: 590ms\n",
      "404:\tlearn: 0.0022609\ttotal: 2.49s\tremaining: 583ms\n",
      "405:\tlearn: 0.0022607\ttotal: 2.49s\tremaining: 577ms\n",
      "406:\tlearn: 0.0022604\ttotal: 2.49s\tremaining: 570ms\n",
      "407:\tlearn: 0.0022603\ttotal: 2.5s\tremaining: 563ms\n",
      "408:\tlearn: 0.0022588\ttotal: 2.5s\tremaining: 556ms\n",
      "409:\tlearn: 0.0022585\ttotal: 2.5s\tremaining: 550ms\n",
      "410:\tlearn: 0.0022584\ttotal: 2.51s\tremaining: 543ms\n",
      "411:\tlearn: 0.0022583\ttotal: 2.51s\tremaining: 537ms\n",
      "412:\tlearn: 0.0022582\ttotal: 2.52s\tremaining: 530ms\n",
      "413:\tlearn: 0.0022582\ttotal: 2.52s\tremaining: 524ms\n",
      "414:\tlearn: 0.0022581\ttotal: 2.53s\tremaining: 519ms\n",
      "415:\tlearn: 0.0022580\ttotal: 2.54s\tremaining: 514ms\n",
      "416:\tlearn: 0.0022579\ttotal: 2.56s\tremaining: 509ms\n",
      "417:\tlearn: 0.0022580\ttotal: 2.56s\tremaining: 503ms\n",
      "418:\tlearn: 0.0022580\ttotal: 2.58s\tremaining: 499ms\n",
      "419:\tlearn: 0.0022580\ttotal: 2.59s\tremaining: 494ms\n",
      "420:\tlearn: 0.0022577\ttotal: 2.6s\tremaining: 488ms\n",
      "421:\tlearn: 0.0022577\ttotal: 2.61s\tremaining: 483ms\n",
      "422:\tlearn: 0.0022577\ttotal: 2.62s\tremaining: 477ms\n",
      "423:\tlearn: 0.0022575\ttotal: 2.63s\tremaining: 471ms\n",
      "424:\tlearn: 0.0022575\ttotal: 2.64s\tremaining: 466ms\n",
      "425:\tlearn: 0.0022574\ttotal: 2.65s\tremaining: 460ms\n",
      "426:\tlearn: 0.0022572\ttotal: 2.66s\tremaining: 454ms\n",
      "427:\tlearn: 0.0022572\ttotal: 2.67s\tremaining: 448ms\n",
      "428:\tlearn: 0.0022571\ttotal: 2.67s\tremaining: 442ms\n",
      "429:\tlearn: 0.0022568\ttotal: 2.67s\tremaining: 436ms\n",
      "430:\tlearn: 0.0022565\ttotal: 2.68s\tremaining: 429ms\n",
      "431:\tlearn: 0.0022564\ttotal: 2.68s\tremaining: 422ms\n",
      "432:\tlearn: 0.0022564\ttotal: 2.69s\tremaining: 416ms\n",
      "433:\tlearn: 0.0022564\ttotal: 2.69s\tremaining: 409ms\n",
      "434:\tlearn: 0.0022564\ttotal: 2.69s\tremaining: 403ms\n",
      "435:\tlearn: 0.0022563\ttotal: 2.7s\tremaining: 396ms\n",
      "436:\tlearn: 0.0022562\ttotal: 2.7s\tremaining: 389ms\n",
      "437:\tlearn: 0.0022562\ttotal: 2.71s\tremaining: 383ms\n",
      "438:\tlearn: 0.0022562\ttotal: 2.71s\tremaining: 376ms\n",
      "439:\tlearn: 0.0022555\ttotal: 2.71s\tremaining: 370ms\n",
      "440:\tlearn: 0.0022550\ttotal: 2.72s\tremaining: 364ms\n",
      "441:\tlearn: 0.0022549\ttotal: 2.72s\tremaining: 357ms\n",
      "442:\tlearn: 0.0022549\ttotal: 2.73s\tremaining: 351ms\n",
      "443:\tlearn: 0.0022548\ttotal: 2.73s\tremaining: 344ms\n",
      "444:\tlearn: 0.0022547\ttotal: 2.74s\tremaining: 339ms\n",
      "445:\tlearn: 0.0022546\ttotal: 2.75s\tremaining: 333ms\n",
      "446:\tlearn: 0.0022546\ttotal: 2.76s\tremaining: 327ms\n",
      "447:\tlearn: 0.0022546\ttotal: 2.77s\tremaining: 321ms\n",
      "448:\tlearn: 0.0022545\ttotal: 2.78s\tremaining: 315ms\n",
      "449:\tlearn: 0.0022545\ttotal: 2.79s\tremaining: 309ms\n",
      "450:\tlearn: 0.0022539\ttotal: 2.79s\tremaining: 304ms\n",
      "451:\tlearn: 0.0022538\ttotal: 2.8s\tremaining: 298ms\n",
      "452:\tlearn: 0.0022537\ttotal: 2.81s\tremaining: 292ms\n",
      "453:\tlearn: 0.0022537\ttotal: 2.81s\tremaining: 285ms\n",
      "454:\tlearn: 0.0022536\ttotal: 2.82s\tremaining: 279ms\n",
      "455:\tlearn: 0.0022534\ttotal: 2.82s\tremaining: 272ms\n",
      "456:\tlearn: 0.0022534\ttotal: 2.83s\tremaining: 266ms\n",
      "457:\tlearn: 0.0022534\ttotal: 2.83s\tremaining: 260ms\n",
      "458:\tlearn: 0.0022533\ttotal: 2.83s\tremaining: 253ms\n",
      "459:\tlearn: 0.0022533\ttotal: 2.84s\tremaining: 247ms\n",
      "460:\tlearn: 0.0022531\ttotal: 2.84s\tremaining: 241ms\n",
      "461:\tlearn: 0.0022529\ttotal: 2.85s\tremaining: 234ms\n",
      "462:\tlearn: 0.0022526\ttotal: 2.85s\tremaining: 228ms\n",
      "463:\tlearn: 0.0022525\ttotal: 2.85s\tremaining: 221ms\n",
      "464:\tlearn: 0.0022525\ttotal: 2.86s\tremaining: 215ms\n",
      "465:\tlearn: 0.0022525\ttotal: 2.86s\tremaining: 209ms\n",
      "466:\tlearn: 0.0022524\ttotal: 2.87s\tremaining: 203ms\n",
      "467:\tlearn: 0.0022523\ttotal: 2.88s\tremaining: 197ms\n",
      "468:\tlearn: 0.0022521\ttotal: 2.88s\tremaining: 191ms\n",
      "469:\tlearn: 0.0022521\ttotal: 2.89s\tremaining: 185ms\n",
      "470:\tlearn: 0.0022521\ttotal: 2.9s\tremaining: 179ms\n",
      "471:\tlearn: 0.0022521\ttotal: 2.91s\tremaining: 173ms\n",
      "472:\tlearn: 0.0022521\ttotal: 2.92s\tremaining: 167ms\n",
      "473:\tlearn: 0.0022521\ttotal: 2.92s\tremaining: 160ms\n",
      "474:\tlearn: 0.0022520\ttotal: 2.93s\tremaining: 154ms\n",
      "475:\tlearn: 0.0021967\ttotal: 2.93s\tremaining: 148ms\n",
      "476:\tlearn: 0.0021629\ttotal: 2.94s\tremaining: 142ms\n",
      "477:\tlearn: 0.0021629\ttotal: 2.94s\tremaining: 136ms\n",
      "478:\tlearn: 0.0021628\ttotal: 2.95s\tremaining: 129ms\n",
      "479:\tlearn: 0.0021141\ttotal: 2.95s\tremaining: 123ms\n",
      "480:\tlearn: 0.0021140\ttotal: 2.96s\tremaining: 117ms\n",
      "481:\tlearn: 0.0021140\ttotal: 2.96s\tremaining: 111ms\n",
      "482:\tlearn: 0.0021139\ttotal: 2.97s\tremaining: 105ms\n",
      "483:\tlearn: 0.0021137\ttotal: 2.97s\tremaining: 98.3ms\n",
      "484:\tlearn: 0.0021137\ttotal: 2.98s\tremaining: 92.1ms\n",
      "485:\tlearn: 0.0021136\ttotal: 2.98s\tremaining: 85.9ms\n",
      "486:\tlearn: 0.0021135\ttotal: 2.99s\tremaining: 79.8ms\n",
      "487:\tlearn: 0.0021134\ttotal: 2.99s\tremaining: 73.6ms\n",
      "488:\tlearn: 0.0021133\ttotal: 3s\tremaining: 67.4ms\n",
      "489:\tlearn: 0.0021133\ttotal: 3s\tremaining: 61.3ms\n",
      "490:\tlearn: 0.0021133\ttotal: 3s\tremaining: 55.1ms\n",
      "491:\tlearn: 0.0021131\ttotal: 3.01s\tremaining: 49ms\n",
      "492:\tlearn: 0.0021130\ttotal: 3.02s\tremaining: 42.9ms\n",
      "493:\tlearn: 0.0021128\ttotal: 3.03s\tremaining: 36.8ms\n",
      "494:\tlearn: 0.0021127\ttotal: 3.04s\tremaining: 30.7ms\n",
      "495:\tlearn: 0.0021127\ttotal: 3.05s\tremaining: 24.6ms\n",
      "496:\tlearn: 0.0021124\ttotal: 3.06s\tremaining: 18.5ms\n",
      "497:\tlearn: 0.0021123\ttotal: 3.07s\tremaining: 12.3ms\n",
      "498:\tlearn: 0.0021123\ttotal: 3.08s\tremaining: 6.17ms\n",
      "499:\tlearn: 0.0021123\ttotal: 3.09s\tremaining: 0us\n",
      "0:\tlearn: 0.6349026\ttotal: 5.2ms\tremaining: 2.59s\n",
      "1:\tlearn: 0.5792234\ttotal: 10.1ms\tremaining: 2.5s\n",
      "2:\tlearn: 0.5382825\ttotal: 14.9ms\tremaining: 2.46s\n",
      "3:\tlearn: 0.4981087\ttotal: 20ms\tremaining: 2.48s\n",
      "4:\tlearn: 0.4657564\ttotal: 24.9ms\tremaining: 2.46s\n",
      "5:\tlearn: 0.4347456\ttotal: 29.4ms\tremaining: 2.42s\n",
      "6:\tlearn: 0.4103857\ttotal: 34.2ms\tremaining: 2.41s\n",
      "7:\tlearn: 0.3839962\ttotal: 39.1ms\tremaining: 2.4s\n",
      "8:\tlearn: 0.3573184\ttotal: 43.9ms\tremaining: 2.39s\n",
      "9:\tlearn: 0.3299473\ttotal: 48.2ms\tremaining: 2.36s\n",
      "10:\tlearn: 0.3077670\ttotal: 52.5ms\tremaining: 2.33s\n",
      "11:\tlearn: 0.2871137\ttotal: 56.5ms\tremaining: 2.3s\n",
      "12:\tlearn: 0.2660322\ttotal: 60.8ms\tremaining: 2.28s\n",
      "13:\tlearn: 0.2556226\ttotal: 65ms\tremaining: 2.25s\n",
      "14:\tlearn: 0.2416382\ttotal: 69.4ms\tremaining: 2.24s\n",
      "15:\tlearn: 0.2278740\ttotal: 73.7ms\tremaining: 2.23s\n",
      "16:\tlearn: 0.2139473\ttotal: 83.5ms\tremaining: 2.37s\n",
      "17:\tlearn: 0.2032004\ttotal: 93.4ms\tremaining: 2.5s\n",
      "18:\tlearn: 0.1903122\ttotal: 103ms\tremaining: 2.61s\n",
      "19:\tlearn: 0.1749857\ttotal: 113ms\tremaining: 2.7s\n",
      "20:\tlearn: 0.1660119\ttotal: 122ms\tremaining: 2.79s\n",
      "21:\tlearn: 0.1580479\ttotal: 132ms\tremaining: 2.87s\n",
      "22:\tlearn: 0.1479360\ttotal: 142ms\tremaining: 2.94s\n",
      "23:\tlearn: 0.1426324\ttotal: 152ms\tremaining: 3.01s\n",
      "24:\tlearn: 0.1346265\ttotal: 161ms\tremaining: 3.06s\n",
      "25:\tlearn: 0.1291584\ttotal: 169ms\tremaining: 3.07s\n",
      "26:\tlearn: 0.1216609\ttotal: 175ms\tremaining: 3.06s\n",
      "27:\tlearn: 0.1166832\ttotal: 181ms\tremaining: 3.05s\n",
      "28:\tlearn: 0.1132535\ttotal: 187ms\tremaining: 3.04s\n",
      "29:\tlearn: 0.1057981\ttotal: 192ms\tremaining: 3.01s\n",
      "30:\tlearn: 0.1008982\ttotal: 197ms\tremaining: 2.99s\n",
      "31:\tlearn: 0.0958980\ttotal: 201ms\tremaining: 2.94s\n",
      "32:\tlearn: 0.0894784\ttotal: 205ms\tremaining: 2.9s\n",
      "33:\tlearn: 0.0863221\ttotal: 210ms\tremaining: 2.88s\n",
      "34:\tlearn: 0.0817553\ttotal: 214ms\tremaining: 2.85s\n",
      "35:\tlearn: 0.0789255\ttotal: 219ms\tremaining: 2.82s\n",
      "36:\tlearn: 0.0779508\ttotal: 223ms\tremaining: 2.79s\n",
      "37:\tlearn: 0.0715742\ttotal: 227ms\tremaining: 2.75s\n",
      "38:\tlearn: 0.0679770\ttotal: 231ms\tremaining: 2.73s\n",
      "39:\tlearn: 0.0643064\ttotal: 235ms\tremaining: 2.7s\n",
      "40:\tlearn: 0.0603510\ttotal: 239ms\tremaining: 2.68s\n",
      "41:\tlearn: 0.0563889\ttotal: 244ms\tremaining: 2.66s\n",
      "42:\tlearn: 0.0535304\ttotal: 254ms\tremaining: 2.7s\n",
      "43:\tlearn: 0.0502481\ttotal: 264ms\tremaining: 2.73s\n",
      "44:\tlearn: 0.0483037\ttotal: 273ms\tremaining: 2.76s\n",
      "45:\tlearn: 0.0442422\ttotal: 283ms\tremaining: 2.79s\n",
      "46:\tlearn: 0.0418128\ttotal: 293ms\tremaining: 2.82s\n",
      "47:\tlearn: 0.0391189\ttotal: 302ms\tremaining: 2.85s\n",
      "48:\tlearn: 0.0381762\ttotal: 312ms\tremaining: 2.87s\n",
      "49:\tlearn: 0.0364445\ttotal: 322ms\tremaining: 2.9s\n",
      "50:\tlearn: 0.0352992\ttotal: 331ms\tremaining: 2.91s\n",
      "51:\tlearn: 0.0331786\ttotal: 337ms\tremaining: 2.9s\n",
      "52:\tlearn: 0.0325639\ttotal: 343ms\tremaining: 2.89s\n",
      "53:\tlearn: 0.0314105\ttotal: 350ms\tremaining: 2.89s\n",
      "54:\tlearn: 0.0294298\ttotal: 356ms\tremaining: 2.88s\n",
      "55:\tlearn: 0.0275657\ttotal: 362ms\tremaining: 2.87s\n",
      "56:\tlearn: 0.0261291\ttotal: 368ms\tremaining: 2.86s\n",
      "57:\tlearn: 0.0250486\ttotal: 374ms\tremaining: 2.85s\n",
      "58:\tlearn: 0.0240890\ttotal: 378ms\tremaining: 2.83s\n",
      "59:\tlearn: 0.0226564\ttotal: 384ms\tremaining: 2.81s\n",
      "60:\tlearn: 0.0223539\ttotal: 387ms\tremaining: 2.79s\n",
      "61:\tlearn: 0.0209921\ttotal: 392ms\tremaining: 2.77s\n",
      "62:\tlearn: 0.0199599\ttotal: 396ms\tremaining: 2.75s\n",
      "63:\tlearn: 0.0192641\ttotal: 400ms\tremaining: 2.73s\n",
      "64:\tlearn: 0.0183493\ttotal: 404ms\tremaining: 2.71s\n",
      "65:\tlearn: 0.0172912\ttotal: 409ms\tremaining: 2.69s\n",
      "66:\tlearn: 0.0164089\ttotal: 413ms\tremaining: 2.67s\n",
      "67:\tlearn: 0.0155359\ttotal: 423ms\tremaining: 2.69s\n",
      "68:\tlearn: 0.0144694\ttotal: 432ms\tremaining: 2.7s\n",
      "69:\tlearn: 0.0141655\ttotal: 442ms\tremaining: 2.72s\n",
      "70:\tlearn: 0.0139069\ttotal: 452ms\tremaining: 2.73s\n",
      "71:\tlearn: 0.0135480\ttotal: 462ms\tremaining: 2.74s\n",
      "72:\tlearn: 0.0131073\ttotal: 471ms\tremaining: 2.76s\n",
      "73:\tlearn: 0.0126321\ttotal: 481ms\tremaining: 2.77s\n",
      "74:\tlearn: 0.0121756\ttotal: 490ms\tremaining: 2.78s\n",
      "75:\tlearn: 0.0116028\ttotal: 500ms\tremaining: 2.79s\n",
      "76:\tlearn: 0.0113493\ttotal: 507ms\tremaining: 2.79s\n",
      "77:\tlearn: 0.0110609\ttotal: 514ms\tremaining: 2.78s\n",
      "78:\tlearn: 0.0107375\ttotal: 521ms\tremaining: 2.77s\n",
      "79:\tlearn: 0.0103773\ttotal: 530ms\tremaining: 2.78s\n",
      "80:\tlearn: 0.0099809\ttotal: 534ms\tremaining: 2.76s\n",
      "81:\tlearn: 0.0096858\ttotal: 539ms\tremaining: 2.75s\n",
      "82:\tlearn: 0.0093703\ttotal: 544ms\tremaining: 2.73s\n",
      "83:\tlearn: 0.0091758\ttotal: 550ms\tremaining: 2.72s\n",
      "84:\tlearn: 0.0087508\ttotal: 554ms\tremaining: 2.7s\n",
      "85:\tlearn: 0.0082798\ttotal: 558ms\tremaining: 2.68s\n",
      "86:\tlearn: 0.0082796\ttotal: 561ms\tremaining: 2.66s\n",
      "87:\tlearn: 0.0082470\ttotal: 565ms\tremaining: 2.65s\n",
      "88:\tlearn: 0.0078100\ttotal: 570ms\tremaining: 2.63s\n",
      "89:\tlearn: 0.0073851\ttotal: 573ms\tremaining: 2.61s\n",
      "90:\tlearn: 0.0070143\ttotal: 577ms\tremaining: 2.59s\n",
      "91:\tlearn: 0.0067594\ttotal: 581ms\tremaining: 2.58s\n",
      "92:\tlearn: 0.0066590\ttotal: 591ms\tremaining: 2.59s\n",
      "93:\tlearn: 0.0063367\ttotal: 600ms\tremaining: 2.59s\n",
      "94:\tlearn: 0.0062019\ttotal: 610ms\tremaining: 2.6s\n",
      "95:\tlearn: 0.0060395\ttotal: 620ms\tremaining: 2.61s\n",
      "96:\tlearn: 0.0059166\ttotal: 630ms\tremaining: 2.62s\n",
      "97:\tlearn: 0.0058257\ttotal: 640ms\tremaining: 2.62s\n",
      "98:\tlearn: 0.0056057\ttotal: 649ms\tremaining: 2.63s\n",
      "99:\tlearn: 0.0052667\ttotal: 659ms\tremaining: 2.64s\n",
      "100:\tlearn: 0.0051027\ttotal: 669ms\tremaining: 2.64s\n",
      "101:\tlearn: 0.0048547\ttotal: 676ms\tremaining: 2.64s\n",
      "102:\tlearn: 0.0048542\ttotal: 682ms\tremaining: 2.63s\n",
      "103:\tlearn: 0.0046180\ttotal: 688ms\tremaining: 2.62s\n",
      "104:\tlearn: 0.0046178\ttotal: 694ms\tremaining: 2.61s\n",
      "105:\tlearn: 0.0046176\ttotal: 700ms\tremaining: 2.6s\n",
      "106:\tlearn: 0.0045204\ttotal: 704ms\tremaining: 2.59s\n",
      "107:\tlearn: 0.0044199\ttotal: 709ms\tremaining: 2.57s\n",
      "108:\tlearn: 0.0044195\ttotal: 713ms\tremaining: 2.56s\n",
      "109:\tlearn: 0.0044195\ttotal: 718ms\tremaining: 2.54s\n",
      "110:\tlearn: 0.0044195\ttotal: 723ms\tremaining: 2.54s\n",
      "111:\tlearn: 0.0044195\ttotal: 728ms\tremaining: 2.52s\n",
      "112:\tlearn: 0.0044194\ttotal: 731ms\tremaining: 2.5s\n",
      "113:\tlearn: 0.0044194\ttotal: 734ms\tremaining: 2.48s\n",
      "114:\tlearn: 0.0044194\ttotal: 738ms\tremaining: 2.47s\n",
      "115:\tlearn: 0.0043665\ttotal: 743ms\tremaining: 2.46s\n",
      "116:\tlearn: 0.0043663\ttotal: 747ms\tremaining: 2.44s\n",
      "117:\tlearn: 0.0043658\ttotal: 751ms\tremaining: 2.43s\n",
      "118:\tlearn: 0.0043657\ttotal: 755ms\tremaining: 2.42s\n",
      "119:\tlearn: 0.0043657\ttotal: 764ms\tremaining: 2.42s\n",
      "120:\tlearn: 0.0043657\ttotal: 774ms\tremaining: 2.42s\n",
      "121:\tlearn: 0.0043657\ttotal: 783ms\tremaining: 2.42s\n",
      "122:\tlearn: 0.0043657\ttotal: 792ms\tremaining: 2.43s\n",
      "123:\tlearn: 0.0043657\ttotal: 801ms\tremaining: 2.43s\n",
      "124:\tlearn: 0.0043657\ttotal: 811ms\tremaining: 2.43s\n",
      "125:\tlearn: 0.0043656\ttotal: 820ms\tremaining: 2.43s\n",
      "126:\tlearn: 0.0042576\ttotal: 829ms\tremaining: 2.44s\n",
      "127:\tlearn: 0.0040807\ttotal: 839ms\tremaining: 2.44s\n",
      "128:\tlearn: 0.0039949\ttotal: 848ms\tremaining: 2.44s\n",
      "129:\tlearn: 0.0039948\ttotal: 854ms\tremaining: 2.43s\n",
      "130:\tlearn: 0.0039948\ttotal: 860ms\tremaining: 2.42s\n",
      "131:\tlearn: 0.0039945\ttotal: 871ms\tremaining: 2.43s\n",
      "132:\tlearn: 0.0039946\ttotal: 877ms\tremaining: 2.42s\n",
      "133:\tlearn: 0.0039944\ttotal: 882ms\tremaining: 2.41s\n",
      "134:\tlearn: 0.0039943\ttotal: 886ms\tremaining: 2.4s\n",
      "135:\tlearn: 0.0039943\ttotal: 890ms\tremaining: 2.38s\n",
      "136:\tlearn: 0.0039943\ttotal: 896ms\tremaining: 2.37s\n",
      "137:\tlearn: 0.0039942\ttotal: 900ms\tremaining: 2.36s\n",
      "138:\tlearn: 0.0039942\ttotal: 903ms\tremaining: 2.35s\n",
      "139:\tlearn: 0.0039941\ttotal: 907ms\tremaining: 2.33s\n",
      "140:\tlearn: 0.0039941\ttotal: 911ms\tremaining: 2.32s\n",
      "141:\tlearn: 0.0039941\ttotal: 915ms\tremaining: 2.31s\n",
      "142:\tlearn: 0.0039941\ttotal: 919ms\tremaining: 2.29s\n",
      "143:\tlearn: 0.0039940\ttotal: 923ms\tremaining: 2.28s\n",
      "144:\tlearn: 0.0039940\ttotal: 932ms\tremaining: 2.28s\n",
      "145:\tlearn: 0.0039941\ttotal: 942ms\tremaining: 2.28s\n",
      "146:\tlearn: 0.0039940\ttotal: 951ms\tremaining: 2.28s\n",
      "147:\tlearn: 0.0039935\ttotal: 961ms\tremaining: 2.29s\n",
      "148:\tlearn: 0.0039935\ttotal: 970ms\tremaining: 2.29s\n",
      "149:\tlearn: 0.0039934\ttotal: 980ms\tremaining: 2.29s\n",
      "150:\tlearn: 0.0039932\ttotal: 989ms\tremaining: 2.29s\n",
      "151:\tlearn: 0.0039928\ttotal: 999ms\tremaining: 2.29s\n",
      "152:\tlearn: 0.0039928\ttotal: 1.01s\tremaining: 2.29s\n",
      "153:\tlearn: 0.0039928\ttotal: 1.02s\tremaining: 2.29s\n",
      "154:\tlearn: 0.0039051\ttotal: 1.02s\tremaining: 2.28s\n",
      "155:\tlearn: 0.0037400\ttotal: 1.03s\tremaining: 2.27s\n",
      "156:\tlearn: 0.0036382\ttotal: 1.04s\tremaining: 2.27s\n",
      "157:\tlearn: 0.0035321\ttotal: 1.04s\tremaining: 2.26s\n",
      "158:\tlearn: 0.0035320\ttotal: 1.05s\tremaining: 2.25s\n",
      "159:\tlearn: 0.0035320\ttotal: 1.05s\tremaining: 2.24s\n",
      "160:\tlearn: 0.0035320\ttotal: 1.06s\tremaining: 2.23s\n",
      "161:\tlearn: 0.0035318\ttotal: 1.06s\tremaining: 2.22s\n",
      "162:\tlearn: 0.0035318\ttotal: 1.07s\tremaining: 2.21s\n",
      "163:\tlearn: 0.0033632\ttotal: 1.07s\tremaining: 2.2s\n",
      "164:\tlearn: 0.0033632\ttotal: 1.08s\tremaining: 2.19s\n",
      "165:\tlearn: 0.0032294\ttotal: 1.08s\tremaining: 2.17s\n",
      "166:\tlearn: 0.0031148\ttotal: 1.09s\tremaining: 2.17s\n",
      "167:\tlearn: 0.0031146\ttotal: 1.09s\tremaining: 2.15s\n",
      "168:\tlearn: 0.0031144\ttotal: 1.09s\tremaining: 2.14s\n",
      "169:\tlearn: 0.0031140\ttotal: 1.1s\tremaining: 2.14s\n",
      "170:\tlearn: 0.0031136\ttotal: 1.11s\tremaining: 2.14s\n",
      "171:\tlearn: 0.0031134\ttotal: 1.12s\tremaining: 2.14s\n",
      "172:\tlearn: 0.0031130\ttotal: 1.13s\tremaining: 2.14s\n",
      "173:\tlearn: 0.0031130\ttotal: 1.14s\tremaining: 2.14s\n",
      "174:\tlearn: 0.0031130\ttotal: 1.15s\tremaining: 2.14s\n",
      "175:\tlearn: 0.0031130\ttotal: 1.16s\tremaining: 2.14s\n",
      "176:\tlearn: 0.0031129\ttotal: 1.17s\tremaining: 2.13s\n",
      "177:\tlearn: 0.0030822\ttotal: 1.18s\tremaining: 2.13s\n",
      "178:\tlearn: 0.0030822\ttotal: 1.19s\tremaining: 2.13s\n",
      "179:\tlearn: 0.0030814\ttotal: 1.19s\tremaining: 2.12s\n",
      "180:\tlearn: 0.0030815\ttotal: 1.2s\tremaining: 2.11s\n",
      "181:\tlearn: 0.0030815\ttotal: 1.2s\tremaining: 2.1s\n",
      "182:\tlearn: 0.0030814\ttotal: 1.21s\tremaining: 2.1s\n",
      "183:\tlearn: 0.0030814\ttotal: 1.22s\tremaining: 2.09s\n",
      "184:\tlearn: 0.0030814\ttotal: 1.22s\tremaining: 2.08s\n",
      "185:\tlearn: 0.0030814\ttotal: 1.22s\tremaining: 2.06s\n",
      "186:\tlearn: 0.0030812\ttotal: 1.23s\tremaining: 2.06s\n",
      "187:\tlearn: 0.0030812\ttotal: 1.23s\tremaining: 2.04s\n",
      "188:\tlearn: 0.0030812\ttotal: 1.24s\tremaining: 2.04s\n",
      "189:\tlearn: 0.0030812\ttotal: 1.24s\tremaining: 2.02s\n",
      "190:\tlearn: 0.0030369\ttotal: 1.25s\tremaining: 2.01s\n",
      "191:\tlearn: 0.0030367\ttotal: 1.25s\tremaining: 2s\n",
      "192:\tlearn: 0.0030366\ttotal: 1.25s\tremaining: 1.99s\n",
      "193:\tlearn: 0.0030360\ttotal: 1.26s\tremaining: 1.98s\n",
      "194:\tlearn: 0.0030359\ttotal: 1.26s\tremaining: 1.97s\n",
      "195:\tlearn: 0.0030357\ttotal: 1.26s\tremaining: 1.96s\n",
      "196:\tlearn: 0.0030357\ttotal: 1.27s\tremaining: 1.95s\n",
      "197:\tlearn: 0.0030357\ttotal: 1.28s\tremaining: 1.96s\n",
      "198:\tlearn: 0.0030356\ttotal: 1.29s\tremaining: 1.95s\n",
      "199:\tlearn: 0.0030353\ttotal: 1.3s\tremaining: 1.95s\n",
      "200:\tlearn: 0.0030352\ttotal: 1.31s\tremaining: 1.95s\n",
      "201:\tlearn: 0.0030350\ttotal: 1.32s\tremaining: 1.95s\n",
      "202:\tlearn: 0.0030349\ttotal: 1.33s\tremaining: 1.94s\n",
      "203:\tlearn: 0.0030348\ttotal: 1.34s\tremaining: 1.94s\n",
      "204:\tlearn: 0.0030346\ttotal: 1.35s\tremaining: 1.94s\n",
      "205:\tlearn: 0.0030345\ttotal: 1.35s\tremaining: 1.93s\n",
      "206:\tlearn: 0.0030345\ttotal: 1.36s\tremaining: 1.93s\n",
      "207:\tlearn: 0.0030344\ttotal: 1.37s\tremaining: 1.92s\n",
      "208:\tlearn: 0.0030344\ttotal: 1.37s\tremaining: 1.91s\n",
      "209:\tlearn: 0.0030343\ttotal: 1.38s\tremaining: 1.9s\n",
      "210:\tlearn: 0.0030343\ttotal: 1.38s\tremaining: 1.9s\n",
      "211:\tlearn: 0.0030343\ttotal: 1.39s\tremaining: 1.89s\n",
      "212:\tlearn: 0.0030343\ttotal: 1.39s\tremaining: 1.88s\n",
      "213:\tlearn: 0.0030343\ttotal: 1.4s\tremaining: 1.87s\n",
      "214:\tlearn: 0.0030343\ttotal: 1.4s\tremaining: 1.86s\n",
      "215:\tlearn: 0.0030343\ttotal: 1.41s\tremaining: 1.85s\n",
      "216:\tlearn: 0.0030343\ttotal: 1.41s\tremaining: 1.84s\n",
      "217:\tlearn: 0.0030342\ttotal: 1.41s\tremaining: 1.83s\n",
      "218:\tlearn: 0.0030339\ttotal: 1.42s\tremaining: 1.82s\n",
      "219:\tlearn: 0.0030339\ttotal: 1.42s\tremaining: 1.81s\n",
      "220:\tlearn: 0.0030339\ttotal: 1.43s\tremaining: 1.8s\n",
      "221:\tlearn: 0.0030339\ttotal: 1.43s\tremaining: 1.79s\n",
      "222:\tlearn: 0.0030338\ttotal: 1.43s\tremaining: 1.78s\n",
      "223:\tlearn: 0.0030332\ttotal: 1.44s\tremaining: 1.77s\n",
      "224:\tlearn: 0.0030332\ttotal: 1.44s\tremaining: 1.76s\n",
      "225:\tlearn: 0.0030331\ttotal: 1.45s\tremaining: 1.76s\n",
      "226:\tlearn: 0.0030331\ttotal: 1.46s\tremaining: 1.76s\n",
      "227:\tlearn: 0.0030331\ttotal: 1.47s\tremaining: 1.75s\n",
      "228:\tlearn: 0.0030330\ttotal: 1.48s\tremaining: 1.75s\n",
      "229:\tlearn: 0.0030331\ttotal: 1.49s\tremaining: 1.75s\n",
      "230:\tlearn: 0.0030326\ttotal: 1.5s\tremaining: 1.74s\n",
      "231:\tlearn: 0.0030324\ttotal: 1.51s\tremaining: 1.74s\n",
      "232:\tlearn: 0.0030324\ttotal: 1.52s\tremaining: 1.74s\n",
      "233:\tlearn: 0.0030323\ttotal: 1.52s\tremaining: 1.73s\n",
      "234:\tlearn: 0.0030318\ttotal: 1.53s\tremaining: 1.72s\n",
      "235:\tlearn: 0.0030316\ttotal: 1.53s\tremaining: 1.71s\n",
      "236:\tlearn: 0.0030313\ttotal: 1.54s\tremaining: 1.7s\n",
      "237:\tlearn: 0.0030313\ttotal: 1.54s\tremaining: 1.7s\n",
      "238:\tlearn: 0.0030313\ttotal: 1.54s\tremaining: 1.69s\n",
      "239:\tlearn: 0.0030312\ttotal: 1.55s\tremaining: 1.68s\n",
      "240:\tlearn: 0.0030312\ttotal: 1.55s\tremaining: 1.67s\n",
      "241:\tlearn: 0.0030312\ttotal: 1.56s\tremaining: 1.66s\n",
      "242:\tlearn: 0.0030312\ttotal: 1.56s\tremaining: 1.65s\n",
      "243:\tlearn: 0.0030312\ttotal: 1.57s\tremaining: 1.65s\n",
      "244:\tlearn: 0.0030307\ttotal: 1.57s\tremaining: 1.64s\n",
      "245:\tlearn: 0.0030306\ttotal: 1.58s\tremaining: 1.63s\n",
      "246:\tlearn: 0.0030304\ttotal: 1.58s\tremaining: 1.62s\n",
      "247:\tlearn: 0.0030304\ttotal: 1.58s\tremaining: 1.61s\n",
      "248:\tlearn: 0.0030302\ttotal: 1.59s\tremaining: 1.6s\n",
      "249:\tlearn: 0.0030301\ttotal: 1.59s\tremaining: 1.59s\n",
      "250:\tlearn: 0.0030301\ttotal: 1.6s\tremaining: 1.58s\n",
      "251:\tlearn: 0.0030301\ttotal: 1.6s\tremaining: 1.57s\n",
      "252:\tlearn: 0.0030300\ttotal: 1.6s\tremaining: 1.57s\n",
      "253:\tlearn: 0.0030300\ttotal: 1.61s\tremaining: 1.56s\n",
      "254:\tlearn: 0.0030299\ttotal: 1.61s\tremaining: 1.55s\n",
      "255:\tlearn: 0.0030289\ttotal: 1.62s\tremaining: 1.54s\n",
      "256:\tlearn: 0.0030288\ttotal: 1.63s\tremaining: 1.54s\n",
      "257:\tlearn: 0.0030287\ttotal: 1.64s\tremaining: 1.54s\n",
      "258:\tlearn: 0.0030285\ttotal: 1.65s\tremaining: 1.53s\n",
      "259:\tlearn: 0.0030284\ttotal: 1.66s\tremaining: 1.53s\n",
      "260:\tlearn: 0.0030283\ttotal: 1.67s\tremaining: 1.53s\n",
      "261:\tlearn: 0.0030280\ttotal: 1.68s\tremaining: 1.52s\n",
      "262:\tlearn: 0.0030280\ttotal: 1.69s\tremaining: 1.52s\n",
      "263:\tlearn: 0.0030279\ttotal: 1.69s\tremaining: 1.51s\n",
      "264:\tlearn: 0.0030278\ttotal: 1.7s\tremaining: 1.51s\n",
      "265:\tlearn: 0.0030277\ttotal: 1.7s\tremaining: 1.5s\n",
      "266:\tlearn: 0.0030277\ttotal: 1.71s\tremaining: 1.49s\n",
      "267:\tlearn: 0.0030274\ttotal: 1.72s\tremaining: 1.49s\n",
      "268:\tlearn: 0.0030269\ttotal: 1.72s\tremaining: 1.48s\n",
      "269:\tlearn: 0.0030269\ttotal: 1.73s\tremaining: 1.47s\n",
      "270:\tlearn: 0.0030268\ttotal: 1.73s\tremaining: 1.46s\n",
      "271:\tlearn: 0.0030264\ttotal: 1.74s\tremaining: 1.46s\n",
      "272:\tlearn: 0.0030260\ttotal: 1.74s\tremaining: 1.45s\n",
      "273:\tlearn: 0.0030255\ttotal: 1.75s\tremaining: 1.44s\n",
      "274:\tlearn: 0.0030249\ttotal: 1.75s\tremaining: 1.43s\n",
      "275:\tlearn: 0.0030246\ttotal: 1.75s\tremaining: 1.43s\n",
      "276:\tlearn: 0.0030241\ttotal: 1.76s\tremaining: 1.42s\n",
      "277:\tlearn: 0.0030239\ttotal: 1.76s\tremaining: 1.41s\n",
      "278:\tlearn: 0.0030238\ttotal: 1.77s\tremaining: 1.4s\n",
      "279:\tlearn: 0.0030234\ttotal: 1.77s\tremaining: 1.39s\n",
      "280:\tlearn: 0.0029444\ttotal: 1.78s\tremaining: 1.38s\n",
      "281:\tlearn: 0.0029443\ttotal: 1.78s\tremaining: 1.38s\n",
      "282:\tlearn: 0.0029440\ttotal: 1.78s\tremaining: 1.37s\n",
      "283:\tlearn: 0.0029440\ttotal: 1.79s\tremaining: 1.36s\n",
      "284:\tlearn: 0.0029436\ttotal: 1.79s\tremaining: 1.35s\n",
      "285:\tlearn: 0.0029436\ttotal: 1.8s\tremaining: 1.34s\n",
      "286:\tlearn: 0.0029435\ttotal: 1.81s\tremaining: 1.34s\n",
      "287:\tlearn: 0.0029435\ttotal: 1.82s\tremaining: 1.34s\n",
      "288:\tlearn: 0.0029435\ttotal: 1.83s\tremaining: 1.33s\n",
      "289:\tlearn: 0.0029129\ttotal: 1.84s\tremaining: 1.33s\n",
      "290:\tlearn: 0.0029129\ttotal: 1.85s\tremaining: 1.33s\n",
      "291:\tlearn: 0.0027811\ttotal: 1.86s\tremaining: 1.32s\n",
      "292:\tlearn: 0.0027810\ttotal: 1.86s\tremaining: 1.32s\n",
      "293:\tlearn: 0.0027810\ttotal: 1.88s\tremaining: 1.31s\n",
      "294:\tlearn: 0.0027809\ttotal: 1.88s\tremaining: 1.31s\n",
      "295:\tlearn: 0.0027807\ttotal: 1.89s\tremaining: 1.3s\n",
      "296:\tlearn: 0.0027807\ttotal: 1.9s\tremaining: 1.3s\n",
      "297:\tlearn: 0.0027802\ttotal: 1.91s\tremaining: 1.29s\n",
      "298:\tlearn: 0.0027802\ttotal: 1.91s\tremaining: 1.28s\n",
      "299:\tlearn: 0.0027802\ttotal: 1.92s\tremaining: 1.28s\n",
      "300:\tlearn: 0.0027802\ttotal: 1.92s\tremaining: 1.27s\n",
      "301:\tlearn: 0.0027802\ttotal: 1.93s\tremaining: 1.26s\n",
      "302:\tlearn: 0.0027802\ttotal: 1.93s\tremaining: 1.25s\n",
      "303:\tlearn: 0.0027801\ttotal: 1.93s\tremaining: 1.25s\n",
      "304:\tlearn: 0.0027801\ttotal: 1.94s\tremaining: 1.24s\n",
      "305:\tlearn: 0.0027801\ttotal: 1.94s\tremaining: 1.23s\n",
      "306:\tlearn: 0.0027800\ttotal: 1.95s\tremaining: 1.22s\n",
      "307:\tlearn: 0.0027798\ttotal: 1.95s\tremaining: 1.22s\n",
      "308:\tlearn: 0.0027798\ttotal: 1.96s\tremaining: 1.21s\n",
      "309:\tlearn: 0.0027798\ttotal: 1.96s\tremaining: 1.2s\n",
      "310:\tlearn: 0.0027798\ttotal: 1.96s\tremaining: 1.19s\n",
      "311:\tlearn: 0.0027798\ttotal: 1.97s\tremaining: 1.19s\n",
      "312:\tlearn: 0.0027796\ttotal: 1.97s\tremaining: 1.18s\n",
      "313:\tlearn: 0.0027795\ttotal: 1.98s\tremaining: 1.17s\n",
      "314:\tlearn: 0.0027790\ttotal: 1.99s\tremaining: 1.17s\n",
      "315:\tlearn: 0.0027790\ttotal: 2s\tremaining: 1.16s\n",
      "316:\tlearn: 0.0027789\ttotal: 2.01s\tremaining: 1.16s\n",
      "317:\tlearn: 0.0027787\ttotal: 2.02s\tremaining: 1.15s\n",
      "318:\tlearn: 0.0027786\ttotal: 2.03s\tremaining: 1.15s\n",
      "319:\tlearn: 0.0027781\ttotal: 2.04s\tremaining: 1.15s\n",
      "320:\tlearn: 0.0027779\ttotal: 2.05s\tremaining: 1.14s\n",
      "321:\tlearn: 0.0027769\ttotal: 2.05s\tremaining: 1.14s\n",
      "322:\tlearn: 0.0027768\ttotal: 2.06s\tremaining: 1.13s\n",
      "323:\tlearn: 0.0027762\ttotal: 2.07s\tremaining: 1.12s\n",
      "324:\tlearn: 0.0027762\ttotal: 2.07s\tremaining: 1.11s\n",
      "325:\tlearn: 0.0027756\ttotal: 2.08s\tremaining: 1.11s\n",
      "326:\tlearn: 0.0027755\ttotal: 2.08s\tremaining: 1.1s\n",
      "327:\tlearn: 0.0027755\ttotal: 2.09s\tremaining: 1.09s\n",
      "328:\tlearn: 0.0026628\ttotal: 2.09s\tremaining: 1.09s\n",
      "329:\tlearn: 0.0026628\ttotal: 2.1s\tremaining: 1.08s\n",
      "330:\tlearn: 0.0026627\ttotal: 2.1s\tremaining: 1.07s\n",
      "331:\tlearn: 0.0026627\ttotal: 2.1s\tremaining: 1.06s\n",
      "332:\tlearn: 0.0026623\ttotal: 2.11s\tremaining: 1.06s\n",
      "333:\tlearn: 0.0026622\ttotal: 2.11s\tremaining: 1.05s\n",
      "334:\tlearn: 0.0026620\ttotal: 2.12s\tremaining: 1.04s\n",
      "335:\tlearn: 0.0026620\ttotal: 2.12s\tremaining: 1.04s\n",
      "336:\tlearn: 0.0026618\ttotal: 2.13s\tremaining: 1.03s\n",
      "337:\tlearn: 0.0026618\ttotal: 2.13s\tremaining: 1.02s\n",
      "338:\tlearn: 0.0026617\ttotal: 2.13s\tremaining: 1.01s\n",
      "339:\tlearn: 0.0026616\ttotal: 2.14s\tremaining: 1.01s\n",
      "340:\tlearn: 0.0026615\ttotal: 2.14s\tremaining: 999ms\n",
      "341:\tlearn: 0.0026612\ttotal: 2.15s\tremaining: 994ms\n",
      "342:\tlearn: 0.0026612\ttotal: 2.16s\tremaining: 989ms\n",
      "343:\tlearn: 0.0026610\ttotal: 2.17s\tremaining: 985ms\n",
      "344:\tlearn: 0.0026610\ttotal: 2.18s\tremaining: 980ms\n",
      "345:\tlearn: 0.0026609\ttotal: 2.19s\tremaining: 975ms\n",
      "346:\tlearn: 0.0026608\ttotal: 2.2s\tremaining: 970ms\n",
      "347:\tlearn: 0.0026606\ttotal: 2.21s\tremaining: 965ms\n",
      "348:\tlearn: 0.0026606\ttotal: 2.22s\tremaining: 959ms\n",
      "349:\tlearn: 0.0026604\ttotal: 2.22s\tremaining: 952ms\n",
      "350:\tlearn: 0.0026602\ttotal: 2.23s\tremaining: 946ms\n",
      "351:\tlearn: 0.0026601\ttotal: 2.23s\tremaining: 939ms\n",
      "352:\tlearn: 0.0026602\ttotal: 2.24s\tremaining: 933ms\n",
      "353:\tlearn: 0.0026601\ttotal: 2.25s\tremaining: 926ms\n",
      "354:\tlearn: 0.0026600\ttotal: 2.25s\tremaining: 920ms\n",
      "355:\tlearn: 0.0026600\ttotal: 2.25s\tremaining: 913ms\n",
      "356:\tlearn: 0.0026600\ttotal: 2.26s\tremaining: 906ms\n",
      "357:\tlearn: 0.0026600\ttotal: 2.26s\tremaining: 898ms\n",
      "358:\tlearn: 0.0026598\ttotal: 2.27s\tremaining: 891ms\n",
      "359:\tlearn: 0.0026597\ttotal: 2.27s\tremaining: 884ms\n",
      "360:\tlearn: 0.0026596\ttotal: 2.28s\tremaining: 877ms\n",
      "361:\tlearn: 0.0026596\ttotal: 2.28s\tremaining: 870ms\n",
      "362:\tlearn: 0.0026596\ttotal: 2.29s\tremaining: 863ms\n",
      "363:\tlearn: 0.0026594\ttotal: 2.29s\tremaining: 856ms\n",
      "364:\tlearn: 0.0026593\ttotal: 2.29s\tremaining: 849ms\n",
      "365:\tlearn: 0.0026592\ttotal: 2.3s\tremaining: 842ms\n",
      "366:\tlearn: 0.0026592\ttotal: 2.3s\tremaining: 834ms\n",
      "367:\tlearn: 0.0026591\ttotal: 2.31s\tremaining: 827ms\n",
      "368:\tlearn: 0.0026590\ttotal: 2.31s\tremaining: 820ms\n",
      "369:\tlearn: 0.0026589\ttotal: 2.32s\tremaining: 815ms\n",
      "370:\tlearn: 0.0026589\ttotal: 2.33s\tremaining: 810ms\n",
      "371:\tlearn: 0.0026588\ttotal: 2.34s\tremaining: 805ms\n",
      "372:\tlearn: 0.0026588\ttotal: 2.35s\tremaining: 799ms\n",
      "373:\tlearn: 0.0026585\ttotal: 2.36s\tremaining: 794ms\n",
      "374:\tlearn: 0.0026585\ttotal: 2.37s\tremaining: 789ms\n",
      "375:\tlearn: 0.0026583\ttotal: 2.38s\tremaining: 784ms\n",
      "376:\tlearn: 0.0026581\ttotal: 2.38s\tremaining: 778ms\n",
      "377:\tlearn: 0.0026579\ttotal: 2.39s\tremaining: 772ms\n",
      "378:\tlearn: 0.0026579\ttotal: 2.4s\tremaining: 766ms\n",
      "379:\tlearn: 0.0026578\ttotal: 2.4s\tremaining: 759ms\n",
      "380:\tlearn: 0.0026578\ttotal: 2.41s\tremaining: 753ms\n",
      "381:\tlearn: 0.0026578\ttotal: 2.41s\tremaining: 746ms\n",
      "382:\tlearn: 0.0026577\ttotal: 2.42s\tremaining: 739ms\n",
      "383:\tlearn: 0.0026577\ttotal: 2.42s\tremaining: 732ms\n",
      "384:\tlearn: 0.0026576\ttotal: 2.43s\tremaining: 725ms\n",
      "385:\tlearn: 0.0026576\ttotal: 2.43s\tremaining: 718ms\n",
      "386:\tlearn: 0.0026574\ttotal: 2.44s\tremaining: 711ms\n",
      "387:\tlearn: 0.0026574\ttotal: 2.44s\tremaining: 704ms\n",
      "388:\tlearn: 0.0026573\ttotal: 2.44s\tremaining: 697ms\n",
      "389:\tlearn: 0.0026572\ttotal: 2.45s\tremaining: 690ms\n",
      "390:\tlearn: 0.0026572\ttotal: 2.45s\tremaining: 684ms\n",
      "391:\tlearn: 0.0026572\ttotal: 2.46s\tremaining: 677ms\n",
      "392:\tlearn: 0.0026571\ttotal: 2.46s\tremaining: 670ms\n",
      "393:\tlearn: 0.0026570\ttotal: 2.46s\tremaining: 663ms\n",
      "394:\tlearn: 0.0026569\ttotal: 2.47s\tremaining: 656ms\n",
      "395:\tlearn: 0.0026568\ttotal: 2.47s\tremaining: 650ms\n",
      "396:\tlearn: 0.0026566\ttotal: 2.48s\tremaining: 644ms\n",
      "397:\tlearn: 0.0026565\ttotal: 2.49s\tremaining: 639ms\n",
      "398:\tlearn: 0.0026564\ttotal: 2.5s\tremaining: 633ms\n",
      "399:\tlearn: 0.0026562\ttotal: 2.51s\tremaining: 628ms\n",
      "400:\tlearn: 0.0026559\ttotal: 2.52s\tremaining: 622ms\n",
      "401:\tlearn: 0.0026559\ttotal: 2.53s\tremaining: 617ms\n",
      "402:\tlearn: 0.0026559\ttotal: 2.54s\tremaining: 611ms\n",
      "403:\tlearn: 0.0026556\ttotal: 2.55s\tremaining: 605ms\n",
      "404:\tlearn: 0.0026555\ttotal: 2.55s\tremaining: 599ms\n",
      "405:\tlearn: 0.0026553\ttotal: 2.56s\tremaining: 592ms\n",
      "406:\tlearn: 0.0026551\ttotal: 2.56s\tremaining: 586ms\n",
      "407:\tlearn: 0.0026550\ttotal: 2.57s\tremaining: 579ms\n",
      "408:\tlearn: 0.0026550\ttotal: 2.57s\tremaining: 572ms\n",
      "409:\tlearn: 0.0026549\ttotal: 2.58s\tremaining: 565ms\n",
      "410:\tlearn: 0.0026549\ttotal: 2.58s\tremaining: 559ms\n",
      "411:\tlearn: 0.0026549\ttotal: 2.58s\tremaining: 552ms\n",
      "412:\tlearn: 0.0026549\ttotal: 2.59s\tremaining: 545ms\n",
      "413:\tlearn: 0.0026549\ttotal: 2.59s\tremaining: 538ms\n",
      "414:\tlearn: 0.0026549\ttotal: 2.6s\tremaining: 532ms\n",
      "415:\tlearn: 0.0026549\ttotal: 2.6s\tremaining: 525ms\n",
      "416:\tlearn: 0.0026548\ttotal: 2.6s\tremaining: 518ms\n",
      "417:\tlearn: 0.0026548\ttotal: 2.61s\tremaining: 512ms\n",
      "418:\tlearn: 0.0026547\ttotal: 2.61s\tremaining: 505ms\n",
      "419:\tlearn: 0.0026546\ttotal: 2.62s\tremaining: 499ms\n",
      "420:\tlearn: 0.0026546\ttotal: 2.63s\tremaining: 494ms\n",
      "421:\tlearn: 0.0026546\ttotal: 2.64s\tremaining: 488ms\n",
      "422:\tlearn: 0.0026546\ttotal: 2.65s\tremaining: 482ms\n",
      "423:\tlearn: 0.0026546\ttotal: 2.66s\tremaining: 477ms\n",
      "424:\tlearn: 0.0026544\ttotal: 2.67s\tremaining: 471ms\n",
      "425:\tlearn: 0.0026544\ttotal: 2.68s\tremaining: 465ms\n",
      "426:\tlearn: 0.0026543\ttotal: 2.69s\tremaining: 459ms\n",
      "427:\tlearn: 0.0026543\ttotal: 2.69s\tremaining: 454ms\n",
      "428:\tlearn: 0.0026542\ttotal: 2.7s\tremaining: 448ms\n",
      "429:\tlearn: 0.0026540\ttotal: 2.71s\tremaining: 441ms\n",
      "430:\tlearn: 0.0026540\ttotal: 2.71s\tremaining: 434ms\n",
      "431:\tlearn: 0.0026538\ttotal: 2.72s\tremaining: 428ms\n",
      "432:\tlearn: 0.0026538\ttotal: 2.72s\tremaining: 421ms\n",
      "433:\tlearn: 0.0026537\ttotal: 2.73s\tremaining: 415ms\n",
      "434:\tlearn: 0.0026537\ttotal: 2.73s\tremaining: 408ms\n",
      "435:\tlearn: 0.0026533\ttotal: 2.74s\tremaining: 402ms\n",
      "436:\tlearn: 0.0026532\ttotal: 2.74s\tremaining: 395ms\n",
      "437:\tlearn: 0.0026532\ttotal: 2.75s\tremaining: 389ms\n",
      "438:\tlearn: 0.0026530\ttotal: 2.75s\tremaining: 382ms\n",
      "439:\tlearn: 0.0026529\ttotal: 2.75s\tremaining: 376ms\n",
      "440:\tlearn: 0.0026528\ttotal: 2.76s\tremaining: 369ms\n",
      "441:\tlearn: 0.0026528\ttotal: 2.76s\tremaining: 363ms\n",
      "442:\tlearn: 0.0026526\ttotal: 2.77s\tremaining: 356ms\n",
      "443:\tlearn: 0.0026524\ttotal: 2.77s\tremaining: 349ms\n",
      "444:\tlearn: 0.0026524\ttotal: 2.77s\tremaining: 343ms\n",
      "445:\tlearn: 0.0026523\ttotal: 2.78s\tremaining: 336ms\n",
      "446:\tlearn: 0.0026521\ttotal: 2.78s\tremaining: 330ms\n",
      "447:\tlearn: 0.0026521\ttotal: 2.79s\tremaining: 323ms\n",
      "448:\tlearn: 0.0026521\ttotal: 2.8s\tremaining: 318ms\n",
      "449:\tlearn: 0.0026519\ttotal: 2.81s\tremaining: 312ms\n",
      "450:\tlearn: 0.0026519\ttotal: 2.81s\tremaining: 306ms\n",
      "451:\tlearn: 0.0026519\ttotal: 2.82s\tremaining: 300ms\n",
      "452:\tlearn: 0.0026519\ttotal: 2.83s\tremaining: 294ms\n",
      "453:\tlearn: 0.0026518\ttotal: 2.84s\tremaining: 288ms\n",
      "454:\tlearn: 0.0026517\ttotal: 2.85s\tremaining: 282ms\n",
      "455:\tlearn: 0.0026517\ttotal: 2.86s\tremaining: 276ms\n",
      "456:\tlearn: 0.0026516\ttotal: 2.87s\tremaining: 270ms\n",
      "457:\tlearn: 0.0026516\ttotal: 2.88s\tremaining: 264ms\n",
      "458:\tlearn: 0.0026515\ttotal: 2.89s\tremaining: 258ms\n",
      "459:\tlearn: 0.0026514\ttotal: 2.89s\tremaining: 252ms\n",
      "460:\tlearn: 0.0026514\ttotal: 2.9s\tremaining: 245ms\n",
      "461:\tlearn: 0.0026512\ttotal: 2.9s\tremaining: 239ms\n",
      "462:\tlearn: 0.0026511\ttotal: 2.91s\tremaining: 232ms\n",
      "463:\tlearn: 0.0026511\ttotal: 2.91s\tremaining: 226ms\n",
      "464:\tlearn: 0.0026511\ttotal: 2.92s\tremaining: 220ms\n",
      "465:\tlearn: 0.0026511\ttotal: 2.92s\tremaining: 213ms\n",
      "466:\tlearn: 0.0026510\ttotal: 2.92s\tremaining: 207ms\n",
      "467:\tlearn: 0.0026510\ttotal: 2.93s\tremaining: 200ms\n",
      "468:\tlearn: 0.0026507\ttotal: 2.93s\tremaining: 194ms\n",
      "469:\tlearn: 0.0026507\ttotal: 2.94s\tremaining: 187ms\n",
      "470:\tlearn: 0.0026506\ttotal: 2.94s\tremaining: 181ms\n",
      "471:\tlearn: 0.0026506\ttotal: 2.94s\tremaining: 175ms\n",
      "472:\tlearn: 0.0026506\ttotal: 2.95s\tremaining: 168ms\n",
      "473:\tlearn: 0.0026506\ttotal: 2.95s\tremaining: 162ms\n",
      "474:\tlearn: 0.0026505\ttotal: 2.96s\tremaining: 156ms\n",
      "475:\tlearn: 0.0026505\ttotal: 2.96s\tremaining: 150ms\n",
      "476:\tlearn: 0.0026505\ttotal: 2.97s\tremaining: 143ms\n",
      "477:\tlearn: 0.0026504\ttotal: 2.98s\tremaining: 137ms\n",
      "478:\tlearn: 0.0026504\ttotal: 2.99s\tremaining: 131ms\n",
      "479:\tlearn: 0.0026502\ttotal: 3s\tremaining: 125ms\n",
      "480:\tlearn: 0.0026500\ttotal: 3.01s\tremaining: 119ms\n",
      "481:\tlearn: 0.0026500\ttotal: 3.01s\tremaining: 113ms\n",
      "482:\tlearn: 0.0026498\ttotal: 3.02s\tremaining: 106ms\n",
      "483:\tlearn: 0.0026497\ttotal: 3.03s\tremaining: 100ms\n",
      "484:\tlearn: 0.0026496\ttotal: 3.03s\tremaining: 93.8ms\n",
      "485:\tlearn: 0.0026492\ttotal: 3.04s\tremaining: 87.5ms\n",
      "486:\tlearn: 0.0026493\ttotal: 3.04s\tremaining: 81.2ms\n",
      "487:\tlearn: 0.0026492\ttotal: 3.04s\tremaining: 74.9ms\n",
      "488:\tlearn: 0.0026490\ttotal: 3.05s\tremaining: 68.6ms\n",
      "489:\tlearn: 0.0026490\ttotal: 3.05s\tremaining: 62.3ms\n",
      "490:\tlearn: 0.0026490\ttotal: 3.06s\tremaining: 56.1ms\n",
      "491:\tlearn: 0.0026490\ttotal: 3.06s\tremaining: 49.8ms\n",
      "492:\tlearn: 0.0026490\ttotal: 3.06s\tremaining: 43.5ms\n",
      "493:\tlearn: 0.0026489\ttotal: 3.07s\tremaining: 37.3ms\n",
      "494:\tlearn: 0.0026487\ttotal: 3.07s\tremaining: 31ms\n",
      "495:\tlearn: 0.0026487\ttotal: 3.08s\tremaining: 24.8ms\n",
      "496:\tlearn: 0.0026487\ttotal: 3.08s\tremaining: 18.6ms\n",
      "497:\tlearn: 0.0026488\ttotal: 3.08s\tremaining: 12.4ms\n",
      "498:\tlearn: 0.0026487\ttotal: 3.09s\tremaining: 6.19ms\n",
      "499:\tlearn: 0.0026485\ttotal: 3.1s\tremaining: 0us\n",
      "0:\tlearn: 0.6376637\ttotal: 5.06ms\tremaining: 2.53s\n",
      "1:\tlearn: 0.5819850\ttotal: 10.3ms\tremaining: 2.57s\n",
      "2:\tlearn: 0.5441819\ttotal: 15.1ms\tremaining: 2.5s\n",
      "3:\tlearn: 0.5112478\ttotal: 19.6ms\tremaining: 2.43s\n",
      "4:\tlearn: 0.4770589\ttotal: 24.1ms\tremaining: 2.39s\n",
      "5:\tlearn: 0.4484506\ttotal: 28.8ms\tremaining: 2.37s\n",
      "6:\tlearn: 0.4265142\ttotal: 33.4ms\tremaining: 2.35s\n",
      "7:\tlearn: 0.3980834\ttotal: 37.9ms\tremaining: 2.33s\n",
      "8:\tlearn: 0.3752617\ttotal: 42.5ms\tremaining: 2.32s\n",
      "9:\tlearn: 0.3485377\ttotal: 47.2ms\tremaining: 2.31s\n",
      "10:\tlearn: 0.3278151\ttotal: 51.6ms\tremaining: 2.29s\n",
      "11:\tlearn: 0.3018330\ttotal: 56.1ms\tremaining: 2.28s\n",
      "12:\tlearn: 0.2812856\ttotal: 60.9ms\tremaining: 2.28s\n",
      "13:\tlearn: 0.2648949\ttotal: 65.2ms\tremaining: 2.26s\n",
      "14:\tlearn: 0.2473963\ttotal: 69.5ms\tremaining: 2.25s\n",
      "15:\tlearn: 0.2292281\ttotal: 74ms\tremaining: 2.24s\n",
      "16:\tlearn: 0.2208293\ttotal: 78.5ms\tremaining: 2.23s\n",
      "17:\tlearn: 0.2047535\ttotal: 82.4ms\tremaining: 2.21s\n",
      "18:\tlearn: 0.1887413\ttotal: 86.8ms\tremaining: 2.2s\n",
      "19:\tlearn: 0.1763240\ttotal: 90.7ms\tremaining: 2.17s\n",
      "20:\tlearn: 0.1629353\ttotal: 100ms\tremaining: 2.29s\n",
      "21:\tlearn: 0.1537204\ttotal: 110ms\tremaining: 2.39s\n",
      "22:\tlearn: 0.1449375\ttotal: 120ms\tremaining: 2.48s\n",
      "23:\tlearn: 0.1370469\ttotal: 129ms\tremaining: 2.56s\n",
      "24:\tlearn: 0.1308344\ttotal: 139ms\tremaining: 2.64s\n",
      "25:\tlearn: 0.1238666\ttotal: 148ms\tremaining: 2.71s\n",
      "26:\tlearn: 0.1158522\ttotal: 158ms\tremaining: 2.77s\n",
      "27:\tlearn: 0.1097021\ttotal: 167ms\tremaining: 2.81s\n",
      "28:\tlearn: 0.1062812\ttotal: 172ms\tremaining: 2.79s\n",
      "29:\tlearn: 0.0995825\ttotal: 177ms\tremaining: 2.78s\n",
      "30:\tlearn: 0.0967225\ttotal: 182ms\tremaining: 2.76s\n",
      "31:\tlearn: 0.0915744\ttotal: 189ms\tremaining: 2.76s\n",
      "32:\tlearn: 0.0840877\ttotal: 193ms\tremaining: 2.73s\n",
      "33:\tlearn: 0.0789917\ttotal: 197ms\tremaining: 2.7s\n",
      "34:\tlearn: 0.0746783\ttotal: 200ms\tremaining: 2.66s\n",
      "35:\tlearn: 0.0689585\ttotal: 205ms\tremaining: 2.65s\n",
      "36:\tlearn: 0.0663212\ttotal: 209ms\tremaining: 2.62s\n",
      "37:\tlearn: 0.0633805\ttotal: 213ms\tremaining: 2.59s\n",
      "38:\tlearn: 0.0615152\ttotal: 218ms\tremaining: 2.58s\n",
      "39:\tlearn: 0.0583631\ttotal: 222ms\tremaining: 2.55s\n",
      "40:\tlearn: 0.0543545\ttotal: 226ms\tremaining: 2.53s\n",
      "41:\tlearn: 0.0506640\ttotal: 236ms\tremaining: 2.57s\n",
      "42:\tlearn: 0.0468606\ttotal: 245ms\tremaining: 2.61s\n",
      "43:\tlearn: 0.0453321\ttotal: 255ms\tremaining: 2.64s\n",
      "44:\tlearn: 0.0429905\ttotal: 265ms\tremaining: 2.68s\n",
      "45:\tlearn: 0.0414246\ttotal: 274ms\tremaining: 2.71s\n",
      "46:\tlearn: 0.0394922\ttotal: 284ms\tremaining: 2.74s\n",
      "47:\tlearn: 0.0372876\ttotal: 294ms\tremaining: 2.77s\n",
      "48:\tlearn: 0.0360737\ttotal: 303ms\tremaining: 2.79s\n",
      "49:\tlearn: 0.0333898\ttotal: 310ms\tremaining: 2.79s\n",
      "50:\tlearn: 0.0318828\ttotal: 316ms\tremaining: 2.79s\n",
      "51:\tlearn: 0.0307811\ttotal: 323ms\tremaining: 2.78s\n",
      "52:\tlearn: 0.0297700\ttotal: 329ms\tremaining: 2.77s\n",
      "53:\tlearn: 0.0285977\ttotal: 336ms\tremaining: 2.77s\n",
      "54:\tlearn: 0.0275898\ttotal: 341ms\tremaining: 2.76s\n",
      "55:\tlearn: 0.0260425\ttotal: 346ms\tremaining: 2.74s\n",
      "56:\tlearn: 0.0256306\ttotal: 351ms\tremaining: 2.73s\n",
      "57:\tlearn: 0.0249400\ttotal: 356ms\tremaining: 2.71s\n",
      "58:\tlearn: 0.0235520\ttotal: 360ms\tremaining: 2.69s\n",
      "59:\tlearn: 0.0229640\ttotal: 365ms\tremaining: 2.67s\n",
      "60:\tlearn: 0.0222919\ttotal: 369ms\tremaining: 2.66s\n",
      "61:\tlearn: 0.0214113\ttotal: 374ms\tremaining: 2.64s\n",
      "62:\tlearn: 0.0206938\ttotal: 378ms\tremaining: 2.62s\n",
      "63:\tlearn: 0.0200683\ttotal: 381ms\tremaining: 2.6s\n",
      "64:\tlearn: 0.0198960\ttotal: 385ms\tremaining: 2.58s\n",
      "65:\tlearn: 0.0191267\ttotal: 389ms\tremaining: 2.56s\n",
      "66:\tlearn: 0.0184112\ttotal: 394ms\tremaining: 2.54s\n",
      "67:\tlearn: 0.0174888\ttotal: 398ms\tremaining: 2.53s\n",
      "68:\tlearn: 0.0170193\ttotal: 408ms\tremaining: 2.54s\n",
      "69:\tlearn: 0.0163023\ttotal: 417ms\tremaining: 2.56s\n",
      "70:\tlearn: 0.0153232\ttotal: 427ms\tremaining: 2.58s\n",
      "71:\tlearn: 0.0146702\ttotal: 437ms\tremaining: 2.59s\n",
      "72:\tlearn: 0.0142075\ttotal: 446ms\tremaining: 2.61s\n",
      "73:\tlearn: 0.0136607\ttotal: 456ms\tremaining: 2.62s\n",
      "74:\tlearn: 0.0129558\ttotal: 466ms\tremaining: 2.64s\n",
      "75:\tlearn: 0.0124283\ttotal: 476ms\tremaining: 2.65s\n",
      "76:\tlearn: 0.0122200\ttotal: 483ms\tremaining: 2.65s\n",
      "77:\tlearn: 0.0120058\ttotal: 489ms\tremaining: 2.65s\n",
      "78:\tlearn: 0.0118810\ttotal: 496ms\tremaining: 2.64s\n",
      "79:\tlearn: 0.0116666\ttotal: 502ms\tremaining: 2.63s\n",
      "80:\tlearn: 0.0113992\ttotal: 508ms\tremaining: 2.63s\n",
      "81:\tlearn: 0.0109742\ttotal: 514ms\tremaining: 2.62s\n",
      "82:\tlearn: 0.0105662\ttotal: 519ms\tremaining: 2.6s\n",
      "83:\tlearn: 0.0103507\ttotal: 523ms\tremaining: 2.59s\n",
      "84:\tlearn: 0.0101123\ttotal: 528ms\tremaining: 2.58s\n",
      "85:\tlearn: 0.0095699\ttotal: 533ms\tremaining: 2.56s\n",
      "86:\tlearn: 0.0095606\ttotal: 537ms\tremaining: 2.55s\n",
      "87:\tlearn: 0.0092832\ttotal: 542ms\tremaining: 2.54s\n",
      "88:\tlearn: 0.0090709\ttotal: 546ms\tremaining: 2.52s\n",
      "89:\tlearn: 0.0087181\ttotal: 551ms\tremaining: 2.51s\n",
      "90:\tlearn: 0.0085021\ttotal: 555ms\tremaining: 2.49s\n",
      "91:\tlearn: 0.0082522\ttotal: 559ms\tremaining: 2.48s\n",
      "92:\tlearn: 0.0080334\ttotal: 563ms\tremaining: 2.46s\n",
      "93:\tlearn: 0.0079638\ttotal: 573ms\tremaining: 2.47s\n",
      "94:\tlearn: 0.0075882\ttotal: 583ms\tremaining: 2.48s\n",
      "95:\tlearn: 0.0071109\ttotal: 592ms\tremaining: 2.49s\n",
      "96:\tlearn: 0.0067027\ttotal: 602ms\tremaining: 2.5s\n",
      "97:\tlearn: 0.0065456\ttotal: 611ms\tremaining: 2.51s\n",
      "98:\tlearn: 0.0063672\ttotal: 621ms\tremaining: 2.51s\n",
      "99:\tlearn: 0.0059974\ttotal: 631ms\tremaining: 2.52s\n",
      "100:\tlearn: 0.0058656\ttotal: 641ms\tremaining: 2.53s\n",
      "101:\tlearn: 0.0058656\ttotal: 650ms\tremaining: 2.54s\n",
      "102:\tlearn: 0.0056101\ttotal: 658ms\tremaining: 2.54s\n",
      "103:\tlearn: 0.0053954\ttotal: 664ms\tremaining: 2.53s\n",
      "104:\tlearn: 0.0053946\ttotal: 670ms\tremaining: 2.52s\n",
      "105:\tlearn: 0.0053024\ttotal: 676ms\tremaining: 2.51s\n",
      "106:\tlearn: 0.0050911\ttotal: 682ms\tremaining: 2.5s\n",
      "107:\tlearn: 0.0048472\ttotal: 688ms\tremaining: 2.5s\n",
      "108:\tlearn: 0.0046179\ttotal: 692ms\tremaining: 2.48s\n",
      "109:\tlearn: 0.0043809\ttotal: 697ms\tremaining: 2.47s\n",
      "110:\tlearn: 0.0041696\ttotal: 701ms\tremaining: 2.46s\n",
      "111:\tlearn: 0.0041685\ttotal: 706ms\tremaining: 2.44s\n",
      "112:\tlearn: 0.0040621\ttotal: 711ms\tremaining: 2.43s\n",
      "113:\tlearn: 0.0040621\ttotal: 715ms\tremaining: 2.42s\n",
      "114:\tlearn: 0.0040615\ttotal: 719ms\tremaining: 2.4s\n",
      "115:\tlearn: 0.0039634\ttotal: 723ms\tremaining: 2.39s\n",
      "116:\tlearn: 0.0039633\ttotal: 727ms\tremaining: 2.38s\n",
      "117:\tlearn: 0.0039632\ttotal: 731ms\tremaining: 2.37s\n",
      "118:\tlearn: 0.0039632\ttotal: 736ms\tremaining: 2.36s\n",
      "119:\tlearn: 0.0039630\ttotal: 745ms\tremaining: 2.36s\n",
      "120:\tlearn: 0.0039629\ttotal: 755ms\tremaining: 2.36s\n",
      "121:\tlearn: 0.0039629\ttotal: 764ms\tremaining: 2.37s\n",
      "122:\tlearn: 0.0039629\ttotal: 773ms\tremaining: 2.37s\n",
      "123:\tlearn: 0.0038556\ttotal: 783ms\tremaining: 2.37s\n",
      "124:\tlearn: 0.0038554\ttotal: 792ms\tremaining: 2.38s\n",
      "125:\tlearn: 0.0038551\ttotal: 802ms\tremaining: 2.38s\n",
      "126:\tlearn: 0.0038551\ttotal: 811ms\tremaining: 2.38s\n",
      "127:\tlearn: 0.0038267\ttotal: 821ms\tremaining: 2.38s\n",
      "128:\tlearn: 0.0038263\ttotal: 829ms\tremaining: 2.38s\n",
      "129:\tlearn: 0.0038261\ttotal: 835ms\tremaining: 2.38s\n",
      "130:\tlearn: 0.0038261\ttotal: 841ms\tremaining: 2.37s\n",
      "131:\tlearn: 0.0038260\ttotal: 847ms\tremaining: 2.36s\n",
      "132:\tlearn: 0.0038252\ttotal: 853ms\tremaining: 2.35s\n",
      "133:\tlearn: 0.0038250\ttotal: 859ms\tremaining: 2.35s\n",
      "134:\tlearn: 0.0038248\ttotal: 863ms\tremaining: 2.33s\n",
      "135:\tlearn: 0.0038245\ttotal: 867ms\tremaining: 2.32s\n",
      "136:\tlearn: 0.0038242\ttotal: 872ms\tremaining: 2.31s\n",
      "137:\tlearn: 0.0038242\ttotal: 876ms\tremaining: 2.3s\n",
      "138:\tlearn: 0.0038238\ttotal: 880ms\tremaining: 2.29s\n",
      "139:\tlearn: 0.0038237\ttotal: 885ms\tremaining: 2.27s\n",
      "140:\tlearn: 0.0038237\ttotal: 889ms\tremaining: 2.26s\n",
      "141:\tlearn: 0.0037176\ttotal: 893ms\tremaining: 2.25s\n",
      "142:\tlearn: 0.0035603\ttotal: 897ms\tremaining: 2.24s\n",
      "143:\tlearn: 0.0035600\ttotal: 901ms\tremaining: 2.23s\n",
      "144:\tlearn: 0.0035598\ttotal: 905ms\tremaining: 2.21s\n",
      "145:\tlearn: 0.0035597\ttotal: 909ms\tremaining: 2.2s\n",
      "146:\tlearn: 0.0035524\ttotal: 913ms\tremaining: 2.19s\n",
      "147:\tlearn: 0.0035524\ttotal: 917ms\tremaining: 2.18s\n",
      "148:\tlearn: 0.0035429\ttotal: 930ms\tremaining: 2.19s\n",
      "149:\tlearn: 0.0035409\ttotal: 940ms\tremaining: 2.19s\n",
      "150:\tlearn: 0.0035408\ttotal: 949ms\tremaining: 2.19s\n",
      "151:\tlearn: 0.0035406\ttotal: 961ms\tremaining: 2.2s\n",
      "152:\tlearn: 0.0035403\ttotal: 970ms\tremaining: 2.2s\n",
      "153:\tlearn: 0.0035403\ttotal: 980ms\tremaining: 2.2s\n",
      "154:\tlearn: 0.0035402\ttotal: 989ms\tremaining: 2.2s\n",
      "155:\tlearn: 0.0035402\ttotal: 997ms\tremaining: 2.2s\n",
      "156:\tlearn: 0.0035402\ttotal: 1s\tremaining: 2.19s\n",
      "157:\tlearn: 0.0035397\ttotal: 1.01s\tremaining: 2.18s\n",
      "158:\tlearn: 0.0035396\ttotal: 1.01s\tremaining: 2.17s\n",
      "159:\tlearn: 0.0035390\ttotal: 1.02s\tremaining: 2.17s\n",
      "160:\tlearn: 0.0035388\ttotal: 1.02s\tremaining: 2.16s\n",
      "161:\tlearn: 0.0035383\ttotal: 1.03s\tremaining: 2.15s\n",
      "162:\tlearn: 0.0035383\ttotal: 1.03s\tremaining: 2.14s\n",
      "163:\tlearn: 0.0035376\ttotal: 1.04s\tremaining: 2.13s\n",
      "164:\tlearn: 0.0035376\ttotal: 1.04s\tremaining: 2.12s\n",
      "165:\tlearn: 0.0035373\ttotal: 1.05s\tremaining: 2.11s\n",
      "166:\tlearn: 0.0035369\ttotal: 1.05s\tremaining: 2.1s\n",
      "167:\tlearn: 0.0035369\ttotal: 1.06s\tremaining: 2.09s\n",
      "168:\tlearn: 0.0035364\ttotal: 1.06s\tremaining: 2.08s\n",
      "169:\tlearn: 0.0035363\ttotal: 1.06s\tremaining: 2.06s\n",
      "170:\tlearn: 0.0035363\ttotal: 1.07s\tremaining: 2.06s\n",
      "171:\tlearn: 0.0035362\ttotal: 1.07s\tremaining: 2.04s\n",
      "172:\tlearn: 0.0035357\ttotal: 1.08s\tremaining: 2.03s\n",
      "173:\tlearn: 0.0035355\ttotal: 1.08s\tremaining: 2.02s\n",
      "174:\tlearn: 0.0035350\ttotal: 1.08s\tremaining: 2.01s\n",
      "175:\tlearn: 0.0035349\ttotal: 1.09s\tremaining: 2.01s\n",
      "176:\tlearn: 0.0035346\ttotal: 1.1s\tremaining: 2.01s\n",
      "177:\tlearn: 0.0035346\ttotal: 1.11s\tremaining: 2.01s\n",
      "178:\tlearn: 0.0035342\ttotal: 1.12s\tremaining: 2.01s\n",
      "179:\tlearn: 0.0035342\ttotal: 1.13s\tremaining: 2.01s\n",
      "180:\tlearn: 0.0035342\ttotal: 1.14s\tremaining: 2.01s\n",
      "181:\tlearn: 0.0035338\ttotal: 1.15s\tremaining: 2.01s\n",
      "182:\tlearn: 0.0035338\ttotal: 1.16s\tremaining: 2.01s\n",
      "183:\tlearn: 0.0035339\ttotal: 1.17s\tremaining: 2s\n",
      "184:\tlearn: 0.0035339\ttotal: 1.17s\tremaining: 1.99s\n",
      "185:\tlearn: 0.0035339\ttotal: 1.17s\tremaining: 1.98s\n",
      "186:\tlearn: 0.0035339\ttotal: 1.18s\tremaining: 1.97s\n",
      "187:\tlearn: 0.0035339\ttotal: 1.18s\tremaining: 1.96s\n",
      "188:\tlearn: 0.0035339\ttotal: 1.19s\tremaining: 1.95s\n",
      "189:\tlearn: 0.0035338\ttotal: 1.19s\tremaining: 1.94s\n",
      "190:\tlearn: 0.0035335\ttotal: 1.2s\tremaining: 1.93s\n",
      "191:\tlearn: 0.0035334\ttotal: 1.2s\tremaining: 1.92s\n",
      "192:\tlearn: 0.0035331\ttotal: 1.2s\tremaining: 1.91s\n",
      "193:\tlearn: 0.0035330\ttotal: 1.21s\tremaining: 1.9s\n",
      "194:\tlearn: 0.0035323\ttotal: 1.21s\tremaining: 1.9s\n",
      "195:\tlearn: 0.0035321\ttotal: 1.22s\tremaining: 1.89s\n",
      "196:\tlearn: 0.0035320\ttotal: 1.22s\tremaining: 1.88s\n",
      "197:\tlearn: 0.0035319\ttotal: 1.22s\tremaining: 1.87s\n",
      "198:\tlearn: 0.0035318\ttotal: 1.23s\tremaining: 1.87s\n",
      "199:\tlearn: 0.0035316\ttotal: 1.24s\tremaining: 1.86s\n",
      "200:\tlearn: 0.0035315\ttotal: 1.25s\tremaining: 1.86s\n",
      "201:\tlearn: 0.0035314\ttotal: 1.26s\tremaining: 1.86s\n",
      "202:\tlearn: 0.0035313\ttotal: 1.27s\tremaining: 1.86s\n",
      "203:\tlearn: 0.0035313\ttotal: 1.28s\tremaining: 1.86s\n",
      "204:\tlearn: 0.0035311\ttotal: 1.29s\tremaining: 1.86s\n",
      "205:\tlearn: 0.0035310\ttotal: 1.3s\tremaining: 1.85s\n",
      "206:\tlearn: 0.0035307\ttotal: 1.31s\tremaining: 1.85s\n",
      "207:\tlearn: 0.0035307\ttotal: 1.32s\tremaining: 1.85s\n",
      "208:\tlearn: 0.0035307\ttotal: 1.32s\tremaining: 1.84s\n",
      "209:\tlearn: 0.0035306\ttotal: 1.32s\tremaining: 1.83s\n",
      "210:\tlearn: 0.0035304\ttotal: 1.33s\tremaining: 1.82s\n",
      "211:\tlearn: 0.0035304\ttotal: 1.33s\tremaining: 1.81s\n",
      "212:\tlearn: 0.0035303\ttotal: 1.34s\tremaining: 1.8s\n",
      "213:\tlearn: 0.0035301\ttotal: 1.34s\tremaining: 1.79s\n",
      "214:\tlearn: 0.0034401\ttotal: 1.35s\tremaining: 1.79s\n",
      "215:\tlearn: 0.0034401\ttotal: 1.35s\tremaining: 1.78s\n",
      "216:\tlearn: 0.0034394\ttotal: 1.36s\tremaining: 1.77s\n",
      "217:\tlearn: 0.0032928\ttotal: 1.36s\tremaining: 1.76s\n",
      "218:\tlearn: 0.0031684\ttotal: 1.36s\tremaining: 1.75s\n",
      "219:\tlearn: 0.0031682\ttotal: 1.37s\tremaining: 1.74s\n",
      "220:\tlearn: 0.0031681\ttotal: 1.37s\tremaining: 1.73s\n",
      "221:\tlearn: 0.0031681\ttotal: 1.38s\tremaining: 1.73s\n",
      "222:\tlearn: 0.0031681\ttotal: 1.38s\tremaining: 1.72s\n",
      "223:\tlearn: 0.0031680\ttotal: 1.39s\tremaining: 1.71s\n",
      "224:\tlearn: 0.0031675\ttotal: 1.39s\tremaining: 1.7s\n",
      "225:\tlearn: 0.0031675\ttotal: 1.39s\tremaining: 1.69s\n",
      "226:\tlearn: 0.0031674\ttotal: 1.4s\tremaining: 1.68s\n",
      "227:\tlearn: 0.0031674\ttotal: 1.41s\tremaining: 1.68s\n",
      "228:\tlearn: 0.0031674\ttotal: 1.42s\tremaining: 1.68s\n",
      "229:\tlearn: 0.0031673\ttotal: 1.43s\tremaining: 1.67s\n",
      "230:\tlearn: 0.0031673\ttotal: 1.43s\tremaining: 1.67s\n",
      "231:\tlearn: 0.0031672\ttotal: 1.44s\tremaining: 1.67s\n",
      "232:\tlearn: 0.0031671\ttotal: 1.45s\tremaining: 1.66s\n",
      "233:\tlearn: 0.0031668\ttotal: 1.46s\tremaining: 1.66s\n",
      "234:\tlearn: 0.0031667\ttotal: 1.47s\tremaining: 1.66s\n",
      "235:\tlearn: 0.0031666\ttotal: 1.48s\tremaining: 1.65s\n",
      "236:\tlearn: 0.0031666\ttotal: 1.48s\tremaining: 1.65s\n",
      "237:\tlearn: 0.0031664\ttotal: 1.49s\tremaining: 1.64s\n",
      "238:\tlearn: 0.0031664\ttotal: 1.5s\tremaining: 1.64s\n",
      "239:\tlearn: 0.0031663\ttotal: 1.5s\tremaining: 1.63s\n",
      "240:\tlearn: 0.0031661\ttotal: 1.51s\tremaining: 1.62s\n",
      "241:\tlearn: 0.0031660\ttotal: 1.51s\tremaining: 1.61s\n",
      "242:\tlearn: 0.0031660\ttotal: 1.52s\tremaining: 1.6s\n",
      "243:\tlearn: 0.0031657\ttotal: 1.52s\tremaining: 1.6s\n",
      "244:\tlearn: 0.0031656\ttotal: 1.52s\tremaining: 1.59s\n",
      "245:\tlearn: 0.0031646\ttotal: 1.53s\tremaining: 1.58s\n",
      "246:\tlearn: 0.0031646\ttotal: 1.53s\tremaining: 1.57s\n",
      "247:\tlearn: 0.0031646\ttotal: 1.54s\tremaining: 1.56s\n",
      "248:\tlearn: 0.0031646\ttotal: 1.54s\tremaining: 1.55s\n",
      "249:\tlearn: 0.0031645\ttotal: 1.54s\tremaining: 1.54s\n",
      "250:\tlearn: 0.0031642\ttotal: 1.55s\tremaining: 1.54s\n",
      "251:\tlearn: 0.0030420\ttotal: 1.55s\tremaining: 1.53s\n",
      "252:\tlearn: 0.0030420\ttotal: 1.56s\tremaining: 1.52s\n",
      "253:\tlearn: 0.0030420\ttotal: 1.57s\tremaining: 1.52s\n",
      "254:\tlearn: 0.0030420\ttotal: 1.58s\tremaining: 1.51s\n",
      "255:\tlearn: 0.0030418\ttotal: 1.59s\tremaining: 1.51s\n",
      "256:\tlearn: 0.0030418\ttotal: 1.6s\tremaining: 1.51s\n",
      "257:\tlearn: 0.0030418\ttotal: 1.61s\tremaining: 1.51s\n",
      "258:\tlearn: 0.0030368\ttotal: 1.62s\tremaining: 1.5s\n",
      "259:\tlearn: 0.0030364\ttotal: 1.62s\tremaining: 1.5s\n",
      "260:\tlearn: 0.0030364\ttotal: 1.63s\tremaining: 1.49s\n",
      "261:\tlearn: 0.0030364\ttotal: 1.64s\tremaining: 1.49s\n",
      "262:\tlearn: 0.0030362\ttotal: 1.64s\tremaining: 1.48s\n",
      "263:\tlearn: 0.0030361\ttotal: 1.65s\tremaining: 1.47s\n",
      "264:\tlearn: 0.0030361\ttotal: 1.65s\tremaining: 1.47s\n",
      "265:\tlearn: 0.0030361\ttotal: 1.66s\tremaining: 1.46s\n",
      "266:\tlearn: 0.0030361\ttotal: 1.66s\tremaining: 1.45s\n",
      "267:\tlearn: 0.0030361\ttotal: 1.67s\tremaining: 1.44s\n",
      "268:\tlearn: 0.0030359\ttotal: 1.67s\tremaining: 1.43s\n",
      "269:\tlearn: 0.0030358\ttotal: 1.68s\tremaining: 1.43s\n",
      "270:\tlearn: 0.0030358\ttotal: 1.68s\tremaining: 1.42s\n",
      "271:\tlearn: 0.0030354\ttotal: 1.68s\tremaining: 1.41s\n",
      "272:\tlearn: 0.0030353\ttotal: 1.69s\tremaining: 1.4s\n",
      "273:\tlearn: 0.0030353\ttotal: 1.69s\tremaining: 1.39s\n",
      "274:\tlearn: 0.0030351\ttotal: 1.69s\tremaining: 1.39s\n",
      "275:\tlearn: 0.0030351\ttotal: 1.7s\tremaining: 1.38s\n",
      "276:\tlearn: 0.0030348\ttotal: 1.7s\tremaining: 1.37s\n",
      "277:\tlearn: 0.0030347\ttotal: 1.71s\tremaining: 1.36s\n",
      "278:\tlearn: 0.0030346\ttotal: 1.71s\tremaining: 1.35s\n",
      "279:\tlearn: 0.0030342\ttotal: 1.72s\tremaining: 1.35s\n",
      "280:\tlearn: 0.0030342\ttotal: 1.72s\tremaining: 1.34s\n",
      "281:\tlearn: 0.0030342\ttotal: 1.72s\tremaining: 1.33s\n",
      "282:\tlearn: 0.0030341\ttotal: 1.73s\tremaining: 1.32s\n",
      "283:\tlearn: 0.0030336\ttotal: 1.73s\tremaining: 1.32s\n",
      "284:\tlearn: 0.0030335\ttotal: 1.74s\tremaining: 1.31s\n",
      "285:\tlearn: 0.0030335\ttotal: 1.75s\tremaining: 1.31s\n",
      "286:\tlearn: 0.0029438\ttotal: 1.76s\tremaining: 1.31s\n",
      "287:\tlearn: 0.0028435\ttotal: 1.77s\tremaining: 1.3s\n",
      "288:\tlearn: 0.0028429\ttotal: 1.78s\tremaining: 1.3s\n",
      "289:\tlearn: 0.0028428\ttotal: 1.79s\tremaining: 1.29s\n",
      "290:\tlearn: 0.0028426\ttotal: 1.8s\tremaining: 1.29s\n",
      "291:\tlearn: 0.0028425\ttotal: 1.81s\tremaining: 1.29s\n",
      "292:\tlearn: 0.0028423\ttotal: 1.82s\tremaining: 1.28s\n",
      "293:\tlearn: 0.0028422\ttotal: 1.82s\tremaining: 1.28s\n",
      "294:\tlearn: 0.0028420\ttotal: 1.83s\tremaining: 1.27s\n",
      "295:\tlearn: 0.0027460\ttotal: 1.84s\tremaining: 1.27s\n",
      "296:\tlearn: 0.0027455\ttotal: 1.85s\tremaining: 1.26s\n",
      "297:\tlearn: 0.0027454\ttotal: 1.85s\tremaining: 1.25s\n",
      "298:\tlearn: 0.0027453\ttotal: 1.86s\tremaining: 1.25s\n",
      "299:\tlearn: 0.0027453\ttotal: 1.86s\tremaining: 1.24s\n",
      "300:\tlearn: 0.0027453\ttotal: 1.87s\tremaining: 1.23s\n",
      "301:\tlearn: 0.0027454\ttotal: 1.87s\tremaining: 1.23s\n",
      "302:\tlearn: 0.0027451\ttotal: 1.87s\tremaining: 1.22s\n",
      "303:\tlearn: 0.0027451\ttotal: 1.88s\tremaining: 1.21s\n",
      "304:\tlearn: 0.0027450\ttotal: 1.88s\tremaining: 1.2s\n",
      "305:\tlearn: 0.0027449\ttotal: 1.89s\tremaining: 1.2s\n",
      "306:\tlearn: 0.0027449\ttotal: 1.89s\tremaining: 1.19s\n",
      "307:\tlearn: 0.0027449\ttotal: 1.89s\tremaining: 1.18s\n",
      "308:\tlearn: 0.0027447\ttotal: 1.9s\tremaining: 1.17s\n",
      "309:\tlearn: 0.0027439\ttotal: 1.91s\tremaining: 1.17s\n",
      "310:\tlearn: 0.0026680\ttotal: 1.92s\tremaining: 1.16s\n",
      "311:\tlearn: 0.0026672\ttotal: 1.93s\tremaining: 1.16s\n",
      "312:\tlearn: 0.0026672\ttotal: 1.94s\tremaining: 1.16s\n",
      "313:\tlearn: 0.0026671\ttotal: 1.95s\tremaining: 1.15s\n",
      "314:\tlearn: 0.0026670\ttotal: 1.95s\tremaining: 1.15s\n",
      "315:\tlearn: 0.0026670\ttotal: 1.96s\tremaining: 1.14s\n",
      "316:\tlearn: 0.0026670\ttotal: 1.97s\tremaining: 1.14s\n",
      "317:\tlearn: 0.0026670\ttotal: 1.98s\tremaining: 1.13s\n",
      "318:\tlearn: 0.0026670\ttotal: 1.99s\tremaining: 1.13s\n",
      "319:\tlearn: 0.0026670\ttotal: 2s\tremaining: 1.12s\n",
      "320:\tlearn: 0.0026670\ttotal: 2s\tremaining: 1.12s\n",
      "321:\tlearn: 0.0026669\ttotal: 2.01s\tremaining: 1.11s\n",
      "322:\tlearn: 0.0026661\ttotal: 2.02s\tremaining: 1.1s\n",
      "323:\tlearn: 0.0026658\ttotal: 2.02s\tremaining: 1.1s\n",
      "324:\tlearn: 0.0026658\ttotal: 2.02s\tremaining: 1.09s\n",
      "325:\tlearn: 0.0026658\ttotal: 2.03s\tremaining: 1.08s\n",
      "326:\tlearn: 0.0026658\ttotal: 2.03s\tremaining: 1.07s\n",
      "327:\tlearn: 0.0026658\ttotal: 2.04s\tremaining: 1.07s\n",
      "328:\tlearn: 0.0026655\ttotal: 2.04s\tremaining: 1.06s\n",
      "329:\tlearn: 0.0026651\ttotal: 2.04s\tremaining: 1.05s\n",
      "330:\tlearn: 0.0026649\ttotal: 2.05s\tremaining: 1.05s\n",
      "331:\tlearn: 0.0026647\ttotal: 2.05s\tremaining: 1.04s\n",
      "332:\tlearn: 0.0026641\ttotal: 2.06s\tremaining: 1.03s\n",
      "333:\tlearn: 0.0026639\ttotal: 2.06s\tremaining: 1.02s\n",
      "334:\tlearn: 0.0026598\ttotal: 2.07s\tremaining: 1.02s\n",
      "335:\tlearn: 0.0026597\ttotal: 2.07s\tremaining: 1.01s\n",
      "336:\tlearn: 0.0026596\ttotal: 2.08s\tremaining: 1s\n",
      "337:\tlearn: 0.0026596\ttotal: 2.08s\tremaining: 999ms\n",
      "338:\tlearn: 0.0026591\ttotal: 2.09s\tremaining: 995ms\n",
      "339:\tlearn: 0.0026583\ttotal: 2.1s\tremaining: 990ms\n",
      "340:\tlearn: 0.0026582\ttotal: 2.11s\tremaining: 985ms\n",
      "341:\tlearn: 0.0026582\ttotal: 2.12s\tremaining: 981ms\n",
      "342:\tlearn: 0.0026582\ttotal: 2.13s\tremaining: 976ms\n",
      "343:\tlearn: 0.0026581\ttotal: 2.14s\tremaining: 971ms\n",
      "344:\tlearn: 0.0026579\ttotal: 2.15s\tremaining: 966ms\n",
      "345:\tlearn: 0.0026579\ttotal: 2.16s\tremaining: 960ms\n",
      "346:\tlearn: 0.0026579\ttotal: 2.16s\tremaining: 954ms\n",
      "347:\tlearn: 0.0026579\ttotal: 2.17s\tremaining: 948ms\n",
      "348:\tlearn: 0.0026579\ttotal: 2.17s\tremaining: 941ms\n",
      "349:\tlearn: 0.0026579\ttotal: 2.18s\tremaining: 935ms\n",
      "350:\tlearn: 0.0026579\ttotal: 2.19s\tremaining: 928ms\n",
      "351:\tlearn: 0.0026579\ttotal: 2.19s\tremaining: 921ms\n",
      "352:\tlearn: 0.0026579\ttotal: 2.19s\tremaining: 914ms\n",
      "353:\tlearn: 0.0026579\ttotal: 2.2s\tremaining: 907ms\n",
      "354:\tlearn: 0.0026579\ttotal: 2.21s\tremaining: 901ms\n",
      "355:\tlearn: 0.0026579\ttotal: 2.21s\tremaining: 893ms\n",
      "356:\tlearn: 0.0026579\ttotal: 2.21s\tremaining: 886ms\n",
      "357:\tlearn: 0.0026579\ttotal: 2.21s\tremaining: 878ms\n",
      "358:\tlearn: 0.0026579\ttotal: 2.22s\tremaining: 871ms\n",
      "359:\tlearn: 0.0026579\ttotal: 2.22s\tremaining: 864ms\n",
      "360:\tlearn: 0.0026579\ttotal: 2.23s\tremaining: 857ms\n",
      "361:\tlearn: 0.0026579\ttotal: 2.23s\tremaining: 851ms\n",
      "362:\tlearn: 0.0026579\ttotal: 2.23s\tremaining: 843ms\n",
      "363:\tlearn: 0.0026579\ttotal: 2.24s\tremaining: 836ms\n",
      "364:\tlearn: 0.0026579\ttotal: 2.24s\tremaining: 829ms\n",
      "365:\tlearn: 0.0026579\ttotal: 2.24s\tremaining: 822ms\n",
      "366:\tlearn: 0.0026579\ttotal: 2.25s\tremaining: 814ms\n",
      "367:\tlearn: 0.0026579\ttotal: 2.25s\tremaining: 807ms\n",
      "368:\tlearn: 0.0026579\ttotal: 2.25s\tremaining: 800ms\n",
      "369:\tlearn: 0.0026579\ttotal: 2.26s\tremaining: 793ms\n",
      "370:\tlearn: 0.0026579\ttotal: 2.26s\tremaining: 787ms\n",
      "371:\tlearn: 0.0026579\ttotal: 2.27s\tremaining: 780ms\n",
      "372:\tlearn: 0.0026579\ttotal: 2.27s\tremaining: 773ms\n",
      "373:\tlearn: 0.0026579\ttotal: 2.28s\tremaining: 768ms\n",
      "374:\tlearn: 0.0026579\ttotal: 2.29s\tremaining: 763ms\n",
      "375:\tlearn: 0.0026579\ttotal: 2.3s\tremaining: 758ms\n",
      "376:\tlearn: 0.0026579\ttotal: 2.31s\tremaining: 753ms\n",
      "377:\tlearn: 0.0026579\ttotal: 2.32s\tremaining: 748ms\n",
      "378:\tlearn: 0.0026579\ttotal: 2.33s\tremaining: 742ms\n",
      "379:\tlearn: 0.0026579\ttotal: 2.33s\tremaining: 737ms\n",
      "380:\tlearn: 0.0026579\ttotal: 2.34s\tremaining: 732ms\n",
      "381:\tlearn: 0.0026579\ttotal: 2.35s\tremaining: 727ms\n",
      "382:\tlearn: 0.0026579\ttotal: 2.36s\tremaining: 721ms\n",
      "383:\tlearn: 0.0026579\ttotal: 2.37s\tremaining: 715ms\n",
      "384:\tlearn: 0.0026579\ttotal: 2.37s\tremaining: 709ms\n",
      "385:\tlearn: 0.0026579\ttotal: 2.38s\tremaining: 703ms\n",
      "386:\tlearn: 0.0026579\ttotal: 2.39s\tremaining: 697ms\n",
      "387:\tlearn: 0.0026579\ttotal: 2.39s\tremaining: 690ms\n",
      "388:\tlearn: 0.0026579\ttotal: 2.41s\tremaining: 689ms\n",
      "389:\tlearn: 0.0026579\ttotal: 2.42s\tremaining: 682ms\n",
      "390:\tlearn: 0.0026579\ttotal: 2.42s\tremaining: 675ms\n",
      "391:\tlearn: 0.0026579\ttotal: 2.42s\tremaining: 668ms\n",
      "392:\tlearn: 0.0026579\ttotal: 2.43s\tremaining: 661ms\n",
      "393:\tlearn: 0.0026579\ttotal: 2.43s\tremaining: 654ms\n",
      "394:\tlearn: 0.0026579\ttotal: 2.43s\tremaining: 647ms\n",
      "395:\tlearn: 0.0026579\ttotal: 2.44s\tremaining: 640ms\n",
      "396:\tlearn: 0.0026579\ttotal: 2.44s\tremaining: 634ms\n",
      "397:\tlearn: 0.0026579\ttotal: 2.45s\tremaining: 628ms\n",
      "398:\tlearn: 0.0026579\ttotal: 2.46s\tremaining: 623ms\n",
      "399:\tlearn: 0.0026579\ttotal: 2.47s\tremaining: 618ms\n",
      "400:\tlearn: 0.0026579\ttotal: 2.48s\tremaining: 612ms\n",
      "401:\tlearn: 0.0026579\ttotal: 2.49s\tremaining: 607ms\n",
      "402:\tlearn: 0.0026579\ttotal: 2.5s\tremaining: 601ms\n",
      "403:\tlearn: 0.0026579\ttotal: 2.51s\tremaining: 596ms\n",
      "404:\tlearn: 0.0026579\ttotal: 2.52s\tremaining: 591ms\n",
      "405:\tlearn: 0.0026579\ttotal: 2.53s\tremaining: 585ms\n",
      "406:\tlearn: 0.0026579\ttotal: 2.53s\tremaining: 579ms\n",
      "407:\tlearn: 0.0026579\ttotal: 2.54s\tremaining: 573ms\n",
      "408:\tlearn: 0.0026579\ttotal: 2.55s\tremaining: 567ms\n",
      "409:\tlearn: 0.0026579\ttotal: 2.55s\tremaining: 560ms\n",
      "410:\tlearn: 0.0026579\ttotal: 2.56s\tremaining: 554ms\n",
      "411:\tlearn: 0.0026579\ttotal: 2.56s\tremaining: 548ms\n",
      "412:\tlearn: 0.0026579\ttotal: 2.57s\tremaining: 541ms\n",
      "413:\tlearn: 0.0026579\ttotal: 2.58s\tremaining: 535ms\n",
      "414:\tlearn: 0.0026579\ttotal: 2.58s\tremaining: 528ms\n",
      "415:\tlearn: 0.0026579\ttotal: 2.58s\tremaining: 521ms\n",
      "416:\tlearn: 0.0026579\ttotal: 2.58s\tremaining: 515ms\n",
      "417:\tlearn: 0.0026579\ttotal: 2.59s\tremaining: 508ms\n",
      "418:\tlearn: 0.0026579\ttotal: 2.59s\tremaining: 501ms\n",
      "419:\tlearn: 0.0026579\ttotal: 2.6s\tremaining: 495ms\n",
      "420:\tlearn: 0.0026579\ttotal: 2.6s\tremaining: 488ms\n",
      "421:\tlearn: 0.0026579\ttotal: 2.6s\tremaining: 481ms\n",
      "422:\tlearn: 0.0026579\ttotal: 2.61s\tremaining: 475ms\n",
      "423:\tlearn: 0.0026579\ttotal: 2.61s\tremaining: 468ms\n",
      "424:\tlearn: 0.0026579\ttotal: 2.62s\tremaining: 462ms\n",
      "425:\tlearn: 0.0026579\ttotal: 2.63s\tremaining: 456ms\n",
      "426:\tlearn: 0.0026579\ttotal: 2.63s\tremaining: 450ms\n",
      "427:\tlearn: 0.0026579\ttotal: 2.64s\tremaining: 445ms\n",
      "428:\tlearn: 0.0026579\ttotal: 2.65s\tremaining: 439ms\n",
      "429:\tlearn: 0.0026579\ttotal: 2.66s\tremaining: 433ms\n",
      "430:\tlearn: 0.0026579\ttotal: 2.67s\tremaining: 428ms\n",
      "431:\tlearn: 0.0026579\ttotal: 2.68s\tremaining: 422ms\n",
      "432:\tlearn: 0.0026579\ttotal: 2.69s\tremaining: 416ms\n",
      "433:\tlearn: 0.0026579\ttotal: 2.7s\tremaining: 410ms\n",
      "434:\tlearn: 0.0026579\ttotal: 2.71s\tremaining: 405ms\n",
      "435:\tlearn: 0.0026579\ttotal: 2.71s\tremaining: 398ms\n",
      "436:\tlearn: 0.0026579\ttotal: 2.72s\tremaining: 392ms\n",
      "437:\tlearn: 0.0026579\ttotal: 2.73s\tremaining: 386ms\n",
      "438:\tlearn: 0.0026579\ttotal: 2.73s\tremaining: 380ms\n",
      "439:\tlearn: 0.0026579\ttotal: 2.73s\tremaining: 373ms\n",
      "440:\tlearn: 0.0026579\ttotal: 2.74s\tremaining: 367ms\n",
      "441:\tlearn: 0.0026579\ttotal: 2.74s\tremaining: 360ms\n",
      "442:\tlearn: 0.0026579\ttotal: 2.75s\tremaining: 354ms\n",
      "443:\tlearn: 0.0026579\ttotal: 2.75s\tremaining: 347ms\n",
      "444:\tlearn: 0.0026579\ttotal: 2.76s\tremaining: 341ms\n",
      "445:\tlearn: 0.0026579\ttotal: 2.76s\tremaining: 334ms\n",
      "446:\tlearn: 0.0026579\ttotal: 2.77s\tremaining: 328ms\n",
      "447:\tlearn: 0.0026579\ttotal: 2.77s\tremaining: 321ms\n",
      "448:\tlearn: 0.0026579\ttotal: 2.77s\tremaining: 315ms\n",
      "449:\tlearn: 0.0026579\ttotal: 2.78s\tremaining: 309ms\n",
      "450:\tlearn: 0.0026579\ttotal: 2.78s\tremaining: 302ms\n",
      "451:\tlearn: 0.0026579\ttotal: 2.79s\tremaining: 296ms\n",
      "452:\tlearn: 0.0026579\ttotal: 2.79s\tremaining: 289ms\n",
      "453:\tlearn: 0.0026579\ttotal: 2.79s\tremaining: 283ms\n",
      "454:\tlearn: 0.0026579\ttotal: 2.8s\tremaining: 277ms\n",
      "455:\tlearn: 0.0026579\ttotal: 2.8s\tremaining: 270ms\n",
      "456:\tlearn: 0.0026579\ttotal: 2.8s\tremaining: 264ms\n",
      "457:\tlearn: 0.0026579\ttotal: 2.81s\tremaining: 257ms\n",
      "458:\tlearn: 0.0026579\ttotal: 2.81s\tremaining: 251ms\n",
      "459:\tlearn: 0.0026579\ttotal: 2.81s\tremaining: 245ms\n",
      "460:\tlearn: 0.0026579\ttotal: 2.83s\tremaining: 239ms\n",
      "461:\tlearn: 0.0026579\ttotal: 2.83s\tremaining: 233ms\n",
      "462:\tlearn: 0.0026579\ttotal: 2.84s\tremaining: 227ms\n",
      "463:\tlearn: 0.0026579\ttotal: 2.85s\tremaining: 221ms\n",
      "464:\tlearn: 0.0026579\ttotal: 2.86s\tremaining: 216ms\n",
      "465:\tlearn: 0.0026579\ttotal: 2.87s\tremaining: 210ms\n",
      "466:\tlearn: 0.0026579\ttotal: 2.88s\tremaining: 203ms\n",
      "467:\tlearn: 0.0026579\ttotal: 2.88s\tremaining: 197ms\n",
      "468:\tlearn: 0.0026579\ttotal: 2.89s\tremaining: 191ms\n",
      "469:\tlearn: 0.0026579\ttotal: 2.89s\tremaining: 185ms\n",
      "470:\tlearn: 0.0026579\ttotal: 2.9s\tremaining: 179ms\n",
      "471:\tlearn: 0.0026579\ttotal: 2.91s\tremaining: 172ms\n",
      "472:\tlearn: 0.0026579\ttotal: 2.91s\tremaining: 166ms\n",
      "473:\tlearn: 0.0026579\ttotal: 2.92s\tremaining: 160ms\n",
      "474:\tlearn: 0.0026579\ttotal: 2.92s\tremaining: 154ms\n",
      "475:\tlearn: 0.0026579\ttotal: 2.92s\tremaining: 148ms\n",
      "476:\tlearn: 0.0026579\ttotal: 2.93s\tremaining: 141ms\n",
      "477:\tlearn: 0.0026579\ttotal: 2.93s\tremaining: 135ms\n",
      "478:\tlearn: 0.0026579\ttotal: 2.94s\tremaining: 129ms\n",
      "479:\tlearn: 0.0026579\ttotal: 2.94s\tremaining: 123ms\n",
      "480:\tlearn: 0.0026579\ttotal: 2.94s\tremaining: 116ms\n",
      "481:\tlearn: 0.0026579\ttotal: 2.95s\tremaining: 110ms\n",
      "482:\tlearn: 0.0026579\ttotal: 2.96s\tremaining: 104ms\n",
      "483:\tlearn: 0.0026579\ttotal: 2.97s\tremaining: 98.3ms\n",
      "484:\tlearn: 0.0026579\ttotal: 2.98s\tremaining: 92.2ms\n",
      "485:\tlearn: 0.0026579\ttotal: 2.99s\tremaining: 86.2ms\n",
      "486:\tlearn: 0.0026579\ttotal: 3s\tremaining: 80.1ms\n",
      "487:\tlearn: 0.0026579\ttotal: 3.01s\tremaining: 74ms\n",
      "488:\tlearn: 0.0026579\ttotal: 3.02s\tremaining: 67.9ms\n",
      "489:\tlearn: 0.0026579\ttotal: 3.03s\tremaining: 61.8ms\n",
      "490:\tlearn: 0.0026579\ttotal: 3.04s\tremaining: 55.7ms\n",
      "491:\tlearn: 0.0026579\ttotal: 3.04s\tremaining: 49.5ms\n",
      "492:\tlearn: 0.0026579\ttotal: 3.05s\tremaining: 43.3ms\n",
      "493:\tlearn: 0.0026579\ttotal: 3.05s\tremaining: 37.1ms\n",
      "494:\tlearn: 0.0026579\ttotal: 3.06s\tremaining: 30.9ms\n",
      "495:\tlearn: 0.0026579\ttotal: 3.06s\tremaining: 24.7ms\n",
      "496:\tlearn: 0.0026579\ttotal: 3.07s\tremaining: 18.5ms\n",
      "497:\tlearn: 0.0026579\ttotal: 3.07s\tremaining: 12.3ms\n",
      "498:\tlearn: 0.0026579\ttotal: 3.08s\tremaining: 6.17ms\n",
      "499:\tlearn: 0.0026579\ttotal: 3.08s\tremaining: 0us\n",
      "0:\tlearn: 0.5826843\ttotal: 10.8ms\tremaining: 1.07s\n",
      "1:\tlearn: 0.5066623\ttotal: 20.2ms\tremaining: 992ms\n",
      "2:\tlearn: 0.4517355\ttotal: 29.8ms\tremaining: 963ms\n",
      "3:\tlearn: 0.3948944\ttotal: 34.4ms\tremaining: 825ms\n",
      "4:\tlearn: 0.3612427\ttotal: 42.7ms\tremaining: 811ms\n",
      "5:\tlearn: 0.3069601\ttotal: 51ms\tremaining: 799ms\n",
      "6:\tlearn: 0.2759419\ttotal: 59.4ms\tremaining: 789ms\n",
      "7:\tlearn: 0.2365192\ttotal: 70.3ms\tremaining: 809ms\n",
      "8:\tlearn: 0.2079364\ttotal: 97.4ms\tremaining: 985ms\n",
      "9:\tlearn: 0.1816791\ttotal: 121ms\tremaining: 1.09s\n",
      "10:\tlearn: 0.1547032\ttotal: 143ms\tremaining: 1.15s\n",
      "11:\tlearn: 0.1351867\ttotal: 157ms\tremaining: 1.15s\n",
      "12:\tlearn: 0.1149012\ttotal: 175ms\tremaining: 1.17s\n",
      "13:\tlearn: 0.0967390\ttotal: 185ms\tremaining: 1.13s\n",
      "14:\tlearn: 0.0840105\ttotal: 194ms\tremaining: 1.1s\n",
      "15:\tlearn: 0.0708120\ttotal: 203ms\tremaining: 1.07s\n",
      "16:\tlearn: 0.0615277\ttotal: 212ms\tremaining: 1.04s\n",
      "17:\tlearn: 0.0537675\ttotal: 221ms\tremaining: 1.01s\n",
      "18:\tlearn: 0.0483860\ttotal: 229ms\tremaining: 977ms\n",
      "19:\tlearn: 0.0446540\ttotal: 237ms\tremaining: 949ms\n",
      "20:\tlearn: 0.0396895\ttotal: 262ms\tremaining: 986ms\n",
      "21:\tlearn: 0.0335224\ttotal: 289ms\tremaining: 1.02s\n",
      "22:\tlearn: 0.0292634\ttotal: 313ms\tremaining: 1.05s\n",
      "23:\tlearn: 0.0239080\ttotal: 323ms\tremaining: 1.02s\n",
      "24:\tlearn: 0.0210345\ttotal: 332ms\tremaining: 996ms\n",
      "25:\tlearn: 0.0193963\ttotal: 341ms\tremaining: 971ms\n",
      "26:\tlearn: 0.0181268\ttotal: 350ms\tremaining: 946ms\n",
      "27:\tlearn: 0.0173302\ttotal: 358ms\tremaining: 920ms\n",
      "28:\tlearn: 0.0162962\ttotal: 366ms\tremaining: 896ms\n",
      "29:\tlearn: 0.0153272\ttotal: 387ms\tremaining: 902ms\n",
      "30:\tlearn: 0.0143366\ttotal: 410ms\tremaining: 913ms\n",
      "31:\tlearn: 0.0129918\ttotal: 435ms\tremaining: 925ms\n",
      "32:\tlearn: 0.0117100\ttotal: 462ms\tremaining: 939ms\n",
      "33:\tlearn: 0.0109845\ttotal: 476ms\tremaining: 924ms\n",
      "34:\tlearn: 0.0104286\ttotal: 493ms\tremaining: 916ms\n",
      "35:\tlearn: 0.0097578\ttotal: 505ms\tremaining: 898ms\n",
      "36:\tlearn: 0.0088419\ttotal: 515ms\tremaining: 876ms\n",
      "37:\tlearn: 0.0082662\ttotal: 523ms\tremaining: 854ms\n",
      "38:\tlearn: 0.0078063\ttotal: 531ms\tremaining: 830ms\n",
      "39:\tlearn: 0.0074524\ttotal: 539ms\tremaining: 809ms\n",
      "40:\tlearn: 0.0071463\ttotal: 547ms\tremaining: 788ms\n",
      "41:\tlearn: 0.0069082\ttotal: 573ms\tremaining: 792ms\n",
      "42:\tlearn: 0.0062093\ttotal: 599ms\tremaining: 794ms\n",
      "43:\tlearn: 0.0057466\ttotal: 625ms\tremaining: 796ms\n",
      "44:\tlearn: 0.0052520\ttotal: 646ms\tremaining: 789ms\n",
      "45:\tlearn: 0.0050641\ttotal: 659ms\tremaining: 774ms\n",
      "46:\tlearn: 0.0044055\ttotal: 673ms\tremaining: 758ms\n",
      "47:\tlearn: 0.0041700\ttotal: 682ms\tremaining: 739ms\n",
      "48:\tlearn: 0.0036716\ttotal: 692ms\tremaining: 720ms\n",
      "49:\tlearn: 0.0035018\ttotal: 701ms\tremaining: 701ms\n",
      "50:\tlearn: 0.0032354\ttotal: 709ms\tremaining: 681ms\n",
      "51:\tlearn: 0.0032352\ttotal: 717ms\tremaining: 662ms\n",
      "52:\tlearn: 0.0028810\ttotal: 730ms\tremaining: 647ms\n",
      "53:\tlearn: 0.0027276\ttotal: 756ms\tremaining: 644ms\n",
      "54:\tlearn: 0.0025556\ttotal: 782ms\tremaining: 640ms\n",
      "55:\tlearn: 0.0025549\ttotal: 809ms\tremaining: 635ms\n",
      "56:\tlearn: 0.0025548\ttotal: 827ms\tremaining: 624ms\n",
      "57:\tlearn: 0.0025547\ttotal: 840ms\tremaining: 609ms\n",
      "58:\tlearn: 0.0025545\ttotal: 853ms\tremaining: 593ms\n",
      "59:\tlearn: 0.0025542\ttotal: 862ms\tremaining: 575ms\n",
      "60:\tlearn: 0.0025541\ttotal: 872ms\tremaining: 557ms\n",
      "61:\tlearn: 0.0025540\ttotal: 879ms\tremaining: 539ms\n",
      "62:\tlearn: 0.0023548\ttotal: 887ms\tremaining: 521ms\n",
      "63:\tlearn: 0.0023547\ttotal: 896ms\tremaining: 504ms\n",
      "64:\tlearn: 0.0023546\ttotal: 903ms\tremaining: 486ms\n",
      "65:\tlearn: 0.0023545\ttotal: 927ms\tremaining: 478ms\n",
      "66:\tlearn: 0.0023544\ttotal: 951ms\tremaining: 469ms\n",
      "67:\tlearn: 0.0023543\ttotal: 968ms\tremaining: 456ms\n",
      "68:\tlearn: 0.0023541\ttotal: 979ms\tremaining: 440ms\n",
      "69:\tlearn: 0.0023541\ttotal: 988ms\tremaining: 424ms\n",
      "70:\tlearn: 0.0022386\ttotal: 997ms\tremaining: 407ms\n",
      "71:\tlearn: 0.0022385\ttotal: 1s\tremaining: 391ms\n",
      "72:\tlearn: 0.0022381\ttotal: 1.01s\tremaining: 375ms\n",
      "73:\tlearn: 0.0022378\ttotal: 1.02s\tremaining: 359ms\n",
      "74:\tlearn: 0.0022377\ttotal: 1.05s\tremaining: 349ms\n",
      "75:\tlearn: 0.0020479\ttotal: 1.07s\tremaining: 339ms\n",
      "76:\tlearn: 0.0020476\ttotal: 1.1s\tremaining: 329ms\n",
      "77:\tlearn: 0.0019018\ttotal: 1.12s\tremaining: 316ms\n",
      "78:\tlearn: 0.0019016\ttotal: 1.13s\tremaining: 302ms\n",
      "79:\tlearn: 0.0019014\ttotal: 1.15s\tremaining: 287ms\n",
      "80:\tlearn: 0.0019014\ttotal: 1.16s\tremaining: 271ms\n",
      "81:\tlearn: 0.0019011\ttotal: 1.17s\tremaining: 256ms\n",
      "82:\tlearn: 0.0019010\ttotal: 1.18s\tremaining: 241ms\n",
      "83:\tlearn: 0.0019009\ttotal: 1.18s\tremaining: 226ms\n",
      "84:\tlearn: 0.0019008\ttotal: 1.19s\tremaining: 210ms\n",
      "85:\tlearn: 0.0019008\ttotal: 1.2s\tremaining: 195ms\n",
      "86:\tlearn: 0.0019008\ttotal: 1.21s\tremaining: 180ms\n",
      "87:\tlearn: 0.0017795\ttotal: 1.23s\tremaining: 168ms\n",
      "88:\tlearn: 0.0017787\ttotal: 1.25s\tremaining: 155ms\n",
      "89:\tlearn: 0.0017787\ttotal: 1.28s\tremaining: 142ms\n",
      "90:\tlearn: 0.0017787\ttotal: 1.3s\tremaining: 129ms\n",
      "91:\tlearn: 0.0017785\ttotal: 1.32s\tremaining: 115ms\n",
      "92:\tlearn: 0.0017785\ttotal: 1.35s\tremaining: 101ms\n",
      "93:\tlearn: 0.0017065\ttotal: 1.37s\tremaining: 87.4ms\n",
      "94:\tlearn: 0.0017065\ttotal: 1.38s\tremaining: 72.5ms\n",
      "95:\tlearn: 0.0017065\ttotal: 1.39s\tremaining: 57.8ms\n",
      "96:\tlearn: 0.0017063\ttotal: 1.4s\tremaining: 43.2ms\n",
      "97:\tlearn: 0.0017063\ttotal: 1.4s\tremaining: 28.7ms\n",
      "98:\tlearn: 0.0017062\ttotal: 1.41s\tremaining: 14.3ms\n",
      "99:\tlearn: 0.0017062\ttotal: 1.42s\tremaining: 0us\n",
      "0:\tlearn: 0.5849470\ttotal: 10.6ms\tremaining: 1.05s\n",
      "1:\tlearn: 0.5113353\ttotal: 20.8ms\tremaining: 1.02s\n",
      "2:\tlearn: 0.4398414\ttotal: 30.6ms\tremaining: 991ms\n",
      "3:\tlearn: 0.3811666\ttotal: 40.1ms\tremaining: 963ms\n",
      "4:\tlearn: 0.3540827\ttotal: 49ms\tremaining: 930ms\n",
      "5:\tlearn: 0.3017938\ttotal: 57.4ms\tremaining: 898ms\n",
      "6:\tlearn: 0.2652799\ttotal: 67.7ms\tremaining: 900ms\n",
      "7:\tlearn: 0.2317990\ttotal: 75.7ms\tremaining: 870ms\n",
      "8:\tlearn: 0.2013792\ttotal: 98.4ms\tremaining: 995ms\n",
      "9:\tlearn: 0.1760783\ttotal: 122ms\tremaining: 1.09s\n",
      "10:\tlearn: 0.1504062\ttotal: 146ms\tremaining: 1.18s\n",
      "11:\tlearn: 0.1291091\ttotal: 161ms\tremaining: 1.18s\n",
      "12:\tlearn: 0.1108112\ttotal: 168ms\tremaining: 1.12s\n",
      "13:\tlearn: 0.0993431\ttotal: 176ms\tremaining: 1.08s\n",
      "14:\tlearn: 0.0877746\ttotal: 185ms\tremaining: 1.05s\n",
      "15:\tlearn: 0.0768273\ttotal: 193ms\tremaining: 1.01s\n",
      "16:\tlearn: 0.0683790\ttotal: 201ms\tremaining: 983ms\n",
      "17:\tlearn: 0.0633716\ttotal: 210ms\tremaining: 957ms\n",
      "18:\tlearn: 0.0582078\ttotal: 219ms\tremaining: 934ms\n",
      "19:\tlearn: 0.0515028\ttotal: 228ms\tremaining: 912ms\n",
      "20:\tlearn: 0.0462555\ttotal: 237ms\tremaining: 891ms\n",
      "21:\tlearn: 0.0406007\ttotal: 245ms\tremaining: 869ms\n",
      "22:\tlearn: 0.0329963\ttotal: 258ms\tremaining: 863ms\n",
      "23:\tlearn: 0.0297792\ttotal: 271ms\tremaining: 858ms\n",
      "24:\tlearn: 0.0261736\ttotal: 286ms\tremaining: 859ms\n",
      "25:\tlearn: 0.0230747\ttotal: 299ms\tremaining: 852ms\n",
      "26:\tlearn: 0.0223990\ttotal: 313ms\tremaining: 845ms\n",
      "27:\tlearn: 0.0205180\ttotal: 327ms\tremaining: 841ms\n",
      "28:\tlearn: 0.0195623\ttotal: 337ms\tremaining: 825ms\n",
      "29:\tlearn: 0.0184842\ttotal: 345ms\tremaining: 806ms\n",
      "30:\tlearn: 0.0180026\ttotal: 354ms\tremaining: 787ms\n",
      "31:\tlearn: 0.0160205\ttotal: 362ms\tremaining: 769ms\n",
      "32:\tlearn: 0.0147165\ttotal: 370ms\tremaining: 751ms\n",
      "33:\tlearn: 0.0141355\ttotal: 394ms\tremaining: 766ms\n",
      "34:\tlearn: 0.0132643\ttotal: 422ms\tremaining: 783ms\n",
      "35:\tlearn: 0.0124481\ttotal: 453ms\tremaining: 805ms\n",
      "36:\tlearn: 0.0113171\ttotal: 467ms\tremaining: 795ms\n",
      "37:\tlearn: 0.0112359\ttotal: 481ms\tremaining: 784ms\n",
      "38:\tlearn: 0.0101652\ttotal: 492ms\tremaining: 769ms\n",
      "39:\tlearn: 0.0097277\ttotal: 501ms\tremaining: 752ms\n",
      "40:\tlearn: 0.0088421\ttotal: 510ms\tremaining: 735ms\n",
      "41:\tlearn: 0.0077830\ttotal: 519ms\tremaining: 716ms\n",
      "42:\tlearn: 0.0070364\ttotal: 527ms\tremaining: 699ms\n",
      "43:\tlearn: 0.0064617\ttotal: 535ms\tremaining: 681ms\n",
      "44:\tlearn: 0.0060732\ttotal: 551ms\tremaining: 674ms\n",
      "45:\tlearn: 0.0055758\ttotal: 576ms\tremaining: 676ms\n",
      "46:\tlearn: 0.0053697\ttotal: 602ms\tremaining: 679ms\n",
      "47:\tlearn: 0.0050426\ttotal: 626ms\tremaining: 679ms\n",
      "48:\tlearn: 0.0047647\ttotal: 637ms\tremaining: 662ms\n",
      "49:\tlearn: 0.0044515\ttotal: 647ms\tremaining: 647ms\n",
      "50:\tlearn: 0.0043584\ttotal: 657ms\tremaining: 631ms\n",
      "51:\tlearn: 0.0040661\ttotal: 672ms\tremaining: 621ms\n",
      "52:\tlearn: 0.0040661\ttotal: 688ms\tremaining: 610ms\n",
      "53:\tlearn: 0.0040661\ttotal: 714ms\tremaining: 609ms\n",
      "54:\tlearn: 0.0039173\ttotal: 740ms\tremaining: 605ms\n",
      "55:\tlearn: 0.0039171\ttotal: 753ms\tremaining: 592ms\n",
      "56:\tlearn: 0.0039169\ttotal: 767ms\tremaining: 579ms\n",
      "57:\tlearn: 0.0039161\ttotal: 777ms\tremaining: 563ms\n",
      "58:\tlearn: 0.0039160\ttotal: 787ms\tremaining: 547ms\n",
      "59:\tlearn: 0.0039160\ttotal: 796ms\tremaining: 531ms\n",
      "60:\tlearn: 0.0039156\ttotal: 805ms\tremaining: 514ms\n",
      "61:\tlearn: 0.0039155\ttotal: 813ms\tremaining: 498ms\n",
      "62:\tlearn: 0.0039154\ttotal: 821ms\tremaining: 482ms\n",
      "63:\tlearn: 0.0039153\ttotal: 840ms\tremaining: 472ms\n",
      "64:\tlearn: 0.0039151\ttotal: 864ms\tremaining: 465ms\n",
      "65:\tlearn: 0.0039150\ttotal: 891ms\tremaining: 459ms\n",
      "66:\tlearn: 0.0039150\ttotal: 919ms\tremaining: 453ms\n",
      "67:\tlearn: 0.0039150\ttotal: 933ms\tremaining: 439ms\n",
      "68:\tlearn: 0.0039150\ttotal: 946ms\tremaining: 425ms\n",
      "69:\tlearn: 0.0039148\ttotal: 956ms\tremaining: 410ms\n",
      "70:\tlearn: 0.0039147\ttotal: 966ms\tremaining: 394ms\n",
      "71:\tlearn: 0.0039147\ttotal: 975ms\tremaining: 379ms\n",
      "72:\tlearn: 0.0039094\ttotal: 984ms\tremaining: 364ms\n",
      "73:\tlearn: 0.0039091\ttotal: 992ms\tremaining: 348ms\n",
      "74:\tlearn: 0.0039084\ttotal: 1s\tremaining: 333ms\n",
      "75:\tlearn: 0.0039083\ttotal: 1.01s\tremaining: 320ms\n",
      "76:\tlearn: 0.0039079\ttotal: 1.04s\tremaining: 310ms\n",
      "77:\tlearn: 0.0038979\ttotal: 1.06s\tremaining: 300ms\n",
      "78:\tlearn: 0.0038971\ttotal: 1.09s\tremaining: 289ms\n",
      "79:\tlearn: 0.0038970\ttotal: 1.1s\tremaining: 275ms\n",
      "80:\tlearn: 0.0038970\ttotal: 1.11s\tremaining: 261ms\n",
      "81:\tlearn: 0.0038919\ttotal: 1.12s\tremaining: 247ms\n",
      "82:\tlearn: 0.0037326\ttotal: 1.13s\tremaining: 232ms\n",
      "83:\tlearn: 0.0033180\ttotal: 1.14s\tremaining: 218ms\n",
      "84:\tlearn: 0.0031627\ttotal: 1.15s\tremaining: 203ms\n",
      "85:\tlearn: 0.0030203\ttotal: 1.16s\tremaining: 189ms\n",
      "86:\tlearn: 0.0028445\ttotal: 1.17s\tremaining: 175ms\n",
      "87:\tlearn: 0.0025952\ttotal: 1.19s\tremaining: 162ms\n",
      "88:\tlearn: 0.0024423\ttotal: 1.21s\tremaining: 150ms\n",
      "89:\tlearn: 0.0024421\ttotal: 1.24s\tremaining: 137ms\n",
      "90:\tlearn: 0.0024420\ttotal: 1.26s\tremaining: 125ms\n",
      "91:\tlearn: 0.0022594\ttotal: 1.27s\tremaining: 111ms\n",
      "92:\tlearn: 0.0022592\ttotal: 1.28s\tremaining: 96.5ms\n",
      "93:\tlearn: 0.0021263\ttotal: 1.29s\tremaining: 82.5ms\n",
      "94:\tlearn: 0.0021263\ttotal: 1.3s\tremaining: 68.4ms\n",
      "95:\tlearn: 0.0021262\ttotal: 1.31s\tremaining: 54.5ms\n",
      "96:\tlearn: 0.0021262\ttotal: 1.31s\tremaining: 40.7ms\n",
      "97:\tlearn: 0.0021262\ttotal: 1.32s\tremaining: 27ms\n",
      "98:\tlearn: 0.0021259\ttotal: 1.35s\tremaining: 13.6ms\n",
      "99:\tlearn: 0.0021259\ttotal: 1.37s\tremaining: 0us\n",
      "0:\tlearn: 0.5910499\ttotal: 10.4ms\tremaining: 1.03s\n",
      "1:\tlearn: 0.5006428\ttotal: 20.3ms\tremaining: 993ms\n",
      "2:\tlearn: 0.4415387\ttotal: 30ms\tremaining: 970ms\n",
      "3:\tlearn: 0.3904213\ttotal: 38.5ms\tremaining: 925ms\n",
      "4:\tlearn: 0.3396329\ttotal: 46.5ms\tremaining: 884ms\n",
      "5:\tlearn: 0.3001661\ttotal: 71.1ms\tremaining: 1.11s\n",
      "6:\tlearn: 0.2573073\ttotal: 96ms\tremaining: 1.27s\n",
      "7:\tlearn: 0.2086769\ttotal: 121ms\tremaining: 1.4s\n",
      "8:\tlearn: 0.1770144\ttotal: 141ms\tremaining: 1.43s\n",
      "9:\tlearn: 0.1554229\ttotal: 150ms\tremaining: 1.35s\n",
      "10:\tlearn: 0.1301899\ttotal: 160ms\tremaining: 1.29s\n",
      "11:\tlearn: 0.1166736\ttotal: 170ms\tremaining: 1.25s\n",
      "12:\tlearn: 0.1000646\ttotal: 178ms\tremaining: 1.19s\n",
      "13:\tlearn: 0.0864658\ttotal: 187ms\tremaining: 1.15s\n",
      "14:\tlearn: 0.0736389\ttotal: 196ms\tremaining: 1.11s\n",
      "15:\tlearn: 0.0648041\ttotal: 212ms\tremaining: 1.11s\n",
      "16:\tlearn: 0.0562670\ttotal: 236ms\tremaining: 1.15s\n",
      "17:\tlearn: 0.0502392\ttotal: 261ms\tremaining: 1.19s\n",
      "18:\tlearn: 0.0442232\ttotal: 284ms\tremaining: 1.21s\n",
      "19:\tlearn: 0.0390765\ttotal: 299ms\tremaining: 1.19s\n",
      "20:\tlearn: 0.0349505\ttotal: 312ms\tremaining: 1.17s\n",
      "21:\tlearn: 0.0316645\ttotal: 322ms\tremaining: 1.14s\n",
      "22:\tlearn: 0.0275945\ttotal: 331ms\tremaining: 1.11s\n",
      "23:\tlearn: 0.0244977\ttotal: 341ms\tremaining: 1.08s\n",
      "24:\tlearn: 0.0225274\ttotal: 349ms\tremaining: 1.05s\n",
      "25:\tlearn: 0.0209201\ttotal: 358ms\tremaining: 1.02s\n",
      "26:\tlearn: 0.0172574\ttotal: 366ms\tremaining: 990ms\n",
      "27:\tlearn: 0.0164919\ttotal: 374ms\tremaining: 962ms\n",
      "28:\tlearn: 0.0146272\ttotal: 399ms\tremaining: 977ms\n",
      "29:\tlearn: 0.0142120\ttotal: 428ms\tremaining: 998ms\n",
      "30:\tlearn: 0.0126035\ttotal: 452ms\tremaining: 1.01s\n",
      "31:\tlearn: 0.0116234\ttotal: 462ms\tremaining: 982ms\n",
      "32:\tlearn: 0.0106020\ttotal: 471ms\tremaining: 957ms\n",
      "33:\tlearn: 0.0099632\ttotal: 482ms\tremaining: 935ms\n",
      "34:\tlearn: 0.0095719\ttotal: 490ms\tremaining: 910ms\n",
      "35:\tlearn: 0.0083184\ttotal: 498ms\tremaining: 886ms\n",
      "36:\tlearn: 0.0075132\ttotal: 506ms\tremaining: 862ms\n",
      "37:\tlearn: 0.0071375\ttotal: 515ms\tremaining: 840ms\n",
      "38:\tlearn: 0.0065474\ttotal: 539ms\tremaining: 842ms\n",
      "39:\tlearn: 0.0061833\ttotal: 562ms\tremaining: 843ms\n",
      "40:\tlearn: 0.0056504\ttotal: 582ms\tremaining: 838ms\n",
      "41:\tlearn: 0.0053547\ttotal: 594ms\tremaining: 820ms\n",
      "42:\tlearn: 0.0053547\ttotal: 604ms\tremaining: 801ms\n",
      "43:\tlearn: 0.0053545\ttotal: 611ms\tremaining: 777ms\n",
      "44:\tlearn: 0.0051968\ttotal: 620ms\tremaining: 757ms\n",
      "45:\tlearn: 0.0047513\ttotal: 628ms\tremaining: 737ms\n",
      "46:\tlearn: 0.0044950\ttotal: 652ms\tremaining: 735ms\n",
      "47:\tlearn: 0.0041326\ttotal: 679ms\tremaining: 735ms\n",
      "48:\tlearn: 0.0041324\ttotal: 704ms\tremaining: 732ms\n",
      "49:\tlearn: 0.0039652\ttotal: 729ms\tremaining: 729ms\n",
      "50:\tlearn: 0.0035976\ttotal: 742ms\tremaining: 713ms\n",
      "51:\tlearn: 0.0035971\ttotal: 756ms\tremaining: 697ms\n",
      "52:\tlearn: 0.0035971\ttotal: 765ms\tremaining: 679ms\n",
      "53:\tlearn: 0.0035969\ttotal: 775ms\tremaining: 660ms\n",
      "54:\tlearn: 0.0035969\ttotal: 784ms\tremaining: 641ms\n",
      "55:\tlearn: 0.0035968\ttotal: 791ms\tremaining: 622ms\n",
      "56:\tlearn: 0.0035968\ttotal: 797ms\tremaining: 601ms\n",
      "57:\tlearn: 0.0035967\ttotal: 805ms\tremaining: 583ms\n",
      "58:\tlearn: 0.0035964\ttotal: 828ms\tremaining: 576ms\n",
      "59:\tlearn: 0.0035964\ttotal: 853ms\tremaining: 569ms\n",
      "60:\tlearn: 0.0035811\ttotal: 879ms\tremaining: 562ms\n",
      "61:\tlearn: 0.0035809\ttotal: 906ms\tremaining: 555ms\n",
      "62:\tlearn: 0.0034369\ttotal: 919ms\tremaining: 540ms\n",
      "63:\tlearn: 0.0032367\ttotal: 933ms\tremaining: 525ms\n",
      "64:\tlearn: 0.0031141\ttotal: 943ms\tremaining: 508ms\n",
      "65:\tlearn: 0.0029800\ttotal: 952ms\tremaining: 491ms\n",
      "66:\tlearn: 0.0029795\ttotal: 960ms\tremaining: 473ms\n",
      "67:\tlearn: 0.0029795\ttotal: 969ms\tremaining: 456ms\n",
      "68:\tlearn: 0.0029794\ttotal: 977ms\tremaining: 439ms\n",
      "69:\tlearn: 0.0029793\ttotal: 994ms\tremaining: 426ms\n",
      "70:\tlearn: 0.0028692\ttotal: 1.02s\tremaining: 417ms\n",
      "71:\tlearn: 0.0028076\ttotal: 1.04s\tremaining: 407ms\n",
      "72:\tlearn: 0.0026136\ttotal: 1.07s\tremaining: 397ms\n",
      "73:\tlearn: 0.0026109\ttotal: 1.09s\tremaining: 382ms\n",
      "74:\tlearn: 0.0026108\ttotal: 1.1s\tremaining: 366ms\n",
      "75:\tlearn: 0.0026107\ttotal: 1.11s\tremaining: 350ms\n",
      "76:\tlearn: 0.0026106\ttotal: 1.12s\tremaining: 334ms\n",
      "77:\tlearn: 0.0026105\ttotal: 1.13s\tremaining: 318ms\n",
      "78:\tlearn: 0.0024446\ttotal: 1.14s\tremaining: 302ms\n",
      "79:\tlearn: 0.0023247\ttotal: 1.14s\tremaining: 286ms\n",
      "80:\tlearn: 0.0023245\ttotal: 1.15s\tremaining: 270ms\n",
      "81:\tlearn: 0.0023244\ttotal: 1.16s\tremaining: 255ms\n",
      "82:\tlearn: 0.0023243\ttotal: 1.19s\tremaining: 244ms\n",
      "83:\tlearn: 0.0022297\ttotal: 1.21s\tremaining: 231ms\n",
      "84:\tlearn: 0.0022297\ttotal: 1.24s\tremaining: 219ms\n",
      "85:\tlearn: 0.0022289\ttotal: 1.25s\tremaining: 204ms\n",
      "86:\tlearn: 0.0022288\ttotal: 1.27s\tremaining: 190ms\n",
      "87:\tlearn: 0.0022288\ttotal: 1.28s\tremaining: 174ms\n",
      "88:\tlearn: 0.0022288\ttotal: 1.29s\tremaining: 159ms\n",
      "89:\tlearn: 0.0022288\ttotal: 1.3s\tremaining: 144ms\n",
      "90:\tlearn: 0.0022284\ttotal: 1.31s\tremaining: 129ms\n",
      "91:\tlearn: 0.0022284\ttotal: 1.31s\tremaining: 114ms\n",
      "92:\tlearn: 0.0022273\ttotal: 1.32s\tremaining: 99.6ms\n",
      "93:\tlearn: 0.0022272\ttotal: 1.33s\tremaining: 85ms\n",
      "94:\tlearn: 0.0022272\ttotal: 1.35s\tremaining: 71ms\n",
      "95:\tlearn: 0.0022269\ttotal: 1.37s\tremaining: 57.2ms\n",
      "96:\tlearn: 0.0022269\ttotal: 1.4s\tremaining: 43.2ms\n",
      "97:\tlearn: 0.0022268\ttotal: 1.42s\tremaining: 29ms\n",
      "98:\tlearn: 0.0022268\ttotal: 1.43s\tremaining: 14.5ms\n",
      "99:\tlearn: 0.0022268\ttotal: 1.45s\tremaining: 0us\n",
      "0:\tlearn: 0.5882423\ttotal: 10.8ms\tremaining: 1.07s\n",
      "1:\tlearn: 0.4994543\ttotal: 19.5ms\tremaining: 954ms\n",
      "2:\tlearn: 0.4346733\ttotal: 26.5ms\tremaining: 858ms\n",
      "3:\tlearn: 0.3754216\ttotal: 34.8ms\tremaining: 835ms\n",
      "4:\tlearn: 0.3289170\ttotal: 42.6ms\tremaining: 809ms\n",
      "5:\tlearn: 0.2832865\ttotal: 50.2ms\tremaining: 787ms\n",
      "6:\tlearn: 0.2488554\ttotal: 76.1ms\tremaining: 1.01s\n",
      "7:\tlearn: 0.2122903\ttotal: 104ms\tremaining: 1.2s\n",
      "8:\tlearn: 0.1730795\ttotal: 129ms\tremaining: 1.31s\n",
      "9:\tlearn: 0.1539869\ttotal: 143ms\tremaining: 1.28s\n",
      "10:\tlearn: 0.1334750\ttotal: 157ms\tremaining: 1.27s\n",
      "11:\tlearn: 0.1103350\ttotal: 168ms\tremaining: 1.23s\n",
      "12:\tlearn: 0.0969322\ttotal: 178ms\tremaining: 1.19s\n",
      "13:\tlearn: 0.0798187\ttotal: 187ms\tremaining: 1.15s\n",
      "14:\tlearn: 0.0645099\ttotal: 196ms\tremaining: 1.11s\n",
      "15:\tlearn: 0.0565114\ttotal: 205ms\tremaining: 1.07s\n",
      "16:\tlearn: 0.0466630\ttotal: 213ms\tremaining: 1.04s\n",
      "17:\tlearn: 0.0423583\ttotal: 229ms\tremaining: 1.04s\n",
      "18:\tlearn: 0.0361387\ttotal: 253ms\tremaining: 1.08s\n",
      "19:\tlearn: 0.0327916\ttotal: 281ms\tremaining: 1.12s\n",
      "20:\tlearn: 0.0299619\ttotal: 296ms\tremaining: 1.11s\n",
      "21:\tlearn: 0.0263075\ttotal: 310ms\tremaining: 1.1s\n",
      "22:\tlearn: 0.0247082\ttotal: 324ms\tremaining: 1.08s\n",
      "23:\tlearn: 0.0202422\ttotal: 338ms\tremaining: 1.07s\n",
      "24:\tlearn: 0.0178076\ttotal: 347ms\tremaining: 1.04s\n",
      "25:\tlearn: 0.0167977\ttotal: 357ms\tremaining: 1.02s\n",
      "26:\tlearn: 0.0156530\ttotal: 366ms\tremaining: 990ms\n",
      "27:\tlearn: 0.0136785\ttotal: 374ms\tremaining: 962ms\n",
      "28:\tlearn: 0.0126063\ttotal: 381ms\tremaining: 932ms\n",
      "29:\tlearn: 0.0112699\ttotal: 389ms\tremaining: 908ms\n",
      "30:\tlearn: 0.0107330\ttotal: 412ms\tremaining: 918ms\n",
      "31:\tlearn: 0.0100982\ttotal: 438ms\tremaining: 930ms\n",
      "32:\tlearn: 0.0094267\ttotal: 463ms\tremaining: 940ms\n",
      "33:\tlearn: 0.0086740\ttotal: 482ms\tremaining: 936ms\n",
      "34:\tlearn: 0.0082931\ttotal: 496ms\tremaining: 920ms\n",
      "35:\tlearn: 0.0080056\ttotal: 509ms\tremaining: 905ms\n",
      "36:\tlearn: 0.0072167\ttotal: 518ms\tremaining: 883ms\n",
      "37:\tlearn: 0.0070565\ttotal: 528ms\tremaining: 862ms\n",
      "38:\tlearn: 0.0065009\ttotal: 538ms\tremaining: 841ms\n",
      "39:\tlearn: 0.0061268\ttotal: 546ms\tremaining: 819ms\n",
      "40:\tlearn: 0.0059661\ttotal: 554ms\tremaining: 797ms\n",
      "41:\tlearn: 0.0056300\ttotal: 562ms\tremaining: 776ms\n",
      "42:\tlearn: 0.0053728\ttotal: 578ms\tremaining: 766ms\n",
      "43:\tlearn: 0.0051342\ttotal: 604ms\tremaining: 768ms\n",
      "44:\tlearn: 0.0046820\ttotal: 628ms\tremaining: 768ms\n",
      "45:\tlearn: 0.0041797\ttotal: 656ms\tremaining: 770ms\n",
      "46:\tlearn: 0.0040242\ttotal: 669ms\tremaining: 754ms\n",
      "47:\tlearn: 0.0038114\ttotal: 682ms\tremaining: 739ms\n",
      "48:\tlearn: 0.0036778\ttotal: 692ms\tremaining: 720ms\n",
      "49:\tlearn: 0.0033965\ttotal: 702ms\tremaining: 702ms\n",
      "50:\tlearn: 0.0032607\ttotal: 712ms\tremaining: 684ms\n",
      "51:\tlearn: 0.0032605\ttotal: 720ms\tremaining: 664ms\n",
      "52:\tlearn: 0.0032605\ttotal: 727ms\tremaining: 645ms\n",
      "53:\tlearn: 0.0031529\ttotal: 736ms\tremaining: 627ms\n",
      "54:\tlearn: 0.0031529\ttotal: 744ms\tremaining: 609ms\n",
      "55:\tlearn: 0.0031528\ttotal: 770ms\tremaining: 605ms\n",
      "56:\tlearn: 0.0030049\ttotal: 797ms\tremaining: 601ms\n",
      "57:\tlearn: 0.0027703\ttotal: 823ms\tremaining: 596ms\n",
      "58:\tlearn: 0.0026811\ttotal: 841ms\tremaining: 584ms\n",
      "59:\tlearn: 0.0026806\ttotal: 854ms\tremaining: 569ms\n",
      "60:\tlearn: 0.0026806\ttotal: 864ms\tremaining: 553ms\n",
      "61:\tlearn: 0.0026708\ttotal: 874ms\tremaining: 536ms\n",
      "62:\tlearn: 0.0025089\ttotal: 883ms\tremaining: 519ms\n",
      "63:\tlearn: 0.0022500\ttotal: 893ms\tremaining: 502ms\n",
      "64:\tlearn: 0.0021236\ttotal: 902ms\tremaining: 486ms\n",
      "65:\tlearn: 0.0021236\ttotal: 911ms\tremaining: 469ms\n",
      "66:\tlearn: 0.0021236\ttotal: 919ms\tremaining: 453ms\n",
      "67:\tlearn: 0.0021236\ttotal: 931ms\tremaining: 438ms\n",
      "68:\tlearn: 0.0021235\ttotal: 955ms\tremaining: 429ms\n",
      "69:\tlearn: 0.0021230\ttotal: 979ms\tremaining: 419ms\n",
      "70:\tlearn: 0.0021229\ttotal: 1s\tremaining: 409ms\n",
      "71:\tlearn: 0.0021229\ttotal: 1.01s\tremaining: 394ms\n",
      "72:\tlearn: 0.0021229\ttotal: 1.03s\tremaining: 380ms\n",
      "73:\tlearn: 0.0021229\ttotal: 1.04s\tremaining: 365ms\n",
      "74:\tlearn: 0.0021228\ttotal: 1.05s\tremaining: 350ms\n",
      "75:\tlearn: 0.0021226\ttotal: 1.06s\tremaining: 334ms\n",
      "76:\tlearn: 0.0020387\ttotal: 1.07s\tremaining: 319ms\n",
      "77:\tlearn: 0.0020385\ttotal: 1.08s\tremaining: 304ms\n",
      "78:\tlearn: 0.0020383\ttotal: 1.08s\tremaining: 288ms\n",
      "79:\tlearn: 0.0020382\ttotal: 1.09s\tremaining: 273ms\n",
      "80:\tlearn: 0.0020381\ttotal: 1.11s\tremaining: 260ms\n",
      "81:\tlearn: 0.0020379\ttotal: 1.14s\tremaining: 249ms\n",
      "82:\tlearn: 0.0020377\ttotal: 1.16s\tremaining: 239ms\n",
      "83:\tlearn: 0.0020377\ttotal: 1.19s\tremaining: 226ms\n",
      "84:\tlearn: 0.0020376\ttotal: 1.2s\tremaining: 212ms\n",
      "85:\tlearn: 0.0020376\ttotal: 1.21s\tremaining: 197ms\n",
      "86:\tlearn: 0.0020374\ttotal: 1.22s\tremaining: 182ms\n",
      "87:\tlearn: 0.0020374\ttotal: 1.23s\tremaining: 168ms\n",
      "88:\tlearn: 0.0020373\ttotal: 1.24s\tremaining: 153ms\n",
      "89:\tlearn: 0.0020373\ttotal: 1.25s\tremaining: 139ms\n",
      "90:\tlearn: 0.0020372\ttotal: 1.25s\tremaining: 124ms\n",
      "91:\tlearn: 0.0020372\ttotal: 1.26s\tremaining: 110ms\n",
      "92:\tlearn: 0.0020371\ttotal: 1.29s\tremaining: 96.9ms\n",
      "93:\tlearn: 0.0020369\ttotal: 1.31s\tremaining: 83.9ms\n",
      "94:\tlearn: 0.0020369\ttotal: 1.34s\tremaining: 70.6ms\n",
      "95:\tlearn: 0.0020369\ttotal: 1.36s\tremaining: 56.8ms\n",
      "96:\tlearn: 0.0020369\ttotal: 1.38s\tremaining: 42.6ms\n",
      "97:\tlearn: 0.0020369\ttotal: 1.39s\tremaining: 28.3ms\n",
      "98:\tlearn: 0.0020369\ttotal: 1.4s\tremaining: 14.1ms\n",
      "99:\tlearn: 0.0020369\ttotal: 1.41s\tremaining: 0us\n",
      "0:\tlearn: 0.5939043\ttotal: 11ms\tremaining: 1.09s\n",
      "1:\tlearn: 0.5078646\ttotal: 21.2ms\tremaining: 1.04s\n",
      "2:\tlearn: 0.4365178\ttotal: 30.2ms\tremaining: 976ms\n",
      "3:\tlearn: 0.3801647\ttotal: 37.5ms\tremaining: 899ms\n",
      "4:\tlearn: 0.3435835\ttotal: 45.8ms\tremaining: 871ms\n",
      "5:\tlearn: 0.3027309\ttotal: 64.9ms\tremaining: 1.02s\n",
      "6:\tlearn: 0.2679533\ttotal: 90.1ms\tremaining: 1.2s\n",
      "7:\tlearn: 0.2332685\ttotal: 114ms\tremaining: 1.31s\n",
      "8:\tlearn: 0.2070189\ttotal: 137ms\tremaining: 1.38s\n",
      "9:\tlearn: 0.1901556\ttotal: 147ms\tremaining: 1.32s\n",
      "10:\tlearn: 0.1600334\ttotal: 156ms\tremaining: 1.26s\n",
      "11:\tlearn: 0.1368602\ttotal: 166ms\tremaining: 1.22s\n",
      "12:\tlearn: 0.1139557\ttotal: 175ms\tremaining: 1.17s\n",
      "13:\tlearn: 0.1016627\ttotal: 183ms\tremaining: 1.13s\n",
      "14:\tlearn: 0.0828334\ttotal: 191ms\tremaining: 1.08s\n",
      "15:\tlearn: 0.0695724\ttotal: 208ms\tremaining: 1.09s\n",
      "16:\tlearn: 0.0626808\ttotal: 237ms\tremaining: 1.16s\n",
      "17:\tlearn: 0.0521683\ttotal: 261ms\tremaining: 1.19s\n",
      "18:\tlearn: 0.0465195\ttotal: 284ms\tremaining: 1.21s\n",
      "19:\tlearn: 0.0405344\ttotal: 301ms\tremaining: 1.2s\n",
      "20:\tlearn: 0.0339380\ttotal: 315ms\tremaining: 1.18s\n",
      "21:\tlearn: 0.0299130\ttotal: 324ms\tremaining: 1.15s\n",
      "22:\tlearn: 0.0262843\ttotal: 336ms\tremaining: 1.13s\n",
      "23:\tlearn: 0.0240461\ttotal: 346ms\tremaining: 1.1s\n",
      "24:\tlearn: 0.0220214\ttotal: 356ms\tremaining: 1.07s\n",
      "25:\tlearn: 0.0199306\ttotal: 365ms\tremaining: 1.04s\n",
      "26:\tlearn: 0.0178287\ttotal: 376ms\tremaining: 1.02s\n",
      "27:\tlearn: 0.0162514\ttotal: 402ms\tremaining: 1.03s\n",
      "28:\tlearn: 0.0159222\ttotal: 429ms\tremaining: 1.05s\n",
      "29:\tlearn: 0.0145557\ttotal: 452ms\tremaining: 1.05s\n",
      "30:\tlearn: 0.0130951\ttotal: 462ms\tremaining: 1.03s\n",
      "31:\tlearn: 0.0119630\ttotal: 472ms\tremaining: 1s\n",
      "32:\tlearn: 0.0109438\ttotal: 482ms\tremaining: 979ms\n",
      "33:\tlearn: 0.0098553\ttotal: 491ms\tremaining: 953ms\n",
      "34:\tlearn: 0.0095159\ttotal: 499ms\tremaining: 927ms\n",
      "35:\tlearn: 0.0091622\ttotal: 508ms\tremaining: 903ms\n",
      "36:\tlearn: 0.0081918\ttotal: 521ms\tremaining: 887ms\n",
      "37:\tlearn: 0.0078167\ttotal: 546ms\tremaining: 891ms\n",
      "38:\tlearn: 0.0072511\ttotal: 571ms\tremaining: 893ms\n",
      "39:\tlearn: 0.0068683\ttotal: 598ms\tremaining: 897ms\n",
      "40:\tlearn: 0.0066145\ttotal: 615ms\tremaining: 885ms\n",
      "41:\tlearn: 0.0062490\ttotal: 631ms\tremaining: 872ms\n",
      "42:\tlearn: 0.0059263\ttotal: 641ms\tremaining: 850ms\n",
      "43:\tlearn: 0.0054693\ttotal: 650ms\tremaining: 828ms\n",
      "44:\tlearn: 0.0052666\ttotal: 660ms\tremaining: 806ms\n",
      "45:\tlearn: 0.0051325\ttotal: 668ms\tremaining: 784ms\n",
      "46:\tlearn: 0.0046249\ttotal: 677ms\tremaining: 763ms\n",
      "47:\tlearn: 0.0043740\ttotal: 685ms\tremaining: 742ms\n",
      "48:\tlearn: 0.0040236\ttotal: 693ms\tremaining: 722ms\n",
      "49:\tlearn: 0.0035850\ttotal: 718ms\tremaining: 718ms\n",
      "50:\tlearn: 0.0034298\ttotal: 745ms\tremaining: 715ms\n",
      "51:\tlearn: 0.0033408\ttotal: 772ms\tremaining: 712ms\n",
      "52:\tlearn: 0.0031792\ttotal: 790ms\tremaining: 701ms\n",
      "53:\tlearn: 0.0028987\ttotal: 807ms\tremaining: 687ms\n",
      "54:\tlearn: 0.0028987\ttotal: 818ms\tremaining: 669ms\n",
      "55:\tlearn: 0.0028987\ttotal: 827ms\tremaining: 650ms\n",
      "56:\tlearn: 0.0028984\ttotal: 837ms\tremaining: 631ms\n",
      "57:\tlearn: 0.0028983\ttotal: 844ms\tremaining: 611ms\n",
      "58:\tlearn: 0.0028984\ttotal: 852ms\tremaining: 592ms\n",
      "59:\tlearn: 0.0028983\ttotal: 861ms\tremaining: 574ms\n",
      "60:\tlearn: 0.0026909\ttotal: 885ms\tremaining: 566ms\n",
      "61:\tlearn: 0.0025622\ttotal: 911ms\tremaining: 558ms\n",
      "62:\tlearn: 0.0025617\ttotal: 939ms\tremaining: 552ms\n",
      "63:\tlearn: 0.0025616\ttotal: 957ms\tremaining: 538ms\n",
      "64:\tlearn: 0.0025616\ttotal: 970ms\tremaining: 523ms\n",
      "65:\tlearn: 0.0025614\ttotal: 984ms\tremaining: 507ms\n",
      "66:\tlearn: 0.0025614\ttotal: 995ms\tremaining: 490ms\n",
      "67:\tlearn: 0.0025613\ttotal: 1s\tremaining: 473ms\n",
      "68:\tlearn: 0.0025612\ttotal: 1.01s\tremaining: 455ms\n",
      "69:\tlearn: 0.0025610\ttotal: 1.02s\tremaining: 437ms\n",
      "70:\tlearn: 0.0025610\ttotal: 1.03s\tremaining: 420ms\n",
      "71:\tlearn: 0.0025609\ttotal: 1.04s\tremaining: 403ms\n",
      "72:\tlearn: 0.0025609\ttotal: 1.06s\tremaining: 393ms\n",
      "73:\tlearn: 0.0025600\ttotal: 1.09s\tremaining: 383ms\n",
      "74:\tlearn: 0.0025599\ttotal: 1.11s\tremaining: 371ms\n",
      "75:\tlearn: 0.0025598\ttotal: 1.14s\tremaining: 358ms\n",
      "76:\tlearn: 0.0025556\ttotal: 1.15s\tremaining: 343ms\n",
      "77:\tlearn: 0.0025555\ttotal: 1.16s\tremaining: 328ms\n",
      "78:\tlearn: 0.0024357\ttotal: 1.17s\tremaining: 312ms\n",
      "79:\tlearn: 0.0024357\ttotal: 1.18s\tremaining: 295ms\n",
      "80:\tlearn: 0.0024334\ttotal: 1.19s\tremaining: 279ms\n",
      "81:\tlearn: 0.0021849\ttotal: 1.2s\tremaining: 263ms\n",
      "82:\tlearn: 0.0021848\ttotal: 1.21s\tremaining: 247ms\n",
      "83:\tlearn: 0.0021847\ttotal: 1.23s\tremaining: 233ms\n",
      "84:\tlearn: 0.0021847\ttotal: 1.25s\tremaining: 221ms\n",
      "85:\tlearn: 0.0021841\ttotal: 1.27s\tremaining: 208ms\n",
      "86:\tlearn: 0.0021839\ttotal: 1.3s\tremaining: 194ms\n",
      "87:\tlearn: 0.0020204\ttotal: 1.32s\tremaining: 180ms\n",
      "88:\tlearn: 0.0020204\ttotal: 1.33s\tremaining: 164ms\n",
      "89:\tlearn: 0.0020203\ttotal: 1.34s\tremaining: 149ms\n",
      "90:\tlearn: 0.0018360\ttotal: 1.35s\tremaining: 134ms\n",
      "91:\tlearn: 0.0018359\ttotal: 1.36s\tremaining: 118ms\n",
      "92:\tlearn: 0.0018358\ttotal: 1.37s\tremaining: 103ms\n",
      "93:\tlearn: 0.0017614\ttotal: 1.38s\tremaining: 87.9ms\n",
      "94:\tlearn: 0.0017614\ttotal: 1.38s\tremaining: 72.9ms\n",
      "95:\tlearn: 0.0017614\ttotal: 1.41s\tremaining: 58.8ms\n",
      "96:\tlearn: 0.0016029\ttotal: 1.44s\tremaining: 44.4ms\n",
      "97:\tlearn: 0.0016028\ttotal: 1.45s\tremaining: 29.6ms\n",
      "98:\tlearn: 0.0016027\ttotal: 1.47s\tremaining: 14.8ms\n",
      "99:\tlearn: 0.0016027\ttotal: 1.48s\tremaining: 0us\n",
      "0:\tlearn: 0.5861879\ttotal: 8.28ms\tremaining: 819ms\n",
      "1:\tlearn: 0.4953830\ttotal: 16.7ms\tremaining: 818ms\n",
      "2:\tlearn: 0.4296443\ttotal: 24.5ms\tremaining: 794ms\n",
      "3:\tlearn: 0.3631065\ttotal: 33.2ms\tremaining: 798ms\n",
      "4:\tlearn: 0.3196085\ttotal: 41.6ms\tremaining: 790ms\n",
      "5:\tlearn: 0.2785345\ttotal: 53.1ms\tremaining: 833ms\n",
      "6:\tlearn: 0.2428009\ttotal: 79.6ms\tremaining: 1.06s\n",
      "7:\tlearn: 0.2069805\ttotal: 107ms\tremaining: 1.23s\n",
      "8:\tlearn: 0.1748071\ttotal: 133ms\tremaining: 1.34s\n",
      "9:\tlearn: 0.1489893\ttotal: 149ms\tremaining: 1.34s\n",
      "10:\tlearn: 0.1248100\ttotal: 163ms\tremaining: 1.31s\n",
      "11:\tlearn: 0.1073595\ttotal: 175ms\tremaining: 1.28s\n",
      "12:\tlearn: 0.0925975\ttotal: 185ms\tremaining: 1.24s\n",
      "13:\tlearn: 0.0781150\ttotal: 194ms\tremaining: 1.19s\n",
      "14:\tlearn: 0.0655751\ttotal: 200ms\tremaining: 1.14s\n",
      "15:\tlearn: 0.0589246\ttotal: 209ms\tremaining: 1.1s\n",
      "16:\tlearn: 0.0522143\ttotal: 217ms\tremaining: 1.06s\n",
      "17:\tlearn: 0.0446865\ttotal: 237ms\tremaining: 1.08s\n",
      "18:\tlearn: 0.0411304\ttotal: 262ms\tremaining: 1.12s\n",
      "19:\tlearn: 0.0357625\ttotal: 289ms\tremaining: 1.16s\n",
      "20:\tlearn: 0.0314774\ttotal: 312ms\tremaining: 1.17s\n",
      "21:\tlearn: 0.0261143\ttotal: 326ms\tremaining: 1.16s\n",
      "22:\tlearn: 0.0226197\ttotal: 340ms\tremaining: 1.14s\n",
      "23:\tlearn: 0.0197766\ttotal: 349ms\tremaining: 1.1s\n",
      "24:\tlearn: 0.0193047\ttotal: 359ms\tremaining: 1.08s\n",
      "25:\tlearn: 0.0178091\ttotal: 369ms\tremaining: 1.05s\n",
      "26:\tlearn: 0.0158946\ttotal: 377ms\tremaining: 1.02s\n",
      "27:\tlearn: 0.0139119\ttotal: 385ms\tremaining: 989ms\n",
      "28:\tlearn: 0.0130424\ttotal: 392ms\tremaining: 960ms\n",
      "29:\tlearn: 0.0115465\ttotal: 413ms\tremaining: 963ms\n",
      "30:\tlearn: 0.0102695\ttotal: 439ms\tremaining: 977ms\n",
      "31:\tlearn: 0.0099049\ttotal: 463ms\tremaining: 983ms\n",
      "32:\tlearn: 0.0092205\ttotal: 487ms\tremaining: 988ms\n",
      "33:\tlearn: 0.0085563\ttotal: 500ms\tremaining: 971ms\n",
      "34:\tlearn: 0.0071934\ttotal: 514ms\tremaining: 955ms\n",
      "35:\tlearn: 0.0066092\ttotal: 523ms\tremaining: 931ms\n",
      "36:\tlearn: 0.0057986\ttotal: 533ms\tremaining: 908ms\n",
      "37:\tlearn: 0.0053487\ttotal: 543ms\tremaining: 886ms\n",
      "38:\tlearn: 0.0053487\ttotal: 551ms\tremaining: 862ms\n",
      "39:\tlearn: 0.0053478\ttotal: 559ms\tremaining: 839ms\n",
      "40:\tlearn: 0.0053474\ttotal: 567ms\tremaining: 816ms\n",
      "41:\tlearn: 0.0052250\ttotal: 576ms\tremaining: 795ms\n",
      "42:\tlearn: 0.0050706\ttotal: 603ms\tremaining: 799ms\n",
      "43:\tlearn: 0.0046596\ttotal: 626ms\tremaining: 797ms\n",
      "44:\tlearn: 0.0045016\ttotal: 651ms\tremaining: 796ms\n",
      "45:\tlearn: 0.0043872\ttotal: 669ms\tremaining: 785ms\n",
      "46:\tlearn: 0.0042388\ttotal: 682ms\tremaining: 769ms\n",
      "47:\tlearn: 0.0040019\ttotal: 694ms\tremaining: 752ms\n",
      "48:\tlearn: 0.0036205\ttotal: 704ms\tremaining: 733ms\n",
      "49:\tlearn: 0.0035868\ttotal: 713ms\tremaining: 713ms\n",
      "50:\tlearn: 0.0035858\ttotal: 723ms\tremaining: 694ms\n",
      "51:\tlearn: 0.0035858\ttotal: 731ms\tremaining: 674ms\n",
      "52:\tlearn: 0.0035858\ttotal: 739ms\tremaining: 655ms\n",
      "53:\tlearn: 0.0033952\ttotal: 747ms\tremaining: 636ms\n",
      "54:\tlearn: 0.0031824\ttotal: 755ms\tremaining: 618ms\n",
      "55:\tlearn: 0.0029121\ttotal: 781ms\tremaining: 614ms\n",
      "56:\tlearn: 0.0027976\ttotal: 810ms\tremaining: 611ms\n",
      "57:\tlearn: 0.0026652\ttotal: 834ms\tremaining: 604ms\n",
      "58:\tlearn: 0.0026650\ttotal: 848ms\tremaining: 589ms\n",
      "59:\tlearn: 0.0026648\ttotal: 858ms\tremaining: 572ms\n",
      "60:\tlearn: 0.0026647\ttotal: 868ms\tremaining: 555ms\n",
      "61:\tlearn: 0.0026646\ttotal: 876ms\tremaining: 537ms\n",
      "62:\tlearn: 0.0026646\ttotal: 884ms\tremaining: 519ms\n",
      "63:\tlearn: 0.0024981\ttotal: 893ms\tremaining: 502ms\n",
      "64:\tlearn: 0.0024981\ttotal: 900ms\tremaining: 485ms\n",
      "65:\tlearn: 0.0024978\ttotal: 925ms\tremaining: 476ms\n",
      "66:\tlearn: 0.0024974\ttotal: 952ms\tremaining: 469ms\n",
      "67:\tlearn: 0.0024974\ttotal: 978ms\tremaining: 460ms\n",
      "68:\tlearn: 0.0024974\ttotal: 994ms\tremaining: 447ms\n",
      "69:\tlearn: 0.0024971\ttotal: 1.01s\tremaining: 433ms\n",
      "70:\tlearn: 0.0024970\ttotal: 1.02s\tremaining: 416ms\n",
      "71:\tlearn: 0.0024968\ttotal: 1.03s\tremaining: 400ms\n",
      "72:\tlearn: 0.0024968\ttotal: 1.04s\tremaining: 384ms\n",
      "73:\tlearn: 0.0024968\ttotal: 1.05s\tremaining: 368ms\n",
      "74:\tlearn: 0.0024967\ttotal: 1.05s\tremaining: 351ms\n",
      "75:\tlearn: 0.0024967\ttotal: 1.06s\tremaining: 336ms\n",
      "76:\tlearn: 0.0024966\ttotal: 1.09s\tremaining: 325ms\n",
      "77:\tlearn: 0.0024964\ttotal: 1.11s\tremaining: 314ms\n",
      "78:\tlearn: 0.0024962\ttotal: 1.14s\tremaining: 303ms\n",
      "79:\tlearn: 0.0024961\ttotal: 1.15s\tremaining: 289ms\n",
      "80:\tlearn: 0.0024960\ttotal: 1.17s\tremaining: 274ms\n",
      "81:\tlearn: 0.0024960\ttotal: 1.18s\tremaining: 259ms\n",
      "82:\tlearn: 0.0024960\ttotal: 1.19s\tremaining: 243ms\n",
      "83:\tlearn: 0.0024959\ttotal: 1.2s\tremaining: 228ms\n",
      "84:\tlearn: 0.0024957\ttotal: 1.2s\tremaining: 212ms\n",
      "85:\tlearn: 0.0024957\ttotal: 1.21s\tremaining: 197ms\n",
      "86:\tlearn: 0.0024955\ttotal: 1.22s\tremaining: 182ms\n",
      "87:\tlearn: 0.0024955\ttotal: 1.24s\tremaining: 170ms\n",
      "88:\tlearn: 0.0024955\ttotal: 1.27s\tremaining: 157ms\n",
      "89:\tlearn: 0.0024953\ttotal: 1.3s\tremaining: 144ms\n",
      "90:\tlearn: 0.0024950\ttotal: 1.32s\tremaining: 131ms\n",
      "91:\tlearn: 0.0024948\ttotal: 1.33s\tremaining: 116ms\n",
      "92:\tlearn: 0.0024947\ttotal: 1.35s\tremaining: 102ms\n",
      "93:\tlearn: 0.0024947\ttotal: 1.36s\tremaining: 86.7ms\n",
      "94:\tlearn: 0.0024945\ttotal: 1.37s\tremaining: 72ms\n",
      "95:\tlearn: 0.0024944\ttotal: 1.38s\tremaining: 57.3ms\n",
      "96:\tlearn: 0.0024943\ttotal: 1.38s\tremaining: 42.8ms\n",
      "97:\tlearn: 0.0024942\ttotal: 1.39s\tremaining: 28.5ms\n",
      "98:\tlearn: 0.0024942\ttotal: 1.4s\tremaining: 14.2ms\n",
      "99:\tlearn: 0.0024942\ttotal: 1.43s\tremaining: 0us\n",
      "0:\tlearn: 0.5959263\ttotal: 11ms\tremaining: 1.09s\n",
      "1:\tlearn: 0.4953445\ttotal: 20.5ms\tremaining: 1s\n",
      "2:\tlearn: 0.4305705\ttotal: 28.5ms\tremaining: 920ms\n",
      "3:\tlearn: 0.3636219\ttotal: 35.2ms\tremaining: 845ms\n",
      "4:\tlearn: 0.3067572\ttotal: 43.5ms\tremaining: 827ms\n",
      "5:\tlearn: 0.2695914\ttotal: 62.1ms\tremaining: 973ms\n",
      "6:\tlearn: 0.2378244\ttotal: 87.9ms\tremaining: 1.17s\n",
      "7:\tlearn: 0.2127582\ttotal: 112ms\tremaining: 1.28s\n",
      "8:\tlearn: 0.1888876\ttotal: 135ms\tremaining: 1.36s\n",
      "9:\tlearn: 0.1599847\ttotal: 149ms\tremaining: 1.34s\n",
      "10:\tlearn: 0.1386935\ttotal: 162ms\tremaining: 1.31s\n",
      "11:\tlearn: 0.1208475\ttotal: 172ms\tremaining: 1.26s\n",
      "12:\tlearn: 0.1014088\ttotal: 182ms\tremaining: 1.22s\n",
      "13:\tlearn: 0.0860533\ttotal: 191ms\tremaining: 1.17s\n",
      "14:\tlearn: 0.0728614\ttotal: 199ms\tremaining: 1.13s\n",
      "15:\tlearn: 0.0645658\ttotal: 207ms\tremaining: 1.09s\n",
      "16:\tlearn: 0.0584388\ttotal: 215ms\tremaining: 1.05s\n",
      "17:\tlearn: 0.0535829\ttotal: 239ms\tremaining: 1.09s\n",
      "18:\tlearn: 0.0473831\ttotal: 266ms\tremaining: 1.13s\n",
      "19:\tlearn: 0.0407826\ttotal: 295ms\tremaining: 1.18s\n",
      "20:\tlearn: 0.0377085\ttotal: 314ms\tremaining: 1.18s\n",
      "21:\tlearn: 0.0335333\ttotal: 327ms\tremaining: 1.16s\n",
      "22:\tlearn: 0.0298909\ttotal: 341ms\tremaining: 1.14s\n",
      "23:\tlearn: 0.0268796\ttotal: 350ms\tremaining: 1.11s\n",
      "24:\tlearn: 0.0253016\ttotal: 360ms\tremaining: 1.08s\n",
      "25:\tlearn: 0.0230636\ttotal: 370ms\tremaining: 1.05s\n",
      "26:\tlearn: 0.0208074\ttotal: 378ms\tremaining: 1.02s\n",
      "27:\tlearn: 0.0182673\ttotal: 386ms\tremaining: 993ms\n",
      "28:\tlearn: 0.0165004\ttotal: 395ms\tremaining: 966ms\n",
      "29:\tlearn: 0.0148313\ttotal: 405ms\tremaining: 945ms\n",
      "30:\tlearn: 0.0131202\ttotal: 432ms\tremaining: 962ms\n",
      "31:\tlearn: 0.0124378\ttotal: 460ms\tremaining: 977ms\n",
      "32:\tlearn: 0.0108299\ttotal: 489ms\tremaining: 992ms\n",
      "33:\tlearn: 0.0096729\ttotal: 502ms\tremaining: 975ms\n",
      "34:\tlearn: 0.0088988\ttotal: 514ms\tremaining: 955ms\n",
      "35:\tlearn: 0.0088985\ttotal: 523ms\tremaining: 931ms\n",
      "36:\tlearn: 0.0087465\ttotal: 533ms\tremaining: 907ms\n",
      "37:\tlearn: 0.0080973\ttotal: 542ms\tremaining: 885ms\n",
      "38:\tlearn: 0.0078222\ttotal: 552ms\tremaining: 863ms\n",
      "39:\tlearn: 0.0075321\ttotal: 560ms\tremaining: 840ms\n",
      "40:\tlearn: 0.0069559\ttotal: 569ms\tremaining: 818ms\n",
      "41:\tlearn: 0.0065147\ttotal: 577ms\tremaining: 797ms\n",
      "42:\tlearn: 0.0060629\ttotal: 589ms\tremaining: 781ms\n",
      "43:\tlearn: 0.0058641\ttotal: 614ms\tremaining: 782ms\n",
      "44:\tlearn: 0.0053105\ttotal: 639ms\tremaining: 781ms\n",
      "45:\tlearn: 0.0050833\ttotal: 659ms\tremaining: 774ms\n",
      "46:\tlearn: 0.0046471\ttotal: 673ms\tremaining: 759ms\n",
      "47:\tlearn: 0.0046411\ttotal: 687ms\tremaining: 744ms\n",
      "48:\tlearn: 0.0043986\ttotal: 696ms\tremaining: 724ms\n",
      "49:\tlearn: 0.0039368\ttotal: 706ms\tremaining: 706ms\n",
      "50:\tlearn: 0.0036337\ttotal: 716ms\tremaining: 687ms\n",
      "51:\tlearn: 0.0035481\ttotal: 724ms\tremaining: 669ms\n",
      "52:\tlearn: 0.0034502\ttotal: 733ms\tremaining: 650ms\n",
      "53:\tlearn: 0.0033053\ttotal: 741ms\tremaining: 631ms\n",
      "54:\tlearn: 0.0031903\ttotal: 749ms\tremaining: 612ms\n",
      "55:\tlearn: 0.0029638\ttotal: 775ms\tremaining: 609ms\n",
      "56:\tlearn: 0.0029638\ttotal: 798ms\tremaining: 602ms\n",
      "57:\tlearn: 0.0028325\ttotal: 822ms\tremaining: 595ms\n",
      "58:\tlearn: 0.0025644\ttotal: 836ms\tremaining: 581ms\n",
      "59:\tlearn: 0.0025644\ttotal: 846ms\tremaining: 564ms\n",
      "60:\tlearn: 0.0025644\ttotal: 855ms\tremaining: 547ms\n",
      "61:\tlearn: 0.0024366\ttotal: 863ms\tremaining: 529ms\n",
      "62:\tlearn: 0.0024365\ttotal: 871ms\tremaining: 512ms\n",
      "63:\tlearn: 0.0024363\ttotal: 879ms\tremaining: 495ms\n",
      "64:\tlearn: 0.0022464\ttotal: 888ms\tremaining: 478ms\n",
      "65:\tlearn: 0.0022464\ttotal: 904ms\tremaining: 466ms\n",
      "66:\tlearn: 0.0022462\ttotal: 927ms\tremaining: 457ms\n",
      "67:\tlearn: 0.0022461\ttotal: 952ms\tremaining: 448ms\n",
      "68:\tlearn: 0.0022461\ttotal: 965ms\tremaining: 434ms\n",
      "69:\tlearn: 0.0021238\ttotal: 977ms\tremaining: 419ms\n",
      "70:\tlearn: 0.0021237\ttotal: 985ms\tremaining: 402ms\n",
      "71:\tlearn: 0.0021236\ttotal: 993ms\tremaining: 386ms\n",
      "72:\tlearn: 0.0021235\ttotal: 1s\tremaining: 370ms\n",
      "73:\tlearn: 0.0021233\ttotal: 1.01s\tremaining: 354ms\n",
      "74:\tlearn: 0.0021233\ttotal: 1.03s\tremaining: 344ms\n",
      "75:\tlearn: 0.0021232\ttotal: 1.06s\tremaining: 335ms\n",
      "76:\tlearn: 0.0021232\ttotal: 1.08s\tremaining: 324ms\n",
      "77:\tlearn: 0.0021231\ttotal: 1.1s\tremaining: 311ms\n",
      "78:\tlearn: 0.0021231\ttotal: 1.11s\tremaining: 297ms\n",
      "79:\tlearn: 0.0020414\ttotal: 1.13s\tremaining: 282ms\n",
      "80:\tlearn: 0.0019992\ttotal: 1.14s\tremaining: 267ms\n",
      "81:\tlearn: 0.0019992\ttotal: 1.15s\tremaining: 252ms\n",
      "82:\tlearn: 0.0019992\ttotal: 1.16s\tremaining: 237ms\n",
      "83:\tlearn: 0.0019991\ttotal: 1.16s\tremaining: 222ms\n",
      "84:\tlearn: 0.0019992\ttotal: 1.17s\tremaining: 207ms\n",
      "85:\tlearn: 0.0019992\ttotal: 1.18s\tremaining: 192ms\n",
      "86:\tlearn: 0.0019990\ttotal: 1.19s\tremaining: 177ms\n",
      "87:\tlearn: 0.0019989\ttotal: 1.21s\tremaining: 165ms\n",
      "88:\tlearn: 0.0019988\ttotal: 1.23s\tremaining: 153ms\n",
      "89:\tlearn: 0.0019987\ttotal: 1.26s\tremaining: 140ms\n",
      "90:\tlearn: 0.0019987\ttotal: 1.28s\tremaining: 126ms\n",
      "91:\tlearn: 0.0019986\ttotal: 1.29s\tremaining: 112ms\n",
      "92:\tlearn: 0.0019985\ttotal: 1.3s\tremaining: 98.1ms\n",
      "93:\tlearn: 0.0019985\ttotal: 1.31s\tremaining: 83.8ms\n",
      "94:\tlearn: 0.0019984\ttotal: 1.32s\tremaining: 69.6ms\n",
      "95:\tlearn: 0.0019975\ttotal: 1.33s\tremaining: 55.5ms\n",
      "96:\tlearn: 0.0019975\ttotal: 1.34s\tremaining: 41.5ms\n",
      "97:\tlearn: 0.0019975\ttotal: 1.35s\tremaining: 27.5ms\n",
      "98:\tlearn: 0.0019975\ttotal: 1.35s\tremaining: 13.7ms\n",
      "99:\tlearn: 0.0019974\ttotal: 1.37s\tremaining: 0us\n",
      "0:\tlearn: 0.5937703\ttotal: 10.6ms\tremaining: 1.05s\n",
      "1:\tlearn: 0.5213630\ttotal: 20.5ms\tremaining: 1s\n",
      "2:\tlearn: 0.4441893\ttotal: 29.2ms\tremaining: 944ms\n",
      "3:\tlearn: 0.3844780\ttotal: 38.2ms\tremaining: 916ms\n",
      "4:\tlearn: 0.3379306\ttotal: 45.5ms\tremaining: 865ms\n",
      "5:\tlearn: 0.2957286\ttotal: 64.1ms\tremaining: 1s\n",
      "6:\tlearn: 0.2668444\ttotal: 90.3ms\tremaining: 1.2s\n",
      "7:\tlearn: 0.2348738\ttotal: 118ms\tremaining: 1.35s\n",
      "8:\tlearn: 0.1991615\ttotal: 143ms\tremaining: 1.45s\n",
      "9:\tlearn: 0.1734936\ttotal: 156ms\tremaining: 1.41s\n",
      "10:\tlearn: 0.1493496\ttotal: 169ms\tremaining: 1.37s\n",
      "11:\tlearn: 0.1285378\ttotal: 178ms\tremaining: 1.31s\n",
      "12:\tlearn: 0.1044259\ttotal: 188ms\tremaining: 1.26s\n",
      "13:\tlearn: 0.0905283\ttotal: 198ms\tremaining: 1.22s\n",
      "14:\tlearn: 0.0743761\ttotal: 207ms\tremaining: 1.17s\n",
      "15:\tlearn: 0.0647832\ttotal: 216ms\tremaining: 1.13s\n",
      "16:\tlearn: 0.0556132\ttotal: 224ms\tremaining: 1.09s\n",
      "17:\tlearn: 0.0484192\ttotal: 245ms\tremaining: 1.11s\n",
      "18:\tlearn: 0.0417308\ttotal: 270ms\tremaining: 1.15s\n",
      "19:\tlearn: 0.0361222\ttotal: 298ms\tremaining: 1.19s\n",
      "20:\tlearn: 0.0317076\ttotal: 323ms\tremaining: 1.21s\n",
      "21:\tlearn: 0.0286964\ttotal: 334ms\tremaining: 1.18s\n",
      "22:\tlearn: 0.0258245\ttotal: 344ms\tremaining: 1.15s\n",
      "23:\tlearn: 0.0234185\ttotal: 353ms\tremaining: 1.12s\n",
      "24:\tlearn: 0.0213655\ttotal: 363ms\tremaining: 1.09s\n",
      "25:\tlearn: 0.0187218\ttotal: 370ms\tremaining: 1.05s\n",
      "26:\tlearn: 0.0166532\ttotal: 397ms\tremaining: 1.07s\n",
      "27:\tlearn: 0.0142522\ttotal: 423ms\tremaining: 1.09s\n",
      "28:\tlearn: 0.0123166\ttotal: 452ms\tremaining: 1.11s\n",
      "29:\tlearn: 0.0114928\ttotal: 473ms\tremaining: 1.1s\n",
      "30:\tlearn: 0.0103559\ttotal: 486ms\tremaining: 1.08s\n",
      "31:\tlearn: 0.0097738\ttotal: 496ms\tremaining: 1.05s\n",
      "32:\tlearn: 0.0085644\ttotal: 505ms\tremaining: 1.03s\n",
      "33:\tlearn: 0.0082545\ttotal: 515ms\tremaining: 999ms\n",
      "34:\tlearn: 0.0073384\ttotal: 523ms\tremaining: 972ms\n",
      "35:\tlearn: 0.0070072\ttotal: 532ms\tremaining: 945ms\n",
      "36:\tlearn: 0.0066448\ttotal: 540ms\tremaining: 919ms\n",
      "37:\tlearn: 0.0061134\ttotal: 548ms\tremaining: 893ms\n",
      "38:\tlearn: 0.0058039\ttotal: 573ms\tremaining: 897ms\n",
      "39:\tlearn: 0.0055581\ttotal: 598ms\tremaining: 897ms\n",
      "40:\tlearn: 0.0050613\ttotal: 625ms\tremaining: 899ms\n",
      "41:\tlearn: 0.0049339\ttotal: 640ms\tremaining: 884ms\n",
      "42:\tlearn: 0.0045983\ttotal: 651ms\tremaining: 862ms\n",
      "43:\tlearn: 0.0044492\ttotal: 659ms\tremaining: 838ms\n",
      "44:\tlearn: 0.0041022\ttotal: 673ms\tremaining: 823ms\n",
      "45:\tlearn: 0.0038218\ttotal: 697ms\tremaining: 818ms\n",
      "46:\tlearn: 0.0036646\ttotal: 722ms\tremaining: 814ms\n",
      "47:\tlearn: 0.0036646\ttotal: 731ms\tremaining: 792ms\n",
      "48:\tlearn: 0.0036645\ttotal: 739ms\tremaining: 769ms\n",
      "49:\tlearn: 0.0036642\ttotal: 747ms\tremaining: 747ms\n",
      "50:\tlearn: 0.0035263\ttotal: 755ms\tremaining: 726ms\n",
      "51:\tlearn: 0.0035260\ttotal: 764ms\tremaining: 705ms\n",
      "52:\tlearn: 0.0035256\ttotal: 772ms\tremaining: 684ms\n",
      "53:\tlearn: 0.0034346\ttotal: 780ms\tremaining: 665ms\n",
      "54:\tlearn: 0.0031169\ttotal: 797ms\tremaining: 652ms\n",
      "55:\tlearn: 0.0029727\ttotal: 822ms\tremaining: 646ms\n",
      "56:\tlearn: 0.0029727\ttotal: 845ms\tremaining: 638ms\n",
      "57:\tlearn: 0.0029724\ttotal: 863ms\tremaining: 625ms\n",
      "58:\tlearn: 0.0028536\ttotal: 873ms\tremaining: 607ms\n",
      "59:\tlearn: 0.0028535\ttotal: 879ms\tremaining: 586ms\n",
      "60:\tlearn: 0.0026523\ttotal: 888ms\tremaining: 568ms\n",
      "61:\tlearn: 0.0025163\ttotal: 896ms\tremaining: 549ms\n",
      "62:\tlearn: 0.0024942\ttotal: 905ms\tremaining: 531ms\n",
      "63:\tlearn: 0.0024940\ttotal: 912ms\tremaining: 513ms\n",
      "64:\tlearn: 0.0023585\ttotal: 920ms\tremaining: 495ms\n",
      "65:\tlearn: 0.0023585\ttotal: 944ms\tremaining: 486ms\n",
      "66:\tlearn: 0.0021893\ttotal: 968ms\tremaining: 477ms\n",
      "67:\tlearn: 0.0021893\ttotal: 991ms\tremaining: 467ms\n",
      "68:\tlearn: 0.0021891\ttotal: 1.01s\tremaining: 453ms\n",
      "69:\tlearn: 0.0021890\ttotal: 1.01s\tremaining: 435ms\n",
      "70:\tlearn: 0.0021888\ttotal: 1.02s\tremaining: 418ms\n",
      "71:\tlearn: 0.0021886\ttotal: 1.03s\tremaining: 401ms\n",
      "72:\tlearn: 0.0021884\ttotal: 1.04s\tremaining: 385ms\n",
      "73:\tlearn: 0.0021884\ttotal: 1.06s\tremaining: 374ms\n",
      "74:\tlearn: 0.0021882\ttotal: 1.09s\tremaining: 363ms\n",
      "75:\tlearn: 0.0020609\ttotal: 1.11s\tremaining: 351ms\n",
      "76:\tlearn: 0.0020609\ttotal: 1.13s\tremaining: 337ms\n",
      "77:\tlearn: 0.0020608\ttotal: 1.13s\tremaining: 320ms\n",
      "78:\tlearn: 0.0020607\ttotal: 1.14s\tremaining: 303ms\n",
      "79:\tlearn: 0.0020607\ttotal: 1.15s\tremaining: 287ms\n",
      "80:\tlearn: 0.0020536\ttotal: 1.15s\tremaining: 271ms\n",
      "81:\tlearn: 0.0020534\ttotal: 1.16s\tremaining: 255ms\n",
      "82:\tlearn: 0.0020534\ttotal: 1.17s\tremaining: 240ms\n",
      "83:\tlearn: 0.0020534\ttotal: 1.18s\tremaining: 224ms\n",
      "84:\tlearn: 0.0020533\ttotal: 1.19s\tremaining: 209ms\n",
      "85:\tlearn: 0.0020532\ttotal: 1.19s\tremaining: 194ms\n",
      "86:\tlearn: 0.0019337\ttotal: 1.2s\tremaining: 180ms\n",
      "87:\tlearn: 0.0019332\ttotal: 1.21s\tremaining: 166ms\n",
      "88:\tlearn: 0.0018338\ttotal: 1.22s\tremaining: 151ms\n",
      "89:\tlearn: 0.0018338\ttotal: 1.23s\tremaining: 137ms\n",
      "90:\tlearn: 0.0018337\ttotal: 1.24s\tremaining: 122ms\n",
      "91:\tlearn: 0.0018337\ttotal: 1.24s\tremaining: 108ms\n",
      "92:\tlearn: 0.0018336\ttotal: 1.25s\tremaining: 94.3ms\n",
      "93:\tlearn: 0.0018335\ttotal: 1.26s\tremaining: 80.5ms\n",
      "94:\tlearn: 0.0018333\ttotal: 1.27s\tremaining: 66.7ms\n",
      "95:\tlearn: 0.0018332\ttotal: 1.27s\tremaining: 53.2ms\n",
      "96:\tlearn: 0.0018331\ttotal: 1.28s\tremaining: 39.7ms\n",
      "97:\tlearn: 0.0018332\ttotal: 1.29s\tremaining: 26.3ms\n",
      "98:\tlearn: 0.0018331\ttotal: 1.31s\tremaining: 13.2ms\n",
      "99:\tlearn: 0.0018330\ttotal: 1.33s\tremaining: 0us\n",
      "0:\tlearn: 0.5745738\ttotal: 10.7ms\tremaining: 1.06s\n",
      "1:\tlearn: 0.4923367\ttotal: 20.5ms\tremaining: 1.01s\n",
      "2:\tlearn: 0.4328120\ttotal: 30.3ms\tremaining: 978ms\n",
      "3:\tlearn: 0.3780853\ttotal: 39ms\tremaining: 937ms\n",
      "4:\tlearn: 0.3281897\ttotal: 47.3ms\tremaining: 899ms\n",
      "5:\tlearn: 0.2846993\ttotal: 55.6ms\tremaining: 871ms\n",
      "6:\tlearn: 0.2529306\ttotal: 63.8ms\tremaining: 848ms\n",
      "7:\tlearn: 0.2071257\ttotal: 88.4ms\tremaining: 1.02s\n",
      "8:\tlearn: 0.1832918\ttotal: 115ms\tremaining: 1.16s\n",
      "9:\tlearn: 0.1510931\ttotal: 139ms\tremaining: 1.25s\n",
      "10:\tlearn: 0.1306139\ttotal: 158ms\tremaining: 1.28s\n",
      "11:\tlearn: 0.1179473\ttotal: 169ms\tremaining: 1.24s\n",
      "12:\tlearn: 0.1054813\ttotal: 178ms\tremaining: 1.19s\n",
      "13:\tlearn: 0.0883676\ttotal: 188ms\tremaining: 1.15s\n",
      "14:\tlearn: 0.0795465\ttotal: 196ms\tremaining: 1.11s\n",
      "15:\tlearn: 0.0679293\ttotal: 205ms\tremaining: 1.08s\n",
      "16:\tlearn: 0.0592634\ttotal: 221ms\tremaining: 1.08s\n",
      "17:\tlearn: 0.0532094\ttotal: 247ms\tremaining: 1.12s\n",
      "18:\tlearn: 0.0460778\ttotal: 272ms\tremaining: 1.16s\n",
      "19:\tlearn: 0.0420695\ttotal: 299ms\tremaining: 1.2s\n",
      "20:\tlearn: 0.0366684\ttotal: 314ms\tremaining: 1.18s\n",
      "21:\tlearn: 0.0304208\ttotal: 329ms\tremaining: 1.17s\n",
      "22:\tlearn: 0.0270904\ttotal: 340ms\tremaining: 1.14s\n",
      "23:\tlearn: 0.0228959\ttotal: 350ms\tremaining: 1.11s\n",
      "24:\tlearn: 0.0199516\ttotal: 362ms\tremaining: 1.09s\n",
      "25:\tlearn: 0.0170651\ttotal: 378ms\tremaining: 1.08s\n",
      "26:\tlearn: 0.0153050\ttotal: 389ms\tremaining: 1.05s\n",
      "27:\tlearn: 0.0144684\ttotal: 405ms\tremaining: 1.04s\n",
      "28:\tlearn: 0.0138077\ttotal: 428ms\tremaining: 1.05s\n",
      "29:\tlearn: 0.0125028\ttotal: 452ms\tremaining: 1.05s\n",
      "30:\tlearn: 0.0114777\ttotal: 473ms\tremaining: 1.05s\n",
      "31:\tlearn: 0.0108973\ttotal: 487ms\tremaining: 1.03s\n",
      "32:\tlearn: 0.0101152\ttotal: 500ms\tremaining: 1.01s\n",
      "33:\tlearn: 0.0095959\ttotal: 510ms\tremaining: 990ms\n",
      "34:\tlearn: 0.0091058\ttotal: 519ms\tremaining: 964ms\n",
      "35:\tlearn: 0.0090815\ttotal: 529ms\tremaining: 940ms\n",
      "36:\tlearn: 0.0081141\ttotal: 537ms\tremaining: 914ms\n",
      "37:\tlearn: 0.0076299\ttotal: 545ms\tremaining: 890ms\n",
      "38:\tlearn: 0.0072517\ttotal: 554ms\tremaining: 866ms\n",
      "39:\tlearn: 0.0064961\ttotal: 562ms\tremaining: 843ms\n",
      "40:\tlearn: 0.0061230\ttotal: 587ms\tremaining: 845ms\n",
      "41:\tlearn: 0.0055997\ttotal: 612ms\tremaining: 845ms\n",
      "42:\tlearn: 0.0052255\ttotal: 636ms\tremaining: 843ms\n",
      "43:\tlearn: 0.0050339\ttotal: 645ms\tremaining: 821ms\n",
      "44:\tlearn: 0.0046195\ttotal: 655ms\tremaining: 801ms\n",
      "45:\tlearn: 0.0044520\ttotal: 665ms\tremaining: 780ms\n",
      "46:\tlearn: 0.0040634\ttotal: 689ms\tremaining: 777ms\n",
      "47:\tlearn: 0.0038859\ttotal: 714ms\tremaining: 774ms\n",
      "48:\tlearn: 0.0034486\ttotal: 739ms\tremaining: 769ms\n",
      "49:\tlearn: 0.0031208\ttotal: 761ms\tremaining: 761ms\n",
      "50:\tlearn: 0.0029541\ttotal: 775ms\tremaining: 745ms\n",
      "51:\tlearn: 0.0026408\ttotal: 789ms\tremaining: 728ms\n",
      "52:\tlearn: 0.0024717\ttotal: 799ms\tremaining: 709ms\n",
      "53:\tlearn: 0.0024714\ttotal: 817ms\tremaining: 696ms\n",
      "54:\tlearn: 0.0024714\ttotal: 825ms\tremaining: 675ms\n",
      "55:\tlearn: 0.0023780\ttotal: 833ms\tremaining: 654ms\n",
      "56:\tlearn: 0.0023780\ttotal: 840ms\tremaining: 634ms\n",
      "57:\tlearn: 0.0023778\ttotal: 864ms\tremaining: 626ms\n",
      "58:\tlearn: 0.0022485\ttotal: 891ms\tremaining: 619ms\n",
      "59:\tlearn: 0.0022484\ttotal: 916ms\tremaining: 611ms\n",
      "60:\tlearn: 0.0022484\ttotal: 940ms\tremaining: 601ms\n",
      "61:\tlearn: 0.0022482\ttotal: 959ms\tremaining: 588ms\n",
      "62:\tlearn: 0.0022222\ttotal: 972ms\tremaining: 571ms\n",
      "63:\tlearn: 0.0020643\ttotal: 982ms\tremaining: 552ms\n",
      "64:\tlearn: 0.0020639\ttotal: 990ms\tremaining: 533ms\n",
      "65:\tlearn: 0.0020636\ttotal: 997ms\tremaining: 514ms\n",
      "66:\tlearn: 0.0020636\ttotal: 1s\tremaining: 495ms\n",
      "67:\tlearn: 0.0020635\ttotal: 1.01s\tremaining: 477ms\n",
      "68:\tlearn: 0.0020634\ttotal: 1.04s\tremaining: 467ms\n",
      "69:\tlearn: 0.0020633\ttotal: 1.07s\tremaining: 457ms\n",
      "70:\tlearn: 0.0020626\ttotal: 1.09s\tremaining: 447ms\n",
      "71:\tlearn: 0.0020623\ttotal: 1.11s\tremaining: 433ms\n",
      "72:\tlearn: 0.0020623\ttotal: 1.13s\tremaining: 417ms\n",
      "73:\tlearn: 0.0020623\ttotal: 1.14s\tremaining: 401ms\n",
      "74:\tlearn: 0.0020623\ttotal: 1.15s\tremaining: 383ms\n",
      "75:\tlearn: 0.0020623\ttotal: 1.16s\tremaining: 366ms\n",
      "76:\tlearn: 0.0020621\ttotal: 1.17s\tremaining: 349ms\n",
      "77:\tlearn: 0.0020621\ttotal: 1.18s\tremaining: 332ms\n",
      "78:\tlearn: 0.0020621\ttotal: 1.18s\tremaining: 315ms\n",
      "79:\tlearn: 0.0020619\ttotal: 1.19s\tremaining: 298ms\n",
      "80:\tlearn: 0.0020619\ttotal: 1.2s\tremaining: 282ms\n",
      "81:\tlearn: 0.0020617\ttotal: 1.23s\tremaining: 269ms\n",
      "82:\tlearn: 0.0020613\ttotal: 1.25s\tremaining: 257ms\n",
      "83:\tlearn: 0.0020612\ttotal: 1.28s\tremaining: 244ms\n",
      "84:\tlearn: 0.0020610\ttotal: 1.29s\tremaining: 229ms\n",
      "85:\tlearn: 0.0020610\ttotal: 1.31s\tremaining: 213ms\n",
      "86:\tlearn: 0.0020608\ttotal: 1.32s\tremaining: 197ms\n",
      "87:\tlearn: 0.0020607\ttotal: 1.33s\tremaining: 181ms\n",
      "88:\tlearn: 0.0020597\ttotal: 1.34s\tremaining: 165ms\n",
      "89:\tlearn: 0.0020597\ttotal: 1.34s\tremaining: 150ms\n",
      "90:\tlearn: 0.0020597\ttotal: 1.35s\tremaining: 134ms\n",
      "91:\tlearn: 0.0020594\ttotal: 1.36s\tremaining: 118ms\n",
      "92:\tlearn: 0.0020594\ttotal: 1.37s\tremaining: 103ms\n",
      "93:\tlearn: 0.0020590\ttotal: 1.39s\tremaining: 88.9ms\n",
      "94:\tlearn: 0.0020588\ttotal: 1.42s\tremaining: 74.6ms\n",
      "95:\tlearn: 0.0020588\ttotal: 1.44s\tremaining: 60.2ms\n",
      "96:\tlearn: 0.0020587\ttotal: 1.46s\tremaining: 45.2ms\n",
      "97:\tlearn: 0.0020586\ttotal: 1.47s\tremaining: 30.1ms\n",
      "98:\tlearn: 0.0020584\ttotal: 1.49s\tremaining: 15ms\n",
      "99:\tlearn: 0.0020584\ttotal: 1.5s\tremaining: 0us\n",
      "0:\tlearn: 0.5734608\ttotal: 10.8ms\tremaining: 1.07s\n",
      "1:\tlearn: 0.4853574\ttotal: 20.5ms\tremaining: 1s\n",
      "2:\tlearn: 0.4251053\ttotal: 30.2ms\tremaining: 976ms\n",
      "3:\tlearn: 0.3596809\ttotal: 39ms\tremaining: 936ms\n",
      "4:\tlearn: 0.3168515\ttotal: 47.1ms\tremaining: 895ms\n",
      "5:\tlearn: 0.2823181\ttotal: 55.6ms\tremaining: 871ms\n",
      "6:\tlearn: 0.2404284\ttotal: 63.9ms\tremaining: 849ms\n",
      "7:\tlearn: 0.2042184\ttotal: 88.8ms\tremaining: 1.02s\n",
      "8:\tlearn: 0.1794075\ttotal: 113ms\tremaining: 1.14s\n",
      "9:\tlearn: 0.1522259\ttotal: 140ms\tremaining: 1.26s\n",
      "10:\tlearn: 0.1279516\ttotal: 161ms\tremaining: 1.3s\n",
      "11:\tlearn: 0.1091092\ttotal: 174ms\tremaining: 1.28s\n",
      "12:\tlearn: 0.0937247\ttotal: 188ms\tremaining: 1.26s\n",
      "13:\tlearn: 0.0835951\ttotal: 202ms\tremaining: 1.24s\n",
      "14:\tlearn: 0.0678932\ttotal: 211ms\tremaining: 1.2s\n",
      "15:\tlearn: 0.0593396\ttotal: 219ms\tremaining: 1.15s\n",
      "16:\tlearn: 0.0488901\ttotal: 227ms\tremaining: 1.11s\n",
      "17:\tlearn: 0.0445079\ttotal: 236ms\tremaining: 1.07s\n",
      "18:\tlearn: 0.0389732\ttotal: 244ms\tremaining: 1.04s\n",
      "19:\tlearn: 0.0343552\ttotal: 270ms\tremaining: 1.08s\n",
      "20:\tlearn: 0.0330455\ttotal: 295ms\tremaining: 1.11s\n",
      "21:\tlearn: 0.0306713\ttotal: 321ms\tremaining: 1.14s\n",
      "22:\tlearn: 0.0285261\ttotal: 336ms\tremaining: 1.12s\n",
      "23:\tlearn: 0.0249392\ttotal: 349ms\tremaining: 1.1s\n",
      "24:\tlearn: 0.0218555\ttotal: 363ms\tremaining: 1.09s\n",
      "25:\tlearn: 0.0212962\ttotal: 372ms\tremaining: 1.06s\n",
      "26:\tlearn: 0.0172757\ttotal: 382ms\tremaining: 1.03s\n",
      "27:\tlearn: 0.0153224\ttotal: 390ms\tremaining: 1s\n",
      "28:\tlearn: 0.0141581\ttotal: 397ms\tremaining: 972ms\n",
      "29:\tlearn: 0.0138842\ttotal: 406ms\tremaining: 947ms\n",
      "30:\tlearn: 0.0128999\ttotal: 414ms\tremaining: 922ms\n",
      "31:\tlearn: 0.0121431\ttotal: 430ms\tremaining: 914ms\n",
      "32:\tlearn: 0.0117860\ttotal: 454ms\tremaining: 921ms\n",
      "33:\tlearn: 0.0114929\ttotal: 478ms\tremaining: 928ms\n",
      "34:\tlearn: 0.0102551\ttotal: 505ms\tremaining: 938ms\n",
      "35:\tlearn: 0.0097601\ttotal: 518ms\tremaining: 921ms\n",
      "36:\tlearn: 0.0092428\ttotal: 528ms\tremaining: 899ms\n",
      "37:\tlearn: 0.0087317\ttotal: 537ms\tremaining: 877ms\n",
      "38:\tlearn: 0.0079392\ttotal: 547ms\tremaining: 855ms\n",
      "39:\tlearn: 0.0075621\ttotal: 556ms\tremaining: 835ms\n",
      "40:\tlearn: 0.0072956\ttotal: 565ms\tremaining: 814ms\n",
      "41:\tlearn: 0.0069159\ttotal: 574ms\tremaining: 793ms\n",
      "42:\tlearn: 0.0063172\ttotal: 582ms\tremaining: 772ms\n",
      "43:\tlearn: 0.0063172\ttotal: 590ms\tremaining: 751ms\n",
      "44:\tlearn: 0.0061552\ttotal: 614ms\tremaining: 751ms\n",
      "45:\tlearn: 0.0057004\ttotal: 640ms\tremaining: 751ms\n",
      "46:\tlearn: 0.0054382\ttotal: 667ms\tremaining: 752ms\n",
      "47:\tlearn: 0.0051297\ttotal: 687ms\tremaining: 744ms\n",
      "48:\tlearn: 0.0049560\ttotal: 700ms\tremaining: 729ms\n",
      "49:\tlearn: 0.0046784\ttotal: 714ms\tremaining: 714ms\n",
      "50:\tlearn: 0.0043562\ttotal: 723ms\tremaining: 695ms\n",
      "51:\tlearn: 0.0040443\ttotal: 732ms\tremaining: 676ms\n",
      "52:\tlearn: 0.0040443\ttotal: 742ms\tremaining: 658ms\n",
      "53:\tlearn: 0.0040442\ttotal: 750ms\tremaining: 639ms\n",
      "54:\tlearn: 0.0040442\ttotal: 758ms\tremaining: 620ms\n",
      "55:\tlearn: 0.0039215\ttotal: 774ms\tremaining: 608ms\n",
      "56:\tlearn: 0.0039214\ttotal: 798ms\tremaining: 602ms\n",
      "57:\tlearn: 0.0039213\ttotal: 825ms\tremaining: 598ms\n",
      "58:\tlearn: 0.0037261\ttotal: 851ms\tremaining: 592ms\n",
      "59:\tlearn: 0.0037261\ttotal: 867ms\tremaining: 578ms\n",
      "60:\tlearn: 0.0037260\ttotal: 881ms\tremaining: 563ms\n",
      "61:\tlearn: 0.0037259\ttotal: 892ms\tremaining: 547ms\n",
      "62:\tlearn: 0.0037259\ttotal: 901ms\tremaining: 529ms\n",
      "63:\tlearn: 0.0037258\ttotal: 911ms\tremaining: 512ms\n",
      "64:\tlearn: 0.0034563\ttotal: 920ms\tremaining: 495ms\n",
      "65:\tlearn: 0.0030865\ttotal: 930ms\tremaining: 479ms\n",
      "66:\tlearn: 0.0028273\ttotal: 938ms\tremaining: 462ms\n",
      "67:\tlearn: 0.0028262\ttotal: 947ms\tremaining: 445ms\n",
      "68:\tlearn: 0.0028262\ttotal: 957ms\tremaining: 430ms\n",
      "69:\tlearn: 0.0028261\ttotal: 983ms\tremaining: 421ms\n",
      "70:\tlearn: 0.0028261\ttotal: 1.01s\tremaining: 412ms\n",
      "71:\tlearn: 0.0026597\ttotal: 1.03s\tremaining: 400ms\n",
      "72:\tlearn: 0.0024395\ttotal: 1.05s\tremaining: 388ms\n",
      "73:\tlearn: 0.0024391\ttotal: 1.06s\tremaining: 372ms\n",
      "74:\tlearn: 0.0024390\ttotal: 1.07s\tremaining: 356ms\n",
      "75:\tlearn: 0.0024390\ttotal: 1.08s\tremaining: 340ms\n",
      "76:\tlearn: 0.0022843\ttotal: 1.09s\tremaining: 325ms\n",
      "77:\tlearn: 0.0022842\ttotal: 1.1s\tremaining: 309ms\n",
      "78:\tlearn: 0.0022841\ttotal: 1.1s\tremaining: 294ms\n",
      "79:\tlearn: 0.0022840\ttotal: 1.11s\tremaining: 278ms\n",
      "80:\tlearn: 0.0022840\ttotal: 1.12s\tremaining: 264ms\n",
      "81:\tlearn: 0.0022839\ttotal: 1.15s\tremaining: 252ms\n",
      "82:\tlearn: 0.0022838\ttotal: 1.17s\tremaining: 240ms\n",
      "83:\tlearn: 0.0022837\ttotal: 1.2s\tremaining: 228ms\n",
      "84:\tlearn: 0.0022837\ttotal: 1.21s\tremaining: 213ms\n",
      "85:\tlearn: 0.0022836\ttotal: 1.22s\tremaining: 198ms\n",
      "86:\tlearn: 0.0022837\ttotal: 1.23s\tremaining: 183ms\n",
      "87:\tlearn: 0.0022834\ttotal: 1.23s\tremaining: 168ms\n",
      "88:\tlearn: 0.0021231\ttotal: 1.24s\tremaining: 154ms\n",
      "89:\tlearn: 0.0021231\ttotal: 1.25s\tremaining: 139ms\n",
      "90:\tlearn: 0.0021231\ttotal: 1.26s\tremaining: 125ms\n",
      "91:\tlearn: 0.0021232\ttotal: 1.28s\tremaining: 112ms\n",
      "92:\tlearn: 0.0021231\ttotal: 1.31s\tremaining: 98.5ms\n",
      "93:\tlearn: 0.0021230\ttotal: 1.33s\tremaining: 85.1ms\n",
      "94:\tlearn: 0.0021227\ttotal: 1.35s\tremaining: 71.3ms\n",
      "95:\tlearn: 0.0021224\ttotal: 1.37s\tremaining: 57.2ms\n",
      "96:\tlearn: 0.0019789\ttotal: 1.39s\tremaining: 42.9ms\n",
      "97:\tlearn: 0.0018796\ttotal: 1.39s\tremaining: 28.5ms\n",
      "98:\tlearn: 0.0018796\ttotal: 1.4s\tremaining: 14.2ms\n",
      "99:\tlearn: 0.0018795\ttotal: 1.41s\tremaining: 0us\n",
      "0:\tlearn: 0.6927932\ttotal: 53.6ms\tremaining: 5.3s\n",
      "1:\tlearn: 0.6923759\ttotal: 117ms\tremaining: 5.74s\n",
      "2:\tlearn: 0.6920555\ttotal: 148ms\tremaining: 4.78s\n",
      "3:\tlearn: 0.6916917\ttotal: 171ms\tremaining: 4.11s\n",
      "4:\tlearn: 0.6914153\ttotal: 209ms\tremaining: 3.98s\n",
      "5:\tlearn: 0.6910511\ttotal: 288ms\tremaining: 4.51s\n",
      "6:\tlearn: 0.6905721\ttotal: 323ms\tremaining: 4.29s\n",
      "7:\tlearn: 0.6900882\ttotal: 351ms\tremaining: 4.03s\n",
      "8:\tlearn: 0.6896419\ttotal: 375ms\tremaining: 3.8s\n",
      "9:\tlearn: 0.6893000\ttotal: 454ms\tremaining: 4.08s\n",
      "10:\tlearn: 0.6889585\ttotal: 494ms\tremaining: 4s\n",
      "11:\tlearn: 0.6885100\ttotal: 523ms\tremaining: 3.84s\n",
      "12:\tlearn: 0.6881565\ttotal: 545ms\tremaining: 3.65s\n",
      "13:\tlearn: 0.6878126\ttotal: 625ms\tremaining: 3.84s\n",
      "14:\tlearn: 0.6874254\ttotal: 668ms\tremaining: 3.78s\n",
      "15:\tlearn: 0.6870289\ttotal: 696ms\tremaining: 3.65s\n",
      "16:\tlearn: 0.6866122\ttotal: 717ms\tremaining: 3.5s\n",
      "17:\tlearn: 0.6862206\ttotal: 798ms\tremaining: 3.63s\n",
      "18:\tlearn: 0.6858353\ttotal: 845ms\tremaining: 3.6s\n",
      "19:\tlearn: 0.6854769\ttotal: 874ms\tremaining: 3.49s\n",
      "20:\tlearn: 0.6851630\ttotal: 896ms\tremaining: 3.37s\n",
      "21:\tlearn: 0.6847249\ttotal: 958ms\tremaining: 3.4s\n",
      "22:\tlearn: 0.6843302\ttotal: 1.02s\tremaining: 3.4s\n",
      "23:\tlearn: 0.6838912\ttotal: 1.05s\tremaining: 3.31s\n",
      "24:\tlearn: 0.6834909\ttotal: 1.07s\tremaining: 3.21s\n",
      "25:\tlearn: 0.6831447\ttotal: 1.14s\tremaining: 3.25s\n",
      "26:\tlearn: 0.6826934\ttotal: 1.2s\tremaining: 3.24s\n",
      "27:\tlearn: 0.6822806\ttotal: 1.23s\tremaining: 3.17s\n",
      "28:\tlearn: 0.6819109\ttotal: 1.25s\tremaining: 3.07s\n",
      "29:\tlearn: 0.6815272\ttotal: 1.3s\tremaining: 3.04s\n",
      "30:\tlearn: 0.6811264\ttotal: 1.37s\tremaining: 3.06s\n",
      "31:\tlearn: 0.6807518\ttotal: 1.4s\tremaining: 2.98s\n",
      "32:\tlearn: 0.6803777\ttotal: 1.42s\tremaining: 2.89s\n",
      "33:\tlearn: 0.6799905\ttotal: 1.47s\tremaining: 2.86s\n",
      "34:\tlearn: 0.6795675\ttotal: 1.54s\tremaining: 2.86s\n",
      "35:\tlearn: 0.6792127\ttotal: 1.57s\tremaining: 2.8s\n",
      "36:\tlearn: 0.6788010\ttotal: 1.6s\tremaining: 2.73s\n",
      "37:\tlearn: 0.6784631\ttotal: 1.63s\tremaining: 2.65s\n",
      "38:\tlearn: 0.6780863\ttotal: 1.71s\tremaining: 2.67s\n",
      "39:\tlearn: 0.6777781\ttotal: 1.75s\tremaining: 2.62s\n",
      "40:\tlearn: 0.6773931\ttotal: 1.77s\tremaining: 2.55s\n",
      "41:\tlearn: 0.6769342\ttotal: 1.79s\tremaining: 2.47s\n",
      "42:\tlearn: 0.6765185\ttotal: 1.87s\tremaining: 2.47s\n",
      "43:\tlearn: 0.6761730\ttotal: 1.9s\tremaining: 2.42s\n",
      "44:\tlearn: 0.6758332\ttotal: 1.92s\tremaining: 2.34s\n",
      "45:\tlearn: 0.6754933\ttotal: 1.99s\tremaining: 2.34s\n",
      "46:\tlearn: 0.6750607\ttotal: 2.04s\tremaining: 2.31s\n",
      "47:\tlearn: 0.6747265\ttotal: 2.08s\tremaining: 2.26s\n",
      "48:\tlearn: 0.6743750\ttotal: 2.16s\tremaining: 2.25s\n",
      "49:\tlearn: 0.6740232\ttotal: 2.2s\tremaining: 2.2s\n",
      "50:\tlearn: 0.6736297\ttotal: 2.25s\tremaining: 2.17s\n",
      "51:\tlearn: 0.6731725\ttotal: 2.33s\tremaining: 2.15s\n",
      "52:\tlearn: 0.6728269\ttotal: 2.37s\tremaining: 2.1s\n",
      "53:\tlearn: 0.6724249\ttotal: 2.45s\tremaining: 2.09s\n",
      "54:\tlearn: 0.6719142\ttotal: 2.5s\tremaining: 2.04s\n",
      "55:\tlearn: 0.6714339\ttotal: 2.55s\tremaining: 2.01s\n",
      "56:\tlearn: 0.6711403\ttotal: 2.64s\tremaining: 1.99s\n",
      "57:\tlearn: 0.6707740\ttotal: 2.74s\tremaining: 1.99s\n",
      "58:\tlearn: 0.6702382\ttotal: 2.82s\tremaining: 1.96s\n",
      "59:\tlearn: 0.6697873\ttotal: 2.86s\tremaining: 1.91s\n",
      "60:\tlearn: 0.6693757\ttotal: 2.88s\tremaining: 1.84s\n",
      "61:\tlearn: 0.6689873\ttotal: 2.91s\tremaining: 1.78s\n",
      "62:\tlearn: 0.6686807\ttotal: 2.99s\tremaining: 1.75s\n",
      "63:\tlearn: 0.6683096\ttotal: 3.03s\tremaining: 1.7s\n",
      "64:\tlearn: 0.6679523\ttotal: 3.06s\tremaining: 1.65s\n",
      "65:\tlearn: 0.6676108\ttotal: 3.08s\tremaining: 1.59s\n",
      "66:\tlearn: 0.6672695\ttotal: 3.16s\tremaining: 1.56s\n",
      "67:\tlearn: 0.6668970\ttotal: 3.21s\tremaining: 1.51s\n",
      "68:\tlearn: 0.6665583\ttotal: 3.23s\tremaining: 1.45s\n",
      "69:\tlearn: 0.6662140\ttotal: 3.25s\tremaining: 1.39s\n",
      "70:\tlearn: 0.6658697\ttotal: 3.34s\tremaining: 1.36s\n",
      "71:\tlearn: 0.6655269\ttotal: 3.38s\tremaining: 1.31s\n",
      "72:\tlearn: 0.6651891\ttotal: 3.41s\tremaining: 1.26s\n",
      "73:\tlearn: 0.6648876\ttotal: 3.43s\tremaining: 1.21s\n",
      "74:\tlearn: 0.6644977\ttotal: 3.5s\tremaining: 1.17s\n",
      "75:\tlearn: 0.6641333\ttotal: 3.55s\tremaining: 1.12s\n",
      "76:\tlearn: 0.6637937\ttotal: 3.58s\tremaining: 1.07s\n",
      "77:\tlearn: 0.6634973\ttotal: 3.6s\tremaining: 1.02s\n",
      "78:\tlearn: 0.6631144\ttotal: 3.68s\tremaining: 979ms\n",
      "79:\tlearn: 0.6628076\ttotal: 3.72s\tremaining: 930ms\n",
      "80:\tlearn: 0.6625473\ttotal: 3.74s\tremaining: 878ms\n",
      "81:\tlearn: 0.6622841\ttotal: 3.77s\tremaining: 827ms\n",
      "82:\tlearn: 0.6619809\ttotal: 3.84s\tremaining: 787ms\n",
      "83:\tlearn: 0.6615683\ttotal: 3.87s\tremaining: 737ms\n",
      "84:\tlearn: 0.6611632\ttotal: 3.89s\tremaining: 687ms\n",
      "85:\tlearn: 0.6607685\ttotal: 3.92s\tremaining: 638ms\n",
      "86:\tlearn: 0.6603768\ttotal: 4s\tremaining: 598ms\n",
      "87:\tlearn: 0.6600029\ttotal: 4.04s\tremaining: 550ms\n",
      "88:\tlearn: 0.6596612\ttotal: 4.06s\tremaining: 502ms\n",
      "89:\tlearn: 0.6593163\ttotal: 4.09s\tremaining: 454ms\n",
      "90:\tlearn: 0.6589996\ttotal: 4.17s\tremaining: 412ms\n",
      "91:\tlearn: 0.6586018\ttotal: 4.21s\tremaining: 366ms\n",
      "92:\tlearn: 0.6582699\ttotal: 4.24s\tremaining: 319ms\n",
      "93:\tlearn: 0.6579390\ttotal: 4.26s\tremaining: 272ms\n",
      "94:\tlearn: 0.6576130\ttotal: 4.31s\tremaining: 227ms\n",
      "95:\tlearn: 0.6572121\ttotal: 4.38s\tremaining: 183ms\n",
      "96:\tlearn: 0.6568762\ttotal: 4.42s\tremaining: 137ms\n",
      "97:\tlearn: 0.6564771\ttotal: 4.44s\tremaining: 90.6ms\n",
      "98:\tlearn: 0.6560749\ttotal: 4.46s\tremaining: 45.1ms\n",
      "99:\tlearn: 0.6557469\ttotal: 4.54s\tremaining: 0us\n",
      "0:\tlearn: 0.6927609\ttotal: 31.6ms\tremaining: 3.13s\n",
      "1:\tlearn: 0.6923508\ttotal: 54.2ms\tremaining: 2.66s\n",
      "2:\tlearn: 0.6919570\ttotal: 106ms\tremaining: 3.44s\n",
      "3:\tlearn: 0.6916313\ttotal: 174ms\tremaining: 4.17s\n",
      "4:\tlearn: 0.6913039\ttotal: 207ms\tremaining: 3.94s\n",
      "5:\tlearn: 0.6909514\ttotal: 232ms\tremaining: 3.64s\n",
      "6:\tlearn: 0.6905511\ttotal: 278ms\tremaining: 3.7s\n",
      "7:\tlearn: 0.6900581\ttotal: 346ms\tremaining: 3.97s\n",
      "8:\tlearn: 0.6896915\ttotal: 381ms\tremaining: 3.85s\n",
      "9:\tlearn: 0.6892766\ttotal: 407ms\tremaining: 3.66s\n",
      "10:\tlearn: 0.6888918\ttotal: 430ms\tremaining: 3.48s\n",
      "11:\tlearn: 0.6883823\ttotal: 517ms\tremaining: 3.79s\n",
      "12:\tlearn: 0.6879864\ttotal: 544ms\tremaining: 3.64s\n",
      "13:\tlearn: 0.6875587\ttotal: 566ms\tremaining: 3.48s\n",
      "14:\tlearn: 0.6871685\ttotal: 630ms\tremaining: 3.57s\n",
      "15:\tlearn: 0.6867939\ttotal: 689ms\tremaining: 3.62s\n",
      "16:\tlearn: 0.6863592\ttotal: 718ms\tremaining: 3.5s\n",
      "17:\tlearn: 0.6859945\ttotal: 739ms\tremaining: 3.37s\n",
      "18:\tlearn: 0.6855966\ttotal: 789ms\tremaining: 3.36s\n",
      "19:\tlearn: 0.6852285\ttotal: 849ms\tremaining: 3.4s\n",
      "20:\tlearn: 0.6848362\ttotal: 889ms\tremaining: 3.34s\n",
      "21:\tlearn: 0.6844036\ttotal: 922ms\tremaining: 3.27s\n",
      "22:\tlearn: 0.6840079\ttotal: 948ms\tremaining: 3.17s\n",
      "23:\tlearn: 0.6836244\ttotal: 1.03s\tremaining: 3.25s\n",
      "24:\tlearn: 0.6831728\ttotal: 1.07s\tremaining: 3.22s\n",
      "25:\tlearn: 0.6827502\ttotal: 1.1s\tremaining: 3.13s\n",
      "26:\tlearn: 0.6823111\ttotal: 1.12s\tremaining: 3.04s\n",
      "27:\tlearn: 0.6818062\ttotal: 1.21s\tremaining: 3.1s\n",
      "28:\tlearn: 0.6814517\ttotal: 1.25s\tremaining: 3.05s\n",
      "29:\tlearn: 0.6809871\ttotal: 1.27s\tremaining: 2.97s\n",
      "30:\tlearn: 0.6806155\ttotal: 1.3s\tremaining: 2.89s\n",
      "31:\tlearn: 0.6802050\ttotal: 1.38s\tremaining: 2.94s\n",
      "32:\tlearn: 0.6797671\ttotal: 1.42s\tremaining: 2.88s\n",
      "33:\tlearn: 0.6793948\ttotal: 1.45s\tremaining: 2.81s\n",
      "34:\tlearn: 0.6790429\ttotal: 1.47s\tremaining: 2.73s\n",
      "35:\tlearn: 0.6786807\ttotal: 1.53s\tremaining: 2.73s\n",
      "36:\tlearn: 0.6782627\ttotal: 1.59s\tremaining: 2.7s\n",
      "37:\tlearn: 0.6779795\ttotal: 1.62s\tremaining: 2.64s\n",
      "38:\tlearn: 0.6775217\ttotal: 1.64s\tremaining: 2.57s\n",
      "39:\tlearn: 0.6771709\ttotal: 1.71s\tremaining: 2.56s\n",
      "40:\tlearn: 0.6766981\ttotal: 1.79s\tremaining: 2.58s\n",
      "41:\tlearn: 0.6763459\ttotal: 1.84s\tremaining: 2.54s\n",
      "42:\tlearn: 0.6759459\ttotal: 1.91s\tremaining: 2.54s\n",
      "43:\tlearn: 0.6756230\ttotal: 2.04s\tremaining: 2.6s\n",
      "44:\tlearn: 0.6752452\ttotal: 2.13s\tremaining: 2.6s\n",
      "45:\tlearn: 0.6749202\ttotal: 2.21s\tremaining: 2.59s\n",
      "46:\tlearn: 0.6744779\ttotal: 2.24s\tremaining: 2.52s\n",
      "47:\tlearn: 0.6741110\ttotal: 2.31s\tremaining: 2.5s\n",
      "48:\tlearn: 0.6738723\ttotal: 2.38s\tremaining: 2.47s\n",
      "49:\tlearn: 0.6735251\ttotal: 2.41s\tremaining: 2.41s\n",
      "50:\tlearn: 0.6731674\ttotal: 2.44s\tremaining: 2.34s\n",
      "51:\tlearn: 0.6728039\ttotal: 2.46s\tremaining: 2.27s\n",
      "52:\tlearn: 0.6724670\ttotal: 2.54s\tremaining: 2.26s\n",
      "53:\tlearn: 0.6720978\ttotal: 2.58s\tremaining: 2.2s\n",
      "54:\tlearn: 0.6717032\ttotal: 2.6s\tremaining: 2.13s\n",
      "55:\tlearn: 0.6712931\ttotal: 2.68s\tremaining: 2.11s\n",
      "56:\tlearn: 0.6708434\ttotal: 2.73s\tremaining: 2.06s\n",
      "57:\tlearn: 0.6705131\ttotal: 2.77s\tremaining: 2s\n",
      "58:\tlearn: 0.6701476\ttotal: 2.83s\tremaining: 1.97s\n",
      "59:\tlearn: 0.6697071\ttotal: 2.89s\tremaining: 1.93s\n",
      "60:\tlearn: 0.6692290\ttotal: 2.92s\tremaining: 1.87s\n",
      "61:\tlearn: 0.6688373\ttotal: 2.95s\tremaining: 1.8s\n",
      "62:\tlearn: 0.6685528\ttotal: 2.99s\tremaining: 1.76s\n",
      "63:\tlearn: 0.6681224\ttotal: 3.06s\tremaining: 1.72s\n",
      "64:\tlearn: 0.6678328\ttotal: 3.1s\tremaining: 1.67s\n",
      "65:\tlearn: 0.6674803\ttotal: 3.12s\tremaining: 1.61s\n",
      "66:\tlearn: 0.6670941\ttotal: 3.17s\tremaining: 1.56s\n",
      "67:\tlearn: 0.6666850\ttotal: 3.24s\tremaining: 1.52s\n",
      "68:\tlearn: 0.6663358\ttotal: 3.27s\tremaining: 1.47s\n",
      "69:\tlearn: 0.6660210\ttotal: 3.3s\tremaining: 1.41s\n",
      "70:\tlearn: 0.6657319\ttotal: 3.32s\tremaining: 1.36s\n",
      "71:\tlearn: 0.6653626\ttotal: 3.4s\tremaining: 1.32s\n",
      "72:\tlearn: 0.6650283\ttotal: 3.43s\tremaining: 1.27s\n",
      "73:\tlearn: 0.6647095\ttotal: 3.46s\tremaining: 1.21s\n",
      "74:\tlearn: 0.6643790\ttotal: 3.54s\tremaining: 1.18s\n",
      "75:\tlearn: 0.6640027\ttotal: 3.58s\tremaining: 1.13s\n",
      "76:\tlearn: 0.6636592\ttotal: 3.61s\tremaining: 1.08s\n",
      "77:\tlearn: 0.6632687\ttotal: 3.63s\tremaining: 1.02s\n",
      "78:\tlearn: 0.6628610\ttotal: 3.71s\tremaining: 987ms\n",
      "79:\tlearn: 0.6624952\ttotal: 3.75s\tremaining: 938ms\n",
      "80:\tlearn: 0.6622613\ttotal: 3.83s\tremaining: 900ms\n",
      "81:\tlearn: 0.6618682\ttotal: 3.87s\tremaining: 849ms\n",
      "82:\tlearn: 0.6615529\ttotal: 3.89s\tremaining: 797ms\n",
      "83:\tlearn: 0.6612436\ttotal: 3.94s\tremaining: 750ms\n",
      "84:\tlearn: 0.6608561\ttotal: 4.01s\tremaining: 707ms\n",
      "85:\tlearn: 0.6605850\ttotal: 4.04s\tremaining: 658ms\n",
      "86:\tlearn: 0.6602373\ttotal: 4.06s\tremaining: 607ms\n",
      "87:\tlearn: 0.6597832\ttotal: 4.11s\tremaining: 561ms\n",
      "88:\tlearn: 0.6594670\ttotal: 4.18s\tremaining: 517ms\n",
      "89:\tlearn: 0.6590694\ttotal: 4.21s\tremaining: 468ms\n",
      "90:\tlearn: 0.6586829\ttotal: 4.24s\tremaining: 419ms\n",
      "91:\tlearn: 0.6582838\ttotal: 4.26s\tremaining: 371ms\n",
      "92:\tlearn: 0.6579730\ttotal: 4.34s\tremaining: 327ms\n",
      "93:\tlearn: 0.6576112\ttotal: 4.38s\tremaining: 280ms\n",
      "94:\tlearn: 0.6572889\ttotal: 4.41s\tremaining: 232ms\n",
      "95:\tlearn: 0.6568829\ttotal: 4.43s\tremaining: 185ms\n",
      "96:\tlearn: 0.6565375\ttotal: 4.51s\tremaining: 139ms\n",
      "97:\tlearn: 0.6561755\ttotal: 4.55s\tremaining: 93ms\n",
      "98:\tlearn: 0.6558733\ttotal: 4.58s\tremaining: 46.3ms\n",
      "99:\tlearn: 0.6554599\ttotal: 4.61s\tremaining: 0us\n",
      "0:\tlearn: 0.6927596\ttotal: 29.4ms\tremaining: 2.91s\n",
      "1:\tlearn: 0.6923574\ttotal: 69.7ms\tremaining: 3.41s\n",
      "2:\tlearn: 0.6919305\ttotal: 143ms\tremaining: 4.62s\n",
      "3:\tlearn: 0.6914843\ttotal: 178ms\tremaining: 4.28s\n",
      "4:\tlearn: 0.6911632\ttotal: 203ms\tremaining: 3.85s\n",
      "5:\tlearn: 0.6907118\ttotal: 229ms\tremaining: 3.59s\n",
      "6:\tlearn: 0.6902799\ttotal: 312ms\tremaining: 4.14s\n",
      "7:\tlearn: 0.6899003\ttotal: 351ms\tremaining: 4.04s\n",
      "8:\tlearn: 0.6894765\ttotal: 379ms\tremaining: 3.83s\n",
      "9:\tlearn: 0.6891483\ttotal: 402ms\tremaining: 3.61s\n",
      "10:\tlearn: 0.6887769\ttotal: 480ms\tremaining: 3.88s\n",
      "11:\tlearn: 0.6883426\ttotal: 524ms\tremaining: 3.84s\n",
      "12:\tlearn: 0.6879545\ttotal: 552ms\tremaining: 3.69s\n",
      "13:\tlearn: 0.6875144\ttotal: 575ms\tremaining: 3.53s\n",
      "14:\tlearn: 0.6870550\ttotal: 605ms\tremaining: 3.43s\n",
      "15:\tlearn: 0.6866792\ttotal: 687ms\tremaining: 3.61s\n",
      "16:\tlearn: 0.6862433\ttotal: 720ms\tremaining: 3.52s\n",
      "17:\tlearn: 0.6858658\ttotal: 744ms\tremaining: 3.39s\n",
      "18:\tlearn: 0.6854686\ttotal: 768ms\tremaining: 3.27s\n",
      "19:\tlearn: 0.6851017\ttotal: 848ms\tremaining: 3.39s\n",
      "20:\tlearn: 0.6847047\ttotal: 885ms\tremaining: 3.33s\n",
      "21:\tlearn: 0.6842398\ttotal: 914ms\tremaining: 3.24s\n",
      "22:\tlearn: 0.6839019\ttotal: 946ms\tremaining: 3.17s\n",
      "23:\tlearn: 0.6835128\ttotal: 1.02s\tremaining: 3.25s\n",
      "24:\tlearn: 0.6830835\ttotal: 1.07s\tremaining: 3.2s\n",
      "25:\tlearn: 0.6825831\ttotal: 1.09s\tremaining: 3.11s\n",
      "26:\tlearn: 0.6820681\ttotal: 1.12s\tremaining: 3.02s\n",
      "27:\tlearn: 0.6817111\ttotal: 1.19s\tremaining: 3.07s\n",
      "28:\tlearn: 0.6813865\ttotal: 1.23s\tremaining: 3.02s\n",
      "29:\tlearn: 0.6809414\ttotal: 1.26s\tremaining: 2.94s\n",
      "30:\tlearn: 0.6805526\ttotal: 1.28s\tremaining: 2.86s\n",
      "31:\tlearn: 0.6801811\ttotal: 1.35s\tremaining: 2.87s\n",
      "32:\tlearn: 0.6797014\ttotal: 1.4s\tremaining: 2.85s\n",
      "33:\tlearn: 0.6793289\ttotal: 1.43s\tremaining: 2.78s\n",
      "34:\tlearn: 0.6789350\ttotal: 1.46s\tremaining: 2.7s\n",
      "35:\tlearn: 0.6785879\ttotal: 1.48s\tremaining: 2.63s\n",
      "36:\tlearn: 0.6781698\ttotal: 1.5s\tremaining: 2.56s\n",
      "37:\tlearn: 0.6778080\ttotal: 1.55s\tremaining: 2.53s\n",
      "38:\tlearn: 0.6773988\ttotal: 1.62s\tremaining: 2.53s\n",
      "39:\tlearn: 0.6770658\ttotal: 1.65s\tremaining: 2.47s\n",
      "40:\tlearn: 0.6766962\ttotal: 1.67s\tremaining: 2.4s\n",
      "41:\tlearn: 0.6763703\ttotal: 1.71s\tremaining: 2.37s\n",
      "42:\tlearn: 0.6760079\ttotal: 1.79s\tremaining: 2.37s\n",
      "43:\tlearn: 0.6756313\ttotal: 1.82s\tremaining: 2.32s\n",
      "44:\tlearn: 0.6752854\ttotal: 1.85s\tremaining: 2.26s\n",
      "45:\tlearn: 0.6749693\ttotal: 1.87s\tremaining: 2.2s\n",
      "46:\tlearn: 0.6745495\ttotal: 1.95s\tremaining: 2.2s\n",
      "47:\tlearn: 0.6741551\ttotal: 1.99s\tremaining: 2.15s\n",
      "48:\tlearn: 0.6738931\ttotal: 2.01s\tremaining: 2.1s\n",
      "49:\tlearn: 0.6735295\ttotal: 2.04s\tremaining: 2.04s\n",
      "50:\tlearn: 0.6731284\ttotal: 2.11s\tremaining: 2.03s\n",
      "51:\tlearn: 0.6727496\ttotal: 2.16s\tremaining: 2s\n",
      "52:\tlearn: 0.6724090\ttotal: 2.19s\tremaining: 1.94s\n",
      "53:\tlearn: 0.6719883\ttotal: 2.21s\tremaining: 1.89s\n",
      "54:\tlearn: 0.6715438\ttotal: 2.29s\tremaining: 1.88s\n",
      "55:\tlearn: 0.6710390\ttotal: 2.34s\tremaining: 1.84s\n",
      "56:\tlearn: 0.6706946\ttotal: 2.37s\tremaining: 1.79s\n",
      "57:\tlearn: 0.6702613\ttotal: 2.39s\tremaining: 1.73s\n",
      "58:\tlearn: 0.6698757\ttotal: 2.46s\tremaining: 1.71s\n",
      "59:\tlearn: 0.6694615\ttotal: 2.52s\tremaining: 1.68s\n",
      "60:\tlearn: 0.6691011\ttotal: 2.54s\tremaining: 1.63s\n",
      "61:\tlearn: 0.6686875\ttotal: 2.57s\tremaining: 1.57s\n",
      "62:\tlearn: 0.6683840\ttotal: 2.65s\tremaining: 1.55s\n",
      "63:\tlearn: 0.6679994\ttotal: 2.69s\tremaining: 1.51s\n",
      "64:\tlearn: 0.6676511\ttotal: 2.72s\tremaining: 1.46s\n",
      "65:\tlearn: 0.6672809\ttotal: 2.74s\tremaining: 1.41s\n",
      "66:\tlearn: 0.6668404\ttotal: 2.79s\tremaining: 1.38s\n",
      "67:\tlearn: 0.6665053\ttotal: 2.85s\tremaining: 1.34s\n",
      "68:\tlearn: 0.6660778\ttotal: 2.89s\tremaining: 1.3s\n",
      "69:\tlearn: 0.6657279\ttotal: 2.91s\tremaining: 1.25s\n",
      "70:\tlearn: 0.6653430\ttotal: 2.93s\tremaining: 1.2s\n",
      "71:\tlearn: 0.6649475\ttotal: 3.01s\tremaining: 1.17s\n",
      "72:\tlearn: 0.6646222\ttotal: 3.05s\tremaining: 1.13s\n",
      "73:\tlearn: 0.6642863\ttotal: 3.08s\tremaining: 1.08s\n",
      "74:\tlearn: 0.6639210\ttotal: 3.13s\tremaining: 1.04s\n",
      "75:\tlearn: 0.6635119\ttotal: 3.2s\tremaining: 1.01s\n",
      "76:\tlearn: 0.6631532\ttotal: 3.23s\tremaining: 966ms\n",
      "77:\tlearn: 0.6627645\ttotal: 3.26s\tremaining: 920ms\n",
      "78:\tlearn: 0.6624316\ttotal: 3.31s\tremaining: 880ms\n",
      "79:\tlearn: 0.6620100\ttotal: 3.38s\tremaining: 845ms\n",
      "80:\tlearn: 0.6617323\ttotal: 3.41s\tremaining: 801ms\n",
      "81:\tlearn: 0.6614126\ttotal: 3.44s\tremaining: 755ms\n",
      "82:\tlearn: 0.6610972\ttotal: 3.49s\tremaining: 714ms\n",
      "83:\tlearn: 0.6606797\ttotal: 3.55s\tremaining: 677ms\n",
      "84:\tlearn: 0.6602961\ttotal: 3.59s\tremaining: 633ms\n",
      "85:\tlearn: 0.6599570\ttotal: 3.61s\tremaining: 588ms\n",
      "86:\tlearn: 0.6595911\ttotal: 3.64s\tremaining: 543ms\n",
      "87:\tlearn: 0.6591675\ttotal: 3.72s\tremaining: 507ms\n",
      "88:\tlearn: 0.6588386\ttotal: 3.75s\tremaining: 464ms\n",
      "89:\tlearn: 0.6584597\ttotal: 3.78s\tremaining: 420ms\n",
      "90:\tlearn: 0.6579881\ttotal: 3.81s\tremaining: 376ms\n",
      "91:\tlearn: 0.6575539\ttotal: 3.85s\tremaining: 335ms\n",
      "92:\tlearn: 0.6571506\ttotal: 3.92s\tremaining: 295ms\n",
      "93:\tlearn: 0.6567235\ttotal: 3.95s\tremaining: 252ms\n",
      "94:\tlearn: 0.6562959\ttotal: 3.97s\tremaining: 209ms\n",
      "95:\tlearn: 0.6559765\ttotal: 4.03s\tremaining: 168ms\n",
      "96:\tlearn: 0.6556528\ttotal: 4.09s\tremaining: 126ms\n",
      "97:\tlearn: 0.6552599\ttotal: 4.12s\tremaining: 84.1ms\n",
      "98:\tlearn: 0.6549457\ttotal: 4.14s\tremaining: 41.9ms\n",
      "99:\tlearn: 0.6546128\ttotal: 4.17s\tremaining: 0us\n",
      "0:\tlearn: 0.6927137\ttotal: 36.6ms\tremaining: 3.62s\n",
      "1:\tlearn: 0.6922688\ttotal: 59.5ms\tremaining: 2.91s\n",
      "2:\tlearn: 0.6918865\ttotal: 82.6ms\tremaining: 2.67s\n",
      "3:\tlearn: 0.6914788\ttotal: 165ms\tremaining: 3.95s\n",
      "4:\tlearn: 0.6911678\ttotal: 207ms\tremaining: 3.92s\n",
      "5:\tlearn: 0.6908300\ttotal: 235ms\tremaining: 3.68s\n",
      "6:\tlearn: 0.6904393\ttotal: 258ms\tremaining: 3.42s\n",
      "7:\tlearn: 0.6900739\ttotal: 339ms\tremaining: 3.89s\n",
      "8:\tlearn: 0.6896834\ttotal: 379ms\tremaining: 3.83s\n",
      "9:\tlearn: 0.6893509\ttotal: 406ms\tremaining: 3.65s\n",
      "10:\tlearn: 0.6889642\ttotal: 429ms\tremaining: 3.47s\n",
      "11:\tlearn: 0.6886264\ttotal: 511ms\tremaining: 3.75s\n",
      "12:\tlearn: 0.6881659\ttotal: 556ms\tremaining: 3.72s\n",
      "13:\tlearn: 0.6876713\ttotal: 585ms\tremaining: 3.59s\n",
      "14:\tlearn: 0.6872348\ttotal: 608ms\tremaining: 3.44s\n",
      "15:\tlearn: 0.6868271\ttotal: 634ms\tremaining: 3.33s\n",
      "16:\tlearn: 0.6863922\ttotal: 711ms\tremaining: 3.47s\n",
      "17:\tlearn: 0.6859857\ttotal: 743ms\tremaining: 3.38s\n",
      "18:\tlearn: 0.6855842\ttotal: 770ms\tremaining: 3.28s\n",
      "19:\tlearn: 0.6852141\ttotal: 793ms\tremaining: 3.17s\n",
      "20:\tlearn: 0.6847301\ttotal: 864ms\tremaining: 3.25s\n",
      "21:\tlearn: 0.6842528\ttotal: 908ms\tremaining: 3.22s\n",
      "22:\tlearn: 0.6838337\ttotal: 939ms\tremaining: 3.14s\n",
      "23:\tlearn: 0.6834196\ttotal: 962ms\tremaining: 3.05s\n",
      "24:\tlearn: 0.6829928\ttotal: 1.01s\tremaining: 3.04s\n",
      "25:\tlearn: 0.6825220\ttotal: 1.08s\tremaining: 3.07s\n",
      "26:\tlearn: 0.6820761\ttotal: 1.11s\tremaining: 3.01s\n",
      "27:\tlearn: 0.6817104\ttotal: 1.14s\tremaining: 2.92s\n",
      "28:\tlearn: 0.6812921\ttotal: 1.22s\tremaining: 2.98s\n",
      "29:\tlearn: 0.6809758\ttotal: 1.26s\tremaining: 2.95s\n",
      "30:\tlearn: 0.6805747\ttotal: 1.29s\tremaining: 2.88s\n",
      "31:\tlearn: 0.6801207\ttotal: 1.32s\tremaining: 2.8s\n",
      "32:\tlearn: 0.6796341\ttotal: 1.4s\tremaining: 2.84s\n",
      "33:\tlearn: 0.6792513\ttotal: 1.44s\tremaining: 2.8s\n",
      "34:\tlearn: 0.6788577\ttotal: 1.47s\tremaining: 2.73s\n",
      "35:\tlearn: 0.6785436\ttotal: 1.49s\tremaining: 2.65s\n",
      "36:\tlearn: 0.6781613\ttotal: 1.57s\tremaining: 2.67s\n",
      "37:\tlearn: 0.6778025\ttotal: 1.62s\tremaining: 2.64s\n",
      "38:\tlearn: 0.6774007\ttotal: 1.65s\tremaining: 2.58s\n",
      "39:\tlearn: 0.6771487\ttotal: 1.67s\tremaining: 2.5s\n",
      "40:\tlearn: 0.6767049\ttotal: 1.73s\tremaining: 2.49s\n",
      "41:\tlearn: 0.6763423\ttotal: 1.8s\tremaining: 2.48s\n",
      "42:\tlearn: 0.6759982\ttotal: 1.82s\tremaining: 2.42s\n",
      "43:\tlearn: 0.6755530\ttotal: 1.86s\tremaining: 2.37s\n",
      "44:\tlearn: 0.6752257\ttotal: 1.94s\tremaining: 2.37s\n",
      "45:\tlearn: 0.6748813\ttotal: 1.98s\tremaining: 2.32s\n",
      "46:\tlearn: 0.6745192\ttotal: 2s\tremaining: 2.26s\n",
      "47:\tlearn: 0.6740761\ttotal: 2.03s\tremaining: 2.19s\n",
      "48:\tlearn: 0.6738303\ttotal: 2.11s\tremaining: 2.19s\n",
      "49:\tlearn: 0.6734630\ttotal: 2.14s\tremaining: 2.14s\n",
      "50:\tlearn: 0.6730720\ttotal: 2.16s\tremaining: 2.08s\n",
      "51:\tlearn: 0.6727792\ttotal: 2.21s\tremaining: 2.04s\n",
      "52:\tlearn: 0.6723967\ttotal: 2.28s\tremaining: 2.02s\n",
      "53:\tlearn: 0.6719852\ttotal: 2.31s\tremaining: 1.97s\n",
      "54:\tlearn: 0.6715476\ttotal: 2.34s\tremaining: 1.91s\n",
      "55:\tlearn: 0.6710700\ttotal: 2.36s\tremaining: 1.86s\n",
      "56:\tlearn: 0.6706278\ttotal: 2.44s\tremaining: 1.84s\n",
      "57:\tlearn: 0.6702780\ttotal: 2.48s\tremaining: 1.79s\n",
      "58:\tlearn: 0.6698925\ttotal: 2.51s\tremaining: 1.74s\n",
      "59:\tlearn: 0.6695273\ttotal: 2.53s\tremaining: 1.69s\n",
      "60:\tlearn: 0.6691042\ttotal: 2.61s\tremaining: 1.67s\n",
      "61:\tlearn: 0.6686999\ttotal: 2.65s\tremaining: 1.63s\n",
      "62:\tlearn: 0.6683997\ttotal: 2.68s\tremaining: 1.57s\n",
      "63:\tlearn: 0.6680002\ttotal: 2.71s\tremaining: 1.52s\n",
      "64:\tlearn: 0.6676909\ttotal: 2.79s\tremaining: 1.5s\n",
      "65:\tlearn: 0.6672930\ttotal: 2.83s\tremaining: 1.46s\n",
      "66:\tlearn: 0.6668699\ttotal: 2.86s\tremaining: 1.41s\n",
      "67:\tlearn: 0.6665354\ttotal: 2.88s\tremaining: 1.35s\n",
      "68:\tlearn: 0.6661509\ttotal: 2.94s\tremaining: 1.32s\n",
      "69:\tlearn: 0.6657875\ttotal: 3s\tremaining: 1.28s\n",
      "70:\tlearn: 0.6654168\ttotal: 3.03s\tremaining: 1.24s\n",
      "71:\tlearn: 0.6650166\ttotal: 3.05s\tremaining: 1.19s\n",
      "72:\tlearn: 0.6646406\ttotal: 3.1s\tremaining: 1.15s\n",
      "73:\tlearn: 0.6643033\ttotal: 3.17s\tremaining: 1.11s\n",
      "74:\tlearn: 0.6639550\ttotal: 3.2s\tremaining: 1.07s\n",
      "75:\tlearn: 0.6635500\ttotal: 3.23s\tremaining: 1.02s\n",
      "76:\tlearn: 0.6631945\ttotal: 3.25s\tremaining: 971ms\n",
      "77:\tlearn: 0.6627959\ttotal: 3.33s\tremaining: 940ms\n",
      "78:\tlearn: 0.6624011\ttotal: 3.41s\tremaining: 907ms\n",
      "79:\tlearn: 0.6619660\ttotal: 3.44s\tremaining: 859ms\n",
      "80:\tlearn: 0.6616841\ttotal: 3.49s\tremaining: 818ms\n",
      "81:\tlearn: 0.6613456\ttotal: 3.55s\tremaining: 779ms\n",
      "82:\tlearn: 0.6610233\ttotal: 3.57s\tremaining: 732ms\n",
      "83:\tlearn: 0.6606010\ttotal: 3.65s\tremaining: 696ms\n",
      "84:\tlearn: 0.6601927\ttotal: 3.7s\tremaining: 653ms\n",
      "85:\tlearn: 0.6598704\ttotal: 3.73s\tremaining: 607ms\n",
      "86:\tlearn: 0.6595063\ttotal: 3.75s\tremaining: 560ms\n",
      "87:\tlearn: 0.6591438\ttotal: 3.83s\tremaining: 522ms\n",
      "88:\tlearn: 0.6588032\ttotal: 3.87s\tremaining: 479ms\n",
      "89:\tlearn: 0.6584289\ttotal: 3.9s\tremaining: 434ms\n",
      "90:\tlearn: 0.6580870\ttotal: 3.93s\tremaining: 388ms\n",
      "91:\tlearn: 0.6577113\ttotal: 3.95s\tremaining: 343ms\n",
      "92:\tlearn: 0.6573702\ttotal: 4.03s\tremaining: 304ms\n",
      "93:\tlearn: 0.6568970\ttotal: 4.07s\tremaining: 260ms\n",
      "94:\tlearn: 0.6565643\ttotal: 4.1s\tremaining: 216ms\n",
      "95:\tlearn: 0.6561667\ttotal: 4.12s\tremaining: 172ms\n",
      "96:\tlearn: 0.6558327\ttotal: 4.18s\tremaining: 129ms\n",
      "97:\tlearn: 0.6554764\ttotal: 4.26s\tremaining: 87ms\n",
      "98:\tlearn: 0.6551659\ttotal: 4.28s\tremaining: 43.3ms\n",
      "99:\tlearn: 0.6548698\ttotal: 4.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6927895\ttotal: 29.4ms\tremaining: 2.91s\n",
      "1:\tlearn: 0.6924173\ttotal: 67.9ms\tremaining: 3.32s\n",
      "2:\tlearn: 0.6920268\ttotal: 148ms\tremaining: 4.8s\n",
      "3:\tlearn: 0.6916394\ttotal: 180ms\tremaining: 4.33s\n",
      "4:\tlearn: 0.6912932\ttotal: 206ms\tremaining: 3.91s\n",
      "5:\tlearn: 0.6908579\ttotal: 231ms\tremaining: 3.62s\n",
      "6:\tlearn: 0.6904439\ttotal: 313ms\tremaining: 4.15s\n",
      "7:\tlearn: 0.6900403\ttotal: 342ms\tremaining: 3.93s\n",
      "8:\tlearn: 0.6896613\ttotal: 366ms\tremaining: 3.7s\n",
      "9:\tlearn: 0.6892938\ttotal: 409ms\tremaining: 3.68s\n",
      "10:\tlearn: 0.6889154\ttotal: 473ms\tremaining: 3.83s\n",
      "11:\tlearn: 0.6885047\ttotal: 506ms\tremaining: 3.71s\n",
      "12:\tlearn: 0.6881161\ttotal: 533ms\tremaining: 3.56s\n",
      "13:\tlearn: 0.6877282\ttotal: 555ms\tremaining: 3.41s\n",
      "14:\tlearn: 0.6873408\ttotal: 634ms\tremaining: 3.59s\n",
      "15:\tlearn: 0.6869264\ttotal: 674ms\tremaining: 3.54s\n",
      "16:\tlearn: 0.6865566\ttotal: 701ms\tremaining: 3.42s\n",
      "17:\tlearn: 0.6861548\ttotal: 724ms\tremaining: 3.3s\n",
      "18:\tlearn: 0.6857294\ttotal: 798ms\tremaining: 3.4s\n",
      "19:\tlearn: 0.6853575\ttotal: 846ms\tremaining: 3.38s\n",
      "20:\tlearn: 0.6849675\ttotal: 874ms\tremaining: 3.29s\n",
      "21:\tlearn: 0.6844928\ttotal: 898ms\tremaining: 3.18s\n",
      "22:\tlearn: 0.6840404\ttotal: 948ms\tremaining: 3.17s\n",
      "23:\tlearn: 0.6836413\ttotal: 1.02s\tremaining: 3.25s\n",
      "24:\tlearn: 0.6831470\ttotal: 1.05s\tremaining: 3.16s\n",
      "25:\tlearn: 0.6827362\ttotal: 1.08s\tremaining: 3.07s\n",
      "26:\tlearn: 0.6824016\ttotal: 1.14s\tremaining: 3.09s\n",
      "27:\tlearn: 0.6820124\ttotal: 1.19s\tremaining: 3.05s\n",
      "28:\tlearn: 0.6816515\ttotal: 1.21s\tremaining: 2.96s\n",
      "29:\tlearn: 0.6812488\ttotal: 1.29s\tremaining: 3.01s\n",
      "30:\tlearn: 0.6808679\ttotal: 1.32s\tremaining: 2.93s\n",
      "31:\tlearn: 0.6804352\ttotal: 1.34s\tremaining: 2.85s\n",
      "32:\tlearn: 0.6800466\ttotal: 1.37s\tremaining: 2.79s\n",
      "33:\tlearn: 0.6796376\ttotal: 1.46s\tremaining: 2.83s\n",
      "34:\tlearn: 0.6792976\ttotal: 1.49s\tremaining: 2.77s\n",
      "35:\tlearn: 0.6789334\ttotal: 1.54s\tremaining: 2.74s\n",
      "36:\tlearn: 0.6785161\ttotal: 1.6s\tremaining: 2.73s\n",
      "37:\tlearn: 0.6781416\ttotal: 1.63s\tremaining: 2.66s\n",
      "38:\tlearn: 0.6776993\ttotal: 1.66s\tremaining: 2.59s\n",
      "39:\tlearn: 0.6773307\ttotal: 1.7s\tremaining: 2.55s\n",
      "40:\tlearn: 0.6768841\ttotal: 1.77s\tremaining: 2.56s\n",
      "41:\tlearn: 0.6765356\ttotal: 1.81s\tremaining: 2.5s\n",
      "42:\tlearn: 0.6761486\ttotal: 1.83s\tremaining: 2.43s\n",
      "43:\tlearn: 0.6757642\ttotal: 1.88s\tremaining: 2.4s\n",
      "44:\tlearn: 0.6753924\ttotal: 1.95s\tremaining: 2.39s\n",
      "45:\tlearn: 0.6750846\ttotal: 1.99s\tremaining: 2.33s\n",
      "46:\tlearn: 0.6746345\ttotal: 2.01s\tremaining: 2.27s\n",
      "47:\tlearn: 0.6741331\ttotal: 2.04s\tremaining: 2.21s\n",
      "48:\tlearn: 0.6738202\ttotal: 2.12s\tremaining: 2.2s\n",
      "49:\tlearn: 0.6734617\ttotal: 2.14s\tremaining: 2.14s\n",
      "50:\tlearn: 0.6731156\ttotal: 2.16s\tremaining: 2.08s\n",
      "51:\tlearn: 0.6727726\ttotal: 2.24s\tremaining: 2.06s\n",
      "52:\tlearn: 0.6724788\ttotal: 2.29s\tremaining: 2.03s\n",
      "53:\tlearn: 0.6720405\ttotal: 2.31s\tremaining: 1.97s\n",
      "54:\tlearn: 0.6716515\ttotal: 2.33s\tremaining: 1.91s\n",
      "55:\tlearn: 0.6712439\ttotal: 2.42s\tremaining: 1.9s\n",
      "56:\tlearn: 0.6708964\ttotal: 2.46s\tremaining: 1.86s\n",
      "57:\tlearn: 0.6705869\ttotal: 2.49s\tremaining: 1.8s\n",
      "58:\tlearn: 0.6702039\ttotal: 2.51s\tremaining: 1.75s\n",
      "59:\tlearn: 0.6698528\ttotal: 2.57s\tremaining: 1.72s\n",
      "60:\tlearn: 0.6694131\ttotal: 2.63s\tremaining: 1.68s\n",
      "61:\tlearn: 0.6691160\ttotal: 2.66s\tremaining: 1.63s\n",
      "62:\tlearn: 0.6686705\ttotal: 2.69s\tremaining: 1.58s\n",
      "63:\tlearn: 0.6683291\ttotal: 2.71s\tremaining: 1.52s\n",
      "64:\tlearn: 0.6679131\ttotal: 2.79s\tremaining: 1.5s\n",
      "65:\tlearn: 0.6675423\ttotal: 2.81s\tremaining: 1.45s\n",
      "66:\tlearn: 0.6671751\ttotal: 2.84s\tremaining: 1.4s\n",
      "67:\tlearn: 0.6667533\ttotal: 2.87s\tremaining: 1.35s\n",
      "68:\tlearn: 0.6664029\ttotal: 2.94s\tremaining: 1.32s\n",
      "69:\tlearn: 0.6660327\ttotal: 2.98s\tremaining: 1.28s\n",
      "70:\tlearn: 0.6656631\ttotal: 3s\tremaining: 1.23s\n",
      "71:\tlearn: 0.6652655\ttotal: 3.05s\tremaining: 1.19s\n",
      "72:\tlearn: 0.6649496\ttotal: 3.12s\tremaining: 1.16s\n",
      "73:\tlearn: 0.6646678\ttotal: 3.16s\tremaining: 1.11s\n",
      "74:\tlearn: 0.6643033\ttotal: 3.18s\tremaining: 1.06s\n",
      "75:\tlearn: 0.6639122\ttotal: 3.23s\tremaining: 1.02s\n",
      "76:\tlearn: 0.6635503\ttotal: 3.3s\tremaining: 986ms\n",
      "77:\tlearn: 0.6632042\ttotal: 3.33s\tremaining: 940ms\n",
      "78:\tlearn: 0.6628611\ttotal: 3.36s\tremaining: 892ms\n",
      "79:\tlearn: 0.6624486\ttotal: 3.38s\tremaining: 845ms\n",
      "80:\tlearn: 0.6621504\ttotal: 3.46s\tremaining: 812ms\n",
      "81:\tlearn: 0.6617485\ttotal: 3.49s\tremaining: 766ms\n",
      "82:\tlearn: 0.6614343\ttotal: 3.51s\tremaining: 720ms\n",
      "83:\tlearn: 0.6610930\ttotal: 3.56s\tremaining: 679ms\n",
      "84:\tlearn: 0.6606075\ttotal: 3.63s\tremaining: 641ms\n",
      "85:\tlearn: 0.6602433\ttotal: 3.67s\tremaining: 597ms\n",
      "86:\tlearn: 0.6599183\ttotal: 3.69s\tremaining: 551ms\n",
      "87:\tlearn: 0.6594534\ttotal: 3.73s\tremaining: 509ms\n",
      "88:\tlearn: 0.6590612\ttotal: 3.8s\tremaining: 470ms\n",
      "89:\tlearn: 0.6587091\ttotal: 3.84s\tremaining: 426ms\n",
      "90:\tlearn: 0.6583412\ttotal: 3.86s\tremaining: 382ms\n",
      "91:\tlearn: 0.6579993\ttotal: 3.88s\tremaining: 338ms\n",
      "92:\tlearn: 0.6576620\ttotal: 3.96s\tremaining: 298ms\n",
      "93:\tlearn: 0.6572261\ttotal: 4s\tremaining: 256ms\n",
      "94:\tlearn: 0.6568866\ttotal: 4.03s\tremaining: 212ms\n",
      "95:\tlearn: 0.6565599\ttotal: 4.05s\tremaining: 169ms\n",
      "96:\tlearn: 0.6560589\ttotal: 4.13s\tremaining: 128ms\n",
      "97:\tlearn: 0.6555940\ttotal: 4.17s\tremaining: 85.2ms\n",
      "98:\tlearn: 0.6552779\ttotal: 4.2s\tremaining: 42.4ms\n",
      "99:\tlearn: 0.6548666\ttotal: 4.22s\tremaining: 0us\n",
      "0:\tlearn: 0.6928128\ttotal: 47.3ms\tremaining: 4.68s\n",
      "1:\tlearn: 0.6924322\ttotal: 80ms\tremaining: 3.92s\n",
      "2:\tlearn: 0.6920227\ttotal: 104ms\tremaining: 3.35s\n",
      "3:\tlearn: 0.6916547\ttotal: 167ms\tremaining: 4.01s\n",
      "4:\tlearn: 0.6913337\ttotal: 226ms\tremaining: 4.3s\n",
      "5:\tlearn: 0.6910222\ttotal: 260ms\tremaining: 4.08s\n",
      "6:\tlearn: 0.6906177\ttotal: 283ms\tremaining: 3.77s\n",
      "7:\tlearn: 0.6901703\ttotal: 318ms\tremaining: 3.65s\n",
      "8:\tlearn: 0.6897573\ttotal: 393ms\tremaining: 3.98s\n",
      "9:\tlearn: 0.6893624\ttotal: 428ms\tremaining: 3.85s\n",
      "10:\tlearn: 0.6889790\ttotal: 454ms\tremaining: 3.67s\n",
      "11:\tlearn: 0.6886275\ttotal: 505ms\tremaining: 3.7s\n",
      "12:\tlearn: 0.6882253\ttotal: 567ms\tremaining: 3.79s\n",
      "13:\tlearn: 0.6877465\ttotal: 601ms\tremaining: 3.69s\n",
      "14:\tlearn: 0.6872603\ttotal: 627ms\tremaining: 3.55s\n",
      "15:\tlearn: 0.6869222\ttotal: 651ms\tremaining: 3.42s\n",
      "16:\tlearn: 0.6864622\ttotal: 735ms\tremaining: 3.59s\n",
      "17:\tlearn: 0.6860521\ttotal: 771ms\tremaining: 3.51s\n",
      "18:\tlearn: 0.6856452\ttotal: 799ms\tremaining: 3.41s\n",
      "19:\tlearn: 0.6852481\ttotal: 824ms\tremaining: 3.29s\n",
      "20:\tlearn: 0.6848676\ttotal: 905ms\tremaining: 3.4s\n",
      "21:\tlearn: 0.6844006\ttotal: 948ms\tremaining: 3.36s\n",
      "22:\tlearn: 0.6839778\ttotal: 974ms\tremaining: 3.26s\n",
      "23:\tlearn: 0.6835391\ttotal: 997ms\tremaining: 3.16s\n",
      "24:\tlearn: 0.6830769\ttotal: 1.08s\tremaining: 3.23s\n",
      "25:\tlearn: 0.6827084\ttotal: 1.12s\tremaining: 3.18s\n",
      "26:\tlearn: 0.6823211\ttotal: 1.14s\tremaining: 3.1s\n",
      "27:\tlearn: 0.6819760\ttotal: 1.17s\tremaining: 3s\n",
      "28:\tlearn: 0.6815715\ttotal: 1.25s\tremaining: 3.05s\n",
      "29:\tlearn: 0.6811715\ttotal: 1.3s\tremaining: 3.02s\n",
      "30:\tlearn: 0.6807712\ttotal: 1.32s\tremaining: 2.95s\n",
      "31:\tlearn: 0.6803109\ttotal: 1.35s\tremaining: 2.87s\n",
      "32:\tlearn: 0.6799217\ttotal: 1.43s\tremaining: 2.9s\n",
      "33:\tlearn: 0.6795621\ttotal: 1.48s\tremaining: 2.86s\n",
      "34:\tlearn: 0.6791643\ttotal: 1.5s\tremaining: 2.79s\n",
      "35:\tlearn: 0.6787689\ttotal: 1.52s\tremaining: 2.71s\n",
      "36:\tlearn: 0.6783582\ttotal: 1.61s\tremaining: 2.74s\n",
      "37:\tlearn: 0.6780140\ttotal: 1.65s\tremaining: 2.69s\n",
      "38:\tlearn: 0.6775571\ttotal: 1.68s\tremaining: 2.62s\n",
      "39:\tlearn: 0.6772205\ttotal: 1.7s\tremaining: 2.55s\n",
      "40:\tlearn: 0.6768053\ttotal: 1.79s\tremaining: 2.57s\n",
      "41:\tlearn: 0.6763493\ttotal: 1.9s\tremaining: 2.62s\n",
      "42:\tlearn: 0.6759991\ttotal: 1.93s\tremaining: 2.56s\n",
      "43:\tlearn: 0.6755110\ttotal: 2s\tremaining: 2.54s\n",
      "44:\tlearn: 0.6751664\ttotal: 2.06s\tremaining: 2.51s\n",
      "45:\tlearn: 0.6748720\ttotal: 2.08s\tremaining: 2.45s\n",
      "46:\tlearn: 0.6744295\ttotal: 2.18s\tremaining: 2.46s\n",
      "47:\tlearn: 0.6740588\ttotal: 2.2s\tremaining: 2.39s\n",
      "48:\tlearn: 0.6738064\ttotal: 2.25s\tremaining: 2.34s\n",
      "49:\tlearn: 0.6734457\ttotal: 2.27s\tremaining: 2.27s\n",
      "50:\tlearn: 0.6730530\ttotal: 2.3s\tremaining: 2.21s\n",
      "51:\tlearn: 0.6727078\ttotal: 2.32s\tremaining: 2.15s\n",
      "52:\tlearn: 0.6723394\ttotal: 2.35s\tremaining: 2.08s\n",
      "53:\tlearn: 0.6718971\ttotal: 2.38s\tremaining: 2.02s\n",
      "54:\tlearn: 0.6713915\ttotal: 2.4s\tremaining: 1.96s\n",
      "55:\tlearn: 0.6709652\ttotal: 2.42s\tremaining: 1.9s\n",
      "56:\tlearn: 0.6705910\ttotal: 2.45s\tremaining: 1.85s\n",
      "57:\tlearn: 0.6701475\ttotal: 2.48s\tremaining: 1.79s\n",
      "58:\tlearn: 0.6697011\ttotal: 2.51s\tremaining: 1.75s\n",
      "59:\tlearn: 0.6693311\ttotal: 2.56s\tremaining: 1.7s\n",
      "60:\tlearn: 0.6688595\ttotal: 2.6s\tremaining: 1.66s\n",
      "61:\tlearn: 0.6684769\ttotal: 2.62s\tremaining: 1.61s\n",
      "62:\tlearn: 0.6681088\ttotal: 2.65s\tremaining: 1.55s\n",
      "63:\tlearn: 0.6677787\ttotal: 2.73s\tremaining: 1.53s\n",
      "64:\tlearn: 0.6674061\ttotal: 2.78s\tremaining: 1.49s\n",
      "65:\tlearn: 0.6670490\ttotal: 2.8s\tremaining: 1.44s\n",
      "66:\tlearn: 0.6667405\ttotal: 2.82s\tremaining: 1.39s\n",
      "67:\tlearn: 0.6663886\ttotal: 2.9s\tremaining: 1.37s\n",
      "68:\tlearn: 0.6660354\ttotal: 2.94s\tremaining: 1.32s\n",
      "69:\tlearn: 0.6656724\ttotal: 2.97s\tremaining: 1.27s\n",
      "70:\tlearn: 0.6653098\ttotal: 3s\tremaining: 1.22s\n",
      "71:\tlearn: 0.6649874\ttotal: 3.07s\tremaining: 1.2s\n",
      "72:\tlearn: 0.6646316\ttotal: 3.12s\tremaining: 1.15s\n",
      "73:\tlearn: 0.6643139\ttotal: 3.15s\tremaining: 1.11s\n",
      "74:\tlearn: 0.6639495\ttotal: 3.18s\tremaining: 1.06s\n",
      "75:\tlearn: 0.6635484\ttotal: 3.2s\tremaining: 1.01s\n",
      "76:\tlearn: 0.6632147\ttotal: 3.27s\tremaining: 978ms\n",
      "77:\tlearn: 0.6628166\ttotal: 3.33s\tremaining: 940ms\n",
      "78:\tlearn: 0.6624705\ttotal: 3.36s\tremaining: 892ms\n",
      "79:\tlearn: 0.6620329\ttotal: 3.38s\tremaining: 844ms\n",
      "80:\tlearn: 0.6617399\ttotal: 3.45s\tremaining: 810ms\n",
      "81:\tlearn: 0.6613918\ttotal: 3.5s\tremaining: 769ms\n",
      "82:\tlearn: 0.6610710\ttotal: 3.53s\tremaining: 722ms\n",
      "83:\tlearn: 0.6607171\ttotal: 3.55s\tremaining: 676ms\n",
      "84:\tlearn: 0.6603422\ttotal: 3.6s\tremaining: 635ms\n",
      "85:\tlearn: 0.6599743\ttotal: 3.65s\tremaining: 595ms\n",
      "86:\tlearn: 0.6595962\ttotal: 3.68s\tremaining: 550ms\n",
      "87:\tlearn: 0.6591429\ttotal: 3.7s\tremaining: 505ms\n",
      "88:\tlearn: 0.6588242\ttotal: 3.78s\tremaining: 468ms\n",
      "89:\tlearn: 0.6584879\ttotal: 3.83s\tremaining: 426ms\n",
      "90:\tlearn: 0.6580350\ttotal: 3.85s\tremaining: 381ms\n",
      "91:\tlearn: 0.6576138\ttotal: 3.87s\tremaining: 337ms\n",
      "92:\tlearn: 0.6572223\ttotal: 3.95s\tremaining: 298ms\n",
      "93:\tlearn: 0.6568470\ttotal: 3.99s\tremaining: 255ms\n",
      "94:\tlearn: 0.6564627\ttotal: 4.01s\tremaining: 211ms\n",
      "95:\tlearn: 0.6559858\ttotal: 4.04s\tremaining: 168ms\n",
      "96:\tlearn: 0.6556273\ttotal: 4.12s\tremaining: 127ms\n",
      "97:\tlearn: 0.6552724\ttotal: 4.15s\tremaining: 84.7ms\n",
      "98:\tlearn: 0.6549637\ttotal: 4.17s\tremaining: 42.1ms\n",
      "99:\tlearn: 0.6546393\ttotal: 4.22s\tremaining: 0us\n",
      "0:\tlearn: 0.6927836\ttotal: 78ms\tremaining: 7.72s\n",
      "1:\tlearn: 0.6924151\ttotal: 115ms\tremaining: 5.65s\n",
      "2:\tlearn: 0.6919582\ttotal: 139ms\tremaining: 4.49s\n",
      "3:\tlearn: 0.6915618\ttotal: 203ms\tremaining: 4.88s\n",
      "4:\tlearn: 0.6912248\ttotal: 269ms\tremaining: 5.1s\n",
      "5:\tlearn: 0.6909244\ttotal: 302ms\tremaining: 4.74s\n",
      "6:\tlearn: 0.6905139\ttotal: 326ms\tremaining: 4.33s\n",
      "7:\tlearn: 0.6900797\ttotal: 397ms\tremaining: 4.56s\n",
      "8:\tlearn: 0.6896558\ttotal: 482ms\tremaining: 4.88s\n",
      "9:\tlearn: 0.6892946\ttotal: 568ms\tremaining: 5.11s\n",
      "10:\tlearn: 0.6889565\ttotal: 591ms\tremaining: 4.78s\n",
      "11:\tlearn: 0.6885398\ttotal: 638ms\tremaining: 4.68s\n",
      "12:\tlearn: 0.6880964\ttotal: 690ms\tremaining: 4.62s\n",
      "13:\tlearn: 0.6876412\ttotal: 714ms\tremaining: 4.38s\n",
      "14:\tlearn: 0.6872232\ttotal: 792ms\tremaining: 4.49s\n",
      "15:\tlearn: 0.6868497\ttotal: 851ms\tremaining: 4.47s\n",
      "16:\tlearn: 0.6863886\ttotal: 883ms\tremaining: 4.31s\n",
      "17:\tlearn: 0.6860074\ttotal: 907ms\tremaining: 4.13s\n",
      "18:\tlearn: 0.6857121\ttotal: 950ms\tremaining: 4.05s\n",
      "19:\tlearn: 0.6853853\ttotal: 1.02s\tremaining: 4.08s\n",
      "20:\tlearn: 0.6850563\ttotal: 1.05s\tremaining: 3.96s\n",
      "21:\tlearn: 0.6846182\ttotal: 1.08s\tremaining: 3.82s\n",
      "22:\tlearn: 0.6842920\ttotal: 1.1s\tremaining: 3.69s\n",
      "23:\tlearn: 0.6839280\ttotal: 1.18s\tremaining: 3.74s\n",
      "24:\tlearn: 0.6835664\ttotal: 1.23s\tremaining: 3.67s\n",
      "25:\tlearn: 0.6830559\ttotal: 1.25s\tremaining: 3.57s\n",
      "26:\tlearn: 0.6826294\ttotal: 1.28s\tremaining: 3.46s\n",
      "27:\tlearn: 0.6822169\ttotal: 1.36s\tremaining: 3.5s\n",
      "28:\tlearn: 0.6818515\ttotal: 1.41s\tremaining: 3.46s\n",
      "29:\tlearn: 0.6814889\ttotal: 1.44s\tremaining: 3.35s\n",
      "30:\tlearn: 0.6811364\ttotal: 1.48s\tremaining: 3.31s\n",
      "31:\tlearn: 0.6808283\ttotal: 1.54s\tremaining: 3.27s\n",
      "32:\tlearn: 0.6804026\ttotal: 1.57s\tremaining: 3.18s\n",
      "33:\tlearn: 0.6799526\ttotal: 1.59s\tremaining: 3.09s\n",
      "34:\tlearn: 0.6796129\ttotal: 1.65s\tremaining: 3.07s\n",
      "35:\tlearn: 0.6792429\ttotal: 1.71s\tremaining: 3.04s\n",
      "36:\tlearn: 0.6789194\ttotal: 1.74s\tremaining: 2.96s\n",
      "37:\tlearn: 0.6785526\ttotal: 1.76s\tremaining: 2.87s\n",
      "38:\tlearn: 0.6781549\ttotal: 1.79s\tremaining: 2.8s\n",
      "39:\tlearn: 0.6778706\ttotal: 1.86s\tremaining: 2.8s\n",
      "40:\tlearn: 0.6775207\ttotal: 1.89s\tremaining: 2.73s\n",
      "41:\tlearn: 0.6771077\ttotal: 1.92s\tremaining: 2.65s\n",
      "42:\tlearn: 0.6767367\ttotal: 1.97s\tremaining: 2.61s\n",
      "43:\tlearn: 0.6763188\ttotal: 2.02s\tremaining: 2.57s\n",
      "44:\tlearn: 0.6759200\ttotal: 2.05s\tremaining: 2.5s\n",
      "45:\tlearn: 0.6755558\ttotal: 2.07s\tremaining: 2.43s\n",
      "46:\tlearn: 0.6750733\ttotal: 2.13s\tremaining: 2.4s\n",
      "47:\tlearn: 0.6746887\ttotal: 2.19s\tremaining: 2.37s\n",
      "48:\tlearn: 0.6744096\ttotal: 2.22s\tremaining: 2.31s\n",
      "49:\tlearn: 0.6741026\ttotal: 2.24s\tremaining: 2.24s\n",
      "50:\tlearn: 0.6736948\ttotal: 2.32s\tremaining: 2.23s\n",
      "51:\tlearn: 0.6733489\ttotal: 2.37s\tremaining: 2.18s\n",
      "52:\tlearn: 0.6730185\ttotal: 2.39s\tremaining: 2.12s\n",
      "53:\tlearn: 0.6725955\ttotal: 2.42s\tremaining: 2.06s\n",
      "54:\tlearn: 0.6721544\ttotal: 2.5s\tremaining: 2.04s\n",
      "55:\tlearn: 0.6717544\ttotal: 2.54s\tremaining: 2s\n",
      "56:\tlearn: 0.6713761\ttotal: 2.57s\tremaining: 1.94s\n",
      "57:\tlearn: 0.6708970\ttotal: 2.6s\tremaining: 1.88s\n",
      "58:\tlearn: 0.6704116\ttotal: 2.68s\tremaining: 1.86s\n",
      "59:\tlearn: 0.6700740\ttotal: 2.73s\tremaining: 1.82s\n",
      "60:\tlearn: 0.6696431\ttotal: 2.76s\tremaining: 1.76s\n",
      "61:\tlearn: 0.6692694\ttotal: 2.78s\tremaining: 1.7s\n",
      "62:\tlearn: 0.6689315\ttotal: 2.84s\tremaining: 1.67s\n",
      "63:\tlearn: 0.6685792\ttotal: 2.89s\tremaining: 1.63s\n",
      "64:\tlearn: 0.6682820\ttotal: 2.92s\tremaining: 1.57s\n",
      "65:\tlearn: 0.6679269\ttotal: 2.95s\tremaining: 1.52s\n",
      "66:\tlearn: 0.6675009\ttotal: 3s\tremaining: 1.48s\n",
      "67:\tlearn: 0.6672192\ttotal: 3.07s\tremaining: 1.45s\n",
      "68:\tlearn: 0.6668567\ttotal: 3.1s\tremaining: 1.39s\n",
      "69:\tlearn: 0.6664651\ttotal: 3.12s\tremaining: 1.34s\n",
      "70:\tlearn: 0.6661000\ttotal: 3.14s\tremaining: 1.28s\n",
      "71:\tlearn: 0.6656928\ttotal: 3.22s\tremaining: 1.25s\n",
      "72:\tlearn: 0.6653602\ttotal: 3.26s\tremaining: 1.21s\n",
      "73:\tlearn: 0.6650670\ttotal: 3.29s\tremaining: 1.16s\n",
      "74:\tlearn: 0.6646893\ttotal: 3.31s\tremaining: 1.1s\n",
      "75:\tlearn: 0.6642776\ttotal: 3.39s\tremaining: 1.07s\n",
      "76:\tlearn: 0.6639396\ttotal: 3.44s\tremaining: 1.03s\n",
      "77:\tlearn: 0.6636163\ttotal: 3.46s\tremaining: 977ms\n",
      "78:\tlearn: 0.6632718\ttotal: 3.48s\tremaining: 926ms\n",
      "79:\tlearn: 0.6628499\ttotal: 3.55s\tremaining: 888ms\n",
      "80:\tlearn: 0.6625145\ttotal: 3.6s\tremaining: 845ms\n",
      "81:\tlearn: 0.6621938\ttotal: 3.63s\tremaining: 797ms\n",
      "82:\tlearn: 0.6618536\ttotal: 3.65s\tremaining: 748ms\n",
      "83:\tlearn: 0.6615054\ttotal: 3.7s\tremaining: 705ms\n",
      "84:\tlearn: 0.6611500\ttotal: 3.77s\tremaining: 665ms\n",
      "85:\tlearn: 0.6608017\ttotal: 3.8s\tremaining: 619ms\n",
      "86:\tlearn: 0.6605357\ttotal: 3.83s\tremaining: 572ms\n",
      "87:\tlearn: 0.6601478\ttotal: 3.85s\tremaining: 525ms\n",
      "88:\tlearn: 0.6598216\ttotal: 3.93s\tremaining: 486ms\n",
      "89:\tlearn: 0.6594949\ttotal: 3.96s\tremaining: 440ms\n",
      "90:\tlearn: 0.6591755\ttotal: 3.98s\tremaining: 394ms\n",
      "91:\tlearn: 0.6587571\ttotal: 4.03s\tremaining: 351ms\n",
      "92:\tlearn: 0.6584654\ttotal: 4.1s\tremaining: 309ms\n",
      "93:\tlearn: 0.6581097\ttotal: 4.13s\tremaining: 264ms\n",
      "94:\tlearn: 0.6577888\ttotal: 4.16s\tremaining: 219ms\n",
      "95:\tlearn: 0.6574234\ttotal: 4.18s\tremaining: 174ms\n",
      "96:\tlearn: 0.6570673\ttotal: 4.25s\tremaining: 131ms\n",
      "97:\tlearn: 0.6567760\ttotal: 4.31s\tremaining: 87.9ms\n",
      "98:\tlearn: 0.6564368\ttotal: 4.34s\tremaining: 43.8ms\n",
      "99:\tlearn: 0.6561405\ttotal: 4.36s\tremaining: 0us\n",
      "0:\tlearn: 0.6928125\ttotal: 25.6ms\tremaining: 2.54s\n",
      "1:\tlearn: 0.6924192\ttotal: 109ms\tremaining: 5.32s\n",
      "2:\tlearn: 0.6920692\ttotal: 140ms\tremaining: 4.54s\n",
      "3:\tlearn: 0.6916966\ttotal: 164ms\tremaining: 3.93s\n",
      "4:\tlearn: 0.6912437\ttotal: 218ms\tremaining: 4.14s\n",
      "5:\tlearn: 0.6908409\ttotal: 283ms\tremaining: 4.43s\n",
      "6:\tlearn: 0.6904222\ttotal: 316ms\tremaining: 4.2s\n",
      "7:\tlearn: 0.6899765\ttotal: 338ms\tremaining: 3.88s\n",
      "8:\tlearn: 0.6896065\ttotal: 363ms\tremaining: 3.67s\n",
      "9:\tlearn: 0.6893188\ttotal: 440ms\tremaining: 3.96s\n",
      "10:\tlearn: 0.6889226\ttotal: 478ms\tremaining: 3.87s\n",
      "11:\tlearn: 0.6884930\ttotal: 497ms\tremaining: 3.65s\n",
      "12:\tlearn: 0.6880812\ttotal: 520ms\tremaining: 3.48s\n",
      "13:\tlearn: 0.6876727\ttotal: 568ms\tremaining: 3.49s\n",
      "14:\tlearn: 0.6872335\ttotal: 633ms\tremaining: 3.59s\n",
      "15:\tlearn: 0.6867679\ttotal: 666ms\tremaining: 3.5s\n",
      "16:\tlearn: 0.6863767\ttotal: 692ms\tremaining: 3.38s\n",
      "17:\tlearn: 0.6859265\ttotal: 715ms\tremaining: 3.26s\n",
      "18:\tlearn: 0.6855516\ttotal: 800ms\tremaining: 3.41s\n",
      "19:\tlearn: 0.6851507\ttotal: 853ms\tremaining: 3.41s\n",
      "20:\tlearn: 0.6847767\ttotal: 884ms\tremaining: 3.32s\n",
      "21:\tlearn: 0.6844245\ttotal: 908ms\tremaining: 3.22s\n",
      "22:\tlearn: 0.6839925\ttotal: 930ms\tremaining: 3.11s\n",
      "23:\tlearn: 0.6835840\ttotal: 1.01s\tremaining: 3.2s\n",
      "24:\tlearn: 0.6831905\ttotal: 1.05s\tremaining: 3.15s\n",
      "25:\tlearn: 0.6827178\ttotal: 1.08s\tremaining: 3.07s\n",
      "26:\tlearn: 0.6822692\ttotal: 1.1s\tremaining: 2.98s\n",
      "27:\tlearn: 0.6819270\ttotal: 1.15s\tremaining: 2.96s\n",
      "28:\tlearn: 0.6816009\ttotal: 1.22s\tremaining: 3s\n",
      "29:\tlearn: 0.6811746\ttotal: 1.25s\tremaining: 2.93s\n",
      "30:\tlearn: 0.6807955\ttotal: 1.28s\tremaining: 2.85s\n",
      "31:\tlearn: 0.6804276\ttotal: 1.3s\tremaining: 2.76s\n",
      "32:\tlearn: 0.6799777\ttotal: 1.38s\tremaining: 2.79s\n",
      "33:\tlearn: 0.6795982\ttotal: 1.41s\tremaining: 2.74s\n",
      "34:\tlearn: 0.6792754\ttotal: 1.44s\tremaining: 2.67s\n",
      "35:\tlearn: 0.6789280\ttotal: 1.46s\tremaining: 2.6s\n",
      "36:\tlearn: 0.6785216\ttotal: 1.54s\tremaining: 2.62s\n",
      "37:\tlearn: 0.6781715\ttotal: 1.59s\tremaining: 2.59s\n",
      "38:\tlearn: 0.6777163\ttotal: 1.61s\tremaining: 2.52s\n",
      "39:\tlearn: 0.6774077\ttotal: 1.64s\tremaining: 2.46s\n",
      "40:\tlearn: 0.6770706\ttotal: 1.71s\tremaining: 2.47s\n",
      "41:\tlearn: 0.6767190\ttotal: 1.76s\tremaining: 2.43s\n",
      "42:\tlearn: 0.6763947\ttotal: 1.79s\tremaining: 2.37s\n",
      "43:\tlearn: 0.6759940\ttotal: 1.81s\tremaining: 2.31s\n",
      "44:\tlearn: 0.6756682\ttotal: 1.89s\tremaining: 2.31s\n",
      "45:\tlearn: 0.6752470\ttotal: 1.94s\tremaining: 2.28s\n",
      "46:\tlearn: 0.6747107\ttotal: 1.97s\tremaining: 2.22s\n",
      "47:\tlearn: 0.6743046\ttotal: 1.99s\tremaining: 2.16s\n",
      "48:\tlearn: 0.6739728\ttotal: 2.04s\tremaining: 2.13s\n",
      "49:\tlearn: 0.6737110\ttotal: 2.11s\tremaining: 2.11s\n",
      "50:\tlearn: 0.6733482\ttotal: 2.14s\tremaining: 2.06s\n",
      "51:\tlearn: 0.6729321\ttotal: 2.16s\tremaining: 2s\n",
      "52:\tlearn: 0.6725244\ttotal: 2.23s\tremaining: 1.98s\n",
      "53:\tlearn: 0.6721082\ttotal: 2.29s\tremaining: 1.95s\n",
      "54:\tlearn: 0.6717895\ttotal: 2.32s\tremaining: 1.9s\n",
      "55:\tlearn: 0.6714430\ttotal: 2.34s\tremaining: 1.84s\n",
      "56:\tlearn: 0.6710553\ttotal: 2.4s\tremaining: 1.81s\n",
      "57:\tlearn: 0.6707304\ttotal: 2.46s\tremaining: 1.78s\n",
      "58:\tlearn: 0.6702395\ttotal: 2.49s\tremaining: 1.73s\n",
      "59:\tlearn: 0.6699792\ttotal: 2.52s\tremaining: 1.68s\n",
      "60:\tlearn: 0.6695233\ttotal: 2.58s\tremaining: 1.65s\n",
      "61:\tlearn: 0.6691586\ttotal: 2.65s\tremaining: 1.62s\n",
      "62:\tlearn: 0.6687879\ttotal: 2.68s\tremaining: 1.57s\n",
      "63:\tlearn: 0.6684275\ttotal: 2.7s\tremaining: 1.52s\n",
      "64:\tlearn: 0.6680790\ttotal: 2.78s\tremaining: 1.5s\n",
      "65:\tlearn: 0.6676075\ttotal: 2.83s\tremaining: 1.46s\n",
      "66:\tlearn: 0.6672727\ttotal: 2.86s\tremaining: 1.41s\n",
      "67:\tlearn: 0.6669064\ttotal: 2.88s\tremaining: 1.36s\n",
      "68:\tlearn: 0.6664863\ttotal: 2.96s\tremaining: 1.33s\n",
      "69:\tlearn: 0.6661377\ttotal: 3s\tremaining: 1.29s\n",
      "70:\tlearn: 0.6657663\ttotal: 3.03s\tremaining: 1.24s\n",
      "71:\tlearn: 0.6654345\ttotal: 3.05s\tremaining: 1.19s\n",
      "72:\tlearn: 0.6650650\ttotal: 3.09s\tremaining: 1.14s\n",
      "73:\tlearn: 0.6647781\ttotal: 3.16s\tremaining: 1.11s\n",
      "74:\tlearn: 0.6644500\ttotal: 3.2s\tremaining: 1.06s\n",
      "75:\tlearn: 0.6640599\ttotal: 3.22s\tremaining: 1.02s\n",
      "76:\tlearn: 0.6636394\ttotal: 3.24s\tremaining: 969ms\n",
      "77:\tlearn: 0.6632212\ttotal: 3.32s\tremaining: 938ms\n",
      "78:\tlearn: 0.6628407\ttotal: 3.35s\tremaining: 891ms\n",
      "79:\tlearn: 0.6624296\ttotal: 3.38s\tremaining: 844ms\n",
      "80:\tlearn: 0.6621690\ttotal: 3.45s\tremaining: 810ms\n",
      "81:\tlearn: 0.6618570\ttotal: 3.5s\tremaining: 769ms\n",
      "82:\tlearn: 0.6615391\ttotal: 3.53s\tremaining: 724ms\n",
      "83:\tlearn: 0.6611386\ttotal: 3.56s\tremaining: 678ms\n",
      "84:\tlearn: 0.6607283\ttotal: 3.63s\tremaining: 641ms\n",
      "85:\tlearn: 0.6603405\ttotal: 3.68s\tremaining: 599ms\n",
      "86:\tlearn: 0.6600291\ttotal: 3.71s\tremaining: 554ms\n",
      "87:\tlearn: 0.6596648\ttotal: 3.73s\tremaining: 509ms\n",
      "88:\tlearn: 0.6593278\ttotal: 3.76s\tremaining: 464ms\n",
      "89:\tlearn: 0.6590249\ttotal: 3.83s\tremaining: 426ms\n",
      "90:\tlearn: 0.6585883\ttotal: 3.88s\tremaining: 384ms\n",
      "91:\tlearn: 0.6582119\ttotal: 3.91s\tremaining: 340ms\n",
      "92:\tlearn: 0.6578826\ttotal: 3.93s\tremaining: 296ms\n",
      "93:\tlearn: 0.6575933\ttotal: 4s\tremaining: 255ms\n",
      "94:\tlearn: 0.6572597\ttotal: 4.05s\tremaining: 213ms\n",
      "95:\tlearn: 0.6568965\ttotal: 4.08s\tremaining: 170ms\n",
      "96:\tlearn: 0.6565386\ttotal: 4.11s\tremaining: 127ms\n",
      "97:\tlearn: 0.6561001\ttotal: 4.16s\tremaining: 84.9ms\n",
      "98:\tlearn: 0.6557667\ttotal: 4.22s\tremaining: 42.6ms\n",
      "99:\tlearn: 0.6554073\ttotal: 4.25s\tremaining: 0us\n",
      "0:\tlearn: 0.6927426\ttotal: 25.5ms\tremaining: 2.52s\n",
      "1:\tlearn: 0.6923141\ttotal: 104ms\tremaining: 5.1s\n",
      "2:\tlearn: 0.6918381\ttotal: 151ms\tremaining: 4.88s\n",
      "3:\tlearn: 0.6914480\ttotal: 179ms\tremaining: 4.29s\n",
      "4:\tlearn: 0.6910990\ttotal: 202ms\tremaining: 3.84s\n",
      "5:\tlearn: 0.6906907\ttotal: 270ms\tremaining: 4.22s\n",
      "6:\tlearn: 0.6902315\ttotal: 325ms\tremaining: 4.32s\n",
      "7:\tlearn: 0.6898437\ttotal: 359ms\tremaining: 4.13s\n",
      "8:\tlearn: 0.6894454\ttotal: 382ms\tremaining: 3.86s\n",
      "9:\tlearn: 0.6890126\ttotal: 444ms\tremaining: 3.99s\n",
      "10:\tlearn: 0.6886276\ttotal: 508ms\tremaining: 4.11s\n",
      "11:\tlearn: 0.6882232\ttotal: 535ms\tremaining: 3.92s\n",
      "12:\tlearn: 0.6878482\ttotal: 557ms\tremaining: 3.73s\n",
      "13:\tlearn: 0.6874067\ttotal: 630ms\tremaining: 3.87s\n",
      "14:\tlearn: 0.6870217\ttotal: 682ms\tremaining: 3.86s\n",
      "15:\tlearn: 0.6866582\ttotal: 711ms\tremaining: 3.73s\n",
      "16:\tlearn: 0.6862076\ttotal: 735ms\tremaining: 3.59s\n",
      "17:\tlearn: 0.6858083\ttotal: 812ms\tremaining: 3.7s\n",
      "18:\tlearn: 0.6853885\ttotal: 861ms\tremaining: 3.67s\n",
      "19:\tlearn: 0.6849867\ttotal: 889ms\tremaining: 3.56s\n",
      "20:\tlearn: 0.6845993\ttotal: 915ms\tremaining: 3.44s\n",
      "21:\tlearn: 0.6841484\ttotal: 994ms\tremaining: 3.52s\n",
      "22:\tlearn: 0.6837532\ttotal: 1.04s\tremaining: 3.48s\n",
      "23:\tlearn: 0.6833631\ttotal: 1.07s\tremaining: 3.38s\n",
      "24:\tlearn: 0.6828684\ttotal: 1.09s\tremaining: 3.28s\n",
      "25:\tlearn: 0.6823736\ttotal: 1.15s\tremaining: 3.29s\n",
      "26:\tlearn: 0.6819184\ttotal: 1.21s\tremaining: 3.28s\n",
      "27:\tlearn: 0.6815192\ttotal: 1.24s\tremaining: 3.19s\n",
      "28:\tlearn: 0.6810901\ttotal: 1.26s\tremaining: 3.1s\n",
      "29:\tlearn: 0.6807164\ttotal: 1.34s\tremaining: 3.14s\n",
      "30:\tlearn: 0.6803412\ttotal: 1.39s\tremaining: 3.1s\n",
      "31:\tlearn: 0.6799643\ttotal: 1.42s\tremaining: 3.02s\n",
      "32:\tlearn: 0.6796025\ttotal: 1.44s\tremaining: 2.93s\n",
      "33:\tlearn: 0.6791786\ttotal: 1.52s\tremaining: 2.95s\n",
      "34:\tlearn: 0.6788704\ttotal: 1.57s\tremaining: 2.91s\n",
      "35:\tlearn: 0.6785363\ttotal: 1.6s\tremaining: 2.84s\n",
      "36:\tlearn: 0.6781061\ttotal: 1.62s\tremaining: 2.76s\n",
      "37:\tlearn: 0.6778082\ttotal: 1.67s\tremaining: 2.72s\n",
      "38:\tlearn: 0.6773766\ttotal: 1.73s\tremaining: 2.71s\n",
      "39:\tlearn: 0.6770110\ttotal: 1.76s\tremaining: 2.64s\n",
      "40:\tlearn: 0.6765499\ttotal: 1.78s\tremaining: 2.57s\n",
      "41:\tlearn: 0.6761529\ttotal: 1.81s\tremaining: 2.5s\n",
      "42:\tlearn: 0.6758192\ttotal: 1.89s\tremaining: 2.51s\n",
      "43:\tlearn: 0.6753856\ttotal: 1.96s\tremaining: 2.49s\n",
      "44:\tlearn: 0.6750061\ttotal: 1.98s\tremaining: 2.42s\n",
      "45:\tlearn: 0.6745296\ttotal: 2.01s\tremaining: 2.36s\n",
      "46:\tlearn: 0.6741235\ttotal: 2.03s\tremaining: 2.29s\n",
      "47:\tlearn: 0.6737205\ttotal: 2.08s\tremaining: 2.26s\n",
      "48:\tlearn: 0.6734244\ttotal: 2.14s\tremaining: 2.23s\n",
      "49:\tlearn: 0.6729990\ttotal: 2.17s\tremaining: 2.17s\n",
      "50:\tlearn: 0.6726227\ttotal: 2.19s\tremaining: 2.1s\n",
      "51:\tlearn: 0.6723204\ttotal: 2.27s\tremaining: 2.1s\n",
      "52:\tlearn: 0.6719861\ttotal: 2.32s\tremaining: 2.06s\n",
      "53:\tlearn: 0.6715183\ttotal: 2.35s\tremaining: 2s\n",
      "54:\tlearn: 0.6710721\ttotal: 2.37s\tremaining: 1.94s\n",
      "55:\tlearn: 0.6706943\ttotal: 2.45s\tremaining: 1.92s\n",
      "56:\tlearn: 0.6703057\ttotal: 2.5s\tremaining: 1.88s\n",
      "57:\tlearn: 0.6698878\ttotal: 2.52s\tremaining: 1.82s\n",
      "58:\tlearn: 0.6695346\ttotal: 2.54s\tremaining: 1.77s\n",
      "59:\tlearn: 0.6692219\ttotal: 2.63s\tremaining: 1.75s\n",
      "60:\tlearn: 0.6688809\ttotal: 2.67s\tremaining: 1.71s\n",
      "61:\tlearn: 0.6684762\ttotal: 2.7s\tremaining: 1.66s\n",
      "62:\tlearn: 0.6680799\ttotal: 2.72s\tremaining: 1.6s\n",
      "63:\tlearn: 0.6676635\ttotal: 2.8s\tremaining: 1.58s\n",
      "64:\tlearn: 0.6673265\ttotal: 2.84s\tremaining: 1.53s\n",
      "65:\tlearn: 0.6669882\ttotal: 2.86s\tremaining: 1.48s\n",
      "66:\tlearn: 0.6666715\ttotal: 2.89s\tremaining: 1.42s\n",
      "67:\tlearn: 0.6663471\ttotal: 2.96s\tremaining: 1.39s\n",
      "68:\tlearn: 0.6658869\ttotal: 3s\tremaining: 1.35s\n",
      "69:\tlearn: 0.6655760\ttotal: 3.02s\tremaining: 1.29s\n",
      "70:\tlearn: 0.6651830\ttotal: 3.04s\tremaining: 1.24s\n",
      "71:\tlearn: 0.6647781\ttotal: 3.13s\tremaining: 1.22s\n",
      "72:\tlearn: 0.6644142\ttotal: 3.15s\tremaining: 1.17s\n",
      "73:\tlearn: 0.6640688\ttotal: 3.18s\tremaining: 1.11s\n",
      "74:\tlearn: 0.6635349\ttotal: 3.25s\tremaining: 1.08s\n",
      "75:\tlearn: 0.6631295\ttotal: 3.29s\tremaining: 1.04s\n",
      "76:\tlearn: 0.6627524\ttotal: 3.32s\tremaining: 991ms\n",
      "77:\tlearn: 0.6623611\ttotal: 3.34s\tremaining: 942ms\n",
      "78:\tlearn: 0.6619758\ttotal: 3.36s\tremaining: 894ms\n",
      "79:\tlearn: 0.6616240\ttotal: 3.44s\tremaining: 861ms\n",
      "80:\tlearn: 0.6612418\ttotal: 3.48s\tremaining: 817ms\n",
      "81:\tlearn: 0.6610022\ttotal: 3.51s\tremaining: 771ms\n",
      "82:\tlearn: 0.6606407\ttotal: 3.53s\tremaining: 724ms\n",
      "83:\tlearn: 0.6602552\ttotal: 3.61s\tremaining: 688ms\n",
      "84:\tlearn: 0.6599052\ttotal: 3.66s\tremaining: 645ms\n",
      "85:\tlearn: 0.6594990\ttotal: 3.69s\tremaining: 600ms\n",
      "86:\tlearn: 0.6591254\ttotal: 3.71s\tremaining: 554ms\n",
      "87:\tlearn: 0.6587085\ttotal: 3.78s\tremaining: 515ms\n",
      "88:\tlearn: 0.6583619\ttotal: 3.83s\tremaining: 474ms\n",
      "89:\tlearn: 0.6580541\ttotal: 3.86s\tremaining: 429ms\n",
      "90:\tlearn: 0.6576670\ttotal: 3.88s\tremaining: 384ms\n",
      "91:\tlearn: 0.6572947\ttotal: 3.96s\tremaining: 344ms\n",
      "92:\tlearn: 0.6569349\ttotal: 4.01s\tremaining: 302ms\n",
      "93:\tlearn: 0.6565843\ttotal: 4.04s\tremaining: 258ms\n",
      "94:\tlearn: 0.6562434\ttotal: 4.06s\tremaining: 214ms\n",
      "95:\tlearn: 0.6557998\ttotal: 4.12s\tremaining: 172ms\n",
      "96:\tlearn: 0.6554121\ttotal: 4.18s\tremaining: 129ms\n",
      "97:\tlearn: 0.6550249\ttotal: 4.21s\tremaining: 86ms\n",
      "98:\tlearn: 0.6547095\ttotal: 4.24s\tremaining: 42.8ms\n",
      "99:\tlearn: 0.6543737\ttotal: 4.29s\tremaining: 0us\n",
      "0:\tlearn: 0.6928090\ttotal: 25.6ms\tremaining: 2.54s\n",
      "1:\tlearn: 0.6923915\ttotal: 94.4ms\tremaining: 4.63s\n",
      "2:\tlearn: 0.6919733\ttotal: 153ms\tremaining: 4.93s\n",
      "3:\tlearn: 0.6915595\ttotal: 181ms\tremaining: 4.35s\n",
      "4:\tlearn: 0.6911915\ttotal: 204ms\tremaining: 3.88s\n",
      "5:\tlearn: 0.6908417\ttotal: 278ms\tremaining: 4.35s\n",
      "6:\tlearn: 0.6904444\ttotal: 327ms\tremaining: 4.35s\n",
      "7:\tlearn: 0.6900264\ttotal: 356ms\tremaining: 4.09s\n",
      "8:\tlearn: 0.6896555\ttotal: 379ms\tremaining: 3.83s\n",
      "9:\tlearn: 0.6892854\ttotal: 401ms\tremaining: 3.61s\n",
      "10:\tlearn: 0.6889674\ttotal: 484ms\tremaining: 3.91s\n",
      "11:\tlearn: 0.6885447\ttotal: 522ms\tremaining: 3.83s\n",
      "12:\tlearn: 0.6882052\ttotal: 546ms\tremaining: 3.65s\n",
      "13:\tlearn: 0.6877588\ttotal: 569ms\tremaining: 3.49s\n",
      "14:\tlearn: 0.6873178\ttotal: 648ms\tremaining: 3.67s\n",
      "15:\tlearn: 0.6869464\ttotal: 694ms\tremaining: 3.65s\n",
      "16:\tlearn: 0.6865085\ttotal: 721ms\tremaining: 3.52s\n",
      "17:\tlearn: 0.6860544\ttotal: 743ms\tremaining: 3.39s\n",
      "18:\tlearn: 0.6857206\ttotal: 824ms\tremaining: 3.51s\n",
      "19:\tlearn: 0.6852916\ttotal: 868ms\tremaining: 3.47s\n",
      "20:\tlearn: 0.6848896\ttotal: 897ms\tremaining: 3.38s\n",
      "21:\tlearn: 0.6844623\ttotal: 920ms\tremaining: 3.26s\n",
      "22:\tlearn: 0.6840911\ttotal: 999ms\tremaining: 3.35s\n",
      "23:\tlearn: 0.6836518\ttotal: 1.04s\tremaining: 3.31s\n",
      "24:\tlearn: 0.6832255\ttotal: 1.07s\tremaining: 3.22s\n",
      "25:\tlearn: 0.6828714\ttotal: 1.1s\tremaining: 3.12s\n",
      "26:\tlearn: 0.6824456\ttotal: 1.17s\tremaining: 3.16s\n",
      "27:\tlearn: 0.6820908\ttotal: 1.22s\tremaining: 3.14s\n",
      "28:\tlearn: 0.6816764\ttotal: 1.25s\tremaining: 3.05s\n",
      "29:\tlearn: 0.6811849\ttotal: 1.27s\tremaining: 2.96s\n",
      "30:\tlearn: 0.6807649\ttotal: 1.32s\tremaining: 2.93s\n",
      "31:\tlearn: 0.6803459\ttotal: 1.39s\tremaining: 2.95s\n",
      "32:\tlearn: 0.6798540\ttotal: 1.41s\tremaining: 2.87s\n",
      "33:\tlearn: 0.6794408\ttotal: 1.44s\tremaining: 2.79s\n",
      "34:\tlearn: 0.6790353\ttotal: 1.46s\tremaining: 2.71s\n",
      "35:\tlearn: 0.6787076\ttotal: 1.54s\tremaining: 2.74s\n",
      "36:\tlearn: 0.6783133\ttotal: 1.58s\tremaining: 2.7s\n",
      "37:\tlearn: 0.6779725\ttotal: 1.61s\tremaining: 2.63s\n",
      "38:\tlearn: 0.6776476\ttotal: 1.64s\tremaining: 2.56s\n",
      "39:\tlearn: 0.6772529\ttotal: 1.66s\tremaining: 2.49s\n",
      "40:\tlearn: 0.6768227\ttotal: 1.74s\tremaining: 2.5s\n",
      "41:\tlearn: 0.6764702\ttotal: 1.78s\tremaining: 2.46s\n",
      "42:\tlearn: 0.6761256\ttotal: 1.82s\tremaining: 2.41s\n",
      "43:\tlearn: 0.6757666\ttotal: 1.85s\tremaining: 2.35s\n",
      "44:\tlearn: 0.6754356\ttotal: 1.93s\tremaining: 2.36s\n",
      "45:\tlearn: 0.6751135\ttotal: 1.97s\tremaining: 2.32s\n",
      "46:\tlearn: 0.6746235\ttotal: 2s\tremaining: 2.26s\n",
      "47:\tlearn: 0.6742023\ttotal: 2.03s\tremaining: 2.2s\n",
      "48:\tlearn: 0.6738845\ttotal: 2.11s\tremaining: 2.19s\n",
      "49:\tlearn: 0.6734985\ttotal: 2.15s\tremaining: 2.15s\n",
      "50:\tlearn: 0.6731490\ttotal: 2.18s\tremaining: 2.09s\n",
      "51:\tlearn: 0.6727427\ttotal: 2.2s\tremaining: 2.03s\n",
      "52:\tlearn: 0.6723971\ttotal: 2.29s\tremaining: 2.03s\n",
      "53:\tlearn: 0.6719829\ttotal: 2.32s\tremaining: 1.98s\n",
      "54:\tlearn: 0.6714932\ttotal: 2.35s\tremaining: 1.92s\n",
      "55:\tlearn: 0.6710911\ttotal: 2.37s\tremaining: 1.86s\n",
      "56:\tlearn: 0.6707152\ttotal: 2.46s\tremaining: 1.85s\n",
      "57:\tlearn: 0.6703591\ttotal: 2.5s\tremaining: 1.81s\n",
      "58:\tlearn: 0.6699135\ttotal: 2.53s\tremaining: 1.76s\n",
      "59:\tlearn: 0.6694816\ttotal: 2.55s\tremaining: 1.7s\n",
      "60:\tlearn: 0.6690564\ttotal: 2.63s\tremaining: 1.68s\n",
      "61:\tlearn: 0.6686506\ttotal: 2.67s\tremaining: 1.64s\n",
      "62:\tlearn: 0.6683025\ttotal: 2.7s\tremaining: 1.59s\n",
      "63:\tlearn: 0.6679426\ttotal: 2.73s\tremaining: 1.53s\n",
      "64:\tlearn: 0.6675924\ttotal: 2.8s\tremaining: 1.51s\n",
      "65:\tlearn: 0.6672328\ttotal: 2.85s\tremaining: 1.47s\n",
      "66:\tlearn: 0.6668592\ttotal: 2.88s\tremaining: 1.42s\n",
      "67:\tlearn: 0.6664030\ttotal: 2.91s\tremaining: 1.37s\n",
      "68:\tlearn: 0.6659717\ttotal: 2.98s\tremaining: 1.34s\n",
      "69:\tlearn: 0.6656816\ttotal: 3.01s\tremaining: 1.29s\n",
      "70:\tlearn: 0.6652850\ttotal: 3.04s\tremaining: 1.24s\n",
      "71:\tlearn: 0.6649004\ttotal: 3.06s\tremaining: 1.19s\n",
      "72:\tlearn: 0.6645145\ttotal: 3.14s\tremaining: 1.16s\n",
      "73:\tlearn: 0.6642370\ttotal: 3.17s\tremaining: 1.11s\n",
      "74:\tlearn: 0.6638383\ttotal: 3.19s\tremaining: 1.06s\n",
      "75:\tlearn: 0.6633973\ttotal: 3.26s\tremaining: 1.03s\n",
      "76:\tlearn: 0.6631056\ttotal: 3.31s\tremaining: 989ms\n",
      "77:\tlearn: 0.6627008\ttotal: 3.34s\tremaining: 943ms\n",
      "78:\tlearn: 0.6623739\ttotal: 3.37s\tremaining: 895ms\n",
      "79:\tlearn: 0.6620561\ttotal: 3.39s\tremaining: 847ms\n",
      "80:\tlearn: 0.6617036\ttotal: 3.47s\tremaining: 813ms\n",
      "81:\tlearn: 0.6613458\ttotal: 3.5s\tremaining: 770ms\n",
      "82:\tlearn: 0.6610306\ttotal: 3.52s\tremaining: 722ms\n",
      "83:\tlearn: 0.6606696\ttotal: 3.55s\tremaining: 676ms\n",
      "84:\tlearn: 0.6603253\ttotal: 3.62s\tremaining: 639ms\n",
      "85:\tlearn: 0.6600132\ttotal: 3.67s\tremaining: 597ms\n",
      "86:\tlearn: 0.6595687\ttotal: 3.69s\tremaining: 552ms\n",
      "87:\tlearn: 0.6592056\ttotal: 3.71s\tremaining: 507ms\n",
      "88:\tlearn: 0.6588503\ttotal: 3.8s\tremaining: 470ms\n",
      "89:\tlearn: 0.6584230\ttotal: 3.83s\tremaining: 426ms\n",
      "90:\tlearn: 0.6580301\ttotal: 3.86s\tremaining: 382ms\n",
      "91:\tlearn: 0.6576232\ttotal: 3.88s\tremaining: 338ms\n",
      "92:\tlearn: 0.6572748\ttotal: 3.96s\tremaining: 298ms\n",
      "93:\tlearn: 0.6568795\ttotal: 4.01s\tremaining: 256ms\n",
      "94:\tlearn: 0.6565074\ttotal: 4.04s\tremaining: 212ms\n",
      "95:\tlearn: 0.6561775\ttotal: 4.06s\tremaining: 169ms\n",
      "96:\tlearn: 0.6558262\ttotal: 4.14s\tremaining: 128ms\n",
      "97:\tlearn: 0.6553862\ttotal: 4.18s\tremaining: 85.4ms\n",
      "98:\tlearn: 0.6550533\ttotal: 4.21s\tremaining: 42.5ms\n",
      "99:\tlearn: 0.6547033\ttotal: 4.23s\tremaining: 0us\n",
      "0:\tlearn: 0.6897409\ttotal: 72ms\tremaining: 35.9s\n",
      "1:\tlearn: 0.6851031\ttotal: 103ms\tremaining: 25.7s\n",
      "2:\tlearn: 0.6819544\ttotal: 128ms\tremaining: 21.2s\n",
      "3:\tlearn: 0.6781778\ttotal: 150ms\tremaining: 18.7s\n",
      "4:\tlearn: 0.6748231\ttotal: 221ms\tremaining: 21.9s\n",
      "5:\tlearn: 0.6712065\ttotal: 268ms\tremaining: 22s\n",
      "6:\tlearn: 0.6672528\ttotal: 295ms\tremaining: 20.8s\n",
      "7:\tlearn: 0.6631670\ttotal: 317ms\tremaining: 19.5s\n",
      "8:\tlearn: 0.6588543\ttotal: 383ms\tremaining: 20.9s\n",
      "9:\tlearn: 0.6558000\ttotal: 428ms\tremaining: 21s\n",
      "10:\tlearn: 0.6524273\ttotal: 452ms\tremaining: 20.1s\n",
      "11:\tlearn: 0.6487875\ttotal: 473ms\tremaining: 19.2s\n",
      "12:\tlearn: 0.6458602\ttotal: 548ms\tremaining: 20.5s\n",
      "13:\tlearn: 0.6429787\ttotal: 590ms\tremaining: 20.5s\n",
      "14:\tlearn: 0.6396250\ttotal: 613ms\tremaining: 19.8s\n",
      "15:\tlearn: 0.6354751\ttotal: 661ms\tremaining: 20s\n",
      "16:\tlearn: 0.6322472\ttotal: 726ms\tremaining: 20.6s\n",
      "17:\tlearn: 0.6288718\ttotal: 758ms\tremaining: 20.3s\n",
      "18:\tlearn: 0.6252919\ttotal: 785ms\tremaining: 19.9s\n",
      "19:\tlearn: 0.6226420\ttotal: 819ms\tremaining: 19.7s\n",
      "20:\tlearn: 0.6196443\ttotal: 892ms\tremaining: 20.3s\n",
      "21:\tlearn: 0.6166113\ttotal: 927ms\tremaining: 20.1s\n",
      "22:\tlearn: 0.6135774\ttotal: 955ms\tremaining: 19.8s\n",
      "23:\tlearn: 0.6100069\ttotal: 977ms\tremaining: 19.4s\n",
      "24:\tlearn: 0.6070831\ttotal: 1.04s\tremaining: 19.7s\n",
      "25:\tlearn: 0.6032144\ttotal: 1.09s\tremaining: 19.9s\n",
      "26:\tlearn: 0.6001844\ttotal: 1.12s\tremaining: 19.6s\n",
      "27:\tlearn: 0.5976551\ttotal: 1.14s\tremaining: 19.3s\n",
      "28:\tlearn: 0.5949169\ttotal: 1.16s\tremaining: 18.9s\n",
      "29:\tlearn: 0.5921504\ttotal: 1.23s\tremaining: 19.3s\n",
      "30:\tlearn: 0.5891235\ttotal: 1.26s\tremaining: 19.1s\n",
      "31:\tlearn: 0.5862334\ttotal: 1.28s\tremaining: 18.8s\n",
      "32:\tlearn: 0.5831964\ttotal: 1.3s\tremaining: 18.4s\n",
      "33:\tlearn: 0.5804971\ttotal: 1.37s\tremaining: 18.8s\n",
      "34:\tlearn: 0.5777558\ttotal: 1.42s\tremaining: 18.9s\n",
      "35:\tlearn: 0.5757198\ttotal: 1.45s\tremaining: 18.7s\n",
      "36:\tlearn: 0.5730825\ttotal: 1.47s\tremaining: 18.4s\n",
      "37:\tlearn: 0.5710644\ttotal: 1.54s\tremaining: 18.7s\n",
      "38:\tlearn: 0.5680692\ttotal: 1.59s\tremaining: 18.8s\n",
      "39:\tlearn: 0.5654977\ttotal: 1.62s\tremaining: 18.7s\n",
      "40:\tlearn: 0.5620425\ttotal: 1.65s\tremaining: 18.4s\n",
      "41:\tlearn: 0.5594203\ttotal: 1.69s\tremaining: 18.5s\n",
      "42:\tlearn: 0.5561147\ttotal: 1.76s\tremaining: 18.7s\n",
      "43:\tlearn: 0.5535242\ttotal: 1.79s\tremaining: 18.5s\n",
      "44:\tlearn: 0.5508610\ttotal: 1.81s\tremaining: 18.3s\n",
      "45:\tlearn: 0.5485092\ttotal: 1.83s\tremaining: 18.1s\n",
      "46:\tlearn: 0.5456415\ttotal: 1.88s\tremaining: 18.1s\n",
      "47:\tlearn: 0.5435045\ttotal: 1.94s\tremaining: 18.2s\n",
      "48:\tlearn: 0.5413366\ttotal: 1.97s\tremaining: 18.1s\n",
      "49:\tlearn: 0.5389609\ttotal: 1.99s\tremaining: 17.9s\n",
      "50:\tlearn: 0.5365702\ttotal: 2.01s\tremaining: 17.7s\n",
      "51:\tlearn: 0.5343139\ttotal: 2.08s\tremaining: 17.9s\n",
      "52:\tlearn: 0.5319409\ttotal: 2.12s\tremaining: 17.9s\n",
      "53:\tlearn: 0.5291593\ttotal: 2.15s\tremaining: 17.8s\n",
      "54:\tlearn: 0.5264368\ttotal: 2.23s\tremaining: 18s\n",
      "55:\tlearn: 0.5242548\ttotal: 2.27s\tremaining: 18s\n",
      "56:\tlearn: 0.5219020\ttotal: 2.3s\tremaining: 17.9s\n",
      "57:\tlearn: 0.5193127\ttotal: 2.33s\tremaining: 17.8s\n",
      "58:\tlearn: 0.5171179\ttotal: 2.36s\tremaining: 17.6s\n",
      "59:\tlearn: 0.5141317\ttotal: 2.39s\tremaining: 17.5s\n",
      "60:\tlearn: 0.5109649\ttotal: 2.41s\tremaining: 17.3s\n",
      "61:\tlearn: 0.5088121\ttotal: 2.43s\tremaining: 17.2s\n",
      "62:\tlearn: 0.5073270\ttotal: 2.51s\tremaining: 17.4s\n",
      "63:\tlearn: 0.5054981\ttotal: 2.55s\tremaining: 17.4s\n",
      "64:\tlearn: 0.5035343\ttotal: 2.57s\tremaining: 17.2s\n",
      "65:\tlearn: 0.5016720\ttotal: 2.6s\tremaining: 17.1s\n",
      "66:\tlearn: 0.4994468\ttotal: 2.62s\tremaining: 16.9s\n",
      "67:\tlearn: 0.4977276\ttotal: 2.66s\tremaining: 16.9s\n",
      "68:\tlearn: 0.4955628\ttotal: 2.73s\tremaining: 17s\n",
      "69:\tlearn: 0.4936294\ttotal: 2.78s\tremaining: 17.1s\n",
      "70:\tlearn: 0.4913956\ttotal: 2.8s\tremaining: 16.9s\n",
      "71:\tlearn: 0.4892595\ttotal: 2.85s\tremaining: 17s\n",
      "72:\tlearn: 0.4871256\ttotal: 2.91s\tremaining: 17s\n",
      "73:\tlearn: 0.4850122\ttotal: 2.93s\tremaining: 16.9s\n",
      "74:\tlearn: 0.4832033\ttotal: 2.96s\tremaining: 16.8s\n",
      "75:\tlearn: 0.4808120\ttotal: 2.98s\tremaining: 16.6s\n",
      "76:\tlearn: 0.4786106\ttotal: 3.05s\tremaining: 16.8s\n",
      "77:\tlearn: 0.4756510\ttotal: 3.09s\tremaining: 16.7s\n",
      "78:\tlearn: 0.4733143\ttotal: 3.13s\tremaining: 16.7s\n",
      "79:\tlearn: 0.4713926\ttotal: 3.15s\tremaining: 16.6s\n",
      "80:\tlearn: 0.4692093\ttotal: 3.22s\tremaining: 16.7s\n",
      "81:\tlearn: 0.4669177\ttotal: 3.28s\tremaining: 16.7s\n",
      "82:\tlearn: 0.4648681\ttotal: 3.3s\tremaining: 16.6s\n",
      "83:\tlearn: 0.4627843\ttotal: 3.32s\tremaining: 16.5s\n",
      "84:\tlearn: 0.4606674\ttotal: 3.34s\tremaining: 16.3s\n",
      "85:\tlearn: 0.4587707\ttotal: 3.42s\tremaining: 16.5s\n",
      "86:\tlearn: 0.4574747\ttotal: 3.48s\tremaining: 16.5s\n",
      "87:\tlearn: 0.4555518\ttotal: 3.5s\tremaining: 16.4s\n",
      "88:\tlearn: 0.4540372\ttotal: 3.54s\tremaining: 16.4s\n",
      "89:\tlearn: 0.4527693\ttotal: 3.6s\tremaining: 16.4s\n",
      "90:\tlearn: 0.4512411\ttotal: 3.63s\tremaining: 16.3s\n",
      "91:\tlearn: 0.4493992\ttotal: 3.65s\tremaining: 16.2s\n",
      "92:\tlearn: 0.4471307\ttotal: 3.7s\tremaining: 16.2s\n",
      "93:\tlearn: 0.4455730\ttotal: 3.75s\tremaining: 16.2s\n",
      "94:\tlearn: 0.4437097\ttotal: 3.77s\tremaining: 16.1s\n",
      "95:\tlearn: 0.4422335\ttotal: 3.8s\tremaining: 16s\n",
      "96:\tlearn: 0.4405991\ttotal: 3.82s\tremaining: 15.9s\n",
      "97:\tlearn: 0.4382737\ttotal: 3.84s\tremaining: 15.8s\n",
      "98:\tlearn: 0.4367811\ttotal: 3.87s\tremaining: 15.7s\n",
      "99:\tlearn: 0.4352620\ttotal: 3.89s\tremaining: 15.6s\n",
      "100:\tlearn: 0.4338507\ttotal: 3.96s\tremaining: 15.6s\n",
      "101:\tlearn: 0.4315079\ttotal: 4s\tremaining: 15.6s\n",
      "102:\tlearn: 0.4299862\ttotal: 4.02s\tremaining: 15.5s\n",
      "103:\tlearn: 0.4281363\ttotal: 4.04s\tremaining: 15.4s\n",
      "104:\tlearn: 0.4267069\ttotal: 4.08s\tremaining: 15.4s\n",
      "105:\tlearn: 0.4248438\ttotal: 4.15s\tremaining: 15.4s\n",
      "106:\tlearn: 0.4219488\ttotal: 4.18s\tremaining: 15.3s\n",
      "107:\tlearn: 0.4198396\ttotal: 4.2s\tremaining: 15.3s\n",
      "108:\tlearn: 0.4180655\ttotal: 4.22s\tremaining: 15.2s\n",
      "109:\tlearn: 0.4160825\ttotal: 4.29s\tremaining: 15.2s\n",
      "110:\tlearn: 0.4142565\ttotal: 4.33s\tremaining: 15.2s\n",
      "111:\tlearn: 0.4125846\ttotal: 4.36s\tremaining: 15.1s\n",
      "112:\tlearn: 0.4111367\ttotal: 4.4s\tremaining: 15.1s\n",
      "113:\tlearn: 0.4098416\ttotal: 4.47s\tremaining: 15.1s\n",
      "114:\tlearn: 0.4079729\ttotal: 4.51s\tremaining: 15.1s\n",
      "115:\tlearn: 0.4066642\ttotal: 4.53s\tremaining: 15s\n",
      "116:\tlearn: 0.4054335\ttotal: 4.55s\tremaining: 14.9s\n",
      "117:\tlearn: 0.4037318\ttotal: 4.62s\tremaining: 15s\n",
      "118:\tlearn: 0.4022018\ttotal: 4.67s\tremaining: 15s\n",
      "119:\tlearn: 0.4008992\ttotal: 4.7s\tremaining: 14.9s\n",
      "120:\tlearn: 0.3994827\ttotal: 4.72s\tremaining: 14.8s\n",
      "121:\tlearn: 0.3980170\ttotal: 4.77s\tremaining: 14.8s\n",
      "122:\tlearn: 0.3962489\ttotal: 4.83s\tremaining: 14.8s\n",
      "123:\tlearn: 0.3947994\ttotal: 4.86s\tremaining: 14.7s\n",
      "124:\tlearn: 0.3931760\ttotal: 4.88s\tremaining: 14.7s\n",
      "125:\tlearn: 0.3914019\ttotal: 4.91s\tremaining: 14.6s\n",
      "126:\tlearn: 0.3893949\ttotal: 4.98s\tremaining: 14.6s\n",
      "127:\tlearn: 0.3881140\ttotal: 5.02s\tremaining: 14.6s\n",
      "128:\tlearn: 0.3861362\ttotal: 5.04s\tremaining: 14.5s\n",
      "129:\tlearn: 0.3837636\ttotal: 5.06s\tremaining: 14.4s\n",
      "130:\tlearn: 0.3821276\ttotal: 5.08s\tremaining: 14.3s\n",
      "131:\tlearn: 0.3809319\ttotal: 5.16s\tremaining: 14.4s\n",
      "132:\tlearn: 0.3790964\ttotal: 5.2s\tremaining: 14.3s\n",
      "133:\tlearn: 0.3770113\ttotal: 5.23s\tremaining: 14.3s\n",
      "134:\tlearn: 0.3754267\ttotal: 5.25s\tremaining: 14.2s\n",
      "135:\tlearn: 0.3741536\ttotal: 5.28s\tremaining: 14.1s\n",
      "136:\tlearn: 0.3730116\ttotal: 5.29s\tremaining: 14s\n",
      "137:\tlearn: 0.3715919\ttotal: 5.37s\tremaining: 14.1s\n",
      "138:\tlearn: 0.3703039\ttotal: 5.41s\tremaining: 14s\n",
      "139:\tlearn: 0.3689641\ttotal: 5.43s\tremaining: 14s\n",
      "140:\tlearn: 0.3677348\ttotal: 5.45s\tremaining: 13.9s\n",
      "141:\tlearn: 0.3661204\ttotal: 5.49s\tremaining: 13.9s\n",
      "142:\tlearn: 0.3647340\ttotal: 5.56s\tremaining: 13.9s\n",
      "143:\tlearn: 0.3636566\ttotal: 5.59s\tremaining: 13.8s\n",
      "144:\tlearn: 0.3625204\ttotal: 5.62s\tremaining: 13.7s\n",
      "145:\tlearn: 0.3612582\ttotal: 5.64s\tremaining: 13.7s\n",
      "146:\tlearn: 0.3591872\ttotal: 5.68s\tremaining: 13.6s\n",
      "147:\tlearn: 0.3579765\ttotal: 5.74s\tremaining: 13.6s\n",
      "148:\tlearn: 0.3565216\ttotal: 5.77s\tremaining: 13.6s\n",
      "149:\tlearn: 0.3552408\ttotal: 5.79s\tremaining: 13.5s\n",
      "150:\tlearn: 0.3539329\ttotal: 5.81s\tremaining: 13.4s\n",
      "151:\tlearn: 0.3528485\ttotal: 5.88s\tremaining: 13.5s\n",
      "152:\tlearn: 0.3515951\ttotal: 5.93s\tremaining: 13.5s\n",
      "153:\tlearn: 0.3500879\ttotal: 5.96s\tremaining: 13.4s\n",
      "154:\tlearn: 0.3489407\ttotal: 5.98s\tremaining: 13.3s\n",
      "155:\tlearn: 0.3470313\ttotal: 6s\tremaining: 13.2s\n",
      "156:\tlearn: 0.3452541\ttotal: 6.08s\tremaining: 13.3s\n",
      "157:\tlearn: 0.3438337\ttotal: 6.11s\tremaining: 13.2s\n",
      "158:\tlearn: 0.3425702\ttotal: 6.14s\tremaining: 13.2s\n",
      "159:\tlearn: 0.3405963\ttotal: 6.16s\tremaining: 13.1s\n",
      "160:\tlearn: 0.3387922\ttotal: 6.18s\tremaining: 13s\n",
      "161:\tlearn: 0.3374615\ttotal: 6.26s\tremaining: 13.1s\n",
      "162:\tlearn: 0.3361752\ttotal: 6.28s\tremaining: 13s\n",
      "163:\tlearn: 0.3351892\ttotal: 6.31s\tremaining: 12.9s\n",
      "164:\tlearn: 0.3335789\ttotal: 6.38s\tremaining: 12.9s\n",
      "165:\tlearn: 0.3326155\ttotal: 6.44s\tremaining: 13s\n",
      "166:\tlearn: 0.3313864\ttotal: 6.46s\tremaining: 12.9s\n",
      "167:\tlearn: 0.3301366\ttotal: 6.48s\tremaining: 12.8s\n",
      "168:\tlearn: 0.3291511\ttotal: 6.53s\tremaining: 12.8s\n",
      "169:\tlearn: 0.3283884\ttotal: 6.59s\tremaining: 12.8s\n",
      "170:\tlearn: 0.3270651\ttotal: 6.61s\tremaining: 12.7s\n",
      "171:\tlearn: 0.3258745\ttotal: 6.64s\tremaining: 12.7s\n",
      "172:\tlearn: 0.3240548\ttotal: 6.66s\tremaining: 12.6s\n",
      "173:\tlearn: 0.3231915\ttotal: 6.73s\tremaining: 12.6s\n",
      "174:\tlearn: 0.3217233\ttotal: 6.78s\tremaining: 12.6s\n",
      "175:\tlearn: 0.3206566\ttotal: 6.8s\tremaining: 12.5s\n",
      "176:\tlearn: 0.3197890\ttotal: 6.83s\tremaining: 12.5s\n",
      "177:\tlearn: 0.3186141\ttotal: 6.85s\tremaining: 12.4s\n",
      "178:\tlearn: 0.3170937\ttotal: 6.92s\tremaining: 12.4s\n",
      "179:\tlearn: 0.3161694\ttotal: 6.96s\tremaining: 12.4s\n",
      "180:\tlearn: 0.3153435\ttotal: 6.99s\tremaining: 12.3s\n",
      "181:\tlearn: 0.3139859\ttotal: 7.01s\tremaining: 12.2s\n",
      "182:\tlearn: 0.3129421\ttotal: 7.03s\tremaining: 12.2s\n",
      "183:\tlearn: 0.3117785\ttotal: 7.1s\tremaining: 12.2s\n",
      "184:\tlearn: 0.3106018\ttotal: 7.14s\tremaining: 12.2s\n",
      "185:\tlearn: 0.3091545\ttotal: 7.17s\tremaining: 12.1s\n",
      "186:\tlearn: 0.3080612\ttotal: 7.19s\tremaining: 12s\n",
      "187:\tlearn: 0.3067948\ttotal: 7.26s\tremaining: 12.1s\n",
      "188:\tlearn: 0.3056321\ttotal: 7.31s\tremaining: 12s\n",
      "189:\tlearn: 0.3041798\ttotal: 7.33s\tremaining: 12s\n",
      "190:\tlearn: 0.3029584\ttotal: 7.36s\tremaining: 11.9s\n",
      "191:\tlearn: 0.3018054\ttotal: 7.38s\tremaining: 11.8s\n",
      "192:\tlearn: 0.3003686\ttotal: 7.45s\tremaining: 11.9s\n",
      "193:\tlearn: 0.2995084\ttotal: 7.49s\tremaining: 11.8s\n",
      "194:\tlearn: 0.2988896\ttotal: 7.52s\tremaining: 11.8s\n",
      "195:\tlearn: 0.2977435\ttotal: 7.54s\tremaining: 11.7s\n",
      "196:\tlearn: 0.2965777\ttotal: 7.6s\tremaining: 11.7s\n",
      "197:\tlearn: 0.2950611\ttotal: 7.65s\tremaining: 11.7s\n",
      "198:\tlearn: 0.2938526\ttotal: 7.68s\tremaining: 11.6s\n",
      "199:\tlearn: 0.2921173\ttotal: 7.7s\tremaining: 11.6s\n",
      "200:\tlearn: 0.2906627\ttotal: 7.72s\tremaining: 11.5s\n",
      "201:\tlearn: 0.2899246\ttotal: 7.77s\tremaining: 11.5s\n",
      "202:\tlearn: 0.2889210\ttotal: 7.82s\tremaining: 11.4s\n",
      "203:\tlearn: 0.2879495\ttotal: 7.84s\tremaining: 11.4s\n",
      "204:\tlearn: 0.2866886\ttotal: 7.87s\tremaining: 11.3s\n",
      "205:\tlearn: 0.2857289\ttotal: 7.91s\tremaining: 11.3s\n",
      "206:\tlearn: 0.2848980\ttotal: 7.98s\tremaining: 11.3s\n",
      "207:\tlearn: 0.2837988\ttotal: 8.01s\tremaining: 11.2s\n",
      "208:\tlearn: 0.2823390\ttotal: 8.04s\tremaining: 11.2s\n",
      "209:\tlearn: 0.2811702\ttotal: 8.06s\tremaining: 11.1s\n",
      "210:\tlearn: 0.2798287\ttotal: 8.13s\tremaining: 11.1s\n",
      "211:\tlearn: 0.2788530\ttotal: 8.17s\tremaining: 11.1s\n",
      "212:\tlearn: 0.2778529\ttotal: 8.2s\tremaining: 11s\n",
      "213:\tlearn: 0.2770211\ttotal: 8.22s\tremaining: 11s\n",
      "214:\tlearn: 0.2762204\ttotal: 8.24s\tremaining: 10.9s\n",
      "215:\tlearn: 0.2753093\ttotal: 8.31s\tremaining: 10.9s\n",
      "216:\tlearn: 0.2742757\ttotal: 8.35s\tremaining: 10.9s\n",
      "217:\tlearn: 0.2734013\ttotal: 8.38s\tremaining: 10.8s\n",
      "218:\tlearn: 0.2724731\ttotal: 8.4s\tremaining: 10.8s\n",
      "219:\tlearn: 0.2714611\ttotal: 8.43s\tremaining: 10.7s\n",
      "220:\tlearn: 0.2706132\ttotal: 8.51s\tremaining: 10.7s\n",
      "221:\tlearn: 0.2692442\ttotal: 8.54s\tremaining: 10.7s\n",
      "222:\tlearn: 0.2680447\ttotal: 8.57s\tremaining: 10.6s\n",
      "223:\tlearn: 0.2669289\ttotal: 8.59s\tremaining: 10.6s\n",
      "224:\tlearn: 0.2658310\ttotal: 8.66s\tremaining: 10.6s\n",
      "225:\tlearn: 0.2650830\ttotal: 8.71s\tremaining: 10.6s\n",
      "226:\tlearn: 0.2642749\ttotal: 8.73s\tremaining: 10.5s\n",
      "227:\tlearn: 0.2635642\ttotal: 8.75s\tremaining: 10.4s\n",
      "228:\tlearn: 0.2624709\ttotal: 8.77s\tremaining: 10.4s\n",
      "229:\tlearn: 0.2614242\ttotal: 8.84s\tremaining: 10.4s\n",
      "230:\tlearn: 0.2602608\ttotal: 8.89s\tremaining: 10.3s\n",
      "231:\tlearn: 0.2591722\ttotal: 8.91s\tremaining: 10.3s\n",
      "232:\tlearn: 0.2582417\ttotal: 8.93s\tremaining: 10.2s\n",
      "233:\tlearn: 0.2576435\ttotal: 9s\tremaining: 10.2s\n",
      "234:\tlearn: 0.2566456\ttotal: 9.04s\tremaining: 10.2s\n",
      "235:\tlearn: 0.2555821\ttotal: 9.07s\tremaining: 10.1s\n",
      "236:\tlearn: 0.2545044\ttotal: 9.09s\tremaining: 10.1s\n",
      "237:\tlearn: 0.2534961\ttotal: 9.15s\tremaining: 10.1s\n",
      "238:\tlearn: 0.2528373\ttotal: 9.2s\tremaining: 10.1s\n",
      "239:\tlearn: 0.2518761\ttotal: 9.23s\tremaining: 10s\n",
      "240:\tlearn: 0.2512155\ttotal: 9.25s\tremaining: 9.94s\n",
      "241:\tlearn: 0.2500732\ttotal: 9.29s\tremaining: 9.91s\n",
      "242:\tlearn: 0.2492066\ttotal: 9.36s\tremaining: 9.9s\n",
      "243:\tlearn: 0.2482493\ttotal: 9.39s\tremaining: 9.86s\n",
      "244:\tlearn: 0.2472083\ttotal: 9.41s\tremaining: 9.8s\n",
      "245:\tlearn: 0.2462395\ttotal: 9.44s\tremaining: 9.74s\n",
      "246:\tlearn: 0.2452474\ttotal: 9.49s\tremaining: 9.72s\n",
      "247:\tlearn: 0.2442437\ttotal: 9.55s\tremaining: 9.7s\n",
      "248:\tlearn: 0.2436184\ttotal: 9.57s\tremaining: 9.65s\n",
      "249:\tlearn: 0.2422713\ttotal: 9.6s\tremaining: 9.6s\n",
      "250:\tlearn: 0.2412804\ttotal: 9.63s\tremaining: 9.55s\n",
      "251:\tlearn: 0.2403870\ttotal: 9.7s\tremaining: 9.54s\n",
      "252:\tlearn: 0.2391837\ttotal: 9.74s\tremaining: 9.51s\n",
      "253:\tlearn: 0.2384476\ttotal: 9.77s\tremaining: 9.46s\n",
      "254:\tlearn: 0.2377134\ttotal: 9.79s\tremaining: 9.4s\n",
      "255:\tlearn: 0.2369329\ttotal: 9.81s\tremaining: 9.35s\n",
      "256:\tlearn: 0.2363487\ttotal: 9.88s\tremaining: 9.34s\n",
      "257:\tlearn: 0.2357046\ttotal: 9.92s\tremaining: 9.3s\n",
      "258:\tlearn: 0.2348393\ttotal: 9.94s\tremaining: 9.25s\n",
      "259:\tlearn: 0.2341145\ttotal: 9.96s\tremaining: 9.2s\n",
      "260:\tlearn: 0.2334103\ttotal: 10s\tremaining: 9.17s\n",
      "261:\tlearn: 0.2324996\ttotal: 10.1s\tremaining: 9.16s\n",
      "262:\tlearn: 0.2317951\ttotal: 10.1s\tremaining: 9.11s\n",
      "263:\tlearn: 0.2310707\ttotal: 10.1s\tremaining: 9.05s\n",
      "264:\tlearn: 0.2302466\ttotal: 10.2s\tremaining: 9s\n",
      "265:\tlearn: 0.2291887\ttotal: 10.2s\tremaining: 8.99s\n",
      "266:\tlearn: 0.2285365\ttotal: 10.3s\tremaining: 8.95s\n",
      "267:\tlearn: 0.2279544\ttotal: 10.3s\tremaining: 8.9s\n",
      "268:\tlearn: 0.2270942\ttotal: 10.3s\tremaining: 8.84s\n",
      "269:\tlearn: 0.2264587\ttotal: 10.3s\tremaining: 8.8s\n",
      "270:\tlearn: 0.2258798\ttotal: 10.4s\tremaining: 8.78s\n",
      "271:\tlearn: 0.2244103\ttotal: 10.4s\tremaining: 8.73s\n",
      "272:\tlearn: 0.2236662\ttotal: 10.4s\tremaining: 8.69s\n",
      "273:\tlearn: 0.2227001\ttotal: 10.5s\tremaining: 8.63s\n",
      "274:\tlearn: 0.2222130\ttotal: 10.5s\tremaining: 8.62s\n",
      "275:\tlearn: 0.2215781\ttotal: 10.6s\tremaining: 8.59s\n",
      "276:\tlearn: 0.2204763\ttotal: 10.6s\tremaining: 8.55s\n",
      "277:\tlearn: 0.2196098\ttotal: 10.6s\tremaining: 8.49s\n",
      "278:\tlearn: 0.2188128\ttotal: 10.7s\tremaining: 8.47s\n",
      "279:\tlearn: 0.2180521\ttotal: 10.8s\tremaining: 8.45s\n",
      "280:\tlearn: 0.2173854\ttotal: 10.8s\tremaining: 8.4s\n",
      "281:\tlearn: 0.2166777\ttotal: 10.8s\tremaining: 8.35s\n",
      "282:\tlearn: 0.2161081\ttotal: 10.8s\tremaining: 8.3s\n",
      "283:\tlearn: 0.2149423\ttotal: 10.9s\tremaining: 8.29s\n",
      "284:\tlearn: 0.2142127\ttotal: 10.9s\tremaining: 8.25s\n",
      "285:\tlearn: 0.2134764\ttotal: 11s\tremaining: 8.2s\n",
      "286:\tlearn: 0.2127011\ttotal: 11s\tremaining: 8.15s\n",
      "287:\tlearn: 0.2118926\ttotal: 11s\tremaining: 8.13s\n",
      "288:\tlearn: 0.2106995\ttotal: 11.1s\tremaining: 8.1s\n",
      "289:\tlearn: 0.2099387\ttotal: 11.1s\tremaining: 8.05s\n",
      "290:\tlearn: 0.2091026\ttotal: 11.1s\tremaining: 8s\n",
      "291:\tlearn: 0.2083100\ttotal: 11.2s\tremaining: 7.96s\n",
      "292:\tlearn: 0.2074213\ttotal: 11.3s\tremaining: 7.95s\n",
      "293:\tlearn: 0.2064241\ttotal: 11.3s\tremaining: 7.91s\n",
      "294:\tlearn: 0.2060240\ttotal: 11.3s\tremaining: 7.86s\n",
      "295:\tlearn: 0.2052843\ttotal: 11.3s\tremaining: 7.81s\n",
      "296:\tlearn: 0.2048664\ttotal: 11.4s\tremaining: 7.79s\n",
      "297:\tlearn: 0.2041583\ttotal: 11.4s\tremaining: 7.76s\n",
      "298:\tlearn: 0.2036951\ttotal: 11.5s\tremaining: 7.71s\n",
      "299:\tlearn: 0.2031314\ttotal: 11.5s\tremaining: 7.67s\n",
      "300:\tlearn: 0.2022981\ttotal: 11.6s\tremaining: 7.64s\n",
      "301:\tlearn: 0.2017109\ttotal: 11.6s\tremaining: 7.61s\n",
      "302:\tlearn: 0.2011617\ttotal: 11.6s\tremaining: 7.57s\n",
      "303:\tlearn: 0.2006794\ttotal: 11.7s\tremaining: 7.52s\n",
      "304:\tlearn: 0.2000242\ttotal: 11.7s\tremaining: 7.47s\n",
      "305:\tlearn: 0.1994882\ttotal: 11.8s\tremaining: 7.45s\n",
      "306:\tlearn: 0.1987734\ttotal: 11.8s\tremaining: 7.42s\n",
      "307:\tlearn: 0.1981296\ttotal: 11.8s\tremaining: 7.37s\n",
      "308:\tlearn: 0.1975872\ttotal: 11.8s\tremaining: 7.32s\n",
      "309:\tlearn: 0.1970713\ttotal: 11.9s\tremaining: 7.28s\n",
      "310:\tlearn: 0.1963867\ttotal: 11.9s\tremaining: 7.23s\n",
      "311:\tlearn: 0.1953276\ttotal: 12s\tremaining: 7.21s\n",
      "312:\tlearn: 0.1948420\ttotal: 12s\tremaining: 7.18s\n",
      "313:\tlearn: 0.1943018\ttotal: 12s\tremaining: 7.13s\n",
      "314:\tlearn: 0.1938607\ttotal: 12.1s\tremaining: 7.08s\n",
      "315:\tlearn: 0.1933945\ttotal: 12.1s\tremaining: 7.06s\n",
      "316:\tlearn: 0.1928267\ttotal: 12.2s\tremaining: 7.03s\n",
      "317:\tlearn: 0.1922490\ttotal: 12.2s\tremaining: 6.99s\n",
      "318:\tlearn: 0.1915584\ttotal: 12.2s\tremaining: 6.94s\n",
      "319:\tlearn: 0.1910960\ttotal: 12.3s\tremaining: 6.89s\n",
      "320:\tlearn: 0.1903318\ttotal: 12.3s\tremaining: 6.88s\n",
      "321:\tlearn: 0.1896526\ttotal: 12.4s\tremaining: 6.84s\n",
      "322:\tlearn: 0.1886722\ttotal: 12.4s\tremaining: 6.79s\n",
      "323:\tlearn: 0.1879597\ttotal: 12.4s\tremaining: 6.75s\n",
      "324:\tlearn: 0.1874264\ttotal: 12.4s\tremaining: 6.7s\n",
      "325:\tlearn: 0.1868345\ttotal: 12.5s\tremaining: 6.67s\n",
      "326:\tlearn: 0.1861957\ttotal: 12.5s\tremaining: 6.64s\n",
      "327:\tlearn: 0.1856292\ttotal: 12.6s\tremaining: 6.59s\n",
      "328:\tlearn: 0.1850981\ttotal: 12.6s\tremaining: 6.54s\n",
      "329:\tlearn: 0.1845283\ttotal: 12.6s\tremaining: 6.51s\n",
      "330:\tlearn: 0.1838453\ttotal: 12.7s\tremaining: 6.49s\n",
      "331:\tlearn: 0.1832470\ttotal: 12.7s\tremaining: 6.45s\n",
      "332:\tlearn: 0.1826691\ttotal: 12.8s\tremaining: 6.4s\n",
      "333:\tlearn: 0.1821160\ttotal: 12.8s\tremaining: 6.35s\n",
      "334:\tlearn: 0.1817469\ttotal: 12.8s\tremaining: 6.32s\n",
      "335:\tlearn: 0.1811812\ttotal: 12.9s\tremaining: 6.29s\n",
      "336:\tlearn: 0.1806582\ttotal: 12.9s\tremaining: 6.25s\n",
      "337:\tlearn: 0.1802252\ttotal: 12.9s\tremaining: 6.2s\n",
      "338:\tlearn: 0.1793850\ttotal: 13s\tremaining: 6.15s\n",
      "339:\tlearn: 0.1785977\ttotal: 13s\tremaining: 6.13s\n",
      "340:\tlearn: 0.1779741\ttotal: 13.1s\tremaining: 6.09s\n",
      "341:\tlearn: 0.1772153\ttotal: 13.1s\tremaining: 6.05s\n",
      "342:\tlearn: 0.1766459\ttotal: 13.1s\tremaining: 6s\n",
      "343:\tlearn: 0.1762381\ttotal: 13.1s\tremaining: 5.96s\n",
      "344:\tlearn: 0.1757975\ttotal: 13.2s\tremaining: 5.93s\n",
      "345:\tlearn: 0.1753186\ttotal: 13.3s\tremaining: 5.9s\n",
      "346:\tlearn: 0.1748557\ttotal: 13.3s\tremaining: 5.85s\n",
      "347:\tlearn: 0.1741383\ttotal: 13.3s\tremaining: 5.81s\n",
      "348:\tlearn: 0.1735440\ttotal: 13.3s\tremaining: 5.77s\n",
      "349:\tlearn: 0.1729951\ttotal: 13.4s\tremaining: 5.75s\n",
      "350:\tlearn: 0.1724599\ttotal: 13.4s\tremaining: 5.71s\n",
      "351:\tlearn: 0.1719043\ttotal: 13.5s\tremaining: 5.66s\n",
      "352:\tlearn: 0.1711226\ttotal: 13.5s\tremaining: 5.62s\n",
      "353:\tlearn: 0.1706369\ttotal: 13.6s\tremaining: 5.59s\n",
      "354:\tlearn: 0.1701390\ttotal: 13.6s\tremaining: 5.57s\n",
      "355:\tlearn: 0.1695441\ttotal: 13.7s\tremaining: 5.54s\n",
      "356:\tlearn: 0.1692282\ttotal: 13.7s\tremaining: 5.5s\n",
      "357:\tlearn: 0.1686752\ttotal: 13.7s\tremaining: 5.45s\n",
      "358:\tlearn: 0.1682004\ttotal: 13.8s\tremaining: 5.41s\n",
      "359:\tlearn: 0.1675761\ttotal: 13.8s\tremaining: 5.38s\n",
      "360:\tlearn: 0.1671688\ttotal: 13.9s\tremaining: 5.34s\n",
      "361:\tlearn: 0.1665288\ttotal: 13.9s\tremaining: 5.29s\n",
      "362:\tlearn: 0.1659825\ttotal: 13.9s\tremaining: 5.26s\n",
      "363:\tlearn: 0.1655137\ttotal: 14s\tremaining: 5.23s\n",
      "364:\tlearn: 0.1649630\ttotal: 14s\tremaining: 5.18s\n",
      "365:\tlearn: 0.1644859\ttotal: 14.1s\tremaining: 5.16s\n",
      "366:\tlearn: 0.1638038\ttotal: 14.1s\tremaining: 5.12s\n",
      "367:\tlearn: 0.1633904\ttotal: 14.2s\tremaining: 5.08s\n",
      "368:\tlearn: 0.1627750\ttotal: 14.2s\tremaining: 5.04s\n",
      "369:\tlearn: 0.1622041\ttotal: 14.2s\tremaining: 5s\n",
      "370:\tlearn: 0.1618458\ttotal: 14.3s\tremaining: 4.97s\n",
      "371:\tlearn: 0.1614152\ttotal: 14.3s\tremaining: 4.93s\n",
      "372:\tlearn: 0.1610854\ttotal: 14.3s\tremaining: 4.88s\n",
      "373:\tlearn: 0.1606931\ttotal: 14.4s\tremaining: 4.84s\n",
      "374:\tlearn: 0.1602662\ttotal: 14.4s\tremaining: 4.81s\n",
      "375:\tlearn: 0.1598294\ttotal: 14.5s\tremaining: 4.78s\n",
      "376:\tlearn: 0.1593309\ttotal: 14.5s\tremaining: 4.73s\n",
      "377:\tlearn: 0.1589305\ttotal: 14.5s\tremaining: 4.69s\n",
      "378:\tlearn: 0.1584393\ttotal: 14.5s\tremaining: 4.64s\n",
      "379:\tlearn: 0.1579891\ttotal: 14.6s\tremaining: 4.62s\n",
      "380:\tlearn: 0.1575265\ttotal: 14.7s\tremaining: 4.58s\n",
      "381:\tlearn: 0.1569011\ttotal: 14.7s\tremaining: 4.54s\n",
      "382:\tlearn: 0.1564563\ttotal: 14.7s\tremaining: 4.5s\n",
      "383:\tlearn: 0.1559734\ttotal: 14.8s\tremaining: 4.46s\n",
      "384:\tlearn: 0.1554836\ttotal: 14.8s\tremaining: 4.43s\n",
      "385:\tlearn: 0.1550448\ttotal: 14.9s\tremaining: 4.39s\n",
      "386:\tlearn: 0.1544534\ttotal: 14.9s\tremaining: 4.34s\n",
      "387:\tlearn: 0.1540279\ttotal: 14.9s\tremaining: 4.3s\n",
      "388:\tlearn: 0.1534657\ttotal: 15s\tremaining: 4.27s\n",
      "389:\tlearn: 0.1528584\ttotal: 15s\tremaining: 4.24s\n",
      "390:\tlearn: 0.1526076\ttotal: 15s\tremaining: 4.19s\n",
      "391:\tlearn: 0.1521740\ttotal: 15.1s\tremaining: 4.15s\n",
      "392:\tlearn: 0.1516353\ttotal: 15.1s\tremaining: 4.11s\n",
      "393:\tlearn: 0.1511663\ttotal: 15.2s\tremaining: 4.08s\n",
      "394:\tlearn: 0.1508662\ttotal: 15.2s\tremaining: 4.04s\n",
      "395:\tlearn: 0.1504030\ttotal: 15.2s\tremaining: 4s\n",
      "396:\tlearn: 0.1501540\ttotal: 15.2s\tremaining: 3.96s\n",
      "397:\tlearn: 0.1498988\ttotal: 15.3s\tremaining: 3.92s\n",
      "398:\tlearn: 0.1492066\ttotal: 15.4s\tremaining: 3.89s\n",
      "399:\tlearn: 0.1488342\ttotal: 15.4s\tremaining: 3.85s\n",
      "400:\tlearn: 0.1482876\ttotal: 15.4s\tremaining: 3.81s\n",
      "401:\tlearn: 0.1478572\ttotal: 15.4s\tremaining: 3.76s\n",
      "402:\tlearn: 0.1474505\ttotal: 15.5s\tremaining: 3.72s\n",
      "403:\tlearn: 0.1470400\ttotal: 15.5s\tremaining: 3.69s\n",
      "404:\tlearn: 0.1465604\ttotal: 15.6s\tremaining: 3.65s\n",
      "405:\tlearn: 0.1461488\ttotal: 15.6s\tremaining: 3.6s\n",
      "406:\tlearn: 0.1457663\ttotal: 15.6s\tremaining: 3.57s\n",
      "407:\tlearn: 0.1453603\ttotal: 15.7s\tremaining: 3.54s\n",
      "408:\tlearn: 0.1446516\ttotal: 15.7s\tremaining: 3.5s\n",
      "409:\tlearn: 0.1443014\ttotal: 15.7s\tremaining: 3.45s\n",
      "410:\tlearn: 0.1437530\ttotal: 15.8s\tremaining: 3.41s\n",
      "411:\tlearn: 0.1433501\ttotal: 15.8s\tremaining: 3.38s\n",
      "412:\tlearn: 0.1430434\ttotal: 15.9s\tremaining: 3.34s\n",
      "413:\tlearn: 0.1426095\ttotal: 15.9s\tremaining: 3.3s\n",
      "414:\tlearn: 0.1421533\ttotal: 15.9s\tremaining: 3.27s\n",
      "415:\tlearn: 0.1417254\ttotal: 16s\tremaining: 3.23s\n",
      "416:\tlearn: 0.1410713\ttotal: 16.1s\tremaining: 3.2s\n",
      "417:\tlearn: 0.1404251\ttotal: 16.1s\tremaining: 3.16s\n",
      "418:\tlearn: 0.1400800\ttotal: 16.1s\tremaining: 3.12s\n",
      "419:\tlearn: 0.1396889\ttotal: 16.2s\tremaining: 3.08s\n",
      "420:\tlearn: 0.1392051\ttotal: 16.2s\tremaining: 3.04s\n",
      "421:\tlearn: 0.1387752\ttotal: 16.3s\tremaining: 3s\n",
      "422:\tlearn: 0.1383114\ttotal: 16.3s\tremaining: 2.96s\n",
      "423:\tlearn: 0.1378253\ttotal: 16.3s\tremaining: 2.92s\n",
      "424:\tlearn: 0.1374759\ttotal: 16.4s\tremaining: 2.89s\n",
      "425:\tlearn: 0.1368270\ttotal: 16.4s\tremaining: 2.85s\n",
      "426:\tlearn: 0.1362588\ttotal: 16.5s\tremaining: 2.81s\n",
      "427:\tlearn: 0.1358205\ttotal: 16.5s\tremaining: 2.77s\n",
      "428:\tlearn: 0.1353732\ttotal: 16.5s\tremaining: 2.73s\n",
      "429:\tlearn: 0.1350551\ttotal: 16.6s\tremaining: 2.7s\n",
      "430:\tlearn: 0.1347917\ttotal: 16.6s\tremaining: 2.66s\n",
      "431:\tlearn: 0.1341294\ttotal: 16.6s\tremaining: 2.62s\n",
      "432:\tlearn: 0.1337552\ttotal: 16.7s\tremaining: 2.58s\n",
      "433:\tlearn: 0.1333410\ttotal: 16.7s\tremaining: 2.54s\n",
      "434:\tlearn: 0.1329965\ttotal: 16.8s\tremaining: 2.51s\n",
      "435:\tlearn: 0.1326968\ttotal: 16.8s\tremaining: 2.46s\n",
      "436:\tlearn: 0.1322406\ttotal: 16.8s\tremaining: 2.42s\n",
      "437:\tlearn: 0.1319784\ttotal: 16.8s\tremaining: 2.38s\n",
      "438:\tlearn: 0.1316393\ttotal: 16.9s\tremaining: 2.35s\n",
      "439:\tlearn: 0.1312278\ttotal: 17s\tremaining: 2.31s\n",
      "440:\tlearn: 0.1309443\ttotal: 17s\tremaining: 2.27s\n",
      "441:\tlearn: 0.1305540\ttotal: 17s\tremaining: 2.23s\n",
      "442:\tlearn: 0.1301022\ttotal: 17.1s\tremaining: 2.19s\n",
      "443:\tlearn: 0.1298730\ttotal: 17.1s\tremaining: 2.16s\n",
      "444:\tlearn: 0.1294883\ttotal: 17.2s\tremaining: 2.12s\n",
      "445:\tlearn: 0.1291575\ttotal: 17.2s\tremaining: 2.08s\n",
      "446:\tlearn: 0.1287367\ttotal: 17.2s\tremaining: 2.04s\n",
      "447:\tlearn: 0.1282286\ttotal: 17.3s\tremaining: 2s\n",
      "448:\tlearn: 0.1279039\ttotal: 17.3s\tremaining: 1.97s\n",
      "449:\tlearn: 0.1274412\ttotal: 17.3s\tremaining: 1.93s\n",
      "450:\tlearn: 0.1270852\ttotal: 17.4s\tremaining: 1.89s\n",
      "451:\tlearn: 0.1266765\ttotal: 17.4s\tremaining: 1.85s\n",
      "452:\tlearn: 0.1261697\ttotal: 17.5s\tremaining: 1.81s\n",
      "453:\tlearn: 0.1259257\ttotal: 17.5s\tremaining: 1.77s\n",
      "454:\tlearn: 0.1254797\ttotal: 17.5s\tremaining: 1.73s\n",
      "455:\tlearn: 0.1250218\ttotal: 17.6s\tremaining: 1.7s\n",
      "456:\tlearn: 0.1244415\ttotal: 17.6s\tremaining: 1.66s\n",
      "457:\tlearn: 0.1241337\ttotal: 17.7s\tremaining: 1.62s\n",
      "458:\tlearn: 0.1237006\ttotal: 17.7s\tremaining: 1.58s\n",
      "459:\tlearn: 0.1233981\ttotal: 17.7s\tremaining: 1.54s\n",
      "460:\tlearn: 0.1231001\ttotal: 17.8s\tremaining: 1.5s\n",
      "461:\tlearn: 0.1227583\ttotal: 17.8s\tremaining: 1.47s\n",
      "462:\tlearn: 0.1224106\ttotal: 17.8s\tremaining: 1.43s\n",
      "463:\tlearn: 0.1221132\ttotal: 17.9s\tremaining: 1.39s\n",
      "464:\tlearn: 0.1218427\ttotal: 17.9s\tremaining: 1.35s\n",
      "465:\tlearn: 0.1214820\ttotal: 18s\tremaining: 1.31s\n",
      "466:\tlearn: 0.1212120\ttotal: 18s\tremaining: 1.27s\n",
      "467:\tlearn: 0.1210085\ttotal: 18s\tremaining: 1.23s\n",
      "468:\tlearn: 0.1207679\ttotal: 18s\tremaining: 1.19s\n",
      "469:\tlearn: 0.1203331\ttotal: 18.1s\tremaining: 1.16s\n",
      "470:\tlearn: 0.1198044\ttotal: 18.2s\tremaining: 1.12s\n",
      "471:\tlearn: 0.1193801\ttotal: 18.2s\tremaining: 1.08s\n",
      "472:\tlearn: 0.1191533\ttotal: 18.2s\tremaining: 1.04s\n",
      "473:\tlearn: 0.1188763\ttotal: 18.2s\tremaining: 1s\n",
      "474:\tlearn: 0.1185286\ttotal: 18.3s\tremaining: 964ms\n",
      "475:\tlearn: 0.1181416\ttotal: 18.3s\tremaining: 925ms\n",
      "476:\tlearn: 0.1175135\ttotal: 18.4s\tremaining: 886ms\n",
      "477:\tlearn: 0.1172228\ttotal: 18.4s\tremaining: 847ms\n",
      "478:\tlearn: 0.1168784\ttotal: 18.4s\tremaining: 808ms\n",
      "479:\tlearn: 0.1165763\ttotal: 18.5s\tremaining: 771ms\n",
      "480:\tlearn: 0.1163311\ttotal: 18.5s\tremaining: 732ms\n",
      "481:\tlearn: 0.1160600\ttotal: 18.6s\tremaining: 694ms\n",
      "482:\tlearn: 0.1156757\ttotal: 18.6s\tremaining: 655ms\n",
      "483:\tlearn: 0.1151195\ttotal: 18.6s\tremaining: 616ms\n",
      "484:\tlearn: 0.1148548\ttotal: 18.7s\tremaining: 578ms\n",
      "485:\tlearn: 0.1143358\ttotal: 18.7s\tremaining: 540ms\n",
      "486:\tlearn: 0.1139744\ttotal: 18.8s\tremaining: 501ms\n",
      "487:\tlearn: 0.1135283\ttotal: 18.8s\tremaining: 462ms\n",
      "488:\tlearn: 0.1131746\ttotal: 18.8s\tremaining: 424ms\n",
      "489:\tlearn: 0.1127870\ttotal: 18.9s\tremaining: 386ms\n",
      "490:\tlearn: 0.1124840\ttotal: 18.9s\tremaining: 347ms\n",
      "491:\tlearn: 0.1122570\ttotal: 18.9s\tremaining: 308ms\n",
      "492:\tlearn: 0.1118595\ttotal: 19s\tremaining: 269ms\n",
      "493:\tlearn: 0.1114990\ttotal: 19s\tremaining: 231ms\n",
      "494:\tlearn: 0.1112258\ttotal: 19.1s\tremaining: 193ms\n",
      "495:\tlearn: 0.1109507\ttotal: 19.1s\tremaining: 154ms\n",
      "496:\tlearn: 0.1106531\ttotal: 19.1s\tremaining: 115ms\n",
      "497:\tlearn: 0.1103676\ttotal: 19.2s\tremaining: 76.9ms\n",
      "498:\tlearn: 0.1100182\ttotal: 19.2s\tremaining: 38.5ms\n",
      "499:\tlearn: 0.1096095\ttotal: 19.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6896822\ttotal: 53.2ms\tremaining: 26.5s\n",
      "1:\tlearn: 0.6860316\ttotal: 78.1ms\tremaining: 19.5s\n",
      "2:\tlearn: 0.6824616\ttotal: 98.7ms\tremaining: 16.3s\n",
      "3:\tlearn: 0.6783233\ttotal: 158ms\tremaining: 19.6s\n",
      "4:\tlearn: 0.6753202\ttotal: 217ms\tremaining: 21.5s\n",
      "5:\tlearn: 0.6718799\ttotal: 248ms\tremaining: 20.4s\n",
      "6:\tlearn: 0.6669201\ttotal: 270ms\tremaining: 19s\n",
      "7:\tlearn: 0.6636494\ttotal: 318ms\tremaining: 19.5s\n",
      "8:\tlearn: 0.6599559\ttotal: 380ms\tremaining: 20.7s\n",
      "9:\tlearn: 0.6557818\ttotal: 411ms\tremaining: 20.1s\n",
      "10:\tlearn: 0.6524307\ttotal: 435ms\tremaining: 19.4s\n",
      "11:\tlearn: 0.6477163\ttotal: 456ms\tremaining: 18.6s\n",
      "12:\tlearn: 0.6434816\ttotal: 503ms\tremaining: 18.9s\n",
      "13:\tlearn: 0.6406673\ttotal: 551ms\tremaining: 19.1s\n",
      "14:\tlearn: 0.6372603\ttotal: 575ms\tremaining: 18.6s\n",
      "15:\tlearn: 0.6334773\ttotal: 596ms\tremaining: 18s\n",
      "16:\tlearn: 0.6303891\ttotal: 663ms\tremaining: 18.8s\n",
      "17:\tlearn: 0.6267194\ttotal: 722ms\tremaining: 19.3s\n",
      "18:\tlearn: 0.6230146\ttotal: 748ms\tremaining: 18.9s\n",
      "19:\tlearn: 0.6200376\ttotal: 769ms\tremaining: 18.4s\n",
      "20:\tlearn: 0.6160090\ttotal: 813ms\tremaining: 18.6s\n",
      "21:\tlearn: 0.6127787\ttotal: 881ms\tremaining: 19.1s\n",
      "22:\tlearn: 0.6096315\ttotal: 917ms\tremaining: 19s\n",
      "23:\tlearn: 0.6061352\ttotal: 936ms\tremaining: 18.6s\n",
      "24:\tlearn: 0.6026205\ttotal: 957ms\tremaining: 18.2s\n",
      "25:\tlearn: 0.6002144\ttotal: 1.03s\tremaining: 18.8s\n",
      "26:\tlearn: 0.5975773\ttotal: 1.07s\tremaining: 18.7s\n",
      "27:\tlearn: 0.5953511\ttotal: 1.09s\tremaining: 18.4s\n",
      "28:\tlearn: 0.5924003\ttotal: 1.11s\tremaining: 18.1s\n",
      "29:\tlearn: 0.5893200\ttotal: 1.16s\tremaining: 18.1s\n",
      "30:\tlearn: 0.5869727\ttotal: 1.23s\tremaining: 18.6s\n",
      "31:\tlearn: 0.5844948\ttotal: 1.26s\tremaining: 18.5s\n",
      "32:\tlearn: 0.5819905\ttotal: 1.29s\tremaining: 18.2s\n",
      "33:\tlearn: 0.5792551\ttotal: 1.31s\tremaining: 17.9s\n",
      "34:\tlearn: 0.5763245\ttotal: 1.38s\tremaining: 18.4s\n",
      "35:\tlearn: 0.5728630\ttotal: 1.42s\tremaining: 18.3s\n",
      "36:\tlearn: 0.5702325\ttotal: 1.45s\tremaining: 18.1s\n",
      "37:\tlearn: 0.5673914\ttotal: 1.47s\tremaining: 17.8s\n",
      "38:\tlearn: 0.5643782\ttotal: 1.49s\tremaining: 17.6s\n",
      "39:\tlearn: 0.5621730\ttotal: 1.57s\tremaining: 18s\n",
      "40:\tlearn: 0.5585495\ttotal: 1.6s\tremaining: 18s\n",
      "41:\tlearn: 0.5558303\ttotal: 1.63s\tremaining: 17.8s\n",
      "42:\tlearn: 0.5527805\ttotal: 1.65s\tremaining: 17.5s\n",
      "43:\tlearn: 0.5502949\ttotal: 1.67s\tremaining: 17.3s\n",
      "44:\tlearn: 0.5483732\ttotal: 1.74s\tremaining: 17.6s\n",
      "45:\tlearn: 0.5458156\ttotal: 1.79s\tremaining: 17.6s\n",
      "46:\tlearn: 0.5434257\ttotal: 1.81s\tremaining: 17.5s\n",
      "47:\tlearn: 0.5399874\ttotal: 1.83s\tremaining: 17.3s\n",
      "48:\tlearn: 0.5377386\ttotal: 1.85s\tremaining: 17.1s\n",
      "49:\tlearn: 0.5354806\ttotal: 1.88s\tremaining: 16.9s\n",
      "50:\tlearn: 0.5331805\ttotal: 1.95s\tremaining: 17.2s\n",
      "51:\tlearn: 0.5309001\ttotal: 1.98s\tremaining: 17.1s\n",
      "52:\tlearn: 0.5289811\ttotal: 2s\tremaining: 16.9s\n",
      "53:\tlearn: 0.5256809\ttotal: 2.07s\tremaining: 17.1s\n",
      "54:\tlearn: 0.5226545\ttotal: 2.12s\tremaining: 17.2s\n",
      "55:\tlearn: 0.5200859\ttotal: 2.15s\tremaining: 17s\n",
      "56:\tlearn: 0.5174203\ttotal: 2.17s\tremaining: 16.8s\n",
      "57:\tlearn: 0.5151241\ttotal: 2.22s\tremaining: 16.9s\n",
      "58:\tlearn: 0.5121380\ttotal: 2.28s\tremaining: 17.1s\n",
      "59:\tlearn: 0.5097282\ttotal: 2.32s\tremaining: 17s\n",
      "60:\tlearn: 0.5068970\ttotal: 2.34s\tremaining: 16.9s\n",
      "61:\tlearn: 0.5044789\ttotal: 2.36s\tremaining: 16.7s\n",
      "62:\tlearn: 0.5022051\ttotal: 2.43s\tremaining: 16.9s\n",
      "63:\tlearn: 0.5002007\ttotal: 2.48s\tremaining: 16.9s\n",
      "64:\tlearn: 0.4979604\ttotal: 2.5s\tremaining: 16.8s\n",
      "65:\tlearn: 0.4962449\ttotal: 2.53s\tremaining: 16.6s\n",
      "66:\tlearn: 0.4940934\ttotal: 2.55s\tremaining: 16.5s\n",
      "67:\tlearn: 0.4919698\ttotal: 2.62s\tremaining: 16.7s\n",
      "68:\tlearn: 0.4896383\ttotal: 2.66s\tremaining: 16.6s\n",
      "69:\tlearn: 0.4871465\ttotal: 2.68s\tremaining: 16.5s\n",
      "70:\tlearn: 0.4850947\ttotal: 2.71s\tremaining: 16.4s\n",
      "71:\tlearn: 0.4827699\ttotal: 2.73s\tremaining: 16.2s\n",
      "72:\tlearn: 0.4809132\ttotal: 2.8s\tremaining: 16.4s\n",
      "73:\tlearn: 0.4788787\ttotal: 2.84s\tremaining: 16.4s\n",
      "74:\tlearn: 0.4771904\ttotal: 2.87s\tremaining: 16.2s\n",
      "75:\tlearn: 0.4753964\ttotal: 2.89s\tremaining: 16.1s\n",
      "76:\tlearn: 0.4733506\ttotal: 2.93s\tremaining: 16.1s\n",
      "77:\tlearn: 0.4716012\ttotal: 2.99s\tremaining: 16.2s\n",
      "78:\tlearn: 0.4695100\ttotal: 3.03s\tremaining: 16.1s\n",
      "79:\tlearn: 0.4672777\ttotal: 3.05s\tremaining: 16s\n",
      "80:\tlearn: 0.4654612\ttotal: 3.07s\tremaining: 15.9s\n",
      "81:\tlearn: 0.4634128\ttotal: 3.14s\tremaining: 16s\n",
      "82:\tlearn: 0.4614573\ttotal: 3.19s\tremaining: 16s\n",
      "83:\tlearn: 0.4598005\ttotal: 3.22s\tremaining: 15.9s\n",
      "84:\tlearn: 0.4576133\ttotal: 3.24s\tremaining: 15.8s\n",
      "85:\tlearn: 0.4557272\ttotal: 3.26s\tremaining: 15.7s\n",
      "86:\tlearn: 0.4540273\ttotal: 3.33s\tremaining: 15.8s\n",
      "87:\tlearn: 0.4518418\ttotal: 3.37s\tremaining: 15.8s\n",
      "88:\tlearn: 0.4501589\ttotal: 3.4s\tremaining: 15.7s\n",
      "89:\tlearn: 0.4483269\ttotal: 3.42s\tremaining: 15.6s\n",
      "90:\tlearn: 0.4465054\ttotal: 3.45s\tremaining: 15.5s\n",
      "91:\tlearn: 0.4443805\ttotal: 3.52s\tremaining: 15.6s\n",
      "92:\tlearn: 0.4424989\ttotal: 3.55s\tremaining: 15.6s\n",
      "93:\tlearn: 0.4405540\ttotal: 3.58s\tremaining: 15.5s\n",
      "94:\tlearn: 0.4389222\ttotal: 3.6s\tremaining: 15.3s\n",
      "95:\tlearn: 0.4365891\ttotal: 3.65s\tremaining: 15.4s\n",
      "96:\tlearn: 0.4347575\ttotal: 3.71s\tremaining: 15.4s\n",
      "97:\tlearn: 0.4330543\ttotal: 3.74s\tremaining: 15.4s\n",
      "98:\tlearn: 0.4313665\ttotal: 3.77s\tremaining: 15.3s\n",
      "99:\tlearn: 0.4296957\ttotal: 3.79s\tremaining: 15.1s\n",
      "100:\tlearn: 0.4280002\ttotal: 3.86s\tremaining: 15.3s\n",
      "101:\tlearn: 0.4261806\ttotal: 3.9s\tremaining: 15.2s\n",
      "102:\tlearn: 0.4245410\ttotal: 3.92s\tremaining: 15.1s\n",
      "103:\tlearn: 0.4225940\ttotal: 3.94s\tremaining: 15s\n",
      "104:\tlearn: 0.4209204\ttotal: 4.01s\tremaining: 15.1s\n",
      "105:\tlearn: 0.4194414\ttotal: 4.05s\tremaining: 15.1s\n",
      "106:\tlearn: 0.4176729\ttotal: 4.08s\tremaining: 15s\n",
      "107:\tlearn: 0.4156581\ttotal: 4.11s\tremaining: 14.9s\n",
      "108:\tlearn: 0.4139602\ttotal: 4.15s\tremaining: 14.9s\n",
      "109:\tlearn: 0.4120918\ttotal: 4.21s\tremaining: 14.9s\n",
      "110:\tlearn: 0.4101481\ttotal: 4.25s\tremaining: 14.9s\n",
      "111:\tlearn: 0.4077283\ttotal: 4.27s\tremaining: 14.8s\n",
      "112:\tlearn: 0.4057269\ttotal: 4.3s\tremaining: 14.7s\n",
      "113:\tlearn: 0.4044709\ttotal: 4.37s\tremaining: 14.8s\n",
      "114:\tlearn: 0.4033377\ttotal: 4.41s\tremaining: 14.8s\n",
      "115:\tlearn: 0.4016507\ttotal: 4.44s\tremaining: 14.7s\n",
      "116:\tlearn: 0.3999890\ttotal: 4.46s\tremaining: 14.6s\n",
      "117:\tlearn: 0.3984708\ttotal: 4.53s\tremaining: 14.7s\n",
      "118:\tlearn: 0.3966839\ttotal: 4.6s\tremaining: 14.7s\n",
      "119:\tlearn: 0.3947776\ttotal: 4.63s\tremaining: 14.7s\n",
      "120:\tlearn: 0.3934143\ttotal: 4.66s\tremaining: 14.6s\n",
      "121:\tlearn: 0.3922338\ttotal: 4.68s\tremaining: 14.5s\n",
      "122:\tlearn: 0.3902030\ttotal: 4.75s\tremaining: 14.6s\n",
      "123:\tlearn: 0.3882305\ttotal: 4.8s\tremaining: 14.5s\n",
      "124:\tlearn: 0.3872065\ttotal: 4.82s\tremaining: 14.5s\n",
      "125:\tlearn: 0.3861210\ttotal: 4.86s\tremaining: 14.4s\n",
      "126:\tlearn: 0.3849654\ttotal: 4.92s\tremaining: 14.5s\n",
      "127:\tlearn: 0.3835586\ttotal: 4.95s\tremaining: 14.4s\n",
      "128:\tlearn: 0.3818314\ttotal: 4.98s\tremaining: 14.3s\n",
      "129:\tlearn: 0.3804988\ttotal: 5s\tremaining: 14.2s\n",
      "130:\tlearn: 0.3794082\ttotal: 5.07s\tremaining: 14.3s\n",
      "131:\tlearn: 0.3785356\ttotal: 5.12s\tremaining: 14.3s\n",
      "132:\tlearn: 0.3761934\ttotal: 5.15s\tremaining: 14.2s\n",
      "133:\tlearn: 0.3741051\ttotal: 5.17s\tremaining: 14.1s\n",
      "134:\tlearn: 0.3726692\ttotal: 5.21s\tremaining: 14.1s\n",
      "135:\tlearn: 0.3711982\ttotal: 5.27s\tremaining: 14.1s\n",
      "136:\tlearn: 0.3700628\ttotal: 5.3s\tremaining: 14.1s\n",
      "137:\tlearn: 0.3687542\ttotal: 5.33s\tremaining: 14s\n",
      "138:\tlearn: 0.3676065\ttotal: 5.35s\tremaining: 13.9s\n",
      "139:\tlearn: 0.3660457\ttotal: 5.38s\tremaining: 13.8s\n",
      "140:\tlearn: 0.3648523\ttotal: 5.45s\tremaining: 13.9s\n",
      "141:\tlearn: 0.3635331\ttotal: 5.5s\tremaining: 13.9s\n",
      "142:\tlearn: 0.3620646\ttotal: 5.52s\tremaining: 13.8s\n",
      "143:\tlearn: 0.3604093\ttotal: 5.56s\tremaining: 13.8s\n",
      "144:\tlearn: 0.3593695\ttotal: 5.62s\tremaining: 13.8s\n",
      "145:\tlearn: 0.3579187\ttotal: 5.66s\tremaining: 13.7s\n",
      "146:\tlearn: 0.3566789\ttotal: 5.68s\tremaining: 13.6s\n",
      "147:\tlearn: 0.3553689\ttotal: 5.71s\tremaining: 13.6s\n",
      "148:\tlearn: 0.3539511\ttotal: 5.76s\tremaining: 13.6s\n",
      "149:\tlearn: 0.3530545\ttotal: 5.8s\tremaining: 13.5s\n",
      "150:\tlearn: 0.3518608\ttotal: 5.83s\tremaining: 13.5s\n",
      "151:\tlearn: 0.3500893\ttotal: 5.85s\tremaining: 13.4s\n",
      "152:\tlearn: 0.3487112\ttotal: 5.87s\tremaining: 13.3s\n",
      "153:\tlearn: 0.3471301\ttotal: 5.95s\tremaining: 13.4s\n",
      "154:\tlearn: 0.3457656\ttotal: 5.98s\tremaining: 13.3s\n",
      "155:\tlearn: 0.3442181\ttotal: 6s\tremaining: 13.2s\n",
      "156:\tlearn: 0.3431384\ttotal: 6.02s\tremaining: 13.2s\n",
      "157:\tlearn: 0.3417121\ttotal: 6.1s\tremaining: 13.2s\n",
      "158:\tlearn: 0.3402496\ttotal: 6.13s\tremaining: 13.2s\n",
      "159:\tlearn: 0.3383575\ttotal: 6.16s\tremaining: 13.1s\n",
      "160:\tlearn: 0.3373313\ttotal: 6.18s\tremaining: 13s\n",
      "161:\tlearn: 0.3356468\ttotal: 6.22s\tremaining: 13s\n",
      "162:\tlearn: 0.3344804\ttotal: 6.29s\tremaining: 13s\n",
      "163:\tlearn: 0.3333145\ttotal: 6.32s\tremaining: 13s\n",
      "164:\tlearn: 0.3321426\ttotal: 6.35s\tremaining: 12.9s\n",
      "165:\tlearn: 0.3309774\ttotal: 6.37s\tremaining: 12.8s\n",
      "166:\tlearn: 0.3297848\ttotal: 6.44s\tremaining: 12.8s\n",
      "167:\tlearn: 0.3284736\ttotal: 6.49s\tremaining: 12.8s\n",
      "168:\tlearn: 0.3274410\ttotal: 6.51s\tremaining: 12.8s\n",
      "169:\tlearn: 0.3263526\ttotal: 6.54s\tremaining: 12.7s\n",
      "170:\tlearn: 0.3250990\ttotal: 6.61s\tremaining: 12.7s\n",
      "171:\tlearn: 0.3241144\ttotal: 6.67s\tremaining: 12.7s\n",
      "172:\tlearn: 0.3229791\ttotal: 6.69s\tremaining: 12.6s\n",
      "173:\tlearn: 0.3214643\ttotal: 6.71s\tremaining: 12.6s\n",
      "174:\tlearn: 0.3204781\ttotal: 6.76s\tremaining: 12.6s\n",
      "175:\tlearn: 0.3193645\ttotal: 6.83s\tremaining: 12.6s\n",
      "176:\tlearn: 0.3185584\ttotal: 6.86s\tremaining: 12.5s\n",
      "177:\tlearn: 0.3173326\ttotal: 6.89s\tremaining: 12.5s\n",
      "178:\tlearn: 0.3160963\ttotal: 6.91s\tremaining: 12.4s\n",
      "179:\tlearn: 0.3146881\ttotal: 6.98s\tremaining: 12.4s\n",
      "180:\tlearn: 0.3132556\ttotal: 7.01s\tremaining: 12.4s\n",
      "181:\tlearn: 0.3120048\ttotal: 7.04s\tremaining: 12.3s\n",
      "182:\tlearn: 0.3108339\ttotal: 7.06s\tremaining: 12.2s\n",
      "183:\tlearn: 0.3097246\ttotal: 7.13s\tremaining: 12.2s\n",
      "184:\tlearn: 0.3083230\ttotal: 7.17s\tremaining: 12.2s\n",
      "185:\tlearn: 0.3061847\ttotal: 7.2s\tremaining: 12.2s\n",
      "186:\tlearn: 0.3052278\ttotal: 7.22s\tremaining: 12.1s\n",
      "187:\tlearn: 0.3040634\ttotal: 7.29s\tremaining: 12.1s\n",
      "188:\tlearn: 0.3031709\ttotal: 7.31s\tremaining: 12s\n",
      "189:\tlearn: 0.3018562\ttotal: 7.34s\tremaining: 12s\n",
      "190:\tlearn: 0.3009197\ttotal: 7.37s\tremaining: 11.9s\n",
      "191:\tlearn: 0.2998245\ttotal: 7.39s\tremaining: 11.9s\n",
      "192:\tlearn: 0.2987992\ttotal: 7.46s\tremaining: 11.9s\n",
      "193:\tlearn: 0.2975418\ttotal: 7.51s\tremaining: 11.8s\n",
      "194:\tlearn: 0.2965013\ttotal: 7.54s\tremaining: 11.8s\n",
      "195:\tlearn: 0.2953730\ttotal: 7.56s\tremaining: 11.7s\n",
      "196:\tlearn: 0.2946459\ttotal: 7.58s\tremaining: 11.7s\n",
      "197:\tlearn: 0.2934520\ttotal: 7.66s\tremaining: 11.7s\n",
      "198:\tlearn: 0.2921756\ttotal: 7.7s\tremaining: 11.6s\n",
      "199:\tlearn: 0.2910581\ttotal: 7.72s\tremaining: 11.6s\n",
      "200:\tlearn: 0.2902410\ttotal: 7.75s\tremaining: 11.5s\n",
      "201:\tlearn: 0.2895889\ttotal: 7.79s\tremaining: 11.5s\n",
      "202:\tlearn: 0.2883870\ttotal: 7.86s\tremaining: 11.5s\n",
      "203:\tlearn: 0.2872283\ttotal: 7.89s\tremaining: 11.4s\n",
      "204:\tlearn: 0.2862874\ttotal: 7.91s\tremaining: 11.4s\n",
      "205:\tlearn: 0.2848617\ttotal: 7.93s\tremaining: 11.3s\n",
      "206:\tlearn: 0.2836614\ttotal: 8.01s\tremaining: 11.3s\n",
      "207:\tlearn: 0.2827170\ttotal: 8.05s\tremaining: 11.3s\n",
      "208:\tlearn: 0.2816069\ttotal: 8.08s\tremaining: 11.2s\n",
      "209:\tlearn: 0.2806762\ttotal: 8.1s\tremaining: 11.2s\n",
      "210:\tlearn: 0.2793845\ttotal: 8.15s\tremaining: 11.2s\n",
      "211:\tlearn: 0.2782818\ttotal: 8.21s\tremaining: 11.2s\n",
      "212:\tlearn: 0.2774364\ttotal: 8.24s\tremaining: 11.1s\n",
      "213:\tlearn: 0.2767592\ttotal: 8.26s\tremaining: 11s\n",
      "214:\tlearn: 0.2757676\ttotal: 8.28s\tremaining: 11s\n",
      "215:\tlearn: 0.2748408\ttotal: 8.36s\tremaining: 11s\n",
      "216:\tlearn: 0.2735301\ttotal: 8.4s\tremaining: 11s\n",
      "217:\tlearn: 0.2727737\ttotal: 8.43s\tremaining: 10.9s\n",
      "218:\tlearn: 0.2716850\ttotal: 8.45s\tremaining: 10.8s\n",
      "219:\tlearn: 0.2708442\ttotal: 8.47s\tremaining: 10.8s\n",
      "220:\tlearn: 0.2699605\ttotal: 8.49s\tremaining: 10.7s\n",
      "221:\tlearn: 0.2689766\ttotal: 8.53s\tremaining: 10.7s\n",
      "222:\tlearn: 0.2677027\ttotal: 8.6s\tremaining: 10.7s\n",
      "223:\tlearn: 0.2666781\ttotal: 8.62s\tremaining: 10.6s\n",
      "224:\tlearn: 0.2656062\ttotal: 8.64s\tremaining: 10.6s\n",
      "225:\tlearn: 0.2639331\ttotal: 8.71s\tremaining: 10.6s\n",
      "226:\tlearn: 0.2631885\ttotal: 8.76s\tremaining: 10.5s\n",
      "227:\tlearn: 0.2627080\ttotal: 8.78s\tremaining: 10.5s\n",
      "228:\tlearn: 0.2617833\ttotal: 8.81s\tremaining: 10.4s\n",
      "229:\tlearn: 0.2611925\ttotal: 8.83s\tremaining: 10.4s\n",
      "230:\tlearn: 0.2599594\ttotal: 8.9s\tremaining: 10.4s\n",
      "231:\tlearn: 0.2589559\ttotal: 8.94s\tremaining: 10.3s\n",
      "232:\tlearn: 0.2577476\ttotal: 8.96s\tremaining: 10.3s\n",
      "233:\tlearn: 0.2568122\ttotal: 8.98s\tremaining: 10.2s\n",
      "234:\tlearn: 0.2555052\ttotal: 9.01s\tremaining: 10.2s\n",
      "235:\tlearn: 0.2548044\ttotal: 9.08s\tremaining: 10.2s\n",
      "236:\tlearn: 0.2539155\ttotal: 9.12s\tremaining: 10.1s\n",
      "237:\tlearn: 0.2530025\ttotal: 9.14s\tremaining: 10.1s\n",
      "238:\tlearn: 0.2520513\ttotal: 9.17s\tremaining: 10s\n",
      "239:\tlearn: 0.2511406\ttotal: 9.19s\tremaining: 9.95s\n",
      "240:\tlearn: 0.2502521\ttotal: 9.26s\tremaining: 9.95s\n",
      "241:\tlearn: 0.2487296\ttotal: 9.3s\tremaining: 9.91s\n",
      "242:\tlearn: 0.2475708\ttotal: 9.32s\tremaining: 9.86s\n",
      "243:\tlearn: 0.2468056\ttotal: 9.35s\tremaining: 9.8s\n",
      "244:\tlearn: 0.2457926\ttotal: 9.37s\tremaining: 9.75s\n",
      "245:\tlearn: 0.2448028\ttotal: 9.44s\tremaining: 9.74s\n",
      "246:\tlearn: 0.2441438\ttotal: 9.47s\tremaining: 9.7s\n",
      "247:\tlearn: 0.2431254\ttotal: 9.5s\tremaining: 9.65s\n",
      "248:\tlearn: 0.2423346\ttotal: 9.52s\tremaining: 9.6s\n",
      "249:\tlearn: 0.2408281\ttotal: 9.56s\tremaining: 9.56s\n",
      "250:\tlearn: 0.2396491\ttotal: 9.63s\tremaining: 9.55s\n",
      "251:\tlearn: 0.2388123\ttotal: 9.66s\tremaining: 9.51s\n",
      "252:\tlearn: 0.2380901\ttotal: 9.68s\tremaining: 9.45s\n",
      "253:\tlearn: 0.2371415\ttotal: 9.7s\tremaining: 9.4s\n",
      "254:\tlearn: 0.2365635\ttotal: 9.78s\tremaining: 9.39s\n",
      "255:\tlearn: 0.2358321\ttotal: 9.82s\tremaining: 9.36s\n",
      "256:\tlearn: 0.2352989\ttotal: 9.85s\tremaining: 9.31s\n",
      "257:\tlearn: 0.2339238\ttotal: 9.87s\tremaining: 9.26s\n",
      "258:\tlearn: 0.2328485\ttotal: 9.89s\tremaining: 9.2s\n",
      "259:\tlearn: 0.2320387\ttotal: 9.96s\tremaining: 9.2s\n",
      "260:\tlearn: 0.2310804\ttotal: 10s\tremaining: 9.16s\n",
      "261:\tlearn: 0.2301411\ttotal: 10s\tremaining: 9.11s\n",
      "262:\tlearn: 0.2294243\ttotal: 10s\tremaining: 9.05s\n",
      "263:\tlearn: 0.2286369\ttotal: 10.1s\tremaining: 9.04s\n",
      "264:\tlearn: 0.2277580\ttotal: 10.2s\tremaining: 9.02s\n",
      "265:\tlearn: 0.2266266\ttotal: 10.2s\tremaining: 8.97s\n",
      "266:\tlearn: 0.2259411\ttotal: 10.2s\tremaining: 8.92s\n",
      "267:\tlearn: 0.2251752\ttotal: 10.3s\tremaining: 8.89s\n",
      "268:\tlearn: 0.2241818\ttotal: 10.3s\tremaining: 8.87s\n",
      "269:\tlearn: 0.2233029\ttotal: 10.4s\tremaining: 8.83s\n",
      "270:\tlearn: 0.2223259\ttotal: 10.4s\tremaining: 8.78s\n",
      "271:\tlearn: 0.2215985\ttotal: 10.4s\tremaining: 8.72s\n",
      "272:\tlearn: 0.2211339\ttotal: 10.5s\tremaining: 8.71s\n",
      "273:\tlearn: 0.2203410\ttotal: 10.5s\tremaining: 8.69s\n",
      "274:\tlearn: 0.2198619\ttotal: 10.6s\tremaining: 8.64s\n",
      "275:\tlearn: 0.2192400\ttotal: 10.6s\tremaining: 8.59s\n",
      "276:\tlearn: 0.2185004\ttotal: 10.6s\tremaining: 8.54s\n",
      "277:\tlearn: 0.2177783\ttotal: 10.7s\tremaining: 8.53s\n",
      "278:\tlearn: 0.2168682\ttotal: 10.7s\tremaining: 8.49s\n",
      "279:\tlearn: 0.2163817\ttotal: 10.7s\tremaining: 8.44s\n",
      "280:\tlearn: 0.2156675\ttotal: 10.8s\tremaining: 8.39s\n",
      "281:\tlearn: 0.2149582\ttotal: 10.8s\tremaining: 8.36s\n",
      "282:\tlearn: 0.2140701\ttotal: 10.9s\tremaining: 8.34s\n",
      "283:\tlearn: 0.2133206\ttotal: 10.9s\tremaining: 8.29s\n",
      "284:\tlearn: 0.2125289\ttotal: 10.9s\tremaining: 8.24s\n",
      "285:\tlearn: 0.2117904\ttotal: 10.9s\tremaining: 8.19s\n",
      "286:\tlearn: 0.2106438\ttotal: 11s\tremaining: 8.18s\n",
      "287:\tlearn: 0.2101136\ttotal: 11.1s\tremaining: 8.14s\n",
      "288:\tlearn: 0.2095118\ttotal: 11.1s\tremaining: 8.1s\n",
      "289:\tlearn: 0.2089349\ttotal: 11.1s\tremaining: 8.04s\n",
      "290:\tlearn: 0.2084189\ttotal: 11.1s\tremaining: 8s\n",
      "291:\tlearn: 0.2077686\ttotal: 11.2s\tremaining: 7.94s\n",
      "292:\tlearn: 0.2069787\ttotal: 11.2s\tremaining: 7.89s\n",
      "293:\tlearn: 0.2063583\ttotal: 11.2s\tremaining: 7.88s\n",
      "294:\tlearn: 0.2058763\ttotal: 11.3s\tremaining: 7.84s\n",
      "295:\tlearn: 0.2050255\ttotal: 11.3s\tremaining: 7.79s\n",
      "296:\tlearn: 0.2040232\ttotal: 11.3s\tremaining: 7.75s\n",
      "297:\tlearn: 0.2034483\ttotal: 11.4s\tremaining: 7.7s\n",
      "298:\tlearn: 0.2026696\ttotal: 11.4s\tremaining: 7.68s\n",
      "299:\tlearn: 0.2018064\ttotal: 11.5s\tremaining: 7.64s\n",
      "300:\tlearn: 0.2013069\ttotal: 11.5s\tremaining: 7.6s\n",
      "301:\tlearn: 0.2006558\ttotal: 11.5s\tremaining: 7.55s\n",
      "302:\tlearn: 0.1998103\ttotal: 11.6s\tremaining: 7.53s\n",
      "303:\tlearn: 0.1989802\ttotal: 11.6s\tremaining: 7.5s\n",
      "304:\tlearn: 0.1982711\ttotal: 11.7s\tremaining: 7.45s\n",
      "305:\tlearn: 0.1976833\ttotal: 11.7s\tremaining: 7.4s\n",
      "306:\tlearn: 0.1969273\ttotal: 11.7s\tremaining: 7.37s\n",
      "307:\tlearn: 0.1960004\ttotal: 11.8s\tremaining: 7.35s\n",
      "308:\tlearn: 0.1954889\ttotal: 11.8s\tremaining: 7.31s\n",
      "309:\tlearn: 0.1950349\ttotal: 11.8s\tremaining: 7.26s\n",
      "310:\tlearn: 0.1944650\ttotal: 11.9s\tremaining: 7.21s\n",
      "311:\tlearn: 0.1934597\ttotal: 11.9s\tremaining: 7.2s\n",
      "312:\tlearn: 0.1928480\ttotal: 12s\tremaining: 7.16s\n",
      "313:\tlearn: 0.1919730\ttotal: 12s\tremaining: 7.11s\n",
      "314:\tlearn: 0.1915925\ttotal: 12s\tremaining: 7.07s\n",
      "315:\tlearn: 0.1910203\ttotal: 12.1s\tremaining: 7.04s\n",
      "316:\tlearn: 0.1904819\ttotal: 12.1s\tremaining: 7.01s\n",
      "317:\tlearn: 0.1892796\ttotal: 12.2s\tremaining: 6.97s\n",
      "318:\tlearn: 0.1884813\ttotal: 12.2s\tremaining: 6.92s\n",
      "319:\tlearn: 0.1880700\ttotal: 12.2s\tremaining: 6.87s\n",
      "320:\tlearn: 0.1873068\ttotal: 12.3s\tremaining: 6.86s\n",
      "321:\tlearn: 0.1865950\ttotal: 12.4s\tremaining: 6.83s\n",
      "322:\tlearn: 0.1859453\ttotal: 12.4s\tremaining: 6.78s\n",
      "323:\tlearn: 0.1850728\ttotal: 12.4s\tremaining: 6.74s\n",
      "324:\tlearn: 0.1844003\ttotal: 12.5s\tremaining: 6.72s\n",
      "325:\tlearn: 0.1838384\ttotal: 12.5s\tremaining: 6.7s\n",
      "326:\tlearn: 0.1831859\ttotal: 12.6s\tremaining: 6.66s\n",
      "327:\tlearn: 0.1826199\ttotal: 12.6s\tremaining: 6.61s\n",
      "328:\tlearn: 0.1822079\ttotal: 12.6s\tremaining: 6.56s\n",
      "329:\tlearn: 0.1818261\ttotal: 12.7s\tremaining: 6.52s\n",
      "330:\tlearn: 0.1813710\ttotal: 12.7s\tremaining: 6.5s\n",
      "331:\tlearn: 0.1807492\ttotal: 12.7s\tremaining: 6.45s\n",
      "332:\tlearn: 0.1802189\ttotal: 12.8s\tremaining: 6.4s\n",
      "333:\tlearn: 0.1797592\ttotal: 12.8s\tremaining: 6.37s\n",
      "334:\tlearn: 0.1792760\ttotal: 12.9s\tremaining: 6.34s\n",
      "335:\tlearn: 0.1785959\ttotal: 12.9s\tremaining: 6.3s\n",
      "336:\tlearn: 0.1781340\ttotal: 12.9s\tremaining: 6.26s\n",
      "337:\tlearn: 0.1775821\ttotal: 13s\tremaining: 6.21s\n",
      "338:\tlearn: 0.1768996\ttotal: 13s\tremaining: 6.19s\n",
      "339:\tlearn: 0.1762066\ttotal: 13.1s\tremaining: 6.15s\n",
      "340:\tlearn: 0.1758415\ttotal: 13.1s\tremaining: 6.11s\n",
      "341:\tlearn: 0.1754760\ttotal: 13.1s\tremaining: 6.06s\n",
      "342:\tlearn: 0.1748363\ttotal: 13.1s\tremaining: 6.01s\n",
      "343:\tlearn: 0.1743741\ttotal: 13.2s\tremaining: 5.99s\n",
      "344:\tlearn: 0.1735587\ttotal: 13.3s\tremaining: 5.96s\n",
      "345:\tlearn: 0.1730033\ttotal: 13.3s\tremaining: 5.91s\n",
      "346:\tlearn: 0.1725437\ttotal: 13.3s\tremaining: 5.87s\n",
      "347:\tlearn: 0.1718451\ttotal: 13.3s\tremaining: 5.83s\n",
      "348:\tlearn: 0.1713240\ttotal: 13.4s\tremaining: 5.8s\n",
      "349:\tlearn: 0.1708471\ttotal: 13.4s\tremaining: 5.76s\n",
      "350:\tlearn: 0.1701960\ttotal: 13.5s\tremaining: 5.72s\n",
      "351:\tlearn: 0.1695654\ttotal: 13.5s\tremaining: 5.67s\n",
      "352:\tlearn: 0.1687535\ttotal: 13.6s\tremaining: 5.65s\n",
      "353:\tlearn: 0.1681456\ttotal: 13.6s\tremaining: 5.61s\n",
      "354:\tlearn: 0.1677770\ttotal: 13.6s\tremaining: 5.56s\n",
      "355:\tlearn: 0.1672376\ttotal: 13.6s\tremaining: 5.52s\n",
      "356:\tlearn: 0.1667350\ttotal: 13.7s\tremaining: 5.49s\n",
      "357:\tlearn: 0.1662483\ttotal: 13.8s\tremaining: 5.46s\n",
      "358:\tlearn: 0.1658047\ttotal: 13.8s\tremaining: 5.41s\n",
      "359:\tlearn: 0.1654236\ttotal: 13.8s\tremaining: 5.37s\n",
      "360:\tlearn: 0.1648752\ttotal: 13.9s\tremaining: 5.34s\n",
      "361:\tlearn: 0.1641300\ttotal: 13.9s\tremaining: 5.3s\n",
      "362:\tlearn: 0.1637027\ttotal: 13.9s\tremaining: 5.26s\n",
      "363:\tlearn: 0.1633157\ttotal: 14s\tremaining: 5.22s\n",
      "364:\tlearn: 0.1629367\ttotal: 14s\tremaining: 5.17s\n",
      "365:\tlearn: 0.1623879\ttotal: 14.1s\tremaining: 5.15s\n",
      "366:\tlearn: 0.1617959\ttotal: 14.1s\tremaining: 5.11s\n",
      "367:\tlearn: 0.1612410\ttotal: 14.1s\tremaining: 5.07s\n",
      "368:\tlearn: 0.1607239\ttotal: 14.2s\tremaining: 5.03s\n",
      "369:\tlearn: 0.1603017\ttotal: 14.2s\tremaining: 4.98s\n",
      "370:\tlearn: 0.1598263\ttotal: 14.3s\tremaining: 4.96s\n",
      "371:\tlearn: 0.1591352\ttotal: 14.3s\tremaining: 4.92s\n",
      "372:\tlearn: 0.1587950\ttotal: 14.3s\tremaining: 4.87s\n",
      "373:\tlearn: 0.1583919\ttotal: 14.3s\tremaining: 4.83s\n",
      "374:\tlearn: 0.1578771\ttotal: 14.4s\tremaining: 4.79s\n",
      "375:\tlearn: 0.1572375\ttotal: 14.4s\tremaining: 4.76s\n",
      "376:\tlearn: 0.1567886\ttotal: 14.5s\tremaining: 4.72s\n",
      "377:\tlearn: 0.1561936\ttotal: 14.5s\tremaining: 4.68s\n",
      "378:\tlearn: 0.1557767\ttotal: 14.5s\tremaining: 4.63s\n",
      "379:\tlearn: 0.1554381\ttotal: 14.6s\tremaining: 4.6s\n",
      "380:\tlearn: 0.1548642\ttotal: 14.6s\tremaining: 4.57s\n",
      "381:\tlearn: 0.1543996\ttotal: 14.7s\tremaining: 4.53s\n",
      "382:\tlearn: 0.1540177\ttotal: 14.7s\tremaining: 4.48s\n",
      "383:\tlearn: 0.1536151\ttotal: 14.7s\tremaining: 4.44s\n",
      "384:\tlearn: 0.1530569\ttotal: 14.8s\tremaining: 4.41s\n",
      "385:\tlearn: 0.1526100\ttotal: 14.8s\tremaining: 4.38s\n",
      "386:\tlearn: 0.1519690\ttotal: 14.9s\tremaining: 4.36s\n",
      "387:\tlearn: 0.1516253\ttotal: 15s\tremaining: 4.32s\n",
      "388:\tlearn: 0.1511108\ttotal: 15s\tremaining: 4.27s\n",
      "389:\tlearn: 0.1507528\ttotal: 15s\tremaining: 4.23s\n",
      "390:\tlearn: 0.1502172\ttotal: 15.1s\tremaining: 4.2s\n",
      "391:\tlearn: 0.1497079\ttotal: 15.1s\tremaining: 4.16s\n",
      "392:\tlearn: 0.1492089\ttotal: 15.1s\tremaining: 4.12s\n",
      "393:\tlearn: 0.1488099\ttotal: 15.1s\tremaining: 4.07s\n",
      "394:\tlearn: 0.1483306\ttotal: 15.2s\tremaining: 4.04s\n",
      "395:\tlearn: 0.1478792\ttotal: 15.3s\tremaining: 4.01s\n",
      "396:\tlearn: 0.1473122\ttotal: 15.3s\tremaining: 3.97s\n",
      "397:\tlearn: 0.1469964\ttotal: 15.3s\tremaining: 3.92s\n",
      "398:\tlearn: 0.1463677\ttotal: 15.4s\tremaining: 3.89s\n",
      "399:\tlearn: 0.1460009\ttotal: 15.4s\tremaining: 3.86s\n",
      "400:\tlearn: 0.1454678\ttotal: 15.5s\tremaining: 3.82s\n",
      "401:\tlearn: 0.1447991\ttotal: 15.5s\tremaining: 3.77s\n",
      "402:\tlearn: 0.1443242\ttotal: 15.5s\tremaining: 3.73s\n",
      "403:\tlearn: 0.1438421\ttotal: 15.6s\tremaining: 3.7s\n",
      "404:\tlearn: 0.1433078\ttotal: 15.6s\tremaining: 3.66s\n",
      "405:\tlearn: 0.1428858\ttotal: 15.6s\tremaining: 3.62s\n",
      "406:\tlearn: 0.1422691\ttotal: 15.7s\tremaining: 3.58s\n",
      "407:\tlearn: 0.1418019\ttotal: 15.7s\tremaining: 3.54s\n",
      "408:\tlearn: 0.1412228\ttotal: 15.8s\tremaining: 3.51s\n",
      "409:\tlearn: 0.1407640\ttotal: 15.8s\tremaining: 3.47s\n",
      "410:\tlearn: 0.1402436\ttotal: 15.8s\tremaining: 3.43s\n",
      "411:\tlearn: 0.1399091\ttotal: 15.9s\tremaining: 3.39s\n",
      "412:\tlearn: 0.1394559\ttotal: 15.9s\tremaining: 3.35s\n",
      "413:\tlearn: 0.1391482\ttotal: 16s\tremaining: 3.32s\n",
      "414:\tlearn: 0.1388127\ttotal: 16s\tremaining: 3.28s\n",
      "415:\tlearn: 0.1383971\ttotal: 16s\tremaining: 3.23s\n",
      "416:\tlearn: 0.1379988\ttotal: 16s\tremaining: 3.19s\n",
      "417:\tlearn: 0.1376083\ttotal: 16.1s\tremaining: 3.16s\n",
      "418:\tlearn: 0.1370496\ttotal: 16.2s\tremaining: 3.12s\n",
      "419:\tlearn: 0.1367953\ttotal: 16.2s\tremaining: 3.08s\n",
      "420:\tlearn: 0.1364243\ttotal: 16.2s\tremaining: 3.04s\n",
      "421:\tlearn: 0.1360083\ttotal: 16.3s\tremaining: 3s\n",
      "422:\tlearn: 0.1356786\ttotal: 16.3s\tremaining: 2.97s\n",
      "423:\tlearn: 0.1351327\ttotal: 16.3s\tremaining: 2.93s\n",
      "424:\tlearn: 0.1348148\ttotal: 16.4s\tremaining: 2.89s\n",
      "425:\tlearn: 0.1343317\ttotal: 16.4s\tremaining: 2.85s\n",
      "426:\tlearn: 0.1338204\ttotal: 16.5s\tremaining: 2.81s\n",
      "427:\tlearn: 0.1334070\ttotal: 16.5s\tremaining: 2.78s\n",
      "428:\tlearn: 0.1328834\ttotal: 16.5s\tremaining: 2.74s\n",
      "429:\tlearn: 0.1326113\ttotal: 16.6s\tremaining: 2.69s\n",
      "430:\tlearn: 0.1322621\ttotal: 16.6s\tremaining: 2.66s\n",
      "431:\tlearn: 0.1318018\ttotal: 16.7s\tremaining: 2.63s\n",
      "432:\tlearn: 0.1313575\ttotal: 16.7s\tremaining: 2.58s\n",
      "433:\tlearn: 0.1309604\ttotal: 16.7s\tremaining: 2.54s\n",
      "434:\tlearn: 0.1307216\ttotal: 16.8s\tremaining: 2.51s\n",
      "435:\tlearn: 0.1302525\ttotal: 16.9s\tremaining: 2.47s\n",
      "436:\tlearn: 0.1296158\ttotal: 16.9s\tremaining: 2.43s\n",
      "437:\tlearn: 0.1293190\ttotal: 16.9s\tremaining: 2.39s\n",
      "438:\tlearn: 0.1289920\ttotal: 16.9s\tremaining: 2.35s\n",
      "439:\tlearn: 0.1285894\ttotal: 17s\tremaining: 2.32s\n",
      "440:\tlearn: 0.1282620\ttotal: 17s\tremaining: 2.28s\n",
      "441:\tlearn: 0.1279189\ttotal: 17.1s\tremaining: 2.24s\n",
      "442:\tlearn: 0.1276417\ttotal: 17.1s\tremaining: 2.2s\n",
      "443:\tlearn: 0.1271280\ttotal: 17.1s\tremaining: 2.16s\n",
      "444:\tlearn: 0.1267371\ttotal: 17.2s\tremaining: 2.13s\n",
      "445:\tlearn: 0.1263654\ttotal: 17.2s\tremaining: 2.09s\n",
      "446:\tlearn: 0.1259141\ttotal: 17.3s\tremaining: 2.04s\n",
      "447:\tlearn: 0.1254328\ttotal: 17.3s\tremaining: 2s\n",
      "448:\tlearn: 0.1250364\ttotal: 17.3s\tremaining: 1.97s\n",
      "449:\tlearn: 0.1247719\ttotal: 17.4s\tremaining: 1.93s\n",
      "450:\tlearn: 0.1245254\ttotal: 17.4s\tremaining: 1.89s\n",
      "451:\tlearn: 0.1242661\ttotal: 17.4s\tremaining: 1.85s\n",
      "452:\tlearn: 0.1237452\ttotal: 17.5s\tremaining: 1.82s\n",
      "453:\tlearn: 0.1232282\ttotal: 17.6s\tremaining: 1.78s\n",
      "454:\tlearn: 0.1227722\ttotal: 17.6s\tremaining: 1.74s\n",
      "455:\tlearn: 0.1224821\ttotal: 17.6s\tremaining: 1.7s\n",
      "456:\tlearn: 0.1220007\ttotal: 17.6s\tremaining: 1.66s\n",
      "457:\tlearn: 0.1215153\ttotal: 17.7s\tremaining: 1.63s\n",
      "458:\tlearn: 0.1211523\ttotal: 17.8s\tremaining: 1.59s\n",
      "459:\tlearn: 0.1208938\ttotal: 17.8s\tremaining: 1.55s\n",
      "460:\tlearn: 0.1205300\ttotal: 17.8s\tremaining: 1.51s\n",
      "461:\tlearn: 0.1201442\ttotal: 17.8s\tremaining: 1.47s\n",
      "462:\tlearn: 0.1197575\ttotal: 17.9s\tremaining: 1.43s\n",
      "463:\tlearn: 0.1195757\ttotal: 17.9s\tremaining: 1.39s\n",
      "464:\tlearn: 0.1193306\ttotal: 18s\tremaining: 1.35s\n",
      "465:\tlearn: 0.1189981\ttotal: 18s\tremaining: 1.31s\n",
      "466:\tlearn: 0.1186862\ttotal: 18.1s\tremaining: 1.27s\n",
      "467:\tlearn: 0.1184272\ttotal: 18.1s\tremaining: 1.24s\n",
      "468:\tlearn: 0.1182044\ttotal: 18.1s\tremaining: 1.2s\n",
      "469:\tlearn: 0.1178301\ttotal: 18.1s\tremaining: 1.16s\n",
      "470:\tlearn: 0.1175226\ttotal: 18.2s\tremaining: 1.12s\n",
      "471:\tlearn: 0.1172092\ttotal: 18.3s\tremaining: 1.08s\n",
      "472:\tlearn: 0.1169454\ttotal: 18.3s\tremaining: 1.04s\n",
      "473:\tlearn: 0.1166601\ttotal: 18.3s\tremaining: 1s\n",
      "474:\tlearn: 0.1164018\ttotal: 18.3s\tremaining: 965ms\n",
      "475:\tlearn: 0.1160386\ttotal: 18.4s\tremaining: 928ms\n",
      "476:\tlearn: 0.1158050\ttotal: 18.4s\tremaining: 889ms\n",
      "477:\tlearn: 0.1154776\ttotal: 18.5s\tremaining: 850ms\n",
      "478:\tlearn: 0.1152633\ttotal: 18.5s\tremaining: 811ms\n",
      "479:\tlearn: 0.1148765\ttotal: 18.5s\tremaining: 771ms\n",
      "480:\tlearn: 0.1146142\ttotal: 18.6s\tremaining: 734ms\n",
      "481:\tlearn: 0.1141182\ttotal: 18.6s\tremaining: 696ms\n",
      "482:\tlearn: 0.1138595\ttotal: 18.7s\tremaining: 657ms\n",
      "483:\tlearn: 0.1135076\ttotal: 18.7s\tremaining: 618ms\n",
      "484:\tlearn: 0.1131596\ttotal: 18.8s\tremaining: 580ms\n",
      "485:\tlearn: 0.1127635\ttotal: 18.8s\tremaining: 542ms\n",
      "486:\tlearn: 0.1124113\ttotal: 18.8s\tremaining: 503ms\n",
      "487:\tlearn: 0.1119750\ttotal: 18.9s\tremaining: 464ms\n",
      "488:\tlearn: 0.1114352\ttotal: 18.9s\tremaining: 425ms\n",
      "489:\tlearn: 0.1111335\ttotal: 19s\tremaining: 387ms\n",
      "490:\tlearn: 0.1107962\ttotal: 19s\tremaining: 348ms\n",
      "491:\tlearn: 0.1105048\ttotal: 19s\tremaining: 309ms\n",
      "492:\tlearn: 0.1102315\ttotal: 19s\tremaining: 270ms\n",
      "493:\tlearn: 0.1100032\ttotal: 19.1s\tremaining: 232ms\n",
      "494:\tlearn: 0.1096669\ttotal: 19.2s\tremaining: 194ms\n",
      "495:\tlearn: 0.1093441\ttotal: 19.2s\tremaining: 155ms\n",
      "496:\tlearn: 0.1089775\ttotal: 19.2s\tremaining: 116ms\n",
      "497:\tlearn: 0.1086511\ttotal: 19.3s\tremaining: 77.4ms\n",
      "498:\tlearn: 0.1083658\ttotal: 19.3s\tremaining: 38.8ms\n",
      "499:\tlearn: 0.1080019\ttotal: 19.4s\tremaining: 0us\n",
      "0:\tlearn: 0.6892975\ttotal: 21.1ms\tremaining: 10.5s\n",
      "1:\tlearn: 0.6854799\ttotal: 41.2ms\tremaining: 10.3s\n",
      "2:\tlearn: 0.6816834\ttotal: 112ms\tremaining: 18.6s\n",
      "3:\tlearn: 0.6777543\ttotal: 154ms\tremaining: 19.1s\n",
      "4:\tlearn: 0.6741008\ttotal: 178ms\tremaining: 17.6s\n",
      "5:\tlearn: 0.6700203\ttotal: 201ms\tremaining: 16.5s\n",
      "6:\tlearn: 0.6665193\ttotal: 222ms\tremaining: 15.6s\n",
      "7:\tlearn: 0.6626865\ttotal: 293ms\tremaining: 18s\n",
      "8:\tlearn: 0.6591542\ttotal: 334ms\tremaining: 18.2s\n",
      "9:\tlearn: 0.6557462\ttotal: 359ms\tremaining: 17.6s\n",
      "10:\tlearn: 0.6521548\ttotal: 380ms\tremaining: 16.9s\n",
      "11:\tlearn: 0.6487067\ttotal: 424ms\tremaining: 17.2s\n",
      "12:\tlearn: 0.6451025\ttotal: 486ms\tremaining: 18.2s\n",
      "13:\tlearn: 0.6415692\ttotal: 520ms\tremaining: 18s\n",
      "14:\tlearn: 0.6379724\ttotal: 544ms\tremaining: 17.6s\n",
      "15:\tlearn: 0.6343340\ttotal: 564ms\tremaining: 17.1s\n",
      "16:\tlearn: 0.6310430\ttotal: 610ms\tremaining: 17.3s\n",
      "17:\tlearn: 0.6277022\ttotal: 665ms\tremaining: 17.8s\n",
      "18:\tlearn: 0.6246817\ttotal: 694ms\tremaining: 17.6s\n",
      "19:\tlearn: 0.6222894\ttotal: 716ms\tremaining: 17.2s\n",
      "20:\tlearn: 0.6195989\ttotal: 737ms\tremaining: 16.8s\n",
      "21:\tlearn: 0.6158917\ttotal: 807ms\tremaining: 17.5s\n",
      "22:\tlearn: 0.6130568\ttotal: 853ms\tremaining: 17.7s\n",
      "23:\tlearn: 0.6101047\ttotal: 878ms\tremaining: 17.4s\n",
      "24:\tlearn: 0.6070807\ttotal: 901ms\tremaining: 17.1s\n",
      "25:\tlearn: 0.6042422\ttotal: 923ms\tremaining: 16.8s\n",
      "26:\tlearn: 0.6003939\ttotal: 972ms\tremaining: 17s\n",
      "27:\tlearn: 0.5976258\ttotal: 996ms\tremaining: 16.8s\n",
      "28:\tlearn: 0.5944980\ttotal: 1.01s\tremaining: 16.5s\n",
      "29:\tlearn: 0.5912082\ttotal: 1.07s\tremaining: 16.8s\n",
      "30:\tlearn: 0.5887281\ttotal: 1.13s\tremaining: 17.1s\n",
      "31:\tlearn: 0.5857942\ttotal: 1.16s\tremaining: 17s\n",
      "32:\tlearn: 0.5832569\ttotal: 1.18s\tremaining: 16.7s\n",
      "33:\tlearn: 0.5805719\ttotal: 1.2s\tremaining: 16.5s\n",
      "34:\tlearn: 0.5778635\ttotal: 1.27s\tremaining: 16.9s\n",
      "35:\tlearn: 0.5748905\ttotal: 1.32s\tremaining: 17s\n",
      "36:\tlearn: 0.5719390\ttotal: 1.34s\tremaining: 16.8s\n",
      "37:\tlearn: 0.5692563\ttotal: 1.36s\tremaining: 16.6s\n",
      "38:\tlearn: 0.5656398\ttotal: 1.38s\tremaining: 16.4s\n",
      "39:\tlearn: 0.5634475\ttotal: 1.46s\tremaining: 16.8s\n",
      "40:\tlearn: 0.5603981\ttotal: 1.5s\tremaining: 16.8s\n",
      "41:\tlearn: 0.5568822\ttotal: 1.52s\tremaining: 16.6s\n",
      "42:\tlearn: 0.5540951\ttotal: 1.54s\tremaining: 16.4s\n",
      "43:\tlearn: 0.5515948\ttotal: 1.59s\tremaining: 16.4s\n",
      "44:\tlearn: 0.5494037\ttotal: 1.65s\tremaining: 16.7s\n",
      "45:\tlearn: 0.5472669\ttotal: 1.69s\tremaining: 16.7s\n",
      "46:\tlearn: 0.5444162\ttotal: 1.71s\tremaining: 16.5s\n",
      "47:\tlearn: 0.5416201\ttotal: 1.73s\tremaining: 16.3s\n",
      "48:\tlearn: 0.5393625\ttotal: 1.81s\tremaining: 16.6s\n",
      "49:\tlearn: 0.5369920\ttotal: 1.85s\tremaining: 16.6s\n",
      "50:\tlearn: 0.5343666\ttotal: 1.87s\tremaining: 16.5s\n",
      "51:\tlearn: 0.5325057\ttotal: 1.9s\tremaining: 16.3s\n",
      "52:\tlearn: 0.5304864\ttotal: 1.93s\tremaining: 16.3s\n",
      "53:\tlearn: 0.5272295\ttotal: 2s\tremaining: 16.5s\n",
      "54:\tlearn: 0.5242958\ttotal: 2.04s\tremaining: 16.5s\n",
      "55:\tlearn: 0.5209942\ttotal: 2.06s\tremaining: 16.3s\n",
      "56:\tlearn: 0.5184869\ttotal: 2.08s\tremaining: 16.2s\n",
      "57:\tlearn: 0.5164783\ttotal: 2.14s\tremaining: 16.3s\n",
      "58:\tlearn: 0.5145307\ttotal: 2.19s\tremaining: 16.4s\n",
      "59:\tlearn: 0.5124605\ttotal: 2.22s\tremaining: 16.3s\n",
      "60:\tlearn: 0.5100638\ttotal: 2.25s\tremaining: 16.2s\n",
      "61:\tlearn: 0.5074051\ttotal: 2.27s\tremaining: 16.1s\n",
      "62:\tlearn: 0.5057938\ttotal: 2.3s\tremaining: 15.9s\n",
      "63:\tlearn: 0.5033339\ttotal: 2.37s\tremaining: 16.2s\n",
      "64:\tlearn: 0.5011125\ttotal: 2.41s\tremaining: 16.1s\n",
      "65:\tlearn: 0.4992944\ttotal: 2.44s\tremaining: 16s\n",
      "66:\tlearn: 0.4971341\ttotal: 2.46s\tremaining: 15.9s\n",
      "67:\tlearn: 0.4953383\ttotal: 2.49s\tremaining: 15.8s\n",
      "68:\tlearn: 0.4931630\ttotal: 2.56s\tremaining: 16s\n",
      "69:\tlearn: 0.4905238\ttotal: 2.59s\tremaining: 15.9s\n",
      "70:\tlearn: 0.4883311\ttotal: 2.62s\tremaining: 15.8s\n",
      "71:\tlearn: 0.4864015\ttotal: 2.64s\tremaining: 15.7s\n",
      "72:\tlearn: 0.4844658\ttotal: 2.67s\tremaining: 15.6s\n",
      "73:\tlearn: 0.4823757\ttotal: 2.74s\tremaining: 15.8s\n",
      "74:\tlearn: 0.4805801\ttotal: 2.76s\tremaining: 15.7s\n",
      "75:\tlearn: 0.4781927\ttotal: 2.78s\tremaining: 15.5s\n",
      "76:\tlearn: 0.4756112\ttotal: 2.83s\tremaining: 15.5s\n",
      "77:\tlearn: 0.4733702\ttotal: 2.88s\tremaining: 15.6s\n",
      "78:\tlearn: 0.4713364\ttotal: 2.92s\tremaining: 15.6s\n",
      "79:\tlearn: 0.4695803\ttotal: 2.94s\tremaining: 15.4s\n",
      "80:\tlearn: 0.4676345\ttotal: 2.96s\tremaining: 15.3s\n",
      "81:\tlearn: 0.4652443\ttotal: 3.03s\tremaining: 15.5s\n",
      "82:\tlearn: 0.4634148\ttotal: 3.08s\tremaining: 15.5s\n",
      "83:\tlearn: 0.4614527\ttotal: 3.11s\tremaining: 15.4s\n",
      "84:\tlearn: 0.4593978\ttotal: 3.13s\tremaining: 15.3s\n",
      "85:\tlearn: 0.4571479\ttotal: 3.17s\tremaining: 15.3s\n",
      "86:\tlearn: 0.4552196\ttotal: 3.24s\tremaining: 15.4s\n",
      "87:\tlearn: 0.4532648\ttotal: 3.27s\tremaining: 15.3s\n",
      "88:\tlearn: 0.4519016\ttotal: 3.3s\tremaining: 15.2s\n",
      "89:\tlearn: 0.4501622\ttotal: 3.32s\tremaining: 15.1s\n",
      "90:\tlearn: 0.4483878\ttotal: 3.39s\tremaining: 15.3s\n",
      "91:\tlearn: 0.4465605\ttotal: 3.42s\tremaining: 15.2s\n",
      "92:\tlearn: 0.4447235\ttotal: 3.45s\tremaining: 15.1s\n",
      "93:\tlearn: 0.4430917\ttotal: 3.52s\tremaining: 15.2s\n",
      "94:\tlearn: 0.4412369\ttotal: 3.57s\tremaining: 15.2s\n",
      "95:\tlearn: 0.4392613\ttotal: 3.61s\tremaining: 15.2s\n",
      "96:\tlearn: 0.4377889\ttotal: 3.63s\tremaining: 15.1s\n",
      "97:\tlearn: 0.4355927\ttotal: 3.65s\tremaining: 15s\n",
      "98:\tlearn: 0.4338140\ttotal: 3.72s\tremaining: 15.1s\n",
      "99:\tlearn: 0.4312749\ttotal: 3.77s\tremaining: 15.1s\n",
      "100:\tlearn: 0.4294563\ttotal: 3.79s\tremaining: 15s\n",
      "101:\tlearn: 0.4279784\ttotal: 3.81s\tremaining: 14.9s\n",
      "102:\tlearn: 0.4259462\ttotal: 3.86s\tremaining: 14.9s\n",
      "103:\tlearn: 0.4242364\ttotal: 3.93s\tremaining: 15s\n",
      "104:\tlearn: 0.4227295\ttotal: 3.96s\tremaining: 14.9s\n",
      "105:\tlearn: 0.4211903\ttotal: 3.98s\tremaining: 14.8s\n",
      "106:\tlearn: 0.4192169\ttotal: 4s\tremaining: 14.7s\n",
      "107:\tlearn: 0.4172314\ttotal: 4.07s\tremaining: 14.8s\n",
      "108:\tlearn: 0.4151206\ttotal: 4.12s\tremaining: 14.8s\n",
      "109:\tlearn: 0.4132622\ttotal: 4.15s\tremaining: 14.7s\n",
      "110:\tlearn: 0.4114128\ttotal: 4.17s\tremaining: 14.6s\n",
      "111:\tlearn: 0.4099284\ttotal: 4.19s\tremaining: 14.5s\n",
      "112:\tlearn: 0.4084531\ttotal: 4.26s\tremaining: 14.6s\n",
      "113:\tlearn: 0.4066414\ttotal: 4.3s\tremaining: 14.6s\n",
      "114:\tlearn: 0.4049655\ttotal: 4.32s\tremaining: 14.5s\n",
      "115:\tlearn: 0.4032624\ttotal: 4.34s\tremaining: 14.4s\n",
      "116:\tlearn: 0.4017457\ttotal: 4.37s\tremaining: 14.3s\n",
      "117:\tlearn: 0.4000450\ttotal: 4.44s\tremaining: 14.4s\n",
      "118:\tlearn: 0.3982966\ttotal: 4.48s\tremaining: 14.3s\n",
      "119:\tlearn: 0.3971104\ttotal: 4.5s\tremaining: 14.3s\n",
      "120:\tlearn: 0.3954984\ttotal: 4.52s\tremaining: 14.2s\n",
      "121:\tlearn: 0.3944920\ttotal: 4.56s\tremaining: 14.1s\n",
      "122:\tlearn: 0.3930987\ttotal: 4.63s\tremaining: 14.2s\n",
      "123:\tlearn: 0.3912428\ttotal: 4.66s\tremaining: 14.1s\n",
      "124:\tlearn: 0.3902425\ttotal: 4.69s\tremaining: 14.1s\n",
      "125:\tlearn: 0.3884180\ttotal: 4.71s\tremaining: 14s\n",
      "126:\tlearn: 0.3872892\ttotal: 4.78s\tremaining: 14s\n",
      "127:\tlearn: 0.3859751\ttotal: 4.82s\tremaining: 14s\n",
      "128:\tlearn: 0.3838691\ttotal: 4.85s\tremaining: 13.9s\n",
      "129:\tlearn: 0.3824758\ttotal: 4.87s\tremaining: 13.9s\n",
      "130:\tlearn: 0.3807318\ttotal: 4.9s\tremaining: 13.8s\n",
      "131:\tlearn: 0.3791225\ttotal: 4.92s\tremaining: 13.7s\n",
      "132:\tlearn: 0.3771358\ttotal: 4.97s\tremaining: 13.7s\n",
      "133:\tlearn: 0.3756061\ttotal: 5.03s\tremaining: 13.7s\n",
      "134:\tlearn: 0.3744623\ttotal: 5.06s\tremaining: 13.7s\n",
      "135:\tlearn: 0.3728397\ttotal: 5.08s\tremaining: 13.6s\n",
      "136:\tlearn: 0.3715312\ttotal: 5.11s\tremaining: 13.5s\n",
      "137:\tlearn: 0.3702845\ttotal: 5.18s\tremaining: 13.6s\n",
      "138:\tlearn: 0.3690960\ttotal: 5.22s\tremaining: 13.6s\n",
      "139:\tlearn: 0.3676848\ttotal: 5.25s\tremaining: 13.5s\n",
      "140:\tlearn: 0.3666923\ttotal: 5.27s\tremaining: 13.4s\n",
      "141:\tlearn: 0.3648430\ttotal: 5.31s\tremaining: 13.4s\n",
      "142:\tlearn: 0.3630289\ttotal: 5.38s\tremaining: 13.4s\n",
      "143:\tlearn: 0.3617541\ttotal: 5.41s\tremaining: 13.4s\n",
      "144:\tlearn: 0.3604459\ttotal: 5.43s\tremaining: 13.3s\n",
      "145:\tlearn: 0.3591461\ttotal: 5.45s\tremaining: 13.2s\n",
      "146:\tlearn: 0.3580222\ttotal: 5.52s\tremaining: 13.3s\n",
      "147:\tlearn: 0.3566695\ttotal: 5.59s\tremaining: 13.3s\n",
      "148:\tlearn: 0.3552533\ttotal: 5.64s\tremaining: 13.3s\n",
      "149:\tlearn: 0.3536907\ttotal: 5.67s\tremaining: 13.2s\n",
      "150:\tlearn: 0.3522016\ttotal: 5.69s\tremaining: 13.2s\n",
      "151:\tlearn: 0.3509992\ttotal: 5.77s\tremaining: 13.2s\n",
      "152:\tlearn: 0.3495096\ttotal: 5.79s\tremaining: 13.1s\n",
      "153:\tlearn: 0.3471795\ttotal: 5.82s\tremaining: 13.1s\n",
      "154:\tlearn: 0.3459636\ttotal: 5.84s\tremaining: 13s\n",
      "155:\tlearn: 0.3443406\ttotal: 5.91s\tremaining: 13s\n",
      "156:\tlearn: 0.3431616\ttotal: 5.95s\tremaining: 13s\n",
      "157:\tlearn: 0.3416389\ttotal: 5.97s\tremaining: 12.9s\n",
      "158:\tlearn: 0.3406017\ttotal: 5.99s\tremaining: 12.9s\n",
      "159:\tlearn: 0.3383875\ttotal: 6.01s\tremaining: 12.8s\n",
      "160:\tlearn: 0.3373992\ttotal: 6.09s\tremaining: 12.8s\n",
      "161:\tlearn: 0.3352138\ttotal: 6.14s\tremaining: 12.8s\n",
      "162:\tlearn: 0.3341452\ttotal: 6.16s\tremaining: 12.7s\n",
      "163:\tlearn: 0.3330961\ttotal: 6.18s\tremaining: 12.7s\n",
      "164:\tlearn: 0.3318080\ttotal: 6.22s\tremaining: 12.6s\n",
      "165:\tlearn: 0.3305670\ttotal: 6.29s\tremaining: 12.6s\n",
      "166:\tlearn: 0.3288814\ttotal: 6.32s\tremaining: 12.6s\n",
      "167:\tlearn: 0.3279496\ttotal: 6.34s\tremaining: 12.5s\n",
      "168:\tlearn: 0.3258140\ttotal: 6.38s\tremaining: 12.5s\n",
      "169:\tlearn: 0.3246310\ttotal: 6.45s\tremaining: 12.5s\n",
      "170:\tlearn: 0.3228795\ttotal: 6.49s\tremaining: 12.5s\n",
      "171:\tlearn: 0.3217832\ttotal: 6.51s\tremaining: 12.4s\n",
      "172:\tlearn: 0.3207878\ttotal: 6.53s\tremaining: 12.3s\n",
      "173:\tlearn: 0.3196653\ttotal: 6.6s\tremaining: 12.4s\n",
      "174:\tlearn: 0.3186814\ttotal: 6.63s\tremaining: 12.3s\n",
      "175:\tlearn: 0.3175064\ttotal: 6.65s\tremaining: 12.2s\n",
      "176:\tlearn: 0.3166418\ttotal: 6.68s\tremaining: 12.2s\n",
      "177:\tlearn: 0.3156152\ttotal: 6.75s\tremaining: 12.2s\n",
      "178:\tlearn: 0.3144665\ttotal: 6.78s\tremaining: 12.2s\n",
      "179:\tlearn: 0.3130801\ttotal: 6.81s\tremaining: 12.1s\n",
      "180:\tlearn: 0.3118151\ttotal: 6.83s\tremaining: 12s\n",
      "181:\tlearn: 0.3104126\ttotal: 6.88s\tremaining: 12s\n",
      "182:\tlearn: 0.3093074\ttotal: 6.95s\tremaining: 12s\n",
      "183:\tlearn: 0.3082836\ttotal: 6.97s\tremaining: 12s\n",
      "184:\tlearn: 0.3065983\ttotal: 7s\tremaining: 11.9s\n",
      "185:\tlearn: 0.3053082\ttotal: 7.02s\tremaining: 11.8s\n",
      "186:\tlearn: 0.3046790\ttotal: 7.09s\tremaining: 11.9s\n",
      "187:\tlearn: 0.3035699\ttotal: 7.13s\tremaining: 11.8s\n",
      "188:\tlearn: 0.3026003\ttotal: 7.16s\tremaining: 11.8s\n",
      "189:\tlearn: 0.3014471\ttotal: 7.18s\tremaining: 11.7s\n",
      "190:\tlearn: 0.3003323\ttotal: 7.2s\tremaining: 11.7s\n",
      "191:\tlearn: 0.2987910\ttotal: 7.27s\tremaining: 11.7s\n",
      "192:\tlearn: 0.2978281\ttotal: 7.31s\tremaining: 11.6s\n",
      "193:\tlearn: 0.2968301\ttotal: 7.33s\tremaining: 11.6s\n",
      "194:\tlearn: 0.2958333\ttotal: 7.36s\tremaining: 11.5s\n",
      "195:\tlearn: 0.2947854\ttotal: 7.39s\tremaining: 11.5s\n",
      "196:\tlearn: 0.2939326\ttotal: 7.46s\tremaining: 11.5s\n",
      "197:\tlearn: 0.2928126\ttotal: 7.49s\tremaining: 11.4s\n",
      "198:\tlearn: 0.2916901\ttotal: 7.52s\tremaining: 11.4s\n",
      "199:\tlearn: 0.2908457\ttotal: 7.54s\tremaining: 11.3s\n",
      "200:\tlearn: 0.2896876\ttotal: 7.56s\tremaining: 11.3s\n",
      "201:\tlearn: 0.2887122\ttotal: 7.63s\tremaining: 11.3s\n",
      "202:\tlearn: 0.2878644\ttotal: 7.68s\tremaining: 11.2s\n",
      "203:\tlearn: 0.2870182\ttotal: 7.71s\tremaining: 11.2s\n",
      "204:\tlearn: 0.2860935\ttotal: 7.73s\tremaining: 11.1s\n",
      "205:\tlearn: 0.2848352\ttotal: 7.8s\tremaining: 11.1s\n",
      "206:\tlearn: 0.2838667\ttotal: 7.85s\tremaining: 11.1s\n",
      "207:\tlearn: 0.2829571\ttotal: 7.88s\tremaining: 11.1s\n",
      "208:\tlearn: 0.2823202\ttotal: 7.9s\tremaining: 11s\n",
      "209:\tlearn: 0.2815131\ttotal: 7.92s\tremaining: 10.9s\n",
      "210:\tlearn: 0.2798958\ttotal: 7.97s\tremaining: 10.9s\n",
      "211:\tlearn: 0.2790922\ttotal: 8.03s\tremaining: 10.9s\n",
      "212:\tlearn: 0.2783686\ttotal: 8.06s\tremaining: 10.9s\n",
      "213:\tlearn: 0.2776286\ttotal: 8.08s\tremaining: 10.8s\n",
      "214:\tlearn: 0.2765469\ttotal: 8.1s\tremaining: 10.7s\n",
      "215:\tlearn: 0.2753902\ttotal: 8.17s\tremaining: 10.7s\n",
      "216:\tlearn: 0.2746565\ttotal: 8.2s\tremaining: 10.7s\n",
      "217:\tlearn: 0.2737658\ttotal: 8.22s\tremaining: 10.6s\n",
      "218:\tlearn: 0.2729026\ttotal: 8.27s\tremaining: 10.6s\n",
      "219:\tlearn: 0.2722468\ttotal: 8.34s\tremaining: 10.6s\n",
      "220:\tlearn: 0.2703562\ttotal: 8.36s\tremaining: 10.6s\n",
      "221:\tlearn: 0.2692877\ttotal: 8.38s\tremaining: 10.5s\n",
      "222:\tlearn: 0.2681171\ttotal: 8.45s\tremaining: 10.5s\n",
      "223:\tlearn: 0.2671448\ttotal: 8.49s\tremaining: 10.5s\n",
      "224:\tlearn: 0.2662341\ttotal: 8.51s\tremaining: 10.4s\n",
      "225:\tlearn: 0.2652849\ttotal: 8.59s\tremaining: 10.4s\n",
      "226:\tlearn: 0.2645254\ttotal: 8.63s\tremaining: 10.4s\n",
      "227:\tlearn: 0.2637844\ttotal: 8.67s\tremaining: 10.3s\n",
      "228:\tlearn: 0.2629460\ttotal: 8.72s\tremaining: 10.3s\n",
      "229:\tlearn: 0.2622486\ttotal: 8.78s\tremaining: 10.3s\n",
      "230:\tlearn: 0.2610216\ttotal: 8.81s\tremaining: 10.3s\n",
      "231:\tlearn: 0.2602556\ttotal: 8.89s\tremaining: 10.3s\n",
      "232:\tlearn: 0.2589328\ttotal: 8.91s\tremaining: 10.2s\n",
      "233:\tlearn: 0.2582498\ttotal: 8.99s\tremaining: 10.2s\n",
      "234:\tlearn: 0.2571828\ttotal: 9.02s\tremaining: 10.2s\n",
      "235:\tlearn: 0.2563343\ttotal: 9.05s\tremaining: 10.1s\n",
      "236:\tlearn: 0.2556061\ttotal: 9.07s\tremaining: 10.1s\n",
      "237:\tlearn: 0.2550672\ttotal: 9.14s\tremaining: 10.1s\n",
      "238:\tlearn: 0.2541375\ttotal: 9.18s\tremaining: 10s\n",
      "239:\tlearn: 0.2531442\ttotal: 9.2s\tremaining: 9.96s\n",
      "240:\tlearn: 0.2523152\ttotal: 9.22s\tremaining: 9.9s\n",
      "241:\tlearn: 0.2513661\ttotal: 9.24s\tremaining: 9.85s\n",
      "242:\tlearn: 0.2507505\ttotal: 9.27s\tremaining: 9.8s\n",
      "243:\tlearn: 0.2500972\ttotal: 9.29s\tremaining: 9.75s\n",
      "244:\tlearn: 0.2495735\ttotal: 9.32s\tremaining: 9.7s\n",
      "245:\tlearn: 0.2488853\ttotal: 9.35s\tremaining: 9.65s\n",
      "246:\tlearn: 0.2482226\ttotal: 9.37s\tremaining: 9.6s\n",
      "247:\tlearn: 0.2472010\ttotal: 9.42s\tremaining: 9.57s\n",
      "248:\tlearn: 0.2464139\ttotal: 9.48s\tremaining: 9.56s\n",
      "249:\tlearn: 0.2452849\ttotal: 9.51s\tremaining: 9.51s\n",
      "250:\tlearn: 0.2442493\ttotal: 9.53s\tremaining: 9.46s\n",
      "251:\tlearn: 0.2431213\ttotal: 9.57s\tremaining: 9.41s\n",
      "252:\tlearn: 0.2421542\ttotal: 9.63s\tremaining: 9.4s\n",
      "253:\tlearn: 0.2408703\ttotal: 9.67s\tremaining: 9.36s\n",
      "254:\tlearn: 0.2398807\ttotal: 9.69s\tremaining: 9.31s\n",
      "255:\tlearn: 0.2391117\ttotal: 9.71s\tremaining: 9.26s\n",
      "256:\tlearn: 0.2385783\ttotal: 9.79s\tremaining: 9.25s\n",
      "257:\tlearn: 0.2377595\ttotal: 9.83s\tremaining: 9.22s\n",
      "258:\tlearn: 0.2370947\ttotal: 9.86s\tremaining: 9.17s\n",
      "259:\tlearn: 0.2362640\ttotal: 9.9s\tremaining: 9.14s\n",
      "260:\tlearn: 0.2354190\ttotal: 9.94s\tremaining: 9.11s\n",
      "261:\tlearn: 0.2340510\ttotal: 10s\tremaining: 9.1s\n",
      "262:\tlearn: 0.2334505\ttotal: 10s\tremaining: 9.04s\n",
      "263:\tlearn: 0.2326544\ttotal: 10.1s\tremaining: 9.03s\n",
      "264:\tlearn: 0.2319110\ttotal: 10.2s\tremaining: 9s\n",
      "265:\tlearn: 0.2309261\ttotal: 10.2s\tremaining: 8.95s\n",
      "266:\tlearn: 0.2301476\ttotal: 10.2s\tremaining: 8.9s\n",
      "267:\tlearn: 0.2291930\ttotal: 10.3s\tremaining: 8.89s\n",
      "268:\tlearn: 0.2286054\ttotal: 10.3s\tremaining: 8.85s\n",
      "269:\tlearn: 0.2279723\ttotal: 10.3s\tremaining: 8.8s\n",
      "270:\tlearn: 0.2272334\ttotal: 10.4s\tremaining: 8.75s\n",
      "271:\tlearn: 0.2265548\ttotal: 10.4s\tremaining: 8.73s\n",
      "272:\tlearn: 0.2260416\ttotal: 10.5s\tremaining: 8.71s\n",
      "273:\tlearn: 0.2253036\ttotal: 10.5s\tremaining: 8.66s\n",
      "274:\tlearn: 0.2247712\ttotal: 10.5s\tremaining: 8.61s\n",
      "275:\tlearn: 0.2242455\ttotal: 10.6s\tremaining: 8.57s\n",
      "276:\tlearn: 0.2233456\ttotal: 10.6s\tremaining: 8.53s\n",
      "277:\tlearn: 0.2225734\ttotal: 10.7s\tremaining: 8.53s\n",
      "278:\tlearn: 0.2216246\ttotal: 10.7s\tremaining: 8.48s\n",
      "279:\tlearn: 0.2208841\ttotal: 10.8s\tremaining: 8.46s\n",
      "280:\tlearn: 0.2200926\ttotal: 10.8s\tremaining: 8.43s\n",
      "281:\tlearn: 0.2190688\ttotal: 10.8s\tremaining: 8.38s\n",
      "282:\tlearn: 0.2185014\ttotal: 10.9s\tremaining: 8.37s\n",
      "283:\tlearn: 0.2177803\ttotal: 10.9s\tremaining: 8.33s\n",
      "284:\tlearn: 0.2169603\ttotal: 11s\tremaining: 8.28s\n",
      "285:\tlearn: 0.2163549\ttotal: 11s\tremaining: 8.24s\n",
      "286:\tlearn: 0.2151501\ttotal: 11.1s\tremaining: 8.23s\n",
      "287:\tlearn: 0.2144914\ttotal: 11.1s\tremaining: 8.19s\n",
      "288:\tlearn: 0.2136420\ttotal: 11.1s\tremaining: 8.14s\n",
      "289:\tlearn: 0.2128687\ttotal: 11.2s\tremaining: 8.09s\n",
      "290:\tlearn: 0.2124172\ttotal: 11.2s\tremaining: 8.07s\n",
      "291:\tlearn: 0.2118167\ttotal: 11.3s\tremaining: 8.04s\n",
      "292:\tlearn: 0.2113057\ttotal: 11.3s\tremaining: 7.99s\n",
      "293:\tlearn: 0.2101876\ttotal: 11.3s\tremaining: 7.94s\n",
      "294:\tlearn: 0.2094393\ttotal: 11.3s\tremaining: 7.89s\n",
      "295:\tlearn: 0.2082965\ttotal: 11.4s\tremaining: 7.87s\n",
      "296:\tlearn: 0.2074018\ttotal: 11.5s\tremaining: 7.84s\n",
      "297:\tlearn: 0.2067355\ttotal: 11.5s\tremaining: 7.79s\n",
      "298:\tlearn: 0.2060077\ttotal: 11.5s\tremaining: 7.74s\n",
      "299:\tlearn: 0.2048641\ttotal: 11.6s\tremaining: 7.72s\n",
      "300:\tlearn: 0.2041623\ttotal: 11.6s\tremaining: 7.68s\n",
      "301:\tlearn: 0.2034996\ttotal: 11.6s\tremaining: 7.63s\n",
      "302:\tlearn: 0.2028054\ttotal: 11.7s\tremaining: 7.58s\n",
      "303:\tlearn: 0.2019437\ttotal: 11.7s\tremaining: 7.56s\n",
      "304:\tlearn: 0.2010614\ttotal: 11.8s\tremaining: 7.53s\n",
      "305:\tlearn: 0.2003945\ttotal: 11.8s\tremaining: 7.49s\n",
      "306:\tlearn: 0.1997214\ttotal: 11.8s\tremaining: 7.44s\n",
      "307:\tlearn: 0.1989722\ttotal: 11.9s\tremaining: 7.4s\n",
      "308:\tlearn: 0.1984502\ttotal: 11.9s\tremaining: 7.38s\n",
      "309:\tlearn: 0.1979562\ttotal: 12s\tremaining: 7.34s\n",
      "310:\tlearn: 0.1974071\ttotal: 12s\tremaining: 7.29s\n",
      "311:\tlearn: 0.1961455\ttotal: 12s\tremaining: 7.24s\n",
      "312:\tlearn: 0.1958083\ttotal: 12.1s\tremaining: 7.22s\n",
      "313:\tlearn: 0.1951842\ttotal: 12.1s\tremaining: 7.19s\n",
      "314:\tlearn: 0.1944335\ttotal: 12.2s\tremaining: 7.14s\n",
      "315:\tlearn: 0.1939772\ttotal: 12.2s\tremaining: 7.09s\n",
      "316:\tlearn: 0.1933043\ttotal: 12.2s\tremaining: 7.07s\n",
      "317:\tlearn: 0.1927225\ttotal: 12.3s\tremaining: 7.04s\n",
      "318:\tlearn: 0.1920783\ttotal: 12.3s\tremaining: 7s\n",
      "319:\tlearn: 0.1916900\ttotal: 12.4s\tremaining: 6.95s\n",
      "320:\tlearn: 0.1908956\ttotal: 12.4s\tremaining: 6.9s\n",
      "321:\tlearn: 0.1901843\ttotal: 12.4s\tremaining: 6.88s\n",
      "322:\tlearn: 0.1896761\ttotal: 12.5s\tremaining: 6.84s\n",
      "323:\tlearn: 0.1891606\ttotal: 12.5s\tremaining: 6.8s\n",
      "324:\tlearn: 0.1884806\ttotal: 12.5s\tremaining: 6.75s\n",
      "325:\tlearn: 0.1878253\ttotal: 12.6s\tremaining: 6.72s\n",
      "326:\tlearn: 0.1869312\ttotal: 12.7s\tremaining: 6.7s\n",
      "327:\tlearn: 0.1859409\ttotal: 12.7s\tremaining: 6.65s\n",
      "328:\tlearn: 0.1854459\ttotal: 12.7s\tremaining: 6.6s\n",
      "329:\tlearn: 0.1849196\ttotal: 12.7s\tremaining: 6.56s\n",
      "330:\tlearn: 0.1844997\ttotal: 12.8s\tremaining: 6.53s\n",
      "331:\tlearn: 0.1839706\ttotal: 12.8s\tremaining: 6.5s\n",
      "332:\tlearn: 0.1833238\ttotal: 12.9s\tremaining: 6.45s\n",
      "333:\tlearn: 0.1828335\ttotal: 12.9s\tremaining: 6.41s\n",
      "334:\tlearn: 0.1823926\ttotal: 12.9s\tremaining: 6.36s\n",
      "335:\tlearn: 0.1817109\ttotal: 13s\tremaining: 6.34s\n",
      "336:\tlearn: 0.1808713\ttotal: 13s\tremaining: 6.3s\n",
      "337:\tlearn: 0.1802382\ttotal: 13.1s\tremaining: 6.26s\n",
      "338:\tlearn: 0.1796366\ttotal: 13.1s\tremaining: 6.21s\n",
      "339:\tlearn: 0.1789736\ttotal: 13.1s\tremaining: 6.17s\n",
      "340:\tlearn: 0.1784775\ttotal: 13.2s\tremaining: 6.15s\n",
      "341:\tlearn: 0.1779111\ttotal: 13.2s\tremaining: 6.11s\n",
      "342:\tlearn: 0.1774258\ttotal: 13.2s\tremaining: 6.06s\n",
      "343:\tlearn: 0.1768844\ttotal: 13.3s\tremaining: 6.01s\n",
      "344:\tlearn: 0.1764125\ttotal: 13.3s\tremaining: 5.98s\n",
      "345:\tlearn: 0.1760571\ttotal: 13.4s\tremaining: 5.95s\n",
      "346:\tlearn: 0.1756235\ttotal: 13.4s\tremaining: 5.91s\n",
      "347:\tlearn: 0.1749247\ttotal: 13.4s\tremaining: 5.86s\n",
      "348:\tlearn: 0.1743026\ttotal: 13.4s\tremaining: 5.82s\n",
      "349:\tlearn: 0.1735428\ttotal: 13.5s\tremaining: 5.79s\n",
      "350:\tlearn: 0.1730349\ttotal: 13.5s\tremaining: 5.75s\n",
      "351:\tlearn: 0.1724410\ttotal: 13.6s\tremaining: 5.7s\n",
      "352:\tlearn: 0.1720377\ttotal: 13.6s\tremaining: 5.66s\n",
      "353:\tlearn: 0.1715530\ttotal: 13.7s\tremaining: 5.63s\n",
      "354:\tlearn: 0.1711644\ttotal: 13.7s\tremaining: 5.6s\n",
      "355:\tlearn: 0.1703163\ttotal: 13.7s\tremaining: 5.55s\n",
      "356:\tlearn: 0.1698565\ttotal: 13.8s\tremaining: 5.51s\n",
      "357:\tlearn: 0.1692582\ttotal: 13.8s\tremaining: 5.47s\n",
      "358:\tlearn: 0.1686594\ttotal: 13.9s\tremaining: 5.45s\n",
      "359:\tlearn: 0.1679386\ttotal: 13.9s\tremaining: 5.4s\n",
      "360:\tlearn: 0.1674320\ttotal: 13.9s\tremaining: 5.36s\n",
      "361:\tlearn: 0.1668291\ttotal: 13.9s\tremaining: 5.32s\n",
      "362:\tlearn: 0.1664187\ttotal: 14s\tremaining: 5.29s\n",
      "363:\tlearn: 0.1660514\ttotal: 14.1s\tremaining: 5.25s\n",
      "364:\tlearn: 0.1655454\ttotal: 14.1s\tremaining: 5.21s\n",
      "365:\tlearn: 0.1651399\ttotal: 14.1s\tremaining: 5.17s\n",
      "366:\tlearn: 0.1643956\ttotal: 14.1s\tremaining: 5.12s\n",
      "367:\tlearn: 0.1639486\ttotal: 14.2s\tremaining: 5.09s\n",
      "368:\tlearn: 0.1634032\ttotal: 14.2s\tremaining: 5.05s\n",
      "369:\tlearn: 0.1628407\ttotal: 14.2s\tremaining: 5s\n",
      "370:\tlearn: 0.1623826\ttotal: 14.3s\tremaining: 4.96s\n",
      "371:\tlearn: 0.1617850\ttotal: 14.3s\tremaining: 4.93s\n",
      "372:\tlearn: 0.1613837\ttotal: 14.4s\tremaining: 4.89s\n",
      "373:\tlearn: 0.1608633\ttotal: 14.4s\tremaining: 4.85s\n",
      "374:\tlearn: 0.1605205\ttotal: 14.4s\tremaining: 4.81s\n",
      "375:\tlearn: 0.1598257\ttotal: 14.5s\tremaining: 4.78s\n",
      "376:\tlearn: 0.1593242\ttotal: 14.5s\tremaining: 4.74s\n",
      "377:\tlearn: 0.1587801\ttotal: 14.6s\tremaining: 4.7s\n",
      "378:\tlearn: 0.1583382\ttotal: 14.6s\tremaining: 4.66s\n",
      "379:\tlearn: 0.1579366\ttotal: 14.7s\tremaining: 4.63s\n",
      "380:\tlearn: 0.1575240\ttotal: 14.7s\tremaining: 4.59s\n",
      "381:\tlearn: 0.1569885\ttotal: 14.7s\tremaining: 4.55s\n",
      "382:\tlearn: 0.1565489\ttotal: 14.8s\tremaining: 4.51s\n",
      "383:\tlearn: 0.1560683\ttotal: 14.8s\tremaining: 4.47s\n",
      "384:\tlearn: 0.1556666\ttotal: 14.9s\tremaining: 4.44s\n",
      "385:\tlearn: 0.1552751\ttotal: 14.9s\tremaining: 4.4s\n",
      "386:\tlearn: 0.1547748\ttotal: 14.9s\tremaining: 4.36s\n",
      "387:\tlearn: 0.1543494\ttotal: 14.9s\tremaining: 4.31s\n",
      "388:\tlearn: 0.1536661\ttotal: 15s\tremaining: 4.29s\n",
      "389:\tlearn: 0.1530411\ttotal: 15.1s\tremaining: 4.25s\n",
      "390:\tlearn: 0.1528537\ttotal: 15.1s\tremaining: 4.2s\n",
      "391:\tlearn: 0.1525676\ttotal: 15.1s\tremaining: 4.17s\n",
      "392:\tlearn: 0.1520386\ttotal: 15.2s\tremaining: 4.13s\n",
      "393:\tlearn: 0.1515055\ttotal: 15.2s\tremaining: 4.09s\n",
      "394:\tlearn: 0.1511267\ttotal: 15.2s\tremaining: 4.05s\n",
      "395:\tlearn: 0.1506283\ttotal: 15.3s\tremaining: 4.01s\n",
      "396:\tlearn: 0.1501600\ttotal: 15.3s\tremaining: 3.96s\n",
      "397:\tlearn: 0.1497303\ttotal: 15.4s\tremaining: 3.94s\n",
      "398:\tlearn: 0.1491075\ttotal: 15.4s\tremaining: 3.89s\n",
      "399:\tlearn: 0.1486545\ttotal: 15.4s\tremaining: 3.85s\n",
      "400:\tlearn: 0.1481692\ttotal: 15.4s\tremaining: 3.81s\n",
      "401:\tlearn: 0.1474998\ttotal: 15.5s\tremaining: 3.78s\n",
      "402:\tlearn: 0.1472044\ttotal: 15.5s\tremaining: 3.74s\n",
      "403:\tlearn: 0.1467343\ttotal: 15.6s\tremaining: 3.7s\n",
      "404:\tlearn: 0.1461988\ttotal: 15.6s\tremaining: 3.65s\n",
      "405:\tlearn: 0.1457010\ttotal: 15.6s\tremaining: 3.62s\n",
      "406:\tlearn: 0.1453676\ttotal: 15.7s\tremaining: 3.59s\n",
      "407:\tlearn: 0.1449879\ttotal: 15.8s\tremaining: 3.56s\n",
      "408:\tlearn: 0.1445104\ttotal: 15.8s\tremaining: 3.52s\n",
      "409:\tlearn: 0.1440384\ttotal: 15.8s\tremaining: 3.48s\n",
      "410:\tlearn: 0.1436399\ttotal: 15.9s\tremaining: 3.44s\n",
      "411:\tlearn: 0.1432142\ttotal: 15.9s\tremaining: 3.4s\n",
      "412:\tlearn: 0.1428403\ttotal: 16s\tremaining: 3.36s\n",
      "413:\tlearn: 0.1423921\ttotal: 16s\tremaining: 3.33s\n",
      "414:\tlearn: 0.1419057\ttotal: 16.1s\tremaining: 3.3s\n",
      "415:\tlearn: 0.1414123\ttotal: 16.1s\tremaining: 3.25s\n",
      "416:\tlearn: 0.1409288\ttotal: 16.2s\tremaining: 3.22s\n",
      "417:\tlearn: 0.1404018\ttotal: 16.2s\tremaining: 3.18s\n",
      "418:\tlearn: 0.1399431\ttotal: 16.2s\tremaining: 3.14s\n",
      "419:\tlearn: 0.1396768\ttotal: 16.3s\tremaining: 3.1s\n",
      "420:\tlearn: 0.1393026\ttotal: 16.4s\tremaining: 3.07s\n",
      "421:\tlearn: 0.1389195\ttotal: 16.4s\tremaining: 3.03s\n",
      "422:\tlearn: 0.1383939\ttotal: 16.4s\tremaining: 2.99s\n",
      "423:\tlearn: 0.1376640\ttotal: 16.5s\tremaining: 2.95s\n",
      "424:\tlearn: 0.1373121\ttotal: 16.5s\tremaining: 2.92s\n",
      "425:\tlearn: 0.1367383\ttotal: 16.6s\tremaining: 2.88s\n",
      "426:\tlearn: 0.1362078\ttotal: 16.6s\tremaining: 2.83s\n",
      "427:\tlearn: 0.1356544\ttotal: 16.6s\tremaining: 2.8s\n",
      "428:\tlearn: 0.1352772\ttotal: 16.7s\tremaining: 2.76s\n",
      "429:\tlearn: 0.1347304\ttotal: 16.7s\tremaining: 2.72s\n",
      "430:\tlearn: 0.1343158\ttotal: 16.7s\tremaining: 2.68s\n",
      "431:\tlearn: 0.1338834\ttotal: 16.8s\tremaining: 2.64s\n",
      "432:\tlearn: 0.1335898\ttotal: 16.8s\tremaining: 2.61s\n",
      "433:\tlearn: 0.1332132\ttotal: 16.9s\tremaining: 2.57s\n",
      "434:\tlearn: 0.1328735\ttotal: 16.9s\tremaining: 2.52s\n",
      "435:\tlearn: 0.1323830\ttotal: 16.9s\tremaining: 2.48s\n",
      "436:\tlearn: 0.1319984\ttotal: 17s\tremaining: 2.45s\n",
      "437:\tlearn: 0.1316478\ttotal: 17s\tremaining: 2.41s\n",
      "438:\tlearn: 0.1313346\ttotal: 17.1s\tremaining: 2.37s\n",
      "439:\tlearn: 0.1309053\ttotal: 17.1s\tremaining: 2.34s\n",
      "440:\tlearn: 0.1305175\ttotal: 17.2s\tremaining: 2.3s\n",
      "441:\tlearn: 0.1301925\ttotal: 17.2s\tremaining: 2.26s\n",
      "442:\tlearn: 0.1298743\ttotal: 17.2s\tremaining: 2.22s\n",
      "443:\tlearn: 0.1295675\ttotal: 17.3s\tremaining: 2.18s\n",
      "444:\tlearn: 0.1291047\ttotal: 17.3s\tremaining: 2.14s\n",
      "445:\tlearn: 0.1287696\ttotal: 17.4s\tremaining: 2.1s\n",
      "446:\tlearn: 0.1282861\ttotal: 17.4s\tremaining: 2.07s\n",
      "447:\tlearn: 0.1278508\ttotal: 17.5s\tremaining: 2.03s\n",
      "448:\tlearn: 0.1274069\ttotal: 17.5s\tremaining: 1.99s\n",
      "449:\tlearn: 0.1270434\ttotal: 17.5s\tremaining: 1.95s\n",
      "450:\tlearn: 0.1267167\ttotal: 17.6s\tremaining: 1.91s\n",
      "451:\tlearn: 0.1263524\ttotal: 17.6s\tremaining: 1.87s\n",
      "452:\tlearn: 0.1260508\ttotal: 17.7s\tremaining: 1.83s\n",
      "453:\tlearn: 0.1255719\ttotal: 17.7s\tremaining: 1.79s\n",
      "454:\tlearn: 0.1252186\ttotal: 17.8s\tremaining: 1.76s\n",
      "455:\tlearn: 0.1248147\ttotal: 17.8s\tremaining: 1.72s\n",
      "456:\tlearn: 0.1241078\ttotal: 17.8s\tremaining: 1.68s\n",
      "457:\tlearn: 0.1236712\ttotal: 17.8s\tremaining: 1.64s\n",
      "458:\tlearn: 0.1233456\ttotal: 17.9s\tremaining: 1.6s\n",
      "459:\tlearn: 0.1229004\ttotal: 18s\tremaining: 1.56s\n",
      "460:\tlearn: 0.1226552\ttotal: 18s\tremaining: 1.52s\n",
      "461:\tlearn: 0.1221884\ttotal: 18s\tremaining: 1.48s\n",
      "462:\tlearn: 0.1218532\ttotal: 18s\tremaining: 1.44s\n",
      "463:\tlearn: 0.1216474\ttotal: 18.1s\tremaining: 1.4s\n",
      "464:\tlearn: 0.1213303\ttotal: 18.1s\tremaining: 1.36s\n",
      "465:\tlearn: 0.1207741\ttotal: 18.2s\tremaining: 1.32s\n",
      "466:\tlearn: 0.1205635\ttotal: 18.2s\tremaining: 1.28s\n",
      "467:\tlearn: 0.1203776\ttotal: 18.2s\tremaining: 1.25s\n",
      "468:\tlearn: 0.1198981\ttotal: 18.3s\tremaining: 1.21s\n",
      "469:\tlearn: 0.1195057\ttotal: 18.3s\tremaining: 1.17s\n",
      "470:\tlearn: 0.1191902\ttotal: 18.4s\tremaining: 1.13s\n",
      "471:\tlearn: 0.1188794\ttotal: 18.4s\tremaining: 1.09s\n",
      "472:\tlearn: 0.1186087\ttotal: 18.4s\tremaining: 1.05s\n",
      "473:\tlearn: 0.1183766\ttotal: 18.5s\tremaining: 1.01s\n",
      "474:\tlearn: 0.1180660\ttotal: 18.5s\tremaining: 975ms\n",
      "475:\tlearn: 0.1175991\ttotal: 18.5s\tremaining: 935ms\n",
      "476:\tlearn: 0.1173528\ttotal: 18.6s\tremaining: 895ms\n",
      "477:\tlearn: 0.1170157\ttotal: 18.6s\tremaining: 856ms\n",
      "478:\tlearn: 0.1166414\ttotal: 18.7s\tremaining: 819ms\n",
      "479:\tlearn: 0.1163555\ttotal: 18.7s\tremaining: 779ms\n",
      "480:\tlearn: 0.1160519\ttotal: 18.7s\tremaining: 740ms\n",
      "481:\tlearn: 0.1155134\ttotal: 18.8s\tremaining: 700ms\n",
      "482:\tlearn: 0.1151991\ttotal: 18.8s\tremaining: 663ms\n",
      "483:\tlearn: 0.1145876\ttotal: 18.9s\tremaining: 624ms\n",
      "484:\tlearn: 0.1142331\ttotal: 18.9s\tremaining: 584ms\n",
      "485:\tlearn: 0.1136639\ttotal: 18.9s\tremaining: 545ms\n",
      "486:\tlearn: 0.1133162\ttotal: 18.9s\tremaining: 505ms\n",
      "487:\tlearn: 0.1128420\ttotal: 19s\tremaining: 468ms\n",
      "488:\tlearn: 0.1125078\ttotal: 19s\tremaining: 428ms\n",
      "489:\tlearn: 0.1122073\ttotal: 19.1s\tremaining: 389ms\n",
      "490:\tlearn: 0.1118172\ttotal: 19.1s\tremaining: 350ms\n",
      "491:\tlearn: 0.1115467\ttotal: 19.2s\tremaining: 312ms\n",
      "492:\tlearn: 0.1112408\ttotal: 19.2s\tremaining: 273ms\n",
      "493:\tlearn: 0.1109670\ttotal: 19.2s\tremaining: 234ms\n",
      "494:\tlearn: 0.1105491\ttotal: 19.3s\tremaining: 194ms\n",
      "495:\tlearn: 0.1102731\ttotal: 19.3s\tremaining: 156ms\n",
      "496:\tlearn: 0.1100027\ttotal: 19.4s\tremaining: 117ms\n",
      "497:\tlearn: 0.1095278\ttotal: 19.4s\tremaining: 77.9ms\n",
      "498:\tlearn: 0.1092172\ttotal: 19.4s\tremaining: 38.9ms\n",
      "499:\tlearn: 0.1088363\ttotal: 19.5s\tremaining: 0us\n",
      "0:\tlearn: 0.6899295\ttotal: 25ms\tremaining: 12.5s\n",
      "1:\tlearn: 0.6859190\ttotal: 44.9ms\tremaining: 11.2s\n",
      "2:\tlearn: 0.6821588\ttotal: 117ms\tremaining: 19.4s\n",
      "3:\tlearn: 0.6778548\ttotal: 156ms\tremaining: 19.4s\n",
      "4:\tlearn: 0.6745524\ttotal: 176ms\tremaining: 17.4s\n",
      "5:\tlearn: 0.6701841\ttotal: 222ms\tremaining: 18.3s\n",
      "6:\tlearn: 0.6657943\ttotal: 280ms\tremaining: 19.7s\n",
      "7:\tlearn: 0.6614127\ttotal: 303ms\tremaining: 18.6s\n",
      "8:\tlearn: 0.6578059\ttotal: 374ms\tremaining: 20.4s\n",
      "9:\tlearn: 0.6540350\ttotal: 417ms\tremaining: 20.4s\n",
      "10:\tlearn: 0.6506747\ttotal: 442ms\tremaining: 19.6s\n",
      "11:\tlearn: 0.6462344\ttotal: 464ms\tremaining: 18.9s\n",
      "12:\tlearn: 0.6427566\ttotal: 484ms\tremaining: 18.1s\n",
      "13:\tlearn: 0.6391274\ttotal: 560ms\tremaining: 19.4s\n",
      "14:\tlearn: 0.6352113\ttotal: 590ms\tremaining: 19.1s\n",
      "15:\tlearn: 0.6321421\ttotal: 616ms\tremaining: 18.6s\n",
      "16:\tlearn: 0.6292126\ttotal: 640ms\tremaining: 18.2s\n",
      "17:\tlearn: 0.6244469\ttotal: 683ms\tremaining: 18.3s\n",
      "18:\tlearn: 0.6212587\ttotal: 751ms\tremaining: 19s\n",
      "19:\tlearn: 0.6181618\ttotal: 787ms\tremaining: 18.9s\n",
      "20:\tlearn: 0.6144457\ttotal: 810ms\tremaining: 18.5s\n",
      "21:\tlearn: 0.6110441\ttotal: 831ms\tremaining: 18s\n",
      "22:\tlearn: 0.6075308\ttotal: 896ms\tremaining: 18.6s\n",
      "23:\tlearn: 0.6038394\ttotal: 949ms\tremaining: 18.8s\n",
      "24:\tlearn: 0.6001121\ttotal: 977ms\tremaining: 18.6s\n",
      "25:\tlearn: 0.5980213\ttotal: 997ms\tremaining: 18.2s\n",
      "26:\tlearn: 0.5945791\ttotal: 1.04s\tremaining: 18.3s\n",
      "27:\tlearn: 0.5916101\ttotal: 1.11s\tremaining: 18.7s\n",
      "28:\tlearn: 0.5888747\ttotal: 1.14s\tremaining: 18.5s\n",
      "29:\tlearn: 0.5864407\ttotal: 1.17s\tremaining: 18.3s\n",
      "30:\tlearn: 0.5834336\ttotal: 1.19s\tremaining: 18s\n",
      "31:\tlearn: 0.5808642\ttotal: 1.26s\tremaining: 18.4s\n",
      "32:\tlearn: 0.5776096\ttotal: 1.31s\tremaining: 18.5s\n",
      "33:\tlearn: 0.5748312\ttotal: 1.33s\tremaining: 18.3s\n",
      "34:\tlearn: 0.5723975\ttotal: 1.36s\tremaining: 18s\n",
      "35:\tlearn: 0.5697663\ttotal: 1.38s\tremaining: 17.8s\n",
      "36:\tlearn: 0.5672816\ttotal: 1.45s\tremaining: 18.2s\n",
      "37:\tlearn: 0.5648406\ttotal: 1.49s\tremaining: 18.1s\n",
      "38:\tlearn: 0.5627442\ttotal: 1.51s\tremaining: 17.9s\n",
      "39:\tlearn: 0.5605546\ttotal: 1.53s\tremaining: 17.7s\n",
      "40:\tlearn: 0.5577262\ttotal: 1.59s\tremaining: 17.8s\n",
      "41:\tlearn: 0.5549799\ttotal: 1.64s\tremaining: 17.9s\n",
      "42:\tlearn: 0.5526731\ttotal: 1.67s\tremaining: 17.7s\n",
      "43:\tlearn: 0.5499232\ttotal: 1.69s\tremaining: 17.5s\n",
      "44:\tlearn: 0.5476799\ttotal: 1.76s\tremaining: 17.8s\n",
      "45:\tlearn: 0.5455019\ttotal: 1.81s\tremaining: 17.8s\n",
      "46:\tlearn: 0.5426495\ttotal: 1.83s\tremaining: 17.7s\n",
      "47:\tlearn: 0.5401243\ttotal: 1.85s\tremaining: 17.5s\n",
      "48:\tlearn: 0.5379742\ttotal: 1.87s\tremaining: 17.2s\n",
      "49:\tlearn: 0.5359179\ttotal: 1.95s\tremaining: 17.5s\n",
      "50:\tlearn: 0.5336120\ttotal: 1.99s\tremaining: 17.5s\n",
      "51:\tlearn: 0.5315456\ttotal: 2.01s\tremaining: 17.3s\n",
      "52:\tlearn: 0.5293748\ttotal: 2.03s\tremaining: 17.2s\n",
      "53:\tlearn: 0.5268764\ttotal: 2.1s\tremaining: 17.3s\n",
      "54:\tlearn: 0.5243060\ttotal: 2.15s\tremaining: 17.4s\n",
      "55:\tlearn: 0.5213890\ttotal: 2.18s\tremaining: 17.3s\n",
      "56:\tlearn: 0.5186880\ttotal: 2.21s\tremaining: 17.2s\n",
      "57:\tlearn: 0.5165271\ttotal: 2.25s\tremaining: 17.2s\n",
      "58:\tlearn: 0.5140425\ttotal: 2.32s\tremaining: 17.3s\n",
      "59:\tlearn: 0.5113483\ttotal: 2.35s\tremaining: 17.2s\n",
      "60:\tlearn: 0.5091054\ttotal: 2.38s\tremaining: 17.1s\n",
      "61:\tlearn: 0.5064864\ttotal: 2.4s\tremaining: 16.9s\n",
      "62:\tlearn: 0.5049338\ttotal: 2.47s\tremaining: 17.1s\n",
      "63:\tlearn: 0.5021639\ttotal: 2.5s\tremaining: 17.1s\n",
      "64:\tlearn: 0.5000410\ttotal: 2.53s\tremaining: 16.9s\n",
      "65:\tlearn: 0.4974658\ttotal: 2.55s\tremaining: 16.8s\n",
      "66:\tlearn: 0.4953323\ttotal: 2.62s\tremaining: 16.9s\n",
      "67:\tlearn: 0.4927862\ttotal: 2.65s\tremaining: 16.8s\n",
      "68:\tlearn: 0.4908698\ttotal: 2.67s\tremaining: 16.7s\n",
      "69:\tlearn: 0.4889820\ttotal: 2.7s\tremaining: 16.6s\n",
      "70:\tlearn: 0.4868685\ttotal: 2.77s\tremaining: 16.8s\n",
      "71:\tlearn: 0.4850008\ttotal: 2.81s\tremaining: 16.7s\n",
      "72:\tlearn: 0.4830128\ttotal: 2.83s\tremaining: 16.6s\n",
      "73:\tlearn: 0.4808431\ttotal: 2.85s\tremaining: 16.4s\n",
      "74:\tlearn: 0.4795037\ttotal: 2.91s\tremaining: 16.5s\n",
      "75:\tlearn: 0.4776183\ttotal: 2.97s\tremaining: 16.6s\n",
      "76:\tlearn: 0.4743581\ttotal: 3s\tremaining: 16.5s\n",
      "77:\tlearn: 0.4726643\ttotal: 3.02s\tremaining: 16.4s\n",
      "78:\tlearn: 0.4707736\ttotal: 3.05s\tremaining: 16.3s\n",
      "79:\tlearn: 0.4680329\ttotal: 3.12s\tremaining: 16.4s\n",
      "80:\tlearn: 0.4661090\ttotal: 3.16s\tremaining: 16.4s\n",
      "81:\tlearn: 0.4643138\ttotal: 3.19s\tremaining: 16.3s\n",
      "82:\tlearn: 0.4620601\ttotal: 3.21s\tremaining: 16.1s\n",
      "83:\tlearn: 0.4603918\ttotal: 3.28s\tremaining: 16.2s\n",
      "84:\tlearn: 0.4571492\ttotal: 3.33s\tremaining: 16.3s\n",
      "85:\tlearn: 0.4550960\ttotal: 3.36s\tremaining: 16.2s\n",
      "86:\tlearn: 0.4529626\ttotal: 3.38s\tremaining: 16s\n",
      "87:\tlearn: 0.4503805\ttotal: 3.4s\tremaining: 15.9s\n",
      "88:\tlearn: 0.4486000\ttotal: 3.48s\tremaining: 16.1s\n",
      "89:\tlearn: 0.4463384\ttotal: 3.52s\tremaining: 16s\n",
      "90:\tlearn: 0.4442886\ttotal: 3.54s\tremaining: 15.9s\n",
      "91:\tlearn: 0.4420973\ttotal: 3.57s\tremaining: 15.8s\n",
      "92:\tlearn: 0.4405122\ttotal: 3.61s\tremaining: 15.8s\n",
      "93:\tlearn: 0.4387054\ttotal: 3.67s\tremaining: 15.9s\n",
      "94:\tlearn: 0.4372749\ttotal: 3.71s\tremaining: 15.8s\n",
      "95:\tlearn: 0.4359352\ttotal: 3.73s\tremaining: 15.7s\n",
      "96:\tlearn: 0.4342983\ttotal: 3.75s\tremaining: 15.6s\n",
      "97:\tlearn: 0.4317300\ttotal: 3.82s\tremaining: 15.7s\n",
      "98:\tlearn: 0.4301764\ttotal: 3.87s\tremaining: 15.7s\n",
      "99:\tlearn: 0.4282932\ttotal: 3.91s\tremaining: 15.6s\n",
      "100:\tlearn: 0.4265464\ttotal: 3.93s\tremaining: 15.5s\n",
      "101:\tlearn: 0.4248975\ttotal: 3.95s\tremaining: 15.4s\n",
      "102:\tlearn: 0.4230782\ttotal: 3.98s\tremaining: 15.3s\n",
      "103:\tlearn: 0.4206185\ttotal: 4.04s\tremaining: 15.4s\n",
      "104:\tlearn: 0.4182953\ttotal: 4.08s\tremaining: 15.4s\n",
      "105:\tlearn: 0.4160933\ttotal: 4.11s\tremaining: 15.3s\n",
      "106:\tlearn: 0.4136126\ttotal: 4.13s\tremaining: 15.2s\n",
      "107:\tlearn: 0.4123236\ttotal: 4.2s\tremaining: 15.2s\n",
      "108:\tlearn: 0.4107471\ttotal: 4.25s\tremaining: 15.2s\n",
      "109:\tlearn: 0.4085780\ttotal: 4.28s\tremaining: 15.2s\n",
      "110:\tlearn: 0.4069864\ttotal: 4.3s\tremaining: 15.1s\n",
      "111:\tlearn: 0.4047884\ttotal: 4.32s\tremaining: 15s\n",
      "112:\tlearn: 0.4034319\ttotal: 4.39s\tremaining: 15s\n",
      "113:\tlearn: 0.4021146\ttotal: 4.44s\tremaining: 15s\n",
      "114:\tlearn: 0.4004493\ttotal: 4.48s\tremaining: 15s\n",
      "115:\tlearn: 0.3988655\ttotal: 4.52s\tremaining: 15s\n",
      "116:\tlearn: 0.3975485\ttotal: 4.59s\tremaining: 15s\n",
      "117:\tlearn: 0.3957214\ttotal: 4.63s\tremaining: 15s\n",
      "118:\tlearn: 0.3944596\ttotal: 4.66s\tremaining: 14.9s\n",
      "119:\tlearn: 0.3931101\ttotal: 4.68s\tremaining: 14.8s\n",
      "120:\tlearn: 0.3916533\ttotal: 4.7s\tremaining: 14.7s\n",
      "121:\tlearn: 0.3904093\ttotal: 4.77s\tremaining: 14.8s\n",
      "122:\tlearn: 0.3891480\ttotal: 4.81s\tremaining: 14.8s\n",
      "123:\tlearn: 0.3874544\ttotal: 4.84s\tremaining: 14.7s\n",
      "124:\tlearn: 0.3859230\ttotal: 4.86s\tremaining: 14.6s\n",
      "125:\tlearn: 0.3842331\ttotal: 4.93s\tremaining: 14.6s\n",
      "126:\tlearn: 0.3832820\ttotal: 4.98s\tremaining: 14.6s\n",
      "127:\tlearn: 0.3817394\ttotal: 5.01s\tremaining: 14.6s\n",
      "128:\tlearn: 0.3800665\ttotal: 5.03s\tremaining: 14.5s\n",
      "129:\tlearn: 0.3787795\ttotal: 5.05s\tremaining: 14.4s\n",
      "130:\tlearn: 0.3774417\ttotal: 5.12s\tremaining: 14.4s\n",
      "131:\tlearn: 0.3761199\ttotal: 5.17s\tremaining: 14.4s\n",
      "132:\tlearn: 0.3743917\ttotal: 5.19s\tremaining: 14.3s\n",
      "133:\tlearn: 0.3728561\ttotal: 5.21s\tremaining: 14.2s\n",
      "134:\tlearn: 0.3714091\ttotal: 5.24s\tremaining: 14.2s\n",
      "135:\tlearn: 0.3698209\ttotal: 5.31s\tremaining: 14.2s\n",
      "136:\tlearn: 0.3685967\ttotal: 5.35s\tremaining: 14.2s\n",
      "137:\tlearn: 0.3672887\ttotal: 5.38s\tremaining: 14.1s\n",
      "138:\tlearn: 0.3658427\ttotal: 5.4s\tremaining: 14s\n",
      "139:\tlearn: 0.3642446\ttotal: 5.42s\tremaining: 13.9s\n",
      "140:\tlearn: 0.3633899\ttotal: 5.5s\tremaining: 14s\n",
      "141:\tlearn: 0.3621249\ttotal: 5.53s\tremaining: 13.9s\n",
      "142:\tlearn: 0.3602054\ttotal: 5.56s\tremaining: 13.9s\n",
      "143:\tlearn: 0.3590996\ttotal: 5.58s\tremaining: 13.8s\n",
      "144:\tlearn: 0.3578395\ttotal: 5.62s\tremaining: 13.8s\n",
      "145:\tlearn: 0.3568055\ttotal: 5.68s\tremaining: 13.8s\n",
      "146:\tlearn: 0.3550957\ttotal: 5.71s\tremaining: 13.7s\n",
      "147:\tlearn: 0.3535024\ttotal: 5.74s\tremaining: 13.7s\n",
      "148:\tlearn: 0.3522209\ttotal: 5.76s\tremaining: 13.6s\n",
      "149:\tlearn: 0.3511110\ttotal: 5.83s\tremaining: 13.6s\n",
      "150:\tlearn: 0.3499032\ttotal: 5.88s\tremaining: 13.6s\n",
      "151:\tlearn: 0.3490232\ttotal: 5.91s\tremaining: 13.5s\n",
      "152:\tlearn: 0.3474181\ttotal: 5.93s\tremaining: 13.4s\n",
      "153:\tlearn: 0.3458907\ttotal: 5.95s\tremaining: 13.4s\n",
      "154:\tlearn: 0.3447901\ttotal: 6.02s\tremaining: 13.4s\n",
      "155:\tlearn: 0.3431949\ttotal: 6.07s\tremaining: 13.4s\n",
      "156:\tlearn: 0.3419394\ttotal: 6.09s\tremaining: 13.3s\n",
      "157:\tlearn: 0.3404505\ttotal: 6.11s\tremaining: 13.2s\n",
      "158:\tlearn: 0.3390181\ttotal: 6.15s\tremaining: 13.2s\n",
      "159:\tlearn: 0.3380121\ttotal: 6.22s\tremaining: 13.2s\n",
      "160:\tlearn: 0.3371203\ttotal: 6.25s\tremaining: 13.2s\n",
      "161:\tlearn: 0.3357647\ttotal: 6.28s\tremaining: 13.1s\n",
      "162:\tlearn: 0.3346529\ttotal: 6.3s\tremaining: 13s\n",
      "163:\tlearn: 0.3334386\ttotal: 6.38s\tremaining: 13.1s\n",
      "164:\tlearn: 0.3321633\ttotal: 6.45s\tremaining: 13.1s\n",
      "165:\tlearn: 0.3308149\ttotal: 6.49s\tremaining: 13.1s\n",
      "166:\tlearn: 0.3290238\ttotal: 6.51s\tremaining: 13s\n",
      "167:\tlearn: 0.3278410\ttotal: 6.52s\tremaining: 12.9s\n",
      "168:\tlearn: 0.3268352\ttotal: 6.59s\tremaining: 12.9s\n",
      "169:\tlearn: 0.3255135\ttotal: 6.63s\tremaining: 12.9s\n",
      "170:\tlearn: 0.3246525\ttotal: 6.65s\tremaining: 12.8s\n",
      "171:\tlearn: 0.3232129\ttotal: 6.72s\tremaining: 12.8s\n",
      "172:\tlearn: 0.3222660\ttotal: 6.75s\tremaining: 12.8s\n",
      "173:\tlearn: 0.3212094\ttotal: 6.78s\tremaining: 12.7s\n",
      "174:\tlearn: 0.3195319\ttotal: 6.8s\tremaining: 12.6s\n",
      "175:\tlearn: 0.3182034\ttotal: 6.82s\tremaining: 12.6s\n",
      "176:\tlearn: 0.3174864\ttotal: 6.84s\tremaining: 12.5s\n",
      "177:\tlearn: 0.3162160\ttotal: 6.92s\tremaining: 12.5s\n",
      "178:\tlearn: 0.3149564\ttotal: 6.95s\tremaining: 12.5s\n",
      "179:\tlearn: 0.3131169\ttotal: 6.97s\tremaining: 12.4s\n",
      "180:\tlearn: 0.3119842\ttotal: 6.99s\tremaining: 12.3s\n",
      "181:\tlearn: 0.3104671\ttotal: 7.06s\tremaining: 12.3s\n",
      "182:\tlearn: 0.3096931\ttotal: 7.11s\tremaining: 12.3s\n",
      "183:\tlearn: 0.3085937\ttotal: 7.14s\tremaining: 12.3s\n",
      "184:\tlearn: 0.3075122\ttotal: 7.16s\tremaining: 12.2s\n",
      "185:\tlearn: 0.3058675\ttotal: 7.22s\tremaining: 12.2s\n",
      "186:\tlearn: 0.3047606\ttotal: 7.27s\tremaining: 12.2s\n",
      "187:\tlearn: 0.3039254\ttotal: 7.3s\tremaining: 12.1s\n",
      "188:\tlearn: 0.3029336\ttotal: 7.33s\tremaining: 12.1s\n",
      "189:\tlearn: 0.3019928\ttotal: 7.35s\tremaining: 12s\n",
      "190:\tlearn: 0.3006561\ttotal: 7.42s\tremaining: 12s\n",
      "191:\tlearn: 0.2992684\ttotal: 7.46s\tremaining: 12s\n",
      "192:\tlearn: 0.2983934\ttotal: 7.49s\tremaining: 11.9s\n",
      "193:\tlearn: 0.2974342\ttotal: 7.51s\tremaining: 11.9s\n",
      "194:\tlearn: 0.2965191\ttotal: 7.56s\tremaining: 11.8s\n",
      "195:\tlearn: 0.2955433\ttotal: 7.62s\tremaining: 11.8s\n",
      "196:\tlearn: 0.2945434\ttotal: 7.65s\tremaining: 11.8s\n",
      "197:\tlearn: 0.2932659\ttotal: 7.67s\tremaining: 11.7s\n",
      "198:\tlearn: 0.2917873\ttotal: 7.7s\tremaining: 11.6s\n",
      "199:\tlearn: 0.2906703\ttotal: 7.75s\tremaining: 11.6s\n",
      "200:\tlearn: 0.2899342\ttotal: 7.8s\tremaining: 11.6s\n",
      "201:\tlearn: 0.2892123\ttotal: 7.82s\tremaining: 11.5s\n",
      "202:\tlearn: 0.2882847\ttotal: 7.84s\tremaining: 11.5s\n",
      "203:\tlearn: 0.2872629\ttotal: 7.92s\tremaining: 11.5s\n",
      "204:\tlearn: 0.2860640\ttotal: 7.95s\tremaining: 11.4s\n",
      "205:\tlearn: 0.2847822\ttotal: 7.97s\tremaining: 11.4s\n",
      "206:\tlearn: 0.2837324\ttotal: 8s\tremaining: 11.3s\n",
      "207:\tlearn: 0.2828815\ttotal: 8.06s\tremaining: 11.3s\n",
      "208:\tlearn: 0.2818551\ttotal: 8.11s\tremaining: 11.3s\n",
      "209:\tlearn: 0.2801516\ttotal: 8.14s\tremaining: 11.2s\n",
      "210:\tlearn: 0.2783801\ttotal: 8.16s\tremaining: 11.2s\n",
      "211:\tlearn: 0.2768614\ttotal: 8.18s\tremaining: 11.1s\n",
      "212:\tlearn: 0.2761195\ttotal: 8.25s\tremaining: 11.1s\n",
      "213:\tlearn: 0.2753235\ttotal: 8.29s\tremaining: 11.1s\n",
      "214:\tlearn: 0.2740498\ttotal: 8.33s\tremaining: 11s\n",
      "215:\tlearn: 0.2731053\ttotal: 8.37s\tremaining: 11s\n",
      "216:\tlearn: 0.2723525\ttotal: 8.4s\tremaining: 10.9s\n",
      "217:\tlearn: 0.2713980\ttotal: 8.42s\tremaining: 10.9s\n",
      "218:\tlearn: 0.2705219\ttotal: 8.49s\tremaining: 10.9s\n",
      "219:\tlearn: 0.2695810\ttotal: 8.54s\tremaining: 10.9s\n",
      "220:\tlearn: 0.2682489\ttotal: 8.56s\tremaining: 10.8s\n",
      "221:\tlearn: 0.2671607\ttotal: 8.58s\tremaining: 10.7s\n",
      "222:\tlearn: 0.2664436\ttotal: 8.64s\tremaining: 10.7s\n",
      "223:\tlearn: 0.2657481\ttotal: 8.69s\tremaining: 10.7s\n",
      "224:\tlearn: 0.2648021\ttotal: 8.72s\tremaining: 10.7s\n",
      "225:\tlearn: 0.2637001\ttotal: 8.75s\tremaining: 10.6s\n",
      "226:\tlearn: 0.2628699\ttotal: 8.76s\tremaining: 10.5s\n",
      "227:\tlearn: 0.2623847\ttotal: 8.83s\tremaining: 10.5s\n",
      "228:\tlearn: 0.2618155\ttotal: 8.88s\tremaining: 10.5s\n",
      "229:\tlearn: 0.2607128\ttotal: 8.9s\tremaining: 10.5s\n",
      "230:\tlearn: 0.2595389\ttotal: 8.93s\tremaining: 10.4s\n",
      "231:\tlearn: 0.2585592\ttotal: 8.95s\tremaining: 10.3s\n",
      "232:\tlearn: 0.2575595\ttotal: 9.02s\tremaining: 10.3s\n",
      "233:\tlearn: 0.2566668\ttotal: 9.06s\tremaining: 10.3s\n",
      "234:\tlearn: 0.2556533\ttotal: 9.09s\tremaining: 10.3s\n",
      "235:\tlearn: 0.2543761\ttotal: 9.11s\tremaining: 10.2s\n",
      "236:\tlearn: 0.2536074\ttotal: 9.16s\tremaining: 10.2s\n",
      "237:\tlearn: 0.2525250\ttotal: 9.21s\tremaining: 10.1s\n",
      "238:\tlearn: 0.2517052\ttotal: 9.24s\tremaining: 10.1s\n",
      "239:\tlearn: 0.2505102\ttotal: 9.26s\tremaining: 10s\n",
      "240:\tlearn: 0.2491233\ttotal: 9.28s\tremaining: 9.97s\n",
      "241:\tlearn: 0.2480181\ttotal: 9.35s\tremaining: 9.97s\n",
      "242:\tlearn: 0.2468408\ttotal: 9.39s\tremaining: 9.93s\n",
      "243:\tlearn: 0.2460693\ttotal: 9.42s\tremaining: 9.88s\n",
      "244:\tlearn: 0.2451442\ttotal: 9.44s\tremaining: 9.82s\n",
      "245:\tlearn: 0.2442720\ttotal: 9.51s\tremaining: 9.81s\n",
      "246:\tlearn: 0.2434566\ttotal: 9.55s\tremaining: 9.79s\n",
      "247:\tlearn: 0.2425595\ttotal: 9.58s\tremaining: 9.73s\n",
      "248:\tlearn: 0.2418797\ttotal: 9.6s\tremaining: 9.68s\n",
      "249:\tlearn: 0.2405740\ttotal: 9.62s\tremaining: 9.62s\n",
      "250:\tlearn: 0.2397448\ttotal: 9.69s\tremaining: 9.62s\n",
      "251:\tlearn: 0.2386697\ttotal: 9.74s\tremaining: 9.58s\n",
      "252:\tlearn: 0.2379164\ttotal: 9.77s\tremaining: 9.54s\n",
      "253:\tlearn: 0.2372359\ttotal: 9.79s\tremaining: 9.48s\n",
      "254:\tlearn: 0.2364815\ttotal: 9.86s\tremaining: 9.48s\n",
      "255:\tlearn: 0.2358784\ttotal: 9.91s\tremaining: 9.45s\n",
      "256:\tlearn: 0.2352463\ttotal: 9.94s\tremaining: 9.39s\n",
      "257:\tlearn: 0.2343181\ttotal: 9.96s\tremaining: 9.34s\n",
      "258:\tlearn: 0.2335360\ttotal: 9.98s\tremaining: 9.29s\n",
      "259:\tlearn: 0.2329071\ttotal: 10.1s\tremaining: 9.28s\n",
      "260:\tlearn: 0.2321270\ttotal: 10.1s\tremaining: 9.25s\n",
      "261:\tlearn: 0.2309306\ttotal: 10.1s\tremaining: 9.2s\n",
      "262:\tlearn: 0.2302397\ttotal: 10.1s\tremaining: 9.14s\n",
      "263:\tlearn: 0.2295468\ttotal: 10.2s\tremaining: 9.09s\n",
      "264:\tlearn: 0.2288429\ttotal: 10.2s\tremaining: 9.08s\n",
      "265:\tlearn: 0.2280855\ttotal: 10.3s\tremaining: 9.04s\n",
      "266:\tlearn: 0.2274449\ttotal: 10.3s\tremaining: 8.98s\n",
      "267:\tlearn: 0.2265760\ttotal: 10.3s\tremaining: 8.93s\n",
      "268:\tlearn: 0.2258782\ttotal: 10.3s\tremaining: 8.88s\n",
      "269:\tlearn: 0.2251860\ttotal: 10.4s\tremaining: 8.87s\n",
      "270:\tlearn: 0.2244830\ttotal: 10.4s\tremaining: 8.83s\n",
      "271:\tlearn: 0.2238518\ttotal: 10.5s\tremaining: 8.78s\n",
      "272:\tlearn: 0.2232211\ttotal: 10.5s\tremaining: 8.72s\n",
      "273:\tlearn: 0.2223197\ttotal: 10.6s\tremaining: 8.71s\n",
      "274:\tlearn: 0.2217241\ttotal: 10.6s\tremaining: 8.68s\n",
      "275:\tlearn: 0.2209352\ttotal: 10.6s\tremaining: 8.63s\n",
      "276:\tlearn: 0.2200023\ttotal: 10.7s\tremaining: 8.58s\n",
      "277:\tlearn: 0.2191214\ttotal: 10.7s\tremaining: 8.53s\n",
      "278:\tlearn: 0.2181969\ttotal: 10.8s\tremaining: 8.53s\n",
      "279:\tlearn: 0.2174931\ttotal: 10.8s\tremaining: 8.49s\n",
      "280:\tlearn: 0.2165618\ttotal: 10.8s\tremaining: 8.44s\n",
      "281:\tlearn: 0.2155294\ttotal: 10.9s\tremaining: 8.39s\n",
      "282:\tlearn: 0.2147913\ttotal: 10.9s\tremaining: 8.35s\n",
      "283:\tlearn: 0.2142471\ttotal: 11s\tremaining: 8.33s\n",
      "284:\tlearn: 0.2134531\ttotal: 11s\tremaining: 8.29s\n",
      "285:\tlearn: 0.2129882\ttotal: 11s\tremaining: 8.24s\n",
      "286:\tlearn: 0.2120886\ttotal: 11s\tremaining: 8.19s\n",
      "287:\tlearn: 0.2115190\ttotal: 11.1s\tremaining: 8.16s\n",
      "288:\tlearn: 0.2105997\ttotal: 11.1s\tremaining: 8.12s\n",
      "289:\tlearn: 0.2099773\ttotal: 11.2s\tremaining: 8.08s\n",
      "290:\tlearn: 0.2092967\ttotal: 11.2s\tremaining: 8.03s\n",
      "291:\tlearn: 0.2086166\ttotal: 11.2s\tremaining: 7.99s\n",
      "292:\tlearn: 0.2078946\ttotal: 11.3s\tremaining: 7.97s\n",
      "293:\tlearn: 0.2070254\ttotal: 11.3s\tremaining: 7.94s\n",
      "294:\tlearn: 0.2062587\ttotal: 11.4s\tremaining: 7.89s\n",
      "295:\tlearn: 0.2054771\ttotal: 11.4s\tremaining: 7.84s\n",
      "296:\tlearn: 0.2046112\ttotal: 11.4s\tremaining: 7.79s\n",
      "297:\tlearn: 0.2039407\ttotal: 11.5s\tremaining: 7.78s\n",
      "298:\tlearn: 0.2033003\ttotal: 11.5s\tremaining: 7.74s\n",
      "299:\tlearn: 0.2023153\ttotal: 11.5s\tremaining: 7.7s\n",
      "300:\tlearn: 0.2016053\ttotal: 11.6s\tremaining: 7.65s\n",
      "301:\tlearn: 0.2010790\ttotal: 11.6s\tremaining: 7.63s\n",
      "302:\tlearn: 0.2003810\ttotal: 11.7s\tremaining: 7.59s\n",
      "303:\tlearn: 0.1996840\ttotal: 11.7s\tremaining: 7.55s\n",
      "304:\tlearn: 0.1989844\ttotal: 11.7s\tremaining: 7.5s\n",
      "305:\tlearn: 0.1985225\ttotal: 11.8s\tremaining: 7.46s\n",
      "306:\tlearn: 0.1978622\ttotal: 11.8s\tremaining: 7.44s\n",
      "307:\tlearn: 0.1972757\ttotal: 11.9s\tremaining: 7.4s\n",
      "308:\tlearn: 0.1963813\ttotal: 11.9s\tremaining: 7.35s\n",
      "309:\tlearn: 0.1956675\ttotal: 11.9s\tremaining: 7.3s\n",
      "310:\tlearn: 0.1950730\ttotal: 12s\tremaining: 7.28s\n",
      "311:\tlearn: 0.1943924\ttotal: 12s\tremaining: 7.25s\n",
      "312:\tlearn: 0.1939977\ttotal: 12.1s\tremaining: 7.21s\n",
      "313:\tlearn: 0.1933332\ttotal: 12.1s\tremaining: 7.16s\n",
      "314:\tlearn: 0.1927683\ttotal: 12.1s\tremaining: 7.13s\n",
      "315:\tlearn: 0.1920002\ttotal: 12.2s\tremaining: 7.1s\n",
      "316:\tlearn: 0.1912902\ttotal: 12.2s\tremaining: 7.06s\n",
      "317:\tlearn: 0.1907607\ttotal: 12.3s\tremaining: 7.01s\n",
      "318:\tlearn: 0.1902881\ttotal: 12.3s\tremaining: 6.96s\n",
      "319:\tlearn: 0.1899206\ttotal: 12.3s\tremaining: 6.94s\n",
      "320:\tlearn: 0.1894066\ttotal: 12.4s\tremaining: 6.91s\n",
      "321:\tlearn: 0.1888475\ttotal: 12.4s\tremaining: 6.87s\n",
      "322:\tlearn: 0.1882310\ttotal: 12.4s\tremaining: 6.82s\n",
      "323:\tlearn: 0.1876397\ttotal: 12.5s\tremaining: 6.8s\n",
      "324:\tlearn: 0.1869465\ttotal: 12.6s\tremaining: 6.77s\n",
      "325:\tlearn: 0.1862937\ttotal: 12.6s\tremaining: 6.72s\n",
      "326:\tlearn: 0.1855274\ttotal: 12.6s\tremaining: 6.68s\n",
      "327:\tlearn: 0.1848802\ttotal: 12.6s\tremaining: 6.63s\n",
      "328:\tlearn: 0.1842825\ttotal: 12.7s\tremaining: 6.61s\n",
      "329:\tlearn: 0.1837162\ttotal: 12.8s\tremaining: 6.57s\n",
      "330:\tlearn: 0.1831028\ttotal: 12.8s\tremaining: 6.52s\n",
      "331:\tlearn: 0.1824309\ttotal: 12.8s\tremaining: 6.48s\n",
      "332:\tlearn: 0.1817737\ttotal: 12.8s\tremaining: 6.44s\n",
      "333:\tlearn: 0.1814033\ttotal: 12.9s\tremaining: 6.42s\n",
      "334:\tlearn: 0.1808602\ttotal: 12.9s\tremaining: 6.38s\n",
      "335:\tlearn: 0.1802167\ttotal: 13s\tremaining: 6.33s\n",
      "336:\tlearn: 0.1796846\ttotal: 13s\tremaining: 6.28s\n",
      "337:\tlearn: 0.1792894\ttotal: 13.1s\tremaining: 6.26s\n",
      "338:\tlearn: 0.1786945\ttotal: 13.1s\tremaining: 6.22s\n",
      "339:\tlearn: 0.1779624\ttotal: 13.1s\tremaining: 6.18s\n",
      "340:\tlearn: 0.1775435\ttotal: 13.2s\tremaining: 6.13s\n",
      "341:\tlearn: 0.1769951\ttotal: 13.2s\tremaining: 6.08s\n",
      "342:\tlearn: 0.1764454\ttotal: 13.2s\tremaining: 6.04s\n",
      "343:\tlearn: 0.1759175\ttotal: 13.2s\tremaining: 5.99s\n",
      "344:\tlearn: 0.1754650\ttotal: 13.3s\tremaining: 5.97s\n",
      "345:\tlearn: 0.1750433\ttotal: 13.3s\tremaining: 5.93s\n",
      "346:\tlearn: 0.1744476\ttotal: 13.4s\tremaining: 5.89s\n",
      "347:\tlearn: 0.1739392\ttotal: 13.4s\tremaining: 5.84s\n",
      "348:\tlearn: 0.1735395\ttotal: 13.4s\tremaining: 5.81s\n",
      "349:\tlearn: 0.1728236\ttotal: 13.5s\tremaining: 5.78s\n",
      "350:\tlearn: 0.1722429\ttotal: 13.5s\tremaining: 5.74s\n",
      "351:\tlearn: 0.1718617\ttotal: 13.5s\tremaining: 5.69s\n",
      "352:\tlearn: 0.1710341\ttotal: 13.6s\tremaining: 5.65s\n",
      "353:\tlearn: 0.1705243\ttotal: 13.6s\tremaining: 5.62s\n",
      "354:\tlearn: 0.1699782\ttotal: 13.7s\tremaining: 5.59s\n",
      "355:\tlearn: 0.1692896\ttotal: 13.7s\tremaining: 5.54s\n",
      "356:\tlearn: 0.1689346\ttotal: 13.7s\tremaining: 5.5s\n",
      "357:\tlearn: 0.1684551\ttotal: 13.8s\tremaining: 5.47s\n",
      "358:\tlearn: 0.1677996\ttotal: 13.8s\tremaining: 5.44s\n",
      "359:\tlearn: 0.1670908\ttotal: 13.9s\tremaining: 5.4s\n",
      "360:\tlearn: 0.1666796\ttotal: 13.9s\tremaining: 5.35s\n",
      "361:\tlearn: 0.1661761\ttotal: 13.9s\tremaining: 5.32s\n",
      "362:\tlearn: 0.1657988\ttotal: 14s\tremaining: 5.29s\n",
      "363:\tlearn: 0.1652599\ttotal: 14s\tremaining: 5.25s\n",
      "364:\tlearn: 0.1647490\ttotal: 14.1s\tremaining: 5.2s\n",
      "365:\tlearn: 0.1643146\ttotal: 14.1s\tremaining: 5.16s\n",
      "366:\tlearn: 0.1638539\ttotal: 14.1s\tremaining: 5.12s\n",
      "367:\tlearn: 0.1634485\ttotal: 14.2s\tremaining: 5.09s\n",
      "368:\tlearn: 0.1627780\ttotal: 14.2s\tremaining: 5.04s\n",
      "369:\tlearn: 0.1622720\ttotal: 14.2s\tremaining: 5s\n",
      "370:\tlearn: 0.1618094\ttotal: 14.3s\tremaining: 4.97s\n",
      "371:\tlearn: 0.1614053\ttotal: 14.4s\tremaining: 4.94s\n",
      "372:\tlearn: 0.1610398\ttotal: 14.4s\tremaining: 4.89s\n",
      "373:\tlearn: 0.1606746\ttotal: 14.4s\tremaining: 4.85s\n",
      "374:\tlearn: 0.1603083\ttotal: 14.4s\tremaining: 4.81s\n",
      "375:\tlearn: 0.1596931\ttotal: 14.5s\tremaining: 4.78s\n",
      "376:\tlearn: 0.1592305\ttotal: 14.5s\tremaining: 4.74s\n",
      "377:\tlearn: 0.1585187\ttotal: 14.6s\tremaining: 4.7s\n",
      "378:\tlearn: 0.1580758\ttotal: 14.6s\tremaining: 4.66s\n",
      "379:\tlearn: 0.1575120\ttotal: 14.7s\tremaining: 4.63s\n",
      "380:\tlearn: 0.1568842\ttotal: 14.7s\tremaining: 4.59s\n",
      "381:\tlearn: 0.1563404\ttotal: 14.7s\tremaining: 4.55s\n",
      "382:\tlearn: 0.1559161\ttotal: 14.7s\tremaining: 4.5s\n",
      "383:\tlearn: 0.1553857\ttotal: 14.8s\tremaining: 4.46s\n",
      "384:\tlearn: 0.1550234\ttotal: 14.8s\tremaining: 4.43s\n",
      "385:\tlearn: 0.1543787\ttotal: 14.9s\tremaining: 4.39s\n",
      "386:\tlearn: 0.1538164\ttotal: 14.9s\tremaining: 4.35s\n",
      "387:\tlearn: 0.1532763\ttotal: 14.9s\tremaining: 4.31s\n",
      "388:\tlearn: 0.1528989\ttotal: 15s\tremaining: 4.27s\n",
      "389:\tlearn: 0.1525569\ttotal: 15s\tremaining: 4.24s\n",
      "390:\tlearn: 0.1520842\ttotal: 15.1s\tremaining: 4.2s\n",
      "391:\tlearn: 0.1515928\ttotal: 15.1s\tremaining: 4.16s\n",
      "392:\tlearn: 0.1512998\ttotal: 15.1s\tremaining: 4.11s\n",
      "393:\tlearn: 0.1508085\ttotal: 15.2s\tremaining: 4.08s\n",
      "394:\tlearn: 0.1503019\ttotal: 15.2s\tremaining: 4.04s\n",
      "395:\tlearn: 0.1497507\ttotal: 15.2s\tremaining: 4s\n",
      "396:\tlearn: 0.1493891\ttotal: 15.3s\tremaining: 3.96s\n",
      "397:\tlearn: 0.1487795\ttotal: 15.3s\tremaining: 3.92s\n",
      "398:\tlearn: 0.1483080\ttotal: 15.4s\tremaining: 3.89s\n",
      "399:\tlearn: 0.1477299\ttotal: 15.4s\tremaining: 3.85s\n",
      "400:\tlearn: 0.1471776\ttotal: 15.4s\tremaining: 3.81s\n",
      "401:\tlearn: 0.1465386\ttotal: 15.4s\tremaining: 3.76s\n",
      "402:\tlearn: 0.1460623\ttotal: 15.5s\tremaining: 3.73s\n",
      "403:\tlearn: 0.1456479\ttotal: 15.6s\tremaining: 3.7s\n",
      "404:\tlearn: 0.1452908\ttotal: 15.6s\tremaining: 3.65s\n",
      "405:\tlearn: 0.1448167\ttotal: 15.6s\tremaining: 3.61s\n",
      "406:\tlearn: 0.1442013\ttotal: 15.6s\tremaining: 3.57s\n",
      "407:\tlearn: 0.1438058\ttotal: 15.7s\tremaining: 3.54s\n",
      "408:\tlearn: 0.1433714\ttotal: 15.7s\tremaining: 3.5s\n",
      "409:\tlearn: 0.1429703\ttotal: 15.8s\tremaining: 3.46s\n",
      "410:\tlearn: 0.1424920\ttotal: 15.8s\tremaining: 3.42s\n",
      "411:\tlearn: 0.1421843\ttotal: 15.9s\tremaining: 3.39s\n",
      "412:\tlearn: 0.1417905\ttotal: 15.9s\tremaining: 3.35s\n",
      "413:\tlearn: 0.1413807\ttotal: 15.9s\tremaining: 3.31s\n",
      "414:\tlearn: 0.1409676\ttotal: 16s\tremaining: 3.27s\n",
      "415:\tlearn: 0.1406595\ttotal: 16s\tremaining: 3.23s\n",
      "416:\tlearn: 0.1403529\ttotal: 16.1s\tremaining: 3.19s\n",
      "417:\tlearn: 0.1398789\ttotal: 16.1s\tremaining: 3.16s\n",
      "418:\tlearn: 0.1394508\ttotal: 16.1s\tremaining: 3.12s\n",
      "419:\tlearn: 0.1390085\ttotal: 16.1s\tremaining: 3.07s\n",
      "420:\tlearn: 0.1385114\ttotal: 16.2s\tremaining: 3.04s\n",
      "421:\tlearn: 0.1381410\ttotal: 16.2s\tremaining: 3s\n",
      "422:\tlearn: 0.1377189\ttotal: 16.3s\tremaining: 2.96s\n",
      "423:\tlearn: 0.1374111\ttotal: 16.3s\tremaining: 2.92s\n",
      "424:\tlearn: 0.1369632\ttotal: 16.3s\tremaining: 2.88s\n",
      "425:\tlearn: 0.1363307\ttotal: 16.4s\tremaining: 2.85s\n",
      "426:\tlearn: 0.1360289\ttotal: 16.4s\tremaining: 2.81s\n",
      "427:\tlearn: 0.1354008\ttotal: 16.4s\tremaining: 2.77s\n",
      "428:\tlearn: 0.1349486\ttotal: 16.5s\tremaining: 2.73s\n",
      "429:\tlearn: 0.1345883\ttotal: 16.5s\tremaining: 2.69s\n",
      "430:\tlearn: 0.1343093\ttotal: 16.6s\tremaining: 2.66s\n",
      "431:\tlearn: 0.1338097\ttotal: 16.6s\tremaining: 2.62s\n",
      "432:\tlearn: 0.1332417\ttotal: 16.7s\tremaining: 2.58s\n",
      "433:\tlearn: 0.1329194\ttotal: 16.7s\tremaining: 2.54s\n",
      "434:\tlearn: 0.1326763\ttotal: 16.8s\tremaining: 2.5s\n",
      "435:\tlearn: 0.1322097\ttotal: 16.8s\tremaining: 2.46s\n",
      "436:\tlearn: 0.1316529\ttotal: 16.8s\tremaining: 2.42s\n",
      "437:\tlearn: 0.1312275\ttotal: 16.9s\tremaining: 2.39s\n",
      "438:\tlearn: 0.1309341\ttotal: 16.9s\tremaining: 2.35s\n",
      "439:\tlearn: 0.1305053\ttotal: 17s\tremaining: 2.31s\n",
      "440:\tlearn: 0.1302086\ttotal: 17s\tremaining: 2.27s\n",
      "441:\tlearn: 0.1299559\ttotal: 17s\tremaining: 2.23s\n",
      "442:\tlearn: 0.1294774\ttotal: 17.1s\tremaining: 2.2s\n",
      "443:\tlearn: 0.1290976\ttotal: 17.1s\tremaining: 2.16s\n",
      "444:\tlearn: 0.1287640\ttotal: 17.1s\tremaining: 2.12s\n",
      "445:\tlearn: 0.1284551\ttotal: 17.2s\tremaining: 2.08s\n",
      "446:\tlearn: 0.1280813\ttotal: 17.2s\tremaining: 2.04s\n",
      "447:\tlearn: 0.1276482\ttotal: 17.3s\tremaining: 2s\n",
      "448:\tlearn: 0.1272182\ttotal: 17.3s\tremaining: 1.97s\n",
      "449:\tlearn: 0.1269219\ttotal: 17.3s\tremaining: 1.92s\n",
      "450:\tlearn: 0.1265249\ttotal: 17.3s\tremaining: 1.88s\n",
      "451:\tlearn: 0.1261228\ttotal: 17.4s\tremaining: 1.85s\n",
      "452:\tlearn: 0.1257594\ttotal: 17.5s\tremaining: 1.81s\n",
      "453:\tlearn: 0.1254474\ttotal: 17.5s\tremaining: 1.77s\n",
      "454:\tlearn: 0.1250566\ttotal: 17.5s\tremaining: 1.73s\n",
      "455:\tlearn: 0.1246426\ttotal: 17.6s\tremaining: 1.7s\n",
      "456:\tlearn: 0.1242485\ttotal: 17.6s\tremaining: 1.66s\n",
      "457:\tlearn: 0.1239034\ttotal: 17.7s\tremaining: 1.62s\n",
      "458:\tlearn: 0.1236773\ttotal: 17.7s\tremaining: 1.58s\n",
      "459:\tlearn: 0.1233433\ttotal: 17.7s\tremaining: 1.54s\n",
      "460:\tlearn: 0.1228863\ttotal: 17.8s\tremaining: 1.5s\n",
      "461:\tlearn: 0.1225042\ttotal: 17.8s\tremaining: 1.47s\n",
      "462:\tlearn: 0.1221743\ttotal: 17.8s\tremaining: 1.43s\n",
      "463:\tlearn: 0.1219327\ttotal: 17.9s\tremaining: 1.39s\n",
      "464:\tlearn: 0.1216173\ttotal: 17.9s\tremaining: 1.35s\n",
      "465:\tlearn: 0.1213610\ttotal: 18s\tremaining: 1.31s\n",
      "466:\tlearn: 0.1210740\ttotal: 18s\tremaining: 1.27s\n",
      "467:\tlearn: 0.1209017\ttotal: 18s\tremaining: 1.23s\n",
      "468:\tlearn: 0.1204534\ttotal: 18s\tremaining: 1.19s\n",
      "469:\tlearn: 0.1199945\ttotal: 18.1s\tremaining: 1.16s\n",
      "470:\tlearn: 0.1196770\ttotal: 18.2s\tremaining: 1.12s\n",
      "471:\tlearn: 0.1192033\ttotal: 18.2s\tremaining: 1.08s\n",
      "472:\tlearn: 0.1188652\ttotal: 18.2s\tremaining: 1.04s\n",
      "473:\tlearn: 0.1186606\ttotal: 18.2s\tremaining: 1s\n",
      "474:\tlearn: 0.1183585\ttotal: 18.3s\tremaining: 964ms\n",
      "475:\tlearn: 0.1179631\ttotal: 18.3s\tremaining: 925ms\n",
      "476:\tlearn: 0.1175100\ttotal: 18.4s\tremaining: 886ms\n",
      "477:\tlearn: 0.1172500\ttotal: 18.4s\tremaining: 846ms\n",
      "478:\tlearn: 0.1168068\ttotal: 18.4s\tremaining: 807ms\n",
      "479:\tlearn: 0.1164647\ttotal: 18.5s\tremaining: 770ms\n",
      "480:\tlearn: 0.1161769\ttotal: 18.5s\tremaining: 732ms\n",
      "481:\tlearn: 0.1157884\ttotal: 18.6s\tremaining: 693ms\n",
      "482:\tlearn: 0.1153657\ttotal: 18.6s\tremaining: 654ms\n",
      "483:\tlearn: 0.1148342\ttotal: 18.6s\tremaining: 615ms\n",
      "484:\tlearn: 0.1146557\ttotal: 18.7s\tremaining: 578ms\n",
      "485:\tlearn: 0.1143640\ttotal: 18.7s\tremaining: 539ms\n",
      "486:\tlearn: 0.1139142\ttotal: 18.7s\tremaining: 500ms\n",
      "487:\tlearn: 0.1135529\ttotal: 18.8s\tremaining: 461ms\n",
      "488:\tlearn: 0.1133124\ttotal: 18.8s\tremaining: 423ms\n",
      "489:\tlearn: 0.1130238\ttotal: 18.9s\tremaining: 385ms\n",
      "490:\tlearn: 0.1126778\ttotal: 18.9s\tremaining: 346ms\n",
      "491:\tlearn: 0.1124289\ttotal: 18.9s\tremaining: 308ms\n",
      "492:\tlearn: 0.1119667\ttotal: 18.9s\tremaining: 269ms\n",
      "493:\tlearn: 0.1116757\ttotal: 19s\tremaining: 231ms\n",
      "494:\tlearn: 0.1114791\ttotal: 19.1s\tremaining: 192ms\n",
      "495:\tlearn: 0.1112335\ttotal: 19.1s\tremaining: 154ms\n",
      "496:\tlearn: 0.1109150\ttotal: 19.1s\tremaining: 115ms\n",
      "497:\tlearn: 0.1106474\ttotal: 19.2s\tremaining: 76.9ms\n",
      "498:\tlearn: 0.1103838\ttotal: 19.2s\tremaining: 38.5ms\n",
      "499:\tlearn: 0.1099677\ttotal: 19.2s\tremaining: 0us\n",
      "0:\tlearn: 0.6893265\ttotal: 22ms\tremaining: 11s\n",
      "1:\tlearn: 0.6853809\ttotal: 83.1ms\tremaining: 20.7s\n",
      "2:\tlearn: 0.6812345\ttotal: 142ms\tremaining: 23.5s\n",
      "3:\tlearn: 0.6762531\ttotal: 168ms\tremaining: 20.8s\n",
      "4:\tlearn: 0.6723666\ttotal: 189ms\tremaining: 18.7s\n",
      "5:\tlearn: 0.6685201\ttotal: 218ms\tremaining: 17.9s\n",
      "6:\tlearn: 0.6650652\ttotal: 290ms\tremaining: 20.4s\n",
      "7:\tlearn: 0.6610569\ttotal: 326ms\tremaining: 20s\n",
      "8:\tlearn: 0.6573972\ttotal: 351ms\tremaining: 19.1s\n",
      "9:\tlearn: 0.6537049\ttotal: 372ms\tremaining: 18.2s\n",
      "10:\tlearn: 0.6501664\ttotal: 411ms\tremaining: 18.3s\n",
      "11:\tlearn: 0.6467579\ttotal: 485ms\tremaining: 19.7s\n",
      "12:\tlearn: 0.6433599\ttotal: 523ms\tremaining: 19.6s\n",
      "13:\tlearn: 0.6401285\ttotal: 546ms\tremaining: 19s\n",
      "14:\tlearn: 0.6365040\ttotal: 567ms\tremaining: 18.3s\n",
      "15:\tlearn: 0.6333208\ttotal: 632ms\tremaining: 19.1s\n",
      "16:\tlearn: 0.6302366\ttotal: 672ms\tremaining: 19.1s\n",
      "17:\tlearn: 0.6266966\ttotal: 711ms\tremaining: 19.1s\n",
      "18:\tlearn: 0.6229112\ttotal: 732ms\tremaining: 18.5s\n",
      "19:\tlearn: 0.6202091\ttotal: 791ms\tremaining: 19s\n",
      "20:\tlearn: 0.6168500\ttotal: 851ms\tremaining: 19.4s\n",
      "21:\tlearn: 0.6134052\ttotal: 877ms\tremaining: 19s\n",
      "22:\tlearn: 0.6107001\ttotal: 900ms\tremaining: 18.7s\n",
      "23:\tlearn: 0.6075502\ttotal: 921ms\tremaining: 18.3s\n",
      "24:\tlearn: 0.6042067\ttotal: 993ms\tremaining: 18.9s\n",
      "25:\tlearn: 0.6014854\ttotal: 1.03s\tremaining: 18.8s\n",
      "26:\tlearn: 0.5974653\ttotal: 1.06s\tremaining: 18.5s\n",
      "27:\tlearn: 0.5942042\ttotal: 1.08s\tremaining: 18.2s\n",
      "28:\tlearn: 0.5915107\ttotal: 1.13s\tremaining: 18.4s\n",
      "29:\tlearn: 0.5888919\ttotal: 1.19s\tremaining: 18.6s\n",
      "30:\tlearn: 0.5859298\ttotal: 1.22s\tremaining: 18.4s\n",
      "31:\tlearn: 0.5830539\ttotal: 1.24s\tremaining: 18.1s\n",
      "32:\tlearn: 0.5802554\ttotal: 1.26s\tremaining: 17.8s\n",
      "33:\tlearn: 0.5778945\ttotal: 1.32s\tremaining: 18.1s\n",
      "34:\tlearn: 0.5752992\ttotal: 1.37s\tremaining: 18.3s\n",
      "35:\tlearn: 0.5723052\ttotal: 1.4s\tremaining: 18.1s\n",
      "36:\tlearn: 0.5696041\ttotal: 1.42s\tremaining: 17.8s\n",
      "37:\tlearn: 0.5665304\ttotal: 1.45s\tremaining: 17.6s\n",
      "38:\tlearn: 0.5637256\ttotal: 1.52s\tremaining: 18s\n",
      "39:\tlearn: 0.5614634\ttotal: 1.56s\tremaining: 18s\n",
      "40:\tlearn: 0.5587316\ttotal: 1.59s\tremaining: 17.8s\n",
      "41:\tlearn: 0.5563418\ttotal: 1.61s\tremaining: 17.6s\n",
      "42:\tlearn: 0.5544290\ttotal: 1.63s\tremaining: 17.4s\n",
      "43:\tlearn: 0.5517311\ttotal: 1.71s\tremaining: 17.7s\n",
      "44:\tlearn: 0.5490529\ttotal: 1.73s\tremaining: 17.5s\n",
      "45:\tlearn: 0.5464382\ttotal: 1.76s\tremaining: 17.3s\n",
      "46:\tlearn: 0.5434201\ttotal: 1.81s\tremaining: 17.5s\n",
      "47:\tlearn: 0.5408863\ttotal: 1.87s\tremaining: 17.6s\n",
      "48:\tlearn: 0.5384203\ttotal: 1.89s\tremaining: 17.4s\n",
      "49:\tlearn: 0.5362731\ttotal: 1.91s\tremaining: 17.2s\n",
      "50:\tlearn: 0.5334447\ttotal: 1.98s\tremaining: 17.5s\n",
      "51:\tlearn: 0.5312925\ttotal: 2.03s\tremaining: 17.5s\n",
      "52:\tlearn: 0.5292739\ttotal: 2.06s\tremaining: 17.3s\n",
      "53:\tlearn: 0.5265623\ttotal: 2.08s\tremaining: 17.1s\n",
      "54:\tlearn: 0.5241375\ttotal: 2.13s\tremaining: 17.2s\n",
      "55:\tlearn: 0.5221453\ttotal: 2.21s\tremaining: 17.5s\n",
      "56:\tlearn: 0.5199183\ttotal: 2.24s\tremaining: 17.4s\n",
      "57:\tlearn: 0.5179586\ttotal: 2.27s\tremaining: 17.3s\n",
      "58:\tlearn: 0.5155095\ttotal: 2.29s\tremaining: 17.1s\n",
      "59:\tlearn: 0.5132008\ttotal: 2.34s\tremaining: 17.2s\n",
      "60:\tlearn: 0.5101468\ttotal: 2.4s\tremaining: 17.2s\n",
      "61:\tlearn: 0.5080201\ttotal: 2.43s\tremaining: 17.2s\n",
      "62:\tlearn: 0.5059300\ttotal: 2.45s\tremaining: 17s\n",
      "63:\tlearn: 0.5032105\ttotal: 2.47s\tremaining: 16.9s\n",
      "64:\tlearn: 0.5011355\ttotal: 2.55s\tremaining: 17.1s\n",
      "65:\tlearn: 0.4989935\ttotal: 2.59s\tremaining: 17s\n",
      "66:\tlearn: 0.4966857\ttotal: 2.62s\tremaining: 16.9s\n",
      "67:\tlearn: 0.4948503\ttotal: 2.64s\tremaining: 16.8s\n",
      "68:\tlearn: 0.4923434\ttotal: 2.69s\tremaining: 16.8s\n",
      "69:\tlearn: 0.4904143\ttotal: 2.75s\tremaining: 16.9s\n",
      "70:\tlearn: 0.4874042\ttotal: 2.78s\tremaining: 16.8s\n",
      "71:\tlearn: 0.4854686\ttotal: 2.81s\tremaining: 16.7s\n",
      "72:\tlearn: 0.4838177\ttotal: 2.83s\tremaining: 16.5s\n",
      "73:\tlearn: 0.4816179\ttotal: 2.86s\tremaining: 16.5s\n",
      "74:\tlearn: 0.4800974\ttotal: 2.92s\tremaining: 16.6s\n",
      "75:\tlearn: 0.4782888\ttotal: 2.96s\tremaining: 16.5s\n",
      "76:\tlearn: 0.4756426\ttotal: 2.98s\tremaining: 16.4s\n",
      "77:\tlearn: 0.4736891\ttotal: 3s\tremaining: 16.2s\n",
      "78:\tlearn: 0.4714274\ttotal: 3.03s\tremaining: 16.1s\n",
      "79:\tlearn: 0.4689420\ttotal: 3.1s\tremaining: 16.3s\n",
      "80:\tlearn: 0.4669018\ttotal: 3.13s\tremaining: 16.2s\n",
      "81:\tlearn: 0.4646180\ttotal: 3.15s\tremaining: 16.1s\n",
      "82:\tlearn: 0.4628219\ttotal: 3.17s\tremaining: 15.9s\n",
      "83:\tlearn: 0.4610472\ttotal: 3.22s\tremaining: 16s\n",
      "84:\tlearn: 0.4591269\ttotal: 3.29s\tremaining: 16.1s\n",
      "85:\tlearn: 0.4571183\ttotal: 3.32s\tremaining: 16s\n",
      "86:\tlearn: 0.4553203\ttotal: 3.34s\tremaining: 15.9s\n",
      "87:\tlearn: 0.4531116\ttotal: 3.36s\tremaining: 15.7s\n",
      "88:\tlearn: 0.4512025\ttotal: 3.43s\tremaining: 15.8s\n",
      "89:\tlearn: 0.4487599\ttotal: 3.48s\tremaining: 15.8s\n",
      "90:\tlearn: 0.4472468\ttotal: 3.5s\tremaining: 15.7s\n",
      "91:\tlearn: 0.4451012\ttotal: 3.52s\tremaining: 15.6s\n",
      "92:\tlearn: 0.4432520\ttotal: 3.54s\tremaining: 15.5s\n",
      "93:\tlearn: 0.4414048\ttotal: 3.62s\tremaining: 15.6s\n",
      "94:\tlearn: 0.4400685\ttotal: 3.66s\tremaining: 15.6s\n",
      "95:\tlearn: 0.4384878\ttotal: 3.68s\tremaining: 15.5s\n",
      "96:\tlearn: 0.4367882\ttotal: 3.7s\tremaining: 15.4s\n",
      "97:\tlearn: 0.4340979\ttotal: 3.73s\tremaining: 15.3s\n",
      "98:\tlearn: 0.4324699\ttotal: 3.8s\tremaining: 15.4s\n",
      "99:\tlearn: 0.4310498\ttotal: 3.83s\tremaining: 15.3s\n",
      "100:\tlearn: 0.4297096\ttotal: 3.86s\tremaining: 15.2s\n",
      "101:\tlearn: 0.4282467\ttotal: 3.88s\tremaining: 15.1s\n",
      "102:\tlearn: 0.4263973\ttotal: 3.93s\tremaining: 15.2s\n",
      "103:\tlearn: 0.4249220\ttotal: 3.99s\tremaining: 15.2s\n",
      "104:\tlearn: 0.4221299\ttotal: 4.02s\tremaining: 15.1s\n",
      "105:\tlearn: 0.4192199\ttotal: 4.04s\tremaining: 15s\n",
      "106:\tlearn: 0.4169934\ttotal: 4.07s\tremaining: 14.9s\n",
      "107:\tlearn: 0.4155952\ttotal: 4.12s\tremaining: 15s\n",
      "108:\tlearn: 0.4142671\ttotal: 4.18s\tremaining: 15s\n",
      "109:\tlearn: 0.4128370\ttotal: 4.21s\tremaining: 14.9s\n",
      "110:\tlearn: 0.4106848\ttotal: 4.23s\tremaining: 14.8s\n",
      "111:\tlearn: 0.4085409\ttotal: 4.25s\tremaining: 14.7s\n",
      "112:\tlearn: 0.4071319\ttotal: 4.32s\tremaining: 14.8s\n",
      "113:\tlearn: 0.4055742\ttotal: 4.36s\tremaining: 14.8s\n",
      "114:\tlearn: 0.4036090\ttotal: 4.38s\tremaining: 14.7s\n",
      "115:\tlearn: 0.4020680\ttotal: 4.41s\tremaining: 14.6s\n",
      "116:\tlearn: 0.4003071\ttotal: 4.43s\tremaining: 14.5s\n",
      "117:\tlearn: 0.3990171\ttotal: 4.5s\tremaining: 14.6s\n",
      "118:\tlearn: 0.3976920\ttotal: 4.54s\tremaining: 14.5s\n",
      "119:\tlearn: 0.3956389\ttotal: 4.56s\tremaining: 14.5s\n",
      "120:\tlearn: 0.3944709\ttotal: 4.58s\tremaining: 14.4s\n",
      "121:\tlearn: 0.3929155\ttotal: 4.6s\tremaining: 14.3s\n",
      "122:\tlearn: 0.3913455\ttotal: 4.68s\tremaining: 14.3s\n",
      "123:\tlearn: 0.3894543\ttotal: 4.72s\tremaining: 14.3s\n",
      "124:\tlearn: 0.3880625\ttotal: 4.75s\tremaining: 14.2s\n",
      "125:\tlearn: 0.3865128\ttotal: 4.77s\tremaining: 14.2s\n",
      "126:\tlearn: 0.3853842\ttotal: 4.82s\tremaining: 14.2s\n",
      "127:\tlearn: 0.3837546\ttotal: 4.88s\tremaining: 14.2s\n",
      "128:\tlearn: 0.3823935\ttotal: 4.91s\tremaining: 14.1s\n",
      "129:\tlearn: 0.3807275\ttotal: 4.93s\tremaining: 14s\n",
      "130:\tlearn: 0.3792922\ttotal: 4.96s\tremaining: 14s\n",
      "131:\tlearn: 0.3779617\ttotal: 5.01s\tremaining: 14s\n",
      "132:\tlearn: 0.3754986\ttotal: 5.05s\tremaining: 13.9s\n",
      "133:\tlearn: 0.3735870\ttotal: 5.07s\tremaining: 13.9s\n",
      "134:\tlearn: 0.3721482\ttotal: 5.1s\tremaining: 13.8s\n",
      "135:\tlearn: 0.3704478\ttotal: 5.17s\tremaining: 13.8s\n",
      "136:\tlearn: 0.3688140\ttotal: 5.21s\tremaining: 13.8s\n",
      "137:\tlearn: 0.3672813\ttotal: 5.24s\tremaining: 13.7s\n",
      "138:\tlearn: 0.3661737\ttotal: 5.26s\tremaining: 13.7s\n",
      "139:\tlearn: 0.3650041\ttotal: 5.31s\tremaining: 13.6s\n",
      "140:\tlearn: 0.3640508\ttotal: 5.38s\tremaining: 13.7s\n",
      "141:\tlearn: 0.3624870\ttotal: 5.41s\tremaining: 13.6s\n",
      "142:\tlearn: 0.3612433\ttotal: 5.42s\tremaining: 13.5s\n",
      "143:\tlearn: 0.3600240\ttotal: 5.45s\tremaining: 13.5s\n",
      "144:\tlearn: 0.3587588\ttotal: 5.5s\tremaining: 13.5s\n",
      "145:\tlearn: 0.3575046\ttotal: 5.55s\tremaining: 13.5s\n",
      "146:\tlearn: 0.3559533\ttotal: 5.59s\tremaining: 13.4s\n",
      "147:\tlearn: 0.3541314\ttotal: 5.61s\tremaining: 13.3s\n",
      "148:\tlearn: 0.3527220\ttotal: 5.63s\tremaining: 13.3s\n",
      "149:\tlearn: 0.3513487\ttotal: 5.7s\tremaining: 13.3s\n",
      "150:\tlearn: 0.3500898\ttotal: 5.75s\tremaining: 13.3s\n",
      "151:\tlearn: 0.3488256\ttotal: 5.77s\tremaining: 13.2s\n",
      "152:\tlearn: 0.3473048\ttotal: 5.79s\tremaining: 13.1s\n",
      "153:\tlearn: 0.3457502\ttotal: 5.86s\tremaining: 13.2s\n",
      "154:\tlearn: 0.3445212\ttotal: 5.92s\tremaining: 13.2s\n",
      "155:\tlearn: 0.3427079\ttotal: 5.95s\tremaining: 13.1s\n",
      "156:\tlearn: 0.3416520\ttotal: 5.97s\tremaining: 13s\n",
      "157:\tlearn: 0.3397548\ttotal: 6.01s\tremaining: 13s\n",
      "158:\tlearn: 0.3384132\ttotal: 6.09s\tremaining: 13.1s\n",
      "159:\tlearn: 0.3368980\ttotal: 6.12s\tremaining: 13s\n",
      "160:\tlearn: 0.3355155\ttotal: 6.14s\tremaining: 12.9s\n",
      "161:\tlearn: 0.3336140\ttotal: 6.16s\tremaining: 12.9s\n",
      "162:\tlearn: 0.3322780\ttotal: 6.23s\tremaining: 12.9s\n",
      "163:\tlearn: 0.3308996\ttotal: 6.28s\tremaining: 12.9s\n",
      "164:\tlearn: 0.3291213\ttotal: 6.3s\tremaining: 12.8s\n",
      "165:\tlearn: 0.3279216\ttotal: 6.33s\tremaining: 12.7s\n",
      "166:\tlearn: 0.3268904\ttotal: 6.34s\tremaining: 12.7s\n",
      "167:\tlearn: 0.3258178\ttotal: 6.42s\tremaining: 12.7s\n",
      "168:\tlearn: 0.3250750\ttotal: 6.46s\tremaining: 12.6s\n",
      "169:\tlearn: 0.3240727\ttotal: 6.48s\tremaining: 12.6s\n",
      "170:\tlearn: 0.3230157\ttotal: 6.5s\tremaining: 12.5s\n",
      "171:\tlearn: 0.3213540\ttotal: 6.57s\tremaining: 12.5s\n",
      "172:\tlearn: 0.3203608\ttotal: 6.63s\tremaining: 12.5s\n",
      "173:\tlearn: 0.3192991\ttotal: 6.65s\tremaining: 12.5s\n",
      "174:\tlearn: 0.3179705\ttotal: 6.67s\tremaining: 12.4s\n",
      "175:\tlearn: 0.3169449\ttotal: 6.7s\tremaining: 12.3s\n",
      "176:\tlearn: 0.3159429\ttotal: 6.77s\tremaining: 12.4s\n",
      "177:\tlearn: 0.3146414\ttotal: 6.81s\tremaining: 12.3s\n",
      "178:\tlearn: 0.3135487\ttotal: 6.84s\tremaining: 12.3s\n",
      "179:\tlearn: 0.3124153\ttotal: 6.86s\tremaining: 12.2s\n",
      "180:\tlearn: 0.3112680\ttotal: 6.92s\tremaining: 12.2s\n",
      "181:\tlearn: 0.3099560\ttotal: 6.97s\tremaining: 12.2s\n",
      "182:\tlearn: 0.3084765\ttotal: 6.99s\tremaining: 12.1s\n",
      "183:\tlearn: 0.3075219\ttotal: 7.01s\tremaining: 12s\n",
      "184:\tlearn: 0.3060776\ttotal: 7.07s\tremaining: 12s\n",
      "185:\tlearn: 0.3049630\ttotal: 7.13s\tremaining: 12s\n",
      "186:\tlearn: 0.3039958\ttotal: 7.16s\tremaining: 12s\n",
      "187:\tlearn: 0.3032887\ttotal: 7.18s\tremaining: 11.9s\n",
      "188:\tlearn: 0.3024421\ttotal: 7.24s\tremaining: 11.9s\n",
      "189:\tlearn: 0.3012491\ttotal: 7.3s\tremaining: 11.9s\n",
      "190:\tlearn: 0.3002153\ttotal: 7.34s\tremaining: 11.9s\n",
      "191:\tlearn: 0.2991522\ttotal: 7.36s\tremaining: 11.8s\n",
      "192:\tlearn: 0.2980339\ttotal: 7.38s\tremaining: 11.7s\n",
      "193:\tlearn: 0.2971076\ttotal: 7.46s\tremaining: 11.8s\n",
      "194:\tlearn: 0.2961783\ttotal: 7.52s\tremaining: 11.8s\n",
      "195:\tlearn: 0.2950963\ttotal: 7.55s\tremaining: 11.7s\n",
      "196:\tlearn: 0.2940679\ttotal: 7.57s\tremaining: 11.6s\n",
      "197:\tlearn: 0.2930912\ttotal: 7.59s\tremaining: 11.6s\n",
      "198:\tlearn: 0.2919714\ttotal: 7.66s\tremaining: 11.6s\n",
      "199:\tlearn: 0.2912234\ttotal: 7.69s\tremaining: 11.5s\n",
      "200:\tlearn: 0.2900874\ttotal: 7.71s\tremaining: 11.5s\n",
      "201:\tlearn: 0.2888767\ttotal: 7.73s\tremaining: 11.4s\n",
      "202:\tlearn: 0.2877902\ttotal: 7.8s\tremaining: 11.4s\n",
      "203:\tlearn: 0.2868626\ttotal: 7.84s\tremaining: 11.4s\n",
      "204:\tlearn: 0.2860016\ttotal: 7.86s\tremaining: 11.3s\n",
      "205:\tlearn: 0.2851617\ttotal: 7.88s\tremaining: 11.2s\n",
      "206:\tlearn: 0.2839390\ttotal: 7.9s\tremaining: 11.2s\n",
      "207:\tlearn: 0.2831089\ttotal: 7.92s\tremaining: 11.1s\n",
      "208:\tlearn: 0.2821345\ttotal: 7.93s\tremaining: 11s\n",
      "209:\tlearn: 0.2811946\ttotal: 7.95s\tremaining: 11s\n",
      "210:\tlearn: 0.2800160\ttotal: 7.96s\tremaining: 10.9s\n",
      "211:\tlearn: 0.2790527\ttotal: 7.99s\tremaining: 10.9s\n",
      "212:\tlearn: 0.2783358\ttotal: 8.02s\tremaining: 10.8s\n",
      "213:\tlearn: 0.2771005\ttotal: 8.05s\tremaining: 10.8s\n",
      "214:\tlearn: 0.2760673\ttotal: 8.07s\tremaining: 10.7s\n",
      "215:\tlearn: 0.2750850\ttotal: 8.1s\tremaining: 10.6s\n",
      "216:\tlearn: 0.2739952\ttotal: 8.17s\tremaining: 10.7s\n",
      "217:\tlearn: 0.2729485\ttotal: 8.2s\tremaining: 10.6s\n",
      "218:\tlearn: 0.2721507\ttotal: 8.23s\tremaining: 10.6s\n",
      "219:\tlearn: 0.2714367\ttotal: 8.25s\tremaining: 10.5s\n",
      "220:\tlearn: 0.2703728\ttotal: 8.3s\tremaining: 10.5s\n",
      "221:\tlearn: 0.2693410\ttotal: 8.36s\tremaining: 10.5s\n",
      "222:\tlearn: 0.2684133\ttotal: 8.41s\tremaining: 10.4s\n",
      "223:\tlearn: 0.2675132\ttotal: 8.43s\tremaining: 10.4s\n",
      "224:\tlearn: 0.2667088\ttotal: 8.48s\tremaining: 10.4s\n",
      "225:\tlearn: 0.2653917\ttotal: 8.54s\tremaining: 10.4s\n",
      "226:\tlearn: 0.2645707\ttotal: 8.56s\tremaining: 10.3s\n",
      "227:\tlearn: 0.2637836\ttotal: 8.59s\tremaining: 10.2s\n",
      "228:\tlearn: 0.2630193\ttotal: 8.61s\tremaining: 10.2s\n",
      "229:\tlearn: 0.2623769\ttotal: 8.69s\tremaining: 10.2s\n",
      "230:\tlearn: 0.2608426\ttotal: 8.72s\tremaining: 10.2s\n",
      "231:\tlearn: 0.2599824\ttotal: 8.75s\tremaining: 10.1s\n",
      "232:\tlearn: 0.2590652\ttotal: 8.77s\tremaining: 10s\n",
      "233:\tlearn: 0.2581130\ttotal: 8.82s\tremaining: 10s\n",
      "234:\tlearn: 0.2569157\ttotal: 8.88s\tremaining: 10s\n",
      "235:\tlearn: 0.2560185\ttotal: 8.91s\tremaining: 9.97s\n",
      "236:\tlearn: 0.2550388\ttotal: 8.94s\tremaining: 9.92s\n",
      "237:\tlearn: 0.2543368\ttotal: 8.96s\tremaining: 9.86s\n",
      "238:\tlearn: 0.2536096\ttotal: 9s\tremaining: 9.83s\n",
      "239:\tlearn: 0.2524201\ttotal: 9.07s\tremaining: 9.82s\n",
      "240:\tlearn: 0.2517193\ttotal: 9.1s\tremaining: 9.78s\n",
      "241:\tlearn: 0.2508852\ttotal: 9.12s\tremaining: 9.72s\n",
      "242:\tlearn: 0.2499925\ttotal: 9.14s\tremaining: 9.67s\n",
      "243:\tlearn: 0.2492518\ttotal: 9.21s\tremaining: 9.66s\n",
      "244:\tlearn: 0.2484083\ttotal: 9.25s\tremaining: 9.63s\n",
      "245:\tlearn: 0.2475124\ttotal: 9.28s\tremaining: 9.58s\n",
      "246:\tlearn: 0.2464944\ttotal: 9.3s\tremaining: 9.52s\n",
      "247:\tlearn: 0.2457064\ttotal: 9.36s\tremaining: 9.51s\n",
      "248:\tlearn: 0.2447157\ttotal: 9.41s\tremaining: 9.49s\n",
      "249:\tlearn: 0.2440484\ttotal: 9.45s\tremaining: 9.45s\n",
      "250:\tlearn: 0.2430086\ttotal: 9.47s\tremaining: 9.39s\n",
      "251:\tlearn: 0.2420294\ttotal: 9.49s\tremaining: 9.34s\n",
      "252:\tlearn: 0.2412036\ttotal: 9.56s\tremaining: 9.33s\n",
      "253:\tlearn: 0.2404886\ttotal: 9.61s\tremaining: 9.3s\n",
      "254:\tlearn: 0.2398094\ttotal: 9.63s\tremaining: 9.26s\n",
      "255:\tlearn: 0.2391795\ttotal: 9.65s\tremaining: 9.2s\n",
      "256:\tlearn: 0.2386334\ttotal: 9.7s\tremaining: 9.17s\n",
      "257:\tlearn: 0.2376592\ttotal: 9.77s\tremaining: 9.16s\n",
      "258:\tlearn: 0.2370037\ttotal: 9.8s\tremaining: 9.12s\n",
      "259:\tlearn: 0.2362616\ttotal: 9.83s\tremaining: 9.08s\n",
      "260:\tlearn: 0.2355803\ttotal: 9.86s\tremaining: 9.02s\n",
      "261:\tlearn: 0.2346979\ttotal: 9.9s\tremaining: 8.99s\n",
      "262:\tlearn: 0.2339602\ttotal: 9.97s\tremaining: 8.98s\n",
      "263:\tlearn: 0.2333252\ttotal: 10s\tremaining: 8.94s\n",
      "264:\tlearn: 0.2327300\ttotal: 10s\tremaining: 8.89s\n",
      "265:\tlearn: 0.2321486\ttotal: 10s\tremaining: 8.84s\n",
      "266:\tlearn: 0.2316267\ttotal: 10.1s\tremaining: 8.83s\n",
      "267:\tlearn: 0.2310477\ttotal: 10.2s\tremaining: 8.8s\n",
      "268:\tlearn: 0.2303589\ttotal: 10.2s\tremaining: 8.75s\n",
      "269:\tlearn: 0.2296952\ttotal: 10.2s\tremaining: 8.7s\n",
      "270:\tlearn: 0.2291284\ttotal: 10.3s\tremaining: 8.67s\n",
      "271:\tlearn: 0.2285163\ttotal: 10.3s\tremaining: 8.65s\n",
      "272:\tlearn: 0.2280737\ttotal: 10.4s\tremaining: 8.61s\n",
      "273:\tlearn: 0.2272363\ttotal: 10.4s\tremaining: 8.56s\n",
      "274:\tlearn: 0.2268626\ttotal: 10.4s\tremaining: 8.51s\n",
      "275:\tlearn: 0.2259646\ttotal: 10.5s\tremaining: 8.48s\n",
      "276:\tlearn: 0.2253229\ttotal: 10.5s\tremaining: 8.46s\n",
      "277:\tlearn: 0.2246089\ttotal: 10.5s\tremaining: 8.41s\n",
      "278:\tlearn: 0.2234988\ttotal: 10.6s\tremaining: 8.36s\n",
      "279:\tlearn: 0.2227211\ttotal: 10.6s\tremaining: 8.32s\n",
      "280:\tlearn: 0.2217716\ttotal: 10.7s\tremaining: 8.3s\n",
      "281:\tlearn: 0.2208785\ttotal: 10.7s\tremaining: 8.26s\n",
      "282:\tlearn: 0.2200173\ttotal: 10.7s\tremaining: 8.21s\n",
      "283:\tlearn: 0.2192847\ttotal: 10.7s\tremaining: 8.16s\n",
      "284:\tlearn: 0.2185849\ttotal: 10.8s\tremaining: 8.15s\n",
      "285:\tlearn: 0.2178157\ttotal: 10.8s\tremaining: 8.11s\n",
      "286:\tlearn: 0.2168821\ttotal: 10.9s\tremaining: 8.07s\n",
      "287:\tlearn: 0.2157576\ttotal: 10.9s\tremaining: 8.02s\n",
      "288:\tlearn: 0.2150207\ttotal: 11s\tremaining: 8s\n",
      "289:\tlearn: 0.2143265\ttotal: 11s\tremaining: 7.97s\n",
      "290:\tlearn: 0.2133142\ttotal: 11s\tremaining: 7.93s\n",
      "291:\tlearn: 0.2127090\ttotal: 11.1s\tremaining: 7.88s\n",
      "292:\tlearn: 0.2119708\ttotal: 11.1s\tremaining: 7.83s\n",
      "293:\tlearn: 0.2112485\ttotal: 11.2s\tremaining: 7.81s\n",
      "294:\tlearn: 0.2102719\ttotal: 11.2s\tremaining: 7.78s\n",
      "295:\tlearn: 0.2096550\ttotal: 11.2s\tremaining: 7.73s\n",
      "296:\tlearn: 0.2090144\ttotal: 11.2s\tremaining: 7.68s\n",
      "297:\tlearn: 0.2084011\ttotal: 11.3s\tremaining: 7.66s\n",
      "298:\tlearn: 0.2074783\ttotal: 11.4s\tremaining: 7.64s\n",
      "299:\tlearn: 0.2066590\ttotal: 11.4s\tremaining: 7.59s\n",
      "300:\tlearn: 0.2059660\ttotal: 11.4s\tremaining: 7.54s\n",
      "301:\tlearn: 0.2054230\ttotal: 11.4s\tremaining: 7.5s\n",
      "302:\tlearn: 0.2048811\ttotal: 11.5s\tremaining: 7.48s\n",
      "303:\tlearn: 0.2040587\ttotal: 11.5s\tremaining: 7.44s\n",
      "304:\tlearn: 0.2032162\ttotal: 11.6s\tremaining: 7.4s\n",
      "305:\tlearn: 0.2025939\ttotal: 11.6s\tremaining: 7.35s\n",
      "306:\tlearn: 0.2018109\ttotal: 11.7s\tremaining: 7.33s\n",
      "307:\tlearn: 0.2010320\ttotal: 11.7s\tremaining: 7.3s\n",
      "308:\tlearn: 0.2005875\ttotal: 11.7s\tremaining: 7.26s\n",
      "309:\tlearn: 0.1999537\ttotal: 11.8s\tremaining: 7.21s\n",
      "310:\tlearn: 0.1992082\ttotal: 11.8s\tremaining: 7.16s\n",
      "311:\tlearn: 0.1984446\ttotal: 11.9s\tremaining: 7.15s\n",
      "312:\tlearn: 0.1978445\ttotal: 11.9s\tremaining: 7.11s\n",
      "313:\tlearn: 0.1974098\ttotal: 11.9s\tremaining: 7.07s\n",
      "314:\tlearn: 0.1969598\ttotal: 12s\tremaining: 7.02s\n",
      "315:\tlearn: 0.1965586\ttotal: 12s\tremaining: 6.98s\n",
      "316:\tlearn: 0.1957769\ttotal: 12.1s\tremaining: 6.96s\n",
      "317:\tlearn: 0.1946779\ttotal: 12.1s\tremaining: 6.93s\n",
      "318:\tlearn: 0.1938650\ttotal: 12.1s\tremaining: 6.88s\n",
      "319:\tlearn: 0.1934375\ttotal: 12.2s\tremaining: 6.87s\n",
      "320:\tlearn: 0.1927119\ttotal: 12.2s\tremaining: 6.83s\n",
      "321:\tlearn: 0.1919290\ttotal: 12.3s\tremaining: 6.78s\n",
      "322:\tlearn: 0.1913697\ttotal: 12.3s\tremaining: 6.73s\n",
      "323:\tlearn: 0.1906583\ttotal: 12.3s\tremaining: 6.69s\n",
      "324:\tlearn: 0.1900337\ttotal: 12.4s\tremaining: 6.67s\n",
      "325:\tlearn: 0.1895481\ttotal: 12.4s\tremaining: 6.63s\n",
      "326:\tlearn: 0.1889371\ttotal: 12.5s\tremaining: 6.59s\n",
      "327:\tlearn: 0.1883018\ttotal: 12.5s\tremaining: 6.54s\n",
      "328:\tlearn: 0.1876033\ttotal: 12.5s\tremaining: 6.49s\n",
      "329:\tlearn: 0.1871776\ttotal: 12.5s\tremaining: 6.46s\n",
      "330:\tlearn: 0.1866460\ttotal: 12.6s\tremaining: 6.44s\n",
      "331:\tlearn: 0.1862105\ttotal: 12.6s\tremaining: 6.4s\n",
      "332:\tlearn: 0.1856565\ttotal: 12.7s\tremaining: 6.35s\n",
      "333:\tlearn: 0.1849572\ttotal: 12.7s\tremaining: 6.31s\n",
      "334:\tlearn: 0.1844157\ttotal: 12.8s\tremaining: 6.29s\n",
      "335:\tlearn: 0.1840068\ttotal: 12.8s\tremaining: 6.25s\n",
      "336:\tlearn: 0.1835643\ttotal: 12.8s\tremaining: 6.21s\n",
      "337:\tlearn: 0.1831193\ttotal: 12.9s\tremaining: 6.16s\n",
      "338:\tlearn: 0.1822561\ttotal: 12.9s\tremaining: 6.13s\n",
      "339:\tlearn: 0.1815937\ttotal: 13s\tremaining: 6.1s\n",
      "340:\tlearn: 0.1810895\ttotal: 13s\tremaining: 6.06s\n",
      "341:\tlearn: 0.1803132\ttotal: 13s\tremaining: 6.01s\n",
      "342:\tlearn: 0.1798534\ttotal: 13s\tremaining: 5.97s\n",
      "343:\tlearn: 0.1794368\ttotal: 13.1s\tremaining: 5.95s\n",
      "344:\tlearn: 0.1789283\ttotal: 13.1s\tremaining: 5.9s\n",
      "345:\tlearn: 0.1780409\ttotal: 13.2s\tremaining: 5.86s\n",
      "346:\tlearn: 0.1777088\ttotal: 13.2s\tremaining: 5.81s\n",
      "347:\tlearn: 0.1769731\ttotal: 13.3s\tremaining: 5.79s\n",
      "348:\tlearn: 0.1765214\ttotal: 13.3s\tremaining: 5.75s\n",
      "349:\tlearn: 0.1760257\ttotal: 13.3s\tremaining: 5.71s\n",
      "350:\tlearn: 0.1753982\ttotal: 13.4s\tremaining: 5.67s\n",
      "351:\tlearn: 0.1749644\ttotal: 13.4s\tremaining: 5.64s\n",
      "352:\tlearn: 0.1742462\ttotal: 13.5s\tremaining: 5.6s\n",
      "353:\tlearn: 0.1736270\ttotal: 13.5s\tremaining: 5.56s\n",
      "354:\tlearn: 0.1733331\ttotal: 13.5s\tremaining: 5.51s\n",
      "355:\tlearn: 0.1726990\ttotal: 13.6s\tremaining: 5.48s\n",
      "356:\tlearn: 0.1722331\ttotal: 13.6s\tremaining: 5.46s\n",
      "357:\tlearn: 0.1717976\ttotal: 13.6s\tremaining: 5.41s\n",
      "358:\tlearn: 0.1713012\ttotal: 13.7s\tremaining: 5.37s\n",
      "359:\tlearn: 0.1708115\ttotal: 13.7s\tremaining: 5.33s\n",
      "360:\tlearn: 0.1704095\ttotal: 13.8s\tremaining: 5.3s\n",
      "361:\tlearn: 0.1698582\ttotal: 13.8s\tremaining: 5.27s\n",
      "362:\tlearn: 0.1695021\ttotal: 13.8s\tremaining: 5.22s\n",
      "363:\tlearn: 0.1690207\ttotal: 13.9s\tremaining: 5.18s\n",
      "364:\tlearn: 0.1684567\ttotal: 13.9s\tremaining: 5.14s\n",
      "365:\tlearn: 0.1679669\ttotal: 14s\tremaining: 5.11s\n",
      "366:\tlearn: 0.1675850\ttotal: 14s\tremaining: 5.08s\n",
      "367:\tlearn: 0.1671109\ttotal: 14s\tremaining: 5.03s\n",
      "368:\tlearn: 0.1666500\ttotal: 14.1s\tremaining: 4.99s\n",
      "369:\tlearn: 0.1659775\ttotal: 14.1s\tremaining: 4.96s\n",
      "370:\tlearn: 0.1655374\ttotal: 14.2s\tremaining: 4.93s\n",
      "371:\tlearn: 0.1650597\ttotal: 14.2s\tremaining: 4.88s\n",
      "372:\tlearn: 0.1642661\ttotal: 14.2s\tremaining: 4.84s\n",
      "373:\tlearn: 0.1637192\ttotal: 14.2s\tremaining: 4.8s\n",
      "374:\tlearn: 0.1634163\ttotal: 14.3s\tremaining: 4.77s\n",
      "375:\tlearn: 0.1627448\ttotal: 14.4s\tremaining: 4.74s\n",
      "376:\tlearn: 0.1622302\ttotal: 14.4s\tremaining: 4.69s\n",
      "377:\tlearn: 0.1616198\ttotal: 14.4s\tremaining: 4.65s\n",
      "378:\tlearn: 0.1610378\ttotal: 14.4s\tremaining: 4.61s\n",
      "379:\tlearn: 0.1605820\ttotal: 14.5s\tremaining: 4.58s\n",
      "380:\tlearn: 0.1602547\ttotal: 14.5s\tremaining: 4.54s\n",
      "381:\tlearn: 0.1595224\ttotal: 14.6s\tremaining: 4.5s\n",
      "382:\tlearn: 0.1590424\ttotal: 14.6s\tremaining: 4.46s\n",
      "383:\tlearn: 0.1584473\ttotal: 14.6s\tremaining: 4.41s\n",
      "384:\tlearn: 0.1578868\ttotal: 14.7s\tremaining: 4.39s\n",
      "385:\tlearn: 0.1574515\ttotal: 14.7s\tremaining: 4.35s\n",
      "386:\tlearn: 0.1567446\ttotal: 14.7s\tremaining: 4.3s\n",
      "387:\tlearn: 0.1560108\ttotal: 14.8s\tremaining: 4.26s\n",
      "388:\tlearn: 0.1554538\ttotal: 14.8s\tremaining: 4.24s\n",
      "389:\tlearn: 0.1551103\ttotal: 14.9s\tremaining: 4.2s\n",
      "390:\tlearn: 0.1548025\ttotal: 14.9s\tremaining: 4.16s\n",
      "391:\tlearn: 0.1544023\ttotal: 14.9s\tremaining: 4.12s\n",
      "392:\tlearn: 0.1538007\ttotal: 15s\tremaining: 4.08s\n",
      "393:\tlearn: 0.1534846\ttotal: 15s\tremaining: 4.05s\n",
      "394:\tlearn: 0.1530733\ttotal: 15.1s\tremaining: 4.01s\n",
      "395:\tlearn: 0.1524650\ttotal: 15.1s\tremaining: 3.96s\n",
      "396:\tlearn: 0.1519734\ttotal: 15.1s\tremaining: 3.92s\n",
      "397:\tlearn: 0.1516505\ttotal: 15.1s\tremaining: 3.88s\n",
      "398:\tlearn: 0.1511940\ttotal: 15.2s\tremaining: 3.85s\n",
      "399:\tlearn: 0.1509054\ttotal: 15.3s\tremaining: 3.81s\n",
      "400:\tlearn: 0.1504675\ttotal: 15.3s\tremaining: 3.77s\n",
      "401:\tlearn: 0.1500269\ttotal: 15.3s\tremaining: 3.73s\n",
      "402:\tlearn: 0.1496908\ttotal: 15.4s\tremaining: 3.7s\n",
      "403:\tlearn: 0.1492205\ttotal: 15.4s\tremaining: 3.66s\n",
      "404:\tlearn: 0.1487574\ttotal: 15.5s\tremaining: 3.63s\n",
      "405:\tlearn: 0.1484181\ttotal: 15.5s\tremaining: 3.58s\n",
      "406:\tlearn: 0.1479324\ttotal: 15.5s\tremaining: 3.54s\n",
      "407:\tlearn: 0.1475344\ttotal: 15.6s\tremaining: 3.51s\n",
      "408:\tlearn: 0.1470197\ttotal: 15.6s\tremaining: 3.47s\n",
      "409:\tlearn: 0.1465206\ttotal: 15.6s\tremaining: 3.43s\n",
      "410:\tlearn: 0.1460754\ttotal: 15.7s\tremaining: 3.39s\n",
      "411:\tlearn: 0.1455765\ttotal: 15.7s\tremaining: 3.35s\n",
      "412:\tlearn: 0.1451173\ttotal: 15.8s\tremaining: 3.32s\n",
      "413:\tlearn: 0.1445541\ttotal: 15.8s\tremaining: 3.28s\n",
      "414:\tlearn: 0.1440636\ttotal: 15.8s\tremaining: 3.24s\n",
      "415:\tlearn: 0.1436091\ttotal: 15.8s\tremaining: 3.2s\n",
      "416:\tlearn: 0.1432788\ttotal: 15.9s\tremaining: 3.16s\n",
      "417:\tlearn: 0.1429306\ttotal: 15.9s\tremaining: 3.13s\n",
      "418:\tlearn: 0.1425400\ttotal: 16s\tremaining: 3.09s\n",
      "419:\tlearn: 0.1420083\ttotal: 16s\tremaining: 3.05s\n",
      "420:\tlearn: 0.1415587\ttotal: 16s\tremaining: 3.01s\n",
      "421:\tlearn: 0.1412513\ttotal: 16.1s\tremaining: 2.97s\n",
      "422:\tlearn: 0.1408974\ttotal: 16.1s\tremaining: 2.94s\n",
      "423:\tlearn: 0.1402222\ttotal: 16.2s\tremaining: 2.9s\n",
      "424:\tlearn: 0.1399417\ttotal: 16.2s\tremaining: 2.86s\n",
      "425:\tlearn: 0.1394691\ttotal: 16.2s\tremaining: 2.81s\n",
      "426:\tlearn: 0.1390261\ttotal: 16.3s\tremaining: 2.78s\n",
      "427:\tlearn: 0.1385502\ttotal: 16.3s\tremaining: 2.75s\n",
      "428:\tlearn: 0.1380029\ttotal: 16.4s\tremaining: 2.71s\n",
      "429:\tlearn: 0.1375808\ttotal: 16.4s\tremaining: 2.67s\n",
      "430:\tlearn: 0.1372321\ttotal: 16.4s\tremaining: 2.63s\n",
      "431:\tlearn: 0.1366928\ttotal: 16.5s\tremaining: 2.6s\n",
      "432:\tlearn: 0.1363915\ttotal: 16.5s\tremaining: 2.56s\n",
      "433:\tlearn: 0.1359184\ttotal: 16.6s\tremaining: 2.52s\n",
      "434:\tlearn: 0.1355288\ttotal: 16.6s\tremaining: 2.48s\n",
      "435:\tlearn: 0.1350339\ttotal: 16.6s\tremaining: 2.44s\n",
      "436:\tlearn: 0.1346394\ttotal: 16.7s\tremaining: 2.4s\n",
      "437:\tlearn: 0.1342904\ttotal: 16.7s\tremaining: 2.36s\n",
      "438:\tlearn: 0.1339330\ttotal: 16.7s\tremaining: 2.32s\n",
      "439:\tlearn: 0.1335139\ttotal: 16.8s\tremaining: 2.29s\n",
      "440:\tlearn: 0.1331348\ttotal: 16.8s\tremaining: 2.25s\n",
      "441:\tlearn: 0.1327845\ttotal: 16.9s\tremaining: 2.21s\n",
      "442:\tlearn: 0.1323843\ttotal: 16.9s\tremaining: 2.17s\n",
      "443:\tlearn: 0.1320223\ttotal: 16.9s\tremaining: 2.13s\n",
      "444:\tlearn: 0.1316395\ttotal: 17s\tremaining: 2.1s\n",
      "445:\tlearn: 0.1313926\ttotal: 17s\tremaining: 2.06s\n",
      "446:\tlearn: 0.1309744\ttotal: 17s\tremaining: 2.02s\n",
      "447:\tlearn: 0.1306289\ttotal: 17.1s\tremaining: 1.98s\n",
      "448:\tlearn: 0.1302808\ttotal: 17.1s\tremaining: 1.95s\n",
      "449:\tlearn: 0.1298681\ttotal: 17.2s\tremaining: 1.91s\n",
      "450:\tlearn: 0.1294736\ttotal: 17.2s\tremaining: 1.87s\n",
      "451:\tlearn: 0.1291419\ttotal: 17.2s\tremaining: 1.83s\n",
      "452:\tlearn: 0.1286438\ttotal: 17.3s\tremaining: 1.79s\n",
      "453:\tlearn: 0.1283923\ttotal: 17.4s\tremaining: 1.76s\n",
      "454:\tlearn: 0.1279656\ttotal: 17.4s\tremaining: 1.72s\n",
      "455:\tlearn: 0.1275082\ttotal: 17.4s\tremaining: 1.68s\n",
      "456:\tlearn: 0.1271102\ttotal: 17.4s\tremaining: 1.64s\n",
      "457:\tlearn: 0.1267364\ttotal: 17.5s\tremaining: 1.61s\n",
      "458:\tlearn: 0.1263065\ttotal: 17.6s\tremaining: 1.57s\n",
      "459:\tlearn: 0.1259426\ttotal: 17.6s\tremaining: 1.53s\n",
      "460:\tlearn: 0.1256061\ttotal: 17.6s\tremaining: 1.49s\n",
      "461:\tlearn: 0.1253595\ttotal: 17.6s\tremaining: 1.45s\n",
      "462:\tlearn: 0.1250161\ttotal: 17.7s\tremaining: 1.42s\n",
      "463:\tlearn: 0.1247015\ttotal: 17.8s\tremaining: 1.38s\n",
      "464:\tlearn: 0.1243878\ttotal: 17.8s\tremaining: 1.34s\n",
      "465:\tlearn: 0.1239037\ttotal: 17.8s\tremaining: 1.3s\n",
      "466:\tlearn: 0.1235872\ttotal: 17.9s\tremaining: 1.26s\n",
      "467:\tlearn: 0.1233708\ttotal: 17.9s\tremaining: 1.23s\n",
      "468:\tlearn: 0.1231435\ttotal: 17.9s\tremaining: 1.19s\n",
      "469:\tlearn: 0.1226008\ttotal: 18s\tremaining: 1.15s\n",
      "470:\tlearn: 0.1222374\ttotal: 18s\tremaining: 1.11s\n",
      "471:\tlearn: 0.1219104\ttotal: 18.1s\tremaining: 1.07s\n",
      "472:\tlearn: 0.1215360\ttotal: 18.1s\tremaining: 1.03s\n",
      "473:\tlearn: 0.1211912\ttotal: 18.1s\tremaining: 993ms\n",
      "474:\tlearn: 0.1208056\ttotal: 18.1s\tremaining: 954ms\n",
      "475:\tlearn: 0.1204393\ttotal: 18.2s\tremaining: 916ms\n",
      "476:\tlearn: 0.1199339\ttotal: 18.2s\tremaining: 877ms\n",
      "477:\tlearn: 0.1196336\ttotal: 18.2s\tremaining: 839ms\n",
      "478:\tlearn: 0.1191612\ttotal: 18.3s\tremaining: 800ms\n",
      "479:\tlearn: 0.1188533\ttotal: 18.3s\tremaining: 761ms\n",
      "480:\tlearn: 0.1186212\ttotal: 18.3s\tremaining: 724ms\n",
      "481:\tlearn: 0.1182596\ttotal: 18.4s\tremaining: 687ms\n",
      "482:\tlearn: 0.1178324\ttotal: 18.4s\tremaining: 648ms\n",
      "483:\tlearn: 0.1173178\ttotal: 18.4s\tremaining: 610ms\n",
      "484:\tlearn: 0.1170836\ttotal: 18.5s\tremaining: 571ms\n",
      "485:\tlearn: 0.1167270\ttotal: 18.5s\tremaining: 534ms\n",
      "486:\tlearn: 0.1164703\ttotal: 18.6s\tremaining: 496ms\n",
      "487:\tlearn: 0.1161288\ttotal: 18.6s\tremaining: 458ms\n",
      "488:\tlearn: 0.1157415\ttotal: 18.6s\tremaining: 419ms\n",
      "489:\tlearn: 0.1154046\ttotal: 18.7s\tremaining: 382ms\n",
      "490:\tlearn: 0.1150518\ttotal: 18.7s\tremaining: 344ms\n",
      "491:\tlearn: 0.1148358\ttotal: 18.8s\tremaining: 305ms\n",
      "492:\tlearn: 0.1145168\ttotal: 18.8s\tremaining: 267ms\n",
      "493:\tlearn: 0.1142561\ttotal: 18.8s\tremaining: 229ms\n",
      "494:\tlearn: 0.1139515\ttotal: 18.9s\tremaining: 191ms\n",
      "495:\tlearn: 0.1135938\ttotal: 18.9s\tremaining: 153ms\n",
      "496:\tlearn: 0.1132318\ttotal: 19s\tremaining: 114ms\n",
      "497:\tlearn: 0.1129005\ttotal: 19s\tremaining: 76.3ms\n",
      "498:\tlearn: 0.1126211\ttotal: 19.1s\tremaining: 38.3ms\n",
      "499:\tlearn: 0.1123226\ttotal: 19.1s\tremaining: 0us\n",
      "0:\tlearn: 0.6900250\ttotal: 29ms\tremaining: 14.5s\n",
      "1:\tlearn: 0.6862612\ttotal: 131ms\tremaining: 32.6s\n",
      "2:\tlearn: 0.6826142\ttotal: 173ms\tremaining: 28.6s\n",
      "3:\tlearn: 0.6784331\ttotal: 193ms\tremaining: 23.9s\n",
      "4:\tlearn: 0.6750512\ttotal: 288ms\tremaining: 28.5s\n",
      "5:\tlearn: 0.6715387\ttotal: 306ms\tremaining: 25.2s\n",
      "6:\tlearn: 0.6680669\ttotal: 324ms\tremaining: 22.9s\n",
      "7:\tlearn: 0.6642728\ttotal: 343ms\tremaining: 21.1s\n",
      "8:\tlearn: 0.6611616\ttotal: 362ms\tremaining: 19.7s\n",
      "9:\tlearn: 0.6577551\ttotal: 380ms\tremaining: 18.6s\n",
      "10:\tlearn: 0.6537612\ttotal: 401ms\tremaining: 17.8s\n",
      "11:\tlearn: 0.6502737\ttotal: 423ms\tremaining: 17.2s\n",
      "12:\tlearn: 0.6470567\ttotal: 444ms\tremaining: 16.6s\n",
      "13:\tlearn: 0.6440248\ttotal: 468ms\tremaining: 16.2s\n",
      "14:\tlearn: 0.6402537\ttotal: 505ms\tremaining: 16.3s\n",
      "15:\tlearn: 0.6370123\ttotal: 545ms\tremaining: 16.5s\n",
      "16:\tlearn: 0.6337346\ttotal: 569ms\tremaining: 16.2s\n",
      "17:\tlearn: 0.6298313\ttotal: 611ms\tremaining: 16.4s\n",
      "18:\tlearn: 0.6267193\ttotal: 678ms\tremaining: 17.2s\n",
      "19:\tlearn: 0.6239046\ttotal: 710ms\tremaining: 17s\n",
      "20:\tlearn: 0.6206747\ttotal: 735ms\tremaining: 16.8s\n",
      "21:\tlearn: 0.6165043\ttotal: 756ms\tremaining: 16.4s\n",
      "22:\tlearn: 0.6129755\ttotal: 811ms\tremaining: 16.8s\n",
      "23:\tlearn: 0.6094269\ttotal: 871ms\tremaining: 17.3s\n",
      "24:\tlearn: 0.6063545\ttotal: 903ms\tremaining: 17.1s\n",
      "25:\tlearn: 0.6027189\ttotal: 925ms\tremaining: 16.9s\n",
      "26:\tlearn: 0.5994362\ttotal: 970ms\tremaining: 17s\n",
      "27:\tlearn: 0.5967690\ttotal: 1.03s\tremaining: 17.5s\n",
      "28:\tlearn: 0.5937014\ttotal: 1.07s\tremaining: 17.4s\n",
      "29:\tlearn: 0.5909275\ttotal: 1.09s\tremaining: 17.1s\n",
      "30:\tlearn: 0.5883039\ttotal: 1.12s\tremaining: 16.9s\n",
      "31:\tlearn: 0.5855310\ttotal: 1.19s\tremaining: 17.3s\n",
      "32:\tlearn: 0.5831630\ttotal: 1.23s\tremaining: 17.4s\n",
      "33:\tlearn: 0.5803676\ttotal: 1.25s\tremaining: 17.2s\n",
      "34:\tlearn: 0.5782535\ttotal: 1.27s\tremaining: 16.9s\n",
      "35:\tlearn: 0.5754152\ttotal: 1.3s\tremaining: 16.7s\n",
      "36:\tlearn: 0.5734288\ttotal: 1.33s\tremaining: 16.6s\n",
      "37:\tlearn: 0.5705461\ttotal: 1.4s\tremaining: 17s\n",
      "38:\tlearn: 0.5676373\ttotal: 1.43s\tremaining: 17s\n",
      "39:\tlearn: 0.5655968\ttotal: 1.46s\tremaining: 16.8s\n",
      "40:\tlearn: 0.5627359\ttotal: 1.48s\tremaining: 16.6s\n",
      "41:\tlearn: 0.5594877\ttotal: 1.53s\tremaining: 16.7s\n",
      "42:\tlearn: 0.5566411\ttotal: 1.59s\tremaining: 16.9s\n",
      "43:\tlearn: 0.5536842\ttotal: 1.62s\tremaining: 16.8s\n",
      "44:\tlearn: 0.5514053\ttotal: 1.64s\tremaining: 16.6s\n",
      "45:\tlearn: 0.5494453\ttotal: 1.66s\tremaining: 16.4s\n",
      "46:\tlearn: 0.5464597\ttotal: 1.73s\tremaining: 16.7s\n",
      "47:\tlearn: 0.5439447\ttotal: 1.77s\tremaining: 16.6s\n",
      "48:\tlearn: 0.5424003\ttotal: 1.79s\tremaining: 16.5s\n",
      "49:\tlearn: 0.5400602\ttotal: 1.81s\tremaining: 16.3s\n",
      "50:\tlearn: 0.5374913\ttotal: 1.88s\tremaining: 16.6s\n",
      "51:\tlearn: 0.5350999\ttotal: 1.93s\tremaining: 16.6s\n",
      "52:\tlearn: 0.5326562\ttotal: 1.96s\tremaining: 16.5s\n",
      "53:\tlearn: 0.5304183\ttotal: 1.98s\tremaining: 16.3s\n",
      "54:\tlearn: 0.5280754\ttotal: 2.02s\tremaining: 16.3s\n",
      "55:\tlearn: 0.5255884\ttotal: 2.09s\tremaining: 16.6s\n",
      "56:\tlearn: 0.5234767\ttotal: 2.12s\tremaining: 16.5s\n",
      "57:\tlearn: 0.5215933\ttotal: 2.15s\tremaining: 16.4s\n",
      "58:\tlearn: 0.5188331\ttotal: 2.17s\tremaining: 16.2s\n",
      "59:\tlearn: 0.5167329\ttotal: 2.24s\tremaining: 16.4s\n",
      "60:\tlearn: 0.5136677\ttotal: 2.29s\tremaining: 16.5s\n",
      "61:\tlearn: 0.5112679\ttotal: 2.31s\tremaining: 16.4s\n",
      "62:\tlearn: 0.5086984\ttotal: 2.33s\tremaining: 16.2s\n",
      "63:\tlearn: 0.5068206\ttotal: 2.39s\tremaining: 16.3s\n",
      "64:\tlearn: 0.5044883\ttotal: 2.45s\tremaining: 16.4s\n",
      "65:\tlearn: 0.5023515\ttotal: 2.48s\tremaining: 16.3s\n",
      "66:\tlearn: 0.5000414\ttotal: 2.5s\tremaining: 16.2s\n",
      "67:\tlearn: 0.4983253\ttotal: 2.52s\tremaining: 16s\n",
      "68:\tlearn: 0.4947978\ttotal: 2.6s\tremaining: 16.2s\n",
      "69:\tlearn: 0.4924081\ttotal: 2.63s\tremaining: 16.1s\n",
      "70:\tlearn: 0.4902395\ttotal: 2.65s\tremaining: 16s\n",
      "71:\tlearn: 0.4883680\ttotal: 2.67s\tremaining: 15.9s\n",
      "72:\tlearn: 0.4860636\ttotal: 2.73s\tremaining: 16s\n",
      "73:\tlearn: 0.4842782\ttotal: 2.78s\tremaining: 16s\n",
      "74:\tlearn: 0.4826500\ttotal: 2.81s\tremaining: 15.9s\n",
      "75:\tlearn: 0.4802057\ttotal: 2.83s\tremaining: 15.8s\n",
      "76:\tlearn: 0.4778620\ttotal: 2.85s\tremaining: 15.7s\n",
      "77:\tlearn: 0.4751484\ttotal: 2.92s\tremaining: 15.8s\n",
      "78:\tlearn: 0.4723379\ttotal: 2.97s\tremaining: 15.8s\n",
      "79:\tlearn: 0.4700795\ttotal: 2.99s\tremaining: 15.7s\n",
      "80:\tlearn: 0.4680941\ttotal: 3.02s\tremaining: 15.6s\n",
      "81:\tlearn: 0.4657403\ttotal: 3.08s\tremaining: 15.7s\n",
      "82:\tlearn: 0.4640560\ttotal: 3.13s\tremaining: 15.7s\n",
      "83:\tlearn: 0.4621438\ttotal: 3.16s\tremaining: 15.7s\n",
      "84:\tlearn: 0.4600259\ttotal: 3.18s\tremaining: 15.5s\n",
      "85:\tlearn: 0.4578578\ttotal: 3.21s\tremaining: 15.4s\n",
      "86:\tlearn: 0.4560439\ttotal: 3.28s\tremaining: 15.6s\n",
      "87:\tlearn: 0.4540883\ttotal: 3.33s\tremaining: 15.6s\n",
      "88:\tlearn: 0.4522952\ttotal: 3.35s\tremaining: 15.5s\n",
      "89:\tlearn: 0.4505404\ttotal: 3.37s\tremaining: 15.4s\n",
      "90:\tlearn: 0.4487328\ttotal: 3.39s\tremaining: 15.2s\n",
      "91:\tlearn: 0.4464331\ttotal: 3.47s\tremaining: 15.4s\n",
      "92:\tlearn: 0.4445819\ttotal: 3.5s\tremaining: 15.3s\n",
      "93:\tlearn: 0.4427262\ttotal: 3.53s\tremaining: 15.3s\n",
      "94:\tlearn: 0.4411158\ttotal: 3.55s\tremaining: 15.1s\n",
      "95:\tlearn: 0.4396067\ttotal: 3.63s\tremaining: 15.3s\n",
      "96:\tlearn: 0.4380233\ttotal: 3.67s\tremaining: 15.3s\n",
      "97:\tlearn: 0.4361488\ttotal: 3.7s\tremaining: 15.2s\n",
      "98:\tlearn: 0.4348708\ttotal: 3.72s\tremaining: 15.1s\n",
      "99:\tlearn: 0.4332002\ttotal: 3.74s\tremaining: 15s\n",
      "100:\tlearn: 0.4317665\ttotal: 3.81s\tremaining: 15.1s\n",
      "101:\tlearn: 0.4304992\ttotal: 3.86s\tremaining: 15s\n",
      "102:\tlearn: 0.4284429\ttotal: 3.88s\tremaining: 15s\n",
      "103:\tlearn: 0.4266293\ttotal: 3.91s\tremaining: 14.9s\n",
      "104:\tlearn: 0.4246702\ttotal: 3.98s\tremaining: 15s\n",
      "105:\tlearn: 0.4225240\ttotal: 4.01s\tremaining: 14.9s\n",
      "106:\tlearn: 0.4206569\ttotal: 4.04s\tremaining: 14.8s\n",
      "107:\tlearn: 0.4192241\ttotal: 4.06s\tremaining: 14.7s\n",
      "108:\tlearn: 0.4179691\ttotal: 4.12s\tremaining: 14.8s\n",
      "109:\tlearn: 0.4162948\ttotal: 4.17s\tremaining: 14.8s\n",
      "110:\tlearn: 0.4143071\ttotal: 4.19s\tremaining: 14.7s\n",
      "111:\tlearn: 0.4124294\ttotal: 4.21s\tremaining: 14.6s\n",
      "112:\tlearn: 0.4103451\ttotal: 4.25s\tremaining: 14.6s\n",
      "113:\tlearn: 0.4091974\ttotal: 4.31s\tremaining: 14.6s\n",
      "114:\tlearn: 0.4080187\ttotal: 4.35s\tremaining: 14.6s\n",
      "115:\tlearn: 0.4065905\ttotal: 4.37s\tremaining: 14.5s\n",
      "116:\tlearn: 0.4051468\ttotal: 4.39s\tremaining: 14.4s\n",
      "117:\tlearn: 0.4035836\ttotal: 4.45s\tremaining: 14.4s\n",
      "118:\tlearn: 0.4023723\ttotal: 4.5s\tremaining: 14.4s\n",
      "119:\tlearn: 0.4011130\ttotal: 4.53s\tremaining: 14.3s\n",
      "120:\tlearn: 0.3995721\ttotal: 4.55s\tremaining: 14.3s\n",
      "121:\tlearn: 0.3981727\ttotal: 4.57s\tremaining: 14.2s\n",
      "122:\tlearn: 0.3968247\ttotal: 4.64s\tremaining: 14.2s\n",
      "123:\tlearn: 0.3952226\ttotal: 4.69s\tremaining: 14.2s\n",
      "124:\tlearn: 0.3933519\ttotal: 4.71s\tremaining: 14.1s\n",
      "125:\tlearn: 0.3920270\ttotal: 4.74s\tremaining: 14.1s\n",
      "126:\tlearn: 0.3891877\ttotal: 4.76s\tremaining: 14s\n",
      "127:\tlearn: 0.3881047\ttotal: 4.83s\tremaining: 14s\n",
      "128:\tlearn: 0.3869136\ttotal: 4.87s\tremaining: 14s\n",
      "129:\tlearn: 0.3846314\ttotal: 4.89s\tremaining: 13.9s\n",
      "130:\tlearn: 0.3835272\ttotal: 4.91s\tremaining: 13.8s\n",
      "131:\tlearn: 0.3815172\ttotal: 4.94s\tremaining: 13.8s\n",
      "132:\tlearn: 0.3800394\ttotal: 5.02s\tremaining: 13.9s\n",
      "133:\tlearn: 0.3782520\ttotal: 5.04s\tremaining: 13.8s\n",
      "134:\tlearn: 0.3768494\ttotal: 5.07s\tremaining: 13.7s\n",
      "135:\tlearn: 0.3750923\ttotal: 5.14s\tremaining: 13.8s\n",
      "136:\tlearn: 0.3740094\ttotal: 5.19s\tremaining: 13.7s\n",
      "137:\tlearn: 0.3725477\ttotal: 5.22s\tremaining: 13.7s\n",
      "138:\tlearn: 0.3712138\ttotal: 5.23s\tremaining: 13.6s\n",
      "139:\tlearn: 0.3698856\ttotal: 5.26s\tremaining: 13.5s\n",
      "140:\tlearn: 0.3690424\ttotal: 5.28s\tremaining: 13.4s\n",
      "141:\tlearn: 0.3669324\ttotal: 5.3s\tremaining: 13.4s\n",
      "142:\tlearn: 0.3652574\ttotal: 5.37s\tremaining: 13.4s\n",
      "143:\tlearn: 0.3634987\ttotal: 5.41s\tremaining: 13.4s\n",
      "144:\tlearn: 0.3624663\ttotal: 5.43s\tremaining: 13.3s\n",
      "145:\tlearn: 0.3609595\ttotal: 5.45s\tremaining: 13.2s\n",
      "146:\tlearn: 0.3597352\ttotal: 5.47s\tremaining: 13.1s\n",
      "147:\tlearn: 0.3586465\ttotal: 5.54s\tremaining: 13.2s\n",
      "148:\tlearn: 0.3573866\ttotal: 5.58s\tremaining: 13.2s\n",
      "149:\tlearn: 0.3557973\ttotal: 5.61s\tremaining: 13.1s\n",
      "150:\tlearn: 0.3545860\ttotal: 5.63s\tremaining: 13s\n",
      "151:\tlearn: 0.3532587\ttotal: 5.71s\tremaining: 13.1s\n",
      "152:\tlearn: 0.3518430\ttotal: 5.75s\tremaining: 13.1s\n",
      "153:\tlearn: 0.3506953\ttotal: 5.78s\tremaining: 13s\n",
      "154:\tlearn: 0.3494206\ttotal: 5.8s\tremaining: 12.9s\n",
      "155:\tlearn: 0.3479555\ttotal: 5.85s\tremaining: 12.9s\n",
      "156:\tlearn: 0.3463398\ttotal: 5.91s\tremaining: 12.9s\n",
      "157:\tlearn: 0.3448192\ttotal: 5.94s\tremaining: 12.9s\n",
      "158:\tlearn: 0.3434094\ttotal: 5.97s\tremaining: 12.8s\n",
      "159:\tlearn: 0.3416974\ttotal: 5.99s\tremaining: 12.7s\n",
      "160:\tlearn: 0.3402559\ttotal: 6.03s\tremaining: 12.7s\n",
      "161:\tlearn: 0.3389270\ttotal: 6.09s\tremaining: 12.7s\n",
      "162:\tlearn: 0.3375212\ttotal: 6.11s\tremaining: 12.6s\n",
      "163:\tlearn: 0.3363316\ttotal: 6.13s\tremaining: 12.6s\n",
      "164:\tlearn: 0.3348234\ttotal: 6.19s\tremaining: 12.6s\n",
      "165:\tlearn: 0.3336303\ttotal: 6.25s\tremaining: 12.6s\n",
      "166:\tlearn: 0.3322492\ttotal: 6.28s\tremaining: 12.5s\n",
      "167:\tlearn: 0.3313148\ttotal: 6.3s\tremaining: 12.4s\n",
      "168:\tlearn: 0.3303242\ttotal: 6.32s\tremaining: 12.4s\n",
      "169:\tlearn: 0.3288354\ttotal: 6.39s\tremaining: 12.4s\n",
      "170:\tlearn: 0.3279061\ttotal: 6.44s\tremaining: 12.4s\n",
      "171:\tlearn: 0.3261163\ttotal: 6.46s\tremaining: 12.3s\n",
      "172:\tlearn: 0.3248696\ttotal: 6.49s\tremaining: 12.3s\n",
      "173:\tlearn: 0.3235934\ttotal: 6.53s\tremaining: 12.2s\n",
      "174:\tlearn: 0.3224629\ttotal: 6.6s\tremaining: 12.3s\n",
      "175:\tlearn: 0.3211302\ttotal: 6.63s\tremaining: 12.2s\n",
      "176:\tlearn: 0.3201192\ttotal: 6.65s\tremaining: 12.1s\n",
      "177:\tlearn: 0.3186692\ttotal: 6.68s\tremaining: 12.1s\n",
      "178:\tlearn: 0.3172999\ttotal: 6.75s\tremaining: 12.1s\n",
      "179:\tlearn: 0.3163589\ttotal: 6.79s\tremaining: 12.1s\n",
      "180:\tlearn: 0.3154893\ttotal: 6.82s\tremaining: 12s\n",
      "181:\tlearn: 0.3142798\ttotal: 6.84s\tremaining: 12s\n",
      "182:\tlearn: 0.3130581\ttotal: 6.92s\tremaining: 12s\n",
      "183:\tlearn: 0.3117509\ttotal: 6.95s\tremaining: 11.9s\n",
      "184:\tlearn: 0.3099993\ttotal: 6.97s\tremaining: 11.9s\n",
      "185:\tlearn: 0.3089994\ttotal: 7s\tremaining: 11.8s\n",
      "186:\tlearn: 0.3075934\ttotal: 7.07s\tremaining: 11.8s\n",
      "187:\tlearn: 0.3062216\ttotal: 7.12s\tremaining: 11.8s\n",
      "188:\tlearn: 0.3052961\ttotal: 7.15s\tremaining: 11.8s\n",
      "189:\tlearn: 0.3041478\ttotal: 7.17s\tremaining: 11.7s\n",
      "190:\tlearn: 0.3030606\ttotal: 7.23s\tremaining: 11.7s\n",
      "191:\tlearn: 0.3020483\ttotal: 7.29s\tremaining: 11.7s\n",
      "192:\tlearn: 0.3010207\ttotal: 7.32s\tremaining: 11.6s\n",
      "193:\tlearn: 0.2999120\ttotal: 7.34s\tremaining: 11.6s\n",
      "194:\tlearn: 0.2989481\ttotal: 7.4s\tremaining: 11.6s\n",
      "195:\tlearn: 0.2978027\ttotal: 7.46s\tremaining: 11.6s\n",
      "196:\tlearn: 0.2969957\ttotal: 7.49s\tremaining: 11.5s\n",
      "197:\tlearn: 0.2959032\ttotal: 7.51s\tremaining: 11.5s\n",
      "198:\tlearn: 0.2941920\ttotal: 7.54s\tremaining: 11.4s\n",
      "199:\tlearn: 0.2933978\ttotal: 7.61s\tremaining: 11.4s\n",
      "200:\tlearn: 0.2925308\ttotal: 7.65s\tremaining: 11.4s\n",
      "201:\tlearn: 0.2914857\ttotal: 7.67s\tremaining: 11.3s\n",
      "202:\tlearn: 0.2905701\ttotal: 7.7s\tremaining: 11.3s\n",
      "203:\tlearn: 0.2894725\ttotal: 7.74s\tremaining: 11.2s\n",
      "204:\tlearn: 0.2881990\ttotal: 7.8s\tremaining: 11.2s\n",
      "205:\tlearn: 0.2869459\ttotal: 7.83s\tremaining: 11.2s\n",
      "206:\tlearn: 0.2859783\ttotal: 7.86s\tremaining: 11.1s\n",
      "207:\tlearn: 0.2851375\ttotal: 7.88s\tremaining: 11.1s\n",
      "208:\tlearn: 0.2843202\ttotal: 7.94s\tremaining: 11.1s\n",
      "209:\tlearn: 0.2833749\ttotal: 7.96s\tremaining: 11s\n",
      "210:\tlearn: 0.2820030\ttotal: 7.98s\tremaining: 10.9s\n",
      "211:\tlearn: 0.2811819\ttotal: 8.01s\tremaining: 10.9s\n",
      "212:\tlearn: 0.2800831\ttotal: 8.09s\tremaining: 10.9s\n",
      "213:\tlearn: 0.2788137\ttotal: 8.12s\tremaining: 10.9s\n",
      "214:\tlearn: 0.2777309\ttotal: 8.14s\tremaining: 10.8s\n",
      "215:\tlearn: 0.2765915\ttotal: 8.17s\tremaining: 10.7s\n",
      "216:\tlearn: 0.2754326\ttotal: 8.22s\tremaining: 10.7s\n",
      "217:\tlearn: 0.2747114\ttotal: 8.27s\tremaining: 10.7s\n",
      "218:\tlearn: 0.2735692\ttotal: 8.3s\tremaining: 10.7s\n",
      "219:\tlearn: 0.2726659\ttotal: 8.32s\tremaining: 10.6s\n",
      "220:\tlearn: 0.2717910\ttotal: 8.34s\tremaining: 10.5s\n",
      "221:\tlearn: 0.2706753\ttotal: 8.42s\tremaining: 10.5s\n",
      "222:\tlearn: 0.2698565\ttotal: 8.46s\tremaining: 10.5s\n",
      "223:\tlearn: 0.2689610\ttotal: 8.49s\tremaining: 10.5s\n",
      "224:\tlearn: 0.2681203\ttotal: 8.51s\tremaining: 10.4s\n",
      "225:\tlearn: 0.2672912\ttotal: 8.56s\tremaining: 10.4s\n",
      "226:\tlearn: 0.2667082\ttotal: 8.62s\tremaining: 10.4s\n",
      "227:\tlearn: 0.2662531\ttotal: 8.65s\tremaining: 10.3s\n",
      "228:\tlearn: 0.2656376\ttotal: 8.68s\tremaining: 10.3s\n",
      "229:\tlearn: 0.2648594\ttotal: 8.71s\tremaining: 10.2s\n",
      "230:\tlearn: 0.2637604\ttotal: 8.79s\tremaining: 10.2s\n",
      "231:\tlearn: 0.2627935\ttotal: 8.84s\tremaining: 10.2s\n",
      "232:\tlearn: 0.2615283\ttotal: 8.87s\tremaining: 10.2s\n",
      "233:\tlearn: 0.2606721\ttotal: 8.91s\tremaining: 10.1s\n",
      "234:\tlearn: 0.2600622\ttotal: 8.93s\tremaining: 10.1s\n",
      "235:\tlearn: 0.2589567\ttotal: 9s\tremaining: 10.1s\n",
      "236:\tlearn: 0.2577712\ttotal: 9.04s\tremaining: 10s\n",
      "237:\tlearn: 0.2566225\ttotal: 9.06s\tremaining: 9.97s\n",
      "238:\tlearn: 0.2556623\ttotal: 9.13s\tremaining: 9.97s\n",
      "239:\tlearn: 0.2544373\ttotal: 9.17s\tremaining: 9.94s\n",
      "240:\tlearn: 0.2535211\ttotal: 9.2s\tremaining: 9.89s\n",
      "241:\tlearn: 0.2527061\ttotal: 9.22s\tremaining: 9.83s\n",
      "242:\tlearn: 0.2517017\ttotal: 9.24s\tremaining: 9.77s\n",
      "243:\tlearn: 0.2509366\ttotal: 9.31s\tremaining: 9.77s\n",
      "244:\tlearn: 0.2497990\ttotal: 9.36s\tremaining: 9.74s\n",
      "245:\tlearn: 0.2487745\ttotal: 9.39s\tremaining: 9.69s\n",
      "246:\tlearn: 0.2478168\ttotal: 9.41s\tremaining: 9.64s\n",
      "247:\tlearn: 0.2468385\ttotal: 9.45s\tremaining: 9.6s\n",
      "248:\tlearn: 0.2459011\ttotal: 9.52s\tremaining: 9.6s\n",
      "249:\tlearn: 0.2449422\ttotal: 9.55s\tremaining: 9.55s\n",
      "250:\tlearn: 0.2438002\ttotal: 9.57s\tremaining: 9.5s\n",
      "251:\tlearn: 0.2425755\ttotal: 9.59s\tremaining: 9.44s\n",
      "252:\tlearn: 0.2415541\ttotal: 9.66s\tremaining: 9.43s\n",
      "253:\tlearn: 0.2407599\ttotal: 9.73s\tremaining: 9.42s\n",
      "254:\tlearn: 0.2396968\ttotal: 9.76s\tremaining: 9.37s\n",
      "255:\tlearn: 0.2387051\ttotal: 9.77s\tremaining: 9.32s\n",
      "256:\tlearn: 0.2381420\ttotal: 9.85s\tremaining: 9.31s\n",
      "257:\tlearn: 0.2371482\ttotal: 9.89s\tremaining: 9.28s\n",
      "258:\tlearn: 0.2363941\ttotal: 9.93s\tremaining: 9.24s\n",
      "259:\tlearn: 0.2356203\ttotal: 9.95s\tremaining: 9.19s\n",
      "260:\tlearn: 0.2351262\ttotal: 9.97s\tremaining: 9.13s\n",
      "261:\tlearn: 0.2344095\ttotal: 10s\tremaining: 9.08s\n",
      "262:\tlearn: 0.2336649\ttotal: 10.1s\tremaining: 9.08s\n",
      "263:\tlearn: 0.2325148\ttotal: 10.1s\tremaining: 9.04s\n",
      "264:\tlearn: 0.2316992\ttotal: 10.1s\tremaining: 8.99s\n",
      "265:\tlearn: 0.2306916\ttotal: 10.2s\tremaining: 8.95s\n",
      "266:\tlearn: 0.2300836\ttotal: 10.2s\tremaining: 8.94s\n",
      "267:\tlearn: 0.2291631\ttotal: 10.3s\tremaining: 8.9s\n",
      "268:\tlearn: 0.2282212\ttotal: 10.3s\tremaining: 8.86s\n",
      "269:\tlearn: 0.2275279\ttotal: 10.3s\tremaining: 8.8s\n",
      "270:\tlearn: 0.2268569\ttotal: 10.4s\tremaining: 8.79s\n",
      "271:\tlearn: 0.2261924\ttotal: 10.4s\tremaining: 8.76s\n",
      "272:\tlearn: 0.2255708\ttotal: 10.5s\tremaining: 8.71s\n",
      "273:\tlearn: 0.2249431\ttotal: 10.5s\tremaining: 8.66s\n",
      "274:\tlearn: 0.2242485\ttotal: 10.5s\tremaining: 8.61s\n",
      "275:\tlearn: 0.2236473\ttotal: 10.6s\tremaining: 8.6s\n",
      "276:\tlearn: 0.2229254\ttotal: 10.6s\tremaining: 8.56s\n",
      "277:\tlearn: 0.2220477\ttotal: 10.7s\tremaining: 8.51s\n",
      "278:\tlearn: 0.2212239\ttotal: 10.7s\tremaining: 8.46s\n",
      "279:\tlearn: 0.2205305\ttotal: 10.7s\tremaining: 8.41s\n",
      "280:\tlearn: 0.2196332\ttotal: 10.8s\tremaining: 8.4s\n",
      "281:\tlearn: 0.2182832\ttotal: 10.8s\tremaining: 8.35s\n",
      "282:\tlearn: 0.2176431\ttotal: 10.8s\tremaining: 8.3s\n",
      "283:\tlearn: 0.2168397\ttotal: 10.8s\tremaining: 8.24s\n",
      "284:\tlearn: 0.2161914\ttotal: 10.9s\tremaining: 8.22s\n",
      "285:\tlearn: 0.2152270\ttotal: 10.9s\tremaining: 8.19s\n",
      "286:\tlearn: 0.2145535\ttotal: 11s\tremaining: 8.14s\n",
      "287:\tlearn: 0.2138693\ttotal: 11s\tremaining: 8.1s\n",
      "288:\tlearn: 0.2129633\ttotal: 11s\tremaining: 8.04s\n",
      "289:\tlearn: 0.2124726\ttotal: 11.1s\tremaining: 8.03s\n",
      "290:\tlearn: 0.2117823\ttotal: 11.1s\tremaining: 8s\n",
      "291:\tlearn: 0.2110876\ttotal: 11.2s\tremaining: 7.96s\n",
      "292:\tlearn: 0.2104648\ttotal: 11.2s\tremaining: 7.91s\n",
      "293:\tlearn: 0.2097437\ttotal: 11.2s\tremaining: 7.86s\n",
      "294:\tlearn: 0.2091043\ttotal: 11.3s\tremaining: 7.84s\n",
      "295:\tlearn: 0.2084788\ttotal: 11.3s\tremaining: 7.81s\n",
      "296:\tlearn: 0.2077648\ttotal: 11.4s\tremaining: 7.76s\n",
      "297:\tlearn: 0.2071391\ttotal: 11.4s\tremaining: 7.72s\n",
      "298:\tlearn: 0.2062934\ttotal: 11.4s\tremaining: 7.68s\n",
      "299:\tlearn: 0.2055118\ttotal: 11.5s\tremaining: 7.66s\n",
      "300:\tlearn: 0.2045736\ttotal: 11.5s\tremaining: 7.62s\n",
      "301:\tlearn: 0.2038510\ttotal: 11.6s\tremaining: 7.58s\n",
      "302:\tlearn: 0.2032660\ttotal: 11.6s\tremaining: 7.53s\n",
      "303:\tlearn: 0.2023537\ttotal: 11.6s\tremaining: 7.5s\n",
      "304:\tlearn: 0.2015736\ttotal: 11.7s\tremaining: 7.47s\n",
      "305:\tlearn: 0.2010953\ttotal: 11.7s\tremaining: 7.42s\n",
      "306:\tlearn: 0.2002729\ttotal: 11.7s\tremaining: 7.38s\n",
      "307:\tlearn: 0.1996155\ttotal: 11.8s\tremaining: 7.34s\n",
      "308:\tlearn: 0.1991494\ttotal: 11.8s\tremaining: 7.33s\n",
      "309:\tlearn: 0.1984458\ttotal: 11.9s\tremaining: 7.28s\n",
      "310:\tlearn: 0.1979822\ttotal: 11.9s\tremaining: 7.23s\n",
      "311:\tlearn: 0.1971846\ttotal: 11.9s\tremaining: 7.18s\n",
      "312:\tlearn: 0.1968360\ttotal: 12s\tremaining: 7.17s\n",
      "313:\tlearn: 0.1959202\ttotal: 12.1s\tremaining: 7.14s\n",
      "314:\tlearn: 0.1954726\ttotal: 12.1s\tremaining: 7.1s\n",
      "315:\tlearn: 0.1950508\ttotal: 12.1s\tremaining: 7.05s\n",
      "316:\tlearn: 0.1942784\ttotal: 12.2s\tremaining: 7.03s\n",
      "317:\tlearn: 0.1932660\ttotal: 12.2s\tremaining: 7s\n",
      "318:\tlearn: 0.1925855\ttotal: 12.3s\tremaining: 6.95s\n",
      "319:\tlearn: 0.1922236\ttotal: 12.3s\tremaining: 6.9s\n",
      "320:\tlearn: 0.1915347\ttotal: 12.3s\tremaining: 6.87s\n",
      "321:\tlearn: 0.1909831\ttotal: 12.4s\tremaining: 6.84s\n",
      "322:\tlearn: 0.1904416\ttotal: 12.4s\tremaining: 6.8s\n",
      "323:\tlearn: 0.1898568\ttotal: 12.4s\tremaining: 6.75s\n",
      "324:\tlearn: 0.1893252\ttotal: 12.5s\tremaining: 6.71s\n",
      "325:\tlearn: 0.1887180\ttotal: 12.5s\tremaining: 6.68s\n",
      "326:\tlearn: 0.1881478\ttotal: 12.6s\tremaining: 6.65s\n",
      "327:\tlearn: 0.1875940\ttotal: 12.6s\tremaining: 6.61s\n",
      "328:\tlearn: 0.1871536\ttotal: 12.6s\tremaining: 6.56s\n",
      "329:\tlearn: 0.1866023\ttotal: 12.6s\tremaining: 6.51s\n",
      "330:\tlearn: 0.1858167\ttotal: 12.7s\tremaining: 6.49s\n",
      "331:\tlearn: 0.1852205\ttotal: 12.8s\tremaining: 6.46s\n",
      "332:\tlearn: 0.1846560\ttotal: 12.8s\tremaining: 6.41s\n",
      "333:\tlearn: 0.1839146\ttotal: 12.8s\tremaining: 6.37s\n",
      "334:\tlearn: 0.1834075\ttotal: 12.8s\tremaining: 6.32s\n",
      "335:\tlearn: 0.1827271\ttotal: 12.9s\tremaining: 6.3s\n",
      "336:\tlearn: 0.1822151\ttotal: 12.9s\tremaining: 6.26s\n",
      "337:\tlearn: 0.1816372\ttotal: 13s\tremaining: 6.21s\n",
      "338:\tlearn: 0.1812220\ttotal: 13s\tremaining: 6.17s\n",
      "339:\tlearn: 0.1805313\ttotal: 13s\tremaining: 6.13s\n",
      "340:\tlearn: 0.1798064\ttotal: 13.1s\tremaining: 6.1s\n",
      "341:\tlearn: 0.1793539\ttotal: 13.1s\tremaining: 6.06s\n",
      "342:\tlearn: 0.1788842\ttotal: 13.1s\tremaining: 6.02s\n",
      "343:\tlearn: 0.1783296\ttotal: 13.2s\tremaining: 5.97s\n",
      "344:\tlearn: 0.1779634\ttotal: 13.2s\tremaining: 5.95s\n",
      "345:\tlearn: 0.1775364\ttotal: 13.3s\tremaining: 5.91s\n",
      "346:\tlearn: 0.1771219\ttotal: 13.3s\tremaining: 5.86s\n",
      "347:\tlearn: 0.1765372\ttotal: 13.3s\tremaining: 5.82s\n",
      "348:\tlearn: 0.1760445\ttotal: 13.4s\tremaining: 5.79s\n",
      "349:\tlearn: 0.1754288\ttotal: 13.4s\tremaining: 5.76s\n",
      "350:\tlearn: 0.1748573\ttotal: 13.5s\tremaining: 5.72s\n",
      "351:\tlearn: 0.1742944\ttotal: 13.5s\tremaining: 5.67s\n",
      "352:\tlearn: 0.1733112\ttotal: 13.5s\tremaining: 5.63s\n",
      "353:\tlearn: 0.1728184\ttotal: 13.5s\tremaining: 5.59s\n",
      "354:\tlearn: 0.1723824\ttotal: 13.6s\tremaining: 5.56s\n",
      "355:\tlearn: 0.1718013\ttotal: 13.7s\tremaining: 5.52s\n",
      "356:\tlearn: 0.1713802\ttotal: 13.7s\tremaining: 5.48s\n",
      "357:\tlearn: 0.1709162\ttotal: 13.7s\tremaining: 5.43s\n",
      "358:\tlearn: 0.1702552\ttotal: 13.8s\tremaining: 5.41s\n",
      "359:\tlearn: 0.1697740\ttotal: 13.8s\tremaining: 5.37s\n",
      "360:\tlearn: 0.1691071\ttotal: 13.8s\tremaining: 5.33s\n",
      "361:\tlearn: 0.1683151\ttotal: 13.9s\tremaining: 5.29s\n",
      "362:\tlearn: 0.1677311\ttotal: 13.9s\tremaining: 5.26s\n",
      "363:\tlearn: 0.1674391\ttotal: 14s\tremaining: 5.23s\n",
      "364:\tlearn: 0.1668777\ttotal: 14s\tremaining: 5.18s\n",
      "365:\tlearn: 0.1663213\ttotal: 14s\tremaining: 5.14s\n",
      "366:\tlearn: 0.1657235\ttotal: 14.1s\tremaining: 5.1s\n",
      "367:\tlearn: 0.1653333\ttotal: 14.1s\tremaining: 5.07s\n",
      "368:\tlearn: 0.1649003\ttotal: 14.2s\tremaining: 5.03s\n",
      "369:\tlearn: 0.1643679\ttotal: 14.2s\tremaining: 4.99s\n",
      "370:\tlearn: 0.1639487\ttotal: 14.2s\tremaining: 4.95s\n",
      "371:\tlearn: 0.1634656\ttotal: 14.2s\tremaining: 4.9s\n",
      "372:\tlearn: 0.1631313\ttotal: 14.3s\tremaining: 4.88s\n",
      "373:\tlearn: 0.1625125\ttotal: 14.3s\tremaining: 4.83s\n",
      "374:\tlearn: 0.1619921\ttotal: 14.4s\tremaining: 4.79s\n",
      "375:\tlearn: 0.1613907\ttotal: 14.4s\tremaining: 4.75s\n",
      "376:\tlearn: 0.1609684\ttotal: 14.5s\tremaining: 4.72s\n",
      "377:\tlearn: 0.1601694\ttotal: 14.5s\tremaining: 4.68s\n",
      "378:\tlearn: 0.1596875\ttotal: 14.5s\tremaining: 4.64s\n",
      "379:\tlearn: 0.1591747\ttotal: 14.6s\tremaining: 4.6s\n",
      "380:\tlearn: 0.1585352\ttotal: 14.6s\tremaining: 4.56s\n",
      "381:\tlearn: 0.1579716\ttotal: 14.6s\tremaining: 4.51s\n",
      "382:\tlearn: 0.1572077\ttotal: 14.7s\tremaining: 4.48s\n",
      "383:\tlearn: 0.1567008\ttotal: 14.7s\tremaining: 4.45s\n",
      "384:\tlearn: 0.1562587\ttotal: 14.8s\tremaining: 4.41s\n",
      "385:\tlearn: 0.1557908\ttotal: 14.8s\tremaining: 4.37s\n",
      "386:\tlearn: 0.1549651\ttotal: 14.8s\tremaining: 4.32s\n",
      "387:\tlearn: 0.1547120\ttotal: 14.9s\tremaining: 4.29s\n",
      "388:\tlearn: 0.1540960\ttotal: 14.9s\tremaining: 4.26s\n",
      "389:\tlearn: 0.1536584\ttotal: 14.9s\tremaining: 4.21s\n",
      "390:\tlearn: 0.1529838\ttotal: 15s\tremaining: 4.17s\n",
      "391:\tlearn: 0.1525191\ttotal: 15s\tremaining: 4.13s\n",
      "392:\tlearn: 0.1519901\ttotal: 15.1s\tremaining: 4.1s\n",
      "393:\tlearn: 0.1515317\ttotal: 15.1s\tremaining: 4.06s\n",
      "394:\tlearn: 0.1510432\ttotal: 15.1s\tremaining: 4.02s\n",
      "395:\tlearn: 0.1505961\ttotal: 15.1s\tremaining: 3.98s\n",
      "396:\tlearn: 0.1499837\ttotal: 15.2s\tremaining: 3.94s\n",
      "397:\tlearn: 0.1496765\ttotal: 15.3s\tremaining: 3.91s\n",
      "398:\tlearn: 0.1493416\ttotal: 15.3s\tremaining: 3.87s\n",
      "399:\tlearn: 0.1487627\ttotal: 15.3s\tremaining: 3.83s\n",
      "400:\tlearn: 0.1483342\ttotal: 15.3s\tremaining: 3.79s\n",
      "401:\tlearn: 0.1476960\ttotal: 15.4s\tremaining: 3.75s\n",
      "402:\tlearn: 0.1474551\ttotal: 15.5s\tremaining: 3.72s\n",
      "403:\tlearn: 0.1469090\ttotal: 15.5s\tremaining: 3.68s\n",
      "404:\tlearn: 0.1464729\ttotal: 15.5s\tremaining: 3.64s\n",
      "405:\tlearn: 0.1459711\ttotal: 15.5s\tremaining: 3.6s\n",
      "406:\tlearn: 0.1454921\ttotal: 15.6s\tremaining: 3.57s\n",
      "407:\tlearn: 0.1450788\ttotal: 15.7s\tremaining: 3.53s\n",
      "408:\tlearn: 0.1443809\ttotal: 15.7s\tremaining: 3.49s\n",
      "409:\tlearn: 0.1439154\ttotal: 15.7s\tremaining: 3.45s\n",
      "410:\tlearn: 0.1433185\ttotal: 15.7s\tremaining: 3.4s\n",
      "411:\tlearn: 0.1429855\ttotal: 15.8s\tremaining: 3.37s\n",
      "412:\tlearn: 0.1425857\ttotal: 15.8s\tremaining: 3.34s\n",
      "413:\tlearn: 0.1419671\ttotal: 15.9s\tremaining: 3.29s\n",
      "414:\tlearn: 0.1415416\ttotal: 15.9s\tremaining: 3.25s\n",
      "415:\tlearn: 0.1410429\ttotal: 15.9s\tremaining: 3.21s\n",
      "416:\tlearn: 0.1407471\ttotal: 16s\tremaining: 3.18s\n",
      "417:\tlearn: 0.1403592\ttotal: 16s\tremaining: 3.15s\n",
      "418:\tlearn: 0.1397312\ttotal: 16.1s\tremaining: 3.1s\n",
      "419:\tlearn: 0.1392835\ttotal: 16.1s\tremaining: 3.07s\n",
      "420:\tlearn: 0.1386997\ttotal: 16.2s\tremaining: 3.03s\n",
      "421:\tlearn: 0.1382451\ttotal: 16.2s\tremaining: 2.99s\n",
      "422:\tlearn: 0.1379858\ttotal: 16.2s\tremaining: 2.95s\n",
      "423:\tlearn: 0.1375553\ttotal: 16.2s\tremaining: 2.91s\n",
      "424:\tlearn: 0.1371016\ttotal: 16.3s\tremaining: 2.88s\n",
      "425:\tlearn: 0.1366438\ttotal: 16.4s\tremaining: 2.84s\n",
      "426:\tlearn: 0.1362749\ttotal: 16.4s\tremaining: 2.8s\n",
      "427:\tlearn: 0.1355355\ttotal: 16.4s\tremaining: 2.76s\n",
      "428:\tlearn: 0.1350968\ttotal: 16.4s\tremaining: 2.72s\n",
      "429:\tlearn: 0.1347026\ttotal: 16.5s\tremaining: 2.68s\n",
      "430:\tlearn: 0.1344015\ttotal: 16.5s\tremaining: 2.64s\n",
      "431:\tlearn: 0.1339048\ttotal: 16.5s\tremaining: 2.6s\n",
      "432:\tlearn: 0.1335478\ttotal: 16.6s\tremaining: 2.56s\n",
      "433:\tlearn: 0.1330064\ttotal: 16.6s\tremaining: 2.53s\n",
      "434:\tlearn: 0.1327385\ttotal: 16.7s\tremaining: 2.5s\n",
      "435:\tlearn: 0.1324253\ttotal: 16.7s\tremaining: 2.46s\n",
      "436:\tlearn: 0.1320587\ttotal: 16.8s\tremaining: 2.42s\n",
      "437:\tlearn: 0.1317381\ttotal: 16.8s\tremaining: 2.38s\n",
      "438:\tlearn: 0.1313548\ttotal: 16.8s\tremaining: 2.34s\n",
      "439:\tlearn: 0.1310269\ttotal: 16.9s\tremaining: 2.3s\n",
      "440:\tlearn: 0.1305713\ttotal: 16.9s\tremaining: 2.27s\n",
      "441:\tlearn: 0.1301342\ttotal: 17s\tremaining: 2.23s\n",
      "442:\tlearn: 0.1297939\ttotal: 17s\tremaining: 2.18s\n",
      "443:\tlearn: 0.1294239\ttotal: 17s\tremaining: 2.15s\n",
      "444:\tlearn: 0.1291724\ttotal: 17.1s\tremaining: 2.11s\n",
      "445:\tlearn: 0.1286597\ttotal: 17.1s\tremaining: 2.07s\n",
      "446:\tlearn: 0.1283845\ttotal: 17.1s\tremaining: 2.03s\n",
      "447:\tlearn: 0.1279714\ttotal: 17.1s\tremaining: 1.99s\n",
      "448:\tlearn: 0.1275690\ttotal: 17.2s\tremaining: 1.96s\n",
      "449:\tlearn: 0.1272524\ttotal: 17.3s\tremaining: 1.92s\n",
      "450:\tlearn: 0.1268115\ttotal: 17.3s\tremaining: 1.88s\n",
      "451:\tlearn: 0.1264139\ttotal: 17.3s\tremaining: 1.84s\n",
      "452:\tlearn: 0.1260437\ttotal: 17.3s\tremaining: 1.8s\n",
      "453:\tlearn: 0.1255941\ttotal: 17.4s\tremaining: 1.76s\n",
      "454:\tlearn: 0.1252429\ttotal: 17.4s\tremaining: 1.72s\n",
      "455:\tlearn: 0.1249116\ttotal: 17.5s\tremaining: 1.68s\n",
      "456:\tlearn: 0.1246221\ttotal: 17.5s\tremaining: 1.64s\n",
      "457:\tlearn: 0.1241909\ttotal: 17.5s\tremaining: 1.61s\n",
      "458:\tlearn: 0.1238974\ttotal: 17.6s\tremaining: 1.57s\n",
      "459:\tlearn: 0.1236675\ttotal: 17.6s\tremaining: 1.53s\n",
      "460:\tlearn: 0.1233777\ttotal: 17.6s\tremaining: 1.49s\n",
      "461:\tlearn: 0.1230479\ttotal: 17.7s\tremaining: 1.46s\n",
      "462:\tlearn: 0.1226728\ttotal: 17.8s\tremaining: 1.42s\n",
      "463:\tlearn: 0.1224122\ttotal: 17.8s\tremaining: 1.38s\n",
      "464:\tlearn: 0.1220860\ttotal: 17.8s\tremaining: 1.34s\n",
      "465:\tlearn: 0.1217207\ttotal: 17.8s\tremaining: 1.3s\n",
      "466:\tlearn: 0.1214957\ttotal: 17.9s\tremaining: 1.26s\n",
      "467:\tlearn: 0.1212527\ttotal: 17.9s\tremaining: 1.23s\n",
      "468:\tlearn: 0.1208297\ttotal: 18s\tremaining: 1.19s\n",
      "469:\tlearn: 0.1204009\ttotal: 18s\tremaining: 1.15s\n",
      "470:\tlearn: 0.1200323\ttotal: 18s\tremaining: 1.11s\n",
      "471:\tlearn: 0.1195787\ttotal: 18.1s\tremaining: 1.07s\n",
      "472:\tlearn: 0.1191966\ttotal: 18.1s\tremaining: 1.03s\n",
      "473:\tlearn: 0.1189149\ttotal: 18.1s\tremaining: 995ms\n",
      "474:\tlearn: 0.1184895\ttotal: 18.2s\tremaining: 956ms\n",
      "475:\tlearn: 0.1180457\ttotal: 18.2s\tremaining: 917ms\n",
      "476:\tlearn: 0.1176450\ttotal: 18.2s\tremaining: 878ms\n",
      "477:\tlearn: 0.1172569\ttotal: 18.3s\tremaining: 841ms\n",
      "478:\tlearn: 0.1170047\ttotal: 18.3s\tremaining: 803ms\n",
      "479:\tlearn: 0.1166334\ttotal: 18.3s\tremaining: 764ms\n",
      "480:\tlearn: 0.1163948\ttotal: 18.4s\tremaining: 725ms\n",
      "481:\tlearn: 0.1159694\ttotal: 18.4s\tremaining: 688ms\n",
      "482:\tlearn: 0.1155728\ttotal: 18.5s\tremaining: 651ms\n",
      "483:\tlearn: 0.1151511\ttotal: 18.5s\tremaining: 612ms\n",
      "484:\tlearn: 0.1149412\ttotal: 18.5s\tremaining: 573ms\n",
      "485:\tlearn: 0.1146778\ttotal: 18.6s\tremaining: 534ms\n",
      "486:\tlearn: 0.1144297\ttotal: 18.6s\tremaining: 497ms\n",
      "487:\tlearn: 0.1139591\ttotal: 18.7s\tremaining: 459ms\n",
      "488:\tlearn: 0.1134732\ttotal: 18.7s\tremaining: 420ms\n",
      "489:\tlearn: 0.1131671\ttotal: 18.7s\tremaining: 382ms\n",
      "490:\tlearn: 0.1128348\ttotal: 18.8s\tremaining: 344ms\n",
      "491:\tlearn: 0.1125575\ttotal: 18.8s\tremaining: 306ms\n",
      "492:\tlearn: 0.1121467\ttotal: 18.9s\tremaining: 268ms\n",
      "493:\tlearn: 0.1117941\ttotal: 18.9s\tremaining: 229ms\n",
      "494:\tlearn: 0.1115219\ttotal: 18.9s\tremaining: 191ms\n",
      "495:\tlearn: 0.1112140\ttotal: 19s\tremaining: 153ms\n",
      "496:\tlearn: 0.1109425\ttotal: 19.1s\tremaining: 115ms\n",
      "497:\tlearn: 0.1106340\ttotal: 19.1s\tremaining: 76.7ms\n",
      "498:\tlearn: 0.1103015\ttotal: 19.1s\tremaining: 38.3ms\n",
      "499:\tlearn: 0.1099454\ttotal: 19.2s\tremaining: 0us\n",
      "0:\tlearn: 0.6897602\ttotal: 16.9ms\tremaining: 8.43s\n",
      "1:\tlearn: 0.6860830\ttotal: 31.6ms\tremaining: 7.88s\n",
      "2:\tlearn: 0.6821969\ttotal: 77.9ms\tremaining: 12.9s\n",
      "3:\tlearn: 0.6776269\ttotal: 107ms\tremaining: 13.2s\n",
      "4:\tlearn: 0.6741874\ttotal: 136ms\tremaining: 13.5s\n",
      "5:\tlearn: 0.6708933\ttotal: 165ms\tremaining: 13.6s\n",
      "6:\tlearn: 0.6665419\ttotal: 192ms\tremaining: 13.5s\n",
      "7:\tlearn: 0.6626946\ttotal: 212ms\tremaining: 13.1s\n",
      "8:\tlearn: 0.6591957\ttotal: 281ms\tremaining: 15.4s\n",
      "9:\tlearn: 0.6548580\ttotal: 330ms\tremaining: 16.2s\n",
      "10:\tlearn: 0.6512827\ttotal: 356ms\tremaining: 15.8s\n",
      "11:\tlearn: 0.6478720\ttotal: 378ms\tremaining: 15.4s\n",
      "12:\tlearn: 0.6448902\ttotal: 399ms\tremaining: 14.9s\n",
      "13:\tlearn: 0.6415625\ttotal: 471ms\tremaining: 16.3s\n",
      "14:\tlearn: 0.6380502\ttotal: 511ms\tremaining: 16.5s\n",
      "15:\tlearn: 0.6347952\ttotal: 537ms\tremaining: 16.2s\n",
      "16:\tlearn: 0.6312761\ttotal: 558ms\tremaining: 15.8s\n",
      "17:\tlearn: 0.6269385\ttotal: 577ms\tremaining: 15.5s\n",
      "18:\tlearn: 0.6238698\ttotal: 653ms\tremaining: 16.5s\n",
      "19:\tlearn: 0.6212926\ttotal: 674ms\tremaining: 16.2s\n",
      "20:\tlearn: 0.6188957\ttotal: 695ms\tremaining: 15.9s\n",
      "21:\tlearn: 0.6152688\ttotal: 765ms\tremaining: 16.6s\n",
      "22:\tlearn: 0.6127182\ttotal: 793ms\tremaining: 16.4s\n",
      "23:\tlearn: 0.6095064\ttotal: 816ms\tremaining: 16.2s\n",
      "24:\tlearn: 0.6063987\ttotal: 864ms\tremaining: 16.4s\n",
      "25:\tlearn: 0.6029743\ttotal: 927ms\tremaining: 16.9s\n",
      "26:\tlearn: 0.6000820\ttotal: 959ms\tremaining: 16.8s\n",
      "27:\tlearn: 0.5972078\ttotal: 984ms\tremaining: 16.6s\n",
      "28:\tlearn: 0.5940135\ttotal: 1s\tremaining: 16.3s\n",
      "29:\tlearn: 0.5905207\ttotal: 1.07s\tremaining: 16.7s\n",
      "30:\tlearn: 0.5873434\ttotal: 1.11s\tremaining: 16.8s\n",
      "31:\tlearn: 0.5841810\ttotal: 1.13s\tremaining: 16.5s\n",
      "32:\tlearn: 0.5807235\ttotal: 1.15s\tremaining: 16.3s\n",
      "33:\tlearn: 0.5780150\ttotal: 1.22s\tremaining: 16.7s\n",
      "34:\tlearn: 0.5756790\ttotal: 1.28s\tremaining: 17s\n",
      "35:\tlearn: 0.5734640\ttotal: 1.31s\tremaining: 16.9s\n",
      "36:\tlearn: 0.5705455\ttotal: 1.33s\tremaining: 16.7s\n",
      "37:\tlearn: 0.5681239\ttotal: 1.36s\tremaining: 16.5s\n",
      "38:\tlearn: 0.5655482\ttotal: 1.41s\tremaining: 16.6s\n",
      "39:\tlearn: 0.5629897\ttotal: 1.46s\tremaining: 16.8s\n",
      "40:\tlearn: 0.5607648\ttotal: 1.5s\tremaining: 16.8s\n",
      "41:\tlearn: 0.5582864\ttotal: 1.52s\tremaining: 16.6s\n",
      "42:\tlearn: 0.5548437\ttotal: 1.54s\tremaining: 16.4s\n",
      "43:\tlearn: 0.5519548\ttotal: 1.61s\tremaining: 16.7s\n",
      "44:\tlearn: 0.5494528\ttotal: 1.64s\tremaining: 16.6s\n",
      "45:\tlearn: 0.5471716\ttotal: 1.66s\tremaining: 16.4s\n",
      "46:\tlearn: 0.5451226\ttotal: 1.74s\tremaining: 16.7s\n",
      "47:\tlearn: 0.5424535\ttotal: 1.77s\tremaining: 16.7s\n",
      "48:\tlearn: 0.5405563\ttotal: 1.8s\tremaining: 16.6s\n",
      "49:\tlearn: 0.5385201\ttotal: 1.82s\tremaining: 16.4s\n",
      "50:\tlearn: 0.5357764\ttotal: 1.85s\tremaining: 16.3s\n",
      "51:\tlearn: 0.5336340\ttotal: 1.91s\tremaining: 16.5s\n",
      "52:\tlearn: 0.5307690\ttotal: 1.96s\tremaining: 16.5s\n",
      "53:\tlearn: 0.5285793\ttotal: 1.99s\tremaining: 16.4s\n",
      "54:\tlearn: 0.5263769\ttotal: 2.01s\tremaining: 16.3s\n",
      "55:\tlearn: 0.5241081\ttotal: 2.03s\tremaining: 16.1s\n",
      "56:\tlearn: 0.5217716\ttotal: 2.07s\tremaining: 16.1s\n",
      "57:\tlearn: 0.5191493\ttotal: 2.14s\tremaining: 16.3s\n",
      "58:\tlearn: 0.5170405\ttotal: 2.18s\tremaining: 16.3s\n",
      "59:\tlearn: 0.5151186\ttotal: 2.2s\tremaining: 16.2s\n",
      "60:\tlearn: 0.5128470\ttotal: 2.23s\tremaining: 16s\n",
      "61:\tlearn: 0.5108258\ttotal: 2.27s\tremaining: 16s\n",
      "62:\tlearn: 0.5083567\ttotal: 2.34s\tremaining: 16.2s\n",
      "63:\tlearn: 0.5058148\ttotal: 2.37s\tremaining: 16.1s\n",
      "64:\tlearn: 0.5037453\ttotal: 2.39s\tremaining: 16s\n",
      "65:\tlearn: 0.5017472\ttotal: 2.41s\tremaining: 15.9s\n",
      "66:\tlearn: 0.4994788\ttotal: 2.47s\tremaining: 16s\n",
      "67:\tlearn: 0.4978177\ttotal: 2.53s\tremaining: 16.1s\n",
      "68:\tlearn: 0.4958379\ttotal: 2.56s\tremaining: 16s\n",
      "69:\tlearn: 0.4937664\ttotal: 2.58s\tremaining: 15.8s\n",
      "70:\tlearn: 0.4917885\ttotal: 2.6s\tremaining: 15.7s\n",
      "71:\tlearn: 0.4899343\ttotal: 2.67s\tremaining: 15.9s\n",
      "72:\tlearn: 0.4885383\ttotal: 2.71s\tremaining: 15.9s\n",
      "73:\tlearn: 0.4864806\ttotal: 2.74s\tremaining: 15.8s\n",
      "74:\tlearn: 0.4848373\ttotal: 2.77s\tremaining: 15.7s\n",
      "75:\tlearn: 0.4825212\ttotal: 2.79s\tremaining: 15.6s\n",
      "76:\tlearn: 0.4804974\ttotal: 2.87s\tremaining: 15.7s\n",
      "77:\tlearn: 0.4781107\ttotal: 2.9s\tremaining: 15.7s\n",
      "78:\tlearn: 0.4750695\ttotal: 2.93s\tremaining: 15.6s\n",
      "79:\tlearn: 0.4728566\ttotal: 2.95s\tremaining: 15.5s\n",
      "80:\tlearn: 0.4714714\ttotal: 2.97s\tremaining: 15.4s\n",
      "81:\tlearn: 0.4679862\ttotal: 3.04s\tremaining: 15.5s\n",
      "82:\tlearn: 0.4661108\ttotal: 3.08s\tremaining: 15.5s\n",
      "83:\tlearn: 0.4642366\ttotal: 3.1s\tremaining: 15.3s\n",
      "84:\tlearn: 0.4619202\ttotal: 3.12s\tremaining: 15.2s\n",
      "85:\tlearn: 0.4591797\ttotal: 3.18s\tremaining: 15.3s\n",
      "86:\tlearn: 0.4575256\ttotal: 3.23s\tremaining: 15.4s\n",
      "87:\tlearn: 0.4551251\ttotal: 3.27s\tremaining: 15.3s\n",
      "88:\tlearn: 0.4529486\ttotal: 3.3s\tremaining: 15.2s\n",
      "89:\tlearn: 0.4514303\ttotal: 3.33s\tremaining: 15.2s\n",
      "90:\tlearn: 0.4495131\ttotal: 3.35s\tremaining: 15s\n",
      "91:\tlearn: 0.4472604\ttotal: 3.39s\tremaining: 15s\n",
      "92:\tlearn: 0.4449614\ttotal: 3.45s\tremaining: 15.1s\n",
      "93:\tlearn: 0.4431772\ttotal: 3.48s\tremaining: 15s\n",
      "94:\tlearn: 0.4415567\ttotal: 3.51s\tremaining: 15s\n",
      "95:\tlearn: 0.4399863\ttotal: 3.53s\tremaining: 14.9s\n",
      "96:\tlearn: 0.4382046\ttotal: 3.58s\tremaining: 14.9s\n",
      "97:\tlearn: 0.4359659\ttotal: 3.63s\tremaining: 14.9s\n",
      "98:\tlearn: 0.4340725\ttotal: 3.65s\tremaining: 14.8s\n",
      "99:\tlearn: 0.4327015\ttotal: 3.67s\tremaining: 14.7s\n",
      "100:\tlearn: 0.4300410\ttotal: 3.75s\tremaining: 14.8s\n",
      "101:\tlearn: 0.4283987\ttotal: 3.8s\tremaining: 14.8s\n",
      "102:\tlearn: 0.4263881\ttotal: 3.82s\tremaining: 14.7s\n",
      "103:\tlearn: 0.4238721\ttotal: 3.84s\tremaining: 14.6s\n",
      "104:\tlearn: 0.4223397\ttotal: 3.9s\tremaining: 14.7s\n",
      "105:\tlearn: 0.4204028\ttotal: 3.95s\tremaining: 14.7s\n",
      "106:\tlearn: 0.4178828\ttotal: 3.98s\tremaining: 14.6s\n",
      "107:\tlearn: 0.4162498\ttotal: 4.01s\tremaining: 14.6s\n",
      "108:\tlearn: 0.4147506\ttotal: 4.03s\tremaining: 14.5s\n",
      "109:\tlearn: 0.4130263\ttotal: 4.1s\tremaining: 14.5s\n",
      "110:\tlearn: 0.4115652\ttotal: 4.15s\tremaining: 14.5s\n",
      "111:\tlearn: 0.4100856\ttotal: 4.17s\tremaining: 14.5s\n",
      "112:\tlearn: 0.4085304\ttotal: 4.19s\tremaining: 14.4s\n",
      "113:\tlearn: 0.4069611\ttotal: 4.21s\tremaining: 14.3s\n",
      "114:\tlearn: 0.4055690\ttotal: 4.28s\tremaining: 14.3s\n",
      "115:\tlearn: 0.4042341\ttotal: 4.33s\tremaining: 14.3s\n",
      "116:\tlearn: 0.4025752\ttotal: 4.35s\tremaining: 14.2s\n",
      "117:\tlearn: 0.4006755\ttotal: 4.37s\tremaining: 14.2s\n",
      "118:\tlearn: 0.3992060\ttotal: 4.39s\tremaining: 14.1s\n",
      "119:\tlearn: 0.3978156\ttotal: 4.46s\tremaining: 14.1s\n",
      "120:\tlearn: 0.3965673\ttotal: 4.5s\tremaining: 14.1s\n",
      "121:\tlearn: 0.3947644\ttotal: 4.53s\tremaining: 14s\n",
      "122:\tlearn: 0.3927753\ttotal: 4.55s\tremaining: 13.9s\n",
      "123:\tlearn: 0.3911418\ttotal: 4.61s\tremaining: 14s\n",
      "124:\tlearn: 0.3902845\ttotal: 4.66s\tremaining: 14s\n",
      "125:\tlearn: 0.3881953\ttotal: 4.7s\tremaining: 13.9s\n",
      "126:\tlearn: 0.3869160\ttotal: 4.72s\tremaining: 13.9s\n",
      "127:\tlearn: 0.3855713\ttotal: 4.74s\tremaining: 13.8s\n",
      "128:\tlearn: 0.3835140\ttotal: 4.81s\tremaining: 13.8s\n",
      "129:\tlearn: 0.3816942\ttotal: 4.86s\tremaining: 13.8s\n",
      "130:\tlearn: 0.3806652\ttotal: 4.88s\tremaining: 13.8s\n",
      "131:\tlearn: 0.3791803\ttotal: 4.9s\tremaining: 13.7s\n",
      "132:\tlearn: 0.3771101\ttotal: 4.92s\tremaining: 13.6s\n",
      "133:\tlearn: 0.3755242\ttotal: 5s\tremaining: 13.6s\n",
      "134:\tlearn: 0.3742030\ttotal: 5.04s\tremaining: 13.6s\n",
      "135:\tlearn: 0.3724437\ttotal: 5.07s\tremaining: 13.6s\n",
      "136:\tlearn: 0.3712746\ttotal: 5.09s\tremaining: 13.5s\n",
      "137:\tlearn: 0.3702479\ttotal: 5.12s\tremaining: 13.4s\n",
      "138:\tlearn: 0.3693878\ttotal: 5.19s\tremaining: 13.5s\n",
      "139:\tlearn: 0.3681797\ttotal: 5.25s\tremaining: 13.5s\n",
      "140:\tlearn: 0.3665200\ttotal: 5.28s\tremaining: 13.5s\n",
      "141:\tlearn: 0.3645856\ttotal: 5.3s\tremaining: 13.4s\n",
      "142:\tlearn: 0.3630581\ttotal: 5.33s\tremaining: 13.3s\n",
      "143:\tlearn: 0.3617613\ttotal: 5.4s\tremaining: 13.4s\n",
      "144:\tlearn: 0.3605185\ttotal: 5.45s\tremaining: 13.3s\n",
      "145:\tlearn: 0.3595512\ttotal: 5.47s\tremaining: 13.3s\n",
      "146:\tlearn: 0.3581850\ttotal: 5.49s\tremaining: 13.2s\n",
      "147:\tlearn: 0.3563142\ttotal: 5.51s\tremaining: 13.1s\n",
      "148:\tlearn: 0.3551307\ttotal: 5.58s\tremaining: 13.1s\n",
      "149:\tlearn: 0.3539604\ttotal: 5.63s\tremaining: 13.1s\n",
      "150:\tlearn: 0.3522995\ttotal: 5.65s\tremaining: 13.1s\n",
      "151:\tlearn: 0.3513698\ttotal: 5.67s\tremaining: 13s\n",
      "152:\tlearn: 0.3498260\ttotal: 5.71s\tremaining: 13s\n",
      "153:\tlearn: 0.3475117\ttotal: 5.78s\tremaining: 13s\n",
      "154:\tlearn: 0.3462748\ttotal: 5.81s\tremaining: 12.9s\n",
      "155:\tlearn: 0.3448967\ttotal: 5.83s\tremaining: 12.9s\n",
      "156:\tlearn: 0.3436733\ttotal: 5.85s\tremaining: 12.8s\n",
      "157:\tlearn: 0.3423734\ttotal: 5.92s\tremaining: 12.8s\n",
      "158:\tlearn: 0.3411793\ttotal: 5.96s\tremaining: 12.8s\n",
      "159:\tlearn: 0.3397436\ttotal: 5.99s\tremaining: 12.7s\n",
      "160:\tlearn: 0.3389492\ttotal: 6.01s\tremaining: 12.7s\n",
      "161:\tlearn: 0.3375415\ttotal: 6.05s\tremaining: 12.6s\n",
      "162:\tlearn: 0.3363899\ttotal: 6.13s\tremaining: 12.7s\n",
      "163:\tlearn: 0.3352783\ttotal: 6.16s\tremaining: 12.6s\n",
      "164:\tlearn: 0.3341129\ttotal: 6.18s\tremaining: 12.6s\n",
      "165:\tlearn: 0.3324759\ttotal: 6.2s\tremaining: 12.5s\n",
      "166:\tlearn: 0.3314728\ttotal: 6.24s\tremaining: 12.4s\n",
      "167:\tlearn: 0.3298345\ttotal: 6.31s\tremaining: 12.5s\n",
      "168:\tlearn: 0.3289403\ttotal: 6.35s\tremaining: 12.4s\n",
      "169:\tlearn: 0.3276657\ttotal: 6.38s\tremaining: 12.4s\n",
      "170:\tlearn: 0.3264306\ttotal: 6.4s\tremaining: 12.3s\n",
      "171:\tlearn: 0.3252485\ttotal: 6.46s\tremaining: 12.3s\n",
      "172:\tlearn: 0.3237127\ttotal: 6.51s\tremaining: 12.3s\n",
      "173:\tlearn: 0.3225119\ttotal: 6.54s\tremaining: 12.3s\n",
      "174:\tlearn: 0.3213945\ttotal: 6.57s\tremaining: 12.2s\n",
      "175:\tlearn: 0.3201694\ttotal: 6.59s\tremaining: 12.1s\n",
      "176:\tlearn: 0.3193728\ttotal: 6.66s\tremaining: 12.1s\n",
      "177:\tlearn: 0.3179385\ttotal: 6.71s\tremaining: 12.1s\n",
      "178:\tlearn: 0.3170677\ttotal: 6.73s\tremaining: 12.1s\n",
      "179:\tlearn: 0.3160528\ttotal: 6.75s\tremaining: 12s\n",
      "180:\tlearn: 0.3151280\ttotal: 6.79s\tremaining: 12s\n",
      "181:\tlearn: 0.3137477\ttotal: 6.86s\tremaining: 12s\n",
      "182:\tlearn: 0.3124010\ttotal: 6.9s\tremaining: 11.9s\n",
      "183:\tlearn: 0.3112455\ttotal: 6.92s\tremaining: 11.9s\n",
      "184:\tlearn: 0.3096444\ttotal: 6.94s\tremaining: 11.8s\n",
      "185:\tlearn: 0.3084648\ttotal: 7.01s\tremaining: 11.8s\n",
      "186:\tlearn: 0.3070974\ttotal: 7.06s\tremaining: 11.8s\n",
      "187:\tlearn: 0.3063281\ttotal: 7.08s\tremaining: 11.8s\n",
      "188:\tlearn: 0.3054535\ttotal: 7.11s\tremaining: 11.7s\n",
      "189:\tlearn: 0.3040131\ttotal: 7.13s\tremaining: 11.6s\n",
      "190:\tlearn: 0.3031767\ttotal: 7.2s\tremaining: 11.7s\n",
      "191:\tlearn: 0.3022788\ttotal: 7.24s\tremaining: 11.6s\n",
      "192:\tlearn: 0.3011649\ttotal: 7.26s\tremaining: 11.6s\n",
      "193:\tlearn: 0.3000751\ttotal: 7.29s\tremaining: 11.5s\n",
      "194:\tlearn: 0.2993228\ttotal: 7.31s\tremaining: 11.4s\n",
      "195:\tlearn: 0.2983869\ttotal: 7.37s\tremaining: 11.4s\n",
      "196:\tlearn: 0.2973977\ttotal: 7.44s\tremaining: 11.4s\n",
      "197:\tlearn: 0.2962993\ttotal: 7.48s\tremaining: 11.4s\n",
      "198:\tlearn: 0.2953769\ttotal: 7.5s\tremaining: 11.3s\n",
      "199:\tlearn: 0.2946323\ttotal: 7.52s\tremaining: 11.3s\n",
      "200:\tlearn: 0.2935356\ttotal: 7.59s\tremaining: 11.3s\n",
      "201:\tlearn: 0.2926146\ttotal: 7.63s\tremaining: 11.3s\n",
      "202:\tlearn: 0.2912954\ttotal: 7.66s\tremaining: 11.2s\n",
      "203:\tlearn: 0.2898848\ttotal: 7.68s\tremaining: 11.1s\n",
      "204:\tlearn: 0.2889799\ttotal: 7.75s\tremaining: 11.2s\n",
      "205:\tlearn: 0.2878313\ttotal: 7.78s\tremaining: 11.1s\n",
      "206:\tlearn: 0.2868219\ttotal: 7.81s\tremaining: 11.1s\n",
      "207:\tlearn: 0.2861137\ttotal: 7.83s\tremaining: 11s\n",
      "208:\tlearn: 0.2851199\ttotal: 7.91s\tremaining: 11s\n",
      "209:\tlearn: 0.2840010\ttotal: 7.94s\tremaining: 11s\n",
      "210:\tlearn: 0.2829396\ttotal: 7.97s\tremaining: 10.9s\n",
      "211:\tlearn: 0.2815994\ttotal: 7.99s\tremaining: 10.9s\n",
      "212:\tlearn: 0.2804447\ttotal: 8.04s\tremaining: 10.8s\n",
      "213:\tlearn: 0.2795859\ttotal: 8.1s\tremaining: 10.8s\n",
      "214:\tlearn: 0.2779820\ttotal: 8.13s\tremaining: 10.8s\n",
      "215:\tlearn: 0.2768391\ttotal: 8.16s\tremaining: 10.7s\n",
      "216:\tlearn: 0.2760457\ttotal: 8.18s\tremaining: 10.7s\n",
      "217:\tlearn: 0.2751395\ttotal: 8.23s\tremaining: 10.7s\n",
      "218:\tlearn: 0.2742767\ttotal: 8.29s\tremaining: 10.6s\n",
      "219:\tlearn: 0.2734297\ttotal: 8.32s\tremaining: 10.6s\n",
      "220:\tlearn: 0.2725682\ttotal: 8.34s\tremaining: 10.5s\n",
      "221:\tlearn: 0.2714949\ttotal: 8.36s\tremaining: 10.5s\n",
      "222:\tlearn: 0.2705354\ttotal: 8.43s\tremaining: 10.5s\n",
      "223:\tlearn: 0.2695632\ttotal: 8.47s\tremaining: 10.4s\n",
      "224:\tlearn: 0.2687165\ttotal: 8.5s\tremaining: 10.4s\n",
      "225:\tlearn: 0.2680447\ttotal: 8.52s\tremaining: 10.3s\n",
      "226:\tlearn: 0.2668310\ttotal: 8.54s\tremaining: 10.3s\n",
      "227:\tlearn: 0.2661868\ttotal: 8.62s\tremaining: 10.3s\n",
      "228:\tlearn: 0.2653221\ttotal: 8.65s\tremaining: 10.2s\n",
      "229:\tlearn: 0.2643365\ttotal: 8.68s\tremaining: 10.2s\n",
      "230:\tlearn: 0.2633778\ttotal: 8.7s\tremaining: 10.1s\n",
      "231:\tlearn: 0.2624839\ttotal: 8.72s\tremaining: 10.1s\n",
      "232:\tlearn: 0.2613307\ttotal: 8.79s\tremaining: 10.1s\n",
      "233:\tlearn: 0.2604670\ttotal: 8.83s\tremaining: 10s\n",
      "234:\tlearn: 0.2591206\ttotal: 8.86s\tremaining: 9.99s\n",
      "235:\tlearn: 0.2583302\ttotal: 8.88s\tremaining: 9.93s\n",
      "236:\tlearn: 0.2574818\ttotal: 8.9s\tremaining: 9.88s\n",
      "237:\tlearn: 0.2567140\ttotal: 8.98s\tremaining: 9.88s\n",
      "238:\tlearn: 0.2556120\ttotal: 9.01s\tremaining: 9.84s\n",
      "239:\tlearn: 0.2546853\ttotal: 9.03s\tremaining: 9.79s\n",
      "240:\tlearn: 0.2537463\ttotal: 9.05s\tremaining: 9.73s\n",
      "241:\tlearn: 0.2525691\ttotal: 9.11s\tremaining: 9.71s\n",
      "242:\tlearn: 0.2517612\ttotal: 9.17s\tremaining: 9.7s\n",
      "243:\tlearn: 0.2509889\ttotal: 9.2s\tremaining: 9.65s\n",
      "244:\tlearn: 0.2503075\ttotal: 9.22s\tremaining: 9.6s\n",
      "245:\tlearn: 0.2496118\ttotal: 9.27s\tremaining: 9.57s\n",
      "246:\tlearn: 0.2489176\ttotal: 9.34s\tremaining: 9.56s\n",
      "247:\tlearn: 0.2480412\ttotal: 9.37s\tremaining: 9.52s\n",
      "248:\tlearn: 0.2472122\ttotal: 9.4s\tremaining: 9.47s\n",
      "249:\tlearn: 0.2463991\ttotal: 9.42s\tremaining: 9.42s\n",
      "250:\tlearn: 0.2452636\ttotal: 9.49s\tremaining: 9.41s\n",
      "251:\tlearn: 0.2443193\ttotal: 9.53s\tremaining: 9.38s\n",
      "252:\tlearn: 0.2432749\ttotal: 9.56s\tremaining: 9.33s\n",
      "253:\tlearn: 0.2423183\ttotal: 9.58s\tremaining: 9.28s\n",
      "254:\tlearn: 0.2415097\ttotal: 9.6s\tremaining: 9.22s\n",
      "255:\tlearn: 0.2408150\ttotal: 9.67s\tremaining: 9.22s\n",
      "256:\tlearn: 0.2400151\ttotal: 9.71s\tremaining: 9.18s\n",
      "257:\tlearn: 0.2392547\ttotal: 9.73s\tremaining: 9.13s\n",
      "258:\tlearn: 0.2382286\ttotal: 9.75s\tremaining: 9.07s\n",
      "259:\tlearn: 0.2373322\ttotal: 9.77s\tremaining: 9.02s\n",
      "260:\tlearn: 0.2364820\ttotal: 9.85s\tremaining: 9.02s\n",
      "261:\tlearn: 0.2354111\ttotal: 9.93s\tremaining: 9.02s\n",
      "262:\tlearn: 0.2348781\ttotal: 10s\tremaining: 9.01s\n",
      "263:\tlearn: 0.2341686\ttotal: 10s\tremaining: 8.96s\n",
      "264:\tlearn: 0.2334866\ttotal: 10s\tremaining: 8.91s\n",
      "265:\tlearn: 0.2321760\ttotal: 10.1s\tremaining: 8.86s\n",
      "266:\tlearn: 0.2314990\ttotal: 10.1s\tremaining: 8.8s\n",
      "267:\tlearn: 0.2307290\ttotal: 10.2s\tremaining: 8.8s\n",
      "268:\tlearn: 0.2299148\ttotal: 10.2s\tremaining: 8.76s\n",
      "269:\tlearn: 0.2290954\ttotal: 10.2s\tremaining: 8.7s\n",
      "270:\tlearn: 0.2284435\ttotal: 10.2s\tremaining: 8.64s\n",
      "271:\tlearn: 0.2279152\ttotal: 10.2s\tremaining: 8.59s\n",
      "272:\tlearn: 0.2271628\ttotal: 10.3s\tremaining: 8.57s\n",
      "273:\tlearn: 0.2262105\ttotal: 10.3s\tremaining: 8.51s\n",
      "274:\tlearn: 0.2257311\ttotal: 10.3s\tremaining: 8.46s\n",
      "275:\tlearn: 0.2249399\ttotal: 10.4s\tremaining: 8.41s\n",
      "276:\tlearn: 0.2241373\ttotal: 10.4s\tremaining: 8.36s\n",
      "277:\tlearn: 0.2234085\ttotal: 10.4s\tremaining: 8.3s\n",
      "278:\tlearn: 0.2227940\ttotal: 10.4s\tremaining: 8.26s\n",
      "279:\tlearn: 0.2219196\ttotal: 10.5s\tremaining: 8.21s\n",
      "280:\tlearn: 0.2211788\ttotal: 10.5s\tremaining: 8.17s\n",
      "281:\tlearn: 0.2203638\ttotal: 10.5s\tremaining: 8.12s\n",
      "282:\tlearn: 0.2196813\ttotal: 10.6s\tremaining: 8.1s\n",
      "283:\tlearn: 0.2187764\ttotal: 10.6s\tremaining: 8.07s\n",
      "284:\tlearn: 0.2180370\ttotal: 10.6s\tremaining: 8.03s\n",
      "285:\tlearn: 0.2171954\ttotal: 10.7s\tremaining: 7.98s\n",
      "286:\tlearn: 0.2163487\ttotal: 10.7s\tremaining: 7.93s\n",
      "287:\tlearn: 0.2156872\ttotal: 10.8s\tremaining: 7.92s\n",
      "288:\tlearn: 0.2151934\ttotal: 10.8s\tremaining: 7.88s\n",
      "289:\tlearn: 0.2144519\ttotal: 10.8s\tremaining: 7.84s\n",
      "290:\tlearn: 0.2136937\ttotal: 10.9s\tremaining: 7.8s\n",
      "291:\tlearn: 0.2131361\ttotal: 10.9s\tremaining: 7.78s\n",
      "292:\tlearn: 0.2126675\ttotal: 11s\tremaining: 7.76s\n",
      "293:\tlearn: 0.2120488\ttotal: 11s\tremaining: 7.71s\n",
      "294:\tlearn: 0.2113737\ttotal: 11s\tremaining: 7.66s\n",
      "295:\tlearn: 0.2103401\ttotal: 11.1s\tremaining: 7.63s\n",
      "296:\tlearn: 0.2096665\ttotal: 11.1s\tremaining: 7.61s\n",
      "297:\tlearn: 0.2089635\ttotal: 11.2s\tremaining: 7.57s\n",
      "298:\tlearn: 0.2083088\ttotal: 11.2s\tremaining: 7.52s\n",
      "299:\tlearn: 0.2077450\ttotal: 11.2s\tremaining: 7.47s\n",
      "300:\tlearn: 0.2070104\ttotal: 11.3s\tremaining: 7.46s\n",
      "301:\tlearn: 0.2061690\ttotal: 11.3s\tremaining: 7.42s\n",
      "302:\tlearn: 0.2054709\ttotal: 11.3s\tremaining: 7.38s\n",
      "303:\tlearn: 0.2045815\ttotal: 11.4s\tremaining: 7.33s\n",
      "304:\tlearn: 0.2038264\ttotal: 11.4s\tremaining: 7.3s\n",
      "305:\tlearn: 0.2033274\ttotal: 11.5s\tremaining: 7.28s\n",
      "306:\tlearn: 0.2025289\ttotal: 11.5s\tremaining: 7.24s\n",
      "307:\tlearn: 0.2017496\ttotal: 11.5s\tremaining: 7.19s\n",
      "308:\tlearn: 0.2011728\ttotal: 11.6s\tremaining: 7.14s\n",
      "309:\tlearn: 0.2005266\ttotal: 11.6s\tremaining: 7.13s\n",
      "310:\tlearn: 0.1996078\ttotal: 11.7s\tremaining: 7.09s\n",
      "311:\tlearn: 0.1990727\ttotal: 11.7s\tremaining: 7.04s\n",
      "312:\tlearn: 0.1984636\ttotal: 11.7s\tremaining: 6.99s\n",
      "313:\tlearn: 0.1977246\ttotal: 11.8s\tremaining: 6.97s\n",
      "314:\tlearn: 0.1970542\ttotal: 11.8s\tremaining: 6.94s\n",
      "315:\tlearn: 0.1964859\ttotal: 11.8s\tremaining: 6.89s\n",
      "316:\tlearn: 0.1958447\ttotal: 11.9s\tremaining: 6.84s\n",
      "317:\tlearn: 0.1947972\ttotal: 11.9s\tremaining: 6.83s\n",
      "318:\tlearn: 0.1942982\ttotal: 12s\tremaining: 6.79s\n",
      "319:\tlearn: 0.1939139\ttotal: 12s\tremaining: 6.75s\n",
      "320:\tlearn: 0.1934598\ttotal: 12s\tremaining: 6.7s\n",
      "321:\tlearn: 0.1928066\ttotal: 12.1s\tremaining: 6.67s\n",
      "322:\tlearn: 0.1924299\ttotal: 12.1s\tremaining: 6.65s\n",
      "323:\tlearn: 0.1916729\ttotal: 12.2s\tremaining: 6.61s\n",
      "324:\tlearn: 0.1909671\ttotal: 12.2s\tremaining: 6.56s\n",
      "325:\tlearn: 0.1901547\ttotal: 12.2s\tremaining: 6.51s\n",
      "326:\tlearn: 0.1893484\ttotal: 12.3s\tremaining: 6.5s\n",
      "327:\tlearn: 0.1886899\ttotal: 12.3s\tremaining: 6.46s\n",
      "328:\tlearn: 0.1880619\ttotal: 12.3s\tremaining: 6.42s\n",
      "329:\tlearn: 0.1875498\ttotal: 12.4s\tremaining: 6.37s\n",
      "330:\tlearn: 0.1868738\ttotal: 12.4s\tremaining: 6.33s\n",
      "331:\tlearn: 0.1863718\ttotal: 12.5s\tremaining: 6.31s\n",
      "332:\tlearn: 0.1858296\ttotal: 12.5s\tremaining: 6.27s\n",
      "333:\tlearn: 0.1852610\ttotal: 12.5s\tremaining: 6.23s\n",
      "334:\tlearn: 0.1845241\ttotal: 12.6s\tremaining: 6.18s\n",
      "335:\tlearn: 0.1839030\ttotal: 12.6s\tremaining: 6.16s\n",
      "336:\tlearn: 0.1834065\ttotal: 12.7s\tremaining: 6.13s\n",
      "337:\tlearn: 0.1828412\ttotal: 12.7s\tremaining: 6.09s\n",
      "338:\tlearn: 0.1818048\ttotal: 12.7s\tremaining: 6.04s\n",
      "339:\tlearn: 0.1812287\ttotal: 12.8s\tremaining: 6s\n",
      "340:\tlearn: 0.1807287\ttotal: 12.8s\tremaining: 5.98s\n",
      "341:\tlearn: 0.1802459\ttotal: 12.8s\tremaining: 5.94s\n",
      "342:\tlearn: 0.1797472\ttotal: 12.9s\tremaining: 5.9s\n",
      "343:\tlearn: 0.1794116\ttotal: 13s\tremaining: 5.88s\n",
      "344:\tlearn: 0.1788128\ttotal: 13s\tremaining: 5.83s\n",
      "345:\tlearn: 0.1781100\ttotal: 13s\tremaining: 5.79s\n",
      "346:\tlearn: 0.1776483\ttotal: 13s\tremaining: 5.75s\n",
      "347:\tlearn: 0.1769767\ttotal: 13.1s\tremaining: 5.73s\n",
      "348:\tlearn: 0.1762483\ttotal: 13.2s\tremaining: 5.69s\n",
      "349:\tlearn: 0.1758041\ttotal: 13.2s\tremaining: 5.65s\n",
      "350:\tlearn: 0.1751685\ttotal: 13.2s\tremaining: 5.6s\n",
      "351:\tlearn: 0.1745886\ttotal: 13.2s\tremaining: 5.57s\n",
      "352:\tlearn: 0.1739951\ttotal: 13.3s\tremaining: 5.54s\n",
      "353:\tlearn: 0.1735551\ttotal: 13.4s\tremaining: 5.51s\n",
      "354:\tlearn: 0.1731296\ttotal: 13.4s\tremaining: 5.46s\n",
      "355:\tlearn: 0.1726054\ttotal: 13.4s\tremaining: 5.42s\n",
      "356:\tlearn: 0.1721091\ttotal: 13.5s\tremaining: 5.39s\n",
      "357:\tlearn: 0.1716211\ttotal: 13.5s\tremaining: 5.36s\n",
      "358:\tlearn: 0.1712366\ttotal: 13.5s\tremaining: 5.32s\n",
      "359:\tlearn: 0.1708461\ttotal: 13.6s\tremaining: 5.27s\n",
      "360:\tlearn: 0.1704039\ttotal: 13.6s\tremaining: 5.24s\n",
      "361:\tlearn: 0.1699909\ttotal: 13.7s\tremaining: 5.21s\n",
      "362:\tlearn: 0.1694899\ttotal: 13.7s\tremaining: 5.17s\n",
      "363:\tlearn: 0.1690760\ttotal: 13.7s\tremaining: 5.13s\n",
      "364:\tlearn: 0.1683389\ttotal: 13.7s\tremaining: 5.08s\n",
      "365:\tlearn: 0.1677942\ttotal: 13.8s\tremaining: 5.06s\n",
      "366:\tlearn: 0.1671734\ttotal: 13.9s\tremaining: 5.02s\n",
      "367:\tlearn: 0.1668352\ttotal: 13.9s\tremaining: 4.98s\n",
      "368:\tlearn: 0.1662788\ttotal: 13.9s\tremaining: 4.94s\n",
      "369:\tlearn: 0.1657426\ttotal: 13.9s\tremaining: 4.89s\n",
      "370:\tlearn: 0.1653497\ttotal: 14s\tremaining: 4.85s\n",
      "371:\tlearn: 0.1649618\ttotal: 14s\tremaining: 4.82s\n",
      "372:\tlearn: 0.1645027\ttotal: 14.1s\tremaining: 4.79s\n",
      "373:\tlearn: 0.1639618\ttotal: 14.1s\tremaining: 4.75s\n",
      "374:\tlearn: 0.1635514\ttotal: 14.1s\tremaining: 4.71s\n",
      "375:\tlearn: 0.1627824\ttotal: 14.2s\tremaining: 4.67s\n",
      "376:\tlearn: 0.1621534\ttotal: 14.2s\tremaining: 4.64s\n",
      "377:\tlearn: 0.1614821\ttotal: 14.3s\tremaining: 4.61s\n",
      "378:\tlearn: 0.1609937\ttotal: 14.3s\tremaining: 4.57s\n",
      "379:\tlearn: 0.1606637\ttotal: 14.3s\tremaining: 4.52s\n",
      "380:\tlearn: 0.1603194\ttotal: 14.4s\tremaining: 4.49s\n",
      "381:\tlearn: 0.1598174\ttotal: 14.4s\tremaining: 4.46s\n",
      "382:\tlearn: 0.1593482\ttotal: 14.5s\tremaining: 4.42s\n",
      "383:\tlearn: 0.1588260\ttotal: 14.5s\tremaining: 4.38s\n",
      "384:\tlearn: 0.1582652\ttotal: 14.5s\tremaining: 4.33s\n",
      "385:\tlearn: 0.1575148\ttotal: 14.6s\tremaining: 4.31s\n",
      "386:\tlearn: 0.1568442\ttotal: 14.6s\tremaining: 4.27s\n",
      "387:\tlearn: 0.1564282\ttotal: 14.7s\tremaining: 4.23s\n",
      "388:\tlearn: 0.1557502\ttotal: 14.7s\tremaining: 4.19s\n",
      "389:\tlearn: 0.1550662\ttotal: 14.7s\tremaining: 4.15s\n",
      "390:\tlearn: 0.1545935\ttotal: 14.8s\tremaining: 4.12s\n",
      "391:\tlearn: 0.1541495\ttotal: 14.8s\tremaining: 4.08s\n",
      "392:\tlearn: 0.1536211\ttotal: 14.8s\tremaining: 4.04s\n",
      "393:\tlearn: 0.1531298\ttotal: 14.9s\tremaining: 4s\n",
      "394:\tlearn: 0.1527096\ttotal: 14.9s\tremaining: 3.97s\n",
      "395:\tlearn: 0.1521310\ttotal: 15s\tremaining: 3.93s\n",
      "396:\tlearn: 0.1516462\ttotal: 15s\tremaining: 3.9s\n",
      "397:\tlearn: 0.1512069\ttotal: 15s\tremaining: 3.85s\n",
      "398:\tlearn: 0.1505464\ttotal: 15.1s\tremaining: 3.82s\n",
      "399:\tlearn: 0.1499337\ttotal: 15.1s\tremaining: 3.79s\n",
      "400:\tlearn: 0.1496077\ttotal: 15.2s\tremaining: 3.75s\n",
      "401:\tlearn: 0.1491533\ttotal: 15.2s\tremaining: 3.71s\n",
      "402:\tlearn: 0.1487195\ttotal: 15.2s\tremaining: 3.67s\n",
      "403:\tlearn: 0.1480176\ttotal: 15.3s\tremaining: 3.64s\n",
      "404:\tlearn: 0.1477028\ttotal: 15.3s\tremaining: 3.6s\n",
      "405:\tlearn: 0.1473310\ttotal: 15.4s\tremaining: 3.56s\n",
      "406:\tlearn: 0.1469087\ttotal: 15.4s\tremaining: 3.52s\n",
      "407:\tlearn: 0.1465507\ttotal: 15.4s\tremaining: 3.47s\n",
      "408:\tlearn: 0.1461939\ttotal: 15.5s\tremaining: 3.44s\n",
      "409:\tlearn: 0.1457859\ttotal: 15.5s\tremaining: 3.4s\n",
      "410:\tlearn: 0.1453506\ttotal: 15.5s\tremaining: 3.36s\n",
      "411:\tlearn: 0.1448061\ttotal: 15.6s\tremaining: 3.32s\n",
      "412:\tlearn: 0.1444838\ttotal: 15.6s\tremaining: 3.29s\n",
      "413:\tlearn: 0.1439928\ttotal: 15.7s\tremaining: 3.25s\n",
      "414:\tlearn: 0.1436665\ttotal: 15.7s\tremaining: 3.21s\n",
      "415:\tlearn: 0.1432813\ttotal: 15.7s\tremaining: 3.17s\n",
      "416:\tlearn: 0.1429730\ttotal: 15.8s\tremaining: 3.14s\n",
      "417:\tlearn: 0.1424352\ttotal: 15.8s\tremaining: 3.1s\n",
      "418:\tlearn: 0.1419646\ttotal: 15.9s\tremaining: 3.06s\n",
      "419:\tlearn: 0.1415386\ttotal: 15.9s\tremaining: 3.02s\n",
      "420:\tlearn: 0.1411280\ttotal: 15.9s\tremaining: 2.98s\n",
      "421:\tlearn: 0.1406189\ttotal: 16s\tremaining: 2.95s\n",
      "422:\tlearn: 0.1403380\ttotal: 16s\tremaining: 2.92s\n",
      "423:\tlearn: 0.1400456\ttotal: 16s\tremaining: 2.88s\n",
      "424:\tlearn: 0.1396077\ttotal: 16.1s\tremaining: 2.83s\n",
      "425:\tlearn: 0.1390384\ttotal: 16.1s\tremaining: 2.8s\n",
      "426:\tlearn: 0.1386844\ttotal: 16.2s\tremaining: 2.76s\n",
      "427:\tlearn: 0.1381370\ttotal: 16.2s\tremaining: 2.73s\n",
      "428:\tlearn: 0.1376430\ttotal: 16.2s\tremaining: 2.69s\n",
      "429:\tlearn: 0.1371245\ttotal: 16.3s\tremaining: 2.65s\n",
      "430:\tlearn: 0.1368487\ttotal: 16.3s\tremaining: 2.61s\n",
      "431:\tlearn: 0.1361720\ttotal: 16.3s\tremaining: 2.57s\n",
      "432:\tlearn: 0.1357746\ttotal: 16.4s\tremaining: 2.53s\n",
      "433:\tlearn: 0.1352826\ttotal: 16.4s\tremaining: 2.49s\n",
      "434:\tlearn: 0.1349210\ttotal: 16.4s\tremaining: 2.46s\n",
      "435:\tlearn: 0.1345581\ttotal: 16.5s\tremaining: 2.42s\n",
      "436:\tlearn: 0.1341009\ttotal: 16.5s\tremaining: 2.38s\n",
      "437:\tlearn: 0.1338727\ttotal: 16.6s\tremaining: 2.34s\n",
      "438:\tlearn: 0.1335992\ttotal: 16.6s\tremaining: 2.3s\n",
      "439:\tlearn: 0.1331439\ttotal: 16.6s\tremaining: 2.26s\n",
      "440:\tlearn: 0.1326022\ttotal: 16.6s\tremaining: 2.22s\n",
      "441:\tlearn: 0.1323271\ttotal: 16.7s\tremaining: 2.19s\n",
      "442:\tlearn: 0.1319149\ttotal: 16.7s\tremaining: 2.15s\n",
      "443:\tlearn: 0.1315425\ttotal: 16.8s\tremaining: 2.11s\n",
      "444:\tlearn: 0.1312209\ttotal: 16.8s\tremaining: 2.07s\n",
      "445:\tlearn: 0.1306456\ttotal: 16.8s\tremaining: 2.04s\n",
      "446:\tlearn: 0.1303356\ttotal: 16.9s\tremaining: 2s\n",
      "447:\tlearn: 0.1299556\ttotal: 16.9s\tremaining: 1.96s\n",
      "448:\tlearn: 0.1295022\ttotal: 16.9s\tremaining: 1.92s\n",
      "449:\tlearn: 0.1290752\ttotal: 17s\tremaining: 1.89s\n",
      "450:\tlearn: 0.1287565\ttotal: 17s\tremaining: 1.85s\n",
      "451:\tlearn: 0.1283429\ttotal: 17.1s\tremaining: 1.81s\n",
      "452:\tlearn: 0.1280554\ttotal: 17.1s\tremaining: 1.77s\n",
      "453:\tlearn: 0.1277497\ttotal: 17.1s\tremaining: 1.74s\n",
      "454:\tlearn: 0.1274071\ttotal: 17.1s\tremaining: 1.7s\n",
      "455:\tlearn: 0.1269391\ttotal: 17.2s\tremaining: 1.66s\n",
      "456:\tlearn: 0.1265928\ttotal: 17.3s\tremaining: 1.62s\n",
      "457:\tlearn: 0.1261031\ttotal: 17.3s\tremaining: 1.58s\n",
      "458:\tlearn: 0.1256789\ttotal: 17.3s\tremaining: 1.55s\n",
      "459:\tlearn: 0.1251047\ttotal: 17.3s\tremaining: 1.51s\n",
      "460:\tlearn: 0.1247084\ttotal: 17.4s\tremaining: 1.47s\n",
      "461:\tlearn: 0.1243464\ttotal: 17.5s\tremaining: 1.44s\n",
      "462:\tlearn: 0.1240566\ttotal: 17.5s\tremaining: 1.4s\n",
      "463:\tlearn: 0.1236238\ttotal: 17.5s\tremaining: 1.36s\n",
      "464:\tlearn: 0.1233951\ttotal: 17.5s\tremaining: 1.32s\n",
      "465:\tlearn: 0.1230166\ttotal: 17.6s\tremaining: 1.28s\n",
      "466:\tlearn: 0.1228030\ttotal: 17.6s\tremaining: 1.25s\n",
      "467:\tlearn: 0.1226012\ttotal: 17.7s\tremaining: 1.21s\n",
      "468:\tlearn: 0.1224030\ttotal: 17.7s\tremaining: 1.17s\n",
      "469:\tlearn: 0.1220688\ttotal: 17.7s\tremaining: 1.13s\n",
      "470:\tlearn: 0.1217754\ttotal: 17.7s\tremaining: 1.09s\n",
      "471:\tlearn: 0.1214314\ttotal: 17.8s\tremaining: 1.05s\n",
      "472:\tlearn: 0.1211559\ttotal: 17.8s\tremaining: 1.02s\n",
      "473:\tlearn: 0.1208938\ttotal: 17.9s\tremaining: 979ms\n",
      "474:\tlearn: 0.1204694\ttotal: 17.9s\tremaining: 941ms\n",
      "475:\tlearn: 0.1200777\ttotal: 17.9s\tremaining: 905ms\n",
      "476:\tlearn: 0.1196864\ttotal: 18s\tremaining: 867ms\n",
      "477:\tlearn: 0.1194029\ttotal: 18s\tremaining: 829ms\n",
      "478:\tlearn: 0.1190876\ttotal: 18s\tremaining: 790ms\n",
      "479:\tlearn: 0.1186434\ttotal: 18.1s\tremaining: 754ms\n",
      "480:\tlearn: 0.1183694\ttotal: 18.1s\tremaining: 717ms\n",
      "481:\tlearn: 0.1180550\ttotal: 18.2s\tremaining: 679ms\n",
      "482:\tlearn: 0.1177222\ttotal: 18.2s\tremaining: 640ms\n",
      "483:\tlearn: 0.1172606\ttotal: 18.2s\tremaining: 603ms\n",
      "484:\tlearn: 0.1169047\ttotal: 18.3s\tremaining: 566ms\n",
      "485:\tlearn: 0.1165429\ttotal: 18.3s\tremaining: 528ms\n",
      "486:\tlearn: 0.1161186\ttotal: 18.4s\tremaining: 490ms\n",
      "487:\tlearn: 0.1155464\ttotal: 18.4s\tremaining: 452ms\n",
      "488:\tlearn: 0.1151874\ttotal: 18.5s\tremaining: 415ms\n",
      "489:\tlearn: 0.1148905\ttotal: 18.5s\tremaining: 377ms\n",
      "490:\tlearn: 0.1146082\ttotal: 18.5s\tremaining: 339ms\n",
      "491:\tlearn: 0.1143683\ttotal: 18.5s\tremaining: 302ms\n",
      "492:\tlearn: 0.1141310\ttotal: 18.6s\tremaining: 264ms\n",
      "493:\tlearn: 0.1137188\ttotal: 18.6s\tremaining: 226ms\n",
      "494:\tlearn: 0.1134875\ttotal: 18.7s\tremaining: 189ms\n",
      "495:\tlearn: 0.1132001\ttotal: 18.7s\tremaining: 151ms\n",
      "496:\tlearn: 0.1128917\ttotal: 18.7s\tremaining: 113ms\n",
      "497:\tlearn: 0.1125594\ttotal: 18.8s\tremaining: 75.4ms\n",
      "498:\tlearn: 0.1122416\ttotal: 18.8s\tremaining: 37.8ms\n",
      "499:\tlearn: 0.1119629\ttotal: 18.9s\tremaining: 0us\n",
      "0:\tlearn: 0.6898775\ttotal: 23ms\tremaining: 11.5s\n",
      "1:\tlearn: 0.6864454\ttotal: 43.4ms\tremaining: 10.8s\n",
      "2:\tlearn: 0.6822496\ttotal: 120ms\tremaining: 19.9s\n",
      "3:\tlearn: 0.6786574\ttotal: 150ms\tremaining: 18.6s\n",
      "4:\tlearn: 0.6753858\ttotal: 174ms\tremaining: 17.2s\n",
      "5:\tlearn: 0.6724167\ttotal: 229ms\tremaining: 18.9s\n",
      "6:\tlearn: 0.6689582\ttotal: 290ms\tremaining: 20.4s\n",
      "7:\tlearn: 0.6636294\ttotal: 321ms\tremaining: 19.7s\n",
      "8:\tlearn: 0.6596637\ttotal: 349ms\tremaining: 19s\n",
      "9:\tlearn: 0.6564528\ttotal: 377ms\tremaining: 18.5s\n",
      "10:\tlearn: 0.6527609\ttotal: 451ms\tremaining: 20s\n",
      "11:\tlearn: 0.6493305\ttotal: 489ms\tremaining: 19.9s\n",
      "12:\tlearn: 0.6461789\ttotal: 515ms\tremaining: 19.3s\n",
      "13:\tlearn: 0.6425211\ttotal: 535ms\tremaining: 18.6s\n",
      "14:\tlearn: 0.6386671\ttotal: 594ms\tremaining: 19.2s\n",
      "15:\tlearn: 0.6350657\ttotal: 649ms\tremaining: 19.6s\n",
      "16:\tlearn: 0.6313407\ttotal: 677ms\tremaining: 19.2s\n",
      "17:\tlearn: 0.6278327\ttotal: 700ms\tremaining: 18.7s\n",
      "18:\tlearn: 0.6244079\ttotal: 721ms\tremaining: 18.3s\n",
      "19:\tlearn: 0.6212040\ttotal: 795ms\tremaining: 19.1s\n",
      "20:\tlearn: 0.6182910\ttotal: 838ms\tremaining: 19.1s\n",
      "21:\tlearn: 0.6147080\ttotal: 864ms\tremaining: 18.8s\n",
      "22:\tlearn: 0.6119460\ttotal: 886ms\tremaining: 18.4s\n",
      "23:\tlearn: 0.6086049\ttotal: 909ms\tremaining: 18s\n",
      "24:\tlearn: 0.6057279\ttotal: 980ms\tremaining: 18.6s\n",
      "25:\tlearn: 0.6027089\ttotal: 1.02s\tremaining: 18.6s\n",
      "26:\tlearn: 0.6000044\ttotal: 1.04s\tremaining: 18.3s\n",
      "27:\tlearn: 0.5972979\ttotal: 1.07s\tremaining: 18s\n",
      "28:\tlearn: 0.5946839\ttotal: 1.13s\tremaining: 18.3s\n",
      "29:\tlearn: 0.5913371\ttotal: 1.2s\tremaining: 18.8s\n",
      "30:\tlearn: 0.5887404\ttotal: 1.25s\tremaining: 19s\n",
      "31:\tlearn: 0.5863684\ttotal: 1.27s\tremaining: 18.6s\n",
      "32:\tlearn: 0.5828714\ttotal: 1.3s\tremaining: 18.4s\n",
      "33:\tlearn: 0.5803014\ttotal: 1.37s\tremaining: 18.8s\n",
      "34:\tlearn: 0.5774765\ttotal: 1.4s\tremaining: 18.6s\n",
      "35:\tlearn: 0.5751383\ttotal: 1.42s\tremaining: 18.3s\n",
      "36:\tlearn: 0.5725440\ttotal: 1.48s\tremaining: 18.5s\n",
      "37:\tlearn: 0.5700030\ttotal: 1.53s\tremaining: 18.6s\n",
      "38:\tlearn: 0.5677131\ttotal: 1.57s\tremaining: 18.6s\n",
      "39:\tlearn: 0.5653252\ttotal: 1.61s\tremaining: 18.5s\n",
      "40:\tlearn: 0.5626180\ttotal: 1.63s\tremaining: 18.2s\n",
      "41:\tlearn: 0.5598060\ttotal: 1.7s\tremaining: 18.5s\n",
      "42:\tlearn: 0.5574607\ttotal: 1.75s\tremaining: 18.6s\n",
      "43:\tlearn: 0.5544581\ttotal: 1.77s\tremaining: 18.4s\n",
      "44:\tlearn: 0.5518020\ttotal: 1.8s\tremaining: 18.2s\n",
      "45:\tlearn: 0.5488847\ttotal: 1.85s\tremaining: 18.3s\n",
      "46:\tlearn: 0.5468160\ttotal: 1.92s\tremaining: 18.5s\n",
      "47:\tlearn: 0.5442442\ttotal: 1.95s\tremaining: 18.3s\n",
      "48:\tlearn: 0.5409995\ttotal: 1.97s\tremaining: 18.2s\n",
      "49:\tlearn: 0.5388178\ttotal: 1.99s\tremaining: 17.9s\n",
      "50:\tlearn: 0.5366382\ttotal: 2.07s\tremaining: 18.2s\n",
      "51:\tlearn: 0.5342886\ttotal: 2.09s\tremaining: 18s\n",
      "52:\tlearn: 0.5321917\ttotal: 2.15s\tremaining: 18.1s\n",
      "53:\tlearn: 0.5296314\ttotal: 2.21s\tremaining: 18.3s\n",
      "54:\tlearn: 0.5272890\ttotal: 2.24s\tremaining: 18.2s\n",
      "55:\tlearn: 0.5249984\ttotal: 2.27s\tremaining: 18s\n",
      "56:\tlearn: 0.5226951\ttotal: 2.3s\tremaining: 17.9s\n",
      "57:\tlearn: 0.5201761\ttotal: 2.37s\tremaining: 18.1s\n",
      "58:\tlearn: 0.5181624\ttotal: 2.4s\tremaining: 18s\n",
      "59:\tlearn: 0.5160303\ttotal: 2.43s\tremaining: 17.8s\n",
      "60:\tlearn: 0.5128834\ttotal: 2.45s\tremaining: 17.6s\n",
      "61:\tlearn: 0.5106160\ttotal: 2.47s\tremaining: 17.5s\n",
      "62:\tlearn: 0.5084420\ttotal: 2.54s\tremaining: 17.7s\n",
      "63:\tlearn: 0.5055940\ttotal: 2.58s\tremaining: 17.6s\n",
      "64:\tlearn: 0.5023962\ttotal: 2.61s\tremaining: 17.4s\n",
      "65:\tlearn: 0.4999868\ttotal: 2.63s\tremaining: 17.3s\n",
      "66:\tlearn: 0.4980235\ttotal: 2.65s\tremaining: 17.1s\n",
      "67:\tlearn: 0.4963027\ttotal: 2.72s\tremaining: 17.3s\n",
      "68:\tlearn: 0.4943564\ttotal: 2.76s\tremaining: 17.3s\n",
      "69:\tlearn: 0.4927875\ttotal: 2.79s\tremaining: 17.1s\n",
      "70:\tlearn: 0.4907519\ttotal: 2.81s\tremaining: 17s\n",
      "71:\tlearn: 0.4886956\ttotal: 2.83s\tremaining: 16.8s\n",
      "72:\tlearn: 0.4865111\ttotal: 2.9s\tremaining: 17s\n",
      "73:\tlearn: 0.4848017\ttotal: 2.94s\tremaining: 16.9s\n",
      "74:\tlearn: 0.4831981\ttotal: 2.97s\tremaining: 16.8s\n",
      "75:\tlearn: 0.4809509\ttotal: 2.99s\tremaining: 16.7s\n",
      "76:\tlearn: 0.4790740\ttotal: 3.05s\tremaining: 16.8s\n",
      "77:\tlearn: 0.4768706\ttotal: 3.1s\tremaining: 16.8s\n",
      "78:\tlearn: 0.4746774\ttotal: 3.14s\tremaining: 16.7s\n",
      "79:\tlearn: 0.4715547\ttotal: 3.16s\tremaining: 16.6s\n",
      "80:\tlearn: 0.4692856\ttotal: 3.18s\tremaining: 16.5s\n",
      "81:\tlearn: 0.4670984\ttotal: 3.25s\tremaining: 16.6s\n",
      "82:\tlearn: 0.4653392\ttotal: 3.3s\tremaining: 16.6s\n",
      "83:\tlearn: 0.4632708\ttotal: 3.33s\tremaining: 16.5s\n",
      "84:\tlearn: 0.4611553\ttotal: 3.36s\tremaining: 16.4s\n",
      "85:\tlearn: 0.4592540\ttotal: 3.38s\tremaining: 16.3s\n",
      "86:\tlearn: 0.4576438\ttotal: 3.45s\tremaining: 16.4s\n",
      "87:\tlearn: 0.4554623\ttotal: 3.5s\tremaining: 16.4s\n",
      "88:\tlearn: 0.4537777\ttotal: 3.52s\tremaining: 16.3s\n",
      "89:\tlearn: 0.4512882\ttotal: 3.54s\tremaining: 16.1s\n",
      "90:\tlearn: 0.4496523\ttotal: 3.6s\tremaining: 16.2s\n",
      "91:\tlearn: 0.4479462\ttotal: 3.66s\tremaining: 16.2s\n",
      "92:\tlearn: 0.4464859\ttotal: 3.68s\tremaining: 16.1s\n",
      "93:\tlearn: 0.4443146\ttotal: 3.71s\tremaining: 16s\n",
      "94:\tlearn: 0.4426489\ttotal: 3.73s\tremaining: 15.9s\n",
      "95:\tlearn: 0.4408824\ttotal: 3.8s\tremaining: 16s\n",
      "96:\tlearn: 0.4394121\ttotal: 3.85s\tremaining: 16s\n",
      "97:\tlearn: 0.4377871\ttotal: 3.87s\tremaining: 15.9s\n",
      "98:\tlearn: 0.4365838\ttotal: 3.89s\tremaining: 15.8s\n",
      "99:\tlearn: 0.4352292\ttotal: 3.94s\tremaining: 15.8s\n",
      "100:\tlearn: 0.4334806\ttotal: 4.01s\tremaining: 15.8s\n",
      "101:\tlearn: 0.4317016\ttotal: 4.04s\tremaining: 15.8s\n",
      "102:\tlearn: 0.4298263\ttotal: 4.06s\tremaining: 15.7s\n",
      "103:\tlearn: 0.4276654\ttotal: 4.08s\tremaining: 15.5s\n",
      "104:\tlearn: 0.4258051\ttotal: 4.15s\tremaining: 15.6s\n",
      "105:\tlearn: 0.4240201\ttotal: 4.2s\tremaining: 15.6s\n",
      "106:\tlearn: 0.4218401\ttotal: 4.22s\tremaining: 15.5s\n",
      "107:\tlearn: 0.4201495\ttotal: 4.25s\tremaining: 15.4s\n",
      "108:\tlearn: 0.4191182\ttotal: 4.27s\tremaining: 15.3s\n",
      "109:\tlearn: 0.4172704\ttotal: 4.31s\tremaining: 15.3s\n",
      "110:\tlearn: 0.4158526\ttotal: 4.38s\tremaining: 15.3s\n",
      "111:\tlearn: 0.4136331\ttotal: 4.42s\tremaining: 15.3s\n",
      "112:\tlearn: 0.4121169\ttotal: 4.44s\tremaining: 15.2s\n",
      "113:\tlearn: 0.4107469\ttotal: 4.46s\tremaining: 15.1s\n",
      "114:\tlearn: 0.4094882\ttotal: 4.48s\tremaining: 15s\n",
      "115:\tlearn: 0.4079484\ttotal: 4.55s\tremaining: 15.1s\n",
      "116:\tlearn: 0.4059010\ttotal: 4.6s\tremaining: 15.1s\n",
      "117:\tlearn: 0.4040798\ttotal: 4.63s\tremaining: 15s\n",
      "118:\tlearn: 0.4027148\ttotal: 4.64s\tremaining: 14.9s\n",
      "119:\tlearn: 0.4006036\ttotal: 4.69s\tremaining: 14.8s\n",
      "120:\tlearn: 0.3991840\ttotal: 4.75s\tremaining: 14.9s\n",
      "121:\tlearn: 0.3977015\ttotal: 4.79s\tremaining: 14.8s\n",
      "122:\tlearn: 0.3953817\ttotal: 4.81s\tremaining: 14.7s\n",
      "123:\tlearn: 0.3936985\ttotal: 4.83s\tremaining: 14.6s\n",
      "124:\tlearn: 0.3921416\ttotal: 4.9s\tremaining: 14.7s\n",
      "125:\tlearn: 0.3908780\ttotal: 4.95s\tremaining: 14.7s\n",
      "126:\tlearn: 0.3899995\ttotal: 4.97s\tremaining: 14.6s\n",
      "127:\tlearn: 0.3887802\ttotal: 5s\tremaining: 14.5s\n",
      "128:\tlearn: 0.3873211\ttotal: 5.02s\tremaining: 14.4s\n",
      "129:\tlearn: 0.3860127\ttotal: 5.09s\tremaining: 14.5s\n",
      "130:\tlearn: 0.3847201\ttotal: 5.13s\tremaining: 14.5s\n",
      "131:\tlearn: 0.3832704\ttotal: 5.16s\tremaining: 14.4s\n",
      "132:\tlearn: 0.3810218\ttotal: 5.18s\tremaining: 14.3s\n",
      "133:\tlearn: 0.3791242\ttotal: 5.22s\tremaining: 14.3s\n",
      "134:\tlearn: 0.3772754\ttotal: 5.28s\tremaining: 14.3s\n",
      "135:\tlearn: 0.3753318\ttotal: 5.31s\tremaining: 14.2s\n",
      "136:\tlearn: 0.3737919\ttotal: 5.33s\tremaining: 14.1s\n",
      "137:\tlearn: 0.3723372\ttotal: 5.4s\tremaining: 14.2s\n",
      "138:\tlearn: 0.3711448\ttotal: 5.45s\tremaining: 14.1s\n",
      "139:\tlearn: 0.3697989\ttotal: 5.48s\tremaining: 14.1s\n",
      "140:\tlearn: 0.3687317\ttotal: 5.5s\tremaining: 14s\n",
      "141:\tlearn: 0.3671687\ttotal: 5.55s\tremaining: 14s\n",
      "142:\tlearn: 0.3659950\ttotal: 5.61s\tremaining: 14s\n",
      "143:\tlearn: 0.3644925\ttotal: 5.65s\tremaining: 14s\n",
      "144:\tlearn: 0.3627551\ttotal: 5.67s\tremaining: 13.9s\n",
      "145:\tlearn: 0.3613439\ttotal: 5.69s\tremaining: 13.8s\n",
      "146:\tlearn: 0.3598702\ttotal: 5.76s\tremaining: 13.8s\n",
      "147:\tlearn: 0.3580289\ttotal: 5.8s\tremaining: 13.8s\n",
      "148:\tlearn: 0.3568693\ttotal: 5.83s\tremaining: 13.7s\n",
      "149:\tlearn: 0.3551016\ttotal: 5.85s\tremaining: 13.7s\n",
      "150:\tlearn: 0.3536644\ttotal: 5.89s\tremaining: 13.6s\n",
      "151:\tlearn: 0.3527340\ttotal: 5.96s\tremaining: 13.7s\n",
      "152:\tlearn: 0.3513065\ttotal: 6s\tremaining: 13.6s\n",
      "153:\tlearn: 0.3505023\ttotal: 6.03s\tremaining: 13.5s\n",
      "154:\tlearn: 0.3495035\ttotal: 6.05s\tremaining: 13.5s\n",
      "155:\tlearn: 0.3476287\ttotal: 6.07s\tremaining: 13.4s\n",
      "156:\tlearn: 0.3458237\ttotal: 6.14s\tremaining: 13.4s\n",
      "157:\tlearn: 0.3441682\ttotal: 6.19s\tremaining: 13.4s\n",
      "158:\tlearn: 0.3429641\ttotal: 6.21s\tremaining: 13.3s\n",
      "159:\tlearn: 0.3414894\ttotal: 6.23s\tremaining: 13.2s\n",
      "160:\tlearn: 0.3403153\ttotal: 6.28s\tremaining: 13.2s\n",
      "161:\tlearn: 0.3388808\ttotal: 6.35s\tremaining: 13.2s\n",
      "162:\tlearn: 0.3377449\ttotal: 6.38s\tremaining: 13.2s\n",
      "163:\tlearn: 0.3366796\ttotal: 6.41s\tremaining: 13.1s\n",
      "164:\tlearn: 0.3354498\ttotal: 6.43s\tremaining: 13.1s\n",
      "165:\tlearn: 0.3341831\ttotal: 6.45s\tremaining: 13s\n",
      "166:\tlearn: 0.3332523\ttotal: 6.53s\tremaining: 13s\n",
      "167:\tlearn: 0.3318235\ttotal: 6.57s\tremaining: 13s\n",
      "168:\tlearn: 0.3307587\ttotal: 6.59s\tremaining: 12.9s\n",
      "169:\tlearn: 0.3295653\ttotal: 6.61s\tremaining: 12.8s\n",
      "170:\tlearn: 0.3282780\ttotal: 6.63s\tremaining: 12.8s\n",
      "171:\tlearn: 0.3270836\ttotal: 6.71s\tremaining: 12.8s\n",
      "172:\tlearn: 0.3257977\ttotal: 6.75s\tremaining: 12.8s\n",
      "173:\tlearn: 0.3247976\ttotal: 6.77s\tremaining: 12.7s\n",
      "174:\tlearn: 0.3233603\ttotal: 6.79s\tremaining: 12.6s\n",
      "175:\tlearn: 0.3220681\ttotal: 6.87s\tremaining: 12.6s\n",
      "176:\tlearn: 0.3211480\ttotal: 6.92s\tremaining: 12.6s\n",
      "177:\tlearn: 0.3196360\ttotal: 6.96s\tremaining: 12.6s\n",
      "178:\tlearn: 0.3185839\ttotal: 6.98s\tremaining: 12.5s\n",
      "179:\tlearn: 0.3176890\ttotal: 7s\tremaining: 12.4s\n",
      "180:\tlearn: 0.3162487\ttotal: 7.04s\tremaining: 12.4s\n",
      "181:\tlearn: 0.3148260\ttotal: 7.1s\tremaining: 12.4s\n",
      "182:\tlearn: 0.3138669\ttotal: 7.14s\tremaining: 12.4s\n",
      "183:\tlearn: 0.3120905\ttotal: 7.16s\tremaining: 12.3s\n",
      "184:\tlearn: 0.3110115\ttotal: 7.18s\tremaining: 12.2s\n",
      "185:\tlearn: 0.3099011\ttotal: 7.22s\tremaining: 12.2s\n",
      "186:\tlearn: 0.3090955\ttotal: 7.28s\tremaining: 12.2s\n",
      "187:\tlearn: 0.3076129\ttotal: 7.32s\tremaining: 12.1s\n",
      "188:\tlearn: 0.3066334\ttotal: 7.34s\tremaining: 12.1s\n",
      "189:\tlearn: 0.3051972\ttotal: 7.36s\tremaining: 12s\n",
      "190:\tlearn: 0.3041795\ttotal: 7.43s\tremaining: 12s\n",
      "191:\tlearn: 0.3029831\ttotal: 7.48s\tremaining: 12s\n",
      "192:\tlearn: 0.3018864\ttotal: 7.51s\tremaining: 11.9s\n",
      "193:\tlearn: 0.3009489\ttotal: 7.53s\tremaining: 11.9s\n",
      "194:\tlearn: 0.3001437\ttotal: 7.6s\tremaining: 11.9s\n",
      "195:\tlearn: 0.2988577\ttotal: 7.65s\tremaining: 11.9s\n",
      "196:\tlearn: 0.2976419\ttotal: 7.68s\tremaining: 11.8s\n",
      "197:\tlearn: 0.2961267\ttotal: 7.7s\tremaining: 11.8s\n",
      "198:\tlearn: 0.2949592\ttotal: 7.76s\tremaining: 11.7s\n",
      "199:\tlearn: 0.2934635\ttotal: 7.82s\tremaining: 11.7s\n",
      "200:\tlearn: 0.2926138\ttotal: 7.85s\tremaining: 11.7s\n",
      "201:\tlearn: 0.2917933\ttotal: 7.87s\tremaining: 11.6s\n",
      "202:\tlearn: 0.2905635\ttotal: 7.89s\tremaining: 11.6s\n",
      "203:\tlearn: 0.2896184\ttotal: 7.97s\tremaining: 11.6s\n",
      "204:\tlearn: 0.2885699\ttotal: 8.01s\tremaining: 11.5s\n",
      "205:\tlearn: 0.2875741\ttotal: 8.04s\tremaining: 11.5s\n",
      "206:\tlearn: 0.2861832\ttotal: 8.06s\tremaining: 11.4s\n",
      "207:\tlearn: 0.2851819\ttotal: 8.11s\tremaining: 11.4s\n",
      "208:\tlearn: 0.2840851\ttotal: 8.17s\tremaining: 11.4s\n",
      "209:\tlearn: 0.2833366\ttotal: 8.22s\tremaining: 11.4s\n",
      "210:\tlearn: 0.2821691\ttotal: 8.24s\tremaining: 11.3s\n",
      "211:\tlearn: 0.2813502\ttotal: 8.26s\tremaining: 11.2s\n",
      "212:\tlearn: 0.2803807\ttotal: 8.31s\tremaining: 11.2s\n",
      "213:\tlearn: 0.2793226\ttotal: 8.37s\tremaining: 11.2s\n",
      "214:\tlearn: 0.2782895\ttotal: 8.4s\tremaining: 11.1s\n",
      "215:\tlearn: 0.2772145\ttotal: 8.43s\tremaining: 11.1s\n",
      "216:\tlearn: 0.2760565\ttotal: 8.45s\tremaining: 11s\n",
      "217:\tlearn: 0.2752355\ttotal: 8.52s\tremaining: 11s\n",
      "218:\tlearn: 0.2745386\ttotal: 8.57s\tremaining: 11s\n",
      "219:\tlearn: 0.2735250\ttotal: 8.61s\tremaining: 11s\n",
      "220:\tlearn: 0.2723301\ttotal: 8.63s\tremaining: 10.9s\n",
      "221:\tlearn: 0.2713254\ttotal: 8.67s\tremaining: 10.9s\n",
      "222:\tlearn: 0.2702248\ttotal: 8.74s\tremaining: 10.9s\n",
      "223:\tlearn: 0.2695722\ttotal: 8.78s\tremaining: 10.8s\n",
      "224:\tlearn: 0.2685429\ttotal: 8.81s\tremaining: 10.8s\n",
      "225:\tlearn: 0.2674692\ttotal: 8.83s\tremaining: 10.7s\n",
      "226:\tlearn: 0.2666097\ttotal: 8.85s\tremaining: 10.6s\n",
      "227:\tlearn: 0.2659829\ttotal: 8.92s\tremaining: 10.6s\n",
      "228:\tlearn: 0.2652046\ttotal: 8.95s\tremaining: 10.6s\n",
      "229:\tlearn: 0.2645813\ttotal: 8.98s\tremaining: 10.5s\n",
      "230:\tlearn: 0.2630561\ttotal: 9s\tremaining: 10.5s\n",
      "231:\tlearn: 0.2621214\ttotal: 9.02s\tremaining: 10.4s\n",
      "232:\tlearn: 0.2611381\ttotal: 9.09s\tremaining: 10.4s\n",
      "233:\tlearn: 0.2601427\ttotal: 9.13s\tremaining: 10.4s\n",
      "234:\tlearn: 0.2589990\ttotal: 9.16s\tremaining: 10.3s\n",
      "235:\tlearn: 0.2582225\ttotal: 9.18s\tremaining: 10.3s\n",
      "236:\tlearn: 0.2572623\ttotal: 9.2s\tremaining: 10.2s\n",
      "237:\tlearn: 0.2560685\ttotal: 9.27s\tremaining: 10.2s\n",
      "238:\tlearn: 0.2554030\ttotal: 9.32s\tremaining: 10.2s\n",
      "239:\tlearn: 0.2544418\ttotal: 9.34s\tremaining: 10.1s\n",
      "240:\tlearn: 0.2538228\ttotal: 9.36s\tremaining: 10.1s\n",
      "241:\tlearn: 0.2529331\ttotal: 9.44s\tremaining: 10.1s\n",
      "242:\tlearn: 0.2519242\ttotal: 9.47s\tremaining: 10s\n",
      "243:\tlearn: 0.2512711\ttotal: 9.5s\tremaining: 9.96s\n",
      "244:\tlearn: 0.2507182\ttotal: 9.52s\tremaining: 9.9s\n",
      "245:\tlearn: 0.2501743\ttotal: 9.59s\tremaining: 9.91s\n",
      "246:\tlearn: 0.2493613\ttotal: 9.62s\tremaining: 9.86s\n",
      "247:\tlearn: 0.2486909\ttotal: 9.66s\tremaining: 9.81s\n",
      "248:\tlearn: 0.2478231\ttotal: 9.73s\tremaining: 9.81s\n",
      "249:\tlearn: 0.2465727\ttotal: 9.76s\tremaining: 9.76s\n",
      "250:\tlearn: 0.2455186\ttotal: 9.79s\tremaining: 9.71s\n",
      "251:\tlearn: 0.2440343\ttotal: 9.81s\tremaining: 9.65s\n",
      "252:\tlearn: 0.2431347\ttotal: 9.83s\tremaining: 9.59s\n",
      "253:\tlearn: 0.2424446\ttotal: 9.9s\tremaining: 9.58s\n",
      "254:\tlearn: 0.2416102\ttotal: 9.93s\tremaining: 9.54s\n",
      "255:\tlearn: 0.2407924\ttotal: 9.96s\tremaining: 9.49s\n",
      "256:\tlearn: 0.2399877\ttotal: 9.98s\tremaining: 9.44s\n",
      "257:\tlearn: 0.2392832\ttotal: 10s\tremaining: 9.39s\n",
      "258:\tlearn: 0.2384941\ttotal: 10.1s\tremaining: 9.38s\n",
      "259:\tlearn: 0.2377911\ttotal: 10.1s\tremaining: 9.34s\n",
      "260:\tlearn: 0.2370608\ttotal: 10.1s\tremaining: 9.28s\n",
      "261:\tlearn: 0.2361447\ttotal: 10.2s\tremaining: 9.23s\n",
      "262:\tlearn: 0.2355951\ttotal: 10.2s\tremaining: 9.22s\n",
      "263:\tlearn: 0.2346676\ttotal: 10.3s\tremaining: 9.19s\n",
      "264:\tlearn: 0.2339263\ttotal: 10.3s\tremaining: 9.14s\n",
      "265:\tlearn: 0.2330792\ttotal: 10.3s\tremaining: 9.08s\n",
      "266:\tlearn: 0.2322718\ttotal: 10.4s\tremaining: 9.04s\n",
      "267:\tlearn: 0.2315080\ttotal: 10.4s\tremaining: 9.02s\n",
      "268:\tlearn: 0.2307108\ttotal: 10.5s\tremaining: 8.99s\n",
      "269:\tlearn: 0.2300108\ttotal: 10.5s\tremaining: 8.94s\n",
      "270:\tlearn: 0.2290047\ttotal: 10.5s\tremaining: 8.88s\n",
      "271:\tlearn: 0.2283900\ttotal: 10.6s\tremaining: 8.87s\n",
      "272:\tlearn: 0.2278620\ttotal: 10.6s\tremaining: 8.84s\n",
      "273:\tlearn: 0.2272707\ttotal: 10.7s\tremaining: 8.8s\n",
      "274:\tlearn: 0.2267780\ttotal: 10.7s\tremaining: 8.74s\n",
      "275:\tlearn: 0.2260541\ttotal: 10.7s\tremaining: 8.71s\n",
      "276:\tlearn: 0.2253927\ttotal: 10.8s\tremaining: 8.69s\n",
      "277:\tlearn: 0.2245231\ttotal: 10.8s\tremaining: 8.65s\n",
      "278:\tlearn: 0.2236810\ttotal: 10.9s\tremaining: 8.6s\n",
      "279:\tlearn: 0.2229427\ttotal: 10.9s\tremaining: 8.54s\n",
      "280:\tlearn: 0.2222395\ttotal: 10.9s\tremaining: 8.49s\n",
      "281:\tlearn: 0.2212642\ttotal: 11s\tremaining: 8.48s\n",
      "282:\tlearn: 0.2206815\ttotal: 11s\tremaining: 8.44s\n",
      "283:\tlearn: 0.2197492\ttotal: 11s\tremaining: 8.39s\n",
      "284:\tlearn: 0.2187838\ttotal: 11.1s\tremaining: 8.34s\n",
      "285:\tlearn: 0.2179821\ttotal: 11.1s\tremaining: 8.33s\n",
      "286:\tlearn: 0.2169467\ttotal: 11.2s\tremaining: 8.29s\n",
      "287:\tlearn: 0.2163391\ttotal: 11.2s\tremaining: 8.25s\n",
      "288:\tlearn: 0.2158775\ttotal: 11.2s\tremaining: 8.2s\n",
      "289:\tlearn: 0.2152981\ttotal: 11.2s\tremaining: 8.14s\n",
      "290:\tlearn: 0.2143000\ttotal: 11.3s\tremaining: 8.14s\n",
      "291:\tlearn: 0.2136348\ttotal: 11.4s\tremaining: 8.12s\n",
      "292:\tlearn: 0.2129851\ttotal: 11.4s\tremaining: 8.07s\n",
      "293:\tlearn: 0.2124094\ttotal: 11.4s\tremaining: 8.02s\n",
      "294:\tlearn: 0.2117029\ttotal: 11.5s\tremaining: 7.97s\n",
      "295:\tlearn: 0.2106360\ttotal: 11.5s\tremaining: 7.96s\n",
      "296:\tlearn: 0.2100262\ttotal: 11.6s\tremaining: 7.91s\n",
      "297:\tlearn: 0.2092679\ttotal: 11.6s\tremaining: 7.86s\n",
      "298:\tlearn: 0.2085865\ttotal: 11.7s\tremaining: 7.84s\n",
      "299:\tlearn: 0.2079548\ttotal: 11.7s\tremaining: 7.8s\n",
      "300:\tlearn: 0.2072953\ttotal: 11.7s\tremaining: 7.76s\n",
      "301:\tlearn: 0.2065495\ttotal: 11.8s\tremaining: 7.72s\n",
      "302:\tlearn: 0.2059570\ttotal: 11.8s\tremaining: 7.7s\n",
      "303:\tlearn: 0.2051731\ttotal: 11.9s\tremaining: 7.66s\n",
      "304:\tlearn: 0.2042527\ttotal: 11.9s\tremaining: 7.61s\n",
      "305:\tlearn: 0.2036332\ttotal: 11.9s\tremaining: 7.57s\n",
      "306:\tlearn: 0.2029407\ttotal: 12s\tremaining: 7.55s\n",
      "307:\tlearn: 0.2022676\ttotal: 12s\tremaining: 7.51s\n",
      "308:\tlearn: 0.2017840\ttotal: 12.1s\tremaining: 7.46s\n",
      "309:\tlearn: 0.2012185\ttotal: 12.1s\tremaining: 7.41s\n",
      "310:\tlearn: 0.2007838\ttotal: 12.1s\tremaining: 7.36s\n",
      "311:\tlearn: 0.2001463\ttotal: 12.2s\tremaining: 7.35s\n",
      "312:\tlearn: 0.1997697\ttotal: 12.3s\tremaining: 7.32s\n",
      "313:\tlearn: 0.1991439\ttotal: 12.3s\tremaining: 7.27s\n",
      "314:\tlearn: 0.1983661\ttotal: 12.3s\tremaining: 7.22s\n",
      "315:\tlearn: 0.1978669\ttotal: 12.3s\tremaining: 7.19s\n",
      "316:\tlearn: 0.1971199\ttotal: 12.4s\tremaining: 7.16s\n",
      "317:\tlearn: 0.1965014\ttotal: 12.4s\tremaining: 7.12s\n",
      "318:\tlearn: 0.1960481\ttotal: 12.5s\tremaining: 7.07s\n",
      "319:\tlearn: 0.1956250\ttotal: 12.5s\tremaining: 7.02s\n",
      "320:\tlearn: 0.1949970\ttotal: 12.6s\tremaining: 7s\n",
      "321:\tlearn: 0.1942071\ttotal: 12.6s\tremaining: 6.97s\n",
      "322:\tlearn: 0.1936232\ttotal: 12.6s\tremaining: 6.93s\n",
      "323:\tlearn: 0.1929040\ttotal: 12.7s\tremaining: 6.88s\n",
      "324:\tlearn: 0.1923605\ttotal: 12.7s\tremaining: 6.83s\n",
      "325:\tlearn: 0.1917155\ttotal: 12.8s\tremaining: 6.81s\n",
      "326:\tlearn: 0.1910235\ttotal: 12.8s\tremaining: 6.78s\n",
      "327:\tlearn: 0.1901524\ttotal: 12.8s\tremaining: 6.73s\n",
      "328:\tlearn: 0.1897195\ttotal: 12.9s\tremaining: 6.68s\n",
      "329:\tlearn: 0.1891556\ttotal: 12.9s\tremaining: 6.63s\n",
      "330:\tlearn: 0.1886678\ttotal: 12.9s\tremaining: 6.61s\n",
      "331:\tlearn: 0.1883074\ttotal: 13s\tremaining: 6.57s\n",
      "332:\tlearn: 0.1875963\ttotal: 13s\tremaining: 6.52s\n",
      "333:\tlearn: 0.1868356\ttotal: 13s\tremaining: 6.48s\n",
      "334:\tlearn: 0.1862294\ttotal: 13.1s\tremaining: 6.44s\n",
      "335:\tlearn: 0.1856659\ttotal: 13.1s\tremaining: 6.41s\n",
      "336:\tlearn: 0.1851614\ttotal: 13.2s\tremaining: 6.37s\n",
      "337:\tlearn: 0.1848696\ttotal: 13.2s\tremaining: 6.32s\n",
      "338:\tlearn: 0.1842440\ttotal: 13.2s\tremaining: 6.28s\n",
      "339:\tlearn: 0.1833634\ttotal: 13.3s\tremaining: 6.25s\n",
      "340:\tlearn: 0.1828829\ttotal: 13.3s\tremaining: 6.21s\n",
      "341:\tlearn: 0.1823645\ttotal: 13.3s\tremaining: 6.16s\n",
      "342:\tlearn: 0.1817827\ttotal: 13.4s\tremaining: 6.12s\n",
      "343:\tlearn: 0.1812366\ttotal: 13.4s\tremaining: 6.09s\n",
      "344:\tlearn: 0.1805912\ttotal: 13.5s\tremaining: 6.05s\n",
      "345:\tlearn: 0.1801043\ttotal: 13.5s\tremaining: 6.01s\n",
      "346:\tlearn: 0.1795927\ttotal: 13.5s\tremaining: 5.96s\n",
      "347:\tlearn: 0.1790549\ttotal: 13.6s\tremaining: 5.92s\n",
      "348:\tlearn: 0.1784375\ttotal: 13.6s\tremaining: 5.87s\n",
      "349:\tlearn: 0.1778962\ttotal: 13.6s\tremaining: 5.84s\n",
      "350:\tlearn: 0.1772950\ttotal: 13.7s\tremaining: 5.81s\n",
      "351:\tlearn: 0.1768500\ttotal: 13.7s\tremaining: 5.77s\n",
      "352:\tlearn: 0.1759132\ttotal: 13.7s\tremaining: 5.72s\n",
      "353:\tlearn: 0.1754428\ttotal: 13.8s\tremaining: 5.68s\n",
      "354:\tlearn: 0.1749851\ttotal: 13.8s\tremaining: 5.63s\n",
      "355:\tlearn: 0.1743788\ttotal: 13.9s\tremaining: 5.61s\n",
      "356:\tlearn: 0.1739458\ttotal: 13.9s\tremaining: 5.57s\n",
      "357:\tlearn: 0.1734645\ttotal: 13.9s\tremaining: 5.52s\n",
      "358:\tlearn: 0.1730223\ttotal: 13.9s\tremaining: 5.48s\n",
      "359:\tlearn: 0.1724064\ttotal: 14s\tremaining: 5.44s\n",
      "360:\tlearn: 0.1719003\ttotal: 14.1s\tremaining: 5.41s\n",
      "361:\tlearn: 0.1711131\ttotal: 14.1s\tremaining: 5.37s\n",
      "362:\tlearn: 0.1705851\ttotal: 14.1s\tremaining: 5.33s\n",
      "363:\tlearn: 0.1700511\ttotal: 14.1s\tremaining: 5.28s\n",
      "364:\tlearn: 0.1694542\ttotal: 14.2s\tremaining: 5.25s\n",
      "365:\tlearn: 0.1689964\ttotal: 14.2s\tremaining: 5.22s\n",
      "366:\tlearn: 0.1683918\ttotal: 14.3s\tremaining: 5.17s\n",
      "367:\tlearn: 0.1677856\ttotal: 14.3s\tremaining: 5.13s\n",
      "368:\tlearn: 0.1673430\ttotal: 14.3s\tremaining: 5.08s\n",
      "369:\tlearn: 0.1668120\ttotal: 14.4s\tremaining: 5.05s\n",
      "370:\tlearn: 0.1664619\ttotal: 14.4s\tremaining: 5.02s\n",
      "371:\tlearn: 0.1658880\ttotal: 14.5s\tremaining: 4.97s\n",
      "372:\tlearn: 0.1654741\ttotal: 14.5s\tremaining: 4.93s\n",
      "373:\tlearn: 0.1648656\ttotal: 14.5s\tremaining: 4.89s\n",
      "374:\tlearn: 0.1644453\ttotal: 14.6s\tremaining: 4.86s\n",
      "375:\tlearn: 0.1639760\ttotal: 14.6s\tremaining: 4.82s\n",
      "376:\tlearn: 0.1633925\ttotal: 14.6s\tremaining: 4.78s\n",
      "377:\tlearn: 0.1629008\ttotal: 14.7s\tremaining: 4.73s\n",
      "378:\tlearn: 0.1623953\ttotal: 14.7s\tremaining: 4.7s\n",
      "379:\tlearn: 0.1620736\ttotal: 14.8s\tremaining: 4.67s\n",
      "380:\tlearn: 0.1614949\ttotal: 14.8s\tremaining: 4.63s\n",
      "381:\tlearn: 0.1609278\ttotal: 14.8s\tremaining: 4.58s\n",
      "382:\tlearn: 0.1602118\ttotal: 14.9s\tremaining: 4.55s\n",
      "383:\tlearn: 0.1598192\ttotal: 14.9s\tremaining: 4.51s\n",
      "384:\tlearn: 0.1592982\ttotal: 15s\tremaining: 4.47s\n",
      "385:\tlearn: 0.1588659\ttotal: 15s\tremaining: 4.43s\n",
      "386:\tlearn: 0.1582002\ttotal: 15.1s\tremaining: 4.39s\n",
      "387:\tlearn: 0.1576292\ttotal: 15.1s\tremaining: 4.36s\n",
      "388:\tlearn: 0.1570889\ttotal: 15.1s\tremaining: 4.32s\n",
      "389:\tlearn: 0.1566289\ttotal: 15.2s\tremaining: 4.27s\n",
      "390:\tlearn: 0.1563188\ttotal: 15.2s\tremaining: 4.23s\n",
      "391:\tlearn: 0.1559103\ttotal: 15.2s\tremaining: 4.2s\n",
      "392:\tlearn: 0.1555025\ttotal: 15.3s\tremaining: 4.16s\n",
      "393:\tlearn: 0.1550285\ttotal: 15.3s\tremaining: 4.12s\n",
      "394:\tlearn: 0.1544405\ttotal: 15.3s\tremaining: 4.08s\n",
      "395:\tlearn: 0.1540801\ttotal: 15.4s\tremaining: 4.04s\n",
      "396:\tlearn: 0.1536062\ttotal: 15.4s\tremaining: 4.01s\n",
      "397:\tlearn: 0.1533468\ttotal: 15.5s\tremaining: 3.97s\n",
      "398:\tlearn: 0.1528588\ttotal: 15.5s\tremaining: 3.92s\n",
      "399:\tlearn: 0.1523674\ttotal: 15.5s\tremaining: 3.88s\n",
      "400:\tlearn: 0.1519494\ttotal: 15.6s\tremaining: 3.85s\n",
      "401:\tlearn: 0.1514878\ttotal: 15.6s\tremaining: 3.81s\n",
      "402:\tlearn: 0.1510929\ttotal: 15.7s\tremaining: 3.77s\n",
      "403:\tlearn: 0.1507699\ttotal: 15.7s\tremaining: 3.73s\n",
      "404:\tlearn: 0.1502981\ttotal: 15.7s\tremaining: 3.69s\n",
      "405:\tlearn: 0.1495962\ttotal: 15.8s\tremaining: 3.66s\n",
      "406:\tlearn: 0.1492068\ttotal: 15.8s\tremaining: 3.62s\n",
      "407:\tlearn: 0.1487639\ttotal: 15.9s\tremaining: 3.58s\n",
      "408:\tlearn: 0.1483087\ttotal: 15.9s\tremaining: 3.54s\n",
      "409:\tlearn: 0.1477232\ttotal: 15.9s\tremaining: 3.49s\n",
      "410:\tlearn: 0.1473340\ttotal: 16s\tremaining: 3.46s\n",
      "411:\tlearn: 0.1469792\ttotal: 16s\tremaining: 3.42s\n",
      "412:\tlearn: 0.1465362\ttotal: 16s\tremaining: 3.38s\n",
      "413:\tlearn: 0.1461471\ttotal: 16.1s\tremaining: 3.34s\n",
      "414:\tlearn: 0.1456076\ttotal: 16.1s\tremaining: 3.3s\n",
      "415:\tlearn: 0.1452793\ttotal: 16.2s\tremaining: 3.27s\n",
      "416:\tlearn: 0.1449289\ttotal: 16.2s\tremaining: 3.23s\n",
      "417:\tlearn: 0.1444207\ttotal: 16.2s\tremaining: 3.19s\n",
      "418:\tlearn: 0.1438126\ttotal: 16.3s\tremaining: 3.14s\n",
      "419:\tlearn: 0.1434141\ttotal: 16.3s\tremaining: 3.11s\n",
      "420:\tlearn: 0.1429691\ttotal: 16.4s\tremaining: 3.07s\n",
      "421:\tlearn: 0.1425532\ttotal: 16.4s\tremaining: 3.03s\n",
      "422:\tlearn: 0.1422064\ttotal: 16.4s\tremaining: 2.99s\n",
      "423:\tlearn: 0.1416170\ttotal: 16.5s\tremaining: 2.95s\n",
      "424:\tlearn: 0.1412654\ttotal: 16.5s\tremaining: 2.92s\n",
      "425:\tlearn: 0.1405219\ttotal: 16.6s\tremaining: 2.88s\n",
      "426:\tlearn: 0.1400226\ttotal: 16.6s\tremaining: 2.84s\n",
      "427:\tlearn: 0.1396227\ttotal: 16.6s\tremaining: 2.8s\n",
      "428:\tlearn: 0.1389468\ttotal: 16.6s\tremaining: 2.75s\n",
      "429:\tlearn: 0.1386030\ttotal: 16.7s\tremaining: 2.72s\n",
      "430:\tlearn: 0.1381276\ttotal: 16.8s\tremaining: 2.68s\n",
      "431:\tlearn: 0.1377113\ttotal: 16.8s\tremaining: 2.64s\n",
      "432:\tlearn: 0.1371096\ttotal: 16.8s\tremaining: 2.6s\n",
      "433:\tlearn: 0.1366948\ttotal: 16.8s\tremaining: 2.56s\n",
      "434:\tlearn: 0.1364399\ttotal: 16.9s\tremaining: 2.52s\n",
      "435:\tlearn: 0.1360016\ttotal: 16.9s\tremaining: 2.48s\n",
      "436:\tlearn: 0.1355974\ttotal: 17s\tremaining: 2.44s\n",
      "437:\tlearn: 0.1352007\ttotal: 17s\tremaining: 2.4s\n",
      "438:\tlearn: 0.1347105\ttotal: 17s\tremaining: 2.36s\n",
      "439:\tlearn: 0.1341987\ttotal: 17.1s\tremaining: 2.33s\n",
      "440:\tlearn: 0.1336749\ttotal: 17.1s\tremaining: 2.29s\n",
      "441:\tlearn: 0.1332746\ttotal: 17.1s\tremaining: 2.25s\n",
      "442:\tlearn: 0.1329482\ttotal: 17.2s\tremaining: 2.21s\n",
      "443:\tlearn: 0.1325225\ttotal: 17.2s\tremaining: 2.17s\n",
      "444:\tlearn: 0.1322002\ttotal: 17.3s\tremaining: 2.13s\n",
      "445:\tlearn: 0.1317053\ttotal: 17.3s\tremaining: 2.09s\n",
      "446:\tlearn: 0.1313853\ttotal: 17.3s\tremaining: 2.05s\n",
      "447:\tlearn: 0.1309642\ttotal: 17.4s\tremaining: 2.02s\n",
      "448:\tlearn: 0.1306094\ttotal: 17.4s\tremaining: 1.98s\n",
      "449:\tlearn: 0.1302239\ttotal: 17.5s\tremaining: 1.94s\n",
      "450:\tlearn: 0.1298178\ttotal: 17.5s\tremaining: 1.9s\n",
      "451:\tlearn: 0.1294233\ttotal: 17.5s\tremaining: 1.86s\n",
      "452:\tlearn: 0.1290060\ttotal: 17.5s\tremaining: 1.82s\n",
      "453:\tlearn: 0.1285331\ttotal: 17.6s\tremaining: 1.78s\n",
      "454:\tlearn: 0.1280764\ttotal: 17.6s\tremaining: 1.74s\n",
      "455:\tlearn: 0.1276121\ttotal: 17.7s\tremaining: 1.71s\n",
      "456:\tlearn: 0.1272050\ttotal: 17.7s\tremaining: 1.67s\n",
      "457:\tlearn: 0.1267155\ttotal: 17.7s\tremaining: 1.63s\n",
      "458:\tlearn: 0.1263994\ttotal: 17.8s\tremaining: 1.59s\n",
      "459:\tlearn: 0.1260581\ttotal: 17.8s\tremaining: 1.55s\n",
      "460:\tlearn: 0.1257968\ttotal: 17.9s\tremaining: 1.51s\n",
      "461:\tlearn: 0.1255599\ttotal: 17.9s\tremaining: 1.47s\n",
      "462:\tlearn: 0.1252073\ttotal: 18s\tremaining: 1.44s\n",
      "463:\tlearn: 0.1249251\ttotal: 18s\tremaining: 1.4s\n",
      "464:\tlearn: 0.1246618\ttotal: 18s\tremaining: 1.36s\n",
      "465:\tlearn: 0.1242080\ttotal: 18.1s\tremaining: 1.32s\n",
      "466:\tlearn: 0.1238631\ttotal: 18.1s\tremaining: 1.28s\n",
      "467:\tlearn: 0.1236795\ttotal: 18.2s\tremaining: 1.24s\n",
      "468:\tlearn: 0.1234567\ttotal: 18.2s\tremaining: 1.2s\n",
      "469:\tlearn: 0.1231934\ttotal: 18.2s\tremaining: 1.16s\n",
      "470:\tlearn: 0.1229073\ttotal: 18.3s\tremaining: 1.12s\n",
      "471:\tlearn: 0.1226920\ttotal: 18.3s\tremaining: 1.08s\n",
      "472:\tlearn: 0.1222707\ttotal: 18.3s\tremaining: 1.05s\n",
      "473:\tlearn: 0.1218967\ttotal: 18.4s\tremaining: 1.01s\n",
      "474:\tlearn: 0.1214290\ttotal: 18.4s\tremaining: 969ms\n",
      "475:\tlearn: 0.1210701\ttotal: 18.4s\tremaining: 929ms\n",
      "476:\tlearn: 0.1207773\ttotal: 18.5s\tremaining: 891ms\n",
      "477:\tlearn: 0.1204693\ttotal: 18.5s\tremaining: 853ms\n",
      "478:\tlearn: 0.1200339\ttotal: 18.6s\tremaining: 814ms\n",
      "479:\tlearn: 0.1196412\ttotal: 18.6s\tremaining: 775ms\n",
      "480:\tlearn: 0.1193719\ttotal: 18.6s\tremaining: 735ms\n",
      "481:\tlearn: 0.1189727\ttotal: 18.7s\tremaining: 698ms\n",
      "482:\tlearn: 0.1186095\ttotal: 18.7s\tremaining: 659ms\n",
      "483:\tlearn: 0.1182010\ttotal: 18.8s\tremaining: 620ms\n",
      "484:\tlearn: 0.1178626\ttotal: 18.8s\tremaining: 581ms\n",
      "485:\tlearn: 0.1175142\ttotal: 18.9s\tremaining: 543ms\n",
      "486:\tlearn: 0.1169689\ttotal: 18.9s\tremaining: 505ms\n",
      "487:\tlearn: 0.1164650\ttotal: 18.9s\tremaining: 466ms\n",
      "488:\tlearn: 0.1160143\ttotal: 19s\tremaining: 427ms\n",
      "489:\tlearn: 0.1157393\ttotal: 19s\tremaining: 388ms\n",
      "490:\tlearn: 0.1152514\ttotal: 19.1s\tremaining: 349ms\n",
      "491:\tlearn: 0.1148740\ttotal: 19.1s\tremaining: 311ms\n",
      "492:\tlearn: 0.1146080\ttotal: 19.1s\tremaining: 272ms\n",
      "493:\tlearn: 0.1143508\ttotal: 19.2s\tremaining: 233ms\n",
      "494:\tlearn: 0.1139668\ttotal: 19.2s\tremaining: 194ms\n",
      "495:\tlearn: 0.1137014\ttotal: 19.2s\tremaining: 155ms\n",
      "496:\tlearn: 0.1133916\ttotal: 19.3s\tremaining: 116ms\n",
      "497:\tlearn: 0.1131215\ttotal: 19.3s\tremaining: 77.6ms\n",
      "498:\tlearn: 0.1128430\ttotal: 19.3s\tremaining: 38.7ms\n",
      "499:\tlearn: 0.1123726\ttotal: 19.4s\tremaining: 0us\n",
      "0:\tlearn: 0.6896451\ttotal: 27.6ms\tremaining: 13.8s\n",
      "1:\tlearn: 0.6857748\ttotal: 48.4ms\tremaining: 12s\n",
      "2:\tlearn: 0.6824398\ttotal: 86.3ms\tremaining: 14.3s\n",
      "3:\tlearn: 0.6777536\ttotal: 154ms\tremaining: 19.1s\n",
      "4:\tlearn: 0.6735830\ttotal: 191ms\tremaining: 18.9s\n",
      "5:\tlearn: 0.6695654\ttotal: 218ms\tremaining: 17.9s\n",
      "6:\tlearn: 0.6658551\ttotal: 239ms\tremaining: 16.8s\n",
      "7:\tlearn: 0.6616570\ttotal: 259ms\tremaining: 15.9s\n",
      "8:\tlearn: 0.6576067\ttotal: 328ms\tremaining: 17.9s\n",
      "9:\tlearn: 0.6536722\ttotal: 371ms\tremaining: 18.2s\n",
      "10:\tlearn: 0.6503199\ttotal: 397ms\tremaining: 17.6s\n",
      "11:\tlearn: 0.6475505\ttotal: 418ms\tremaining: 17s\n",
      "12:\tlearn: 0.6443014\ttotal: 461ms\tremaining: 17.3s\n",
      "13:\tlearn: 0.6416080\ttotal: 524ms\tremaining: 18.2s\n",
      "14:\tlearn: 0.6379043\ttotal: 551ms\tremaining: 17.8s\n",
      "15:\tlearn: 0.6340578\ttotal: 574ms\tremaining: 17.4s\n",
      "16:\tlearn: 0.6307850\ttotal: 596ms\tremaining: 16.9s\n",
      "17:\tlearn: 0.6276112\ttotal: 670ms\tremaining: 17.9s\n",
      "18:\tlearn: 0.6244895\ttotal: 710ms\tremaining: 18s\n",
      "19:\tlearn: 0.6213410\ttotal: 738ms\tremaining: 17.7s\n",
      "20:\tlearn: 0.6186640\ttotal: 760ms\tremaining: 17.3s\n",
      "21:\tlearn: 0.6158954\ttotal: 781ms\tremaining: 17s\n",
      "22:\tlearn: 0.6129549\ttotal: 853ms\tremaining: 17.7s\n",
      "23:\tlearn: 0.6099642\ttotal: 905ms\tremaining: 17.9s\n",
      "24:\tlearn: 0.6066196\ttotal: 930ms\tremaining: 17.7s\n",
      "25:\tlearn: 0.6032511\ttotal: 951ms\tremaining: 17.3s\n",
      "26:\tlearn: 0.6008800\ttotal: 972ms\tremaining: 17s\n",
      "27:\tlearn: 0.5983446\ttotal: 1.04s\tremaining: 17.6s\n",
      "28:\tlearn: 0.5947890\ttotal: 1.08s\tremaining: 17.5s\n",
      "29:\tlearn: 0.5912082\ttotal: 1.1s\tremaining: 17.3s\n",
      "30:\tlearn: 0.5883805\ttotal: 1.13s\tremaining: 17s\n",
      "31:\tlearn: 0.5857825\ttotal: 1.18s\tremaining: 17.3s\n",
      "32:\tlearn: 0.5822416\ttotal: 1.24s\tremaining: 17.6s\n",
      "33:\tlearn: 0.5797817\ttotal: 1.27s\tremaining: 17.5s\n",
      "34:\tlearn: 0.5771436\ttotal: 1.3s\tremaining: 17.3s\n",
      "35:\tlearn: 0.5734063\ttotal: 1.32s\tremaining: 17s\n",
      "36:\tlearn: 0.5702247\ttotal: 1.39s\tremaining: 17.4s\n",
      "37:\tlearn: 0.5672786\ttotal: 1.44s\tremaining: 17.5s\n",
      "38:\tlearn: 0.5643783\ttotal: 1.46s\tremaining: 17.3s\n",
      "39:\tlearn: 0.5615123\ttotal: 1.49s\tremaining: 17.1s\n",
      "40:\tlearn: 0.5586204\ttotal: 1.55s\tremaining: 17.4s\n",
      "41:\tlearn: 0.5559138\ttotal: 1.61s\tremaining: 17.6s\n",
      "42:\tlearn: 0.5534855\ttotal: 1.64s\tremaining: 17.4s\n",
      "43:\tlearn: 0.5505181\ttotal: 1.66s\tremaining: 17.2s\n",
      "44:\tlearn: 0.5473361\ttotal: 1.68s\tremaining: 17s\n",
      "45:\tlearn: 0.5447258\ttotal: 1.75s\tremaining: 17.3s\n",
      "46:\tlearn: 0.5420937\ttotal: 1.79s\tremaining: 17.3s\n",
      "47:\tlearn: 0.5397159\ttotal: 1.82s\tremaining: 17.1s\n",
      "48:\tlearn: 0.5364112\ttotal: 1.84s\tremaining: 16.9s\n",
      "49:\tlearn: 0.5338827\ttotal: 1.88s\tremaining: 16.9s\n",
      "50:\tlearn: 0.5312702\ttotal: 1.95s\tremaining: 17.2s\n",
      "51:\tlearn: 0.5288437\ttotal: 2.03s\tremaining: 17.5s\n",
      "52:\tlearn: 0.5264681\ttotal: 2.09s\tremaining: 17.6s\n",
      "53:\tlearn: 0.5234558\ttotal: 2.11s\tremaining: 17.5s\n",
      "54:\tlearn: 0.5206807\ttotal: 2.14s\tremaining: 17.3s\n",
      "55:\tlearn: 0.5182370\ttotal: 2.16s\tremaining: 17.1s\n",
      "56:\tlearn: 0.5158834\ttotal: 2.23s\tremaining: 17.3s\n",
      "57:\tlearn: 0.5131490\ttotal: 2.25s\tremaining: 17.1s\n",
      "58:\tlearn: 0.5108088\ttotal: 2.27s\tremaining: 17s\n",
      "59:\tlearn: 0.5082923\ttotal: 2.29s\tremaining: 16.8s\n",
      "60:\tlearn: 0.5058780\ttotal: 2.37s\tremaining: 17s\n",
      "61:\tlearn: 0.5035792\ttotal: 2.41s\tremaining: 17s\n",
      "62:\tlearn: 0.5012766\ttotal: 2.44s\tremaining: 16.9s\n",
      "63:\tlearn: 0.4987021\ttotal: 2.47s\tremaining: 16.8s\n",
      "64:\tlearn: 0.4967631\ttotal: 2.54s\tremaining: 17s\n",
      "65:\tlearn: 0.4946838\ttotal: 2.59s\tremaining: 17s\n",
      "66:\tlearn: 0.4926710\ttotal: 2.61s\tremaining: 16.9s\n",
      "67:\tlearn: 0.4906238\ttotal: 2.63s\tremaining: 16.7s\n",
      "68:\tlearn: 0.4888320\ttotal: 2.68s\tremaining: 16.7s\n",
      "69:\tlearn: 0.4871320\ttotal: 2.75s\tremaining: 16.9s\n",
      "70:\tlearn: 0.4852417\ttotal: 2.78s\tremaining: 16.8s\n",
      "71:\tlearn: 0.4830711\ttotal: 2.81s\tremaining: 16.7s\n",
      "72:\tlearn: 0.4815384\ttotal: 2.83s\tremaining: 16.5s\n",
      "73:\tlearn: 0.4799546\ttotal: 2.87s\tremaining: 16.5s\n",
      "74:\tlearn: 0.4781204\ttotal: 2.95s\tremaining: 16.7s\n",
      "75:\tlearn: 0.4758940\ttotal: 2.98s\tremaining: 16.6s\n",
      "76:\tlearn: 0.4733291\ttotal: 3.01s\tremaining: 16.5s\n",
      "77:\tlearn: 0.4713282\ttotal: 3.03s\tremaining: 16.4s\n",
      "78:\tlearn: 0.4683139\ttotal: 3.08s\tremaining: 16.4s\n",
      "79:\tlearn: 0.4662311\ttotal: 3.13s\tremaining: 16.5s\n",
      "80:\tlearn: 0.4641209\ttotal: 3.16s\tremaining: 16.3s\n",
      "81:\tlearn: 0.4628079\ttotal: 3.18s\tremaining: 16.2s\n",
      "82:\tlearn: 0.4606359\ttotal: 3.21s\tremaining: 16.2s\n",
      "83:\tlearn: 0.4588314\ttotal: 3.29s\tremaining: 16.3s\n",
      "84:\tlearn: 0.4564848\ttotal: 3.32s\tremaining: 16.2s\n",
      "85:\tlearn: 0.4542442\ttotal: 3.34s\tremaining: 16.1s\n",
      "86:\tlearn: 0.4527581\ttotal: 3.37s\tremaining: 16s\n",
      "87:\tlearn: 0.4507599\ttotal: 3.39s\tremaining: 15.9s\n",
      "88:\tlearn: 0.4491437\ttotal: 3.44s\tremaining: 15.9s\n",
      "89:\tlearn: 0.4472362\ttotal: 3.49s\tremaining: 15.9s\n",
      "90:\tlearn: 0.4453259\ttotal: 3.51s\tremaining: 15.8s\n",
      "91:\tlearn: 0.4435182\ttotal: 3.59s\tremaining: 15.9s\n",
      "92:\tlearn: 0.4414458\ttotal: 3.63s\tremaining: 15.9s\n",
      "93:\tlearn: 0.4395211\ttotal: 3.66s\tremaining: 15.8s\n",
      "94:\tlearn: 0.4380628\ttotal: 3.68s\tremaining: 15.7s\n",
      "95:\tlearn: 0.4364828\ttotal: 3.73s\tremaining: 15.7s\n",
      "96:\tlearn: 0.4342531\ttotal: 3.79s\tremaining: 15.8s\n",
      "97:\tlearn: 0.4314602\ttotal: 3.82s\tremaining: 15.7s\n",
      "98:\tlearn: 0.4302562\ttotal: 3.85s\tremaining: 15.6s\n",
      "99:\tlearn: 0.4275126\ttotal: 3.87s\tremaining: 15.5s\n",
      "100:\tlearn: 0.4254634\ttotal: 3.95s\tremaining: 15.6s\n",
      "101:\tlearn: 0.4239018\ttotal: 3.99s\tremaining: 15.6s\n",
      "102:\tlearn: 0.4220956\ttotal: 4.02s\tremaining: 15.5s\n",
      "103:\tlearn: 0.4200226\ttotal: 4.04s\tremaining: 15.4s\n",
      "104:\tlearn: 0.4183569\ttotal: 4.06s\tremaining: 15.3s\n",
      "105:\tlearn: 0.4164348\ttotal: 4.13s\tremaining: 15.4s\n",
      "106:\tlearn: 0.4145381\ttotal: 4.17s\tremaining: 15.3s\n",
      "107:\tlearn: 0.4131014\ttotal: 4.19s\tremaining: 15.2s\n",
      "108:\tlearn: 0.4119590\ttotal: 4.21s\tremaining: 15.1s\n",
      "109:\tlearn: 0.4099767\ttotal: 4.24s\tremaining: 15s\n",
      "110:\tlearn: 0.4078405\ttotal: 4.32s\tremaining: 15.1s\n",
      "111:\tlearn: 0.4061851\ttotal: 4.35s\tremaining: 15.1s\n",
      "112:\tlearn: 0.4046573\ttotal: 4.37s\tremaining: 15s\n",
      "113:\tlearn: 0.4034296\ttotal: 4.39s\tremaining: 14.9s\n",
      "114:\tlearn: 0.4018000\ttotal: 4.47s\tremaining: 15s\n",
      "115:\tlearn: 0.4005180\ttotal: 4.51s\tremaining: 14.9s\n",
      "116:\tlearn: 0.3992997\ttotal: 4.54s\tremaining: 14.9s\n",
      "117:\tlearn: 0.3977824\ttotal: 4.56s\tremaining: 14.8s\n",
      "118:\tlearn: 0.3962606\ttotal: 4.62s\tremaining: 14.8s\n",
      "119:\tlearn: 0.3948407\ttotal: 4.67s\tremaining: 14.8s\n",
      "120:\tlearn: 0.3935357\ttotal: 4.7s\tremaining: 14.7s\n",
      "121:\tlearn: 0.3920353\ttotal: 4.72s\tremaining: 14.6s\n",
      "122:\tlearn: 0.3901932\ttotal: 4.75s\tremaining: 14.5s\n",
      "123:\tlearn: 0.3882801\ttotal: 4.82s\tremaining: 14.6s\n",
      "124:\tlearn: 0.3870154\ttotal: 4.86s\tremaining: 14.6s\n",
      "125:\tlearn: 0.3853101\ttotal: 4.89s\tremaining: 14.5s\n",
      "126:\tlearn: 0.3843651\ttotal: 4.92s\tremaining: 14.4s\n",
      "127:\tlearn: 0.3833760\ttotal: 4.94s\tremaining: 14.4s\n",
      "128:\tlearn: 0.3821638\ttotal: 4.98s\tremaining: 14.3s\n",
      "129:\tlearn: 0.3809225\ttotal: 5.05s\tremaining: 14.4s\n",
      "130:\tlearn: 0.3794011\ttotal: 5.08s\tremaining: 14.3s\n",
      "131:\tlearn: 0.3777878\ttotal: 5.11s\tremaining: 14.2s\n",
      "132:\tlearn: 0.3758387\ttotal: 5.13s\tremaining: 14.2s\n",
      "133:\tlearn: 0.3739165\ttotal: 5.2s\tremaining: 14.2s\n",
      "134:\tlearn: 0.3726967\ttotal: 5.25s\tremaining: 14.2s\n",
      "135:\tlearn: 0.3710568\ttotal: 5.28s\tremaining: 14.1s\n",
      "136:\tlearn: 0.3695562\ttotal: 5.3s\tremaining: 14s\n",
      "137:\tlearn: 0.3682316\ttotal: 5.32s\tremaining: 13.9s\n",
      "138:\tlearn: 0.3665583\ttotal: 5.39s\tremaining: 14s\n",
      "139:\tlearn: 0.3653672\ttotal: 5.43s\tremaining: 14s\n",
      "140:\tlearn: 0.3641849\ttotal: 5.45s\tremaining: 13.9s\n",
      "141:\tlearn: 0.3626766\ttotal: 5.47s\tremaining: 13.8s\n",
      "142:\tlearn: 0.3612050\ttotal: 5.5s\tremaining: 13.7s\n",
      "143:\tlearn: 0.3600669\ttotal: 5.58s\tremaining: 13.8s\n",
      "144:\tlearn: 0.3588504\ttotal: 5.61s\tremaining: 13.7s\n",
      "145:\tlearn: 0.3572020\ttotal: 5.64s\tremaining: 13.7s\n",
      "146:\tlearn: 0.3556777\ttotal: 5.66s\tremaining: 13.6s\n",
      "147:\tlearn: 0.3543622\ttotal: 5.71s\tremaining: 13.6s\n",
      "148:\tlearn: 0.3534895\ttotal: 5.76s\tremaining: 13.6s\n",
      "149:\tlearn: 0.3520890\ttotal: 5.79s\tremaining: 13.5s\n",
      "150:\tlearn: 0.3501729\ttotal: 5.81s\tremaining: 13.4s\n",
      "151:\tlearn: 0.3487185\ttotal: 5.85s\tremaining: 13.4s\n",
      "152:\tlearn: 0.3475025\ttotal: 5.92s\tremaining: 13.4s\n",
      "153:\tlearn: 0.3459696\ttotal: 5.96s\tremaining: 13.4s\n",
      "154:\tlearn: 0.3441507\ttotal: 5.98s\tremaining: 13.3s\n",
      "155:\tlearn: 0.3429856\ttotal: 6.01s\tremaining: 13.2s\n",
      "156:\tlearn: 0.3419949\ttotal: 6.03s\tremaining: 13.2s\n",
      "157:\tlearn: 0.3408974\ttotal: 6.1s\tremaining: 13.2s\n",
      "158:\tlearn: 0.3398671\ttotal: 6.15s\tremaining: 13.2s\n",
      "159:\tlearn: 0.3384945\ttotal: 6.17s\tremaining: 13.1s\n",
      "160:\tlearn: 0.3373487\ttotal: 6.2s\tremaining: 13s\n",
      "161:\tlearn: 0.3358455\ttotal: 6.22s\tremaining: 13s\n",
      "162:\tlearn: 0.3349851\ttotal: 6.29s\tremaining: 13s\n",
      "163:\tlearn: 0.3338070\ttotal: 6.33s\tremaining: 13s\n",
      "164:\tlearn: 0.3329093\ttotal: 6.35s\tremaining: 12.9s\n",
      "165:\tlearn: 0.3316769\ttotal: 6.37s\tremaining: 12.8s\n",
      "166:\tlearn: 0.3308128\ttotal: 6.42s\tremaining: 12.8s\n",
      "167:\tlearn: 0.3297221\ttotal: 6.48s\tremaining: 12.8s\n",
      "168:\tlearn: 0.3288695\ttotal: 6.52s\tremaining: 12.8s\n",
      "169:\tlearn: 0.3276738\ttotal: 6.54s\tremaining: 12.7s\n",
      "170:\tlearn: 0.3262362\ttotal: 6.56s\tremaining: 12.6s\n",
      "171:\tlearn: 0.3250273\ttotal: 6.59s\tremaining: 12.6s\n",
      "172:\tlearn: 0.3238734\ttotal: 6.66s\tremaining: 12.6s\n",
      "173:\tlearn: 0.3228339\ttotal: 6.68s\tremaining: 12.5s\n",
      "174:\tlearn: 0.3215609\ttotal: 6.71s\tremaining: 12.5s\n",
      "175:\tlearn: 0.3202915\ttotal: 6.78s\tremaining: 12.5s\n",
      "176:\tlearn: 0.3194371\ttotal: 6.83s\tremaining: 12.5s\n",
      "177:\tlearn: 0.3184841\ttotal: 6.87s\tremaining: 12.4s\n",
      "178:\tlearn: 0.3172321\ttotal: 6.89s\tremaining: 12.4s\n",
      "179:\tlearn: 0.3163270\ttotal: 6.91s\tremaining: 12.3s\n",
      "180:\tlearn: 0.3149903\ttotal: 6.96s\tremaining: 12.3s\n",
      "181:\tlearn: 0.3138386\ttotal: 7.03s\tremaining: 12.3s\n",
      "182:\tlearn: 0.3126957\ttotal: 7.07s\tremaining: 12.3s\n",
      "183:\tlearn: 0.3112204\ttotal: 7.09s\tremaining: 12.2s\n",
      "184:\tlearn: 0.3095655\ttotal: 7.12s\tremaining: 12.1s\n",
      "185:\tlearn: 0.3084888\ttotal: 7.16s\tremaining: 12.1s\n",
      "186:\tlearn: 0.3075291\ttotal: 7.22s\tremaining: 12.1s\n",
      "187:\tlearn: 0.3063277\ttotal: 7.25s\tremaining: 12s\n",
      "188:\tlearn: 0.3054280\ttotal: 7.28s\tremaining: 12s\n",
      "189:\tlearn: 0.3044239\ttotal: 7.3s\tremaining: 11.9s\n",
      "190:\tlearn: 0.3030455\ttotal: 7.37s\tremaining: 11.9s\n",
      "191:\tlearn: 0.3017888\ttotal: 7.41s\tremaining: 11.9s\n",
      "192:\tlearn: 0.3008415\ttotal: 7.43s\tremaining: 11.8s\n",
      "193:\tlearn: 0.2994382\ttotal: 7.45s\tremaining: 11.8s\n",
      "194:\tlearn: 0.2983908\ttotal: 7.48s\tremaining: 11.7s\n",
      "195:\tlearn: 0.2971888\ttotal: 7.54s\tremaining: 11.7s\n",
      "196:\tlearn: 0.2962523\ttotal: 7.58s\tremaining: 11.7s\n",
      "197:\tlearn: 0.2952269\ttotal: 7.6s\tremaining: 11.6s\n",
      "198:\tlearn: 0.2941730\ttotal: 7.62s\tremaining: 11.5s\n",
      "199:\tlearn: 0.2929105\ttotal: 7.7s\tremaining: 11.6s\n",
      "200:\tlearn: 0.2917977\ttotal: 7.74s\tremaining: 11.5s\n",
      "201:\tlearn: 0.2907836\ttotal: 7.76s\tremaining: 11.4s\n",
      "202:\tlearn: 0.2897745\ttotal: 7.78s\tremaining: 11.4s\n",
      "203:\tlearn: 0.2885547\ttotal: 7.81s\tremaining: 11.3s\n",
      "204:\tlearn: 0.2875169\ttotal: 7.88s\tremaining: 11.3s\n",
      "205:\tlearn: 0.2863330\ttotal: 7.92s\tremaining: 11.3s\n",
      "206:\tlearn: 0.2851627\ttotal: 7.95s\tremaining: 11.3s\n",
      "207:\tlearn: 0.2842546\ttotal: 7.97s\tremaining: 11.2s\n",
      "208:\tlearn: 0.2831115\ttotal: 7.99s\tremaining: 11.1s\n",
      "209:\tlearn: 0.2818933\ttotal: 8.06s\tremaining: 11.1s\n",
      "210:\tlearn: 0.2799795\ttotal: 8.11s\tremaining: 11.1s\n",
      "211:\tlearn: 0.2793160\ttotal: 8.14s\tremaining: 11.1s\n",
      "212:\tlearn: 0.2788207\ttotal: 8.17s\tremaining: 11s\n",
      "213:\tlearn: 0.2779770\ttotal: 8.19s\tremaining: 10.9s\n",
      "214:\tlearn: 0.2769226\ttotal: 8.26s\tremaining: 10.9s\n",
      "215:\tlearn: 0.2760007\ttotal: 8.3s\tremaining: 10.9s\n",
      "216:\tlearn: 0.2751922\ttotal: 8.33s\tremaining: 10.9s\n",
      "217:\tlearn: 0.2736580\ttotal: 8.35s\tremaining: 10.8s\n",
      "218:\tlearn: 0.2728335\ttotal: 8.4s\tremaining: 10.8s\n",
      "219:\tlearn: 0.2721299\ttotal: 8.47s\tremaining: 10.8s\n",
      "220:\tlearn: 0.2712654\ttotal: 8.5s\tremaining: 10.7s\n",
      "221:\tlearn: 0.2702466\ttotal: 8.52s\tremaining: 10.7s\n",
      "222:\tlearn: 0.2693616\ttotal: 8.54s\tremaining: 10.6s\n",
      "223:\tlearn: 0.2685375\ttotal: 8.62s\tremaining: 10.6s\n",
      "224:\tlearn: 0.2676729\ttotal: 8.64s\tremaining: 10.6s\n",
      "225:\tlearn: 0.2669278\ttotal: 8.67s\tremaining: 10.5s\n",
      "226:\tlearn: 0.2662566\ttotal: 8.69s\tremaining: 10.5s\n",
      "227:\tlearn: 0.2657807\ttotal: 8.73s\tremaining: 10.4s\n",
      "228:\tlearn: 0.2647903\ttotal: 8.79s\tremaining: 10.4s\n",
      "229:\tlearn: 0.2635828\ttotal: 8.82s\tremaining: 10.4s\n",
      "230:\tlearn: 0.2624656\ttotal: 8.85s\tremaining: 10.3s\n",
      "231:\tlearn: 0.2616147\ttotal: 8.87s\tremaining: 10.2s\n",
      "232:\tlearn: 0.2606175\ttotal: 8.92s\tremaining: 10.2s\n",
      "233:\tlearn: 0.2596552\ttotal: 8.98s\tremaining: 10.2s\n",
      "234:\tlearn: 0.2585793\ttotal: 9.02s\tremaining: 10.2s\n",
      "235:\tlearn: 0.2577706\ttotal: 9.04s\tremaining: 10.1s\n",
      "236:\tlearn: 0.2568672\ttotal: 9.06s\tremaining: 10.1s\n",
      "237:\tlearn: 0.2561398\ttotal: 9.08s\tremaining: 10s\n",
      "238:\tlearn: 0.2550358\ttotal: 9.17s\tremaining: 10s\n",
      "239:\tlearn: 0.2539906\ttotal: 9.23s\tremaining: 10s\n",
      "240:\tlearn: 0.2530831\ttotal: 9.26s\tremaining: 9.95s\n",
      "241:\tlearn: 0.2519943\ttotal: 9.28s\tremaining: 9.89s\n",
      "242:\tlearn: 0.2509803\ttotal: 9.3s\tremaining: 9.84s\n",
      "243:\tlearn: 0.2503198\ttotal: 9.38s\tremaining: 9.84s\n",
      "244:\tlearn: 0.2491269\ttotal: 9.41s\tremaining: 9.79s\n",
      "245:\tlearn: 0.2481176\ttotal: 9.44s\tremaining: 9.74s\n",
      "246:\tlearn: 0.2473436\ttotal: 9.46s\tremaining: 9.69s\n",
      "247:\tlearn: 0.2463096\ttotal: 9.5s\tremaining: 9.65s\n",
      "248:\tlearn: 0.2453938\ttotal: 9.56s\tremaining: 9.64s\n",
      "249:\tlearn: 0.2444537\ttotal: 9.6s\tremaining: 9.6s\n",
      "250:\tlearn: 0.2435646\ttotal: 9.62s\tremaining: 9.54s\n",
      "251:\tlearn: 0.2426963\ttotal: 9.64s\tremaining: 9.49s\n",
      "252:\tlearn: 0.2419295\ttotal: 9.71s\tremaining: 9.48s\n",
      "253:\tlearn: 0.2409017\ttotal: 9.76s\tremaining: 9.45s\n",
      "254:\tlearn: 0.2403849\ttotal: 9.79s\tremaining: 9.4s\n",
      "255:\tlearn: 0.2396661\ttotal: 9.81s\tremaining: 9.35s\n",
      "256:\tlearn: 0.2391639\ttotal: 9.88s\tremaining: 9.34s\n",
      "257:\tlearn: 0.2379448\ttotal: 9.94s\tremaining: 9.32s\n",
      "258:\tlearn: 0.2371033\ttotal: 9.96s\tremaining: 9.27s\n",
      "259:\tlearn: 0.2362197\ttotal: 9.98s\tremaining: 9.22s\n",
      "260:\tlearn: 0.2355624\ttotal: 10s\tremaining: 9.16s\n",
      "261:\tlearn: 0.2350197\ttotal: 10.1s\tremaining: 9.16s\n",
      "262:\tlearn: 0.2342932\ttotal: 10.1s\tremaining: 9.11s\n",
      "263:\tlearn: 0.2335584\ttotal: 10.1s\tremaining: 9.06s\n",
      "264:\tlearn: 0.2327494\ttotal: 10.2s\tremaining: 9.01s\n",
      "265:\tlearn: 0.2318560\ttotal: 10.2s\tremaining: 8.98s\n",
      "266:\tlearn: 0.2309540\ttotal: 10.3s\tremaining: 8.96s\n",
      "267:\tlearn: 0.2302923\ttotal: 10.3s\tremaining: 8.91s\n",
      "268:\tlearn: 0.2297168\ttotal: 10.3s\tremaining: 8.86s\n",
      "269:\tlearn: 0.2287875\ttotal: 10.4s\tremaining: 8.83s\n",
      "270:\tlearn: 0.2279831\ttotal: 10.4s\tremaining: 8.81s\n",
      "271:\tlearn: 0.2270448\ttotal: 10.5s\tremaining: 8.77s\n",
      "272:\tlearn: 0.2261682\ttotal: 10.5s\tremaining: 8.72s\n",
      "273:\tlearn: 0.2252966\ttotal: 10.5s\tremaining: 8.67s\n",
      "274:\tlearn: 0.2248377\ttotal: 10.6s\tremaining: 8.65s\n",
      "275:\tlearn: 0.2242185\ttotal: 10.6s\tremaining: 8.63s\n",
      "276:\tlearn: 0.2233567\ttotal: 10.7s\tremaining: 8.58s\n",
      "277:\tlearn: 0.2225510\ttotal: 10.7s\tremaining: 8.53s\n",
      "278:\tlearn: 0.2216762\ttotal: 10.7s\tremaining: 8.49s\n",
      "279:\tlearn: 0.2208328\ttotal: 10.8s\tremaining: 8.48s\n",
      "280:\tlearn: 0.2202707\ttotal: 10.8s\tremaining: 8.43s\n",
      "281:\tlearn: 0.2192228\ttotal: 10.8s\tremaining: 8.38s\n",
      "282:\tlearn: 0.2185964\ttotal: 10.9s\tremaining: 8.33s\n",
      "283:\tlearn: 0.2178129\ttotal: 10.9s\tremaining: 8.32s\n",
      "284:\tlearn: 0.2170357\ttotal: 11s\tremaining: 8.28s\n",
      "285:\tlearn: 0.2163516\ttotal: 11s\tremaining: 8.22s\n",
      "286:\tlearn: 0.2154459\ttotal: 11s\tremaining: 8.17s\n",
      "287:\tlearn: 0.2147163\ttotal: 11.1s\tremaining: 8.16s\n",
      "288:\tlearn: 0.2142242\ttotal: 11.1s\tremaining: 8.13s\n",
      "289:\tlearn: 0.2134580\ttotal: 11.2s\tremaining: 8.08s\n",
      "290:\tlearn: 0.2126665\ttotal: 11.2s\tremaining: 8.03s\n",
      "291:\tlearn: 0.2118166\ttotal: 11.2s\tremaining: 7.98s\n",
      "292:\tlearn: 0.2110743\ttotal: 11.3s\tremaining: 7.97s\n",
      "293:\tlearn: 0.2103815\ttotal: 11.3s\tremaining: 7.92s\n",
      "294:\tlearn: 0.2095672\ttotal: 11.3s\tremaining: 7.87s\n",
      "295:\tlearn: 0.2088243\ttotal: 11.3s\tremaining: 7.82s\n",
      "296:\tlearn: 0.2083679\ttotal: 11.4s\tremaining: 7.81s\n",
      "297:\tlearn: 0.2073805\ttotal: 11.5s\tremaining: 7.76s\n",
      "298:\tlearn: 0.2065932\ttotal: 11.5s\tremaining: 7.72s\n",
      "299:\tlearn: 0.2057572\ttotal: 11.5s\tremaining: 7.67s\n",
      "300:\tlearn: 0.2050652\ttotal: 11.6s\tremaining: 7.65s\n",
      "301:\tlearn: 0.2041527\ttotal: 11.6s\tremaining: 7.62s\n",
      "302:\tlearn: 0.2034082\ttotal: 11.6s\tremaining: 7.57s\n",
      "303:\tlearn: 0.2026603\ttotal: 11.7s\tremaining: 7.53s\n",
      "304:\tlearn: 0.2018229\ttotal: 11.7s\tremaining: 7.48s\n",
      "305:\tlearn: 0.2013155\ttotal: 11.8s\tremaining: 7.46s\n",
      "306:\tlearn: 0.2005694\ttotal: 11.8s\tremaining: 7.42s\n",
      "307:\tlearn: 0.1998697\ttotal: 11.8s\tremaining: 7.37s\n",
      "308:\tlearn: 0.1994562\ttotal: 11.8s\tremaining: 7.32s\n",
      "309:\tlearn: 0.1989455\ttotal: 11.9s\tremaining: 7.3s\n",
      "310:\tlearn: 0.1981693\ttotal: 12s\tremaining: 7.27s\n",
      "311:\tlearn: 0.1973817\ttotal: 12s\tremaining: 7.23s\n",
      "312:\tlearn: 0.1969644\ttotal: 12s\tremaining: 7.18s\n",
      "313:\tlearn: 0.1960849\ttotal: 12.1s\tremaining: 7.15s\n",
      "314:\tlearn: 0.1955716\ttotal: 12.1s\tremaining: 7.12s\n",
      "315:\tlearn: 0.1949306\ttotal: 12.2s\tremaining: 7.08s\n",
      "316:\tlearn: 0.1941877\ttotal: 12.2s\tremaining: 7.03s\n",
      "317:\tlearn: 0.1935594\ttotal: 12.3s\tremaining: 7.02s\n",
      "318:\tlearn: 0.1928993\ttotal: 12.3s\tremaining: 6.99s\n",
      "319:\tlearn: 0.1924175\ttotal: 12.3s\tremaining: 6.94s\n",
      "320:\tlearn: 0.1919741\ttotal: 12.4s\tremaining: 6.89s\n",
      "321:\tlearn: 0.1912672\ttotal: 12.4s\tremaining: 6.86s\n",
      "322:\tlearn: 0.1907354\ttotal: 12.5s\tremaining: 6.83s\n",
      "323:\tlearn: 0.1901036\ttotal: 12.5s\tremaining: 6.79s\n",
      "324:\tlearn: 0.1894464\ttotal: 12.5s\tremaining: 6.74s\n",
      "325:\tlearn: 0.1886394\ttotal: 12.6s\tremaining: 6.71s\n",
      "326:\tlearn: 0.1879905\ttotal: 12.6s\tremaining: 6.68s\n",
      "327:\tlearn: 0.1873451\ttotal: 12.7s\tremaining: 6.64s\n",
      "328:\tlearn: 0.1867241\ttotal: 12.7s\tremaining: 6.6s\n",
      "329:\tlearn: 0.1859963\ttotal: 12.7s\tremaining: 6.55s\n",
      "330:\tlearn: 0.1855489\ttotal: 12.7s\tremaining: 6.51s\n",
      "331:\tlearn: 0.1848812\ttotal: 12.8s\tremaining: 6.46s\n",
      "332:\tlearn: 0.1843851\ttotal: 12.8s\tremaining: 6.44s\n",
      "333:\tlearn: 0.1837958\ttotal: 12.9s\tremaining: 6.4s\n",
      "334:\tlearn: 0.1833077\ttotal: 12.9s\tremaining: 6.36s\n",
      "335:\tlearn: 0.1826700\ttotal: 12.9s\tremaining: 6.31s\n",
      "336:\tlearn: 0.1820064\ttotal: 13s\tremaining: 6.27s\n",
      "337:\tlearn: 0.1815658\ttotal: 13s\tremaining: 6.25s\n",
      "338:\tlearn: 0.1810091\ttotal: 13.1s\tremaining: 6.21s\n",
      "339:\tlearn: 0.1805895\ttotal: 13.1s\tremaining: 6.16s\n",
      "340:\tlearn: 0.1801304\ttotal: 13.1s\tremaining: 6.12s\n",
      "341:\tlearn: 0.1796878\ttotal: 13.2s\tremaining: 6.1s\n",
      "342:\tlearn: 0.1793304\ttotal: 13.2s\tremaining: 6.05s\n",
      "343:\tlearn: 0.1788207\ttotal: 13.2s\tremaining: 6.01s\n",
      "344:\tlearn: 0.1784033\ttotal: 13.3s\tremaining: 5.96s\n",
      "345:\tlearn: 0.1777800\ttotal: 13.3s\tremaining: 5.94s\n",
      "346:\tlearn: 0.1772438\ttotal: 13.4s\tremaining: 5.9s\n",
      "347:\tlearn: 0.1767598\ttotal: 13.4s\tremaining: 5.86s\n",
      "348:\tlearn: 0.1762289\ttotal: 13.4s\tremaining: 5.81s\n",
      "349:\tlearn: 0.1757730\ttotal: 13.5s\tremaining: 5.78s\n",
      "350:\tlearn: 0.1749549\ttotal: 13.5s\tremaining: 5.75s\n",
      "351:\tlearn: 0.1744377\ttotal: 13.6s\tremaining: 5.71s\n",
      "352:\tlearn: 0.1737632\ttotal: 13.6s\tremaining: 5.66s\n",
      "353:\tlearn: 0.1732695\ttotal: 13.6s\tremaining: 5.62s\n",
      "354:\tlearn: 0.1727497\ttotal: 13.7s\tremaining: 5.59s\n",
      "355:\tlearn: 0.1722755\ttotal: 13.7s\tremaining: 5.56s\n",
      "356:\tlearn: 0.1713936\ttotal: 13.8s\tremaining: 5.51s\n",
      "357:\tlearn: 0.1707652\ttotal: 13.8s\tremaining: 5.47s\n",
      "358:\tlearn: 0.1701933\ttotal: 13.8s\tremaining: 5.42s\n",
      "359:\tlearn: 0.1694254\ttotal: 13.9s\tremaining: 5.4s\n",
      "360:\tlearn: 0.1689142\ttotal: 13.9s\tremaining: 5.36s\n",
      "361:\tlearn: 0.1682823\ttotal: 13.9s\tremaining: 5.32s\n",
      "362:\tlearn: 0.1677629\ttotal: 14s\tremaining: 5.27s\n",
      "363:\tlearn: 0.1673171\ttotal: 14s\tremaining: 5.22s\n",
      "364:\tlearn: 0.1667660\ttotal: 14.1s\tremaining: 5.2s\n",
      "365:\tlearn: 0.1664288\ttotal: 14.1s\tremaining: 5.16s\n",
      "366:\tlearn: 0.1658993\ttotal: 14.1s\tremaining: 5.11s\n",
      "367:\tlearn: 0.1652995\ttotal: 14.2s\tremaining: 5.09s\n",
      "368:\tlearn: 0.1647402\ttotal: 14.2s\tremaining: 5.04s\n",
      "369:\tlearn: 0.1644504\ttotal: 14.2s\tremaining: 5s\n",
      "370:\tlearn: 0.1639766\ttotal: 14.3s\tremaining: 4.96s\n",
      "371:\tlearn: 0.1635521\ttotal: 14.3s\tremaining: 4.93s\n",
      "372:\tlearn: 0.1631996\ttotal: 14.3s\tremaining: 4.88s\n",
      "373:\tlearn: 0.1626622\ttotal: 14.4s\tremaining: 4.86s\n",
      "374:\tlearn: 0.1621712\ttotal: 14.5s\tremaining: 4.82s\n",
      "375:\tlearn: 0.1616198\ttotal: 14.5s\tremaining: 4.78s\n",
      "376:\tlearn: 0.1611429\ttotal: 14.5s\tremaining: 4.73s\n",
      "377:\tlearn: 0.1605885\ttotal: 14.5s\tremaining: 4.7s\n",
      "378:\tlearn: 0.1601969\ttotal: 14.6s\tremaining: 4.66s\n",
      "379:\tlearn: 0.1597717\ttotal: 14.6s\tremaining: 4.62s\n",
      "380:\tlearn: 0.1594537\ttotal: 14.7s\tremaining: 4.58s\n",
      "381:\tlearn: 0.1589883\ttotal: 14.7s\tremaining: 4.54s\n",
      "382:\tlearn: 0.1584596\ttotal: 14.8s\tremaining: 4.51s\n",
      "383:\tlearn: 0.1577499\ttotal: 14.8s\tremaining: 4.47s\n",
      "384:\tlearn: 0.1572151\ttotal: 14.8s\tremaining: 4.42s\n",
      "385:\tlearn: 0.1567694\ttotal: 14.9s\tremaining: 4.39s\n",
      "386:\tlearn: 0.1561282\ttotal: 14.9s\tremaining: 4.36s\n",
      "387:\tlearn: 0.1558062\ttotal: 14.9s\tremaining: 4.32s\n",
      "388:\tlearn: 0.1552745\ttotal: 15s\tremaining: 4.28s\n",
      "389:\tlearn: 0.1548783\ttotal: 15.1s\tremaining: 4.25s\n",
      "390:\tlearn: 0.1543448\ttotal: 15.1s\tremaining: 4.2s\n",
      "391:\tlearn: 0.1539548\ttotal: 15.1s\tremaining: 4.16s\n",
      "392:\tlearn: 0.1536188\ttotal: 15.2s\tremaining: 4.13s\n",
      "393:\tlearn: 0.1532440\ttotal: 15.2s\tremaining: 4.09s\n",
      "394:\tlearn: 0.1526095\ttotal: 15.2s\tremaining: 4.05s\n",
      "395:\tlearn: 0.1521409\ttotal: 15.3s\tremaining: 4.01s\n",
      "396:\tlearn: 0.1516368\ttotal: 15.3s\tremaining: 3.97s\n",
      "397:\tlearn: 0.1512016\ttotal: 15.3s\tremaining: 3.93s\n",
      "398:\tlearn: 0.1507566\ttotal: 15.4s\tremaining: 3.9s\n",
      "399:\tlearn: 0.1502486\ttotal: 15.4s\tremaining: 3.86s\n",
      "400:\tlearn: 0.1498122\ttotal: 15.5s\tremaining: 3.82s\n",
      "401:\tlearn: 0.1491115\ttotal: 15.5s\tremaining: 3.77s\n",
      "402:\tlearn: 0.1486323\ttotal: 15.5s\tremaining: 3.74s\n",
      "403:\tlearn: 0.1480453\ttotal: 15.6s\tremaining: 3.71s\n",
      "404:\tlearn: 0.1475616\ttotal: 15.6s\tremaining: 3.67s\n",
      "405:\tlearn: 0.1471666\ttotal: 15.7s\tremaining: 3.62s\n",
      "406:\tlearn: 0.1466127\ttotal: 15.7s\tremaining: 3.58s\n",
      "407:\tlearn: 0.1461406\ttotal: 15.7s\tremaining: 3.55s\n",
      "408:\tlearn: 0.1456246\ttotal: 15.8s\tremaining: 3.51s\n",
      "409:\tlearn: 0.1451014\ttotal: 15.8s\tremaining: 3.47s\n",
      "410:\tlearn: 0.1446414\ttotal: 15.8s\tremaining: 3.43s\n",
      "411:\tlearn: 0.1442285\ttotal: 15.9s\tremaining: 3.4s\n",
      "412:\tlearn: 0.1438343\ttotal: 15.9s\tremaining: 3.36s\n",
      "413:\tlearn: 0.1432998\ttotal: 16s\tremaining: 3.32s\n",
      "414:\tlearn: 0.1429740\ttotal: 16s\tremaining: 3.27s\n",
      "415:\tlearn: 0.1426245\ttotal: 16s\tremaining: 3.24s\n",
      "416:\tlearn: 0.1422560\ttotal: 16.1s\tremaining: 3.2s\n",
      "417:\tlearn: 0.1416480\ttotal: 16.1s\tremaining: 3.17s\n",
      "418:\tlearn: 0.1412869\ttotal: 16.2s\tremaining: 3.12s\n",
      "419:\tlearn: 0.1407557\ttotal: 16.2s\tremaining: 3.08s\n",
      "420:\tlearn: 0.1404528\ttotal: 16.2s\tremaining: 3.05s\n",
      "421:\tlearn: 0.1400024\ttotal: 16.3s\tremaining: 3.01s\n",
      "422:\tlearn: 0.1397241\ttotal: 16.3s\tremaining: 2.97s\n",
      "423:\tlearn: 0.1391769\ttotal: 16.3s\tremaining: 2.93s\n",
      "424:\tlearn: 0.1388453\ttotal: 16.4s\tremaining: 2.89s\n",
      "425:\tlearn: 0.1381747\ttotal: 16.4s\tremaining: 2.85s\n",
      "426:\tlearn: 0.1376462\ttotal: 16.5s\tremaining: 2.82s\n",
      "427:\tlearn: 0.1370643\ttotal: 16.5s\tremaining: 2.78s\n",
      "428:\tlearn: 0.1367437\ttotal: 16.5s\tremaining: 2.73s\n",
      "429:\tlearn: 0.1362956\ttotal: 16.5s\tremaining: 2.69s\n",
      "430:\tlearn: 0.1360316\ttotal: 16.6s\tremaining: 2.66s\n",
      "431:\tlearn: 0.1353798\ttotal: 16.7s\tremaining: 2.62s\n",
      "432:\tlearn: 0.1348994\ttotal: 16.7s\tremaining: 2.58s\n",
      "433:\tlearn: 0.1345210\ttotal: 16.7s\tremaining: 2.54s\n",
      "434:\tlearn: 0.1342771\ttotal: 16.7s\tremaining: 2.5s\n",
      "435:\tlearn: 0.1338463\ttotal: 16.8s\tremaining: 2.47s\n",
      "436:\tlearn: 0.1335046\ttotal: 16.8s\tremaining: 2.43s\n",
      "437:\tlearn: 0.1331198\ttotal: 16.9s\tremaining: 2.39s\n",
      "438:\tlearn: 0.1327695\ttotal: 16.9s\tremaining: 2.35s\n",
      "439:\tlearn: 0.1324159\ttotal: 17s\tremaining: 2.31s\n",
      "440:\tlearn: 0.1319932\ttotal: 17s\tremaining: 2.27s\n",
      "441:\tlearn: 0.1315436\ttotal: 17s\tremaining: 2.23s\n",
      "442:\tlearn: 0.1311574\ttotal: 17s\tremaining: 2.19s\n",
      "443:\tlearn: 0.1308547\ttotal: 17.1s\tremaining: 2.16s\n",
      "444:\tlearn: 0.1303868\ttotal: 17.2s\tremaining: 2.12s\n",
      "445:\tlearn: 0.1299267\ttotal: 17.2s\tremaining: 2.08s\n",
      "446:\tlearn: 0.1296405\ttotal: 17.2s\tremaining: 2.04s\n",
      "447:\tlearn: 0.1290230\ttotal: 17.2s\tremaining: 2s\n",
      "448:\tlearn: 0.1287450\ttotal: 17.3s\tremaining: 1.96s\n",
      "449:\tlearn: 0.1284466\ttotal: 17.3s\tremaining: 1.93s\n",
      "450:\tlearn: 0.1280789\ttotal: 17.4s\tremaining: 1.89s\n",
      "451:\tlearn: 0.1275643\ttotal: 17.4s\tremaining: 1.85s\n",
      "452:\tlearn: 0.1272360\ttotal: 17.4s\tremaining: 1.81s\n",
      "453:\tlearn: 0.1267803\ttotal: 17.5s\tremaining: 1.77s\n",
      "454:\tlearn: 0.1264794\ttotal: 17.5s\tremaining: 1.73s\n",
      "455:\tlearn: 0.1260946\ttotal: 17.6s\tremaining: 1.69s\n",
      "456:\tlearn: 0.1257341\ttotal: 17.6s\tremaining: 1.65s\n",
      "457:\tlearn: 0.1254089\ttotal: 17.6s\tremaining: 1.61s\n",
      "458:\tlearn: 0.1251096\ttotal: 17.7s\tremaining: 1.58s\n",
      "459:\tlearn: 0.1246127\ttotal: 17.7s\tremaining: 1.54s\n",
      "460:\tlearn: 0.1243871\ttotal: 17.7s\tremaining: 1.5s\n",
      "461:\tlearn: 0.1241069\ttotal: 17.8s\tremaining: 1.46s\n",
      "462:\tlearn: 0.1238251\ttotal: 17.8s\tremaining: 1.42s\n",
      "463:\tlearn: 0.1235842\ttotal: 17.9s\tremaining: 1.39s\n",
      "464:\tlearn: 0.1232915\ttotal: 17.9s\tremaining: 1.35s\n",
      "465:\tlearn: 0.1227728\ttotal: 17.9s\tremaining: 1.31s\n",
      "466:\tlearn: 0.1225414\ttotal: 17.9s\tremaining: 1.27s\n",
      "467:\tlearn: 0.1221751\ttotal: 18s\tremaining: 1.23s\n",
      "468:\tlearn: 0.1219030\ttotal: 18s\tremaining: 1.19s\n",
      "469:\tlearn: 0.1215167\ttotal: 18.1s\tremaining: 1.15s\n",
      "470:\tlearn: 0.1212292\ttotal: 18.1s\tremaining: 1.11s\n",
      "471:\tlearn: 0.1207248\ttotal: 18.1s\tremaining: 1.07s\n",
      "472:\tlearn: 0.1205399\ttotal: 18.2s\tremaining: 1.04s\n",
      "473:\tlearn: 0.1202326\ttotal: 18.2s\tremaining: 1s\n",
      "474:\tlearn: 0.1198079\ttotal: 18.3s\tremaining: 962ms\n",
      "475:\tlearn: 0.1193550\ttotal: 18.3s\tremaining: 923ms\n",
      "476:\tlearn: 0.1190289\ttotal: 18.3s\tremaining: 883ms\n",
      "477:\tlearn: 0.1187714\ttotal: 18.4s\tremaining: 847ms\n",
      "478:\tlearn: 0.1182254\ttotal: 18.4s\tremaining: 808ms\n",
      "479:\tlearn: 0.1177878\ttotal: 18.5s\tremaining: 769ms\n",
      "480:\tlearn: 0.1174806\ttotal: 18.5s\tremaining: 730ms\n",
      "481:\tlearn: 0.1169989\ttotal: 18.5s\tremaining: 692ms\n",
      "482:\tlearn: 0.1165337\ttotal: 18.6s\tremaining: 655ms\n",
      "483:\tlearn: 0.1160098\ttotal: 18.6s\tremaining: 616ms\n",
      "484:\tlearn: 0.1155102\ttotal: 18.7s\tremaining: 577ms\n",
      "485:\tlearn: 0.1151836\ttotal: 18.7s\tremaining: 538ms\n",
      "486:\tlearn: 0.1146834\ttotal: 18.8s\tremaining: 501ms\n",
      "487:\tlearn: 0.1142987\ttotal: 18.8s\tremaining: 462ms\n",
      "488:\tlearn: 0.1138764\ttotal: 18.8s\tremaining: 423ms\n",
      "489:\tlearn: 0.1135664\ttotal: 18.8s\tremaining: 385ms\n",
      "490:\tlearn: 0.1132129\ttotal: 18.9s\tremaining: 346ms\n",
      "491:\tlearn: 0.1128758\ttotal: 19s\tremaining: 308ms\n",
      "492:\tlearn: 0.1126336\ttotal: 19s\tremaining: 270ms\n",
      "493:\tlearn: 0.1122619\ttotal: 19s\tremaining: 231ms\n",
      "494:\tlearn: 0.1120046\ttotal: 19s\tremaining: 192ms\n",
      "495:\tlearn: 0.1117334\ttotal: 19.1s\tremaining: 154ms\n",
      "496:\tlearn: 0.1114164\ttotal: 19.1s\tremaining: 116ms\n",
      "497:\tlearn: 0.1110412\ttotal: 19.2s\tremaining: 77ms\n",
      "498:\tlearn: 0.1107649\ttotal: 19.2s\tremaining: 38.4ms\n",
      "499:\tlearn: 0.1103074\ttotal: 19.3s\tremaining: 0us\n",
      "0:\tlearn: 0.6893204\ttotal: 23.2ms\tremaining: 11.6s\n",
      "1:\tlearn: 0.6854802\ttotal: 93.3ms\tremaining: 23.2s\n",
      "2:\tlearn: 0.6816226\ttotal: 144ms\tremaining: 23.9s\n",
      "3:\tlearn: 0.6774266\ttotal: 171ms\tremaining: 21.2s\n",
      "4:\tlearn: 0.6735388\ttotal: 189ms\tremaining: 18.7s\n",
      "5:\tlearn: 0.6706132\ttotal: 209ms\tremaining: 17.2s\n",
      "6:\tlearn: 0.6670256\ttotal: 285ms\tremaining: 20.1s\n",
      "7:\tlearn: 0.6635206\ttotal: 327ms\tremaining: 20.1s\n",
      "8:\tlearn: 0.6595626\ttotal: 353ms\tremaining: 19.2s\n",
      "9:\tlearn: 0.6554880\ttotal: 373ms\tremaining: 18.3s\n",
      "10:\tlearn: 0.6526821\ttotal: 441ms\tremaining: 19.6s\n",
      "11:\tlearn: 0.6487391\ttotal: 489ms\tremaining: 19.9s\n",
      "12:\tlearn: 0.6462656\ttotal: 517ms\tremaining: 19.4s\n",
      "13:\tlearn: 0.6424659\ttotal: 539ms\tremaining: 18.7s\n",
      "14:\tlearn: 0.6390914\ttotal: 559ms\tremaining: 18.1s\n",
      "15:\tlearn: 0.6355447\ttotal: 630ms\tremaining: 19.1s\n",
      "16:\tlearn: 0.6318436\ttotal: 679ms\tremaining: 19.3s\n",
      "17:\tlearn: 0.6275235\ttotal: 708ms\tremaining: 19s\n",
      "18:\tlearn: 0.6244562\ttotal: 730ms\tremaining: 18.5s\n",
      "19:\tlearn: 0.6215751\ttotal: 801ms\tremaining: 19.2s\n",
      "20:\tlearn: 0.6184273\ttotal: 849ms\tremaining: 19.4s\n",
      "21:\tlearn: 0.6149643\ttotal: 876ms\tremaining: 19s\n",
      "22:\tlearn: 0.6121408\ttotal: 899ms\tremaining: 18.6s\n",
      "23:\tlearn: 0.6084494\ttotal: 944ms\tremaining: 18.7s\n",
      "24:\tlearn: 0.6052465\ttotal: 1.01s\tremaining: 19.2s\n",
      "25:\tlearn: 0.6019501\ttotal: 1.04s\tremaining: 19s\n",
      "26:\tlearn: 0.5986557\ttotal: 1.07s\tremaining: 18.7s\n",
      "27:\tlearn: 0.5955565\ttotal: 1.09s\tremaining: 18.4s\n",
      "28:\tlearn: 0.5918743\ttotal: 1.14s\tremaining: 18.4s\n",
      "29:\tlearn: 0.5885733\ttotal: 1.19s\tremaining: 18.6s\n",
      "30:\tlearn: 0.5863100\ttotal: 1.21s\tremaining: 18.3s\n",
      "31:\tlearn: 0.5834914\ttotal: 1.23s\tremaining: 18s\n",
      "32:\tlearn: 0.5805685\ttotal: 1.3s\tremaining: 18.4s\n",
      "33:\tlearn: 0.5772649\ttotal: 1.34s\tremaining: 18.4s\n",
      "34:\tlearn: 0.5750656\ttotal: 1.36s\tremaining: 18.1s\n",
      "35:\tlearn: 0.5727205\ttotal: 1.39s\tremaining: 17.9s\n",
      "36:\tlearn: 0.5701548\ttotal: 1.43s\tremaining: 17.9s\n",
      "37:\tlearn: 0.5674723\ttotal: 1.49s\tremaining: 18.1s\n",
      "38:\tlearn: 0.5647203\ttotal: 1.52s\tremaining: 17.9s\n",
      "39:\tlearn: 0.5624042\ttotal: 1.54s\tremaining: 17.7s\n",
      "40:\tlearn: 0.5597207\ttotal: 1.56s\tremaining: 17.5s\n",
      "41:\tlearn: 0.5561774\ttotal: 1.61s\tremaining: 17.6s\n",
      "42:\tlearn: 0.5533409\ttotal: 1.67s\tremaining: 17.8s\n",
      "43:\tlearn: 0.5510470\ttotal: 1.7s\tremaining: 17.6s\n",
      "44:\tlearn: 0.5483403\ttotal: 1.73s\tremaining: 17.5s\n",
      "45:\tlearn: 0.5459194\ttotal: 1.75s\tremaining: 17.2s\n",
      "46:\tlearn: 0.5430119\ttotal: 1.82s\tremaining: 17.5s\n",
      "47:\tlearn: 0.5403207\ttotal: 1.86s\tremaining: 17.6s\n",
      "48:\tlearn: 0.5379809\ttotal: 1.89s\tremaining: 17.4s\n",
      "49:\tlearn: 0.5356869\ttotal: 1.91s\tremaining: 17.2s\n",
      "50:\tlearn: 0.5329385\ttotal: 1.98s\tremaining: 17.4s\n",
      "51:\tlearn: 0.5311286\ttotal: 2.04s\tremaining: 17.5s\n",
      "52:\tlearn: 0.5285421\ttotal: 2.06s\tremaining: 17.4s\n",
      "53:\tlearn: 0.5254162\ttotal: 2.08s\tremaining: 17.2s\n",
      "54:\tlearn: 0.5229124\ttotal: 2.1s\tremaining: 17s\n",
      "55:\tlearn: 0.5208105\ttotal: 2.17s\tremaining: 17.2s\n",
      "56:\tlearn: 0.5188000\ttotal: 2.22s\tremaining: 17.2s\n",
      "57:\tlearn: 0.5158021\ttotal: 2.24s\tremaining: 17.1s\n",
      "58:\tlearn: 0.5136243\ttotal: 2.26s\tremaining: 16.9s\n",
      "59:\tlearn: 0.5108961\ttotal: 2.29s\tremaining: 16.8s\n",
      "60:\tlearn: 0.5084952\ttotal: 2.36s\tremaining: 17s\n",
      "61:\tlearn: 0.5061907\ttotal: 2.4s\tremaining: 17s\n",
      "62:\tlearn: 0.5035372\ttotal: 2.42s\tremaining: 16.8s\n",
      "63:\tlearn: 0.5012701\ttotal: 2.44s\tremaining: 16.7s\n",
      "64:\tlearn: 0.4989664\ttotal: 2.49s\tremaining: 16.7s\n",
      "65:\tlearn: 0.4961851\ttotal: 2.55s\tremaining: 16.8s\n",
      "66:\tlearn: 0.4941441\ttotal: 2.58s\tremaining: 16.7s\n",
      "67:\tlearn: 0.4920078\ttotal: 2.6s\tremaining: 16.5s\n",
      "68:\tlearn: 0.4900421\ttotal: 2.62s\tremaining: 16.4s\n",
      "69:\tlearn: 0.4878294\ttotal: 2.67s\tremaining: 16.4s\n",
      "70:\tlearn: 0.4859562\ttotal: 2.73s\tremaining: 16.5s\n",
      "71:\tlearn: 0.4841182\ttotal: 2.76s\tremaining: 16.4s\n",
      "72:\tlearn: 0.4822149\ttotal: 2.78s\tremaining: 16.3s\n",
      "73:\tlearn: 0.4803377\ttotal: 2.81s\tremaining: 16.2s\n",
      "74:\tlearn: 0.4786551\ttotal: 2.88s\tremaining: 16.3s\n",
      "75:\tlearn: 0.4763585\ttotal: 2.92s\tremaining: 16.3s\n",
      "76:\tlearn: 0.4745067\ttotal: 2.95s\tremaining: 16.2s\n",
      "77:\tlearn: 0.4722098\ttotal: 2.97s\tremaining: 16.1s\n",
      "78:\tlearn: 0.4694992\ttotal: 3.02s\tremaining: 16.1s\n",
      "79:\tlearn: 0.4672302\ttotal: 3.07s\tremaining: 16.1s\n",
      "80:\tlearn: 0.4650467\ttotal: 3.1s\tremaining: 16s\n",
      "81:\tlearn: 0.4623701\ttotal: 3.18s\tremaining: 16.2s\n",
      "82:\tlearn: 0.4608182\ttotal: 3.25s\tremaining: 16.3s\n",
      "83:\tlearn: 0.4589378\ttotal: 3.27s\tremaining: 16.2s\n",
      "84:\tlearn: 0.4571227\ttotal: 3.29s\tremaining: 16.1s\n",
      "85:\tlearn: 0.4549974\ttotal: 3.35s\tremaining: 16.1s\n",
      "86:\tlearn: 0.4527555\ttotal: 3.4s\tremaining: 16.1s\n",
      "87:\tlearn: 0.4505956\ttotal: 3.43s\tremaining: 16s\n",
      "88:\tlearn: 0.4492239\ttotal: 3.45s\tremaining: 15.9s\n",
      "89:\tlearn: 0.4471934\ttotal: 3.49s\tremaining: 15.9s\n",
      "90:\tlearn: 0.4447700\ttotal: 3.55s\tremaining: 16s\n",
      "91:\tlearn: 0.4430285\ttotal: 3.58s\tremaining: 15.9s\n",
      "92:\tlearn: 0.4413544\ttotal: 3.61s\tremaining: 15.8s\n",
      "93:\tlearn: 0.4390013\ttotal: 3.63s\tremaining: 15.7s\n",
      "94:\tlearn: 0.4372605\ttotal: 3.7s\tremaining: 15.8s\n",
      "95:\tlearn: 0.4356868\ttotal: 3.75s\tremaining: 15.8s\n",
      "96:\tlearn: 0.4338427\ttotal: 3.78s\tremaining: 15.7s\n",
      "97:\tlearn: 0.4312971\ttotal: 3.8s\tremaining: 15.6s\n",
      "98:\tlearn: 0.4301639\ttotal: 3.83s\tremaining: 15.5s\n",
      "99:\tlearn: 0.4286214\ttotal: 3.9s\tremaining: 15.6s\n",
      "100:\tlearn: 0.4261935\ttotal: 3.93s\tremaining: 15.5s\n",
      "101:\tlearn: 0.4237476\ttotal: 3.95s\tremaining: 15.4s\n",
      "102:\tlearn: 0.4216796\ttotal: 3.98s\tremaining: 15.3s\n",
      "103:\tlearn: 0.4199057\ttotal: 4s\tremaining: 15.2s\n",
      "104:\tlearn: 0.4182472\ttotal: 4.07s\tremaining: 15.3s\n",
      "105:\tlearn: 0.4168235\ttotal: 4.12s\tremaining: 15.3s\n",
      "106:\tlearn: 0.4147606\ttotal: 4.14s\tremaining: 15.2s\n",
      "107:\tlearn: 0.4134588\ttotal: 4.17s\tremaining: 15.1s\n",
      "108:\tlearn: 0.4112366\ttotal: 4.19s\tremaining: 15s\n",
      "109:\tlearn: 0.4094561\ttotal: 4.26s\tremaining: 15.1s\n",
      "110:\tlearn: 0.4075272\ttotal: 4.3s\tremaining: 15.1s\n",
      "111:\tlearn: 0.4055227\ttotal: 4.33s\tremaining: 15s\n",
      "112:\tlearn: 0.4041617\ttotal: 4.35s\tremaining: 14.9s\n",
      "113:\tlearn: 0.4027345\ttotal: 4.37s\tremaining: 14.8s\n",
      "114:\tlearn: 0.4014858\ttotal: 4.44s\tremaining: 14.9s\n",
      "115:\tlearn: 0.3995860\ttotal: 4.48s\tremaining: 14.8s\n",
      "116:\tlearn: 0.3975250\ttotal: 4.5s\tremaining: 14.7s\n",
      "117:\tlearn: 0.3959148\ttotal: 4.52s\tremaining: 14.6s\n",
      "118:\tlearn: 0.3941565\ttotal: 4.57s\tremaining: 14.6s\n",
      "119:\tlearn: 0.3924763\ttotal: 4.64s\tremaining: 14.7s\n",
      "120:\tlearn: 0.3914656\ttotal: 4.67s\tremaining: 14.6s\n",
      "121:\tlearn: 0.3897022\ttotal: 4.69s\tremaining: 14.5s\n",
      "122:\tlearn: 0.3881598\ttotal: 4.71s\tremaining: 14.4s\n",
      "123:\tlearn: 0.3857723\ttotal: 4.79s\tremaining: 14.5s\n",
      "124:\tlearn: 0.3832027\ttotal: 4.82s\tremaining: 14.4s\n",
      "125:\tlearn: 0.3816528\ttotal: 4.84s\tremaining: 14.4s\n",
      "126:\tlearn: 0.3805037\ttotal: 4.86s\tremaining: 14.3s\n",
      "127:\tlearn: 0.3791515\ttotal: 4.93s\tremaining: 14.3s\n",
      "128:\tlearn: 0.3775659\ttotal: 4.98s\tremaining: 14.3s\n",
      "129:\tlearn: 0.3758252\ttotal: 5.01s\tremaining: 14.3s\n",
      "130:\tlearn: 0.3746260\ttotal: 5.03s\tremaining: 14.2s\n",
      "131:\tlearn: 0.3731670\ttotal: 5.1s\tremaining: 14.2s\n",
      "132:\tlearn: 0.3713222\ttotal: 5.15s\tremaining: 14.2s\n",
      "133:\tlearn: 0.3696584\ttotal: 5.17s\tremaining: 14.1s\n",
      "134:\tlearn: 0.3685235\ttotal: 5.19s\tremaining: 14s\n",
      "135:\tlearn: 0.3669271\ttotal: 5.22s\tremaining: 14s\n",
      "136:\tlearn: 0.3655054\ttotal: 5.29s\tremaining: 14s\n",
      "137:\tlearn: 0.3642957\ttotal: 5.33s\tremaining: 14s\n",
      "138:\tlearn: 0.3625482\ttotal: 5.36s\tremaining: 13.9s\n",
      "139:\tlearn: 0.3613079\ttotal: 5.38s\tremaining: 13.8s\n",
      "140:\tlearn: 0.3601080\ttotal: 5.43s\tremaining: 13.8s\n",
      "141:\tlearn: 0.3583234\ttotal: 5.49s\tremaining: 13.8s\n",
      "142:\tlearn: 0.3566756\ttotal: 5.52s\tremaining: 13.8s\n",
      "143:\tlearn: 0.3548638\ttotal: 5.54s\tremaining: 13.7s\n",
      "144:\tlearn: 0.3534151\ttotal: 5.56s\tremaining: 13.6s\n",
      "145:\tlearn: 0.3523332\ttotal: 5.61s\tremaining: 13.6s\n",
      "146:\tlearn: 0.3510741\ttotal: 5.67s\tremaining: 13.6s\n",
      "147:\tlearn: 0.3493766\ttotal: 5.69s\tremaining: 13.5s\n",
      "148:\tlearn: 0.3479048\ttotal: 5.71s\tremaining: 13.5s\n",
      "149:\tlearn: 0.3464694\ttotal: 5.78s\tremaining: 13.5s\n",
      "150:\tlearn: 0.3450152\ttotal: 5.83s\tremaining: 13.5s\n",
      "151:\tlearn: 0.3437626\ttotal: 5.86s\tremaining: 13.4s\n",
      "152:\tlearn: 0.3424837\ttotal: 5.88s\tremaining: 13.3s\n",
      "153:\tlearn: 0.3409036\ttotal: 5.92s\tremaining: 13.3s\n",
      "154:\tlearn: 0.3398449\ttotal: 5.99s\tremaining: 13.3s\n",
      "155:\tlearn: 0.3387383\ttotal: 6.02s\tremaining: 13.3s\n",
      "156:\tlearn: 0.3371194\ttotal: 6.05s\tremaining: 13.2s\n",
      "157:\tlearn: 0.3358261\ttotal: 6.07s\tremaining: 13.1s\n",
      "158:\tlearn: 0.3341970\ttotal: 6.14s\tremaining: 13.2s\n",
      "159:\tlearn: 0.3323974\ttotal: 6.19s\tremaining: 13.1s\n",
      "160:\tlearn: 0.3310138\ttotal: 6.21s\tremaining: 13.1s\n",
      "161:\tlearn: 0.3298218\ttotal: 6.23s\tremaining: 13s\n",
      "162:\tlearn: 0.3284626\ttotal: 6.26s\tremaining: 12.9s\n",
      "163:\tlearn: 0.3269277\ttotal: 6.33s\tremaining: 13s\n",
      "164:\tlearn: 0.3254044\ttotal: 6.37s\tremaining: 12.9s\n",
      "165:\tlearn: 0.3241988\ttotal: 6.39s\tremaining: 12.9s\n",
      "166:\tlearn: 0.3230696\ttotal: 6.41s\tremaining: 12.8s\n",
      "167:\tlearn: 0.3216707\ttotal: 6.46s\tremaining: 12.8s\n",
      "168:\tlearn: 0.3204998\ttotal: 6.52s\tremaining: 12.8s\n",
      "169:\tlearn: 0.3197615\ttotal: 6.55s\tremaining: 12.7s\n",
      "170:\tlearn: 0.3185789\ttotal: 6.57s\tremaining: 12.6s\n",
      "171:\tlearn: 0.3173085\ttotal: 6.59s\tremaining: 12.6s\n",
      "172:\tlearn: 0.3162631\ttotal: 6.62s\tremaining: 12.5s\n",
      "173:\tlearn: 0.3152965\ttotal: 6.66s\tremaining: 12.5s\n",
      "174:\tlearn: 0.3142592\ttotal: 6.72s\tremaining: 12.5s\n",
      "175:\tlearn: 0.3132280\ttotal: 6.76s\tremaining: 12.4s\n",
      "176:\tlearn: 0.3122526\ttotal: 6.78s\tremaining: 12.4s\n",
      "177:\tlearn: 0.3111164\ttotal: 6.8s\tremaining: 12.3s\n",
      "178:\tlearn: 0.3101685\ttotal: 6.86s\tremaining: 12.3s\n",
      "179:\tlearn: 0.3089347\ttotal: 6.91s\tremaining: 12.3s\n",
      "180:\tlearn: 0.3080231\ttotal: 6.93s\tremaining: 12.2s\n",
      "181:\tlearn: 0.3066561\ttotal: 6.95s\tremaining: 12.2s\n",
      "182:\tlearn: 0.3055270\ttotal: 7.03s\tremaining: 12.2s\n",
      "183:\tlearn: 0.3044346\ttotal: 7.07s\tremaining: 12.1s\n",
      "184:\tlearn: 0.3035042\ttotal: 7.09s\tremaining: 12.1s\n",
      "185:\tlearn: 0.3020969\ttotal: 7.12s\tremaining: 12s\n",
      "186:\tlearn: 0.3009691\ttotal: 7.14s\tremaining: 11.9s\n",
      "187:\tlearn: 0.2995822\ttotal: 7.21s\tremaining: 12s\n",
      "188:\tlearn: 0.2985111\ttotal: 7.25s\tremaining: 11.9s\n",
      "189:\tlearn: 0.2973578\ttotal: 7.28s\tremaining: 11.9s\n",
      "190:\tlearn: 0.2962904\ttotal: 7.3s\tremaining: 11.8s\n",
      "191:\tlearn: 0.2949857\ttotal: 7.36s\tremaining: 11.8s\n",
      "192:\tlearn: 0.2938547\ttotal: 7.41s\tremaining: 11.8s\n",
      "193:\tlearn: 0.2929666\ttotal: 7.45s\tremaining: 11.7s\n",
      "194:\tlearn: 0.2917595\ttotal: 7.47s\tremaining: 11.7s\n",
      "195:\tlearn: 0.2908414\ttotal: 7.51s\tremaining: 11.7s\n",
      "196:\tlearn: 0.2899034\ttotal: 7.59s\tremaining: 11.7s\n",
      "197:\tlearn: 0.2885176\ttotal: 7.62s\tremaining: 11.6s\n",
      "198:\tlearn: 0.2873724\ttotal: 7.64s\tremaining: 11.6s\n",
      "199:\tlearn: 0.2861649\ttotal: 7.67s\tremaining: 11.5s\n",
      "200:\tlearn: 0.2850621\ttotal: 7.71s\tremaining: 11.5s\n",
      "201:\tlearn: 0.2842333\ttotal: 7.78s\tremaining: 11.5s\n",
      "202:\tlearn: 0.2831838\ttotal: 7.81s\tremaining: 11.4s\n",
      "203:\tlearn: 0.2818401\ttotal: 7.83s\tremaining: 11.4s\n",
      "204:\tlearn: 0.2807035\ttotal: 7.85s\tremaining: 11.3s\n",
      "205:\tlearn: 0.2795616\ttotal: 7.92s\tremaining: 11.3s\n",
      "206:\tlearn: 0.2785563\ttotal: 7.96s\tremaining: 11.3s\n",
      "207:\tlearn: 0.2777399\ttotal: 7.98s\tremaining: 11.2s\n",
      "208:\tlearn: 0.2767653\ttotal: 8s\tremaining: 11.1s\n",
      "209:\tlearn: 0.2758096\ttotal: 8.04s\tremaining: 11.1s\n",
      "210:\tlearn: 0.2743879\ttotal: 8.1s\tremaining: 11.1s\n",
      "211:\tlearn: 0.2736626\ttotal: 8.14s\tremaining: 11.1s\n",
      "212:\tlearn: 0.2725286\ttotal: 8.16s\tremaining: 11s\n",
      "213:\tlearn: 0.2710302\ttotal: 8.18s\tremaining: 10.9s\n",
      "214:\tlearn: 0.2699230\ttotal: 8.25s\tremaining: 10.9s\n",
      "215:\tlearn: 0.2688794\ttotal: 8.3s\tremaining: 10.9s\n",
      "216:\tlearn: 0.2680425\ttotal: 8.32s\tremaining: 10.9s\n",
      "217:\tlearn: 0.2670041\ttotal: 8.35s\tremaining: 10.8s\n",
      "218:\tlearn: 0.2662008\ttotal: 8.39s\tremaining: 10.8s\n",
      "219:\tlearn: 0.2650304\ttotal: 8.46s\tremaining: 10.8s\n",
      "220:\tlearn: 0.2642383\ttotal: 8.49s\tremaining: 10.7s\n",
      "221:\tlearn: 0.2631088\ttotal: 8.52s\tremaining: 10.7s\n",
      "222:\tlearn: 0.2622728\ttotal: 8.54s\tremaining: 10.6s\n",
      "223:\tlearn: 0.2613942\ttotal: 8.62s\tremaining: 10.6s\n",
      "224:\tlearn: 0.2603392\ttotal: 8.64s\tremaining: 10.6s\n",
      "225:\tlearn: 0.2593299\ttotal: 8.67s\tremaining: 10.5s\n",
      "226:\tlearn: 0.2586278\ttotal: 8.69s\tremaining: 10.4s\n",
      "227:\tlearn: 0.2581237\ttotal: 8.76s\tremaining: 10.4s\n",
      "228:\tlearn: 0.2575326\ttotal: 8.81s\tremaining: 10.4s\n",
      "229:\tlearn: 0.2569571\ttotal: 8.83s\tremaining: 10.4s\n",
      "230:\tlearn: 0.2557999\ttotal: 8.85s\tremaining: 10.3s\n",
      "231:\tlearn: 0.2548958\ttotal: 8.92s\tremaining: 10.3s\n",
      "232:\tlearn: 0.2538570\ttotal: 8.98s\tremaining: 10.3s\n",
      "233:\tlearn: 0.2532192\ttotal: 9s\tremaining: 10.2s\n",
      "234:\tlearn: 0.2517350\ttotal: 9.02s\tremaining: 10.2s\n",
      "235:\tlearn: 0.2509156\ttotal: 9.04s\tremaining: 10.1s\n",
      "236:\tlearn: 0.2502278\ttotal: 9.11s\tremaining: 10.1s\n",
      "237:\tlearn: 0.2492891\ttotal: 9.15s\tremaining: 10.1s\n",
      "238:\tlearn: 0.2482099\ttotal: 9.18s\tremaining: 10s\n",
      "239:\tlearn: 0.2473307\ttotal: 9.2s\tremaining: 9.97s\n",
      "240:\tlearn: 0.2465882\ttotal: 9.22s\tremaining: 9.91s\n",
      "241:\tlearn: 0.2457000\ttotal: 9.28s\tremaining: 9.9s\n",
      "242:\tlearn: 0.2449626\ttotal: 9.31s\tremaining: 9.85s\n",
      "243:\tlearn: 0.2443189\ttotal: 9.34s\tremaining: 9.79s\n",
      "244:\tlearn: 0.2434898\ttotal: 9.36s\tremaining: 9.74s\n",
      "245:\tlearn: 0.2423470\ttotal: 9.41s\tremaining: 9.71s\n",
      "246:\tlearn: 0.2417306\ttotal: 9.46s\tremaining: 9.69s\n",
      "247:\tlearn: 0.2408672\ttotal: 9.48s\tremaining: 9.63s\n",
      "248:\tlearn: 0.2400792\ttotal: 9.5s\tremaining: 9.58s\n",
      "249:\tlearn: 0.2392351\ttotal: 9.57s\tremaining: 9.57s\n",
      "250:\tlearn: 0.2384756\ttotal: 9.62s\tremaining: 9.54s\n",
      "251:\tlearn: 0.2376673\ttotal: 9.65s\tremaining: 9.49s\n",
      "252:\tlearn: 0.2367991\ttotal: 9.67s\tremaining: 9.44s\n",
      "253:\tlearn: 0.2361667\ttotal: 9.69s\tremaining: 9.38s\n",
      "254:\tlearn: 0.2355667\ttotal: 9.76s\tremaining: 9.38s\n",
      "255:\tlearn: 0.2349766\ttotal: 9.81s\tremaining: 9.35s\n",
      "256:\tlearn: 0.2343542\ttotal: 9.83s\tremaining: 9.3s\n",
      "257:\tlearn: 0.2331990\ttotal: 9.85s\tremaining: 9.24s\n",
      "258:\tlearn: 0.2322806\ttotal: 9.91s\tremaining: 9.22s\n",
      "259:\tlearn: 0.2314631\ttotal: 9.96s\tremaining: 9.2s\n",
      "260:\tlearn: 0.2307598\ttotal: 9.99s\tremaining: 9.15s\n",
      "261:\tlearn: 0.2295477\ttotal: 10s\tremaining: 9.09s\n",
      "262:\tlearn: 0.2289271\ttotal: 10s\tremaining: 9.04s\n",
      "263:\tlearn: 0.2278986\ttotal: 10.1s\tremaining: 9s\n",
      "264:\tlearn: 0.2268669\ttotal: 10.1s\tremaining: 8.99s\n",
      "265:\tlearn: 0.2256611\ttotal: 10.2s\tremaining: 8.95s\n",
      "266:\tlearn: 0.2249769\ttotal: 10.2s\tremaining: 8.89s\n",
      "267:\tlearn: 0.2239111\ttotal: 10.2s\tremaining: 8.84s\n",
      "268:\tlearn: 0.2234159\ttotal: 10.3s\tremaining: 8.83s\n",
      "269:\tlearn: 0.2228910\ttotal: 10.3s\tremaining: 8.8s\n",
      "270:\tlearn: 0.2221372\ttotal: 10.4s\tremaining: 8.75s\n",
      "271:\tlearn: 0.2214420\ttotal: 10.4s\tremaining: 8.7s\n",
      "272:\tlearn: 0.2209491\ttotal: 10.4s\tremaining: 8.65s\n",
      "273:\tlearn: 0.2202461\ttotal: 10.5s\tremaining: 8.64s\n",
      "274:\tlearn: 0.2195074\ttotal: 10.5s\tremaining: 8.6s\n",
      "275:\tlearn: 0.2188890\ttotal: 10.5s\tremaining: 8.55s\n",
      "276:\tlearn: 0.2182029\ttotal: 10.6s\tremaining: 8.5s\n",
      "277:\tlearn: 0.2174077\ttotal: 10.6s\tremaining: 8.47s\n",
      "278:\tlearn: 0.2164552\ttotal: 10.7s\tremaining: 8.45s\n",
      "279:\tlearn: 0.2157524\ttotal: 10.7s\tremaining: 8.41s\n",
      "280:\tlearn: 0.2148440\ttotal: 10.7s\tremaining: 8.36s\n",
      "281:\tlearn: 0.2136573\ttotal: 10.7s\tremaining: 8.31s\n",
      "282:\tlearn: 0.2130700\ttotal: 10.8s\tremaining: 8.27s\n",
      "283:\tlearn: 0.2121900\ttotal: 10.9s\tremaining: 8.26s\n",
      "284:\tlearn: 0.2114054\ttotal: 10.9s\tremaining: 8.21s\n",
      "285:\tlearn: 0.2106022\ttotal: 10.9s\tremaining: 8.16s\n",
      "286:\tlearn: 0.2092897\ttotal: 10.9s\tremaining: 8.12s\n",
      "287:\tlearn: 0.2085539\ttotal: 11s\tremaining: 8.1s\n",
      "288:\tlearn: 0.2079800\ttotal: 11s\tremaining: 8.07s\n",
      "289:\tlearn: 0.2074289\ttotal: 11.1s\tremaining: 8.02s\n",
      "290:\tlearn: 0.2067237\ttotal: 11.1s\tremaining: 7.97s\n",
      "291:\tlearn: 0.2060747\ttotal: 11.1s\tremaining: 7.93s\n",
      "292:\tlearn: 0.2054194\ttotal: 11.2s\tremaining: 7.91s\n",
      "293:\tlearn: 0.2042731\ttotal: 11.2s\tremaining: 7.87s\n",
      "294:\tlearn: 0.2034114\ttotal: 11.3s\tremaining: 7.82s\n",
      "295:\tlearn: 0.2027361\ttotal: 11.3s\tremaining: 7.78s\n",
      "296:\tlearn: 0.2023059\ttotal: 11.3s\tremaining: 7.74s\n",
      "297:\tlearn: 0.2018499\ttotal: 11.4s\tremaining: 7.72s\n",
      "298:\tlearn: 0.2011052\ttotal: 11.4s\tremaining: 7.67s\n",
      "299:\tlearn: 0.2004981\ttotal: 11.4s\tremaining: 7.63s\n",
      "300:\tlearn: 0.1998082\ttotal: 11.5s\tremaining: 7.58s\n",
      "301:\tlearn: 0.1991999\ttotal: 11.5s\tremaining: 7.56s\n",
      "302:\tlearn: 0.1984607\ttotal: 11.6s\tremaining: 7.52s\n",
      "303:\tlearn: 0.1977464\ttotal: 11.6s\tremaining: 7.47s\n",
      "304:\tlearn: 0.1971583\ttotal: 11.6s\tremaining: 7.42s\n",
      "305:\tlearn: 0.1963920\ttotal: 11.7s\tremaining: 7.4s\n",
      "306:\tlearn: 0.1957043\ttotal: 11.7s\tremaining: 7.37s\n",
      "307:\tlearn: 0.1951321\ttotal: 11.7s\tremaining: 7.32s\n",
      "308:\tlearn: 0.1944601\ttotal: 11.8s\tremaining: 7.28s\n",
      "309:\tlearn: 0.1937672\ttotal: 11.8s\tremaining: 7.23s\n",
      "310:\tlearn: 0.1933195\ttotal: 11.9s\tremaining: 7.21s\n",
      "311:\tlearn: 0.1925985\ttotal: 11.9s\tremaining: 7.17s\n",
      "312:\tlearn: 0.1917132\ttotal: 11.9s\tremaining: 7.13s\n",
      "313:\tlearn: 0.1908731\ttotal: 12s\tremaining: 7.08s\n",
      "314:\tlearn: 0.1903127\ttotal: 12s\tremaining: 7.04s\n",
      "315:\tlearn: 0.1897046\ttotal: 12.1s\tremaining: 7.02s\n",
      "316:\tlearn: 0.1891149\ttotal: 12.1s\tremaining: 6.98s\n",
      "317:\tlearn: 0.1881765\ttotal: 12.1s\tremaining: 6.94s\n",
      "318:\tlearn: 0.1874240\ttotal: 12.1s\tremaining: 6.89s\n",
      "319:\tlearn: 0.1867562\ttotal: 12.2s\tremaining: 6.86s\n",
      "320:\tlearn: 0.1859633\ttotal: 12.3s\tremaining: 6.84s\n",
      "321:\tlearn: 0.1852158\ttotal: 12.3s\tremaining: 6.79s\n",
      "322:\tlearn: 0.1847201\ttotal: 12.3s\tremaining: 6.75s\n",
      "323:\tlearn: 0.1840721\ttotal: 12.3s\tremaining: 6.7s\n",
      "324:\tlearn: 0.1833236\ttotal: 12.4s\tremaining: 6.67s\n",
      "325:\tlearn: 0.1827717\ttotal: 12.4s\tremaining: 6.64s\n",
      "326:\tlearn: 0.1822189\ttotal: 12.5s\tremaining: 6.6s\n",
      "327:\tlearn: 0.1816411\ttotal: 12.5s\tremaining: 6.55s\n",
      "328:\tlearn: 0.1811186\ttotal: 12.5s\tremaining: 6.51s\n",
      "329:\tlearn: 0.1807692\ttotal: 12.6s\tremaining: 6.49s\n",
      "330:\tlearn: 0.1803081\ttotal: 12.6s\tremaining: 6.45s\n",
      "331:\tlearn: 0.1797880\ttotal: 12.7s\tremaining: 6.4s\n",
      "332:\tlearn: 0.1793518\ttotal: 12.7s\tremaining: 6.36s\n",
      "333:\tlearn: 0.1786049\ttotal: 12.7s\tremaining: 6.32s\n",
      "334:\tlearn: 0.1782535\ttotal: 12.8s\tremaining: 6.29s\n",
      "335:\tlearn: 0.1777016\ttotal: 12.8s\tremaining: 6.25s\n",
      "336:\tlearn: 0.1771554\ttotal: 12.8s\tremaining: 6.21s\n",
      "337:\tlearn: 0.1767015\ttotal: 12.9s\tremaining: 6.16s\n",
      "338:\tlearn: 0.1758355\ttotal: 12.9s\tremaining: 6.13s\n",
      "339:\tlearn: 0.1751839\ttotal: 13s\tremaining: 6.1s\n",
      "340:\tlearn: 0.1746208\ttotal: 13s\tremaining: 6.05s\n",
      "341:\tlearn: 0.1740603\ttotal: 13s\tremaining: 6.01s\n",
      "342:\tlearn: 0.1736176\ttotal: 13.1s\tremaining: 5.99s\n",
      "343:\tlearn: 0.1732060\ttotal: 13.1s\tremaining: 5.95s\n",
      "344:\tlearn: 0.1726871\ttotal: 13.2s\tremaining: 5.91s\n",
      "345:\tlearn: 0.1720635\ttotal: 13.2s\tremaining: 5.86s\n",
      "346:\tlearn: 0.1714452\ttotal: 13.2s\tremaining: 5.82s\n",
      "347:\tlearn: 0.1709296\ttotal: 13.2s\tremaining: 5.77s\n",
      "348:\tlearn: 0.1704031\ttotal: 13.2s\tremaining: 5.73s\n",
      "349:\tlearn: 0.1699116\ttotal: 13.3s\tremaining: 5.71s\n",
      "350:\tlearn: 0.1694363\ttotal: 13.4s\tremaining: 5.67s\n",
      "351:\tlearn: 0.1689133\ttotal: 13.4s\tremaining: 5.64s\n",
      "352:\tlearn: 0.1683039\ttotal: 13.4s\tremaining: 5.6s\n",
      "353:\tlearn: 0.1680110\ttotal: 13.5s\tremaining: 5.55s\n",
      "354:\tlearn: 0.1674001\ttotal: 13.5s\tremaining: 5.52s\n",
      "355:\tlearn: 0.1667038\ttotal: 13.6s\tremaining: 5.49s\n",
      "356:\tlearn: 0.1663357\ttotal: 13.6s\tremaining: 5.44s\n",
      "357:\tlearn: 0.1658544\ttotal: 13.6s\tremaining: 5.41s\n",
      "358:\tlearn: 0.1650224\ttotal: 13.7s\tremaining: 5.37s\n",
      "359:\tlearn: 0.1644962\ttotal: 13.7s\tremaining: 5.33s\n",
      "360:\tlearn: 0.1640551\ttotal: 13.7s\tremaining: 5.28s\n",
      "361:\tlearn: 0.1633677\ttotal: 13.7s\tremaining: 5.24s\n",
      "362:\tlearn: 0.1627353\ttotal: 13.8s\tremaining: 5.19s\n",
      "363:\tlearn: 0.1620481\ttotal: 13.8s\tremaining: 5.15s\n",
      "364:\tlearn: 0.1614165\ttotal: 13.8s\tremaining: 5.11s\n",
      "365:\tlearn: 0.1610256\ttotal: 13.8s\tremaining: 5.07s\n",
      "366:\tlearn: 0.1606177\ttotal: 13.9s\tremaining: 5.03s\n",
      "367:\tlearn: 0.1601298\ttotal: 13.9s\tremaining: 4.98s\n",
      "368:\tlearn: 0.1596354\ttotal: 14s\tremaining: 4.96s\n",
      "369:\tlearn: 0.1591358\ttotal: 14s\tremaining: 4.92s\n",
      "370:\tlearn: 0.1588238\ttotal: 14s\tremaining: 4.87s\n",
      "371:\tlearn: 0.1584127\ttotal: 14s\tremaining: 4.83s\n",
      "372:\tlearn: 0.1577367\ttotal: 14.1s\tremaining: 4.8s\n",
      "373:\tlearn: 0.1573384\ttotal: 14.1s\tremaining: 4.77s\n",
      "374:\tlearn: 0.1568791\ttotal: 14.2s\tremaining: 4.72s\n",
      "375:\tlearn: 0.1563240\ttotal: 14.2s\tremaining: 4.68s\n",
      "376:\tlearn: 0.1558255\ttotal: 14.2s\tremaining: 4.65s\n",
      "377:\tlearn: 0.1552516\ttotal: 14.3s\tremaining: 4.62s\n",
      "378:\tlearn: 0.1549547\ttotal: 14.3s\tremaining: 4.57s\n",
      "379:\tlearn: 0.1545573\ttotal: 14.4s\tremaining: 4.53s\n",
      "380:\tlearn: 0.1541002\ttotal: 14.4s\tremaining: 4.5s\n",
      "381:\tlearn: 0.1534399\ttotal: 14.5s\tremaining: 4.46s\n",
      "382:\tlearn: 0.1530333\ttotal: 14.5s\tremaining: 4.42s\n",
      "383:\tlearn: 0.1522544\ttotal: 14.5s\tremaining: 4.38s\n",
      "384:\tlearn: 0.1516967\ttotal: 14.5s\tremaining: 4.34s\n",
      "385:\tlearn: 0.1512122\ttotal: 14.6s\tremaining: 4.3s\n",
      "386:\tlearn: 0.1504124\ttotal: 14.6s\tremaining: 4.26s\n",
      "387:\tlearn: 0.1499246\ttotal: 14.7s\tremaining: 4.23s\n",
      "388:\tlearn: 0.1494307\ttotal: 14.7s\tremaining: 4.19s\n",
      "389:\tlearn: 0.1490874\ttotal: 14.7s\tremaining: 4.15s\n",
      "390:\tlearn: 0.1487976\ttotal: 14.7s\tremaining: 4.11s\n",
      "391:\tlearn: 0.1483911\ttotal: 14.8s\tremaining: 4.07s\n",
      "392:\tlearn: 0.1478019\ttotal: 14.8s\tremaining: 4.04s\n",
      "393:\tlearn: 0.1473240\ttotal: 14.9s\tremaining: 4s\n",
      "394:\tlearn: 0.1466067\ttotal: 14.9s\tremaining: 3.96s\n",
      "395:\tlearn: 0.1462091\ttotal: 14.9s\tremaining: 3.92s\n",
      "396:\tlearn: 0.1457859\ttotal: 15s\tremaining: 3.89s\n",
      "397:\tlearn: 0.1456063\ttotal: 15s\tremaining: 3.85s\n",
      "398:\tlearn: 0.1451913\ttotal: 15s\tremaining: 3.81s\n",
      "399:\tlearn: 0.1446376\ttotal: 15.1s\tremaining: 3.77s\n",
      "400:\tlearn: 0.1442311\ttotal: 15.1s\tremaining: 3.73s\n",
      "401:\tlearn: 0.1434783\ttotal: 15.2s\tremaining: 3.7s\n",
      "402:\tlearn: 0.1431438\ttotal: 15.2s\tremaining: 3.66s\n",
      "403:\tlearn: 0.1425801\ttotal: 15.2s\tremaining: 3.62s\n",
      "404:\tlearn: 0.1421489\ttotal: 15.2s\tremaining: 3.58s\n",
      "405:\tlearn: 0.1417325\ttotal: 15.3s\tremaining: 3.55s\n",
      "406:\tlearn: 0.1411262\ttotal: 15.4s\tremaining: 3.51s\n",
      "407:\tlearn: 0.1406279\ttotal: 15.4s\tremaining: 3.47s\n",
      "408:\tlearn: 0.1402762\ttotal: 15.4s\tremaining: 3.43s\n",
      "409:\tlearn: 0.1398033\ttotal: 15.5s\tremaining: 3.4s\n",
      "410:\tlearn: 0.1394932\ttotal: 15.5s\tremaining: 3.37s\n",
      "411:\tlearn: 0.1391976\ttotal: 15.6s\tremaining: 3.33s\n",
      "412:\tlearn: 0.1389153\ttotal: 15.6s\tremaining: 3.28s\n",
      "413:\tlearn: 0.1383969\ttotal: 15.6s\tremaining: 3.24s\n",
      "414:\tlearn: 0.1378824\ttotal: 15.7s\tremaining: 3.21s\n",
      "415:\tlearn: 0.1373824\ttotal: 15.7s\tremaining: 3.17s\n",
      "416:\tlearn: 0.1369139\ttotal: 15.8s\tremaining: 3.13s\n",
      "417:\tlearn: 0.1365035\ttotal: 15.8s\tremaining: 3.09s\n",
      "418:\tlearn: 0.1361341\ttotal: 15.8s\tremaining: 3.06s\n",
      "419:\tlearn: 0.1358186\ttotal: 15.9s\tremaining: 3.02s\n",
      "420:\tlearn: 0.1354559\ttotal: 15.9s\tremaining: 2.98s\n",
      "421:\tlearn: 0.1351334\ttotal: 15.9s\tremaining: 2.94s\n",
      "422:\tlearn: 0.1347349\ttotal: 16s\tremaining: 2.91s\n",
      "423:\tlearn: 0.1344311\ttotal: 16s\tremaining: 2.88s\n",
      "424:\tlearn: 0.1339509\ttotal: 16.1s\tremaining: 2.83s\n",
      "425:\tlearn: 0.1335110\ttotal: 16.1s\tremaining: 2.79s\n",
      "426:\tlearn: 0.1331235\ttotal: 16.1s\tremaining: 2.76s\n",
      "427:\tlearn: 0.1328382\ttotal: 16.2s\tremaining: 2.72s\n",
      "428:\tlearn: 0.1324545\ttotal: 16.2s\tremaining: 2.69s\n",
      "429:\tlearn: 0.1321286\ttotal: 16.3s\tremaining: 2.65s\n",
      "430:\tlearn: 0.1317763\ttotal: 16.3s\tremaining: 2.6s\n",
      "431:\tlearn: 0.1311689\ttotal: 16.3s\tremaining: 2.57s\n",
      "432:\tlearn: 0.1306198\ttotal: 16.4s\tremaining: 2.53s\n",
      "433:\tlearn: 0.1302149\ttotal: 16.4s\tremaining: 2.5s\n",
      "434:\tlearn: 0.1299872\ttotal: 16.4s\tremaining: 2.46s\n",
      "435:\tlearn: 0.1296654\ttotal: 16.5s\tremaining: 2.42s\n",
      "436:\tlearn: 0.1292977\ttotal: 16.5s\tremaining: 2.38s\n",
      "437:\tlearn: 0.1289159\ttotal: 16.6s\tremaining: 2.35s\n",
      "438:\tlearn: 0.1285454\ttotal: 16.6s\tremaining: 2.31s\n",
      "439:\tlearn: 0.1280877\ttotal: 16.6s\tremaining: 2.27s\n",
      "440:\tlearn: 0.1277029\ttotal: 16.6s\tremaining: 2.23s\n",
      "441:\tlearn: 0.1273600\ttotal: 16.7s\tremaining: 2.19s\n",
      "442:\tlearn: 0.1268530\ttotal: 16.8s\tremaining: 2.15s\n",
      "443:\tlearn: 0.1263677\ttotal: 16.8s\tremaining: 2.12s\n",
      "444:\tlearn: 0.1259998\ttotal: 16.8s\tremaining: 2.08s\n",
      "445:\tlearn: 0.1254255\ttotal: 16.8s\tremaining: 2.04s\n",
      "446:\tlearn: 0.1251045\ttotal: 16.9s\tremaining: 2s\n",
      "447:\tlearn: 0.1248829\ttotal: 16.9s\tremaining: 1.96s\n",
      "448:\tlearn: 0.1245608\ttotal: 17s\tremaining: 1.93s\n",
      "449:\tlearn: 0.1240927\ttotal: 17s\tremaining: 1.89s\n",
      "450:\tlearn: 0.1237187\ttotal: 17s\tremaining: 1.85s\n",
      "451:\tlearn: 0.1232683\ttotal: 17.1s\tremaining: 1.81s\n",
      "452:\tlearn: 0.1228547\ttotal: 17.1s\tremaining: 1.77s\n",
      "453:\tlearn: 0.1226246\ttotal: 17.1s\tremaining: 1.74s\n",
      "454:\tlearn: 0.1222040\ttotal: 17.2s\tremaining: 1.7s\n",
      "455:\tlearn: 0.1218280\ttotal: 17.2s\tremaining: 1.66s\n",
      "456:\tlearn: 0.1214259\ttotal: 17.3s\tremaining: 1.62s\n",
      "457:\tlearn: 0.1209787\ttotal: 17.3s\tremaining: 1.58s\n",
      "458:\tlearn: 0.1206733\ttotal: 17.4s\tremaining: 1.55s\n",
      "459:\tlearn: 0.1204373\ttotal: 17.4s\tremaining: 1.51s\n",
      "460:\tlearn: 0.1201477\ttotal: 17.4s\tremaining: 1.47s\n",
      "461:\tlearn: 0.1198174\ttotal: 17.4s\tremaining: 1.43s\n",
      "462:\tlearn: 0.1194412\ttotal: 17.5s\tremaining: 1.4s\n",
      "463:\tlearn: 0.1188724\ttotal: 17.6s\tremaining: 1.36s\n",
      "464:\tlearn: 0.1185952\ttotal: 17.6s\tremaining: 1.32s\n",
      "465:\tlearn: 0.1182839\ttotal: 17.6s\tremaining: 1.28s\n",
      "466:\tlearn: 0.1180111\ttotal: 17.6s\tremaining: 1.25s\n",
      "467:\tlearn: 0.1178408\ttotal: 17.7s\tremaining: 1.21s\n",
      "468:\tlearn: 0.1175489\ttotal: 17.7s\tremaining: 1.17s\n",
      "469:\tlearn: 0.1171579\ttotal: 17.8s\tremaining: 1.13s\n",
      "470:\tlearn: 0.1168541\ttotal: 17.8s\tremaining: 1.09s\n",
      "471:\tlearn: 0.1165123\ttotal: 17.8s\tremaining: 1.06s\n",
      "472:\tlearn: 0.1162096\ttotal: 17.9s\tremaining: 1.02s\n",
      "473:\tlearn: 0.1159756\ttotal: 17.9s\tremaining: 983ms\n",
      "474:\tlearn: 0.1155484\ttotal: 17.9s\tremaining: 945ms\n",
      "475:\tlearn: 0.1149847\ttotal: 18s\tremaining: 906ms\n",
      "476:\tlearn: 0.1145310\ttotal: 18s\tremaining: 869ms\n",
      "477:\tlearn: 0.1141564\ttotal: 18.1s\tremaining: 832ms\n",
      "478:\tlearn: 0.1135791\ttotal: 18.1s\tremaining: 794ms\n",
      "479:\tlearn: 0.1131559\ttotal: 18.1s\tremaining: 756ms\n",
      "480:\tlearn: 0.1128632\ttotal: 18.2s\tremaining: 717ms\n",
      "481:\tlearn: 0.1125495\ttotal: 18.2s\tremaining: 681ms\n",
      "482:\tlearn: 0.1122252\ttotal: 18.3s\tremaining: 643ms\n",
      "483:\tlearn: 0.1116900\ttotal: 18.3s\tremaining: 606ms\n",
      "484:\tlearn: 0.1115015\ttotal: 18.4s\tremaining: 568ms\n",
      "485:\tlearn: 0.1112974\ttotal: 18.4s\tremaining: 530ms\n",
      "486:\tlearn: 0.1108405\ttotal: 18.4s\tremaining: 492ms\n",
      "487:\tlearn: 0.1104734\ttotal: 18.4s\tremaining: 454ms\n",
      "488:\tlearn: 0.1100480\ttotal: 18.5s\tremaining: 417ms\n",
      "489:\tlearn: 0.1097205\ttotal: 18.6s\tremaining: 379ms\n",
      "490:\tlearn: 0.1094716\ttotal: 18.6s\tremaining: 341ms\n",
      "491:\tlearn: 0.1092174\ttotal: 18.6s\tremaining: 303ms\n",
      "492:\tlearn: 0.1088630\ttotal: 18.6s\tremaining: 265ms\n",
      "493:\tlearn: 0.1085959\ttotal: 18.7s\tremaining: 227ms\n",
      "494:\tlearn: 0.1081491\ttotal: 18.7s\tremaining: 189ms\n",
      "495:\tlearn: 0.1077316\ttotal: 18.8s\tremaining: 151ms\n",
      "496:\tlearn: 0.1073420\ttotal: 18.8s\tremaining: 113ms\n",
      "497:\tlearn: 0.1069886\ttotal: 18.8s\tremaining: 75.7ms\n",
      "498:\tlearn: 0.1066723\ttotal: 18.9s\tremaining: 37.9ms\n",
      "499:\tlearn: 0.1062263\ttotal: 18.9s\tremaining: 0us\n",
      "0:\tlearn: 0.6491456\ttotal: 52.7ms\tremaining: 26.3s\n",
      "1:\tlearn: 0.6092273\ttotal: 154ms\tremaining: 38.5s\n",
      "2:\tlearn: 0.5665969\ttotal: 203ms\tremaining: 33.6s\n",
      "3:\tlearn: 0.5328385\ttotal: 305ms\tremaining: 37.8s\n",
      "4:\tlearn: 0.5069668\ttotal: 388ms\tremaining: 38.4s\n",
      "5:\tlearn: 0.4722739\ttotal: 464ms\tremaining: 38.2s\n",
      "6:\tlearn: 0.4417808\ttotal: 509ms\tremaining: 35.8s\n",
      "7:\tlearn: 0.4172719\ttotal: 607ms\tremaining: 37.3s\n",
      "8:\tlearn: 0.3863159\ttotal: 652ms\tremaining: 35.6s\n",
      "9:\tlearn: 0.3691644\ttotal: 765ms\tremaining: 37.5s\n",
      "10:\tlearn: 0.3522050\ttotal: 822ms\tremaining: 36.5s\n",
      "11:\tlearn: 0.3360410\ttotal: 912ms\tremaining: 37.1s\n",
      "12:\tlearn: 0.3246648\ttotal: 990ms\tremaining: 37.1s\n",
      "13:\tlearn: 0.3097414\ttotal: 1.05s\tremaining: 36.3s\n",
      "14:\tlearn: 0.2946965\ttotal: 1.15s\tremaining: 37.3s\n",
      "15:\tlearn: 0.2819231\ttotal: 1.2s\tremaining: 36.2s\n",
      "16:\tlearn: 0.2675865\ttotal: 1.3s\tremaining: 37s\n",
      "17:\tlearn: 0.2571883\ttotal: 1.35s\tremaining: 36.1s\n",
      "18:\tlearn: 0.2494237\ttotal: 1.45s\tremaining: 36.8s\n",
      "19:\tlearn: 0.2382659\ttotal: 1.51s\tremaining: 36.2s\n",
      "20:\tlearn: 0.2272632\ttotal: 1.57s\tremaining: 35.9s\n",
      "21:\tlearn: 0.2146416\ttotal: 1.67s\tremaining: 36.2s\n",
      "22:\tlearn: 0.2068261\ttotal: 1.71s\tremaining: 35.4s\n",
      "23:\tlearn: 0.1966513\ttotal: 1.83s\tremaining: 36.3s\n",
      "24:\tlearn: 0.1896403\ttotal: 1.88s\tremaining: 35.6s\n",
      "25:\tlearn: 0.1822320\ttotal: 1.99s\tremaining: 36.3s\n",
      "26:\tlearn: 0.1740261\ttotal: 2.04s\tremaining: 35.8s\n",
      "27:\tlearn: 0.1675218\ttotal: 2.14s\tremaining: 36s\n",
      "28:\tlearn: 0.1561658\ttotal: 2.21s\tremaining: 36s\n",
      "29:\tlearn: 0.1504974\ttotal: 2.25s\tremaining: 35.3s\n",
      "30:\tlearn: 0.1466481\ttotal: 2.37s\tremaining: 35.8s\n",
      "31:\tlearn: 0.1402797\ttotal: 2.42s\tremaining: 35.3s\n",
      "32:\tlearn: 0.1324450\ttotal: 2.53s\tremaining: 35.7s\n",
      "33:\tlearn: 0.1273180\ttotal: 2.58s\tremaining: 35.3s\n",
      "34:\tlearn: 0.1209276\ttotal: 2.67s\tremaining: 35.5s\n",
      "35:\tlearn: 0.1161394\ttotal: 2.73s\tremaining: 35.2s\n",
      "36:\tlearn: 0.1094522\ttotal: 2.82s\tremaining: 35.3s\n",
      "37:\tlearn: 0.1049366\ttotal: 2.89s\tremaining: 35.2s\n",
      "38:\tlearn: 0.1015007\ttotal: 2.94s\tremaining: 34.8s\n",
      "39:\tlearn: 0.0981810\ttotal: 3.06s\tremaining: 35.1s\n",
      "40:\tlearn: 0.0938330\ttotal: 3.1s\tremaining: 34.7s\n",
      "41:\tlearn: 0.0905169\ttotal: 3.2s\tremaining: 34.9s\n",
      "42:\tlearn: 0.0868523\ttotal: 3.25s\tremaining: 34.6s\n",
      "43:\tlearn: 0.0842778\ttotal: 3.3s\tremaining: 34.2s\n",
      "44:\tlearn: 0.0825771\ttotal: 3.41s\tremaining: 34.5s\n",
      "45:\tlearn: 0.0798119\ttotal: 3.46s\tremaining: 34.1s\n",
      "46:\tlearn: 0.0767319\ttotal: 3.58s\tremaining: 34.5s\n",
      "47:\tlearn: 0.0748904\ttotal: 3.63s\tremaining: 34.2s\n",
      "48:\tlearn: 0.0731434\ttotal: 3.74s\tremaining: 34.4s\n",
      "49:\tlearn: 0.0707266\ttotal: 3.81s\tremaining: 34.3s\n",
      "50:\tlearn: 0.0682460\ttotal: 3.92s\tremaining: 34.5s\n",
      "51:\tlearn: 0.0661931\ttotal: 3.98s\tremaining: 34.2s\n",
      "52:\tlearn: 0.0646287\ttotal: 4.02s\tremaining: 33.9s\n",
      "53:\tlearn: 0.0623425\ttotal: 4.13s\tremaining: 34.1s\n",
      "54:\tlearn: 0.0600761\ttotal: 4.18s\tremaining: 33.8s\n",
      "55:\tlearn: 0.0573744\ttotal: 4.29s\tremaining: 34s\n",
      "56:\tlearn: 0.0557881\ttotal: 4.34s\tremaining: 33.7s\n",
      "57:\tlearn: 0.0546867\ttotal: 4.43s\tremaining: 33.7s\n",
      "58:\tlearn: 0.0522500\ttotal: 4.49s\tremaining: 33.6s\n",
      "59:\tlearn: 0.0507554\ttotal: 4.64s\tremaining: 34s\n",
      "60:\tlearn: 0.0496545\ttotal: 4.68s\tremaining: 33.7s\n",
      "61:\tlearn: 0.0482024\ttotal: 4.79s\tremaining: 33.8s\n",
      "62:\tlearn: 0.0466957\ttotal: 4.83s\tremaining: 33.5s\n",
      "63:\tlearn: 0.0453726\ttotal: 4.91s\tremaining: 33.4s\n",
      "64:\tlearn: 0.0432541\ttotal: 4.96s\tremaining: 33.2s\n",
      "65:\tlearn: 0.0423403\ttotal: 5.01s\tremaining: 32.9s\n",
      "66:\tlearn: 0.0414168\ttotal: 5.1s\tremaining: 33s\n",
      "67:\tlearn: 0.0403302\ttotal: 5.17s\tremaining: 32.8s\n",
      "68:\tlearn: 0.0388279\ttotal: 5.21s\tremaining: 32.5s\n",
      "69:\tlearn: 0.0378166\ttotal: 5.33s\tremaining: 32.7s\n",
      "70:\tlearn: 0.0369586\ttotal: 5.37s\tremaining: 32.4s\n",
      "71:\tlearn: 0.0357025\ttotal: 5.47s\tremaining: 32.5s\n",
      "72:\tlearn: 0.0344827\ttotal: 5.52s\tremaining: 32.3s\n",
      "73:\tlearn: 0.0330835\ttotal: 5.64s\tremaining: 32.5s\n",
      "74:\tlearn: 0.0326356\ttotal: 5.69s\tremaining: 32.3s\n",
      "75:\tlearn: 0.0320736\ttotal: 5.78s\tremaining: 32.3s\n",
      "76:\tlearn: 0.0311514\ttotal: 5.85s\tremaining: 32.1s\n",
      "77:\tlearn: 0.0300774\ttotal: 5.9s\tremaining: 31.9s\n",
      "78:\tlearn: 0.0293923\ttotal: 6.01s\tremaining: 32s\n",
      "79:\tlearn: 0.0289813\ttotal: 6.05s\tremaining: 31.8s\n",
      "80:\tlearn: 0.0285673\ttotal: 6.17s\tremaining: 31.9s\n",
      "81:\tlearn: 0.0276042\ttotal: 6.23s\tremaining: 31.7s\n",
      "82:\tlearn: 0.0268541\ttotal: 6.34s\tremaining: 31.8s\n",
      "83:\tlearn: 0.0262358\ttotal: 6.39s\tremaining: 31.7s\n",
      "84:\tlearn: 0.0253520\ttotal: 6.44s\tremaining: 31.4s\n",
      "85:\tlearn: 0.0245236\ttotal: 6.55s\tremaining: 31.5s\n",
      "86:\tlearn: 0.0236340\ttotal: 6.59s\tremaining: 31.3s\n",
      "87:\tlearn: 0.0230511\ttotal: 6.71s\tremaining: 31.4s\n",
      "88:\tlearn: 0.0226112\ttotal: 6.76s\tremaining: 31.2s\n",
      "89:\tlearn: 0.0218449\ttotal: 6.87s\tremaining: 31.3s\n",
      "90:\tlearn: 0.0212550\ttotal: 6.93s\tremaining: 31.2s\n",
      "91:\tlearn: 0.0206175\ttotal: 6.99s\tremaining: 31s\n",
      "92:\tlearn: 0.0201251\ttotal: 7.09s\tremaining: 31s\n",
      "93:\tlearn: 0.0196309\ttotal: 7.14s\tremaining: 30.8s\n",
      "94:\tlearn: 0.0190557\ttotal: 7.24s\tremaining: 30.9s\n",
      "95:\tlearn: 0.0183349\ttotal: 7.28s\tremaining: 30.6s\n",
      "96:\tlearn: 0.0179279\ttotal: 7.4s\tremaining: 30.7s\n",
      "97:\tlearn: 0.0174216\ttotal: 7.45s\tremaining: 30.6s\n",
      "98:\tlearn: 0.0170063\ttotal: 7.56s\tremaining: 30.6s\n",
      "99:\tlearn: 0.0166088\ttotal: 7.62s\tremaining: 30.5s\n",
      "100:\tlearn: 0.0160946\ttotal: 7.69s\tremaining: 30.4s\n",
      "101:\tlearn: 0.0157408\ttotal: 7.78s\tremaining: 30.4s\n",
      "102:\tlearn: 0.0153899\ttotal: 7.83s\tremaining: 30.2s\n",
      "103:\tlearn: 0.0151256\ttotal: 7.95s\tremaining: 30.3s\n",
      "104:\tlearn: 0.0148768\ttotal: 7.99s\tremaining: 30.1s\n",
      "105:\tlearn: 0.0144776\ttotal: 8.11s\tremaining: 30.1s\n",
      "106:\tlearn: 0.0142227\ttotal: 8.16s\tremaining: 30s\n",
      "107:\tlearn: 0.0139406\ttotal: 8.25s\tremaining: 29.9s\n",
      "108:\tlearn: 0.0135131\ttotal: 8.32s\tremaining: 29.8s\n",
      "109:\tlearn: 0.0132183\ttotal: 8.37s\tremaining: 29.7s\n",
      "110:\tlearn: 0.0129504\ttotal: 8.48s\tremaining: 29.7s\n",
      "111:\tlearn: 0.0126440\ttotal: 8.53s\tremaining: 29.5s\n",
      "112:\tlearn: 0.0123205\ttotal: 8.64s\tremaining: 29.6s\n",
      "113:\tlearn: 0.0120456\ttotal: 8.69s\tremaining: 29.4s\n",
      "114:\tlearn: 0.0117849\ttotal: 8.79s\tremaining: 29.4s\n",
      "115:\tlearn: 0.0115923\ttotal: 8.86s\tremaining: 29.3s\n",
      "116:\tlearn: 0.0113460\ttotal: 8.9s\tremaining: 29.1s\n",
      "117:\tlearn: 0.0111697\ttotal: 8.94s\tremaining: 28.9s\n",
      "118:\tlearn: 0.0108917\ttotal: 9.05s\tremaining: 29s\n",
      "119:\tlearn: 0.0107247\ttotal: 9.09s\tremaining: 28.8s\n",
      "120:\tlearn: 0.0105335\ttotal: 9.14s\tremaining: 28.6s\n",
      "121:\tlearn: 0.0103498\ttotal: 9.25s\tremaining: 28.7s\n",
      "122:\tlearn: 0.0101131\ttotal: 9.3s\tremaining: 28.5s\n",
      "123:\tlearn: 0.0098544\ttotal: 9.42s\tremaining: 28.6s\n",
      "124:\tlearn: 0.0097193\ttotal: 9.47s\tremaining: 28.4s\n",
      "125:\tlearn: 0.0095204\ttotal: 9.59s\tremaining: 28.5s\n",
      "126:\tlearn: 0.0093640\ttotal: 9.65s\tremaining: 28.3s\n",
      "127:\tlearn: 0.0091854\ttotal: 9.69s\tremaining: 28.1s\n",
      "128:\tlearn: 0.0090137\ttotal: 9.8s\tremaining: 28.2s\n",
      "129:\tlearn: 0.0088767\ttotal: 9.84s\tremaining: 28s\n",
      "130:\tlearn: 0.0086974\ttotal: 9.95s\tremaining: 28s\n",
      "131:\tlearn: 0.0085614\ttotal: 10s\tremaining: 27.9s\n",
      "132:\tlearn: 0.0084226\ttotal: 10.1s\tremaining: 27.8s\n",
      "133:\tlearn: 0.0082681\ttotal: 10.2s\tremaining: 27.8s\n",
      "134:\tlearn: 0.0081423\ttotal: 10.2s\tremaining: 27.7s\n",
      "135:\tlearn: 0.0080092\ttotal: 10.3s\tremaining: 27.7s\n",
      "136:\tlearn: 0.0078801\ttotal: 10.4s\tremaining: 27.5s\n",
      "137:\tlearn: 0.0077399\ttotal: 10.5s\tremaining: 27.5s\n",
      "138:\tlearn: 0.0076106\ttotal: 10.6s\tremaining: 27.4s\n",
      "139:\tlearn: 0.0074731\ttotal: 10.6s\tremaining: 27.4s\n",
      "140:\tlearn: 0.0073841\ttotal: 10.7s\tremaining: 27.2s\n",
      "141:\tlearn: 0.0072357\ttotal: 10.8s\tremaining: 27.2s\n",
      "142:\tlearn: 0.0071291\ttotal: 10.8s\tremaining: 27.1s\n",
      "143:\tlearn: 0.0070022\ttotal: 10.9s\tremaining: 27s\n",
      "144:\tlearn: 0.0069023\ttotal: 11s\tremaining: 26.9s\n",
      "145:\tlearn: 0.0067718\ttotal: 11s\tremaining: 26.8s\n",
      "146:\tlearn: 0.0066586\ttotal: 11.2s\tremaining: 26.8s\n",
      "147:\tlearn: 0.0065457\ttotal: 11.2s\tremaining: 26.7s\n",
      "148:\tlearn: 0.0064558\ttotal: 11.3s\tremaining: 26.6s\n",
      "149:\tlearn: 0.0063789\ttotal: 11.4s\tremaining: 26.5s\n",
      "150:\tlearn: 0.0062747\ttotal: 11.4s\tremaining: 26.3s\n",
      "151:\tlearn: 0.0061905\ttotal: 11.5s\tremaining: 26.4s\n",
      "152:\tlearn: 0.0061089\ttotal: 11.6s\tremaining: 26.2s\n",
      "153:\tlearn: 0.0060285\ttotal: 11.7s\tremaining: 26.2s\n",
      "154:\tlearn: 0.0059361\ttotal: 11.7s\tremaining: 26.1s\n",
      "155:\tlearn: 0.0058742\ttotal: 11.8s\tremaining: 26.1s\n",
      "156:\tlearn: 0.0058074\ttotal: 11.9s\tremaining: 25.9s\n",
      "157:\tlearn: 0.0057319\ttotal: 11.9s\tremaining: 25.8s\n",
      "158:\tlearn: 0.0056695\ttotal: 12s\tremaining: 25.8s\n",
      "159:\tlearn: 0.0056092\ttotal: 12.1s\tremaining: 25.7s\n",
      "160:\tlearn: 0.0055257\ttotal: 12.2s\tremaining: 25.7s\n",
      "161:\tlearn: 0.0054737\ttotal: 12.2s\tremaining: 25.5s\n",
      "162:\tlearn: 0.0054027\ttotal: 12.4s\tremaining: 25.6s\n",
      "163:\tlearn: 0.0053258\ttotal: 12.4s\tremaining: 25.4s\n",
      "164:\tlearn: 0.0052564\ttotal: 12.5s\tremaining: 25.4s\n",
      "165:\tlearn: 0.0051767\ttotal: 12.6s\tremaining: 25.3s\n",
      "166:\tlearn: 0.0051168\ttotal: 12.6s\tremaining: 25.2s\n",
      "167:\tlearn: 0.0050354\ttotal: 12.8s\tremaining: 25.2s\n",
      "168:\tlearn: 0.0049668\ttotal: 12.8s\tremaining: 25.1s\n",
      "169:\tlearn: 0.0048941\ttotal: 12.9s\tremaining: 25.1s\n",
      "170:\tlearn: 0.0048277\ttotal: 13s\tremaining: 24.9s\n",
      "171:\tlearn: 0.0047826\ttotal: 13s\tremaining: 24.8s\n",
      "172:\tlearn: 0.0047300\ttotal: 13.1s\tremaining: 24.8s\n",
      "173:\tlearn: 0.0046817\ttotal: 13.2s\tremaining: 24.7s\n",
      "174:\tlearn: 0.0046381\ttotal: 13.3s\tremaining: 24.7s\n",
      "175:\tlearn: 0.0045928\ttotal: 13.3s\tremaining: 24.5s\n",
      "176:\tlearn: 0.0045426\ttotal: 13.4s\tremaining: 24.4s\n",
      "177:\tlearn: 0.0045077\ttotal: 13.5s\tremaining: 24.4s\n",
      "178:\tlearn: 0.0044650\ttotal: 13.5s\tremaining: 24.3s\n",
      "179:\tlearn: 0.0044305\ttotal: 13.6s\tremaining: 24.2s\n",
      "180:\tlearn: 0.0043840\ttotal: 13.7s\tremaining: 24.1s\n",
      "181:\tlearn: 0.0043205\ttotal: 13.8s\tremaining: 24.1s\n",
      "182:\tlearn: 0.0042738\ttotal: 13.9s\tremaining: 24s\n",
      "183:\tlearn: 0.0042081\ttotal: 13.9s\tremaining: 23.9s\n",
      "184:\tlearn: 0.0041803\ttotal: 14s\tremaining: 23.9s\n",
      "185:\tlearn: 0.0041370\ttotal: 14.1s\tremaining: 23.7s\n",
      "186:\tlearn: 0.0040984\ttotal: 14.2s\tremaining: 23.7s\n",
      "187:\tlearn: 0.0040451\ttotal: 14.2s\tremaining: 23.6s\n",
      "188:\tlearn: 0.0040174\ttotal: 14.3s\tremaining: 23.5s\n",
      "189:\tlearn: 0.0039783\ttotal: 14.4s\tremaining: 23.5s\n",
      "190:\tlearn: 0.0039360\ttotal: 14.4s\tremaining: 23.3s\n",
      "191:\tlearn: 0.0038835\ttotal: 14.5s\tremaining: 23.3s\n",
      "192:\tlearn: 0.0038484\ttotal: 14.6s\tremaining: 23.2s\n",
      "193:\tlearn: 0.0038070\ttotal: 14.7s\tremaining: 23.2s\n",
      "194:\tlearn: 0.0037724\ttotal: 14.8s\tremaining: 23.1s\n",
      "195:\tlearn: 0.0037327\ttotal: 14.8s\tremaining: 23s\n",
      "196:\tlearn: 0.0036883\ttotal: 15s\tremaining: 23s\n",
      "197:\tlearn: 0.0036654\ttotal: 15s\tremaining: 22.9s\n",
      "198:\tlearn: 0.0036260\ttotal: 15.1s\tremaining: 22.9s\n",
      "199:\tlearn: 0.0035956\ttotal: 15.2s\tremaining: 22.8s\n",
      "200:\tlearn: 0.0035591\ttotal: 15.3s\tremaining: 22.7s\n",
      "201:\tlearn: 0.0035160\ttotal: 15.4s\tremaining: 22.7s\n",
      "202:\tlearn: 0.0034846\ttotal: 15.4s\tremaining: 22.6s\n",
      "203:\tlearn: 0.0034485\ttotal: 15.5s\tremaining: 22.5s\n",
      "204:\tlearn: 0.0034199\ttotal: 15.6s\tremaining: 22.4s\n",
      "205:\tlearn: 0.0033936\ttotal: 15.6s\tremaining: 22.3s\n",
      "206:\tlearn: 0.0033657\ttotal: 15.7s\tremaining: 22.3s\n",
      "207:\tlearn: 0.0033437\ttotal: 15.8s\tremaining: 22.2s\n",
      "208:\tlearn: 0.0033177\ttotal: 15.9s\tremaining: 22.1s\n",
      "209:\tlearn: 0.0033177\ttotal: 15.9s\tremaining: 22s\n",
      "210:\tlearn: 0.0032964\ttotal: 16s\tremaining: 22s\n",
      "211:\tlearn: 0.0032586\ttotal: 16.1s\tremaining: 21.9s\n",
      "212:\tlearn: 0.0032287\ttotal: 16.2s\tremaining: 21.8s\n",
      "213:\tlearn: 0.0032002\ttotal: 16.2s\tremaining: 21.7s\n",
      "214:\tlearn: 0.0031763\ttotal: 16.3s\tremaining: 21.7s\n",
      "215:\tlearn: 0.0031482\ttotal: 16.4s\tremaining: 21.5s\n",
      "216:\tlearn: 0.0031250\ttotal: 16.5s\tremaining: 21.5s\n",
      "217:\tlearn: 0.0031031\ttotal: 16.6s\tremaining: 21.4s\n",
      "218:\tlearn: 0.0030699\ttotal: 16.6s\tremaining: 21.3s\n",
      "219:\tlearn: 0.0030474\ttotal: 16.7s\tremaining: 21.3s\n",
      "220:\tlearn: 0.0030474\ttotal: 16.8s\tremaining: 21.2s\n",
      "221:\tlearn: 0.0030224\ttotal: 16.9s\tremaining: 21.1s\n",
      "222:\tlearn: 0.0029939\ttotal: 16.9s\tremaining: 21s\n",
      "223:\tlearn: 0.0029694\ttotal: 17s\tremaining: 21s\n",
      "224:\tlearn: 0.0029486\ttotal: 17.1s\tremaining: 20.9s\n",
      "225:\tlearn: 0.0029245\ttotal: 17.2s\tremaining: 20.8s\n",
      "226:\tlearn: 0.0028945\ttotal: 17.3s\tremaining: 20.7s\n",
      "227:\tlearn: 0.0028762\ttotal: 17.3s\tremaining: 20.6s\n",
      "228:\tlearn: 0.0028555\ttotal: 17.4s\tremaining: 20.6s\n",
      "229:\tlearn: 0.0028346\ttotal: 17.5s\tremaining: 20.5s\n",
      "230:\tlearn: 0.0028144\ttotal: 17.6s\tremaining: 20.5s\n",
      "231:\tlearn: 0.0028143\ttotal: 17.6s\tremaining: 20.4s\n",
      "232:\tlearn: 0.0027873\ttotal: 17.8s\tremaining: 20.3s\n",
      "233:\tlearn: 0.0027676\ttotal: 17.8s\tremaining: 20.2s\n",
      "234:\tlearn: 0.0027394\ttotal: 17.9s\tremaining: 20.2s\n",
      "235:\tlearn: 0.0027394\ttotal: 18s\tremaining: 20.1s\n",
      "236:\tlearn: 0.0027169\ttotal: 18.1s\tremaining: 20s\n",
      "237:\tlearn: 0.0027166\ttotal: 18.1s\tremaining: 20s\n",
      "238:\tlearn: 0.0026971\ttotal: 18.2s\tremaining: 19.9s\n",
      "239:\tlearn: 0.0026770\ttotal: 18.3s\tremaining: 19.8s\n",
      "240:\tlearn: 0.0026545\ttotal: 18.3s\tremaining: 19.7s\n",
      "241:\tlearn: 0.0026331\ttotal: 18.4s\tremaining: 19.6s\n",
      "242:\tlearn: 0.0026140\ttotal: 18.5s\tremaining: 19.5s\n",
      "243:\tlearn: 0.0025918\ttotal: 18.5s\tremaining: 19.5s\n",
      "244:\tlearn: 0.0025917\ttotal: 18.6s\tremaining: 19.3s\n",
      "245:\tlearn: 0.0025734\ttotal: 18.7s\tremaining: 19.3s\n",
      "246:\tlearn: 0.0025734\ttotal: 18.8s\tremaining: 19.2s\n",
      "247:\tlearn: 0.0025734\ttotal: 18.9s\tremaining: 19.2s\n",
      "248:\tlearn: 0.0025734\ttotal: 18.9s\tremaining: 19.1s\n",
      "249:\tlearn: 0.0025734\ttotal: 19s\tremaining: 19s\n",
      "250:\tlearn: 0.0025734\ttotal: 19.1s\tremaining: 18.9s\n",
      "251:\tlearn: 0.0025540\ttotal: 19.1s\tremaining: 18.8s\n",
      "252:\tlearn: 0.0025540\ttotal: 19.2s\tremaining: 18.8s\n",
      "253:\tlearn: 0.0025539\ttotal: 19.3s\tremaining: 18.7s\n",
      "254:\tlearn: 0.0025363\ttotal: 19.4s\tremaining: 18.6s\n",
      "255:\tlearn: 0.0025363\ttotal: 19.4s\tremaining: 18.5s\n",
      "256:\tlearn: 0.0025361\ttotal: 19.5s\tremaining: 18.4s\n",
      "257:\tlearn: 0.0025360\ttotal: 19.6s\tremaining: 18.4s\n",
      "258:\tlearn: 0.0025123\ttotal: 19.6s\tremaining: 18.3s\n",
      "259:\tlearn: 0.0025122\ttotal: 19.8s\tremaining: 18.3s\n",
      "260:\tlearn: 0.0025122\ttotal: 19.8s\tremaining: 18.1s\n",
      "261:\tlearn: 0.0025122\ttotal: 19.9s\tremaining: 18s\n",
      "262:\tlearn: 0.0025122\ttotal: 20s\tremaining: 18s\n",
      "263:\tlearn: 0.0024948\ttotal: 20s\tremaining: 17.9s\n",
      "264:\tlearn: 0.0024758\ttotal: 20.1s\tremaining: 17.8s\n",
      "265:\tlearn: 0.0024758\ttotal: 20.2s\tremaining: 17.7s\n",
      "266:\tlearn: 0.0024628\ttotal: 20.2s\tremaining: 17.7s\n",
      "267:\tlearn: 0.0024378\ttotal: 20.3s\tremaining: 17.6s\n",
      "268:\tlearn: 0.0024184\ttotal: 20.4s\tremaining: 17.5s\n",
      "269:\tlearn: 0.0024089\ttotal: 20.5s\tremaining: 17.5s\n",
      "270:\tlearn: 0.0024088\ttotal: 20.5s\tremaining: 17.4s\n",
      "271:\tlearn: 0.0024088\ttotal: 20.7s\tremaining: 17.3s\n",
      "272:\tlearn: 0.0024088\ttotal: 20.7s\tremaining: 17.2s\n",
      "273:\tlearn: 0.0024088\ttotal: 20.8s\tremaining: 17.2s\n",
      "274:\tlearn: 0.0023865\ttotal: 20.8s\tremaining: 17.1s\n",
      "275:\tlearn: 0.0023864\ttotal: 20.9s\tremaining: 17s\n",
      "276:\tlearn: 0.0023864\ttotal: 21s\tremaining: 16.9s\n",
      "277:\tlearn: 0.0023687\ttotal: 21s\tremaining: 16.8s\n",
      "278:\tlearn: 0.0023687\ttotal: 21s\tremaining: 16.7s\n",
      "279:\tlearn: 0.0023687\ttotal: 21.1s\tremaining: 16.5s\n",
      "280:\tlearn: 0.0023687\ttotal: 21.1s\tremaining: 16.4s\n",
      "281:\tlearn: 0.0023493\ttotal: 21.2s\tremaining: 16.4s\n",
      "282:\tlearn: 0.0023493\ttotal: 21.3s\tremaining: 16.3s\n",
      "283:\tlearn: 0.0023493\ttotal: 21.4s\tremaining: 16.3s\n",
      "284:\tlearn: 0.0023317\ttotal: 21.5s\tremaining: 16.2s\n",
      "285:\tlearn: 0.0023317\ttotal: 21.5s\tremaining: 16.1s\n",
      "286:\tlearn: 0.0023317\ttotal: 21.5s\tremaining: 16s\n",
      "287:\tlearn: 0.0023124\ttotal: 21.6s\tremaining: 15.9s\n",
      "288:\tlearn: 0.0023123\ttotal: 21.6s\tremaining: 15.8s\n",
      "289:\tlearn: 0.0023123\ttotal: 21.7s\tremaining: 15.7s\n",
      "290:\tlearn: 0.0023123\ttotal: 21.7s\tremaining: 15.6s\n",
      "291:\tlearn: 0.0023123\ttotal: 21.7s\tremaining: 15.5s\n",
      "292:\tlearn: 0.0023123\ttotal: 21.8s\tremaining: 15.4s\n",
      "293:\tlearn: 0.0022968\ttotal: 21.9s\tremaining: 15.3s\n",
      "294:\tlearn: 0.0022817\ttotal: 21.9s\tremaining: 15.3s\n",
      "295:\tlearn: 0.0022817\ttotal: 22.1s\tremaining: 15.2s\n",
      "296:\tlearn: 0.0022817\ttotal: 22.1s\tremaining: 15.1s\n",
      "297:\tlearn: 0.0022817\ttotal: 22.2s\tremaining: 15s\n",
      "298:\tlearn: 0.0022626\ttotal: 22.3s\tremaining: 15s\n",
      "299:\tlearn: 0.0022626\ttotal: 22.3s\tremaining: 14.9s\n",
      "300:\tlearn: 0.0022626\ttotal: 22.4s\tremaining: 14.8s\n",
      "301:\tlearn: 0.0022626\ttotal: 22.5s\tremaining: 14.7s\n",
      "302:\tlearn: 0.0022626\ttotal: 22.5s\tremaining: 14.6s\n",
      "303:\tlearn: 0.0022525\ttotal: 22.6s\tremaining: 14.6s\n",
      "304:\tlearn: 0.0022525\ttotal: 22.7s\tremaining: 14.5s\n",
      "305:\tlearn: 0.0022452\ttotal: 22.8s\tremaining: 14.4s\n",
      "306:\tlearn: 0.0022451\ttotal: 22.8s\tremaining: 14.3s\n",
      "307:\tlearn: 0.0022451\ttotal: 22.9s\tremaining: 14.3s\n",
      "308:\tlearn: 0.0022451\ttotal: 23s\tremaining: 14.2s\n",
      "309:\tlearn: 0.0022349\ttotal: 23.1s\tremaining: 14.1s\n",
      "310:\tlearn: 0.0022349\ttotal: 23.2s\tremaining: 14.1s\n",
      "311:\tlearn: 0.0022349\ttotal: 23.2s\tremaining: 14s\n",
      "312:\tlearn: 0.0022349\ttotal: 23.3s\tremaining: 13.9s\n",
      "313:\tlearn: 0.0022163\ttotal: 23.4s\tremaining: 13.8s\n",
      "314:\tlearn: 0.0022019\ttotal: 23.5s\tremaining: 13.8s\n",
      "315:\tlearn: 0.0022018\ttotal: 23.6s\tremaining: 13.7s\n",
      "316:\tlearn: 0.0022019\ttotal: 23.6s\tremaining: 13.6s\n",
      "317:\tlearn: 0.0022017\ttotal: 23.7s\tremaining: 13.5s\n",
      "318:\tlearn: 0.0022017\ttotal: 23.8s\tremaining: 13.5s\n",
      "319:\tlearn: 0.0022017\ttotal: 23.8s\tremaining: 13.4s\n",
      "320:\tlearn: 0.0022017\ttotal: 23.9s\tremaining: 13.3s\n",
      "321:\tlearn: 0.0022017\ttotal: 24s\tremaining: 13.3s\n",
      "322:\tlearn: 0.0022017\ttotal: 24s\tremaining: 13.2s\n",
      "323:\tlearn: 0.0022017\ttotal: 24.1s\tremaining: 13.1s\n",
      "324:\tlearn: 0.0022017\ttotal: 24.2s\tremaining: 13s\n",
      "325:\tlearn: 0.0022016\ttotal: 24.3s\tremaining: 13s\n",
      "326:\tlearn: 0.0022016\ttotal: 24.4s\tremaining: 12.9s\n",
      "327:\tlearn: 0.0022016\ttotal: 24.5s\tremaining: 12.8s\n",
      "328:\tlearn: 0.0022016\ttotal: 24.5s\tremaining: 12.7s\n",
      "329:\tlearn: 0.0022016\ttotal: 24.6s\tremaining: 12.7s\n",
      "330:\tlearn: 0.0022016\ttotal: 24.7s\tremaining: 12.6s\n",
      "331:\tlearn: 0.0021942\ttotal: 24.7s\tremaining: 12.5s\n",
      "332:\tlearn: 0.0021942\ttotal: 24.8s\tremaining: 12.5s\n",
      "333:\tlearn: 0.0021942\ttotal: 24.9s\tremaining: 12.4s\n",
      "334:\tlearn: 0.0021942\ttotal: 25s\tremaining: 12.3s\n",
      "335:\tlearn: 0.0021942\ttotal: 25s\tremaining: 12.2s\n",
      "336:\tlearn: 0.0021942\ttotal: 25.1s\tremaining: 12.1s\n",
      "337:\tlearn: 0.0021739\ttotal: 25.2s\tremaining: 12.1s\n",
      "338:\tlearn: 0.0021739\ttotal: 25.2s\tremaining: 12s\n",
      "339:\tlearn: 0.0021637\ttotal: 25.4s\tremaining: 11.9s\n",
      "340:\tlearn: 0.0021636\ttotal: 25.4s\tremaining: 11.9s\n",
      "341:\tlearn: 0.0021636\ttotal: 25.6s\tremaining: 11.8s\n",
      "342:\tlearn: 0.0021550\ttotal: 25.6s\tremaining: 11.7s\n",
      "343:\tlearn: 0.0021550\ttotal: 25.6s\tremaining: 11.6s\n",
      "344:\tlearn: 0.0021549\ttotal: 25.7s\tremaining: 11.5s\n",
      "345:\tlearn: 0.0021549\ttotal: 25.8s\tremaining: 11.5s\n",
      "346:\tlearn: 0.0021549\ttotal: 25.8s\tremaining: 11.4s\n",
      "347:\tlearn: 0.0021549\ttotal: 25.9s\tremaining: 11.3s\n",
      "348:\tlearn: 0.0021549\ttotal: 25.9s\tremaining: 11.2s\n",
      "349:\tlearn: 0.0021549\ttotal: 26.1s\tremaining: 11.2s\n",
      "350:\tlearn: 0.0021549\ttotal: 26.1s\tremaining: 11.1s\n",
      "351:\tlearn: 0.0021549\ttotal: 26.2s\tremaining: 11s\n",
      "352:\tlearn: 0.0021549\ttotal: 26.3s\tremaining: 10.9s\n",
      "353:\tlearn: 0.0021549\ttotal: 26.4s\tremaining: 10.9s\n",
      "354:\tlearn: 0.0021549\ttotal: 26.4s\tremaining: 10.8s\n",
      "355:\tlearn: 0.0021377\ttotal: 26.5s\tremaining: 10.7s\n",
      "356:\tlearn: 0.0021198\ttotal: 26.6s\tremaining: 10.7s\n",
      "357:\tlearn: 0.0021198\ttotal: 26.7s\tremaining: 10.6s\n",
      "358:\tlearn: 0.0021197\ttotal: 26.8s\tremaining: 10.5s\n",
      "359:\tlearn: 0.0021197\ttotal: 26.8s\tremaining: 10.4s\n",
      "360:\tlearn: 0.0021197\ttotal: 26.9s\tremaining: 10.4s\n",
      "361:\tlearn: 0.0021196\ttotal: 27s\tremaining: 10.3s\n",
      "362:\tlearn: 0.0021196\ttotal: 27s\tremaining: 10.2s\n",
      "363:\tlearn: 0.0021196\ttotal: 27.1s\tremaining: 10.1s\n",
      "364:\tlearn: 0.0021196\ttotal: 27.2s\tremaining: 10.1s\n",
      "365:\tlearn: 0.0021196\ttotal: 27.3s\tremaining: 9.99s\n",
      "366:\tlearn: 0.0021196\ttotal: 27.3s\tremaining: 9.9s\n",
      "367:\tlearn: 0.0021196\ttotal: 27.5s\tremaining: 9.85s\n",
      "368:\tlearn: 0.0021195\ttotal: 27.5s\tremaining: 9.77s\n",
      "369:\tlearn: 0.0021195\ttotal: 27.6s\tremaining: 9.7s\n",
      "370:\tlearn: 0.0021193\ttotal: 27.7s\tremaining: 9.62s\n",
      "371:\tlearn: 0.0021193\ttotal: 27.7s\tremaining: 9.54s\n",
      "372:\tlearn: 0.0021193\ttotal: 27.8s\tremaining: 9.47s\n",
      "373:\tlearn: 0.0021193\ttotal: 27.9s\tremaining: 9.39s\n",
      "374:\tlearn: 0.0021062\ttotal: 28s\tremaining: 9.33s\n",
      "375:\tlearn: 0.0021062\ttotal: 28s\tremaining: 9.25s\n",
      "376:\tlearn: 0.0021062\ttotal: 28.2s\tremaining: 9.18s\n",
      "377:\tlearn: 0.0021062\ttotal: 28.2s\tremaining: 9.1s\n",
      "378:\tlearn: 0.0021062\ttotal: 28.3s\tremaining: 9.03s\n",
      "379:\tlearn: 0.0021061\ttotal: 28.4s\tremaining: 8.96s\n",
      "380:\tlearn: 0.0021061\ttotal: 28.4s\tremaining: 8.87s\n",
      "381:\tlearn: 0.0021061\ttotal: 28.5s\tremaining: 8.81s\n",
      "382:\tlearn: 0.0021061\ttotal: 28.6s\tremaining: 8.73s\n",
      "383:\tlearn: 0.0021061\ttotal: 28.7s\tremaining: 8.67s\n",
      "384:\tlearn: 0.0021061\ttotal: 28.7s\tremaining: 8.59s\n",
      "385:\tlearn: 0.0021061\ttotal: 28.8s\tremaining: 8.51s\n",
      "386:\tlearn: 0.0021061\ttotal: 28.9s\tremaining: 8.44s\n",
      "387:\tlearn: 0.0021061\ttotal: 28.9s\tremaining: 8.35s\n",
      "388:\tlearn: 0.0021061\ttotal: 29.1s\tremaining: 8.29s\n",
      "389:\tlearn: 0.0021060\ttotal: 29.1s\tremaining: 8.21s\n",
      "390:\tlearn: 0.0021060\ttotal: 29.2s\tremaining: 8.13s\n",
      "391:\tlearn: 0.0021060\ttotal: 29.3s\tremaining: 8.06s\n",
      "392:\tlearn: 0.0021060\ttotal: 29.3s\tremaining: 7.98s\n",
      "393:\tlearn: 0.0021060\ttotal: 29.4s\tremaining: 7.92s\n",
      "394:\tlearn: 0.0021060\ttotal: 29.5s\tremaining: 7.83s\n",
      "395:\tlearn: 0.0021059\ttotal: 29.5s\tremaining: 7.75s\n",
      "396:\tlearn: 0.0021059\ttotal: 29.6s\tremaining: 7.69s\n",
      "397:\tlearn: 0.0021059\ttotal: 29.7s\tremaining: 7.6s\n",
      "398:\tlearn: 0.0020867\ttotal: 29.7s\tremaining: 7.53s\n",
      "399:\tlearn: 0.0020867\ttotal: 29.8s\tremaining: 7.45s\n",
      "400:\tlearn: 0.0020867\ttotal: 29.9s\tremaining: 7.37s\n",
      "401:\tlearn: 0.0020867\ttotal: 30s\tremaining: 7.31s\n",
      "402:\tlearn: 0.0020867\ttotal: 30s\tremaining: 7.23s\n",
      "403:\tlearn: 0.0020867\ttotal: 30.1s\tremaining: 7.16s\n",
      "404:\tlearn: 0.0020866\ttotal: 30.2s\tremaining: 7.08s\n",
      "405:\tlearn: 0.0020767\ttotal: 30.2s\tremaining: 7s\n",
      "406:\tlearn: 0.0020767\ttotal: 30.3s\tremaining: 6.93s\n",
      "407:\tlearn: 0.0020766\ttotal: 30.4s\tremaining: 6.85s\n",
      "408:\tlearn: 0.0020766\ttotal: 30.4s\tremaining: 6.77s\n",
      "409:\tlearn: 0.0020766\ttotal: 30.5s\tremaining: 6.7s\n",
      "410:\tlearn: 0.0020766\ttotal: 30.6s\tremaining: 6.62s\n",
      "411:\tlearn: 0.0020766\ttotal: 30.7s\tremaining: 6.55s\n",
      "412:\tlearn: 0.0020766\ttotal: 30.7s\tremaining: 6.47s\n",
      "413:\tlearn: 0.0020766\ttotal: 30.8s\tremaining: 6.4s\n",
      "414:\tlearn: 0.0020766\ttotal: 30.9s\tremaining: 6.33s\n",
      "415:\tlearn: 0.0020765\ttotal: 31s\tremaining: 6.26s\n",
      "416:\tlearn: 0.0020706\ttotal: 31.1s\tremaining: 6.19s\n",
      "417:\tlearn: 0.0020705\ttotal: 31.1s\tremaining: 6.11s\n",
      "418:\tlearn: 0.0020705\ttotal: 31.2s\tremaining: 6.04s\n",
      "419:\tlearn: 0.0020705\ttotal: 31.3s\tremaining: 5.96s\n",
      "420:\tlearn: 0.0020705\ttotal: 31.4s\tremaining: 5.89s\n",
      "421:\tlearn: 0.0020623\ttotal: 31.4s\tremaining: 5.81s\n",
      "422:\tlearn: 0.0020623\ttotal: 31.5s\tremaining: 5.73s\n",
      "423:\tlearn: 0.0020622\ttotal: 31.6s\tremaining: 5.66s\n",
      "424:\tlearn: 0.0020622\ttotal: 31.6s\tremaining: 5.58s\n",
      "425:\tlearn: 0.0020622\ttotal: 31.8s\tremaining: 5.52s\n",
      "426:\tlearn: 0.0020622\ttotal: 31.8s\tremaining: 5.44s\n",
      "427:\tlearn: 0.0020622\ttotal: 31.9s\tremaining: 5.36s\n",
      "428:\tlearn: 0.0020622\ttotal: 32s\tremaining: 5.29s\n",
      "429:\tlearn: 0.0020622\ttotal: 32s\tremaining: 5.21s\n",
      "430:\tlearn: 0.0020526\ttotal: 32.1s\tremaining: 5.14s\n",
      "431:\tlearn: 0.0020525\ttotal: 32.2s\tremaining: 5.06s\n",
      "432:\tlearn: 0.0020525\ttotal: 32.3s\tremaining: 5s\n",
      "433:\tlearn: 0.0020524\ttotal: 32.3s\tremaining: 4.92s\n",
      "434:\tlearn: 0.0020524\ttotal: 32.4s\tremaining: 4.85s\n",
      "435:\tlearn: 0.0020524\ttotal: 32.5s\tremaining: 4.77s\n",
      "436:\tlearn: 0.0020524\ttotal: 32.6s\tremaining: 4.7s\n",
      "437:\tlearn: 0.0020524\ttotal: 32.7s\tremaining: 4.62s\n",
      "438:\tlearn: 0.0020521\ttotal: 32.7s\tremaining: 4.54s\n",
      "439:\tlearn: 0.0020521\ttotal: 32.8s\tremaining: 4.47s\n",
      "440:\tlearn: 0.0020521\ttotal: 32.9s\tremaining: 4.4s\n",
      "441:\tlearn: 0.0020521\ttotal: 32.9s\tremaining: 4.32s\n",
      "442:\tlearn: 0.0020521\ttotal: 33s\tremaining: 4.25s\n",
      "443:\tlearn: 0.0020363\ttotal: 33.1s\tremaining: 4.17s\n",
      "444:\tlearn: 0.0020166\ttotal: 33.2s\tremaining: 4.1s\n",
      "445:\tlearn: 0.0020167\ttotal: 33.2s\tremaining: 4.02s\n",
      "446:\tlearn: 0.0020166\ttotal: 33.3s\tremaining: 3.95s\n",
      "447:\tlearn: 0.0020166\ttotal: 33.4s\tremaining: 3.88s\n",
      "448:\tlearn: 0.0020166\ttotal: 33.5s\tremaining: 3.8s\n",
      "449:\tlearn: 0.0020166\ttotal: 33.5s\tremaining: 3.73s\n",
      "450:\tlearn: 0.0020165\ttotal: 33.6s\tremaining: 3.65s\n",
      "451:\tlearn: 0.0020165\ttotal: 33.7s\tremaining: 3.58s\n",
      "452:\tlearn: 0.0020165\ttotal: 33.8s\tremaining: 3.5s\n",
      "453:\tlearn: 0.0020162\ttotal: 33.9s\tremaining: 3.43s\n",
      "454:\tlearn: 0.0020162\ttotal: 33.9s\tremaining: 3.35s\n",
      "455:\tlearn: 0.0020162\ttotal: 34s\tremaining: 3.28s\n",
      "456:\tlearn: 0.0020162\ttotal: 34.1s\tremaining: 3.21s\n",
      "457:\tlearn: 0.0020162\ttotal: 34.1s\tremaining: 3.13s\n",
      "458:\tlearn: 0.0020161\ttotal: 34.2s\tremaining: 3.06s\n",
      "459:\tlearn: 0.0020056\ttotal: 34.3s\tremaining: 2.98s\n",
      "460:\tlearn: 0.0019881\ttotal: 34.4s\tremaining: 2.91s\n",
      "461:\tlearn: 0.0019881\ttotal: 34.4s\tremaining: 2.83s\n",
      "462:\tlearn: 0.0019880\ttotal: 34.5s\tremaining: 2.75s\n",
      "463:\tlearn: 0.0019880\ttotal: 34.6s\tremaining: 2.68s\n",
      "464:\tlearn: 0.0019880\ttotal: 34.6s\tremaining: 2.61s\n",
      "465:\tlearn: 0.0019880\ttotal: 34.7s\tremaining: 2.54s\n",
      "466:\tlearn: 0.0019880\ttotal: 34.8s\tremaining: 2.46s\n",
      "467:\tlearn: 0.0019880\ttotal: 34.9s\tremaining: 2.38s\n",
      "468:\tlearn: 0.0019880\ttotal: 35s\tremaining: 2.31s\n",
      "469:\tlearn: 0.0019880\ttotal: 35s\tremaining: 2.23s\n",
      "470:\tlearn: 0.0019681\ttotal: 35.1s\tremaining: 2.16s\n",
      "471:\tlearn: 0.0019514\ttotal: 35.2s\tremaining: 2.09s\n",
      "472:\tlearn: 0.0019514\ttotal: 35.3s\tremaining: 2.01s\n",
      "473:\tlearn: 0.0019514\ttotal: 35.3s\tremaining: 1.94s\n",
      "474:\tlearn: 0.0019514\ttotal: 35.4s\tremaining: 1.86s\n",
      "475:\tlearn: 0.0019514\ttotal: 35.5s\tremaining: 1.79s\n",
      "476:\tlearn: 0.0019514\ttotal: 35.5s\tremaining: 1.71s\n",
      "477:\tlearn: 0.0019514\ttotal: 35.7s\tremaining: 1.64s\n",
      "478:\tlearn: 0.0019514\ttotal: 35.7s\tremaining: 1.57s\n",
      "479:\tlearn: 0.0019514\ttotal: 35.8s\tremaining: 1.49s\n",
      "480:\tlearn: 0.0019514\ttotal: 35.9s\tremaining: 1.42s\n",
      "481:\tlearn: 0.0019514\ttotal: 36s\tremaining: 1.34s\n",
      "482:\tlearn: 0.0019514\ttotal: 36.1s\tremaining: 1.27s\n",
      "483:\tlearn: 0.0019514\ttotal: 36.2s\tremaining: 1.2s\n",
      "484:\tlearn: 0.0019514\ttotal: 36.2s\tremaining: 1.12s\n",
      "485:\tlearn: 0.0019514\ttotal: 36.3s\tremaining: 1.04s\n",
      "486:\tlearn: 0.0019514\ttotal: 36.4s\tremaining: 971ms\n",
      "487:\tlearn: 0.0019514\ttotal: 36.4s\tremaining: 896ms\n",
      "488:\tlearn: 0.0019513\ttotal: 36.5s\tremaining: 821ms\n",
      "489:\tlearn: 0.0019513\ttotal: 36.6s\tremaining: 747ms\n",
      "490:\tlearn: 0.0019514\ttotal: 36.6s\tremaining: 671ms\n",
      "491:\tlearn: 0.0019514\ttotal: 36.7s\tremaining: 597ms\n",
      "492:\tlearn: 0.0019513\ttotal: 36.8s\tremaining: 522ms\n",
      "493:\tlearn: 0.0019513\ttotal: 36.9s\tremaining: 448ms\n",
      "494:\tlearn: 0.0019513\ttotal: 36.9s\tremaining: 373ms\n",
      "495:\tlearn: 0.0019513\ttotal: 37s\tremaining: 298ms\n",
      "496:\tlearn: 0.0019513\ttotal: 37.1s\tremaining: 224ms\n",
      "497:\tlearn: 0.0019513\ttotal: 37.1s\tremaining: 149ms\n",
      "498:\tlearn: 0.0019513\ttotal: 37.1s\tremaining: 74.4ms\n",
      "499:\tlearn: 0.0019513\ttotal: 37.3s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 2610, in __init__\n",
      "    _safe_call(_LIB.LGBM_BoosterCreate(\n",
      "  File \"C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 125, in _safe_call\n",
      "    raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))\n",
      "lightgbm.basic.LightGBMError: Check failed: config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f at D:\\a\\1\\s\\python-package\\compile\\src\\boosting\\rf.hpp, line 35 .\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\smit1\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.70854701        nan 0.70982906        nan        nan 0.96666667\n",
      "        nan 0.66367521        nan 0.99401709]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rscv_result = {}\n",
    "\n",
    "#Fitting & Testing the model\n",
    "for model, name in zip([lr, knn, svm, dt, bag, adb, gb, rf, cgb, lgb,  xgb], ['Logistic Regression', 'KNeighbors', 'SVM',\n",
    "                                                                             'DecisionTree', 'Bagging', 'AdaBoost', 'GradientBoost',\n",
    "                                                                             'Random Forest', 'CatBoost', 'LightGBM', 'XGBoost']):\n",
    "    if model == lr:\n",
    "        params = {'solver': ['liblinear', 'lfbgs', 'sag', 'saga'], 'penalty':['elasticnet', 'l1', 'l2', 'none'],\n",
    "             'multi_class': ['auto', 'ovr', 'multinomial'], 'C':[0.1, 1, 10],\n",
    "             'tol': [0.00001, 0.0001, 0.001], 'class_weight': ['balanced', None]}\n",
    "    \n",
    "    if model == knn:\n",
    "        params = {'n_neighbors':np.arange(5,50,5), 'weights': ['uniform', 'distance'],\n",
    "            'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': np.arange(10,51,10),\n",
    "            'metric': ['minkowski', 'euclidean', 'manhattan']}\n",
    "    \n",
    "    if model == svm:\n",
    "        params = {'gamma': [10, 1, 0.1, 0.01, 0.001, 0.0001], 'C': [1000, 100, 10, 1, 0.1, 0.01, 0.001],\n",
    "            'kernel': ['poly', 'rbf', 'sigmoid'], 'class_weight': ['balanced', None],\n",
    "            'decision_function_shape': ['ovo', 'ovr']}\n",
    "    \n",
    "    if model == dt:\n",
    "        params = {'criterion':['gini', 'entropy', 'log_loss'], 'splitter':['best', 'random'], 'max_depth':[None, np.arange(1,11)],\n",
    "           'max_features': np.arange(8, 21, 2), 'random_state':[1], 'class_weight':['balanced', None]}\n",
    "    \n",
    "    if model==bag:\n",
    "        params = {'n_estimators': [10, 30, 50, 100, 500], 'max_features': np.arange(8, 21, 2), 'random_state':[1]}\n",
    "        with open('models.pckl', 'wb') as f:\n",
    "            pickle.dump(model,f)\n",
    "    \n",
    "    if model == adb:\n",
    "        params = {'n_estimators': [10, 30, 50, 100, 500], 'learning_rate':[0.001, 0.01, 0.1, 1, 10], 'algorithm':['SAMME.R', 'SAMME'],\n",
    "            'random_state':[1]}\n",
    "\n",
    "    if model == gb:\n",
    "        params = {'loss':['log_loss', 'exponential'], 'learning_rate':[0.001, 0.01, 0.1, 1, 10],\n",
    "           'n_estimators': [10, 30, 50, 100, 500], 'max_depth':np.arange(1,11), 'random_state':[1],\n",
    "           'max_features': np.arange(8, 21, 2)}\n",
    "\n",
    "    if model == rf:\n",
    "        params = {'n_estimators': [10, 30, 50, 100, 500], 'criterion':['gini', 'entropy', 'log_loss'],\n",
    "           'max_depth':np.arange(1,11), 'max_features': np.arange(8, 21, 2), 'random_state':[1]}\n",
    "\n",
    "    if model == lgb:\n",
    "        params = {'boosting_type':['gbdt', 'rf'], 'num_leaves':np.arange(20, 40), 'max_depth':np.arange(1,11),\n",
    "            'learning_rate':[0.001, 0.01, 0.1, 1, 10], 'n_estimators': [10, 30, 50, 100, 500], 'class_weight': ['balanced', None],\n",
    "            'random_state':[1]}\n",
    "\n",
    "    if model == cgb:\n",
    "        params = {'learning_rate':[0.001, 0.01, 0.1, 1], 'n_estimators': [100, 500], \n",
    "            'max_depth':np.arange(1,11), 'random_state':[1], \n",
    "            'feature_border_type': ['Median', 'Uniform', 'UniformAndQuantiles', 'GreedyLogSum', 'MaxLogSum', 'MinEntropy']}\n",
    "\n",
    "    if model == xgb:\n",
    "        le = LabelEncoder()\n",
    "        ypca_tr = le.fit_transform(ypca_tr)\n",
    "        ypca_te = le.fit_transform(ypca_te)\n",
    "        params = {'n_estimators': [10, 30, 50, 100, 500], 'max_depth':np.arange(1,11),\n",
    "            'max_leaves': np.arange(0, 150), 'learning_rate':[0.001, 0.01, 0.1, 1, 10], 'random_state':[1]}\n",
    "\n",
    "    rscv_result[name] = tun_fun(model, name, xpca_tr, xpca_te, ypca_tr, ypca_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd57ae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smit1\\AppData\\Local\\Temp\\ipykernel_10072\\4195121569.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mod_tune_perform = pd.DataFrame(np.array(list(rscv_result.values()))[:, 1:-1], columns=['Best Tuning Score', 'Training Score', 'Test Score', 'Duration'],\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Tuning Score</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.738889</td>\n",
       "      <td>0.749573</td>\n",
       "      <td>0.761092</td>\n",
       "      <td>6.064314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.920513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926621</td>\n",
       "      <td>10.618165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.992308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994881</td>\n",
       "      <td>47.389324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964164</td>\n",
       "      <td>3.340484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>556.079649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.711966</td>\n",
       "      <td>0.72265</td>\n",
       "      <td>0.667235</td>\n",
       "      <td>255.186742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost</th>\n",
       "      <td>0.999573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.374144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.967521</td>\n",
       "      <td>0.982479</td>\n",
       "      <td>0.97099</td>\n",
       "      <td>208.218806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.997863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>984.652401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.994017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994881</td>\n",
       "      <td>19.559664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>121.401201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Best Tuning Score Training Score Test Score    Duration\n",
       "Model                                                                      \n",
       "Logistic Regression          0.738889       0.749573   0.761092    6.064314\n",
       "KNeighbors                   0.920513            1.0   0.926621   10.618165\n",
       "SVM                          0.992308            1.0   0.994881   47.389324\n",
       "DecisionTree                 0.966667            1.0   0.964164    3.340484\n",
       "Bagging                           1.0            1.0        1.0  556.079649\n",
       "AdaBoost                     0.711966        0.72265   0.667235  255.186742\n",
       "GradientBoost                0.999573            1.0        1.0  205.374144\n",
       "Random Forest                0.967521       0.982479    0.97099  208.218806\n",
       "CatBoost                     0.997863            1.0        1.0  984.652401\n",
       "LightGBM                     0.994017            1.0   0.994881   19.559664\n",
       "XGBoost                      0.996154            1.0   0.998294  121.401201"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the result as a dataframe\n",
    "mod_tune_perform = pd.DataFrame(np.array(list(rscv_result.values()))[:, 1:-1], columns=['Best Tuning Score', 'Training Score', 'Test Score', 'Duration'],\n",
    "                         index = rscv_result.keys())\n",
    "mod_tune_perform.index.name = 'Model'\n",
    "mod_tune_perform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c80a08",
   "metadata": {},
   "source": [
    "### 6. Post Training and Conclusion: [5 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c9731",
   "metadata": {},
   "source": [
    "#### 6A. Display and compare all the models designed with their train and test accuracies. [1 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb47b969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Basic Models\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988055</td>\n",
       "      <td>59.595356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.996581</td>\n",
       "      <td>0.986348</td>\n",
       "      <td>1.214389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964164</td>\n",
       "      <td>2.189227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911263</td>\n",
       "      <td>1.818029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.90273</td>\n",
       "      <td>0.773142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.858362</td>\n",
       "      <td>1.682107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost</th>\n",
       "      <td>0.998291</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>7.709227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>0.999573</td>\n",
       "      <td>0.757679</td>\n",
       "      <td>1.688601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.937179</td>\n",
       "      <td>0.754266</td>\n",
       "      <td>1.668377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.77094</td>\n",
       "      <td>0.721843</td>\n",
       "      <td>0.113728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.361856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Training Score Test Score   Duration\n",
       "Model                                                   \n",
       "CatBoost                       1.0   0.988055  59.595356\n",
       "SVM                       0.996581   0.986348   1.214389\n",
       "XGBoost                        1.0   0.964164   2.189227\n",
       "LightGBM                       1.0   0.911263   1.818029\n",
       "KNeighbors                0.931624    0.90273   0.773142\n",
       "Random Forest                  1.0   0.858362   1.682107\n",
       "GradientBoost             0.998291   0.849829   7.709227\n",
       "Bagging                   0.999573   0.757679   1.688601\n",
       "AdaBoost                  0.937179   0.754266   1.668377\n",
       "Logistic Regression        0.77094   0.721843   0.113728\n",
       "DecisionTree                   1.0   0.675768   0.361856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Comaprison of Hyperparameter Tuned Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Tuning Score</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bagging</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>556.079649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoost</th>\n",
       "      <td>0.999573</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>205.374144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.997863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>984.652401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.996154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998294</td>\n",
       "      <td>121.401201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.992308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994881</td>\n",
       "      <td>47.389324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.994017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.994881</td>\n",
       "      <td>19.559664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.967521</td>\n",
       "      <td>0.982479</td>\n",
       "      <td>0.97099</td>\n",
       "      <td>208.218806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964164</td>\n",
       "      <td>3.340484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.920513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926621</td>\n",
       "      <td>10.618165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.738889</td>\n",
       "      <td>0.749573</td>\n",
       "      <td>0.761092</td>\n",
       "      <td>6.064314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>0.711966</td>\n",
       "      <td>0.72265</td>\n",
       "      <td>0.667235</td>\n",
       "      <td>255.186742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Best Tuning Score Training Score Test Score    Duration\n",
       "Model                                                                      \n",
       "Bagging                           1.0            1.0        1.0  556.079649\n",
       "GradientBoost                0.999573            1.0        1.0  205.374144\n",
       "CatBoost                     0.997863            1.0        1.0  984.652401\n",
       "XGBoost                      0.996154            1.0   0.998294  121.401201\n",
       "SVM                          0.992308            1.0   0.994881   47.389324\n",
       "LightGBM                     0.994017            1.0   0.994881   19.559664\n",
       "Random Forest                0.967521       0.982479    0.97099  208.218806\n",
       "DecisionTree                 0.966667            1.0   0.964164    3.340484\n",
       "KNeighbors                   0.920513            1.0   0.926621   10.618165\n",
       "Logistic Regression          0.738889       0.749573   0.761092    6.064314\n",
       "AdaBoost                     0.711966        0.72265   0.667235  255.186742"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Displaying the comparision for Basic model & Hypertuned Model\n",
    "print('Comparison of Basic Models')\n",
    "display(mod_perform.sort_values(by='Test Score', ascending=False))\n",
    "print('\\n')\n",
    "print('Comaprison of Hyperparameter Tuned Model')\n",
    "display(mod_tune_perform.sort_values(by='Test Score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace55221",
   "metadata": {},
   "source": [
    "#### 6B. Select the final best trained model along with your detailed comments for selecting this model. [1 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9abb20",
   "metadata": {},
   "source": [
    "- Here we observe that 'Bagging' shows the best tuning score, train score & test score of 1 in Hypertune DataFrame. This means that the model overfits itslef, & it may not perform well in production.\n",
    "- In Gradient Boosting, the same scenerio applies as that of 'Bagging' & hence it may not be well suited in production.\n",
    "- Also the time taken by Gradient Boost is almost 1/3rd less compared to that of Bagging, it is much higher in comparion to that of XGBoost, SVM & LightGBM.\n",
    "- While for CatBoost & XGBoost, XGBoost take almost 1/10th of the time taken by CatBoost. So here it is better to prefer XGBoost model.\n",
    "- Again for SVM & LightGBM the score is tied, but time taken by LightGBM is much less than that of the time taken by SVM. Also the time taken by SVM model is a bit lesser than XGBoost model, while not compromising so much on the score.\n",
    "- While it it noticeable that Decision Tree has taken the least time, the score is little compromised compared to that of CatBoost, XGBoost, SVM & LightGBM model.\n",
    "- Random Forest has slightly less score than that of Decision Tree & even took more time, but the model is not over fitted on Training Dataset.\n",
    "- The rest of the model, Logistic Regression & Ada-Boost have compromised highly on score & cannot be put to prooduction.\n",
    "\n",
    "Overall observation can be made that after tuning of Hyperparameter, all models have improved score compared to that of their basic paramter.\n",
    "\n",
    "Hence, from the above we can conclude that 'LightGBM' can be considered as a best model for this dataset & can be put to production. It can be said to have higher chances of predicting more accurately in production compared to any other model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5499a815",
   "metadata": {},
   "source": [
    "#### 6C. Pickle the selected model for future use. [2 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d470b4dc",
   "metadata": {},
   "source": [
    "- We have selected LightGBM as best model & hence we pickle it for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93dc4fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=10, estimator=LGBMClassifier(),\n",
       "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;rf&#x27;],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;learning_rate&#x27;: [0.001, 0.01, 0.1, 1,\n",
       "                                                          10],\n",
       "                                        &#x27;max_depth&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        &#x27;n_estimators&#x27;: [10, 30, 50, 100, 500],\n",
       "                                        &#x27;num_leaves&#x27;: array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39]),\n",
       "                                        &#x27;random_state&#x27;: [1]},\n",
       "                   random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=10, estimator=LGBMClassifier(),\n",
       "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;rf&#x27;],\n",
       "                                        &#x27;class_weight&#x27;: [&#x27;balanced&#x27;, None],\n",
       "                                        &#x27;learning_rate&#x27;: [0.001, 0.01, 0.1, 1,\n",
       "                                                          10],\n",
       "                                        &#x27;max_depth&#x27;: array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        &#x27;n_estimators&#x27;: [10, 30, 50, 100, 500],\n",
       "                                        &#x27;num_leaves&#x27;: array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39]),\n",
       "                                        &#x27;random_state&#x27;: [1]},\n",
       "                   random_state=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=LGBMClassifier(),\n",
       "                   param_distributions={'boosting_type': ['gbdt', 'rf'],\n",
       "                                        'class_weight': ['balanced', None],\n",
       "                                        'learning_rate': [0.001, 0.01, 0.1, 1,\n",
       "                                                          10],\n",
       "                                        'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       "                                        'n_estimators': [10, 30, 50, 100, 500],\n",
       "                                        'num_leaves': array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39]),\n",
       "                                        'random_state': [1]},\n",
       "                   random_state=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the saved model 'LightGBM' for future use.\n",
    "lgb_pickle = pickle.load(open('LightGBM', 'rb'))\n",
    "lgb_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef67ed07",
   "metadata": {},
   "source": [
    "#### 6D. Write your conclusion on the results. [1 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f123739f",
   "metadata": {},
   "source": [
    "- We have selected the LightGBM model based on it's scoring on train & test data set and time taked to execute the process by it.\n",
    "- We need to select the best model that will be suitable of production, and here LightGBM suits the best.\n",
    "- Here in the dataset we observed that the ratio of '-1' (Pass) to '1' (Fail) for the manufacturing products is highly imbalanced. Hence the model will be likely to identify more Pass compared to Failure. Rather for us the Failed class is of more importance to us. So it it imperative to feed the data to model to predict the Fail class almost as accurately as that of Pass class.\n",
    "- The Original dataset had too many unwated & unnecessary features that were not at all likely to predict the Pass/Failure state of the product. Hence it was extremely important that such features be removed to enhance the accuracy of the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
